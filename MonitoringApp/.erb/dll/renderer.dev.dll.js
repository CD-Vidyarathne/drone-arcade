/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
var renderer;
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/@mongodb-js/saslprep/dist/code-points-data.js":
/*!********************************************************************!*\
  !*** ./node_modules/@mongodb-js/saslprep/dist/code-points-data.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nconst zlib_1 = __webpack_require__(/*! zlib */ \"zlib\");\nexports[\"default\"] = (0, zlib_1.gunzipSync)(Buffer.from('H4sIAAAAAAACA+3dTYgcWR0A8FfTnekQ47aCkBxiZpYV8RhwYQM7bA/ksoLgSRD0IOSiePAkLrowvWSF4CkHEW856MlTQHA9RKZ1ZJODsEcVcTOyhxUEbXdXtpPp1PNVV39Uz4czEyaTVOb3G6a7XtWrr/devX49/+qekG2Go7Aa2jHGyozG+Dmrzi2mP/xb/zMhLI+WlRm2byubm2h0ivVi7BYzusVjuNkt1l9uFWsutWL8OP4rzV9KeXdsKx1HFhbSc6vIG0fKBZ14UNfLFS6FRrGRtXh98ZvphL/x4uLV/IOzaat/vlikv/TixavxR8PQitfPpKNbffXSwgtr8fV07GX+L1967urwg5W0/t0LV37y/oWFlQtX8ping7reXE3LT680r9yPKyn/3Vn64SwdVs6m/KN0yHrp9D+RvXsqpe6MSia5mH6LSog//Xq/++O74YVTjfDFWK2VIuNSemiPppphcVYeyzcudKqFMiq6cs3vVkrzlcnE0mxeZ1Jf2ZXsSvk8TmRZWYdpalydxd5bc8eUkt1wlEbtqTVLr8XQLFpKMb+dpr9SbSOt4ozTgXUq8+Ihm8cTt0shtCvT6dwao6sxPf5ydmU208/Z0yH8IZtlvZi3e5fG12yn3PLSdPvnQ7vsK9rxyKpqevzFZGVfu3YHezvbnbvit9Xdm5fGbf/MZ7PuuNrTjLJnaofH7gm0h+VKU/g/tdUocrer3cO4yOcuycGoyLrba6Ta+lrlnkZ5ntvWCrfV39wLTuNg9QvsvHb37P8BAGCP0eNTOH5szf154JmnNQIcn7b+FziyAfX4eWnn+C6Lm4M0mj31ubkViiDV4WLvs56qN54xGS3HWER5su6nQtZubl9tcY/4atbr9e5kWewew/g2a8fdy2Yaa97+pgQAAAAAAIBHtt+dYmWwaN/byI5g/9PYVfMvb4YvvDpOLJxvFgueP9VbPXh8/yCZViZxNYATaejmDQAAAACgfjJ/3QUA4JD3Px1InT+5PtQCAAAAAAAAAKD2xP8BAAAAAAAAoP7E/wEAAAAAAACg/sT/AQAAAAAAAKD+xP8BAAAAAAAAoP7E/wEAAAAAAACg/sT/AQAAAAAAAKD+xP8BAAAAAAAAoP7E/wEAAAAAAACg/sT/AQAAAAAAAKD+xP8BAAAAAAAAoP6G6+khVCgSAAAAAAAAAKidYQjLYVfNcPSyAE+dhQsnvAAq59/VHAAAAAAAAOCJmv8E/w4HiLqf3nWuWCB1pe0esg/pT3sKd+m4XjhpFpZH3/1THTcU6cfRLnrHf3ZNPZs+bf9rwPuIUPYAWb+j/Zy0EaAxAAAAAADwrPJ1IMBenu6ea99M+0W/17wCAAAAAAAAnGRLm8oA4JnQUAQAAAAAAAAAUHvi/wAAAAAAAABQf+L/AAAAAAAAAFB/4v8AAAAAAAAAUH/i/wAAAAAAAABQf+L/AAAAAAAAAFB/4v8AAAAAAAAAUH/i/wAAAAAAAABQf+L/AAAAAAAAAFB/4v8AAAAAAAAAUH/i/wAAAAAAAABQf+L/AAAAAAAAAFB/jdX0ECsUCQAAAAAAAADUTiMCAAAAAAAAAHU3VAQAAAAAAAAAUH8hLNf1uwsWbhT/uWBzUEx/ei1Nxc001VqrnN2wuRjCK3G4HuNgtuJoSVj17Q9QyBQBAAAAAAAAHMKpuJ4/+Otc5L2XZi8dJlQ/LCPXhc4keJ9UI9uFre3rDfY9uoXZPQBFHL34HSWWm8sx5rH83d967IfZMRZHHG/2Qi8MFnbscXnhnzHei5NND8P2bW2OT3G8vFeebBHbz9dGEf5jDt+fK4/mTve1bnwndsNL92+mE/75xhs/yz65Ed/ZbP29SP96oxvCDxrxcjj333R262/d6X6tG66lYy/z/+rtMn83nHvv9nfOv/dw4+pvspCl4v7+1npa/nHvtbSvjSJ/mf79/VuLC7N03LiW8o/SMU8ldO+jPOul1OVQ3vVwK+TZqBLCt3/RXvveS7eaD0L8YyhrJeV/cC0WGTdD1hzlCo2H98vzK9a+963V7qRVTeaNa+ZGpWp+N62jSmOetJD8dn67fB4n8nzchG7n4+os2tcgzLWUQVg70rta8lE7nqW7IW710v7eDsV1F7e6433njYfd9j9Gl2KIveptMePVamOXQuhXO5tUk6Pv+kiPX43T7/3YevDy4MN+HLw8CHPX6OqOOwKe73z0+pnf3rvT6pX76j/SUU7/3UjqX5r7ZW7PdZU8Vq2id+29Pphdh3n1Tqp/t0aXaWVOPnsFGre+waRdpKf/TK+7fiX3bOWluVeJg77AAPNDwr37fwAA2GP0+BSOHwcn6/231ghwfPr6X+DIBtTj582d47s8LD3xMeYktt+YHXHe6XQuH9P4Nu+H3ctmGmve/qYEAAAAAACAR7bfnWJlsGgSNNoM54tPZ23EI4vYzPY1/fzq1ud/GP/01jjx8P2tYsG7DzrrB4/vHySTz5YB+n8AAAAAgJrJ/XEXAIDHEf/2yXUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgGdABAAAAAAAAADqbqgIAAAAAAAAAKD2hv8DWK79UBhoBgA=', 'base64'));\n//# sourceMappingURL=code-points-data.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/@mongodb-js/saslprep/dist/code-points-data.js?");

/***/ }),

/***/ "./node_modules/@mongodb-js/saslprep/dist/index.js":
/*!*********************************************************!*\
  !*** ./node_modules/@mongodb-js/saslprep/dist/index.js ***!
  \*********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst memory_code_points_1 = __webpack_require__(/*! ./memory-code-points */ \"./node_modules/@mongodb-js/saslprep/dist/memory-code-points.js\");\nconst mapping2space = memory_code_points_1.non_ASCII_space_characters;\nconst mapping2nothing = memory_code_points_1.commonly_mapped_to_nothing;\nconst getCodePoint = (character) => character.codePointAt(0);\nconst first = (x) => x[0];\nconst last = (x) => x[x.length - 1];\nfunction toCodePoints(input) {\n    const codepoints = [];\n    const size = input.length;\n    for (let i = 0; i < size; i += 1) {\n        const before = input.charCodeAt(i);\n        if (before >= 0xd800 && before <= 0xdbff && size > i + 1) {\n            const next = input.charCodeAt(i + 1);\n            if (next >= 0xdc00 && next <= 0xdfff) {\n                codepoints.push((before - 0xd800) * 0x400 + next - 0xdc00 + 0x10000);\n                i += 1;\n                continue;\n            }\n        }\n        codepoints.push(before);\n    }\n    return codepoints;\n}\nfunction saslprep(input, opts = {}) {\n    if (typeof input !== 'string') {\n        throw new TypeError('Expected string.');\n    }\n    if (input.length === 0) {\n        return '';\n    }\n    const mapped_input = toCodePoints(input)\n        .map((character) => (mapping2space.get(character) ? 0x20 : character))\n        .filter((character) => !mapping2nothing.get(character));\n    const normalized_input = String.fromCodePoint\n        .apply(null, mapped_input)\n        .normalize('NFKC');\n    const normalized_map = toCodePoints(normalized_input);\n    const hasProhibited = normalized_map.some((character) => memory_code_points_1.prohibited_characters.get(character));\n    if (hasProhibited) {\n        throw new Error('Prohibited character, see https://tools.ietf.org/html/rfc4013#section-2.3');\n    }\n    if (opts.allowUnassigned !== true) {\n        const hasUnassigned = normalized_map.some((character) => memory_code_points_1.unassigned_code_points.get(character));\n        if (hasUnassigned) {\n            throw new Error('Unassigned code point, see https://tools.ietf.org/html/rfc4013#section-2.5');\n        }\n    }\n    const hasBidiRAL = normalized_map.some((character) => memory_code_points_1.bidirectional_r_al.get(character));\n    const hasBidiL = normalized_map.some((character) => memory_code_points_1.bidirectional_l.get(character));\n    if (hasBidiRAL && hasBidiL) {\n        throw new Error('String must not contain RandALCat and LCat at the same time,' +\n            ' see https://tools.ietf.org/html/rfc3454#section-6');\n    }\n    const isFirstBidiRAL = memory_code_points_1.bidirectional_r_al.get(getCodePoint(first(normalized_input)));\n    const isLastBidiRAL = memory_code_points_1.bidirectional_r_al.get(getCodePoint(last(normalized_input)));\n    if (hasBidiRAL && !(isFirstBidiRAL && isLastBidiRAL)) {\n        throw new Error('Bidirectional RandALCat character must be the first and the last' +\n            ' character of the string, see https://tools.ietf.org/html/rfc3454#section-6');\n    }\n    return normalized_input;\n}\nsaslprep.saslprep = saslprep;\nsaslprep.default = saslprep;\nmodule.exports = saslprep;\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/@mongodb-js/saslprep/dist/index.js?");

/***/ }),

/***/ "./node_modules/@mongodb-js/saslprep/dist/memory-code-points.js":
/*!**********************************************************************!*\
  !*** ./node_modules/@mongodb-js/saslprep/dist/memory-code-points.js ***!
  \**********************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.bidirectional_l = exports.bidirectional_r_al = exports.prohibited_characters = exports.non_ASCII_space_characters = exports.commonly_mapped_to_nothing = exports.unassigned_code_points = void 0;\nconst sparse_bitfield_1 = __importDefault(__webpack_require__(/*! sparse-bitfield */ \"./node_modules/sparse-bitfield/index.js\"));\nconst code_points_data_1 = __importDefault(__webpack_require__(/*! ./code-points-data */ \"./node_modules/@mongodb-js/saslprep/dist/code-points-data.js\"));\nlet offset = 0;\nfunction read() {\n    const size = code_points_data_1.default.readUInt32BE(offset);\n    offset += 4;\n    const codepoints = code_points_data_1.default.slice(offset, offset + size);\n    offset += size;\n    return (0, sparse_bitfield_1.default)({ buffer: codepoints });\n}\nexports.unassigned_code_points = read();\nexports.commonly_mapped_to_nothing = read();\nexports.non_ASCII_space_characters = read();\nexports.prohibited_characters = read();\nexports.bidirectional_r_al = read();\nexports.bidirectional_l = read();\n//# sourceMappingURL=memory-code-points.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/@mongodb-js/saslprep/dist/memory-code-points.js?");

/***/ }),

/***/ "./node_modules/builder-util-runtime/out/CancellationToken.js":
/*!********************************************************************!*\
  !*** ./node_modules/builder-util-runtime/out/CancellationToken.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CancellationError = exports.CancellationToken = void 0;\nconst events_1 = __webpack_require__(/*! events */ \"events\");\nclass CancellationToken extends events_1.EventEmitter {\n    // babel cannot compile ... correctly for super calls\n    constructor(parent) {\n        super();\n        this.parentCancelHandler = null;\n        this._parent = null;\n        this._cancelled = false;\n        if (parent != null) {\n            this.parent = parent;\n        }\n    }\n    get cancelled() {\n        return this._cancelled || (this._parent != null && this._parent.cancelled);\n    }\n    set parent(value) {\n        this.removeParentCancelHandler();\n        this._parent = value;\n        this.parentCancelHandler = () => this.cancel();\n        this._parent.onCancel(this.parentCancelHandler);\n    }\n    cancel() {\n        this._cancelled = true;\n        this.emit(\"cancel\");\n    }\n    onCancel(handler) {\n        if (this.cancelled) {\n            handler();\n        }\n        else {\n            this.once(\"cancel\", handler);\n        }\n    }\n    createPromise(callback) {\n        if (this.cancelled) {\n            return Promise.reject(new CancellationError());\n        }\n        const finallyHandler = () => {\n            if (cancelHandler != null) {\n                try {\n                    this.removeListener(\"cancel\", cancelHandler);\n                    cancelHandler = null;\n                }\n                catch (ignore) {\n                    // ignore\n                }\n            }\n        };\n        let cancelHandler = null;\n        return new Promise((resolve, reject) => {\n            let addedCancelHandler = null;\n            cancelHandler = () => {\n                try {\n                    if (addedCancelHandler != null) {\n                        addedCancelHandler();\n                        addedCancelHandler = null;\n                    }\n                }\n                finally {\n                    reject(new CancellationError());\n                }\n            };\n            if (this.cancelled) {\n                cancelHandler();\n                return;\n            }\n            this.onCancel(cancelHandler);\n            callback(resolve, reject, (callback) => {\n                addedCancelHandler = callback;\n            });\n        })\n            .then(it => {\n            finallyHandler();\n            return it;\n        })\n            .catch((e) => {\n            finallyHandler();\n            throw e;\n        });\n    }\n    removeParentCancelHandler() {\n        const parent = this._parent;\n        if (parent != null && this.parentCancelHandler != null) {\n            parent.removeListener(\"cancel\", this.parentCancelHandler);\n            this.parentCancelHandler = null;\n        }\n    }\n    dispose() {\n        try {\n            this.removeParentCancelHandler();\n        }\n        finally {\n            this.removeAllListeners();\n            this._parent = null;\n        }\n    }\n}\nexports.CancellationToken = CancellationToken;\nclass CancellationError extends Error {\n    constructor() {\n        super(\"cancelled\");\n    }\n}\nexports.CancellationError = CancellationError;\n//# sourceMappingURL=CancellationToken.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/builder-util-runtime/out/CancellationToken.js?");

/***/ }),

/***/ "./node_modules/builder-util-runtime/out/ProgressCallbackTransform.js":
/*!****************************************************************************!*\
  !*** ./node_modules/builder-util-runtime/out/ProgressCallbackTransform.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ProgressCallbackTransform = void 0;\nconst stream_1 = __webpack_require__(/*! stream */ \"stream\");\nclass ProgressCallbackTransform extends stream_1.Transform {\n    constructor(total, cancellationToken, onProgress) {\n        super();\n        this.total = total;\n        this.cancellationToken = cancellationToken;\n        this.onProgress = onProgress;\n        this.start = Date.now();\n        this.transferred = 0;\n        this.delta = 0;\n        this.nextUpdate = this.start + 1000;\n    }\n    _transform(chunk, encoding, callback) {\n        if (this.cancellationToken.cancelled) {\n            callback(new Error(\"cancelled\"), null);\n            return;\n        }\n        this.transferred += chunk.length;\n        this.delta += chunk.length;\n        const now = Date.now();\n        if (now >= this.nextUpdate && this.transferred !== this.total /* will be emitted on _flush */) {\n            this.nextUpdate = now + 1000;\n            this.onProgress({\n                total: this.total,\n                delta: this.delta,\n                transferred: this.transferred,\n                percent: (this.transferred / this.total) * 100,\n                bytesPerSecond: Math.round(this.transferred / ((now - this.start) / 1000)),\n            });\n            this.delta = 0;\n        }\n        callback(null, chunk);\n    }\n    _flush(callback) {\n        if (this.cancellationToken.cancelled) {\n            callback(new Error(\"cancelled\"));\n            return;\n        }\n        this.onProgress({\n            total: this.total,\n            delta: this.delta,\n            transferred: this.total,\n            percent: 100,\n            bytesPerSecond: Math.round(this.transferred / ((Date.now() - this.start) / 1000)),\n        });\n        this.delta = 0;\n        callback(null);\n    }\n}\nexports.ProgressCallbackTransform = ProgressCallbackTransform;\n//# sourceMappingURL=ProgressCallbackTransform.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/builder-util-runtime/out/ProgressCallbackTransform.js?");

/***/ }),

/***/ "./node_modules/builder-util-runtime/out/httpExecutor.js":
/*!***************************************************************!*\
  !*** ./node_modules/builder-util-runtime/out/httpExecutor.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.safeStringifyJson = exports.configureRequestOptions = exports.safeGetHeader = exports.DigestTransform = exports.configureRequestUrl = exports.configureRequestOptionsFromUrl = exports.HttpExecutor = exports.parseJson = exports.HttpError = exports.createHttpError = void 0;\nconst crypto_1 = __webpack_require__(/*! crypto */ \"crypto\");\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/debug/src/browser.js\");\nconst fs_1 = __webpack_require__(/*! fs */ \"fs\");\nconst stream_1 = __webpack_require__(/*! stream */ \"stream\");\nconst url_1 = __webpack_require__(/*! url */ \"url\");\nconst CancellationToken_1 = __webpack_require__(/*! ./CancellationToken */ \"./node_modules/builder-util-runtime/out/CancellationToken.js\");\nconst index_1 = __webpack_require__(/*! ./index */ \"./node_modules/builder-util-runtime/out/index.js\");\nconst ProgressCallbackTransform_1 = __webpack_require__(/*! ./ProgressCallbackTransform */ \"./node_modules/builder-util-runtime/out/ProgressCallbackTransform.js\");\nconst debug = (0, debug_1.default)(\"electron-builder\");\nfunction createHttpError(response, description = null) {\n    return new HttpError(response.statusCode || -1, `${response.statusCode} ${response.statusMessage}` +\n        (description == null ? \"\" : \"\\n\" + JSON.stringify(description, null, \"  \")) +\n        \"\\nHeaders: \" +\n        safeStringifyJson(response.headers), description);\n}\nexports.createHttpError = createHttpError;\nconst HTTP_STATUS_CODES = new Map([\n    [429, \"Too many requests\"],\n    [400, \"Bad request\"],\n    [403, \"Forbidden\"],\n    [404, \"Not found\"],\n    [405, \"Method not allowed\"],\n    [406, \"Not acceptable\"],\n    [408, \"Request timeout\"],\n    [413, \"Request entity too large\"],\n    [500, \"Internal server error\"],\n    [502, \"Bad gateway\"],\n    [503, \"Service unavailable\"],\n    [504, \"Gateway timeout\"],\n    [505, \"HTTP version not supported\"],\n]);\nclass HttpError extends Error {\n    constructor(statusCode, message = `HTTP error: ${HTTP_STATUS_CODES.get(statusCode) || statusCode}`, description = null) {\n        super(message);\n        this.statusCode = statusCode;\n        this.description = description;\n        this.name = \"HttpError\";\n        this.code = `HTTP_ERROR_${statusCode}`;\n    }\n    isServerError() {\n        return this.statusCode >= 500 && this.statusCode <= 599;\n    }\n}\nexports.HttpError = HttpError;\nfunction parseJson(result) {\n    return result.then(it => (it == null || it.length === 0 ? null : JSON.parse(it)));\n}\nexports.parseJson = parseJson;\nclass HttpExecutor {\n    constructor() {\n        this.maxRedirects = 10;\n    }\n    request(options, cancellationToken = new CancellationToken_1.CancellationToken(), data) {\n        configureRequestOptions(options);\n        const json = data == null ? undefined : JSON.stringify(data);\n        const encodedData = json ? Buffer.from(json) : undefined;\n        if (encodedData != null) {\n            debug(json);\n            const { headers, ...opts } = options;\n            options = {\n                method: \"post\",\n                headers: {\n                    \"Content-Type\": \"application/json\",\n                    \"Content-Length\": encodedData.length,\n                    ...headers,\n                },\n                ...opts,\n            };\n        }\n        return this.doApiRequest(options, cancellationToken, it => it.end(encodedData));\n    }\n    doApiRequest(options, cancellationToken, requestProcessor, redirectCount = 0) {\n        if (debug.enabled) {\n            debug(`Request: ${safeStringifyJson(options)}`);\n        }\n        return cancellationToken.createPromise((resolve, reject, onCancel) => {\n            const request = this.createRequest(options, (response) => {\n                try {\n                    this.handleResponse(response, options, cancellationToken, resolve, reject, redirectCount, requestProcessor);\n                }\n                catch (e) {\n                    reject(e);\n                }\n            });\n            this.addErrorAndTimeoutHandlers(request, reject, options.timeout);\n            this.addRedirectHandlers(request, options, reject, redirectCount, options => {\n                this.doApiRequest(options, cancellationToken, requestProcessor, redirectCount).then(resolve).catch(reject);\n            });\n            requestProcessor(request, reject);\n            onCancel(() => request.abort());\n        });\n    }\n    // noinspection JSUnusedLocalSymbols\n    // eslint-disable-next-line\n    addRedirectHandlers(request, options, reject, redirectCount, handler) {\n        // not required for NodeJS\n    }\n    addErrorAndTimeoutHandlers(request, reject, timeout = 60 * 1000) {\n        this.addTimeOutHandler(request, reject, timeout);\n        request.on(\"error\", reject);\n        request.on(\"aborted\", () => {\n            reject(new Error(\"Request has been aborted by the server\"));\n        });\n    }\n    handleResponse(response, options, cancellationToken, resolve, reject, redirectCount, requestProcessor) {\n        var _a;\n        if (debug.enabled) {\n            debug(`Response: ${response.statusCode} ${response.statusMessage}, request options: ${safeStringifyJson(options)}`);\n        }\n        // we handle any other >= 400 error on request end (read detailed message in the response body)\n        if (response.statusCode === 404) {\n            // error is clear, we don't need to read detailed error description\n            reject(createHttpError(response, `method: ${options.method || \"GET\"} url: ${options.protocol || \"https:\"}//${options.hostname}${options.port ? `:${options.port}` : \"\"}${options.path}\n\nPlease double check that your authentication token is correct. Due to security reasons, actual status maybe not reported, but 404.\n`));\n            return;\n        }\n        else if (response.statusCode === 204) {\n            // on DELETE request\n            resolve();\n            return;\n        }\n        const code = (_a = response.statusCode) !== null && _a !== void 0 ? _a : 0;\n        const shouldRedirect = code >= 300 && code < 400;\n        const redirectUrl = safeGetHeader(response, \"location\");\n        if (shouldRedirect && redirectUrl != null) {\n            if (redirectCount > this.maxRedirects) {\n                reject(this.createMaxRedirectError());\n                return;\n            }\n            this.doApiRequest(HttpExecutor.prepareRedirectUrlOptions(redirectUrl, options), cancellationToken, requestProcessor, redirectCount).then(resolve).catch(reject);\n            return;\n        }\n        response.setEncoding(\"utf8\");\n        let data = \"\";\n        response.on(\"error\", reject);\n        response.on(\"data\", (chunk) => (data += chunk));\n        response.on(\"end\", () => {\n            try {\n                if (response.statusCode != null && response.statusCode >= 400) {\n                    const contentType = safeGetHeader(response, \"content-type\");\n                    const isJson = contentType != null && (Array.isArray(contentType) ? contentType.find(it => it.includes(\"json\")) != null : contentType.includes(\"json\"));\n                    reject(createHttpError(response, `method: ${options.method || \"GET\"} url: ${options.protocol || \"https:\"}//${options.hostname}${options.port ? `:${options.port}` : \"\"}${options.path}\n\n          Data:\n          ${isJson ? JSON.stringify(JSON.parse(data)) : data}\n          `));\n                }\n                else {\n                    resolve(data.length === 0 ? null : data);\n                }\n            }\n            catch (e) {\n                reject(e);\n            }\n        });\n    }\n    async downloadToBuffer(url, options) {\n        return await options.cancellationToken.createPromise((resolve, reject, onCancel) => {\n            const responseChunks = [];\n            const requestOptions = {\n                headers: options.headers || undefined,\n                // because PrivateGitHubProvider requires HttpExecutor.prepareRedirectUrlOptions logic, so, we need to redirect manually\n                redirect: \"manual\",\n            };\n            configureRequestUrl(url, requestOptions);\n            configureRequestOptions(requestOptions);\n            this.doDownload(requestOptions, {\n                destination: null,\n                options,\n                onCancel,\n                callback: error => {\n                    if (error == null) {\n                        resolve(Buffer.concat(responseChunks));\n                    }\n                    else {\n                        reject(error);\n                    }\n                },\n                responseHandler: (response, callback) => {\n                    let receivedLength = 0;\n                    response.on(\"data\", (chunk) => {\n                        receivedLength += chunk.length;\n                        if (receivedLength > 524288000) {\n                            callback(new Error(\"Maximum allowed size is 500 MB\"));\n                            return;\n                        }\n                        responseChunks.push(chunk);\n                    });\n                    response.on(\"end\", () => {\n                        callback(null);\n                    });\n                },\n            }, 0);\n        });\n    }\n    doDownload(requestOptions, options, redirectCount) {\n        const request = this.createRequest(requestOptions, (response) => {\n            if (response.statusCode >= 400) {\n                options.callback(new Error(`Cannot download \"${requestOptions.protocol || \"https:\"}//${requestOptions.hostname}${requestOptions.path}\", status ${response.statusCode}: ${response.statusMessage}`));\n                return;\n            }\n            // It is possible for the response stream to fail, e.g. when a network is lost while\n            // response stream is in progress. Stop waiting and reject so consumer can catch the error.\n            response.on(\"error\", options.callback);\n            // this code not relevant for Electron (redirect event instead handled)\n            const redirectUrl = safeGetHeader(response, \"location\");\n            if (redirectUrl != null) {\n                if (redirectCount < this.maxRedirects) {\n                    this.doDownload(HttpExecutor.prepareRedirectUrlOptions(redirectUrl, requestOptions), options, redirectCount++);\n                }\n                else {\n                    options.callback(this.createMaxRedirectError());\n                }\n                return;\n            }\n            if (options.responseHandler == null) {\n                configurePipes(options, response);\n            }\n            else {\n                options.responseHandler(response, options.callback);\n            }\n        });\n        this.addErrorAndTimeoutHandlers(request, options.callback, requestOptions.timeout);\n        this.addRedirectHandlers(request, requestOptions, options.callback, redirectCount, requestOptions => {\n            this.doDownload(requestOptions, options, redirectCount++);\n        });\n        request.end();\n    }\n    createMaxRedirectError() {\n        return new Error(`Too many redirects (> ${this.maxRedirects})`);\n    }\n    addTimeOutHandler(request, callback, timeout) {\n        request.on(\"socket\", (socket) => {\n            socket.setTimeout(timeout, () => {\n                request.abort();\n                callback(new Error(\"Request timed out\"));\n            });\n        });\n    }\n    static prepareRedirectUrlOptions(redirectUrl, options) {\n        const newOptions = configureRequestOptionsFromUrl(redirectUrl, { ...options });\n        const headers = newOptions.headers;\n        if (headers === null || headers === void 0 ? void 0 : headers.authorization) {\n            const parsedNewUrl = new url_1.URL(redirectUrl);\n            if (parsedNewUrl.hostname.endsWith(\".amazonaws.com\") || parsedNewUrl.searchParams.has(\"X-Amz-Credential\")) {\n                delete headers.authorization;\n            }\n        }\n        return newOptions;\n    }\n    static retryOnServerError(task, maxRetries = 3) {\n        for (let attemptNumber = 0;; attemptNumber++) {\n            try {\n                return task();\n            }\n            catch (e) {\n                if (attemptNumber < maxRetries && ((e instanceof HttpError && e.isServerError()) || e.code === \"EPIPE\")) {\n                    continue;\n                }\n                throw e;\n            }\n        }\n    }\n}\nexports.HttpExecutor = HttpExecutor;\nfunction configureRequestOptionsFromUrl(url, options) {\n    const result = configureRequestOptions(options);\n    configureRequestUrl(new url_1.URL(url), result);\n    return result;\n}\nexports.configureRequestOptionsFromUrl = configureRequestOptionsFromUrl;\nfunction configureRequestUrl(url, options) {\n    options.protocol = url.protocol;\n    options.hostname = url.hostname;\n    if (url.port) {\n        options.port = url.port;\n    }\n    else if (options.port) {\n        delete options.port;\n    }\n    options.path = url.pathname + url.search;\n}\nexports.configureRequestUrl = configureRequestUrl;\nclass DigestTransform extends stream_1.Transform {\n    constructor(expected, algorithm = \"sha512\", encoding = \"base64\") {\n        super();\n        this.expected = expected;\n        this.algorithm = algorithm;\n        this.encoding = encoding;\n        this._actual = null;\n        this.isValidateOnEnd = true;\n        this.digester = (0, crypto_1.createHash)(algorithm);\n    }\n    // noinspection JSUnusedGlobalSymbols\n    get actual() {\n        return this._actual;\n    }\n    // noinspection JSUnusedGlobalSymbols\n    _transform(chunk, encoding, callback) {\n        this.digester.update(chunk);\n        callback(null, chunk);\n    }\n    // noinspection JSUnusedGlobalSymbols\n    _flush(callback) {\n        this._actual = this.digester.digest(this.encoding);\n        if (this.isValidateOnEnd) {\n            try {\n                this.validate();\n            }\n            catch (e) {\n                callback(e);\n                return;\n            }\n        }\n        callback(null);\n    }\n    validate() {\n        if (this._actual == null) {\n            throw (0, index_1.newError)(\"Not finished yet\", \"ERR_STREAM_NOT_FINISHED\");\n        }\n        if (this._actual !== this.expected) {\n            throw (0, index_1.newError)(`${this.algorithm} checksum mismatch, expected ${this.expected}, got ${this._actual}`, \"ERR_CHECKSUM_MISMATCH\");\n        }\n        return null;\n    }\n}\nexports.DigestTransform = DigestTransform;\nfunction checkSha2(sha2Header, sha2, callback) {\n    if (sha2Header != null && sha2 != null && sha2Header !== sha2) {\n        callback(new Error(`checksum mismatch: expected ${sha2} but got ${sha2Header} (X-Checksum-Sha2 header)`));\n        return false;\n    }\n    return true;\n}\nfunction safeGetHeader(response, headerKey) {\n    const value = response.headers[headerKey];\n    if (value == null) {\n        return null;\n    }\n    else if (Array.isArray(value)) {\n        // electron API\n        return value.length === 0 ? null : value[value.length - 1];\n    }\n    else {\n        return value;\n    }\n}\nexports.safeGetHeader = safeGetHeader;\nfunction configurePipes(options, response) {\n    if (!checkSha2(safeGetHeader(response, \"X-Checksum-Sha2\"), options.options.sha2, options.callback)) {\n        return;\n    }\n    const streams = [];\n    if (options.options.onProgress != null) {\n        const contentLength = safeGetHeader(response, \"content-length\");\n        if (contentLength != null) {\n            streams.push(new ProgressCallbackTransform_1.ProgressCallbackTransform(parseInt(contentLength, 10), options.options.cancellationToken, options.options.onProgress));\n        }\n    }\n    const sha512 = options.options.sha512;\n    if (sha512 != null) {\n        streams.push(new DigestTransform(sha512, \"sha512\", sha512.length === 128 && !sha512.includes(\"+\") && !sha512.includes(\"Z\") && !sha512.includes(\"=\") ? \"hex\" : \"base64\"));\n    }\n    else if (options.options.sha2 != null) {\n        streams.push(new DigestTransform(options.options.sha2, \"sha256\", \"hex\"));\n    }\n    const fileOut = (0, fs_1.createWriteStream)(options.destination);\n    streams.push(fileOut);\n    let lastStream = response;\n    for (const stream of streams) {\n        stream.on(\"error\", (error) => {\n            fileOut.close();\n            if (!options.options.cancellationToken.cancelled) {\n                options.callback(error);\n            }\n        });\n        lastStream = lastStream.pipe(stream);\n    }\n    fileOut.on(\"finish\", () => {\n        ;\n        fileOut.close(options.callback);\n    });\n}\nfunction configureRequestOptions(options, token, method) {\n    if (method != null) {\n        options.method = method;\n    }\n    options.headers = { ...options.headers };\n    const headers = options.headers;\n    if (token != null) {\n        ;\n        headers.authorization = token.startsWith(\"Basic\") || token.startsWith(\"Bearer\") ? token : `token ${token}`;\n    }\n    if (headers[\"User-Agent\"] == null) {\n        headers[\"User-Agent\"] = \"electron-builder\";\n    }\n    if (method == null || method === \"GET\" || headers[\"Cache-Control\"] == null) {\n        headers[\"Cache-Control\"] = \"no-cache\";\n    }\n    // do not specify for node (in any case we use https module)\n    if (options.protocol == null && process.versions.electron != null) {\n        options.protocol = \"https:\";\n    }\n    return options;\n}\nexports.configureRequestOptions = configureRequestOptions;\nfunction safeStringifyJson(data, skippedNames) {\n    return JSON.stringify(data, (name, value) => {\n        if (name.endsWith(\"Authorization\") ||\n            name.endsWith(\"authorization\") ||\n            name.endsWith(\"Password\") ||\n            name.endsWith(\"PASSWORD\") ||\n            name.endsWith(\"Token\") ||\n            name.includes(\"password\") ||\n            name.includes(\"token\") ||\n            (skippedNames != null && skippedNames.has(name))) {\n            return \"<stripped sensitive data>\";\n        }\n        return value;\n    }, 2);\n}\nexports.safeStringifyJson = safeStringifyJson;\n//# sourceMappingURL=httpExecutor.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/builder-util-runtime/out/httpExecutor.js?");

/***/ }),

/***/ "./node_modules/builder-util-runtime/out/index.js":
/*!********************************************************!*\
  !*** ./node_modules/builder-util-runtime/out/index.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.newError = exports.asArray = exports.CURRENT_APP_PACKAGE_FILE_NAME = exports.CURRENT_APP_INSTALLER_FILE_NAME = exports.XElement = exports.parseXml = exports.ProgressCallbackTransform = exports.UUID = exports.parseDn = exports.githubUrl = exports.getS3LikeProviderBaseUrl = exports.configureRequestUrl = exports.parseJson = exports.safeStringifyJson = exports.configureRequestOptionsFromUrl = exports.configureRequestOptions = exports.safeGetHeader = exports.DigestTransform = exports.HttpExecutor = exports.createHttpError = exports.HttpError = exports.CancellationError = exports.CancellationToken = void 0;\nvar CancellationToken_1 = __webpack_require__(/*! ./CancellationToken */ \"./node_modules/builder-util-runtime/out/CancellationToken.js\");\nObject.defineProperty(exports, \"CancellationToken\", ({ enumerable: true, get: function () { return CancellationToken_1.CancellationToken; } }));\nObject.defineProperty(exports, \"CancellationError\", ({ enumerable: true, get: function () { return CancellationToken_1.CancellationError; } }));\nvar httpExecutor_1 = __webpack_require__(/*! ./httpExecutor */ \"./node_modules/builder-util-runtime/out/httpExecutor.js\");\nObject.defineProperty(exports, \"HttpError\", ({ enumerable: true, get: function () { return httpExecutor_1.HttpError; } }));\nObject.defineProperty(exports, \"createHttpError\", ({ enumerable: true, get: function () { return httpExecutor_1.createHttpError; } }));\nObject.defineProperty(exports, \"HttpExecutor\", ({ enumerable: true, get: function () { return httpExecutor_1.HttpExecutor; } }));\nObject.defineProperty(exports, \"DigestTransform\", ({ enumerable: true, get: function () { return httpExecutor_1.DigestTransform; } }));\nObject.defineProperty(exports, \"safeGetHeader\", ({ enumerable: true, get: function () { return httpExecutor_1.safeGetHeader; } }));\nObject.defineProperty(exports, \"configureRequestOptions\", ({ enumerable: true, get: function () { return httpExecutor_1.configureRequestOptions; } }));\nObject.defineProperty(exports, \"configureRequestOptionsFromUrl\", ({ enumerable: true, get: function () { return httpExecutor_1.configureRequestOptionsFromUrl; } }));\nObject.defineProperty(exports, \"safeStringifyJson\", ({ enumerable: true, get: function () { return httpExecutor_1.safeStringifyJson; } }));\nObject.defineProperty(exports, \"parseJson\", ({ enumerable: true, get: function () { return httpExecutor_1.parseJson; } }));\nObject.defineProperty(exports, \"configureRequestUrl\", ({ enumerable: true, get: function () { return httpExecutor_1.configureRequestUrl; } }));\nvar publishOptions_1 = __webpack_require__(/*! ./publishOptions */ \"./node_modules/builder-util-runtime/out/publishOptions.js\");\nObject.defineProperty(exports, \"getS3LikeProviderBaseUrl\", ({ enumerable: true, get: function () { return publishOptions_1.getS3LikeProviderBaseUrl; } }));\nObject.defineProperty(exports, \"githubUrl\", ({ enumerable: true, get: function () { return publishOptions_1.githubUrl; } }));\nvar rfc2253Parser_1 = __webpack_require__(/*! ./rfc2253Parser */ \"./node_modules/builder-util-runtime/out/rfc2253Parser.js\");\nObject.defineProperty(exports, \"parseDn\", ({ enumerable: true, get: function () { return rfc2253Parser_1.parseDn; } }));\nvar uuid_1 = __webpack_require__(/*! ./uuid */ \"./node_modules/builder-util-runtime/out/uuid.js\");\nObject.defineProperty(exports, \"UUID\", ({ enumerable: true, get: function () { return uuid_1.UUID; } }));\nvar ProgressCallbackTransform_1 = __webpack_require__(/*! ./ProgressCallbackTransform */ \"./node_modules/builder-util-runtime/out/ProgressCallbackTransform.js\");\nObject.defineProperty(exports, \"ProgressCallbackTransform\", ({ enumerable: true, get: function () { return ProgressCallbackTransform_1.ProgressCallbackTransform; } }));\nvar xml_1 = __webpack_require__(/*! ./xml */ \"./node_modules/builder-util-runtime/out/xml.js\");\nObject.defineProperty(exports, \"parseXml\", ({ enumerable: true, get: function () { return xml_1.parseXml; } }));\nObject.defineProperty(exports, \"XElement\", ({ enumerable: true, get: function () { return xml_1.XElement; } }));\n// nsis\nexports.CURRENT_APP_INSTALLER_FILE_NAME = \"installer.exe\";\n// nsis-web\nexports.CURRENT_APP_PACKAGE_FILE_NAME = \"package.7z\";\nfunction asArray(v) {\n    if (v == null) {\n        return [];\n    }\n    else if (Array.isArray(v)) {\n        return v;\n    }\n    else {\n        return [v];\n    }\n}\nexports.asArray = asArray;\nfunction newError(message, code) {\n    const error = new Error(message);\n    error.code = code;\n    return error;\n}\nexports.newError = newError;\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/builder-util-runtime/out/index.js?");

/***/ }),

/***/ "./node_modules/builder-util-runtime/out/publishOptions.js":
/*!*****************************************************************!*\
  !*** ./node_modules/builder-util-runtime/out/publishOptions.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.getS3LikeProviderBaseUrl = exports.githubUrl = void 0;\n/** @private */\nfunction githubUrl(options, defaultHost = \"github.com\") {\n    return `${options.protocol || \"https\"}://${options.host || defaultHost}`;\n}\nexports.githubUrl = githubUrl;\nfunction getS3LikeProviderBaseUrl(configuration) {\n    const provider = configuration.provider;\n    if (provider === \"s3\") {\n        return s3Url(configuration);\n    }\n    if (provider === \"spaces\") {\n        return spacesUrl(configuration);\n    }\n    throw new Error(`Not supported provider: ${provider}`);\n}\nexports.getS3LikeProviderBaseUrl = getS3LikeProviderBaseUrl;\nfunction s3Url(options) {\n    let url;\n    if (options.accelerate == true) {\n        url = `https://${options.bucket}.s3-accelerate.amazonaws.com`;\n    }\n    else if (options.endpoint != null) {\n        url = `${options.endpoint}/${options.bucket}`;\n    }\n    else if (options.bucket.includes(\".\")) {\n        if (options.region == null) {\n            throw new Error(`Bucket name \"${options.bucket}\" includes a dot, but S3 region is missing`);\n        }\n        // special case, see http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingBucket.html#access-bucket-intro\n        if (options.region === \"us-east-1\") {\n            url = `https://s3.amazonaws.com/${options.bucket}`;\n        }\n        else {\n            url = `https://s3-${options.region}.amazonaws.com/${options.bucket}`;\n        }\n    }\n    else if (options.region === \"cn-north-1\") {\n        url = `https://${options.bucket}.s3.${options.region}.amazonaws.com.cn`;\n    }\n    else {\n        url = `https://${options.bucket}.s3.amazonaws.com`;\n    }\n    return appendPath(url, options.path);\n}\nfunction appendPath(url, p) {\n    if (p != null && p.length > 0) {\n        if (!p.startsWith(\"/\")) {\n            url += \"/\";\n        }\n        url += p;\n    }\n    return url;\n}\nfunction spacesUrl(options) {\n    if (options.name == null) {\n        throw new Error(`name is missing`);\n    }\n    if (options.region == null) {\n        throw new Error(`region is missing`);\n    }\n    return appendPath(`https://${options.name}.${options.region}.digitaloceanspaces.com`, options.path);\n}\n//# sourceMappingURL=publishOptions.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/builder-util-runtime/out/publishOptions.js?");

/***/ }),

/***/ "./node_modules/builder-util-runtime/out/rfc2253Parser.js":
/*!****************************************************************!*\
  !*** ./node_modules/builder-util-runtime/out/rfc2253Parser.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.parseDn = void 0;\nfunction parseDn(seq) {\n    let quoted = false;\n    let key = null;\n    let token = \"\";\n    let nextNonSpace = 0;\n    seq = seq.trim();\n    const result = new Map();\n    for (let i = 0; i <= seq.length; i++) {\n        if (i === seq.length) {\n            if (key !== null) {\n                result.set(key, token);\n            }\n            break;\n        }\n        const ch = seq[i];\n        if (quoted) {\n            if (ch === '\"') {\n                quoted = false;\n                continue;\n            }\n        }\n        else {\n            if (ch === '\"') {\n                quoted = true;\n                continue;\n            }\n            if (ch === \"\\\\\") {\n                i++;\n                const ord = parseInt(seq.slice(i, i + 2), 16);\n                if (Number.isNaN(ord)) {\n                    token += seq[i];\n                }\n                else {\n                    i++;\n                    token += String.fromCharCode(ord);\n                }\n                continue;\n            }\n            if (key === null && ch === \"=\") {\n                key = token;\n                token = \"\";\n                continue;\n            }\n            if (ch === \",\" || ch === \";\" || ch === \"+\") {\n                if (key !== null) {\n                    result.set(key, token);\n                }\n                key = null;\n                token = \"\";\n                continue;\n            }\n        }\n        if (ch === \" \" && !quoted) {\n            if (token.length === 0) {\n                continue;\n            }\n            if (i > nextNonSpace) {\n                let j = i;\n                while (seq[j] === \" \") {\n                    j++;\n                }\n                nextNonSpace = j;\n            }\n            if (nextNonSpace >= seq.length ||\n                seq[nextNonSpace] === \",\" ||\n                seq[nextNonSpace] === \";\" ||\n                (key === null && seq[nextNonSpace] === \"=\") ||\n                (key !== null && seq[nextNonSpace] === \"+\")) {\n                i = nextNonSpace - 1;\n                continue;\n            }\n        }\n        token += ch;\n    }\n    return result;\n}\nexports.parseDn = parseDn;\n//# sourceMappingURL=rfc2253Parser.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/builder-util-runtime/out/rfc2253Parser.js?");

/***/ }),

/***/ "./node_modules/builder-util-runtime/out/uuid.js":
/*!*******************************************************!*\
  !*** ./node_modules/builder-util-runtime/out/uuid.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.nil = exports.UUID = void 0;\nconst crypto_1 = __webpack_require__(/*! crypto */ \"crypto\");\nconst index_1 = __webpack_require__(/*! ./index */ \"./node_modules/builder-util-runtime/out/index.js\");\nconst invalidName = \"options.name must be either a string or a Buffer\";\n// Node ID according to rfc4122#section-4.5\nconst randomHost = (0, crypto_1.randomBytes)(16);\nrandomHost[0] = randomHost[0] | 0x01;\n// lookup table hex to byte\nconst hex2byte = {};\n// lookup table byte to hex\nconst byte2hex = [];\n// populate lookup tables\nfor (let i = 0; i < 256; i++) {\n    const hex = (i + 0x100).toString(16).substr(1);\n    hex2byte[hex] = i;\n    byte2hex[i] = hex;\n}\n// UUID class\nclass UUID {\n    constructor(uuid) {\n        this.ascii = null;\n        this.binary = null;\n        const check = UUID.check(uuid);\n        if (!check) {\n            throw new Error(\"not a UUID\");\n        }\n        this.version = check.version;\n        if (check.format === \"ascii\") {\n            this.ascii = uuid;\n        }\n        else {\n            this.binary = uuid;\n        }\n    }\n    static v5(name, namespace) {\n        return uuidNamed(name, \"sha1\", 0x50, namespace);\n    }\n    toString() {\n        if (this.ascii == null) {\n            this.ascii = stringify(this.binary);\n        }\n        return this.ascii;\n    }\n    inspect() {\n        return `UUID v${this.version} ${this.toString()}`;\n    }\n    static check(uuid, offset = 0) {\n        if (typeof uuid === \"string\") {\n            uuid = uuid.toLowerCase();\n            if (!/^[a-f0-9]{8}(-[a-f0-9]{4}){3}-([a-f0-9]{12})$/.test(uuid)) {\n                return false;\n            }\n            if (uuid === \"00000000-0000-0000-0000-000000000000\") {\n                return { version: undefined, variant: \"nil\", format: \"ascii\" };\n            }\n            return {\n                version: (hex2byte[uuid[14] + uuid[15]] & 0xf0) >> 4,\n                variant: getVariant((hex2byte[uuid[19] + uuid[20]] & 0xe0) >> 5),\n                format: \"ascii\",\n            };\n        }\n        if (Buffer.isBuffer(uuid)) {\n            if (uuid.length < offset + 16) {\n                return false;\n            }\n            let i = 0;\n            for (; i < 16; i++) {\n                if (uuid[offset + i] !== 0) {\n                    break;\n                }\n            }\n            if (i === 16) {\n                return { version: undefined, variant: \"nil\", format: \"binary\" };\n            }\n            return {\n                version: (uuid[offset + 6] & 0xf0) >> 4,\n                variant: getVariant((uuid[offset + 8] & 0xe0) >> 5),\n                format: \"binary\",\n            };\n        }\n        throw (0, index_1.newError)(\"Unknown type of uuid\", \"ERR_UNKNOWN_UUID_TYPE\");\n    }\n    // read stringified uuid into a Buffer\n    static parse(input) {\n        const buffer = Buffer.allocUnsafe(16);\n        let j = 0;\n        for (let i = 0; i < 16; i++) {\n            buffer[i] = hex2byte[input[j++] + input[j++]];\n            if (i === 3 || i === 5 || i === 7 || i === 9) {\n                j += 1;\n            }\n        }\n        return buffer;\n    }\n}\nexports.UUID = UUID;\n// from rfc4122#appendix-C\nUUID.OID = UUID.parse(\"6ba7b812-9dad-11d1-80b4-00c04fd430c8\");\n// according to rfc4122#section-4.1.1\nfunction getVariant(bits) {\n    switch (bits) {\n        case 0:\n        case 1:\n        case 3:\n            return \"ncs\";\n        case 4:\n        case 5:\n            return \"rfc4122\";\n        case 6:\n            return \"microsoft\";\n        default:\n            return \"future\";\n    }\n}\nvar UuidEncoding;\n(function (UuidEncoding) {\n    UuidEncoding[UuidEncoding[\"ASCII\"] = 0] = \"ASCII\";\n    UuidEncoding[UuidEncoding[\"BINARY\"] = 1] = \"BINARY\";\n    UuidEncoding[UuidEncoding[\"OBJECT\"] = 2] = \"OBJECT\";\n})(UuidEncoding || (UuidEncoding = {}));\n// v3 + v5\nfunction uuidNamed(name, hashMethod, version, namespace, encoding = UuidEncoding.ASCII) {\n    const hash = (0, crypto_1.createHash)(hashMethod);\n    const nameIsNotAString = typeof name !== \"string\";\n    if (nameIsNotAString && !Buffer.isBuffer(name)) {\n        throw (0, index_1.newError)(invalidName, \"ERR_INVALID_UUID_NAME\");\n    }\n    hash.update(namespace);\n    hash.update(name);\n    const buffer = hash.digest();\n    let result;\n    switch (encoding) {\n        case UuidEncoding.BINARY:\n            buffer[6] = (buffer[6] & 0x0f) | version;\n            buffer[8] = (buffer[8] & 0x3f) | 0x80;\n            result = buffer;\n            break;\n        case UuidEncoding.OBJECT:\n            buffer[6] = (buffer[6] & 0x0f) | version;\n            buffer[8] = (buffer[8] & 0x3f) | 0x80;\n            result = new UUID(buffer);\n            break;\n        default:\n            result =\n                byte2hex[buffer[0]] +\n                    byte2hex[buffer[1]] +\n                    byte2hex[buffer[2]] +\n                    byte2hex[buffer[3]] +\n                    \"-\" +\n                    byte2hex[buffer[4]] +\n                    byte2hex[buffer[5]] +\n                    \"-\" +\n                    byte2hex[(buffer[6] & 0x0f) | version] +\n                    byte2hex[buffer[7]] +\n                    \"-\" +\n                    byte2hex[(buffer[8] & 0x3f) | 0x80] +\n                    byte2hex[buffer[9]] +\n                    \"-\" +\n                    byte2hex[buffer[10]] +\n                    byte2hex[buffer[11]] +\n                    byte2hex[buffer[12]] +\n                    byte2hex[buffer[13]] +\n                    byte2hex[buffer[14]] +\n                    byte2hex[buffer[15]];\n            break;\n    }\n    return result;\n}\nfunction stringify(buffer) {\n    return (byte2hex[buffer[0]] +\n        byte2hex[buffer[1]] +\n        byte2hex[buffer[2]] +\n        byte2hex[buffer[3]] +\n        \"-\" +\n        byte2hex[buffer[4]] +\n        byte2hex[buffer[5]] +\n        \"-\" +\n        byte2hex[buffer[6]] +\n        byte2hex[buffer[7]] +\n        \"-\" +\n        byte2hex[buffer[8]] +\n        byte2hex[buffer[9]] +\n        \"-\" +\n        byte2hex[buffer[10]] +\n        byte2hex[buffer[11]] +\n        byte2hex[buffer[12]] +\n        byte2hex[buffer[13]] +\n        byte2hex[buffer[14]] +\n        byte2hex[buffer[15]]);\n}\n// according to rfc4122#section-4.1.7\nexports.nil = new UUID(\"00000000-0000-0000-0000-000000000000\");\n// UUID.v4 = uuidRandom\n// UUID.v4fast = uuidRandomFast\n// UUID.v3 = function(options, callback) {\n//     return uuidNamed(\"md5\", 0x30, options, callback)\n// }\n//# sourceMappingURL=uuid.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/builder-util-runtime/out/uuid.js?");

/***/ }),

/***/ "./node_modules/builder-util-runtime/out/xml.js":
/*!******************************************************!*\
  !*** ./node_modules/builder-util-runtime/out/xml.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.parseXml = exports.XElement = void 0;\nconst sax = __webpack_require__(/*! sax */ \"./node_modules/sax/lib/sax.js\");\nconst index_1 = __webpack_require__(/*! ./index */ \"./node_modules/builder-util-runtime/out/index.js\");\nclass XElement {\n    constructor(name) {\n        this.name = name;\n        this.value = \"\";\n        this.attributes = null;\n        this.isCData = false;\n        this.elements = null;\n        if (!name) {\n            throw (0, index_1.newError)(\"Element name cannot be empty\", \"ERR_XML_ELEMENT_NAME_EMPTY\");\n        }\n        if (!isValidName(name)) {\n            throw (0, index_1.newError)(`Invalid element name: ${name}`, \"ERR_XML_ELEMENT_INVALID_NAME\");\n        }\n    }\n    attribute(name) {\n        const result = this.attributes === null ? null : this.attributes[name];\n        if (result == null) {\n            throw (0, index_1.newError)(`No attribute \"${name}\"`, \"ERR_XML_MISSED_ATTRIBUTE\");\n        }\n        return result;\n    }\n    removeAttribute(name) {\n        if (this.attributes !== null) {\n            delete this.attributes[name];\n        }\n    }\n    element(name, ignoreCase = false, errorIfMissed = null) {\n        const result = this.elementOrNull(name, ignoreCase);\n        if (result === null) {\n            throw (0, index_1.newError)(errorIfMissed || `No element \"${name}\"`, \"ERR_XML_MISSED_ELEMENT\");\n        }\n        return result;\n    }\n    elementOrNull(name, ignoreCase = false) {\n        if (this.elements === null) {\n            return null;\n        }\n        for (const element of this.elements) {\n            if (isNameEquals(element, name, ignoreCase)) {\n                return element;\n            }\n        }\n        return null;\n    }\n    getElements(name, ignoreCase = false) {\n        if (this.elements === null) {\n            return [];\n        }\n        return this.elements.filter(it => isNameEquals(it, name, ignoreCase));\n    }\n    elementValueOrEmpty(name, ignoreCase = false) {\n        const element = this.elementOrNull(name, ignoreCase);\n        return element === null ? \"\" : element.value;\n    }\n}\nexports.XElement = XElement;\nconst NAME_REG_EXP = new RegExp(/^[A-Za-z_][:A-Za-z0-9_-]*$/i);\nfunction isValidName(name) {\n    return NAME_REG_EXP.test(name);\n}\nfunction isNameEquals(element, name, ignoreCase) {\n    const elementName = element.name;\n    return elementName === name || (ignoreCase === true && elementName.length === name.length && elementName.toLowerCase() === name.toLowerCase());\n}\nfunction parseXml(data) {\n    let rootElement = null;\n    const parser = sax.parser(true, {});\n    const elements = [];\n    parser.onopentag = saxElement => {\n        const element = new XElement(saxElement.name);\n        element.attributes = saxElement.attributes;\n        if (rootElement === null) {\n            rootElement = element;\n        }\n        else {\n            const parent = elements[elements.length - 1];\n            if (parent.elements == null) {\n                parent.elements = [];\n            }\n            parent.elements.push(element);\n        }\n        elements.push(element);\n    };\n    parser.onclosetag = () => {\n        elements.pop();\n    };\n    parser.ontext = text => {\n        if (elements.length > 0) {\n            elements[elements.length - 1].value = text;\n        }\n    };\n    parser.oncdata = cdata => {\n        const element = elements[elements.length - 1];\n        element.value = cdata;\n        element.isCData = true;\n    };\n    parser.onerror = err => {\n        throw err;\n    };\n    parser.write(data);\n    return rootElement;\n}\nexports.parseXml = parseXml;\n//# sourceMappingURL=xml.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/builder-util-runtime/out/xml.js?");

/***/ }),

/***/ "./node_modules/debug/src/browser.js":
/*!*******************************************!*\
  !*** ./node_modules/debug/src/browser.js ***!
  \*******************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("/* eslint-env browser */\n\n/**\n * This is the web browser implementation of `debug()`.\n */\n\nexports.formatArgs = formatArgs;\nexports.save = save;\nexports.load = load;\nexports.useColors = useColors;\nexports.storage = localstorage();\nexports.destroy = (() => {\n\tlet warned = false;\n\n\treturn () => {\n\t\tif (!warned) {\n\t\t\twarned = true;\n\t\t\tconsole.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');\n\t\t}\n\t};\n})();\n\n/**\n * Colors.\n */\n\nexports.colors = [\n\t'#0000CC',\n\t'#0000FF',\n\t'#0033CC',\n\t'#0033FF',\n\t'#0066CC',\n\t'#0066FF',\n\t'#0099CC',\n\t'#0099FF',\n\t'#00CC00',\n\t'#00CC33',\n\t'#00CC66',\n\t'#00CC99',\n\t'#00CCCC',\n\t'#00CCFF',\n\t'#3300CC',\n\t'#3300FF',\n\t'#3333CC',\n\t'#3333FF',\n\t'#3366CC',\n\t'#3366FF',\n\t'#3399CC',\n\t'#3399FF',\n\t'#33CC00',\n\t'#33CC33',\n\t'#33CC66',\n\t'#33CC99',\n\t'#33CCCC',\n\t'#33CCFF',\n\t'#6600CC',\n\t'#6600FF',\n\t'#6633CC',\n\t'#6633FF',\n\t'#66CC00',\n\t'#66CC33',\n\t'#9900CC',\n\t'#9900FF',\n\t'#9933CC',\n\t'#9933FF',\n\t'#99CC00',\n\t'#99CC33',\n\t'#CC0000',\n\t'#CC0033',\n\t'#CC0066',\n\t'#CC0099',\n\t'#CC00CC',\n\t'#CC00FF',\n\t'#CC3300',\n\t'#CC3333',\n\t'#CC3366',\n\t'#CC3399',\n\t'#CC33CC',\n\t'#CC33FF',\n\t'#CC6600',\n\t'#CC6633',\n\t'#CC9900',\n\t'#CC9933',\n\t'#CCCC00',\n\t'#CCCC33',\n\t'#FF0000',\n\t'#FF0033',\n\t'#FF0066',\n\t'#FF0099',\n\t'#FF00CC',\n\t'#FF00FF',\n\t'#FF3300',\n\t'#FF3333',\n\t'#FF3366',\n\t'#FF3399',\n\t'#FF33CC',\n\t'#FF33FF',\n\t'#FF6600',\n\t'#FF6633',\n\t'#FF9900',\n\t'#FF9933',\n\t'#FFCC00',\n\t'#FFCC33'\n];\n\n/**\n * Currently only WebKit-based Web Inspectors, Firefox >= v31,\n * and the Firebug extension (any Firefox version) are known\n * to support \"%c\" CSS customizations.\n *\n * TODO: add a `localStorage` variable to explicitly enable/disable colors\n */\n\n// eslint-disable-next-line complexity\nfunction useColors() {\n\t// NB: In an Electron preload script, document will be defined but not fully\n\t// initialized. Since we know we're in Chrome, we'll just detect this case\n\t// explicitly\n\tif (typeof window !== 'undefined' && window.process && (window.process.type === 'renderer' || window.process.__nwjs)) {\n\t\treturn true;\n\t}\n\n\t// Internet Explorer and Edge do not support colors.\n\tif (typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/(edge|trident)\\/(\\d+)/)) {\n\t\treturn false;\n\t}\n\n\t// Is webkit? http://stackoverflow.com/a/16459606/376773\n\t// document is undefined in react-native: https://github.com/facebook/react-native/pull/1632\n\treturn (typeof document !== 'undefined' && document.documentElement && document.documentElement.style && document.documentElement.style.WebkitAppearance) ||\n\t\t// Is firebug? http://stackoverflow.com/a/398120/376773\n\t\t(typeof window !== 'undefined' && window.console && (window.console.firebug || (window.console.exception && window.console.table))) ||\n\t\t// Is firefox >= v31?\n\t\t// https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages\n\t\t(typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/firefox\\/(\\d+)/) && parseInt(RegExp.$1, 10) >= 31) ||\n\t\t// Double check webkit in userAgent just in case we are in a worker\n\t\t(typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\\/(\\d+)/));\n}\n\n/**\n * Colorize log arguments if enabled.\n *\n * @api public\n */\n\nfunction formatArgs(args) {\n\targs[0] = (this.useColors ? '%c' : '') +\n\t\tthis.namespace +\n\t\t(this.useColors ? ' %c' : ' ') +\n\t\targs[0] +\n\t\t(this.useColors ? '%c ' : ' ') +\n\t\t'+' + module.exports.humanize(this.diff);\n\n\tif (!this.useColors) {\n\t\treturn;\n\t}\n\n\tconst c = 'color: ' + this.color;\n\targs.splice(1, 0, c, 'color: inherit');\n\n\t// The final \"%c\" is somewhat tricky, because there could be other\n\t// arguments passed either before or after the %c, so we need to\n\t// figure out the correct index to insert the CSS into\n\tlet index = 0;\n\tlet lastC = 0;\n\targs[0].replace(/%[a-zA-Z%]/g, match => {\n\t\tif (match === '%%') {\n\t\t\treturn;\n\t\t}\n\t\tindex++;\n\t\tif (match === '%c') {\n\t\t\t// We only are interested in the *last* %c\n\t\t\t// (the user may have provided their own)\n\t\t\tlastC = index;\n\t\t}\n\t});\n\n\targs.splice(lastC, 0, c);\n}\n\n/**\n * Invokes `console.debug()` when available.\n * No-op when `console.debug` is not a \"function\".\n * If `console.debug` is not available, falls back\n * to `console.log`.\n *\n * @api public\n */\nexports.log = console.debug || console.log || (() => {});\n\n/**\n * Save `namespaces`.\n *\n * @param {String} namespaces\n * @api private\n */\nfunction save(namespaces) {\n\ttry {\n\t\tif (namespaces) {\n\t\t\texports.storage.setItem('debug', namespaces);\n\t\t} else {\n\t\t\texports.storage.removeItem('debug');\n\t\t}\n\t} catch (error) {\n\t\t// Swallow\n\t\t// XXX (@Qix-) should we be logging these?\n\t}\n}\n\n/**\n * Load `namespaces`.\n *\n * @return {String} returns the previously persisted debug modes\n * @api private\n */\nfunction load() {\n\tlet r;\n\ttry {\n\t\tr = exports.storage.getItem('debug');\n\t} catch (error) {\n\t\t// Swallow\n\t\t// XXX (@Qix-) should we be logging these?\n\t}\n\n\t// If debug isn't set in LS, and we're in Electron, try to load $DEBUG\n\tif (!r && typeof process !== 'undefined' && 'env' in process) {\n\t\tr = process.env.DEBUG;\n\t}\n\n\treturn r;\n}\n\n/**\n * Localstorage attempts to return the localstorage.\n *\n * This is necessary because safari throws\n * when a user disables cookies/localstorage\n * and you attempt to access it.\n *\n * @return {LocalStorage}\n * @api private\n */\n\nfunction localstorage() {\n\ttry {\n\t\t// TVMLKit (Apple TV JS Runtime) does not have a window object, just localStorage in the global context\n\t\t// The Browser also has localStorage in the global context.\n\t\treturn localStorage;\n\t} catch (error) {\n\t\t// Swallow\n\t\t// XXX (@Qix-) should we be logging these?\n\t}\n}\n\nmodule.exports = __webpack_require__(/*! ./common */ \"./node_modules/debug/src/common.js\")(exports);\n\nconst {formatters} = module.exports;\n\n/**\n * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.\n */\n\nformatters.j = function (v) {\n\ttry {\n\t\treturn JSON.stringify(v);\n\t} catch (error) {\n\t\treturn '[UnexpectedJSONParseError]: ' + error.message;\n\t}\n};\n\n\n//# sourceURL=webpack://renderer/./node_modules/debug/src/browser.js?");

/***/ }),

/***/ "./node_modules/debug/src/common.js":
/*!******************************************!*\
  !*** ./node_modules/debug/src/common.js ***!
  \******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("\n/**\n * This is the common logic for both the Node.js and web browser\n * implementations of `debug()`.\n */\n\nfunction setup(env) {\n\tcreateDebug.debug = createDebug;\n\tcreateDebug.default = createDebug;\n\tcreateDebug.coerce = coerce;\n\tcreateDebug.disable = disable;\n\tcreateDebug.enable = enable;\n\tcreateDebug.enabled = enabled;\n\tcreateDebug.humanize = __webpack_require__(/*! ms */ \"./node_modules/ms/index.js\");\n\tcreateDebug.destroy = destroy;\n\n\tObject.keys(env).forEach(key => {\n\t\tcreateDebug[key] = env[key];\n\t});\n\n\t/**\n\t* The currently active debug mode names, and names to skip.\n\t*/\n\n\tcreateDebug.names = [];\n\tcreateDebug.skips = [];\n\n\t/**\n\t* Map of special \"%n\" handling functions, for the debug \"format\" argument.\n\t*\n\t* Valid key names are a single, lower or upper-case letter, i.e. \"n\" and \"N\".\n\t*/\n\tcreateDebug.formatters = {};\n\n\t/**\n\t* Selects a color for a debug namespace\n\t* @param {String} namespace The namespace string for the debug instance to be colored\n\t* @return {Number|String} An ANSI color code for the given namespace\n\t* @api private\n\t*/\n\tfunction selectColor(namespace) {\n\t\tlet hash = 0;\n\n\t\tfor (let i = 0; i < namespace.length; i++) {\n\t\t\thash = ((hash << 5) - hash) + namespace.charCodeAt(i);\n\t\t\thash |= 0; // Convert to 32bit integer\n\t\t}\n\n\t\treturn createDebug.colors[Math.abs(hash) % createDebug.colors.length];\n\t}\n\tcreateDebug.selectColor = selectColor;\n\n\t/**\n\t* Create a debugger with the given `namespace`.\n\t*\n\t* @param {String} namespace\n\t* @return {Function}\n\t* @api public\n\t*/\n\tfunction createDebug(namespace) {\n\t\tlet prevTime;\n\t\tlet enableOverride = null;\n\t\tlet namespacesCache;\n\t\tlet enabledCache;\n\n\t\tfunction debug(...args) {\n\t\t\t// Disabled?\n\t\t\tif (!debug.enabled) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tconst self = debug;\n\n\t\t\t// Set `diff` timestamp\n\t\t\tconst curr = Number(new Date());\n\t\t\tconst ms = curr - (prevTime || curr);\n\t\t\tself.diff = ms;\n\t\t\tself.prev = prevTime;\n\t\t\tself.curr = curr;\n\t\t\tprevTime = curr;\n\n\t\t\targs[0] = createDebug.coerce(args[0]);\n\n\t\t\tif (typeof args[0] !== 'string') {\n\t\t\t\t// Anything else let's inspect with %O\n\t\t\t\targs.unshift('%O');\n\t\t\t}\n\n\t\t\t// Apply any `formatters` transformations\n\t\t\tlet index = 0;\n\t\t\targs[0] = args[0].replace(/%([a-zA-Z%])/g, (match, format) => {\n\t\t\t\t// If we encounter an escaped % then don't increase the array index\n\t\t\t\tif (match === '%%') {\n\t\t\t\t\treturn '%';\n\t\t\t\t}\n\t\t\t\tindex++;\n\t\t\t\tconst formatter = createDebug.formatters[format];\n\t\t\t\tif (typeof formatter === 'function') {\n\t\t\t\t\tconst val = args[index];\n\t\t\t\t\tmatch = formatter.call(self, val);\n\n\t\t\t\t\t// Now we need to remove `args[index]` since it's inlined in the `format`\n\t\t\t\t\targs.splice(index, 1);\n\t\t\t\t\tindex--;\n\t\t\t\t}\n\t\t\t\treturn match;\n\t\t\t});\n\n\t\t\t// Apply env-specific formatting (colors, etc.)\n\t\t\tcreateDebug.formatArgs.call(self, args);\n\n\t\t\tconst logFn = self.log || createDebug.log;\n\t\t\tlogFn.apply(self, args);\n\t\t}\n\n\t\tdebug.namespace = namespace;\n\t\tdebug.useColors = createDebug.useColors();\n\t\tdebug.color = createDebug.selectColor(namespace);\n\t\tdebug.extend = extend;\n\t\tdebug.destroy = createDebug.destroy; // XXX Temporary. Will be removed in the next major release.\n\n\t\tObject.defineProperty(debug, 'enabled', {\n\t\t\tenumerable: true,\n\t\t\tconfigurable: false,\n\t\t\tget: () => {\n\t\t\t\tif (enableOverride !== null) {\n\t\t\t\t\treturn enableOverride;\n\t\t\t\t}\n\t\t\t\tif (namespacesCache !== createDebug.namespaces) {\n\t\t\t\t\tnamespacesCache = createDebug.namespaces;\n\t\t\t\t\tenabledCache = createDebug.enabled(namespace);\n\t\t\t\t}\n\n\t\t\t\treturn enabledCache;\n\t\t\t},\n\t\t\tset: v => {\n\t\t\t\tenableOverride = v;\n\t\t\t}\n\t\t});\n\n\t\t// Env-specific initialization logic for debug instances\n\t\tif (typeof createDebug.init === 'function') {\n\t\t\tcreateDebug.init(debug);\n\t\t}\n\n\t\treturn debug;\n\t}\n\n\tfunction extend(namespace, delimiter) {\n\t\tconst newDebug = createDebug(this.namespace + (typeof delimiter === 'undefined' ? ':' : delimiter) + namespace);\n\t\tnewDebug.log = this.log;\n\t\treturn newDebug;\n\t}\n\n\t/**\n\t* Enables a debug mode by namespaces. This can include modes\n\t* separated by a colon and wildcards.\n\t*\n\t* @param {String} namespaces\n\t* @api public\n\t*/\n\tfunction enable(namespaces) {\n\t\tcreateDebug.save(namespaces);\n\t\tcreateDebug.namespaces = namespaces;\n\n\t\tcreateDebug.names = [];\n\t\tcreateDebug.skips = [];\n\n\t\tlet i;\n\t\tconst split = (typeof namespaces === 'string' ? namespaces : '').split(/[\\s,]+/);\n\t\tconst len = split.length;\n\n\t\tfor (i = 0; i < len; i++) {\n\t\t\tif (!split[i]) {\n\t\t\t\t// ignore empty strings\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tnamespaces = split[i].replace(/\\*/g, '.*?');\n\n\t\t\tif (namespaces[0] === '-') {\n\t\t\t\tcreateDebug.skips.push(new RegExp('^' + namespaces.slice(1) + '$'));\n\t\t\t} else {\n\t\t\t\tcreateDebug.names.push(new RegExp('^' + namespaces + '$'));\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t* Disable debug output.\n\t*\n\t* @return {String} namespaces\n\t* @api public\n\t*/\n\tfunction disable() {\n\t\tconst namespaces = [\n\t\t\t...createDebug.names.map(toNamespace),\n\t\t\t...createDebug.skips.map(toNamespace).map(namespace => '-' + namespace)\n\t\t].join(',');\n\t\tcreateDebug.enable('');\n\t\treturn namespaces;\n\t}\n\n\t/**\n\t* Returns true if the given mode name is enabled, false otherwise.\n\t*\n\t* @param {String} name\n\t* @return {Boolean}\n\t* @api public\n\t*/\n\tfunction enabled(name) {\n\t\tif (name[name.length - 1] === '*') {\n\t\t\treturn true;\n\t\t}\n\n\t\tlet i;\n\t\tlet len;\n\n\t\tfor (i = 0, len = createDebug.skips.length; i < len; i++) {\n\t\t\tif (createDebug.skips[i].test(name)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\n\t\tfor (i = 0, len = createDebug.names.length; i < len; i++) {\n\t\t\tif (createDebug.names[i].test(name)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\n\t\treturn false;\n\t}\n\n\t/**\n\t* Convert regexp to namespace\n\t*\n\t* @param {RegExp} regxep\n\t* @return {String} namespace\n\t* @api private\n\t*/\n\tfunction toNamespace(regexp) {\n\t\treturn regexp.toString()\n\t\t\t.substring(2, regexp.toString().length - 2)\n\t\t\t.replace(/\\.\\*\\?$/, '*');\n\t}\n\n\t/**\n\t* Coerce `val`.\n\t*\n\t* @param {Mixed} val\n\t* @return {Mixed}\n\t* @api private\n\t*/\n\tfunction coerce(val) {\n\t\tif (val instanceof Error) {\n\t\t\treturn val.stack || val.message;\n\t\t}\n\t\treturn val;\n\t}\n\n\t/**\n\t* XXX DO NOT USE. This is a temporary stub function.\n\t* XXX It WILL be removed in the next major release.\n\t*/\n\tfunction destroy() {\n\t\tconsole.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');\n\t}\n\n\tcreateDebug.enable(createDebug.load());\n\n\treturn createDebug;\n}\n\nmodule.exports = setup;\n\n\n//# sourceURL=webpack://renderer/./node_modules/debug/src/common.js?");

/***/ }),

/***/ "./node_modules/electron-debug/index.js":
/*!**********************************************!*\
  !*** ./node_modules/electron-debug/index.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst {app, BrowserWindow, session} = __webpack_require__(/*! electron */ \"electron\");\nconst path = __webpack_require__(/*! path */ \"path\");\nconst localShortcut = __webpack_require__(/*! electron-localshortcut */ \"./node_modules/electron-localshortcut/index.js\");\nconst isDev = __webpack_require__(/*! electron-is-dev */ \"./node_modules/electron-is-dev/index.js\");\n\nconst isMacOS = process.platform === 'darwin';\n\nconst devToolsOptions = {};\n\nfunction toggleDevTools(win = BrowserWindow.getFocusedWindow()) {\n\tif (win) {\n\t\tconst {webContents} = win;\n\t\tif (webContents.isDevToolsOpened()) {\n\t\t\twebContents.closeDevTools();\n\t\t} else {\n\t\t\twebContents.openDevTools(devToolsOptions);\n\t\t}\n\t}\n}\n\nfunction devTools(win = BrowserWindow.getFocusedWindow()) {\n\tif (win) {\n\t\ttoggleDevTools(win);\n\t}\n}\n\nfunction openDevTools(win = BrowserWindow.getFocusedWindow()) {\n\tif (win) {\n\t\twin.webContents.openDevTools(devToolsOptions);\n\t}\n}\n\nfunction refresh(win = BrowserWindow.getFocusedWindow()) {\n\tif (win) {\n\t\twin.webContents.reloadIgnoringCache();\n\t}\n}\n\nfunction inspectElements() {\n\tconst win = BrowserWindow.getFocusedWindow();\n\tconst inspect = () => {\n\t\twin.devToolsWebContents.executeJavaScript('DevToolsAPI.enterInspectElementMode()');\n\t};\n\n\tif (win) {\n\t\tif (win.webContents.isDevToolsOpened()) {\n\t\t\tinspect();\n\t\t} else {\n\t\t\twin.webContents.once('devtools-opened', inspect);\n\t\t\twin.openDevTools();\n\t\t}\n\t}\n}\n\nconst addExtensionIfInstalled = (name, getPath) => {\n\tconst isExtensionInstalled = name => {\n\t\t// For Electron >=9.\n\t\tif (session.defaultSession.getAllExtensions) {\n\t\t\treturn {}.hasOwnProperty.call(session.defaultSession.getAllExtensions(), name);\n\t\t}\n\n\t\t// TODO: Remove this when targeting Electron >=9.\n\t\treturn BrowserWindow.getDevToolsExtensions &&\n\t\t\t{}.hasOwnProperty.call(BrowserWindow.getDevToolsExtensions(), name);\n\t};\n\n\ttry {\n\t\tif (!isExtensionInstalled(name)) {\n\t\t\t// For Electron >=9.\n\t\t\tif (session.defaultSession.loadExtension) {\n\t\t\t\tsession.defaultSession.loadExtension(getPath(name));\n\t\t\t} else {\n\t\t\t\t// TODO: Remove this when targeting Electron >=9.\n\t\t\t\tBrowserWindow.addDevToolsExtension(getPath(name));\n\t\t\t}\n\t\t}\n\t} catch (_) {}\n};\n\nmodule.exports = options => {\n\toptions = {\n\t\tisEnabled: null,\n\t\tshowDevTools: true,\n\t\tdevToolsMode: 'previous',\n\t\t...options\n\t};\n\n\tif (options.isEnabled === false || (options.isEnabled === null && !isDev)) {\n\t\treturn;\n\t}\n\n\tif (options.devToolsMode !== 'previous') {\n\t\tdevToolsOptions.mode = options.devToolsMode;\n\t}\n\n\tapp.on('browser-window-created', (event, win) => {\n\t\tif (options.showDevTools) {\n\t\t\t/// Workaround for https://github.com/electron/electron/issues/12438\n\t\t\twin.webContents.once('dom-ready', () => {\n\t\t\t\topenDevTools(win, options.showDevTools, false);\n\t\t\t});\n\t\t}\n\t});\n\n\t(async () => {\n\t\tawait app.whenReady();\n\n\t\taddExtensionIfInstalled('devtron', name => __webpack_require__(\"./node_modules/electron-debug sync recursive\")(name).path);\n\t\taddExtensionIfInstalled('electron-react-devtools', name => __webpack_require__(\"./node_modules/electron-debug sync recursive\")(name).path);\n\n\t\tlocalShortcut.register('CommandOrControl+Shift+C', inspectElements);\n\t\tlocalShortcut.register(isMacOS ? 'Command+Alt+I' : 'Control+Shift+I', devTools);\n\t\tlocalShortcut.register('F12', devTools);\n\n\t\tlocalShortcut.register('CommandOrControl+R', refresh);\n\t\tlocalShortcut.register('F5', refresh);\n\t})();\n};\n\nmodule.exports.refresh = refresh;\nmodule.exports.devTools = devTools;\nmodule.exports.openDevTools = openDevTools;\nmodule.exports.preloadScriptPath = path.join(__dirname, 'preload.js');\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-debug/index.js?");

/***/ }),

/***/ "./node_modules/electron-debug sync recursive":
/*!*******************************************!*\
  !*** ./node_modules/electron-debug/ sync ***!
  \*******************************************/
/***/ ((module) => {

eval("function webpackEmptyContext(req) {\n\tvar e = new Error(\"Cannot find module '\" + req + \"'\");\n\te.code = 'MODULE_NOT_FOUND';\n\tthrow e;\n}\nwebpackEmptyContext.keys = () => ([]);\nwebpackEmptyContext.resolve = webpackEmptyContext;\nwebpackEmptyContext.id = \"./node_modules/electron-debug sync recursive\";\nmodule.exports = webpackEmptyContext;\n\n//# sourceURL=webpack://renderer/./node_modules/electron-debug/_sync?");

/***/ }),

/***/ "./node_modules/electron-is-accelerator/index.js":
/*!*******************************************************!*\
  !*** ./node_modules/electron-is-accelerator/index.js ***!
  \*******************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nconst modifiers = /^(Command|Cmd|Control|Ctrl|CommandOrControl|CmdOrCtrl|Alt|Option|AltGr|Shift|Super)$/;\nconst keyCodes = /^([0-9A-Z)!@#$%^&*(:+<_>?~{|}\";=,\\-./`[\\\\\\]']|F1*[1-9]|F10|F2[0-4]|Plus|Space|Tab|Backspace|Delete|Insert|Return|Enter|Up|Down|Left|Right|Home|End|PageUp|PageDown|Escape|Esc|VolumeUp|VolumeDown|VolumeMute|MediaNextTrack|MediaPreviousTrack|MediaStop|MediaPlayPause|PrintScreen)$/;\n\nmodule.exports = function (str) {\n\tlet parts = str.split(\"+\");\n\tlet keyFound = false;\n    return parts.every((val, index) => {\n\t\tconst isKey = keyCodes.test(val);\n\t\tconst isModifier = modifiers.test(val);\n\t\tif (isKey) {\n\t\t\t// Key must be unique\n\t\t\tif (keyFound) return false;\n\t\t\tkeyFound = true;\n\t\t}\n\t\t// Key is required\n\t\tif (index === parts.length - 1 && !keyFound) return false;\n        return isKey || isModifier;\n    });\n};\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-is-accelerator/index.js?");

/***/ }),

/***/ "./node_modules/electron-is-dev/index.js":
/*!***********************************************!*\
  !*** ./node_modules/electron-is-dev/index.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst electron = __webpack_require__(/*! electron */ \"electron\");\n\nif (typeof electron === 'string') {\n\tthrow new TypeError('Not running in an Electron environment!');\n}\n\nconst app = electron.app || electron.remote.app;\n\nconst isEnvSet = 'ELECTRON_IS_DEV' in process.env;\nconst getFromEnv = parseInt(process.env.ELECTRON_IS_DEV, 10) === 1;\n\nmodule.exports = isEnvSet ? getFromEnv : !app.isPackaged;\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-is-dev/index.js?");

/***/ }),

/***/ "./node_modules/electron-localshortcut/index.js":
/*!******************************************************!*\
  !*** ./node_modules/electron-localshortcut/index.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst {app, BrowserWindow} = __webpack_require__(/*! electron */ \"electron\");\nconst isAccelerator = __webpack_require__(/*! electron-is-accelerator */ \"./node_modules/electron-is-accelerator/index.js\");\nconst equals = __webpack_require__(/*! keyboardevents-areequal */ \"./node_modules/keyboardevents-areequal/index.js\");\nconst {toKeyEvent} = __webpack_require__(/*! keyboardevent-from-electron-accelerator */ \"./node_modules/keyboardevent-from-electron-accelerator/index.js\");\nconst _debug = __webpack_require__(/*! debug */ \"./node_modules/debug/src/browser.js\");\n\nconst debug = _debug('electron-localshortcut');\n\n// A placeholder to register shortcuts\n// on any window of the app.\nconst ANY_WINDOW = {};\n\nconst windowsWithShortcuts = new WeakMap();\n\nconst title = win => {\n\tif (win) {\n\t\ttry {\n\t\t\treturn win.getTitle();\n\t\t// eslint-disable-next-line no-unused-vars\n\t\t} catch (error) {\n\t\t\treturn 'A destroyed window';\n\t\t}\n\t}\n\n\treturn 'An falsy value';\n};\n\nfunction _checkAccelerator(accelerator) {\n\tif (!isAccelerator(accelerator)) {\n\t\tconst w = {};\n\t\tError.captureStackTrace(w);\n\t\tconst stack = w.stack ? w.stack.split('\\n').slice(4).join('\\n') : w.message;\n\t\tconst msg = `\nWARNING: ${accelerator} is not a valid accelerator.\n\n${stack}\n`;\n\t\tconsole.error(msg);\n\t}\n}\n\n/**\n * Disable all of the shortcuts registered on the BrowserWindow instance.\n * Registered shortcuts no more works on the `window` instance, but the module\n * keep a reference on them. You can reactivate them later by calling `enableAll`\n * method on the same window instance.\n * @param  {BrowserWindow} win BrowserWindow instance\n */\nfunction disableAll(win) {\n\tdebug(`Disabling all shortcuts on window ${title(win)}`);\n\tconst wc = win.webContents;\n\tconst shortcutsOfWindow = windowsWithShortcuts.get(wc);\n\n\tfor (const shortcut of shortcutsOfWindow) {\n\t\tshortcut.enabled = false;\n\t}\n}\n\n/**\n * Enable all of the shortcuts registered on the BrowserWindow instance that\n * you had previously disabled calling `disableAll` method.\n * @param  {BrowserWindow} win BrowserWindow instance\n */\nfunction enableAll(win) {\n\tdebug(`Enabling all shortcuts on window ${title(win)}`);\n\tconst wc = win.webContents;\n\tconst shortcutsOfWindow = windowsWithShortcuts.get(wc);\n\n\tfor (const shortcut of shortcutsOfWindow) {\n\t\tshortcut.enabled = true;\n\t}\n}\n\n/**\n * Unregisters all of the shortcuts registered on any focused BrowserWindow\n * instance. This method does not unregister any shortcut you registered on\n * a particular window instance.\n * @param  {BrowserWindow} win BrowserWindow instance\n */\nfunction unregisterAll(win) {\n\tdebug(`Unregistering all shortcuts on window ${title(win)}`);\n\tconst wc = win.webContents;\n\tconst shortcutsOfWindow = windowsWithShortcuts.get(wc);\n\tif (shortcutsOfWindow && shortcutsOfWindow.removeListener) {\n\t\t// Remove listener from window\n\t\tshortcutsOfWindow.removeListener();\n\t\twindowsWithShortcuts.delete(wc);\n\t}\n}\n\nfunction _normalizeEvent(input) {\n\tconst normalizedEvent = {\n\t\tcode: input.code,\n\t\tkey: input.key\n\t};\n\n\t['alt', 'shift', 'meta'].forEach(prop => {\n\t\tif (typeof input[prop] !== 'undefined') {\n\t\t\tnormalizedEvent[`${prop}Key`] = input[prop];\n\t\t}\n\t});\n\n\tif (typeof input.control !== 'undefined') {\n\t\tnormalizedEvent.ctrlKey = input.control;\n\t}\n\n\treturn normalizedEvent;\n}\n\nfunction _findShortcut(event, shortcutsOfWindow) {\n\tlet i = 0;\n\tfor (const shortcut of shortcutsOfWindow) {\n\t\tif (equals(shortcut.eventStamp, event)) {\n\t\t\treturn i;\n\t\t}\n\n\t\ti++;\n\t}\n\n\treturn -1;\n}\n\nconst _onBeforeInput = shortcutsOfWindow => (e, input) => {\n\tif (input.type === 'keyUp') {\n\t\treturn;\n\t}\n\n\tconst event = _normalizeEvent(input);\n\n\tdebug(`before-input-event: ${input} is translated to: ${event}`);\n\tfor (const {eventStamp, callback} of shortcutsOfWindow) {\n\t\tif (equals(eventStamp, event)) {\n\t\t\tdebug(`eventStamp: ${eventStamp} match`);\n\t\t\tcallback();\n\n\t\t\treturn;\n\t\t}\n\n\t\tdebug(`eventStamp: ${eventStamp} no match`);\n\t}\n};\n\n/**\n * Registers the shortcut `accelerator`on the BrowserWindow instance.\n * @param  {BrowserWindow} win - BrowserWindow instance to register.\n * This argument could be omitted, in this case the function register\n * the shortcut on all app windows.\n * @param  {String|Array<String>} accelerator - the shortcut to register\n * @param  {Function} callback    This function is called when the shortcut is pressed\n * and the window is focused and not minimized.\n */\nfunction register(win, accelerator, callback) {\n\tlet wc;\n\tif (typeof callback === 'undefined') {\n\t\twc = ANY_WINDOW;\n\t\tcallback = accelerator;\n\t\taccelerator = win;\n\t} else {\n\t\twc = win.webContents;\n\t}\n\n\tif (Array.isArray(accelerator) === true) {\n\t\taccelerator.forEach(accelerator => {\n\t\t\tif (typeof accelerator === 'string') {\n\t\t\t\tregister(win, accelerator, callback);\n\t\t\t}\n\t\t});\n\t\treturn;\n\t}\n\n\tdebug(`Registering callback for ${accelerator} on window ${title(win)}`);\n\t_checkAccelerator(accelerator);\n\n\tdebug(`${accelerator} seems a valid shortcut sequence.`);\n\n\tlet shortcutsOfWindow;\n\tif (windowsWithShortcuts.has(wc)) {\n\t\tdebug('Window has others shortcuts registered.');\n\t\tshortcutsOfWindow = windowsWithShortcuts.get(wc);\n\t} else {\n\t\tdebug('This is the first shortcut of the window.');\n\t\tshortcutsOfWindow = [];\n\t\twindowsWithShortcuts.set(wc, shortcutsOfWindow);\n\n\t\tif (wc === ANY_WINDOW) {\n\t\t\tconst keyHandler = _onBeforeInput(shortcutsOfWindow);\n\t\t\tconst enableAppShortcuts = (e, win) => {\n\t\t\t\tconst wc = win.webContents;\n\t\t\t\twc.on('before-input-event', keyHandler);\n\t\t\t\twc.once('closed', () =>\n\t\t\t\t\twc.removeListener('before-input-event', keyHandler)\n\t\t\t\t);\n\t\t\t};\n\n\t\t\t// Enable shortcut on current windows\n\t\t\tconst windows = BrowserWindow.getAllWindows();\n\n\t\t\twindows.forEach(win => enableAppShortcuts(null, win));\n\n\t\t\t// Enable shortcut on future windows\n\t\t\tapp.on('browser-window-created', enableAppShortcuts);\n\n\t\t\tshortcutsOfWindow.removeListener = () => {\n\t\t\t\tconst windows = BrowserWindow.getAllWindows();\n\t\t\t\twindows.forEach(win =>\n\t\t\t\t\twin.webContents.removeListener('before-input-event', keyHandler)\n\t\t\t\t);\n\t\t\t\tapp.removeListener('browser-window-created', enableAppShortcuts);\n\t\t\t};\n\t\t} else {\n\t\t\tconst keyHandler = _onBeforeInput(shortcutsOfWindow);\n\t\t\twc.on('before-input-event', keyHandler);\n\n\t\t\t// Save a reference to allow remove of listener from elsewhere\n\t\t\tshortcutsOfWindow.removeListener = () =>\n\t\t\t\twc.removeListener('before-input-event', keyHandler);\n\t\t\twc.once('closed', shortcutsOfWindow.removeListener);\n\t\t}\n\t}\n\n\tdebug('Adding shortcut to window set.');\n\n\tconst eventStamp = toKeyEvent(accelerator);\n\n\tshortcutsOfWindow.push({\n\t\teventStamp,\n\t\tcallback,\n\t\tenabled: true\n\t});\n\n\tdebug('Shortcut registered.');\n}\n\n/**\n * Unregisters the shortcut of `accelerator` registered on the BrowserWindow instance.\n * @param  {BrowserWindow} win - BrowserWindow instance to unregister.\n * This argument could be omitted, in this case the function unregister the shortcut\n * on all app windows. If you registered the shortcut on a particular window instance, it will do nothing.\n * @param  {String|Array<String>} accelerator - the shortcut to unregister\n */\nfunction unregister(win, accelerator) {\n\tlet wc;\n\tif (typeof accelerator === 'undefined') {\n\t\twc = ANY_WINDOW;\n\t\taccelerator = win;\n\t} else {\n\t\tif (win.isDestroyed()) {\n\t\t\tdebug('Early return because window is destroyed.');\n\t\t\treturn;\n\t\t}\n\n\t\twc = win.webContents;\n\t}\n\n\tif (Array.isArray(accelerator) === true) {\n\t\taccelerator.forEach(accelerator => {\n\t\t\tif (typeof accelerator === 'string') {\n\t\t\t\tunregister(win, accelerator);\n\t\t\t}\n\t\t});\n\t\treturn;\n\t}\n\n\tdebug(`Unregistering callback for ${accelerator} on window ${title(win)}`);\n\n\t_checkAccelerator(accelerator);\n\n\tdebug(`${accelerator} seems a valid shortcut sequence.`);\n\n\tif (!windowsWithShortcuts.has(wc)) {\n\t\tdebug('Early return because window has never had shortcuts registered.');\n\t\treturn;\n\t}\n\n\tconst shortcutsOfWindow = windowsWithShortcuts.get(wc);\n\n\tconst eventStamp = toKeyEvent(accelerator);\n\tconst shortcutIdx = _findShortcut(eventStamp, shortcutsOfWindow);\n\tif (shortcutIdx === -1) {\n\t\treturn;\n\t}\n\n\tshortcutsOfWindow.splice(shortcutIdx, 1);\n\n\t// If the window has no more shortcuts,\n\t// we remove it early from the WeakMap\n\t// and unregistering the event listener\n\tif (shortcutsOfWindow.length === 0) {\n\t\t// Remove listener from window\n\t\tshortcutsOfWindow.removeListener();\n\n\t\t// Remove window from shortcuts catalog\n\t\twindowsWithShortcuts.delete(wc);\n\t}\n}\n\n/**\n * Returns `true` or `false` depending on whether the shortcut `accelerator`\n * is registered on `window`.\n * @param  {BrowserWindow} win - BrowserWindow instance to check. This argument\n * could be omitted, in this case the function returns whether the shortcut\n * `accelerator` is registered on all app windows. If you registered the\n * shortcut on a particular window instance, it return false.\n * @param  {String} accelerator - the shortcut to check\n * @return {Boolean} - if the shortcut `accelerator` is registered on `window`.\n */\nfunction isRegistered(win, accelerator) {\n\t_checkAccelerator(accelerator);\n\tconst wc = win.webContents;\n\tconst shortcutsOfWindow = windowsWithShortcuts.get(wc);\n\tconst eventStamp = toKeyEvent(accelerator);\n\n\treturn _findShortcut(eventStamp, shortcutsOfWindow) !== -1;\n}\n\nmodule.exports = {\n\tregister,\n\tunregister,\n\tisRegistered,\n\tunregisterAll,\n\tenableAll,\n\tdisableAll\n};\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-localshortcut/index.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/catchErrors.js":
/*!******************************************************!*\
  !*** ./node_modules/electron-log/src/catchErrors.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/**\n * Some ideas from sindresorhus/electron-unhandled\n */\n\nvar electronApi = __webpack_require__(/*! ./electronApi */ \"./node_modules/electron-log/src/electronApi.js\");\nvar queryString = __webpack_require__(/*! querystring */ \"querystring\");\n\nvar isAttached = false;\n\nmodule.exports = function catchErrors(options) {\n  if (isAttached) return { stop: stop };\n  isAttached = true;\n\n  if (process.type === 'renderer') {\n    window.addEventListener('error', onRendererError);\n    window.addEventListener('unhandledrejection', onRendererRejection);\n  } else {\n    process.on('uncaughtException', onError);\n    process.on('unhandledRejection', onRejection);\n  }\n\n  return { stop: stop };\n\n  function onError(e) {\n    try {\n      if (typeof options.onError === 'function') {\n        var versions = electronApi.getVersions();\n        if (options.onError(e, versions, createIssue) === false) {\n          return;\n        }\n      }\n\n      options.log('Unhandled Exception', e);\n\n      if (options.showDialog && e.name.indexOf('UnhandledRejection') < 0) {\n        var type = process.type || 'main';\n        electronApi.showErrorBox(\n          'A JavaScript error occurred in the ' + type + ' process',\n          e.stack\n        );\n      }\n    } catch (logError) {\n      // eslint-disable-next-line no-console\n      console.error(e);\n    }\n  }\n\n  function onRejection(reason) {\n    if (reason instanceof Error) {\n      try {\n        Object.defineProperty(reason, 'name', {\n          value: 'UnhandledRejection ' + reason.name,\n        });\n      } catch (e) {\n        // Can't redefine error name, but who cares?\n      }\n\n      onError(reason);\n      return;\n    }\n\n    var error = new Error(JSON.stringify(reason));\n    error.name = 'UnhandledRejection';\n    onError(error);\n  }\n\n  function onRendererError(event) {\n    event.preventDefault();\n    onError(event.error);\n  }\n\n  function onRendererRejection(event) {\n    event.preventDefault();\n    onRejection(event.reason);\n  }\n\n  function stop() {\n    isAttached = false;\n\n    if (process.type === 'renderer') {\n      window.removeEventListener('error', onRendererError);\n      window.removeEventListener('unhandledrejection', onRendererRejection);\n    } else {\n      process.removeListener('uncaughtException', onError);\n      process.removeListener('unhandledRejection', onRejection);\n    }\n  }\n\n  function createIssue(pageUrl, queryParams) {\n    var issueUrl = pageUrl + '?' + queryString.stringify(queryParams);\n    electronApi.openUrl(issueUrl, options.log);\n  }\n};\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-log/src/catchErrors.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/electronApi.js":
/*!******************************************************!*\
  !*** ./node_modules/electron-log/src/electronApi.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/**\n * Split Electron API from the main code\n */\n\nvar path = __webpack_require__(/*! path */ \"path\");\nvar electron;\ntry {\n  // eslint-disable-next-line global-require\n  electron = __webpack_require__(/*! electron */ \"electron\");\n} catch (e) {\n  electron = null;\n}\n\nvar os = __webpack_require__(/*! os */ \"os\");\n\nmodule.exports = {\n  getName: getName,\n  getPath: getPath,\n  getVersion: getVersion,\n  getVersions: getVersions,\n  isDev: isDev,\n  isElectron: isElectron,\n  isIpcChannelListened: isIpcChannelListened,\n  loadRemoteModule: loadRemoteModule,\n  onIpc: onIpc,\n  openUrl: openUrl,\n  sendIpc: sendIpc,\n  showErrorBox: showErrorBox,\n};\n\nfunction getApp() {\n  return getElectronModule('app');\n}\n\nfunction getName() {\n  var app = getApp();\n  if (!app) return null;\n\n  return 'name' in app ? app.name : app.getName();\n}\n\nfunction getElectronModule(name) {\n  if (!electron) {\n    return null;\n  }\n\n  if (electron[name]) {\n    return electron[name];\n  }\n\n  if (electron.remote) {\n    return electron.remote[name];\n  }\n\n  return null;\n}\n\nfunction getIpc() {\n  if (process.type === 'browser' && electron && electron.ipcMain) {\n    return electron.ipcMain;\n  }\n\n  if (process.type === 'renderer' && electron && electron.ipcRenderer) {\n    return electron.ipcRenderer;\n  }\n\n  return null;\n}\n\nfunction getPath(name) {\n  var app = getApp();\n  if (!app) return null;\n\n  try {\n    return app.getPath(name);\n  } catch (e) {\n    return null;\n  }\n}\n\nfunction getVersion() {\n  var app = getApp();\n  if (!app) return null;\n\n  return 'version' in app ? app.version : app.getVersion();\n}\n\nfunction getVersions() {\n  return {\n    app: getName() + ' ' + getVersion(),\n    electron: 'Electron ' + process.versions.electron,\n    os: getOsVersion(),\n  };\n}\n\nfunction getOsVersion() {\n  var osName = os.type().replace('_', ' ');\n  var osVersion = os.release();\n\n  if (osName === 'Darwin') {\n    osName = 'macOS';\n    osVersion = getMacOsVersion();\n  }\n\n  return osName + ' ' + osVersion;\n}\n\nfunction getMacOsVersion() {\n  var release = Number(os.release().split('.')[0]);\n  return '10.' + (release - 4);\n}\n\nfunction isDev() {\n  var app = getApp();\n\n  if (app && app.isPackaged !== undefined) {\n    return !app.isPackaged;\n  }\n\n  if (typeof process.execPath === 'string') {\n    var execFileName = path.basename(process.execPath).toLowerCase();\n    return execFileName.startsWith('electron');\n  }\n\n  return  true\n    || 0;\n}\n\nfunction isElectron() {\n  return process.type === 'browser' || process.type === 'renderer';\n}\n\n/**\n * Return true if the process listens for the IPC channel\n * @param {string} channel\n */\nfunction isIpcChannelListened(channel) {\n  var ipc = getIpc();\n  return ipc ? ipc.listenerCount(channel) > 0 : false;\n}\n\n/**\n * Try to load the module in the opposite process\n * @param {string} moduleName\n */\nfunction loadRemoteModule(moduleName) {\n  if (process.type === 'browser') {\n    getApp().on('web-contents-created', function (e, contents) {\n      var promise = contents.executeJavaScript(\n        'try {require(\"' + moduleName + '\")} catch(e){}; void 0;'\n      );\n\n      // Do nothing on error, just prevent Unhandled rejection\n      if (promise && typeof promise.catch === 'function') {\n        promise.catch(function () {});\n      }\n    });\n  } else if (process.type === 'renderer') {\n    // Previously, it was electron.remote.require(moduleName)\n    // but now the remote module is deprecated\n  }\n}\n\n/**\n * Listen to async messages sent from opposite process\n * @param {string} channel\n * @param {function} listener\n */\nfunction onIpc(channel, listener) {\n  var ipc = getIpc();\n  if (ipc) {\n    ipc.on(channel, listener);\n  }\n}\n\n/**\n * Sent a message to opposite process\n * @param {string} channel\n * @param {any} message\n */\nfunction sendIpc(channel, message) {\n  if (process.type === 'browser') {\n    sendIpcToRenderer(channel, message);\n  } else if (process.type === 'renderer') {\n    sendIpcToMain(channel, message);\n  }\n}\n\nfunction sendIpcToMain(channel, message) {\n  var ipc = getIpc();\n  if (ipc) {\n    ipc.send(channel, message);\n  }\n}\n\nfunction sendIpcToRenderer(channel, message) {\n  if (!electron || !electron.BrowserWindow) {\n    return;\n  }\n\n  electron.BrowserWindow.getAllWindows().forEach(function (wnd) {\n    if (wnd.webContents && !wnd.webContents.isDestroyed()) {\n      wnd.webContents.send(channel, message);\n    }\n  });\n}\n\nfunction showErrorBox(title, message) {\n  var dialog = getElectronModule('dialog');\n  if (!dialog) return;\n\n  dialog.showErrorBox(title, message);\n}\n\n/**\n * @param {string} url\n * @param {Function} [logFunction]\n */\nfunction openUrl(url, logFunction) {\n  // eslint-disable-next-line no-console\n  logFunction = logFunction || console.error;\n\n  var shell = getElectronModule('shell');\n  if (!shell) return;\n\n  shell.openExternal(url).catch(logFunction);\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-log/src/electronApi.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/index.js":
/*!************************************************!*\
  !*** ./node_modules/electron-log/src/index.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar catchErrors = __webpack_require__(/*! ./catchErrors */ \"./node_modules/electron-log/src/catchErrors.js\");\nvar electronApi = __webpack_require__(/*! ./electronApi */ \"./node_modules/electron-log/src/electronApi.js\");\nvar log = __webpack_require__(/*! ./log */ \"./node_modules/electron-log/src/log.js\");\nvar scopeFactory = __webpack_require__(/*! ./scope */ \"./node_modules/electron-log/src/scope.js\");\nvar transportConsole = __webpack_require__(/*! ./transports/console */ \"./node_modules/electron-log/src/transports/console.js\");\nvar transportFile = __webpack_require__(/*! ./transports/file */ \"./node_modules/electron-log/src/transports/file/index.js\");\nvar transportIpc = __webpack_require__(/*! ./transports/ipc */ \"./node_modules/electron-log/src/transports/ipc.js\");\nvar transportRemote = __webpack_require__(/*! ./transports/remote */ \"./node_modules/electron-log/src/transports/remote.js\");\n\nmodule.exports = create('default');\nmodule.exports[\"default\"] = module.exports;\n\n/**\n * @param {string} logId\n * @return {ElectronLog.ElectronLog}\n */\nfunction create(logId) {\n  /**\n   * @type {ElectronLog.ElectronLog}\n   */\n  var instance = {\n    catchErrors: function callCatchErrors(options) {\n      var opts = Object.assign({}, {\n        log: instance.error,\n        showDialog: process.type === 'browser',\n      }, options || {});\n\n      catchErrors(opts);\n    },\n    create: create,\n    functions: {},\n    hooks: [],\n    isDev: electronApi.isDev(),\n    levels: [],\n    logId: logId,\n    variables: {\n      processType: process.type,\n    },\n  };\n\n  instance.scope = scopeFactory(instance);\n\n  instance.transports = {\n    console: transportConsole(instance),\n    file: transportFile(instance),\n    remote: transportRemote(instance),\n    ipc: transportIpc(instance),\n  };\n\n  Object.defineProperty(instance.levels, 'add', {\n    enumerable: false,\n    value: function add(name, index) {\n      index = index === undefined ? instance.levels.length : index;\n      instance.levels.splice(index, 0, name);\n      instance[name] = log.log.bind(null, instance, { level: name });\n      instance.functions[name] = instance[name];\n    },\n  });\n\n  ['error', 'warn', 'info', 'verbose', 'debug', 'silly'].forEach(\n    function (level) { instance.levels.add(level) }\n  );\n\n  instance.log = log.log.bind(null, instance, { level: 'info' });\n  instance.functions.log = instance.log;\n\n  instance.logMessageWithTransports = function logMessageWithTransports(\n    message,\n    transports\n  ) {\n    if (message.date === undefined) {\n      message.date = new Date();\n    }\n\n    if (message.variables === undefined) {\n      message.variables = instance.variables;\n    }\n\n    return log.runTransports(transports, message, instance);\n  };\n\n  return instance;\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-log/src/index.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/log.js":
/*!**********************************************!*\
  !*** ./node_modules/electron-log/src/log.js ***!
  \**********************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = {\n  compareLevels: compareLevels,\n  log: log,\n  runTransport: runTransport,\n  runTransports: runTransports,\n};\n\nfunction log(electronLog, options) {\n  var transports = electronLog.transports;\n\n  var message = {\n    data: Array.prototype.slice.call(arguments, 2),\n    date: new Date(),\n    level: options.level,\n    scope: options.scope ? options.scope.toJSON() : null,\n    variables: electronLog.variables,\n  };\n\n  runTransports(transports, message, electronLog);\n}\n\nfunction runTransports(transports, message, electronLog) {\n  for (var i in transports) {\n    if (Object.prototype.hasOwnProperty.call(transports, i)) {\n      runTransport(transports[i], message, electronLog);\n    }\n  }\n}\n\nfunction runTransport(transport, message, electronLog) {\n  if (typeof transport !== 'function' || transport.level === false) {\n    return;\n  }\n\n  if (!compareLevels(electronLog.levels, transport.level, message.level)) {\n    return;\n  }\n\n  message = runHooks(electronLog.hooks, transport, message);\n\n  if (message) {\n    transport(message);\n  }\n}\n\nfunction compareLevels(levels, passLevel, checkLevel) {\n  var pass = levels.indexOf(passLevel);\n  var check = levels.indexOf(checkLevel);\n  if (check === -1 || pass === -1) {\n    return true;\n  }\n\n  return check <= pass;\n}\n\nfunction runHooks(hooks, transport, message) {\n  if (!hooks || !hooks.length) {\n    return message;\n  }\n\n  // eslint-disable-next-line no-plusplus\n  for (var i = 0; i < hooks.length; i++) {\n    message = hooks[i](message, transport);\n    if (!message) break;\n  }\n\n  return message;\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-log/src/log.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/scope.js":
/*!************************************************!*\
  !*** ./node_modules/electron-log/src/scope.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar log = (__webpack_require__(/*! ./log */ \"./node_modules/electron-log/src/log.js\").log);\n\nmodule.exports = scopeFactory;\n\n/**\n * @param {ElectronLog.ElectronLog} electronLog\n * @return {ElectronLog.Scope}\n */\nfunction scopeFactory(electronLog) {\n  scope.labelPadding = true;\n  scope.defaultLabel = '';\n\n  /** @private */\n  scope.maxLabelLength = 0;\n\n  /**\n   * @type {typeof getOptions}\n   * @package\n   */\n  scope.getOptions = getOptions;\n\n  return scope;\n\n  function scope(label) {\n    var instance = {\n      label: label,\n      toJSON: function () {\n        return {\n          label: this.label,\n        };\n      },\n    };\n\n    electronLog.levels.forEach(function (level) {\n      instance[level] = log.bind(null, electronLog, {\n        level: level,\n        scope: instance,\n      });\n    });\n\n    instance.log = instance.info;\n\n    scope.maxLabelLength = Math.max(scope.maxLabelLength, label.length);\n\n    return instance;\n  }\n\n  function getOptions() {\n    return {\n      defaultLabel: scope.defaultLabel,\n      labelLength: getLabelLength(),\n    };\n  }\n\n  function getLabelLength() {\n    if (scope.labelPadding === true) {\n      return scope.maxLabelLength;\n    }\n\n    if (scope.labelPadding === false) {\n      return 0;\n    }\n\n    if (typeof scope.labelPadding === 'number') {\n      return scope.labelPadding;\n    }\n\n    return 0;\n  }\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-log/src/scope.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/transform/index.js":
/*!**********************************************************!*\
  !*** ./node_modules/electron-log/src/transform/index.js ***!
  \**********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar object = __webpack_require__(/*! ./object */ \"./node_modules/electron-log/src/transform/object.js\");\nvar style = __webpack_require__(/*! ./style */ \"./node_modules/electron-log/src/transform/style.js\");\nvar template = __webpack_require__(/*! ./template */ \"./node_modules/electron-log/src/transform/template.js\");\n\nmodule.exports = {\n  applyAnsiStyles: style.applyAnsiStyles,\n  concatFirstStringElements: template.concatFirstStringElements,\n  customFormatterFactory: customFormatterFactory,\n  maxDepthFactory: object.maxDepthFactory,\n  removeStyles: style.removeStyles,\n  toJSON: object.toJSON,\n  toStringFactory: object.toStringFactory,\n  transform: transform,\n};\n\nfunction customFormatterFactory(customFormat, concatFirst, scopeOptions) {\n  if (typeof customFormat === 'string') {\n    return function customStringFormatter(data, message) {\n      return transform(message, [\n        template.templateVariables,\n        template.templateScopeFactory(scopeOptions),\n        template.templateDate,\n        template.templateText,\n        concatFirst && template.concatFirstStringElements,\n      ], [customFormat].concat(data));\n    };\n  }\n\n  if (typeof customFormat === 'function') {\n    return function customFunctionFormatter(data, message) {\n      var modifiedMessage = Object.assign({}, message, { data: data });\n      var texts = customFormat(modifiedMessage, data);\n      return [].concat(texts);\n    };\n  }\n\n  return function (data) {\n    return [].concat(data);\n  };\n}\n\nfunction transform(message, transformers, initialData) {\n  return transformers.reduce(function (data, transformer) {\n    if (typeof transformer === 'function') {\n      return transformer(data, message);\n    }\n\n    return data;\n  }, initialData || message.data);\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-log/src/transform/index.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/transform/object.js":
/*!***********************************************************!*\
  !*** ./node_modules/electron-log/src/transform/object.js ***!
  \***********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar util = __webpack_require__(/*! util */ \"util\");\n\nmodule.exports = {\n  maxDepthFactory: maxDepthFactory,\n  serialize: serialize,\n  toJSON: toJSON,\n  toStringFactory: toStringFactory,\n};\n\n/**\n * @param {object} options?\n * @param {boolean} options.serializeMapAndSet?\n * @return {function}\n */\nfunction createSerializer(options) {\n  var seen = createWeakSet();\n\n  return function (key, value) {\n    if (typeof value === 'object' && value !== null) {\n      if (seen.has(value)) {\n        return undefined;\n      }\n\n      seen.add(value);\n    }\n\n    return serialize(key, value, options);\n  };\n}\n\n/**\n * @return {WeakSet<object>}\n */\nfunction createWeakSet() {\n  if (typeof WeakSet !== 'undefined') {\n    return new WeakSet();\n  }\n\n  var cache = [];\n  return {\n    add: function (value) { cache.push(value) },\n    has: function (value) { return cache.indexOf(value) !== -1 },\n  };\n}\n\nfunction maxDepth(data, depth) {\n  if (!data) {\n    return data;\n  }\n\n  if (depth < 1) {\n    if (isArray(data)) return '[array]';\n    if (typeof data === 'object' && data) return '[object]';\n\n    return data;\n  }\n\n  if (isArray(data)) {\n    return data.map(function (child) {\n      return maxDepth(child, depth - 1);\n    });\n  }\n\n  if (typeof data !== 'object') {\n    return data;\n  }\n\n  if (data && typeof data.toISOString === 'function') {\n    return data;\n  }\n\n  // noinspection PointlessBooleanExpressionJS\n  if (data === null) {\n    return null;\n  }\n\n  if (data instanceof Error) {\n    return data;\n  }\n\n  var newJson = {};\n  for (var i in data) {\n    if (!Object.prototype.hasOwnProperty.call(data, i)) continue;\n    newJson[i] = maxDepth(data[i], depth - 1);\n  }\n\n  return newJson;\n}\n\nfunction maxDepthFactory(depth) {\n  depth = depth || 6;\n\n  return function maxDepthFunction(data) {\n    return maxDepth(data, depth);\n  };\n}\n\n/**\n * @param {string} key\n * @param {any} value\n * @param {object} options?\n * @return {any}\n */\nfunction serialize(key, value, options) {\n  var serializeMapAndSet = !options || options.serializeMapAndSet !== false;\n\n  if (value instanceof Error) {\n    return value.stack;\n  }\n\n  if (!value) {\n    return value;\n  }\n\n  if (typeof value.toJSON === 'function') {\n    return value.toJSON();\n  }\n\n  if (typeof value === 'function') {\n    return '[function] ' + value.toString();\n  }\n\n  if (serializeMapAndSet && value instanceof Map && Object.fromEntries) {\n    return Object.fromEntries(value);\n  }\n\n  if (serializeMapAndSet && value instanceof Set && Array.from) {\n    return Array.from(value);\n  }\n\n  return value;\n}\n\nfunction toJSON(data) {\n  return JSON.parse(JSON.stringify(data, createSerializer()));\n}\n\nfunction toStringFactory(inspectOptions) {\n  return function toStringFunction(data) {\n    var simplifiedData = data.map(function (item) {\n      if (item === undefined) {\n        return undefined;\n      }\n\n      try {\n        var str = JSON.stringify(item, createSerializer(), '  ');\n        return str === undefined ? undefined : JSON.parse(str);\n      } catch (e) {\n        // There are some rare cases when an item can't be simplified.\n        // In that case, it's fine to pass it to util.format directly.\n        return item;\n      }\n    });\n\n    if (util.formatWithOptions) {\n      simplifiedData.unshift(inspectOptions || {});\n      return util.formatWithOptions.apply(util, simplifiedData);\n    }\n\n    return util.format.apply(util, simplifiedData);\n  };\n}\n\nfunction isArray(value) {\n  return Object.prototype.toString.call(value) === '[object Array]';\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-log/src/transform/object.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/transform/style.js":
/*!**********************************************************!*\
  !*** ./node_modules/electron-log/src/transform/style.js ***!
  \**********************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = {\n  applyAnsiStyles: applyAnsiStyles,\n  removeStyles: removeStyles,\n  transformStyles: transformStyles,\n};\n\nvar ANSI_COLORS = {\n  unset: '\\x1b[0m',\n  black: '\\x1b[30m',\n  red: '\\x1b[31m',\n  green: '\\x1b[32m',\n  yellow: '\\x1b[33m',\n  blue: '\\x1b[34m',\n  magenta: '\\x1b[35m',\n  cyan: '\\x1b[36m',\n  white: '\\x1b[37m',\n};\n\nfunction applyAnsiStyles(data) {\n  return transformStyles(data, styleToAnsi, resetAnsiStyle);\n}\n\nfunction styleToAnsi(style) {\n  var color = style.replace(/color:\\s*(\\w+).*/, '$1').toLowerCase();\n  return ANSI_COLORS[color] || '';\n}\n\nfunction resetAnsiStyle(string) {\n  return string + ANSI_COLORS.unset;\n}\n\nfunction removeStyles(data) {\n  return transformStyles(data, function () { return '' });\n}\n\nfunction transformStyles(data, onStyleFound, onStyleApplied) {\n  var foundStyles = {};\n\n  return data.reduce(function (result, item, index, array) {\n    if (foundStyles[index]) {\n      return result;\n    }\n\n    if (typeof item === 'string') {\n      var valueIndex = index;\n      var styleApplied = false;\n\n      item = item.replace(/%[1cdfiOos]/g, function (match) {\n        valueIndex += 1;\n\n        if (match !== '%c') {\n          return match;\n        }\n\n        var style = array[valueIndex];\n        if (typeof style === 'string') {\n          foundStyles[valueIndex] = true;\n          styleApplied = true;\n          return onStyleFound(style, item);\n        }\n\n        return match;\n      });\n\n      if (styleApplied && onStyleApplied) {\n        item = onStyleApplied(item);\n      }\n    }\n\n    result.push(item);\n    return result;\n  }, []);\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-log/src/transform/style.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/transform/template.js":
/*!*************************************************************!*\
  !*** ./node_modules/electron-log/src/transform/template.js ***!
  \*************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = {\n  concatFirstStringElements: concatFirstStringElements,\n  formatDate: formatDate,\n  formatTimeZone: formatTimeZone,\n  pad: pad,\n  padString: padString,\n  templateDate: templateDate,\n  templateVariables: templateVariables,\n  templateScopeFactory: templateScopeFactory,\n  templateText: templateText,\n};\n\n/**\n * The first argument of console.log may contain templates. In the library\n * the first element is a string related to transports.console.format. So\n * this function concatenates first two elements to make templates like %d\n * work\n * @param {*[]} data\n * @return {*[]}\n */\nfunction concatFirstStringElements(data) {\n  if (typeof data[0] !== 'string' || typeof data[1] !== 'string') {\n    return data;\n  }\n\n  if (data[0].match(/%[1cdfiOos]/)) {\n    return data;\n  }\n\n  data[1] = data[0] + ' ' + data[1];\n  data.shift();\n\n  return data;\n}\n\nfunction formatDate(template, date) {\n  return template\n    .replace('{y}', String(date.getFullYear()))\n    .replace('{m}', pad(date.getMonth() + 1))\n    .replace('{d}', pad(date.getDate()))\n    .replace('{h}', pad(date.getHours()))\n    .replace('{i}', pad(date.getMinutes()))\n    .replace('{s}', pad(date.getSeconds()))\n    .replace('{ms}', pad(date.getMilliseconds(), 3))\n    .replace('{z}', formatTimeZone(date.getTimezoneOffset()))\n    .replace('{iso}', date.toISOString());\n}\n\nfunction formatTimeZone(minutesOffset) {\n  var m = Math.abs(minutesOffset);\n  return (minutesOffset >= 0 ? '-' : '+')\n    + pad(Math.floor(m / 60)) + ':'\n    + pad(m % 60);\n}\n\nfunction pad(number, zeros) {\n  zeros = zeros || 2;\n  return (new Array(zeros + 1).join('0') + number).substr(-zeros, zeros);\n}\n\nfunction padString(value, length) {\n  length = Math.max(length, value.length);\n  var padValue = Array(length + 1).join(' ');\n  return (value + padValue).substring(0, length);\n}\n\nfunction templateDate(data, message) {\n  var template = data[0];\n  if (typeof template !== 'string') {\n    return data;\n  }\n\n  data[0] = formatDate(template, message.date);\n  return data;\n}\n\n/**\n * @param {{ labelLength: number, defaultLabel: string }} options\n */\nfunction templateScopeFactory(options) {\n  options = options || {};\n  var labelLength = options.labelLength || 0;\n\n  return function templateScope(data, message) {\n    var template = data[0];\n    var label = message.scope && message.scope.label;\n\n    if (!label) {\n      label = options.defaultLabel;\n    }\n\n    var scopeText;\n    if (label === '') {\n      scopeText = labelLength > 0 ? padString('', labelLength + 3) : '';\n    } else if (typeof label === 'string') {\n      scopeText = padString(' (' + label + ')', labelLength + 3);\n    } else {\n      scopeText = '';\n    }\n\n    data[0] = template.replace('{scope}', scopeText);\n    return data;\n  };\n}\n\nfunction templateVariables(data, message) {\n  var template = data[0];\n  var variables = message.variables;\n\n  if (typeof template !== 'string' || !message.variables) {\n    return data;\n  }\n\n  for (var i in variables) {\n    if (!Object.prototype.hasOwnProperty.call(variables, i)) continue;\n    template = template.replace('{' + i + '}', variables[i]);\n  }\n\n  // Add additional space to the end of {level}] template to align messages\n  template = template.replace('{level}]', padString(message.level + ']', 6));\n  template = template.replace('{level}', message.level);\n\n  data[0] = template;\n  return data;\n}\n\nfunction templateText(data) {\n  var template = data[0];\n  if (typeof template !== 'string') {\n    return data;\n  }\n\n  var textTplPosition = template.lastIndexOf('{text}');\n  if (textTplPosition === template.length - 6) {\n    data[0] = template.replace(/\\s?{text}/, '');\n    if (data[0] === '') {\n      data.shift();\n    }\n\n    return data;\n  }\n\n  var templatePieces = template.split('{text}');\n  var result = [];\n\n  if (templatePieces[0] !== '') {\n    result.push(templatePieces[0]);\n  }\n\n  result = result.concat(data.slice(1));\n\n  if (templatePieces[1] !== '') {\n    result.push(templatePieces[1]);\n  }\n\n  return result;\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-log/src/transform/template.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/transports/console.js":
/*!*************************************************************!*\
  !*** ./node_modules/electron-log/src/transports/console.js ***!
  \*************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/* eslint-disable no-multi-spaces, no-console */\n\nvar transform = __webpack_require__(/*! ../transform */ \"./node_modules/electron-log/src/transform/index.js\");\n\nvar consoleMethods = {\n  context: console,\n  error:   console.error,\n  warn:    console.warn,\n  info:    console.info,\n  verbose: console.verbose,\n  debug:   console.debug,\n  silly:   console.silly,\n  log:     console.log,\n};\n\nmodule.exports = consoleTransportFactory;\nmodule.exports.transformRenderer = transformRenderer;\nmodule.exports.transformMain = transformMain;\n\nvar separator = process.platform === 'win32' ? '>' : '';\nvar DEFAULT_FORMAT = {\n  browser: '%c{h}:{i}:{s}.{ms}{scope}%c ' + separator + ' {text}',\n  renderer: '{h}:{i}:{s}.{ms}{scope}  {text}',\n  worker: '{h}:{i}:{s}.{ms}{scope}  {text}',\n};\n\nfunction consoleTransportFactory(electronLog) {\n  transport.level  = 'silly';\n  transport.useStyles = process.env.FORCE_STYLES;\n  transport.format = DEFAULT_FORMAT[process.type] || DEFAULT_FORMAT.browser;\n\n  return transport;\n\n  function transport(message) {\n    var scopeOptions = electronLog.scope.getOptions();\n\n    var data;\n    if (process.type === 'renderer' || process.type === 'worker') {\n      data = transformRenderer(message, transport, scopeOptions);\n    } else {\n      data = transformMain(message, transport, scopeOptions);\n    }\n\n    consoleLog(message.level, data);\n  }\n}\n\nfunction transformRenderer(message, transport, scopeOptions) {\n  return transform.transform(message, [\n    transform.customFormatterFactory(transport.format, true, scopeOptions),\n  ]);\n}\n\nfunction transformMain(message, transport, scopeOptions) {\n  var useStyles = canUseStyles(transport.useStyles, message.level);\n\n  return transform.transform(message, [\n    addTemplateColorFactory(transport.format),\n    transform.customFormatterFactory(transport.format, false, scopeOptions),\n    useStyles ? transform.applyAnsiStyles : transform.removeStyles,\n    transform.concatFirstStringElements,\n    transform.maxDepthFactory(4),\n    transform.toJSON,\n  ]);\n}\n\nfunction addTemplateColorFactory(format) {\n  return function addTemplateColors(data, message) {\n    if (format !== DEFAULT_FORMAT.browser) {\n      return data;\n    }\n\n    return ['color:' + levelToStyle(message.level), 'color:unset'].concat(data);\n  };\n}\n\nfunction canUseStyles(useStyleValue, level) {\n  if (useStyleValue === true || useStyleValue === false) {\n    return useStyleValue;\n  }\n\n  var useStderr = level === 'error' || level === 'warn';\n  var stream = useStderr ? process.stderr : process.stdout;\n  return stream && stream.isTTY;\n}\n\nfunction consoleLog(level, args) {\n  var consoleMethod = consoleMethods[level] || consoleMethods.info;\n\n  if (process.type === 'renderer') {\n    setTimeout(consoleMethod.bind.apply(\n      consoleMethod,\n      [consoleMethod.context].concat(args)\n    ));\n    return;\n  }\n\n  consoleMethod.apply(consoleMethods.context, args);\n}\n\nfunction levelToStyle(level) {\n  switch (level) {\n    case 'error': return 'red';\n    case 'warn':  return 'yellow';\n    case 'info':  return 'cyan';\n    default:      return 'unset';\n  }\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-log/src/transports/console.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/transports/file/file.js":
/*!***************************************************************!*\
  !*** ./node_modules/electron-log/src/transports/file/file.js ***!
  \***************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar EventEmitter = __webpack_require__(/*! events */ \"events\");\nvar fs = __webpack_require__(/*! fs */ \"fs\");\nvar os = __webpack_require__(/*! os */ \"os\");\nvar path = __webpack_require__(/*! path */ \"path\");\nvar url = __webpack_require__(/*! url */ \"url\");\nvar util = __webpack_require__(/*! util */ \"util\");\n\nmodule.exports = {\n  File: File,\n  FileRegistry: FileRegistry,\n  NullFile: NullFile,\n};\n\n/**\n * File manipulations on filesystem\n * @class\n * @extends EventEmitter\n * @property {number} size\n *\n * @constructor\n * @param {string} filePath\n * @param {WriteOptions} [writeOptions]\n * @param {boolean} [writeAsync]\n */\nfunction File(filePath, writeOptions, writeAsync) {\n  EventEmitter.call(this);\n\n  /**\n   * @type {string}\n   * @readonly\n   */\n  this.path = filePath;\n\n  /**\n   * @type {number}\n   * @private\n   */\n  this.initialSize = undefined;\n\n  /**\n   * @type {number}\n   * @readonly\n   */\n  this.bytesWritten = 0;\n\n  /**\n   * @type {boolean}\n   * @private\n   */\n  this.writeAsync = Boolean(writeAsync);\n\n  /**\n   * @type {string[]}\n   * @private\n   */\n  this.asyncWriteQueue = [];\n\n  /**\n   * @type {boolean}\n   * @private\n   */\n  this.hasActiveAsyncWritting = false;\n\n  /**\n   * @type {WriteOptions}\n   * @private\n   */\n  this.writeOptions = writeOptions || {\n    flag: 'a',\n    mode: 438, // 0666\n    encoding: 'utf8',\n  };\n\n  Object.defineProperty(this, 'size', {\n    get: this.getSize.bind(this),\n  });\n}\n\nutil.inherits(File, EventEmitter);\n\nFile.prototype.clear = function () {\n  try {\n    fs.writeFileSync(this.path, '', {\n      mode: this.writeOptions.mode,\n      flag: 'w',\n    });\n    this.reset();\n    return true;\n  } catch (e) {\n    if (e.code === 'ENOENT') {\n      return true;\n    }\n\n    this.emit('error', e, this);\n    return false;\n  }\n};\n\nFile.prototype.crop = function (bytesAfter) {\n  try {\n    var content = readFileSyncFromEnd(this.path, bytesAfter || 4096);\n    this.clear();\n    this.writeLine('[log cropped]' + os.EOL + content);\n  } catch (e) {\n    this.emit(\n      'error',\n      new Error('Couldn\\'t crop file ' + this.path + '. ' + e.message),\n      this\n    );\n  }\n};\n\nFile.prototype.toString = function () {\n  return this.path;\n};\n\n/**\n * @package\n */\nFile.prototype.reset = function () {\n  this.initialSize = undefined;\n  this.bytesWritten = 0;\n};\n\n/**\n * @package\n */\nFile.prototype.writeLine = function (text) {\n  text += os.EOL;\n\n  if (this.writeAsync) {\n    this.asyncWriteQueue.push(text);\n    this.nextAsyncWrite();\n    return;\n  }\n\n  try {\n    fs.writeFileSync(this.path, text, this.writeOptions);\n    this.increaseBytesWrittenCounter(text);\n  } catch (e) {\n    this.emit(\n      'error',\n      new Error('Couldn\\'t write to ' + this.path + '. ' + e.message),\n      this\n    );\n  }\n};\n\n/**\n * @return {number}\n * @protected\n */\nFile.prototype.getSize = function () {\n  if (this.initialSize === undefined) {\n    try {\n      var stats = fs.statSync(this.path);\n      this.initialSize = stats.size;\n    } catch (e) {\n      this.initialSize = 0;\n    }\n  }\n\n  return this.initialSize + this.bytesWritten;\n};\n\n/**\n * @return {boolean}\n * @package\n */\nFile.prototype.isNull = function () {\n  return false;\n};\n\n/**\n * @private\n */\nFile.prototype.increaseBytesWrittenCounter = function (text) {\n  this.bytesWritten += Buffer.byteLength(text, this.writeOptions.encoding);\n};\n\n/**\n * @private\n */\nFile.prototype.nextAsyncWrite = function () {\n  var file = this;\n\n  if (this.hasActiveAsyncWritting || this.asyncWriteQueue.length < 1) {\n    return;\n  }\n\n  var text = this.asyncWriteQueue.shift();\n  this.hasActiveAsyncWritting = true;\n\n  fs.writeFile(this.path, text, this.writeOptions, function (e) {\n    file.hasActiveAsyncWritting = false;\n\n    if (e) {\n      file.emit(\n        'error',\n        new Error('Couldn\\'t write to ' + file.path + '. ' + e.message),\n        this\n      );\n    } else {\n      file.increaseBytesWrittenCounter(text);\n    }\n\n    file.nextAsyncWrite();\n  });\n};\n\n/**\n * File manipulations on filesystem\n * @class\n * @property {number} size\n *\n * @constructor\n * @param {string} filePath\n */\nfunction NullFile(filePath) {\n  File.call(this, filePath);\n}\n\nutil.inherits(NullFile, File);\n\nNullFile.prototype.clear = function () {};\nNullFile.prototype.crop = function () {};\nNullFile.prototype.writeLine = function () {};\nNullFile.prototype.getSize = function () { return 0 };\nNullFile.prototype.isNull = function () { return true };\n\n/**\n * Collection, key is a file path, value is a File instance\n * @class\n *\n * @constructor\n */\nfunction FileRegistry() {\n  EventEmitter.call(this);\n  this.store = {};\n\n  this.emitError = this.emitError.bind(this);\n}\n\nutil.inherits(FileRegistry, EventEmitter);\n\n/**\n * Provide a File object corresponding to the filePath\n * @param {string} filePath\n * @param {WriteOptions} [writeOptions]\n * @param {boolean} [async]\n * @return {File}\n */\nFileRegistry.prototype.provide = function (filePath, writeOptions, async) {\n  var file;\n  try {\n    filePath = path.resolve(filePath);\n\n    if (this.store[filePath]) {\n      return this.store[filePath];\n    }\n\n    file = this.createFile(filePath, writeOptions, Boolean(async));\n  } catch (e) {\n    file = new NullFile(filePath);\n    this.emitError(e, file);\n  }\n\n  file.on('error', this.emitError);\n  this.store[filePath] = file;\n  return file;\n};\n\n/**\n * @param {string} filePath\n * @param {WriteOptions} writeOptions\n * @param {boolean} async\n * @return {File}\n * @private\n */\nFileRegistry.prototype.createFile = function (filePath, writeOptions, async) {\n  this.testFileWriting(filePath);\n  return new File(filePath, writeOptions, async);\n};\n\n/**\n * @param {Error} error\n * @param {File} file\n * @private\n */\nFileRegistry.prototype.emitError = function (error, file) {\n  this.emit('error', error, file);\n};\n\n/**\n * @param {string} filePath\n * @private\n */\nFileRegistry.prototype.testFileWriting = function (filePath) {\n  mkDir(path.dirname(filePath));\n  fs.writeFileSync(filePath, '', { flag: 'a' });\n};\n\nfunction mkDir(dirPath) {\n  var isNode1012 = Boolean(url.fileURLToPath);\n  if (isNode1012) {\n    fs.mkdirSync(dirPath, { recursive: true });\n    return true;\n  }\n\n  try {\n    fs.mkdirSync(dirPath);\n    return true;\n  } catch (error) {\n    if (error.code === 'ENOENT') {\n      return mkDir(path.dirname(dirPath)) && mkDir(dirPath);\n    }\n\n    // eslint-disable-next-line no-useless-catch\n    try {\n      if (fs.statSync(dirPath).isDirectory()) {\n        return true;\n      }\n\n      // noinspection ExceptionCaughtLocallyJS\n      throw error;\n    } catch (e) {\n      throw e;\n    }\n  }\n}\n\nfunction readFileSyncFromEnd(filePath, bytesCount) {\n  var buffer = Buffer.alloc(bytesCount);\n  var stats = fs.statSync(filePath);\n\n  var readLength = Math.min(stats.size, bytesCount);\n  var offset = Math.max(0, stats.size - bytesCount);\n\n  var fd = fs.openSync(filePath, 'r');\n  var totalBytes = fs.readSync(fd, buffer, 0, readLength, offset);\n  fs.closeSync(fd);\n\n  return buffer.toString('utf8', 0, totalBytes);\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-log/src/transports/file/file.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/transports/file/index.js":
/*!****************************************************************!*\
  !*** ./node_modules/electron-log/src/transports/file/index.js ***!
  \****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar fs = __webpack_require__(/*! fs */ \"fs\");\nvar path = __webpack_require__(/*! path */ \"path\");\nvar os = __webpack_require__(/*! os */ \"os\");\nvar util = __webpack_require__(/*! util */ \"util\");\nvar transform = __webpack_require__(/*! ../../transform */ \"./node_modules/electron-log/src/transform/index.js\");\nvar FileRegistry = (__webpack_require__(/*! ./file */ \"./node_modules/electron-log/src/transports/file/file.js\").FileRegistry);\nvar variables = __webpack_require__(/*! ./variables */ \"./node_modules/electron-log/src/transports/file/variables.js\");\n\nmodule.exports = fileTransportFactory;\n\n// Shared between multiple file transport instances\nvar globalRegistry = new FileRegistry();\n\nfunction fileTransportFactory(electronLog, customRegistry) {\n  var pathVariables = variables.getPathVariables(process.platform);\n\n  var registry = customRegistry || globalRegistry;\n  if (registry.listenerCount('error') < 1) {\n    registry.on('error', function (e, file) {\n      logConsole('Can\\'t write to ' + file, e);\n    });\n  }\n\n  /* eslint-disable no-multi-spaces */\n  transport.archiveLog   = archiveLog;\n  transport.depth        = 5;\n  transport.fileName     = getDefaultFileName();\n  transport\n    .format = '[{y}-{m}-{d} {h}:{i}:{s}.{ms}] [{level}]{scope} {text}';\n  transport.getFile      = getFile;\n  transport.level        = 'silly';\n  transport.maxSize      = 1024 * 1024;\n  transport.readAllLogs  = readAllLogs;\n  transport.resolvePath  = resolvePath;\n  transport.sync         = true;\n  transport.writeOptions = {\n    flag: 'a',\n    mode: 438, // 0666\n    encoding: 'utf8',\n  };\n  transport.inspectOptions = {};\n\n  initDeprecated();\n\n  return transport;\n\n  function transport(message) {\n    var file = getFile(message);\n\n    var needLogRotation = transport.maxSize > 0\n      && file.size > transport.maxSize;\n\n    if (needLogRotation) {\n      transport.archiveLog(file);\n      file.reset();\n    }\n\n    var scopeOptions = electronLog.scope.getOptions();\n    var inspectOptions = Object.assign(\n      { depth: transport.depth },\n      transport.inspectOptions\n    );\n    var content = transform.transform(message, [\n      transform.removeStyles,\n      transform.customFormatterFactory(transport.format, false, scopeOptions),\n      transform.concatFirstStringElements,\n      transform.toStringFactory(inspectOptions),\n    ]);\n\n    file.writeLine(content);\n  }\n\n  function archiveLog(file) {\n    var oldPath = file.toString();\n    var inf = path.parse(oldPath);\n    try {\n      fs.renameSync(oldPath, path.join(inf.dir, inf.name + '.old' + inf.ext));\n    } catch (e) {\n      logConsole('Could not rotate log', e);\n      var quarterOfMaxSize = Math.round(transport.maxSize / 4);\n      file.crop(Math.min(quarterOfMaxSize, 256 * 1024));\n    }\n  }\n\n  function logConsole(message, error) {\n    var data = ['electron-log.transports.file: ' + message];\n\n    if (error) {\n      data.push(error);\n    }\n\n    electronLog.transports.console({\n      data: data,\n      date: new Date(),\n      level: 'warn',\n    });\n  }\n\n  function getFile(msg) {\n    var vars = Object.assign({}, pathVariables, {\n      fileName: transport.fileName,\n    });\n\n    var filePath = transport.resolvePath(vars, msg);\n    return registry.provide(filePath, transport.writeOptions, !transport.sync);\n  }\n\n  /**\n   * @param {PathVariables} vars\n   */\n  function resolvePath(vars) {\n    return path.join(vars.libraryDefaultDir, vars.fileName);\n  }\n\n  function readAllLogs(options) {\n    var fileFilter = options && typeof options.fileFilter === 'function'\n      ? options.fileFilter\n      : function (fileName) { return fileName.endsWith('.log') };\n\n    var vars = Object.assign({}, pathVariables, {\n      fileName: transport.fileName,\n    });\n    var logsPath = path.dirname(transport.resolvePath(vars));\n\n    return fs.readdirSync(logsPath)\n      .map(function (fileName) { return path.join(logsPath, fileName) })\n      .filter(fileFilter)\n      .map(function (logPath) {\n        try {\n          return {\n            path: logPath,\n            lines: fs.readFileSync(logPath, 'utf8').split(os.EOL),\n          };\n        } catch (e) {\n          return null;\n        }\n      })\n      .filter(Boolean);\n  }\n\n  function initDeprecated() {\n    var isDeprecatedText = ' is deprecated and will be removed in v5.';\n    var isDeprecatedProp = ' property' + isDeprecatedText;\n\n    Object.defineProperties(transport, {\n      bytesWritten: {\n        get: util.deprecate(getBytesWritten, 'bytesWritten' + isDeprecatedProp),\n      },\n\n      file: {\n        get: util.deprecate(getLogFile, 'file' + isDeprecatedProp),\n        set: util.deprecate(setLogFile, 'file' + isDeprecatedProp),\n      },\n\n      fileSize: {\n        get: util.deprecate(getFileSize, 'file' + isDeprecatedProp),\n      },\n    });\n\n    transport.clear = util.deprecate(clear, 'clear()' + isDeprecatedText);\n    transport.findLogPath = util.deprecate(\n      getLogFile,\n      'findLogPath()' + isDeprecatedText\n    );\n    transport.init = util.deprecate(init, 'init()' + isDeprecatedText);\n\n    function getBytesWritten() {\n      return getFile().bytesWritten;\n    }\n\n    function getLogFile() {\n      return getFile().path;\n    }\n\n    function setLogFile(filePath) {\n      transport.resolvePath = function () {\n        return filePath;\n      };\n    }\n\n    function getFileSize() {\n      return getFile().size;\n    }\n\n    function clear() {\n      getFile().clear();\n    }\n\n    function init() {}\n  }\n}\n\nfunction getDefaultFileName() {\n  switch (process.type) {\n    case 'renderer': return 'renderer.log';\n    case 'worker': return 'worker.log';\n    default: return 'main.log';\n  }\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-log/src/transports/file/index.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/transports/file/packageJson.js":
/*!**********************************************************************!*\
  !*** ./node_modules/electron-log/src/transports/file/packageJson.js ***!
  \**********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/* eslint-disable consistent-return */\n\nvar fs = __webpack_require__(/*! fs */ \"fs\");\nvar path = __webpack_require__(/*! path */ \"path\");\n\nmodule.exports = {\n  readPackageJson: readPackageJson,\n  tryReadJsonAt: tryReadJsonAt,\n};\n\n/**\n * @return {{ name?: string, version?: string}}\n */\nfunction readPackageJson() {\n  return tryReadJsonAt(__webpack_require__.c[__webpack_require__.s] && __webpack_require__.c[__webpack_require__.s].filename)\n    || tryReadJsonAt(extractPathFromArgs())\n    || tryReadJsonAt(process.resourcesPath, 'app.asar')\n    || tryReadJsonAt(process.resourcesPath, 'app')\n    || tryReadJsonAt(process.cwd())\n    || { name: null, version: null };\n}\n\n/**\n * @param {...string} searchPath\n * @return {{ name?: string, version?: string } | null}\n */\nfunction tryReadJsonAt(searchPath) {\n  if (!searchPath) {\n    return null;\n  }\n\n  try {\n    searchPath = path.join.apply(path, arguments);\n    var fileName = findUp('package.json', searchPath);\n    if (!fileName) {\n      return null;\n    }\n\n    var json = JSON.parse(fs.readFileSync(fileName, 'utf8'));\n    var name = json.productName || json.name;\n    if (!name || name.toLowerCase() === 'electron') {\n      return null;\n    }\n\n    if (json.productName || json.name) {\n      return {\n        name: name,\n        version: json.version,\n      };\n    }\n  } catch (e) {\n    return null;\n  }\n}\n\n/**\n * @param {string} fileName\n * @param {string} [cwd]\n * @return {string | null}\n */\nfunction findUp(fileName, cwd) {\n  var currentPath = cwd;\n  // eslint-disable-next-line no-constant-condition\n  while (true) {\n    var parsedPath = path.parse(currentPath);\n    var root = parsedPath.root;\n    var dir = parsedPath.dir;\n\n    if (fs.existsSync(path.join(currentPath, fileName))) {\n      return path.resolve(path.join(currentPath, fileName));\n    }\n\n    if (currentPath === root) {\n      return null;\n    }\n\n    currentPath = dir;\n  }\n}\n\n/**\n * Get app path from --user-data-dir cmd arg, passed to a renderer process\n * @return {string|null}\n */\nfunction extractPathFromArgs() {\n  var matchedArgs = process.argv.filter(function (arg) {\n    return arg.indexOf('--user-data-dir=') === 0;\n  });\n\n  if (matchedArgs.length === 0 || typeof matchedArgs[0] !== 'string') {\n    return null;\n  }\n\n  var userDataDir = matchedArgs[0];\n  return userDataDir.replace('--user-data-dir=', '');\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-log/src/transports/file/packageJson.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/transports/file/variables.js":
/*!********************************************************************!*\
  !*** ./node_modules/electron-log/src/transports/file/variables.js ***!
  \********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar os = __webpack_require__(/*! os */ \"os\");\nvar path = __webpack_require__(/*! path */ \"path\");\nvar electronApi = __webpack_require__(/*! ../../electronApi */ \"./node_modules/electron-log/src/electronApi.js\");\nvar packageJson = __webpack_require__(/*! ./packageJson */ \"./node_modules/electron-log/src/transports/file/packageJson.js\");\n\nmodule.exports = {\n  getAppData: getAppData,\n  getLibraryDefaultDir: getLibraryDefaultDir,\n  getLibraryTemplate: getLibraryTemplate,\n  getNameAndVersion: getNameAndVersion,\n  getPathVariables: getPathVariables,\n  getUserData: getUserData,\n};\n\nfunction getAppData(platform) {\n  var appData = electronApi.getPath('appData');\n  if (appData) {\n    return appData;\n  }\n\n  var home = getHome();\n\n  switch (platform) {\n    case 'darwin': {\n      return path.join(home, 'Library/Application Support');\n    }\n\n    case 'win32': {\n      return process.env.APPDATA || path.join(home, 'AppData/Roaming');\n    }\n\n    default: {\n      return process.env.XDG_CONFIG_HOME || path.join(home, '.config');\n    }\n  }\n}\n\nfunction getHome() {\n  return os.homedir ? os.homedir() : process.env.HOME;\n}\n\nfunction getLibraryDefaultDir(platform, appName) {\n  if (platform === 'darwin') {\n    return path.join(getHome(), 'Library/Logs', appName);\n  }\n\n  return path.join(getUserData(platform, appName), 'logs');\n}\n\nfunction getLibraryTemplate(platform) {\n  if (platform === 'darwin') {\n    return path.join(getHome(), 'Library/Logs', '{appName}');\n  }\n\n  return path.join(getAppData(platform), '{appName}', 'logs');\n}\n\nfunction getNameAndVersion() {\n  var name = electronApi.getName() || '';\n  var version = electronApi.getVersion();\n\n  if (name.toLowerCase() === 'electron') {\n    name = '';\n    version = '';\n  }\n\n  if (name && version) {\n    return { name: name, version: version };\n  }\n\n  var packageValues = packageJson.readPackageJson();\n  if (!name) {\n    name = packageValues.name;\n  }\n\n  if (!version) {\n    version = packageValues.version;\n  }\n\n  if (!name) {\n    // Fallback, otherwise file transport can't be initialized\n    name = 'Electron';\n  }\n\n  return { name: name, version: version };\n}\n\n/**\n * @param {string} platform\n * @return {PathVariables}\n */\nfunction getPathVariables(platform) {\n  var nameAndVersion = getNameAndVersion();\n  var appName = nameAndVersion.name;\n  var appVersion = nameAndVersion.version;\n\n  return {\n    appData: getAppData(platform),\n    appName: appName,\n    appVersion: appVersion,\n    electronDefaultDir: electronApi.getPath('logs'),\n    home: getHome(),\n    libraryDefaultDir: getLibraryDefaultDir(platform, appName),\n    libraryTemplate: getLibraryTemplate(platform),\n    temp: electronApi.getPath('temp') || os.tmpdir(),\n    userData: getUserData(platform, appName),\n  };\n}\n\nfunction getUserData(platform, appName) {\n  if (electronApi.getName() !== appName) {\n    return path.join(getAppData(platform), appName);\n  }\n\n  return electronApi.getPath('userData')\n    || path.join(getAppData(platform), appName);\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-log/src/transports/file/variables.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/transports/ipc.js":
/*!*********************************************************!*\
  !*** ./node_modules/electron-log/src/transports/ipc.js ***!
  \*********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar transform = __webpack_require__(/*! ../transform */ \"./node_modules/electron-log/src/transform/index.js\");\nvar electronApi = __webpack_require__(/*! ../electronApi */ \"./node_modules/electron-log/src/electronApi.js\");\nvar log = __webpack_require__(/*! ../log.js */ \"./node_modules/electron-log/src/log.js\");\n\nmodule.exports = ipcTransportFactory;\n\nfunction ipcTransportFactory(electronLog) {\n  transport.eventId = '__ELECTRON_LOG_IPC_' + electronLog.logId + '__';\n  transport.level = electronLog.isDev ? 'silly' : false;\n\n  // Prevent problems when there are multiple instances after webpack\n  if (electronApi.isIpcChannelListened(transport.eventId)) {\n    return function () {};\n  }\n\n  electronApi.onIpc(transport.eventId, function (_, message) {\n    message.date = new Date(message.date);\n\n    log.runTransport(\n      electronLog.transports.console,\n      message,\n      electronLog\n    );\n  });\n\n  electronApi.loadRemoteModule('electron-log');\n\n  return electronApi.isElectron() ? transport : null;\n\n  function transport(message) {\n    var ipcMessage = Object.assign({}, message, {\n      data: transform.transform(message, [\n        transform.toJSON,\n        transform.maxDepthFactory(3),\n      ]),\n    });\n\n    electronApi.sendIpc(transport.eventId, ipcMessage);\n  }\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-log/src/transports/ipc.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/transports/remote.js":
/*!************************************************************!*\
  !*** ./node_modules/electron-log/src/transports/remote.js ***!
  \************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar http = __webpack_require__(/*! http */ \"http\");\nvar https = __webpack_require__(/*! https */ \"https\");\nvar url = __webpack_require__(/*! url */ \"url\");\nvar transform = __webpack_require__(/*! ../transform */ \"./node_modules/electron-log/src/transform/index.js\");\n\nmodule.exports = remoteTransportFactory;\n\nfunction remoteTransportFactory(electronLog) {\n  transport.client = { name: 'electron-application' };\n  transport.depth = 6;\n  transport.level = false;\n  transport.requestOptions = {};\n  transport.url = null;\n  transport.onError = null;\n  transport.transformBody = function (body) { return JSON.stringify(body) };\n\n  return transport;\n\n  function transport(message) {\n    if (!transport.url) return;\n\n    var body = transport.transformBody({\n      client: transport.client,\n      data: transform.transform(message, [\n        transform.removeStyles,\n        transform.toJSON,\n        transform.maxDepthFactory(transport.depth + 1),\n      ]),\n      date: message.date.getTime(),\n      level: message.level,\n      variables: message.variables,\n    });\n\n    var request = post(\n      transport.url,\n      transport.requestOptions,\n      Buffer.from(body, 'utf8')\n    );\n\n    request.on('error', transport.onError || onError);\n\n    function onError(error) {\n      electronLog.logMessageWithTransports(\n        {\n          data: [\n            'electron-log.transports.remote:'\n            + ' cannot send HTTP request to ' + transport.url,\n            error,\n          ],\n          level: 'warn',\n        },\n        [\n          electronLog.transports.console,\n          electronLog.transports.ipc,\n          electronLog.transports.file,\n        ]\n      );\n    }\n  }\n}\n\nfunction post(serverUrl, requestOptions, body) {\n  var urlObject = url.parse(serverUrl);\n  var httpTransport = urlObject.protocol === 'https:' ? https : http;\n\n  var options = {\n    hostname: urlObject.hostname,\n    port:     urlObject.port,\n    path:     urlObject.path,\n    method:   'POST',\n    headers:  {},\n  };\n\n  Object.assign(options, requestOptions);\n\n  options.headers['Content-Length'] = body.length;\n  if (!options.headers['Content-Type']) {\n    options.headers['Content-Type'] = 'application/json';\n  }\n\n  var request = httpTransport.request(options);\n  request.write(body);\n  request.end();\n\n  return request;\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-log/src/transports/remote.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/copy/copy-sync.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/copy/copy-sync.js ***!
  \***********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst mkdirsSync = (__webpack_require__(/*! ../mkdirs */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/mkdirs/index.js\").mkdirsSync)\nconst utimesMillisSync = (__webpack_require__(/*! ../util/utimes */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/util/utimes.js\").utimesMillisSync)\nconst stat = __webpack_require__(/*! ../util/stat */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/util/stat.js\")\n\nfunction copySync (src, dest, opts) {\n  if (typeof opts === 'function') {\n    opts = { filter: opts }\n  }\n\n  opts = opts || {}\n  opts.clobber = 'clobber' in opts ? !!opts.clobber : true // default to true for now\n  opts.overwrite = 'overwrite' in opts ? !!opts.overwrite : opts.clobber // overwrite falls back to clobber\n\n  // Warn about using preserveTimestamps on 32-bit node\n  if (opts.preserveTimestamps && process.arch === 'ia32') {\n    process.emitWarning(\n      'Using the preserveTimestamps option in 32-bit node is not recommended;\\n\\n' +\n      '\\tsee https://github.com/jprichardson/node-fs-extra/issues/269',\n      'Warning', 'fs-extra-WARN0002'\n    )\n  }\n\n  const { srcStat, destStat } = stat.checkPathsSync(src, dest, 'copy', opts)\n  stat.checkParentPathsSync(src, srcStat, dest, 'copy')\n  return handleFilterAndCopy(destStat, src, dest, opts)\n}\n\nfunction handleFilterAndCopy (destStat, src, dest, opts) {\n  if (opts.filter && !opts.filter(src, dest)) return\n  const destParent = path.dirname(dest)\n  if (!fs.existsSync(destParent)) mkdirsSync(destParent)\n  return getStats(destStat, src, dest, opts)\n}\n\nfunction startCopy (destStat, src, dest, opts) {\n  if (opts.filter && !opts.filter(src, dest)) return\n  return getStats(destStat, src, dest, opts)\n}\n\nfunction getStats (destStat, src, dest, opts) {\n  const statSync = opts.dereference ? fs.statSync : fs.lstatSync\n  const srcStat = statSync(src)\n\n  if (srcStat.isDirectory()) return onDir(srcStat, destStat, src, dest, opts)\n  else if (srcStat.isFile() ||\n           srcStat.isCharacterDevice() ||\n           srcStat.isBlockDevice()) return onFile(srcStat, destStat, src, dest, opts)\n  else if (srcStat.isSymbolicLink()) return onLink(destStat, src, dest, opts)\n  else if (srcStat.isSocket()) throw new Error(`Cannot copy a socket file: ${src}`)\n  else if (srcStat.isFIFO()) throw new Error(`Cannot copy a FIFO pipe: ${src}`)\n  throw new Error(`Unknown file: ${src}`)\n}\n\nfunction onFile (srcStat, destStat, src, dest, opts) {\n  if (!destStat) return copyFile(srcStat, src, dest, opts)\n  return mayCopyFile(srcStat, src, dest, opts)\n}\n\nfunction mayCopyFile (srcStat, src, dest, opts) {\n  if (opts.overwrite) {\n    fs.unlinkSync(dest)\n    return copyFile(srcStat, src, dest, opts)\n  } else if (opts.errorOnExist) {\n    throw new Error(`'${dest}' already exists`)\n  }\n}\n\nfunction copyFile (srcStat, src, dest, opts) {\n  fs.copyFileSync(src, dest)\n  if (opts.preserveTimestamps) handleTimestamps(srcStat.mode, src, dest)\n  return setDestMode(dest, srcStat.mode)\n}\n\nfunction handleTimestamps (srcMode, src, dest) {\n  // Make sure the file is writable before setting the timestamp\n  // otherwise open fails with EPERM when invoked with 'r+'\n  // (through utimes call)\n  if (fileIsNotWritable(srcMode)) makeFileWritable(dest, srcMode)\n  return setDestTimestamps(src, dest)\n}\n\nfunction fileIsNotWritable (srcMode) {\n  return (srcMode & 0o200) === 0\n}\n\nfunction makeFileWritable (dest, srcMode) {\n  return setDestMode(dest, srcMode | 0o200)\n}\n\nfunction setDestMode (dest, srcMode) {\n  return fs.chmodSync(dest, srcMode)\n}\n\nfunction setDestTimestamps (src, dest) {\n  // The initial srcStat.atime cannot be trusted\n  // because it is modified by the read(2) system call\n  // (See https://nodejs.org/api/fs.html#fs_stat_time_values)\n  const updatedSrcStat = fs.statSync(src)\n  return utimesMillisSync(dest, updatedSrcStat.atime, updatedSrcStat.mtime)\n}\n\nfunction onDir (srcStat, destStat, src, dest, opts) {\n  if (!destStat) return mkDirAndCopy(srcStat.mode, src, dest, opts)\n  return copyDir(src, dest, opts)\n}\n\nfunction mkDirAndCopy (srcMode, src, dest, opts) {\n  fs.mkdirSync(dest)\n  copyDir(src, dest, opts)\n  return setDestMode(dest, srcMode)\n}\n\nfunction copyDir (src, dest, opts) {\n  fs.readdirSync(src).forEach(item => copyDirItem(item, src, dest, opts))\n}\n\nfunction copyDirItem (item, src, dest, opts) {\n  const srcItem = path.join(src, item)\n  const destItem = path.join(dest, item)\n  const { destStat } = stat.checkPathsSync(srcItem, destItem, 'copy', opts)\n  return startCopy(destStat, srcItem, destItem, opts)\n}\n\nfunction onLink (destStat, src, dest, opts) {\n  let resolvedSrc = fs.readlinkSync(src)\n  if (opts.dereference) {\n    resolvedSrc = path.resolve(process.cwd(), resolvedSrc)\n  }\n\n  if (!destStat) {\n    return fs.symlinkSync(resolvedSrc, dest)\n  } else {\n    let resolvedDest\n    try {\n      resolvedDest = fs.readlinkSync(dest)\n    } catch (err) {\n      // dest exists and is a regular file or directory,\n      // Windows may throw UNKNOWN error. If dest already exists,\n      // fs throws error anyway, so no need to guard against it here.\n      if (err.code === 'EINVAL' || err.code === 'UNKNOWN') return fs.symlinkSync(resolvedSrc, dest)\n      throw err\n    }\n    if (opts.dereference) {\n      resolvedDest = path.resolve(process.cwd(), resolvedDest)\n    }\n    if (stat.isSrcSubdir(resolvedSrc, resolvedDest)) {\n      throw new Error(`Cannot copy '${resolvedSrc}' to a subdirectory of itself, '${resolvedDest}'.`)\n    }\n\n    // prevent copy if src is a subdir of dest since unlinking\n    // dest in this case would result in removing src contents\n    // and therefore a broken symlink would be created.\n    if (fs.statSync(dest).isDirectory() && stat.isSrcSubdir(resolvedDest, resolvedSrc)) {\n      throw new Error(`Cannot overwrite '${resolvedDest}' with '${resolvedSrc}'.`)\n    }\n    return copyLink(resolvedSrc, dest)\n  }\n}\n\nfunction copyLink (resolvedSrc, dest) {\n  fs.unlinkSync(dest)\n  return fs.symlinkSync(resolvedSrc, dest)\n}\n\nmodule.exports = copySync\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/copy/copy-sync.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/copy/copy.js":
/*!******************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/copy/copy.js ***!
  \******************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst mkdirs = (__webpack_require__(/*! ../mkdirs */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/mkdirs/index.js\").mkdirs)\nconst pathExists = (__webpack_require__(/*! ../path-exists */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/path-exists/index.js\").pathExists)\nconst utimesMillis = (__webpack_require__(/*! ../util/utimes */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/util/utimes.js\").utimesMillis)\nconst stat = __webpack_require__(/*! ../util/stat */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/util/stat.js\")\n\nfunction copy (src, dest, opts, cb) {\n  if (typeof opts === 'function' && !cb) {\n    cb = opts\n    opts = {}\n  } else if (typeof opts === 'function') {\n    opts = { filter: opts }\n  }\n\n  cb = cb || function () {}\n  opts = opts || {}\n\n  opts.clobber = 'clobber' in opts ? !!opts.clobber : true // default to true for now\n  opts.overwrite = 'overwrite' in opts ? !!opts.overwrite : opts.clobber // overwrite falls back to clobber\n\n  // Warn about using preserveTimestamps on 32-bit node\n  if (opts.preserveTimestamps && process.arch === 'ia32') {\n    process.emitWarning(\n      'Using the preserveTimestamps option in 32-bit node is not recommended;\\n\\n' +\n      '\\tsee https://github.com/jprichardson/node-fs-extra/issues/269',\n      'Warning', 'fs-extra-WARN0001'\n    )\n  }\n\n  stat.checkPaths(src, dest, 'copy', opts, (err, stats) => {\n    if (err) return cb(err)\n    const { srcStat, destStat } = stats\n    stat.checkParentPaths(src, srcStat, dest, 'copy', err => {\n      if (err) return cb(err)\n      if (opts.filter) return handleFilter(checkParentDir, destStat, src, dest, opts, cb)\n      return checkParentDir(destStat, src, dest, opts, cb)\n    })\n  })\n}\n\nfunction checkParentDir (destStat, src, dest, opts, cb) {\n  const destParent = path.dirname(dest)\n  pathExists(destParent, (err, dirExists) => {\n    if (err) return cb(err)\n    if (dirExists) return getStats(destStat, src, dest, opts, cb)\n    mkdirs(destParent, err => {\n      if (err) return cb(err)\n      return getStats(destStat, src, dest, opts, cb)\n    })\n  })\n}\n\nfunction handleFilter (onInclude, destStat, src, dest, opts, cb) {\n  Promise.resolve(opts.filter(src, dest)).then(include => {\n    if (include) return onInclude(destStat, src, dest, opts, cb)\n    return cb()\n  }, error => cb(error))\n}\n\nfunction startCopy (destStat, src, dest, opts, cb) {\n  if (opts.filter) return handleFilter(getStats, destStat, src, dest, opts, cb)\n  return getStats(destStat, src, dest, opts, cb)\n}\n\nfunction getStats (destStat, src, dest, opts, cb) {\n  const stat = opts.dereference ? fs.stat : fs.lstat\n  stat(src, (err, srcStat) => {\n    if (err) return cb(err)\n\n    if (srcStat.isDirectory()) return onDir(srcStat, destStat, src, dest, opts, cb)\n    else if (srcStat.isFile() ||\n             srcStat.isCharacterDevice() ||\n             srcStat.isBlockDevice()) return onFile(srcStat, destStat, src, dest, opts, cb)\n    else if (srcStat.isSymbolicLink()) return onLink(destStat, src, dest, opts, cb)\n    else if (srcStat.isSocket()) return cb(new Error(`Cannot copy a socket file: ${src}`))\n    else if (srcStat.isFIFO()) return cb(new Error(`Cannot copy a FIFO pipe: ${src}`))\n    return cb(new Error(`Unknown file: ${src}`))\n  })\n}\n\nfunction onFile (srcStat, destStat, src, dest, opts, cb) {\n  if (!destStat) return copyFile(srcStat, src, dest, opts, cb)\n  return mayCopyFile(srcStat, src, dest, opts, cb)\n}\n\nfunction mayCopyFile (srcStat, src, dest, opts, cb) {\n  if (opts.overwrite) {\n    fs.unlink(dest, err => {\n      if (err) return cb(err)\n      return copyFile(srcStat, src, dest, opts, cb)\n    })\n  } else if (opts.errorOnExist) {\n    return cb(new Error(`'${dest}' already exists`))\n  } else return cb()\n}\n\nfunction copyFile (srcStat, src, dest, opts, cb) {\n  fs.copyFile(src, dest, err => {\n    if (err) return cb(err)\n    if (opts.preserveTimestamps) return handleTimestampsAndMode(srcStat.mode, src, dest, cb)\n    return setDestMode(dest, srcStat.mode, cb)\n  })\n}\n\nfunction handleTimestampsAndMode (srcMode, src, dest, cb) {\n  // Make sure the file is writable before setting the timestamp\n  // otherwise open fails with EPERM when invoked with 'r+'\n  // (through utimes call)\n  if (fileIsNotWritable(srcMode)) {\n    return makeFileWritable(dest, srcMode, err => {\n      if (err) return cb(err)\n      return setDestTimestampsAndMode(srcMode, src, dest, cb)\n    })\n  }\n  return setDestTimestampsAndMode(srcMode, src, dest, cb)\n}\n\nfunction fileIsNotWritable (srcMode) {\n  return (srcMode & 0o200) === 0\n}\n\nfunction makeFileWritable (dest, srcMode, cb) {\n  return setDestMode(dest, srcMode | 0o200, cb)\n}\n\nfunction setDestTimestampsAndMode (srcMode, src, dest, cb) {\n  setDestTimestamps(src, dest, err => {\n    if (err) return cb(err)\n    return setDestMode(dest, srcMode, cb)\n  })\n}\n\nfunction setDestMode (dest, srcMode, cb) {\n  return fs.chmod(dest, srcMode, cb)\n}\n\nfunction setDestTimestamps (src, dest, cb) {\n  // The initial srcStat.atime cannot be trusted\n  // because it is modified by the read(2) system call\n  // (See https://nodejs.org/api/fs.html#fs_stat_time_values)\n  fs.stat(src, (err, updatedSrcStat) => {\n    if (err) return cb(err)\n    return utimesMillis(dest, updatedSrcStat.atime, updatedSrcStat.mtime, cb)\n  })\n}\n\nfunction onDir (srcStat, destStat, src, dest, opts, cb) {\n  if (!destStat) return mkDirAndCopy(srcStat.mode, src, dest, opts, cb)\n  return copyDir(src, dest, opts, cb)\n}\n\nfunction mkDirAndCopy (srcMode, src, dest, opts, cb) {\n  fs.mkdir(dest, err => {\n    if (err) return cb(err)\n    copyDir(src, dest, opts, err => {\n      if (err) return cb(err)\n      return setDestMode(dest, srcMode, cb)\n    })\n  })\n}\n\nfunction copyDir (src, dest, opts, cb) {\n  fs.readdir(src, (err, items) => {\n    if (err) return cb(err)\n    return copyDirItems(items, src, dest, opts, cb)\n  })\n}\n\nfunction copyDirItems (items, src, dest, opts, cb) {\n  const item = items.pop()\n  if (!item) return cb()\n  return copyDirItem(items, item, src, dest, opts, cb)\n}\n\nfunction copyDirItem (items, item, src, dest, opts, cb) {\n  const srcItem = path.join(src, item)\n  const destItem = path.join(dest, item)\n  stat.checkPaths(srcItem, destItem, 'copy', opts, (err, stats) => {\n    if (err) return cb(err)\n    const { destStat } = stats\n    startCopy(destStat, srcItem, destItem, opts, err => {\n      if (err) return cb(err)\n      return copyDirItems(items, src, dest, opts, cb)\n    })\n  })\n}\n\nfunction onLink (destStat, src, dest, opts, cb) {\n  fs.readlink(src, (err, resolvedSrc) => {\n    if (err) return cb(err)\n    if (opts.dereference) {\n      resolvedSrc = path.resolve(process.cwd(), resolvedSrc)\n    }\n\n    if (!destStat) {\n      return fs.symlink(resolvedSrc, dest, cb)\n    } else {\n      fs.readlink(dest, (err, resolvedDest) => {\n        if (err) {\n          // dest exists and is a regular file or directory,\n          // Windows may throw UNKNOWN error. If dest already exists,\n          // fs throws error anyway, so no need to guard against it here.\n          if (err.code === 'EINVAL' || err.code === 'UNKNOWN') return fs.symlink(resolvedSrc, dest, cb)\n          return cb(err)\n        }\n        if (opts.dereference) {\n          resolvedDest = path.resolve(process.cwd(), resolvedDest)\n        }\n        if (stat.isSrcSubdir(resolvedSrc, resolvedDest)) {\n          return cb(new Error(`Cannot copy '${resolvedSrc}' to a subdirectory of itself, '${resolvedDest}'.`))\n        }\n\n        // do not copy if src is a subdir of dest since unlinking\n        // dest in this case would result in removing src contents\n        // and therefore a broken symlink would be created.\n        if (destStat.isDirectory() && stat.isSrcSubdir(resolvedDest, resolvedSrc)) {\n          return cb(new Error(`Cannot overwrite '${resolvedDest}' with '${resolvedSrc}'.`))\n        }\n        return copyLink(resolvedSrc, dest, cb)\n      })\n    }\n  })\n}\n\nfunction copyLink (resolvedSrc, dest, cb) {\n  fs.unlink(dest, err => {\n    if (err) return cb(err)\n    return fs.symlink(resolvedSrc, dest, cb)\n  })\n}\n\nmodule.exports = copy\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/copy/copy.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/copy/index.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/copy/index.js ***!
  \*******************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = (__webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\").fromCallback)\nmodule.exports = {\n  copy: u(__webpack_require__(/*! ./copy */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/copy/copy.js\")),\n  copySync: __webpack_require__(/*! ./copy-sync */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/copy/copy-sync.js\")\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/copy/index.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/empty/index.js":
/*!********************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/empty/index.js ***!
  \********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = (__webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\").fromPromise)\nconst fs = __webpack_require__(/*! ../fs */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/fs/index.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst mkdir = __webpack_require__(/*! ../mkdirs */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/mkdirs/index.js\")\nconst remove = __webpack_require__(/*! ../remove */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/remove/index.js\")\n\nconst emptyDir = u(async function emptyDir (dir) {\n  let items\n  try {\n    items = await fs.readdir(dir)\n  } catch {\n    return mkdir.mkdirs(dir)\n  }\n\n  return Promise.all(items.map(item => remove.remove(path.join(dir, item))))\n})\n\nfunction emptyDirSync (dir) {\n  let items\n  try {\n    items = fs.readdirSync(dir)\n  } catch {\n    return mkdir.mkdirsSync(dir)\n  }\n\n  items.forEach(item => {\n    item = path.join(dir, item)\n    remove.removeSync(item)\n  })\n}\n\nmodule.exports = {\n  emptyDirSync,\n  emptydirSync: emptyDirSync,\n  emptyDir,\n  emptydir: emptyDir\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/empty/index.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/ensure/file.js":
/*!********************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/ensure/file.js ***!
  \********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = (__webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\").fromCallback)\nconst path = __webpack_require__(/*! path */ \"path\")\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\nconst mkdir = __webpack_require__(/*! ../mkdirs */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/mkdirs/index.js\")\n\nfunction createFile (file, callback) {\n  function makeFile () {\n    fs.writeFile(file, '', err => {\n      if (err) return callback(err)\n      callback()\n    })\n  }\n\n  fs.stat(file, (err, stats) => { // eslint-disable-line handle-callback-err\n    if (!err && stats.isFile()) return callback()\n    const dir = path.dirname(file)\n    fs.stat(dir, (err, stats) => {\n      if (err) {\n        // if the directory doesn't exist, make it\n        if (err.code === 'ENOENT') {\n          return mkdir.mkdirs(dir, err => {\n            if (err) return callback(err)\n            makeFile()\n          })\n        }\n        return callback(err)\n      }\n\n      if (stats.isDirectory()) makeFile()\n      else {\n        // parent is not a directory\n        // This is just to cause an internal ENOTDIR error to be thrown\n        fs.readdir(dir, err => {\n          if (err) return callback(err)\n        })\n      }\n    })\n  })\n}\n\nfunction createFileSync (file) {\n  let stats\n  try {\n    stats = fs.statSync(file)\n  } catch {}\n  if (stats && stats.isFile()) return\n\n  const dir = path.dirname(file)\n  try {\n    if (!fs.statSync(dir).isDirectory()) {\n      // parent is not a directory\n      // This is just to cause an internal ENOTDIR error to be thrown\n      fs.readdirSync(dir)\n    }\n  } catch (err) {\n    // If the stat call above failed because the directory doesn't exist, create it\n    if (err && err.code === 'ENOENT') mkdir.mkdirsSync(dir)\n    else throw err\n  }\n\n  fs.writeFileSync(file, '')\n}\n\nmodule.exports = {\n  createFile: u(createFile),\n  createFileSync\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/ensure/file.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/ensure/index.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/ensure/index.js ***!
  \*********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst { createFile, createFileSync } = __webpack_require__(/*! ./file */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/ensure/file.js\")\nconst { createLink, createLinkSync } = __webpack_require__(/*! ./link */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/ensure/link.js\")\nconst { createSymlink, createSymlinkSync } = __webpack_require__(/*! ./symlink */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/ensure/symlink.js\")\n\nmodule.exports = {\n  // file\n  createFile,\n  createFileSync,\n  ensureFile: createFile,\n  ensureFileSync: createFileSync,\n  // link\n  createLink,\n  createLinkSync,\n  ensureLink: createLink,\n  ensureLinkSync: createLinkSync,\n  // symlink\n  createSymlink,\n  createSymlinkSync,\n  ensureSymlink: createSymlink,\n  ensureSymlinkSync: createSymlinkSync\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/ensure/index.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/ensure/link.js":
/*!********************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/ensure/link.js ***!
  \********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = (__webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\").fromCallback)\nconst path = __webpack_require__(/*! path */ \"path\")\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\nconst mkdir = __webpack_require__(/*! ../mkdirs */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/mkdirs/index.js\")\nconst pathExists = (__webpack_require__(/*! ../path-exists */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/path-exists/index.js\").pathExists)\nconst { areIdentical } = __webpack_require__(/*! ../util/stat */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/util/stat.js\")\n\nfunction createLink (srcpath, dstpath, callback) {\n  function makeLink (srcpath, dstpath) {\n    fs.link(srcpath, dstpath, err => {\n      if (err) return callback(err)\n      callback(null)\n    })\n  }\n\n  fs.lstat(dstpath, (_, dstStat) => {\n    fs.lstat(srcpath, (err, srcStat) => {\n      if (err) {\n        err.message = err.message.replace('lstat', 'ensureLink')\n        return callback(err)\n      }\n      if (dstStat && areIdentical(srcStat, dstStat)) return callback(null)\n\n      const dir = path.dirname(dstpath)\n      pathExists(dir, (err, dirExists) => {\n        if (err) return callback(err)\n        if (dirExists) return makeLink(srcpath, dstpath)\n        mkdir.mkdirs(dir, err => {\n          if (err) return callback(err)\n          makeLink(srcpath, dstpath)\n        })\n      })\n    })\n  })\n}\n\nfunction createLinkSync (srcpath, dstpath) {\n  let dstStat\n  try {\n    dstStat = fs.lstatSync(dstpath)\n  } catch {}\n\n  try {\n    const srcStat = fs.lstatSync(srcpath)\n    if (dstStat && areIdentical(srcStat, dstStat)) return\n  } catch (err) {\n    err.message = err.message.replace('lstat', 'ensureLink')\n    throw err\n  }\n\n  const dir = path.dirname(dstpath)\n  const dirExists = fs.existsSync(dir)\n  if (dirExists) return fs.linkSync(srcpath, dstpath)\n  mkdir.mkdirsSync(dir)\n\n  return fs.linkSync(srcpath, dstpath)\n}\n\nmodule.exports = {\n  createLink: u(createLink),\n  createLinkSync\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/ensure/link.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/ensure/symlink-paths.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/ensure/symlink-paths.js ***!
  \*****************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst path = __webpack_require__(/*! path */ \"path\")\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\nconst pathExists = (__webpack_require__(/*! ../path-exists */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/path-exists/index.js\").pathExists)\n\n/**\n * Function that returns two types of paths, one relative to symlink, and one\n * relative to the current working directory. Checks if path is absolute or\n * relative. If the path is relative, this function checks if the path is\n * relative to symlink or relative to current working directory. This is an\n * initiative to find a smarter `srcpath` to supply when building symlinks.\n * This allows you to determine which path to use out of one of three possible\n * types of source paths. The first is an absolute path. This is detected by\n * `path.isAbsolute()`. When an absolute path is provided, it is checked to\n * see if it exists. If it does it's used, if not an error is returned\n * (callback)/ thrown (sync). The other two options for `srcpath` are a\n * relative url. By default Node's `fs.symlink` works by creating a symlink\n * using `dstpath` and expects the `srcpath` to be relative to the newly\n * created symlink. If you provide a `srcpath` that does not exist on the file\n * system it results in a broken symlink. To minimize this, the function\n * checks to see if the 'relative to symlink' source file exists, and if it\n * does it will use it. If it does not, it checks if there's a file that\n * exists that is relative to the current working directory, if does its used.\n * This preserves the expectations of the original fs.symlink spec and adds\n * the ability to pass in `relative to current working direcotry` paths.\n */\n\nfunction symlinkPaths (srcpath, dstpath, callback) {\n  if (path.isAbsolute(srcpath)) {\n    return fs.lstat(srcpath, (err) => {\n      if (err) {\n        err.message = err.message.replace('lstat', 'ensureSymlink')\n        return callback(err)\n      }\n      return callback(null, {\n        toCwd: srcpath,\n        toDst: srcpath\n      })\n    })\n  } else {\n    const dstdir = path.dirname(dstpath)\n    const relativeToDst = path.join(dstdir, srcpath)\n    return pathExists(relativeToDst, (err, exists) => {\n      if (err) return callback(err)\n      if (exists) {\n        return callback(null, {\n          toCwd: relativeToDst,\n          toDst: srcpath\n        })\n      } else {\n        return fs.lstat(srcpath, (err) => {\n          if (err) {\n            err.message = err.message.replace('lstat', 'ensureSymlink')\n            return callback(err)\n          }\n          return callback(null, {\n            toCwd: srcpath,\n            toDst: path.relative(dstdir, srcpath)\n          })\n        })\n      }\n    })\n  }\n}\n\nfunction symlinkPathsSync (srcpath, dstpath) {\n  let exists\n  if (path.isAbsolute(srcpath)) {\n    exists = fs.existsSync(srcpath)\n    if (!exists) throw new Error('absolute srcpath does not exist')\n    return {\n      toCwd: srcpath,\n      toDst: srcpath\n    }\n  } else {\n    const dstdir = path.dirname(dstpath)\n    const relativeToDst = path.join(dstdir, srcpath)\n    exists = fs.existsSync(relativeToDst)\n    if (exists) {\n      return {\n        toCwd: relativeToDst,\n        toDst: srcpath\n      }\n    } else {\n      exists = fs.existsSync(srcpath)\n      if (!exists) throw new Error('relative srcpath does not exist')\n      return {\n        toCwd: srcpath,\n        toDst: path.relative(dstdir, srcpath)\n      }\n    }\n  }\n}\n\nmodule.exports = {\n  symlinkPaths,\n  symlinkPathsSync\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/ensure/symlink-paths.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/ensure/symlink-type.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/ensure/symlink-type.js ***!
  \****************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\n\nfunction symlinkType (srcpath, type, callback) {\n  callback = (typeof type === 'function') ? type : callback\n  type = (typeof type === 'function') ? false : type\n  if (type) return callback(null, type)\n  fs.lstat(srcpath, (err, stats) => {\n    if (err) return callback(null, 'file')\n    type = (stats && stats.isDirectory()) ? 'dir' : 'file'\n    callback(null, type)\n  })\n}\n\nfunction symlinkTypeSync (srcpath, type) {\n  let stats\n\n  if (type) return type\n  try {\n    stats = fs.lstatSync(srcpath)\n  } catch {\n    return 'file'\n  }\n  return (stats && stats.isDirectory()) ? 'dir' : 'file'\n}\n\nmodule.exports = {\n  symlinkType,\n  symlinkTypeSync\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/ensure/symlink-type.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/ensure/symlink.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/ensure/symlink.js ***!
  \***********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = (__webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\").fromCallback)\nconst path = __webpack_require__(/*! path */ \"path\")\nconst fs = __webpack_require__(/*! ../fs */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/fs/index.js\")\nconst _mkdirs = __webpack_require__(/*! ../mkdirs */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/mkdirs/index.js\")\nconst mkdirs = _mkdirs.mkdirs\nconst mkdirsSync = _mkdirs.mkdirsSync\n\nconst _symlinkPaths = __webpack_require__(/*! ./symlink-paths */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/ensure/symlink-paths.js\")\nconst symlinkPaths = _symlinkPaths.symlinkPaths\nconst symlinkPathsSync = _symlinkPaths.symlinkPathsSync\n\nconst _symlinkType = __webpack_require__(/*! ./symlink-type */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/ensure/symlink-type.js\")\nconst symlinkType = _symlinkType.symlinkType\nconst symlinkTypeSync = _symlinkType.symlinkTypeSync\n\nconst pathExists = (__webpack_require__(/*! ../path-exists */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/path-exists/index.js\").pathExists)\n\nconst { areIdentical } = __webpack_require__(/*! ../util/stat */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/util/stat.js\")\n\nfunction createSymlink (srcpath, dstpath, type, callback) {\n  callback = (typeof type === 'function') ? type : callback\n  type = (typeof type === 'function') ? false : type\n\n  fs.lstat(dstpath, (err, stats) => {\n    if (!err && stats.isSymbolicLink()) {\n      Promise.all([\n        fs.stat(srcpath),\n        fs.stat(dstpath)\n      ]).then(([srcStat, dstStat]) => {\n        if (areIdentical(srcStat, dstStat)) return callback(null)\n        _createSymlink(srcpath, dstpath, type, callback)\n      })\n    } else _createSymlink(srcpath, dstpath, type, callback)\n  })\n}\n\nfunction _createSymlink (srcpath, dstpath, type, callback) {\n  symlinkPaths(srcpath, dstpath, (err, relative) => {\n    if (err) return callback(err)\n    srcpath = relative.toDst\n    symlinkType(relative.toCwd, type, (err, type) => {\n      if (err) return callback(err)\n      const dir = path.dirname(dstpath)\n      pathExists(dir, (err, dirExists) => {\n        if (err) return callback(err)\n        if (dirExists) return fs.symlink(srcpath, dstpath, type, callback)\n        mkdirs(dir, err => {\n          if (err) return callback(err)\n          fs.symlink(srcpath, dstpath, type, callback)\n        })\n      })\n    })\n  })\n}\n\nfunction createSymlinkSync (srcpath, dstpath, type) {\n  let stats\n  try {\n    stats = fs.lstatSync(dstpath)\n  } catch {}\n  if (stats && stats.isSymbolicLink()) {\n    const srcStat = fs.statSync(srcpath)\n    const dstStat = fs.statSync(dstpath)\n    if (areIdentical(srcStat, dstStat)) return\n  }\n\n  const relative = symlinkPathsSync(srcpath, dstpath)\n  srcpath = relative.toDst\n  type = symlinkTypeSync(relative.toCwd, type)\n  const dir = path.dirname(dstpath)\n  const exists = fs.existsSync(dir)\n  if (exists) return fs.symlinkSync(srcpath, dstpath, type)\n  mkdirsSync(dir)\n  return fs.symlinkSync(srcpath, dstpath, type)\n}\n\nmodule.exports = {\n  createSymlink: u(createSymlink),\n  createSymlinkSync\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/ensure/symlink.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/fs/index.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/fs/index.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// This is adapted from https://github.com/normalize/mz\n// Copyright (c) 2014-2016 Jonathan Ong me@jongleberry.com and Contributors\nconst u = (__webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\").fromCallback)\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\n\nconst api = [\n  'access',\n  'appendFile',\n  'chmod',\n  'chown',\n  'close',\n  'copyFile',\n  'fchmod',\n  'fchown',\n  'fdatasync',\n  'fstat',\n  'fsync',\n  'ftruncate',\n  'futimes',\n  'lchmod',\n  'lchown',\n  'link',\n  'lstat',\n  'mkdir',\n  'mkdtemp',\n  'open',\n  'opendir',\n  'readdir',\n  'readFile',\n  'readlink',\n  'realpath',\n  'rename',\n  'rm',\n  'rmdir',\n  'stat',\n  'symlink',\n  'truncate',\n  'unlink',\n  'utimes',\n  'writeFile'\n].filter(key => {\n  // Some commands are not available on some systems. Ex:\n  // fs.opendir was added in Node.js v12.12.0\n  // fs.rm was added in Node.js v14.14.0\n  // fs.lchown is not available on at least some Linux\n  return typeof fs[key] === 'function'\n})\n\n// Export cloned fs:\nObject.assign(exports, fs)\n\n// Universalify async methods:\napi.forEach(method => {\n  exports[method] = u(fs[method])\n})\n\n// We differ from mz/fs in that we still ship the old, broken, fs.exists()\n// since we are a drop-in replacement for the native module\nexports.exists = function (filename, callback) {\n  if (typeof callback === 'function') {\n    return fs.exists(filename, callback)\n  }\n  return new Promise(resolve => {\n    return fs.exists(filename, resolve)\n  })\n}\n\n// fs.read(), fs.write(), & fs.writev() need special treatment due to multiple callback args\n\nexports.read = function (fd, buffer, offset, length, position, callback) {\n  if (typeof callback === 'function') {\n    return fs.read(fd, buffer, offset, length, position, callback)\n  }\n  return new Promise((resolve, reject) => {\n    fs.read(fd, buffer, offset, length, position, (err, bytesRead, buffer) => {\n      if (err) return reject(err)\n      resolve({ bytesRead, buffer })\n    })\n  })\n}\n\n// Function signature can be\n// fs.write(fd, buffer[, offset[, length[, position]]], callback)\n// OR\n// fs.write(fd, string[, position[, encoding]], callback)\n// We need to handle both cases, so we use ...args\nexports.write = function (fd, buffer, ...args) {\n  if (typeof args[args.length - 1] === 'function') {\n    return fs.write(fd, buffer, ...args)\n  }\n\n  return new Promise((resolve, reject) => {\n    fs.write(fd, buffer, ...args, (err, bytesWritten, buffer) => {\n      if (err) return reject(err)\n      resolve({ bytesWritten, buffer })\n    })\n  })\n}\n\n// fs.writev only available in Node v12.9.0+\nif (typeof fs.writev === 'function') {\n  // Function signature is\n  // s.writev(fd, buffers[, position], callback)\n  // We need to handle the optional arg, so we use ...args\n  exports.writev = function (fd, buffers, ...args) {\n    if (typeof args[args.length - 1] === 'function') {\n      return fs.writev(fd, buffers, ...args)\n    }\n\n    return new Promise((resolve, reject) => {\n      fs.writev(fd, buffers, ...args, (err, bytesWritten, buffers) => {\n        if (err) return reject(err)\n        resolve({ bytesWritten, buffers })\n      })\n    })\n  }\n}\n\n// fs.realpath.native sometimes not available if fs is monkey-patched\nif (typeof fs.realpath.native === 'function') {\n  exports.realpath.native = u(fs.realpath.native)\n} else {\n  process.emitWarning(\n    'fs.realpath.native is not a function. Is fs being monkey-patched?',\n    'Warning', 'fs-extra-WARN0003'\n  )\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/fs/index.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/index.js":
/*!**************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/index.js ***!
  \**************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = {\n  // Export promiseified graceful-fs:\n  ...__webpack_require__(/*! ./fs */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/fs/index.js\"),\n  // Export extra methods:\n  ...__webpack_require__(/*! ./copy */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/copy/index.js\"),\n  ...__webpack_require__(/*! ./empty */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/empty/index.js\"),\n  ...__webpack_require__(/*! ./ensure */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/ensure/index.js\"),\n  ...__webpack_require__(/*! ./json */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/json/index.js\"),\n  ...__webpack_require__(/*! ./mkdirs */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/mkdirs/index.js\"),\n  ...__webpack_require__(/*! ./move */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/move/index.js\"),\n  ...__webpack_require__(/*! ./output-file */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/output-file/index.js\"),\n  ...__webpack_require__(/*! ./path-exists */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/path-exists/index.js\"),\n  ...__webpack_require__(/*! ./remove */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/remove/index.js\")\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/index.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/json/index.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/json/index.js ***!
  \*******************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = (__webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\").fromPromise)\nconst jsonFile = __webpack_require__(/*! ./jsonfile */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/json/jsonfile.js\")\n\njsonFile.outputJson = u(__webpack_require__(/*! ./output-json */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/json/output-json.js\"))\njsonFile.outputJsonSync = __webpack_require__(/*! ./output-json-sync */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/json/output-json-sync.js\")\n// aliases\njsonFile.outputJSON = jsonFile.outputJson\njsonFile.outputJSONSync = jsonFile.outputJsonSync\njsonFile.writeJSON = jsonFile.writeJson\njsonFile.writeJSONSync = jsonFile.writeJsonSync\njsonFile.readJSON = jsonFile.readJson\njsonFile.readJSONSync = jsonFile.readJsonSync\n\nmodule.exports = jsonFile\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/json/index.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/json/jsonfile.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/json/jsonfile.js ***!
  \**********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst jsonFile = __webpack_require__(/*! jsonfile */ \"./node_modules/jsonfile/index.js\")\n\nmodule.exports = {\n  // jsonfile exports\n  readJson: jsonFile.readFile,\n  readJsonSync: jsonFile.readFileSync,\n  writeJson: jsonFile.writeFile,\n  writeJsonSync: jsonFile.writeFileSync\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/json/jsonfile.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/json/output-json-sync.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/json/output-json-sync.js ***!
  \******************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst { stringify } = __webpack_require__(/*! jsonfile/utils */ \"./node_modules/jsonfile/utils.js\")\nconst { outputFileSync } = __webpack_require__(/*! ../output-file */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/output-file/index.js\")\n\nfunction outputJsonSync (file, data, options) {\n  const str = stringify(data, options)\n\n  outputFileSync(file, str, options)\n}\n\nmodule.exports = outputJsonSync\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/json/output-json-sync.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/json/output-json.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/json/output-json.js ***!
  \*************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst { stringify } = __webpack_require__(/*! jsonfile/utils */ \"./node_modules/jsonfile/utils.js\")\nconst { outputFile } = __webpack_require__(/*! ../output-file */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/output-file/index.js\")\n\nasync function outputJson (file, data, options = {}) {\n  const str = stringify(data, options)\n\n  await outputFile(file, str, options)\n}\n\nmodule.exports = outputJson\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/json/output-json.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/mkdirs/index.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/mkdirs/index.js ***!
  \*********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst u = (__webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\").fromPromise)\nconst { makeDir: _makeDir, makeDirSync } = __webpack_require__(/*! ./make-dir */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/mkdirs/make-dir.js\")\nconst makeDir = u(_makeDir)\n\nmodule.exports = {\n  mkdirs: makeDir,\n  mkdirsSync: makeDirSync,\n  // alias\n  mkdirp: makeDir,\n  mkdirpSync: makeDirSync,\n  ensureDir: makeDir,\n  ensureDirSync: makeDirSync\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/mkdirs/index.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/mkdirs/make-dir.js":
/*!************************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/mkdirs/make-dir.js ***!
  \************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst fs = __webpack_require__(/*! ../fs */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/fs/index.js\")\nconst { checkPath } = __webpack_require__(/*! ./utils */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/mkdirs/utils.js\")\n\nconst getMode = options => {\n  const defaults = { mode: 0o777 }\n  if (typeof options === 'number') return options\n  return ({ ...defaults, ...options }).mode\n}\n\nmodule.exports.makeDir = async (dir, options) => {\n  checkPath(dir)\n\n  return fs.mkdir(dir, {\n    mode: getMode(options),\n    recursive: true\n  })\n}\n\nmodule.exports.makeDirSync = (dir, options) => {\n  checkPath(dir)\n\n  return fs.mkdirSync(dir, {\n    mode: getMode(options),\n    recursive: true\n  })\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/mkdirs/make-dir.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/mkdirs/utils.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/mkdirs/utils.js ***!
  \*********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Adapted from https://github.com/sindresorhus/make-dir\n// Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)\n// Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n// The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nconst path = __webpack_require__(/*! path */ \"path\")\n\n// https://github.com/nodejs/node/issues/8987\n// https://github.com/libuv/libuv/pull/1088\nmodule.exports.checkPath = function checkPath (pth) {\n  if (process.platform === 'win32') {\n    const pathHasInvalidWinCharacters = /[<>:\"|?*]/.test(pth.replace(path.parse(pth).root, ''))\n\n    if (pathHasInvalidWinCharacters) {\n      const error = new Error(`Path contains invalid characters: ${pth}`)\n      error.code = 'EINVAL'\n      throw error\n    }\n  }\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/mkdirs/utils.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/move/index.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/move/index.js ***!
  \*******************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = (__webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\").fromCallback)\nmodule.exports = {\n  move: u(__webpack_require__(/*! ./move */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/move/move.js\")),\n  moveSync: __webpack_require__(/*! ./move-sync */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/move/move-sync.js\")\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/move/index.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/move/move-sync.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/move/move-sync.js ***!
  \***********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst copySync = (__webpack_require__(/*! ../copy */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/copy/index.js\").copySync)\nconst removeSync = (__webpack_require__(/*! ../remove */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/remove/index.js\").removeSync)\nconst mkdirpSync = (__webpack_require__(/*! ../mkdirs */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/mkdirs/index.js\").mkdirpSync)\nconst stat = __webpack_require__(/*! ../util/stat */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/util/stat.js\")\n\nfunction moveSync (src, dest, opts) {\n  opts = opts || {}\n  const overwrite = opts.overwrite || opts.clobber || false\n\n  const { srcStat, isChangingCase = false } = stat.checkPathsSync(src, dest, 'move', opts)\n  stat.checkParentPathsSync(src, srcStat, dest, 'move')\n  if (!isParentRoot(dest)) mkdirpSync(path.dirname(dest))\n  return doRename(src, dest, overwrite, isChangingCase)\n}\n\nfunction isParentRoot (dest) {\n  const parent = path.dirname(dest)\n  const parsedPath = path.parse(parent)\n  return parsedPath.root === parent\n}\n\nfunction doRename (src, dest, overwrite, isChangingCase) {\n  if (isChangingCase) return rename(src, dest, overwrite)\n  if (overwrite) {\n    removeSync(dest)\n    return rename(src, dest, overwrite)\n  }\n  if (fs.existsSync(dest)) throw new Error('dest already exists.')\n  return rename(src, dest, overwrite)\n}\n\nfunction rename (src, dest, overwrite) {\n  try {\n    fs.renameSync(src, dest)\n  } catch (err) {\n    if (err.code !== 'EXDEV') throw err\n    return moveAcrossDevice(src, dest, overwrite)\n  }\n}\n\nfunction moveAcrossDevice (src, dest, overwrite) {\n  const opts = {\n    overwrite,\n    errorOnExist: true\n  }\n  copySync(src, dest, opts)\n  return removeSync(src)\n}\n\nmodule.exports = moveSync\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/move/move-sync.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/move/move.js":
/*!******************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/move/move.js ***!
  \******************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst copy = (__webpack_require__(/*! ../copy */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/copy/index.js\").copy)\nconst remove = (__webpack_require__(/*! ../remove */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/remove/index.js\").remove)\nconst mkdirp = (__webpack_require__(/*! ../mkdirs */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/mkdirs/index.js\").mkdirp)\nconst pathExists = (__webpack_require__(/*! ../path-exists */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/path-exists/index.js\").pathExists)\nconst stat = __webpack_require__(/*! ../util/stat */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/util/stat.js\")\n\nfunction move (src, dest, opts, cb) {\n  if (typeof opts === 'function') {\n    cb = opts\n    opts = {}\n  }\n\n  opts = opts || {}\n\n  const overwrite = opts.overwrite || opts.clobber || false\n\n  stat.checkPaths(src, dest, 'move', opts, (err, stats) => {\n    if (err) return cb(err)\n    const { srcStat, isChangingCase = false } = stats\n    stat.checkParentPaths(src, srcStat, dest, 'move', err => {\n      if (err) return cb(err)\n      if (isParentRoot(dest)) return doRename(src, dest, overwrite, isChangingCase, cb)\n      mkdirp(path.dirname(dest), err => {\n        if (err) return cb(err)\n        return doRename(src, dest, overwrite, isChangingCase, cb)\n      })\n    })\n  })\n}\n\nfunction isParentRoot (dest) {\n  const parent = path.dirname(dest)\n  const parsedPath = path.parse(parent)\n  return parsedPath.root === parent\n}\n\nfunction doRename (src, dest, overwrite, isChangingCase, cb) {\n  if (isChangingCase) return rename(src, dest, overwrite, cb)\n  if (overwrite) {\n    return remove(dest, err => {\n      if (err) return cb(err)\n      return rename(src, dest, overwrite, cb)\n    })\n  }\n  pathExists(dest, (err, destExists) => {\n    if (err) return cb(err)\n    if (destExists) return cb(new Error('dest already exists.'))\n    return rename(src, dest, overwrite, cb)\n  })\n}\n\nfunction rename (src, dest, overwrite, cb) {\n  fs.rename(src, dest, err => {\n    if (!err) return cb()\n    if (err.code !== 'EXDEV') return cb(err)\n    return moveAcrossDevice(src, dest, overwrite, cb)\n  })\n}\n\nfunction moveAcrossDevice (src, dest, overwrite, cb) {\n  const opts = {\n    overwrite,\n    errorOnExist: true\n  }\n  copy(src, dest, opts, err => {\n    if (err) return cb(err)\n    return remove(src, cb)\n  })\n}\n\nmodule.exports = move\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/move/move.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/output-file/index.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/output-file/index.js ***!
  \**************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = (__webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\").fromCallback)\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst mkdir = __webpack_require__(/*! ../mkdirs */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/mkdirs/index.js\")\nconst pathExists = (__webpack_require__(/*! ../path-exists */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/path-exists/index.js\").pathExists)\n\nfunction outputFile (file, data, encoding, callback) {\n  if (typeof encoding === 'function') {\n    callback = encoding\n    encoding = 'utf8'\n  }\n\n  const dir = path.dirname(file)\n  pathExists(dir, (err, itDoes) => {\n    if (err) return callback(err)\n    if (itDoes) return fs.writeFile(file, data, encoding, callback)\n\n    mkdir.mkdirs(dir, err => {\n      if (err) return callback(err)\n\n      fs.writeFile(file, data, encoding, callback)\n    })\n  })\n}\n\nfunction outputFileSync (file, ...args) {\n  const dir = path.dirname(file)\n  if (fs.existsSync(dir)) {\n    return fs.writeFileSync(file, ...args)\n  }\n  mkdir.mkdirsSync(dir)\n  fs.writeFileSync(file, ...args)\n}\n\nmodule.exports = {\n  outputFile: u(outputFile),\n  outputFileSync\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/output-file/index.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/path-exists/index.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/path-exists/index.js ***!
  \**************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst u = (__webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\").fromPromise)\nconst fs = __webpack_require__(/*! ../fs */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/fs/index.js\")\n\nfunction pathExists (path) {\n  return fs.access(path).then(() => true).catch(() => false)\n}\n\nmodule.exports = {\n  pathExists: u(pathExists),\n  pathExistsSync: fs.existsSync\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/path-exists/index.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/remove/index.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/remove/index.js ***!
  \*********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\nconst u = (__webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\").fromCallback)\nconst rimraf = __webpack_require__(/*! ./rimraf */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/remove/rimraf.js\")\n\nfunction remove (path, callback) {\n  // Node 14.14.0+\n  if (fs.rm) return fs.rm(path, { recursive: true, force: true }, callback)\n  rimraf(path, callback)\n}\n\nfunction removeSync (path) {\n  // Node 14.14.0+\n  if (fs.rmSync) return fs.rmSync(path, { recursive: true, force: true })\n  rimraf.sync(path)\n}\n\nmodule.exports = {\n  remove: u(remove),\n  removeSync\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/remove/index.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/remove/rimraf.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/remove/rimraf.js ***!
  \**********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst assert = __webpack_require__(/*! assert */ \"assert\")\n\nconst isWindows = (process.platform === 'win32')\n\nfunction defaults (options) {\n  const methods = [\n    'unlink',\n    'chmod',\n    'stat',\n    'lstat',\n    'rmdir',\n    'readdir'\n  ]\n  methods.forEach(m => {\n    options[m] = options[m] || fs[m]\n    m = m + 'Sync'\n    options[m] = options[m] || fs[m]\n  })\n\n  options.maxBusyTries = options.maxBusyTries || 3\n}\n\nfunction rimraf (p, options, cb) {\n  let busyTries = 0\n\n  if (typeof options === 'function') {\n    cb = options\n    options = {}\n  }\n\n  assert(p, 'rimraf: missing path')\n  assert.strictEqual(typeof p, 'string', 'rimraf: path should be a string')\n  assert.strictEqual(typeof cb, 'function', 'rimraf: callback function required')\n  assert(options, 'rimraf: invalid options argument provided')\n  assert.strictEqual(typeof options, 'object', 'rimraf: options should be object')\n\n  defaults(options)\n\n  rimraf_(p, options, function CB (er) {\n    if (er) {\n      if ((er.code === 'EBUSY' || er.code === 'ENOTEMPTY' || er.code === 'EPERM') &&\n          busyTries < options.maxBusyTries) {\n        busyTries++\n        const time = busyTries * 100\n        // try again, with the same exact callback as this one.\n        return setTimeout(() => rimraf_(p, options, CB), time)\n      }\n\n      // already gone\n      if (er.code === 'ENOENT') er = null\n    }\n\n    cb(er)\n  })\n}\n\n// Two possible strategies.\n// 1. Assume it's a file.  unlink it, then do the dir stuff on EPERM or EISDIR\n// 2. Assume it's a directory.  readdir, then do the file stuff on ENOTDIR\n//\n// Both result in an extra syscall when you guess wrong.  However, there\n// are likely far more normal files in the world than directories.  This\n// is based on the assumption that a the average number of files per\n// directory is >= 1.\n//\n// If anyone ever complains about this, then I guess the strategy could\n// be made configurable somehow.  But until then, YAGNI.\nfunction rimraf_ (p, options, cb) {\n  assert(p)\n  assert(options)\n  assert(typeof cb === 'function')\n\n  // sunos lets the root user unlink directories, which is... weird.\n  // so we have to lstat here and make sure it's not a dir.\n  options.lstat(p, (er, st) => {\n    if (er && er.code === 'ENOENT') {\n      return cb(null)\n    }\n\n    // Windows can EPERM on stat.  Life is suffering.\n    if (er && er.code === 'EPERM' && isWindows) {\n      return fixWinEPERM(p, options, er, cb)\n    }\n\n    if (st && st.isDirectory()) {\n      return rmdir(p, options, er, cb)\n    }\n\n    options.unlink(p, er => {\n      if (er) {\n        if (er.code === 'ENOENT') {\n          return cb(null)\n        }\n        if (er.code === 'EPERM') {\n          return (isWindows)\n            ? fixWinEPERM(p, options, er, cb)\n            : rmdir(p, options, er, cb)\n        }\n        if (er.code === 'EISDIR') {\n          return rmdir(p, options, er, cb)\n        }\n      }\n      return cb(er)\n    })\n  })\n}\n\nfunction fixWinEPERM (p, options, er, cb) {\n  assert(p)\n  assert(options)\n  assert(typeof cb === 'function')\n\n  options.chmod(p, 0o666, er2 => {\n    if (er2) {\n      cb(er2.code === 'ENOENT' ? null : er)\n    } else {\n      options.stat(p, (er3, stats) => {\n        if (er3) {\n          cb(er3.code === 'ENOENT' ? null : er)\n        } else if (stats.isDirectory()) {\n          rmdir(p, options, er, cb)\n        } else {\n          options.unlink(p, cb)\n        }\n      })\n    }\n  })\n}\n\nfunction fixWinEPERMSync (p, options, er) {\n  let stats\n\n  assert(p)\n  assert(options)\n\n  try {\n    options.chmodSync(p, 0o666)\n  } catch (er2) {\n    if (er2.code === 'ENOENT') {\n      return\n    } else {\n      throw er\n    }\n  }\n\n  try {\n    stats = options.statSync(p)\n  } catch (er3) {\n    if (er3.code === 'ENOENT') {\n      return\n    } else {\n      throw er\n    }\n  }\n\n  if (stats.isDirectory()) {\n    rmdirSync(p, options, er)\n  } else {\n    options.unlinkSync(p)\n  }\n}\n\nfunction rmdir (p, options, originalEr, cb) {\n  assert(p)\n  assert(options)\n  assert(typeof cb === 'function')\n\n  // try to rmdir first, and only readdir on ENOTEMPTY or EEXIST (SunOS)\n  // if we guessed wrong, and it's not a directory, then\n  // raise the original error.\n  options.rmdir(p, er => {\n    if (er && (er.code === 'ENOTEMPTY' || er.code === 'EEXIST' || er.code === 'EPERM')) {\n      rmkids(p, options, cb)\n    } else if (er && er.code === 'ENOTDIR') {\n      cb(originalEr)\n    } else {\n      cb(er)\n    }\n  })\n}\n\nfunction rmkids (p, options, cb) {\n  assert(p)\n  assert(options)\n  assert(typeof cb === 'function')\n\n  options.readdir(p, (er, files) => {\n    if (er) return cb(er)\n\n    let n = files.length\n    let errState\n\n    if (n === 0) return options.rmdir(p, cb)\n\n    files.forEach(f => {\n      rimraf(path.join(p, f), options, er => {\n        if (errState) {\n          return\n        }\n        if (er) return cb(errState = er)\n        if (--n === 0) {\n          options.rmdir(p, cb)\n        }\n      })\n    })\n  })\n}\n\n// this looks simpler, and is strictly *faster*, but will\n// tie up the JavaScript thread and fail on excessively\n// deep directory trees.\nfunction rimrafSync (p, options) {\n  let st\n\n  options = options || {}\n  defaults(options)\n\n  assert(p, 'rimraf: missing path')\n  assert.strictEqual(typeof p, 'string', 'rimraf: path should be a string')\n  assert(options, 'rimraf: missing options')\n  assert.strictEqual(typeof options, 'object', 'rimraf: options should be object')\n\n  try {\n    st = options.lstatSync(p)\n  } catch (er) {\n    if (er.code === 'ENOENT') {\n      return\n    }\n\n    // Windows can EPERM on stat.  Life is suffering.\n    if (er.code === 'EPERM' && isWindows) {\n      fixWinEPERMSync(p, options, er)\n    }\n  }\n\n  try {\n    // sunos lets the root user unlink directories, which is... weird.\n    if (st && st.isDirectory()) {\n      rmdirSync(p, options, null)\n    } else {\n      options.unlinkSync(p)\n    }\n  } catch (er) {\n    if (er.code === 'ENOENT') {\n      return\n    } else if (er.code === 'EPERM') {\n      return isWindows ? fixWinEPERMSync(p, options, er) : rmdirSync(p, options, er)\n    } else if (er.code !== 'EISDIR') {\n      throw er\n    }\n    rmdirSync(p, options, er)\n  }\n}\n\nfunction rmdirSync (p, options, originalEr) {\n  assert(p)\n  assert(options)\n\n  try {\n    options.rmdirSync(p)\n  } catch (er) {\n    if (er.code === 'ENOTDIR') {\n      throw originalEr\n    } else if (er.code === 'ENOTEMPTY' || er.code === 'EEXIST' || er.code === 'EPERM') {\n      rmkidsSync(p, options)\n    } else if (er.code !== 'ENOENT') {\n      throw er\n    }\n  }\n}\n\nfunction rmkidsSync (p, options) {\n  assert(p)\n  assert(options)\n  options.readdirSync(p).forEach(f => rimrafSync(path.join(p, f), options))\n\n  if (isWindows) {\n    // We only end up here once we got ENOTEMPTY at least once, and\n    // at this point, we are guaranteed to have removed all the kids.\n    // So, we know that it won't be ENOENT or ENOTDIR or anything else.\n    // try really hard to delete stuff on windows, because it has a\n    // PROFOUNDLY annoying habit of not closing handles promptly when\n    // files are deleted, resulting in spurious ENOTEMPTY errors.\n    const startTime = Date.now()\n    do {\n      try {\n        const ret = options.rmdirSync(p, options)\n        return ret\n      } catch {}\n    } while (Date.now() - startTime < 500) // give up after 500ms\n  } else {\n    const ret = options.rmdirSync(p, options)\n    return ret\n  }\n}\n\nmodule.exports = rimraf\nrimraf.sync = rimrafSync\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/remove/rimraf.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/util/stat.js":
/*!******************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/util/stat.js ***!
  \******************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! ../fs */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/fs/index.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst util = __webpack_require__(/*! util */ \"util\")\n\nfunction getStats (src, dest, opts) {\n  const statFunc = opts.dereference\n    ? (file) => fs.stat(file, { bigint: true })\n    : (file) => fs.lstat(file, { bigint: true })\n  return Promise.all([\n    statFunc(src),\n    statFunc(dest).catch(err => {\n      if (err.code === 'ENOENT') return null\n      throw err\n    })\n  ]).then(([srcStat, destStat]) => ({ srcStat, destStat }))\n}\n\nfunction getStatsSync (src, dest, opts) {\n  let destStat\n  const statFunc = opts.dereference\n    ? (file) => fs.statSync(file, { bigint: true })\n    : (file) => fs.lstatSync(file, { bigint: true })\n  const srcStat = statFunc(src)\n  try {\n    destStat = statFunc(dest)\n  } catch (err) {\n    if (err.code === 'ENOENT') return { srcStat, destStat: null }\n    throw err\n  }\n  return { srcStat, destStat }\n}\n\nfunction checkPaths (src, dest, funcName, opts, cb) {\n  util.callbackify(getStats)(src, dest, opts, (err, stats) => {\n    if (err) return cb(err)\n    const { srcStat, destStat } = stats\n\n    if (destStat) {\n      if (areIdentical(srcStat, destStat)) {\n        const srcBaseName = path.basename(src)\n        const destBaseName = path.basename(dest)\n        if (funcName === 'move' &&\n          srcBaseName !== destBaseName &&\n          srcBaseName.toLowerCase() === destBaseName.toLowerCase()) {\n          return cb(null, { srcStat, destStat, isChangingCase: true })\n        }\n        return cb(new Error('Source and destination must not be the same.'))\n      }\n      if (srcStat.isDirectory() && !destStat.isDirectory()) {\n        return cb(new Error(`Cannot overwrite non-directory '${dest}' with directory '${src}'.`))\n      }\n      if (!srcStat.isDirectory() && destStat.isDirectory()) {\n        return cb(new Error(`Cannot overwrite directory '${dest}' with non-directory '${src}'.`))\n      }\n    }\n\n    if (srcStat.isDirectory() && isSrcSubdir(src, dest)) {\n      return cb(new Error(errMsg(src, dest, funcName)))\n    }\n    return cb(null, { srcStat, destStat })\n  })\n}\n\nfunction checkPathsSync (src, dest, funcName, opts) {\n  const { srcStat, destStat } = getStatsSync(src, dest, opts)\n\n  if (destStat) {\n    if (areIdentical(srcStat, destStat)) {\n      const srcBaseName = path.basename(src)\n      const destBaseName = path.basename(dest)\n      if (funcName === 'move' &&\n        srcBaseName !== destBaseName &&\n        srcBaseName.toLowerCase() === destBaseName.toLowerCase()) {\n        return { srcStat, destStat, isChangingCase: true }\n      }\n      throw new Error('Source and destination must not be the same.')\n    }\n    if (srcStat.isDirectory() && !destStat.isDirectory()) {\n      throw new Error(`Cannot overwrite non-directory '${dest}' with directory '${src}'.`)\n    }\n    if (!srcStat.isDirectory() && destStat.isDirectory()) {\n      throw new Error(`Cannot overwrite directory '${dest}' with non-directory '${src}'.`)\n    }\n  }\n\n  if (srcStat.isDirectory() && isSrcSubdir(src, dest)) {\n    throw new Error(errMsg(src, dest, funcName))\n  }\n  return { srcStat, destStat }\n}\n\n// recursively check if dest parent is a subdirectory of src.\n// It works for all file types including symlinks since it\n// checks the src and dest inodes. It starts from the deepest\n// parent and stops once it reaches the src parent or the root path.\nfunction checkParentPaths (src, srcStat, dest, funcName, cb) {\n  const srcParent = path.resolve(path.dirname(src))\n  const destParent = path.resolve(path.dirname(dest))\n  if (destParent === srcParent || destParent === path.parse(destParent).root) return cb()\n  fs.stat(destParent, { bigint: true }, (err, destStat) => {\n    if (err) {\n      if (err.code === 'ENOENT') return cb()\n      return cb(err)\n    }\n    if (areIdentical(srcStat, destStat)) {\n      return cb(new Error(errMsg(src, dest, funcName)))\n    }\n    return checkParentPaths(src, srcStat, destParent, funcName, cb)\n  })\n}\n\nfunction checkParentPathsSync (src, srcStat, dest, funcName) {\n  const srcParent = path.resolve(path.dirname(src))\n  const destParent = path.resolve(path.dirname(dest))\n  if (destParent === srcParent || destParent === path.parse(destParent).root) return\n  let destStat\n  try {\n    destStat = fs.statSync(destParent, { bigint: true })\n  } catch (err) {\n    if (err.code === 'ENOENT') return\n    throw err\n  }\n  if (areIdentical(srcStat, destStat)) {\n    throw new Error(errMsg(src, dest, funcName))\n  }\n  return checkParentPathsSync(src, srcStat, destParent, funcName)\n}\n\nfunction areIdentical (srcStat, destStat) {\n  return destStat.ino && destStat.dev && destStat.ino === srcStat.ino && destStat.dev === srcStat.dev\n}\n\n// return true if dest is a subdir of src, otherwise false.\n// It only checks the path strings.\nfunction isSrcSubdir (src, dest) {\n  const srcArr = path.resolve(src).split(path.sep).filter(i => i)\n  const destArr = path.resolve(dest).split(path.sep).filter(i => i)\n  return srcArr.reduce((acc, cur, i) => acc && destArr[i] === cur, true)\n}\n\nfunction errMsg (src, dest, funcName) {\n  return `Cannot ${funcName} '${src}' to a subdirectory of itself, '${dest}'.`\n}\n\nmodule.exports = {\n  checkPaths,\n  checkPathsSync,\n  checkParentPaths,\n  checkParentPathsSync,\n  isSrcSubdir,\n  areIdentical\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/util/stat.js?");

/***/ }),

/***/ "./node_modules/electron-updater/node_modules/fs-extra/lib/util/utimes.js":
/*!********************************************************************************!*\
  !*** ./node_modules/electron-updater/node_modules/fs-extra/lib/util/utimes.js ***!
  \********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\n\nfunction utimesMillis (path, atime, mtime, callback) {\n  // if (!HAS_MILLIS_RES) return fs.utimes(path, atime, mtime, callback)\n  fs.open(path, 'r+', (err, fd) => {\n    if (err) return callback(err)\n    fs.futimes(fd, atime, mtime, futimesErr => {\n      fs.close(fd, closeErr => {\n        if (callback) callback(futimesErr || closeErr)\n      })\n    })\n  })\n}\n\nfunction utimesMillisSync (path, atime, mtime) {\n  const fd = fs.openSync(path, 'r+')\n  fs.futimesSync(fd, atime, mtime)\n  return fs.closeSync(fd)\n}\n\nmodule.exports = {\n  utimesMillis,\n  utimesMillisSync\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/node_modules/fs-extra/lib/util/utimes.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/AppAdapter.js":
/*!*********************************************************!*\
  !*** ./node_modules/electron-updater/out/AppAdapter.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.getAppCacheDir = void 0;\nconst path = __webpack_require__(/*! path */ \"path\");\nconst os_1 = __webpack_require__(/*! os */ \"os\");\nfunction getAppCacheDir() {\n    const homedir = (0, os_1.homedir)();\n    // https://github.com/electron/electron/issues/1404#issuecomment-194391247\n    let result;\n    if (process.platform === \"win32\") {\n        result = process.env[\"LOCALAPPDATA\"] || path.join(homedir, \"AppData\", \"Local\");\n    }\n    else if (process.platform === \"darwin\") {\n        result = path.join(homedir, \"Library\", \"Caches\");\n    }\n    else {\n        result = process.env[\"XDG_CACHE_HOME\"] || path.join(homedir, \".cache\");\n    }\n    return result;\n}\nexports.getAppCacheDir = getAppCacheDir;\n//# sourceMappingURL=AppAdapter.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/AppAdapter.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/AppImageUpdater.js":
/*!**************************************************************!*\
  !*** ./node_modules/electron-updater/out/AppImageUpdater.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AppImageUpdater = void 0;\nconst builder_util_runtime_1 = __webpack_require__(/*! builder-util-runtime */ \"./node_modules/builder-util-runtime/out/index.js\");\nconst child_process_1 = __webpack_require__(/*! child_process */ \"child_process\");\nconst fs_extra_1 = __webpack_require__(/*! fs-extra */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/index.js\");\nconst fs_1 = __webpack_require__(/*! fs */ \"fs\");\nconst path = __webpack_require__(/*! path */ \"path\");\nconst BaseUpdater_1 = __webpack_require__(/*! ./BaseUpdater */ \"./node_modules/electron-updater/out/BaseUpdater.js\");\nconst FileWithEmbeddedBlockMapDifferentialDownloader_1 = __webpack_require__(/*! ./differentialDownloader/FileWithEmbeddedBlockMapDifferentialDownloader */ \"./node_modules/electron-updater/out/differentialDownloader/FileWithEmbeddedBlockMapDifferentialDownloader.js\");\nconst main_1 = __webpack_require__(/*! ./main */ \"./node_modules/electron-updater/out/main.js\");\nconst Provider_1 = __webpack_require__(/*! ./providers/Provider */ \"./node_modules/electron-updater/out/providers/Provider.js\");\nclass AppImageUpdater extends BaseUpdater_1.BaseUpdater {\n    constructor(options, app) {\n        super(options, app);\n    }\n    isUpdaterActive() {\n        if (process.env[\"APPIMAGE\"] == null) {\n            if (process.env[\"SNAP\"] == null) {\n                this._logger.warn(\"APPIMAGE env is not defined, current application is not an AppImage\");\n            }\n            else {\n                this._logger.info(\"SNAP env is defined, updater is disabled\");\n            }\n            return false;\n        }\n        return super.isUpdaterActive();\n    }\n    /*** @private */\n    doDownloadUpdate(downloadUpdateOptions) {\n        const provider = downloadUpdateOptions.updateInfoAndProvider.provider;\n        const fileInfo = (0, Provider_1.findFile)(provider.resolveFiles(downloadUpdateOptions.updateInfoAndProvider.info), \"AppImage\", [\"rpm\", \"deb\"]);\n        return this.executeDownload({\n            fileExtension: \"AppImage\",\n            fileInfo,\n            downloadUpdateOptions,\n            task: async (updateFile, downloadOptions) => {\n                const oldFile = process.env[\"APPIMAGE\"];\n                if (oldFile == null) {\n                    throw (0, builder_util_runtime_1.newError)(\"APPIMAGE env is not defined\", \"ERR_UPDATER_OLD_FILE_NOT_FOUND\");\n                }\n                let isDownloadFull = false;\n                try {\n                    const downloadOptions = {\n                        newUrl: fileInfo.url,\n                        oldFile,\n                        logger: this._logger,\n                        newFile: updateFile,\n                        isUseMultipleRangeRequest: provider.isUseMultipleRangeRequest,\n                        requestHeaders: downloadUpdateOptions.requestHeaders,\n                        cancellationToken: downloadUpdateOptions.cancellationToken,\n                    };\n                    if (this.listenerCount(main_1.DOWNLOAD_PROGRESS) > 0) {\n                        downloadOptions.onProgress = it => this.emit(main_1.DOWNLOAD_PROGRESS, it);\n                    }\n                    await new FileWithEmbeddedBlockMapDifferentialDownloader_1.FileWithEmbeddedBlockMapDifferentialDownloader(fileInfo.info, this.httpExecutor, downloadOptions).download();\n                }\n                catch (e) {\n                    this._logger.error(`Cannot download differentially, fallback to full download: ${e.stack || e}`);\n                    // during test (developer machine mac) we must throw error\n                    isDownloadFull = process.platform === \"linux\";\n                }\n                if (isDownloadFull) {\n                    await this.httpExecutor.download(fileInfo.url, updateFile, downloadOptions);\n                }\n                await (0, fs_extra_1.chmod)(updateFile, 0o755);\n            },\n        });\n    }\n    doInstall(options) {\n        const appImageFile = process.env[\"APPIMAGE\"];\n        if (appImageFile == null) {\n            throw (0, builder_util_runtime_1.newError)(\"APPIMAGE env is not defined\", \"ERR_UPDATER_OLD_FILE_NOT_FOUND\");\n        }\n        // https://stackoverflow.com/a/1712051/1910191\n        (0, fs_1.unlinkSync)(appImageFile);\n        let destination;\n        const existingBaseName = path.basename(appImageFile);\n        // https://github.com/electron-userland/electron-builder/issues/2964\n        // if no version in existing file name, it means that user wants to preserve current custom name\n        if (path.basename(options.installerPath) === existingBaseName || !/\\d+\\.\\d+\\.\\d+/.test(existingBaseName)) {\n            // no version in the file name, overwrite existing\n            destination = appImageFile;\n        }\n        else {\n            destination = path.join(path.dirname(appImageFile), path.basename(options.installerPath));\n        }\n        (0, child_process_1.execFileSync)(\"mv\", [\"-f\", options.installerPath, destination]);\n        if (destination !== appImageFile) {\n            this.emit(\"appimage-filename-updated\", destination);\n        }\n        const env = {\n            ...process.env,\n            APPIMAGE_SILENT_INSTALL: \"true\",\n        };\n        if (options.isForceRunAfter) {\n            // eslint-disable-next-line @typescript-eslint/no-floating-promises\n            this.spawnLog(destination, [], env);\n        }\n        else {\n            env.APPIMAGE_EXIT_AFTER_INSTALL = \"true\";\n            (0, child_process_1.execFileSync)(destination, [], { env });\n        }\n        return true;\n    }\n}\nexports.AppImageUpdater = AppImageUpdater;\n//# sourceMappingURL=AppImageUpdater.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/AppImageUpdater.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/AppUpdater.js":
/*!*********************************************************!*\
  !*** ./node_modules/electron-updater/out/AppUpdater.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.NoOpLogger = exports.AppUpdater = void 0;\nconst builder_util_runtime_1 = __webpack_require__(/*! builder-util-runtime */ \"./node_modules/builder-util-runtime/out/index.js\");\nconst crypto_1 = __webpack_require__(/*! crypto */ \"crypto\");\nconst events_1 = __webpack_require__(/*! events */ \"events\");\nconst fs_extra_1 = __webpack_require__(/*! fs-extra */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/index.js\");\nconst js_yaml_1 = __webpack_require__(/*! js-yaml */ \"./node_modules/js-yaml/index.js\");\nconst lazy_val_1 = __webpack_require__(/*! lazy-val */ \"./node_modules/lazy-val/out/main.js\");\nconst path = __webpack_require__(/*! path */ \"path\");\nconst semver_1 = __webpack_require__(/*! semver */ \"./node_modules/semver/index.js\");\nconst DownloadedUpdateHelper_1 = __webpack_require__(/*! ./DownloadedUpdateHelper */ \"./node_modules/electron-updater/out/DownloadedUpdateHelper.js\");\nconst ElectronAppAdapter_1 = __webpack_require__(/*! ./ElectronAppAdapter */ \"./node_modules/electron-updater/out/ElectronAppAdapter.js\");\nconst electronHttpExecutor_1 = __webpack_require__(/*! ./electronHttpExecutor */ \"./node_modules/electron-updater/out/electronHttpExecutor.js\");\nconst GenericProvider_1 = __webpack_require__(/*! ./providers/GenericProvider */ \"./node_modules/electron-updater/out/providers/GenericProvider.js\");\nconst main_1 = __webpack_require__(/*! ./main */ \"./node_modules/electron-updater/out/main.js\");\nconst providerFactory_1 = __webpack_require__(/*! ./providerFactory */ \"./node_modules/electron-updater/out/providerFactory.js\");\nclass AppUpdater extends events_1.EventEmitter {\n    constructor(options, app) {\n        super();\n        /**\n         * Whether to automatically download an update when it is found.\n         */\n        this.autoDownload = true;\n        /**\n         * Whether to automatically install a downloaded update on app quit (if `quitAndInstall` was not called before).\n         */\n        this.autoInstallOnAppQuit = true;\n        /**\n         * *windows-only* Whether to run the app after finish install when run the installer NOT in silent mode.\n         * @default true\n         */\n        this.autoRunAppAfterInstall = true;\n        /**\n         * *GitHub provider only.* Whether to allow update to pre-release versions. Defaults to `true` if application version contains prerelease components (e.g. `0.12.1-alpha.1`, here `alpha` is a prerelease component), otherwise `false`.\n         *\n         * If `true`, downgrade will be allowed (`allowDowngrade` will be set to `true`).\n         */\n        this.allowPrerelease = false;\n        /**\n         * *GitHub provider only.* Get all release notes (from current version to latest), not just the latest.\n         * @default false\n         */\n        this.fullChangelog = false;\n        /**\n         * Whether to allow version downgrade (when a user from the beta channel wants to go back to the stable channel).\n         *\n         * Taken in account only if channel differs (pre-release version component in terms of semantic versioning).\n         *\n         * @default false\n         */\n        this.allowDowngrade = false;\n        /**\n         * Web installer files might not have signature verification, this switch prevents to load them unless it is needed.\n         *\n         * Currently false to prevent breaking the current API, but it should be changed to default true at some point that\n         * breaking changes are allowed.\n         *\n         * @default false\n         */\n        this.disableWebInstaller = false;\n        /**\n         * Allows developer to force the updater to work in \"dev\" mode, looking for \"dev-app-update.yml\" instead of \"app-update.yml\"\n         * Dev: `path.join(this.app.getAppPath(), \"dev-app-update.yml\")`\n         * Prod: `path.join(process.resourcesPath!, \"app-update.yml\")`\n         *\n         * @default false\n         */\n        this.forceDevUpdateConfig = false;\n        this._channel = null;\n        this.downloadedUpdateHelper = null;\n        /**\n         *  The request headers.\n         */\n        this.requestHeaders = null;\n        this._logger = console;\n        // noinspection JSUnusedGlobalSymbols\n        /**\n         * For type safety you can use signals, e.g. `autoUpdater.signals.updateDownloaded(() => {})` instead of `autoUpdater.on('update-available', () => {})`\n         */\n        this.signals = new main_1.UpdaterSignal(this);\n        this._appUpdateConfigPath = null;\n        this.clientPromise = null;\n        this.stagingUserIdPromise = new lazy_val_1.Lazy(() => this.getOrCreateStagingUserId());\n        // public, allow to read old config for anyone\n        /** @internal */\n        this.configOnDisk = new lazy_val_1.Lazy(() => this.loadUpdateConfig());\n        this.checkForUpdatesPromise = null;\n        this.updateInfoAndProvider = null;\n        /**\n         * @private\n         * @internal\n         */\n        this._testOnlyOptions = null;\n        this.on(\"error\", (error) => {\n            this._logger.error(`Error: ${error.stack || error.message}`);\n        });\n        if (app == null) {\n            this.app = new ElectronAppAdapter_1.ElectronAppAdapter();\n            this.httpExecutor = new electronHttpExecutor_1.ElectronHttpExecutor((authInfo, callback) => this.emit(\"login\", authInfo, callback));\n        }\n        else {\n            this.app = app;\n            this.httpExecutor = null;\n        }\n        const currentVersionString = this.app.version;\n        const currentVersion = (0, semver_1.parse)(currentVersionString);\n        if (currentVersion == null) {\n            throw (0, builder_util_runtime_1.newError)(`App version is not a valid semver version: \"${currentVersionString}\"`, \"ERR_UPDATER_INVALID_VERSION\");\n        }\n        this.currentVersion = currentVersion;\n        this.allowPrerelease = hasPrereleaseComponents(currentVersion);\n        if (options != null) {\n            this.setFeedURL(options);\n            if (typeof options !== \"string\" && options.requestHeaders) {\n                this.requestHeaders = options.requestHeaders;\n            }\n        }\n    }\n    /**\n     * Get the update channel. Not applicable for GitHub. Doesn't return `channel` from the update configuration, only if was previously set.\n     */\n    get channel() {\n        return this._channel;\n    }\n    /**\n     * Set the update channel. Not applicable for GitHub. Overrides `channel` in the update configuration.\n     *\n     * `allowDowngrade` will be automatically set to `true`. If this behavior is not suitable for you, simple set `allowDowngrade` explicitly after.\n     */\n    set channel(value) {\n        if (this._channel != null) {\n            // noinspection SuspiciousTypeOfGuard\n            if (typeof value !== \"string\") {\n                throw (0, builder_util_runtime_1.newError)(`Channel must be a string, but got: ${value}`, \"ERR_UPDATER_INVALID_CHANNEL\");\n            }\n            else if (value.length === 0) {\n                throw (0, builder_util_runtime_1.newError)(`Channel must be not an empty string`, \"ERR_UPDATER_INVALID_CHANNEL\");\n            }\n        }\n        this._channel = value;\n        this.allowDowngrade = true;\n    }\n    /**\n     *  Shortcut for explicitly adding auth tokens to request headers\n     */\n    addAuthHeader(token) {\n        this.requestHeaders = Object.assign({}, this.requestHeaders, {\n            authorization: token,\n        });\n    }\n    // noinspection JSMethodCanBeStatic,JSUnusedGlobalSymbols\n    get netSession() {\n        return (0, electronHttpExecutor_1.getNetSession)();\n    }\n    /**\n     * The logger. You can pass [electron-log](https://github.com/megahertz/electron-log), [winston](https://github.com/winstonjs/winston) or another logger with the following interface: `{ info(), warn(), error() }`.\n     * Set it to `null` if you would like to disable a logging feature.\n     */\n    get logger() {\n        return this._logger;\n    }\n    set logger(value) {\n        this._logger = value == null ? new NoOpLogger() : value;\n    }\n    // noinspection JSUnusedGlobalSymbols\n    /**\n     * test only\n     * @private\n     */\n    set updateConfigPath(value) {\n        this.clientPromise = null;\n        this._appUpdateConfigPath = value;\n        this.configOnDisk = new lazy_val_1.Lazy(() => this.loadUpdateConfig());\n    }\n    //noinspection JSMethodCanBeStatic,JSUnusedGlobalSymbols\n    getFeedURL() {\n        return \"Deprecated. Do not use it.\";\n    }\n    /**\n     * Configure update provider. If value is `string`, [GenericServerOptions](/configuration/publish#genericserveroptions) will be set with value as `url`.\n     * @param options If you want to override configuration in the `app-update.yml`.\n     */\n    setFeedURL(options) {\n        const runtimeOptions = this.createProviderRuntimeOptions();\n        // https://github.com/electron-userland/electron-builder/issues/1105\n        let provider;\n        if (typeof options === \"string\") {\n            provider = new GenericProvider_1.GenericProvider({ provider: \"generic\", url: options }, this, {\n                ...runtimeOptions,\n                isUseMultipleRangeRequest: (0, providerFactory_1.isUrlProbablySupportMultiRangeRequests)(options),\n            });\n        }\n        else {\n            provider = (0, providerFactory_1.createClient)(options, this, runtimeOptions);\n        }\n        this.clientPromise = Promise.resolve(provider);\n    }\n    /**\n     * Asks the server whether there is an update.\n     */\n    checkForUpdates() {\n        if (!this.isUpdaterActive()) {\n            return Promise.resolve(null);\n        }\n        let checkForUpdatesPromise = this.checkForUpdatesPromise;\n        if (checkForUpdatesPromise != null) {\n            this._logger.info(\"Checking for update (already in progress)\");\n            return checkForUpdatesPromise;\n        }\n        const nullizePromise = () => (this.checkForUpdatesPromise = null);\n        this._logger.info(\"Checking for update\");\n        checkForUpdatesPromise = this.doCheckForUpdates()\n            .then(it => {\n            nullizePromise();\n            return it;\n        })\n            .catch((e) => {\n            nullizePromise();\n            this.emit(\"error\", e, `Cannot check for updates: ${(e.stack || e).toString()}`);\n            throw e;\n        });\n        this.checkForUpdatesPromise = checkForUpdatesPromise;\n        return checkForUpdatesPromise;\n    }\n    isUpdaterActive() {\n        const isEnabled = this.app.isPackaged || this.forceDevUpdateConfig;\n        if (!isEnabled) {\n            this._logger.info(\"Skip checkForUpdates because application is not packed and dev update config is not forced\");\n            return false;\n        }\n        return true;\n    }\n    // noinspection JSUnusedGlobalSymbols\n    checkForUpdatesAndNotify(downloadNotification) {\n        return this.checkForUpdates().then(it => {\n            if (!(it === null || it === void 0 ? void 0 : it.downloadPromise)) {\n                if (this._logger.debug != null) {\n                    this._logger.debug(\"checkForUpdatesAndNotify called, downloadPromise is null\");\n                }\n                return it;\n            }\n            void it.downloadPromise.then(() => {\n                const notificationContent = AppUpdater.formatDownloadNotification(it.updateInfo.version, this.app.name, downloadNotification);\n                new ((__webpack_require__(/*! electron */ \"electron\").Notification))(notificationContent).show();\n            });\n            return it;\n        });\n    }\n    static formatDownloadNotification(version, appName, downloadNotification) {\n        if (downloadNotification == null) {\n            downloadNotification = {\n                title: \"A new update is ready to install\",\n                body: `{appName} version {version} has been downloaded and will be automatically installed on exit`,\n            };\n        }\n        downloadNotification = {\n            title: downloadNotification.title.replace(\"{appName}\", appName).replace(\"{version}\", version),\n            body: downloadNotification.body.replace(\"{appName}\", appName).replace(\"{version}\", version),\n        };\n        return downloadNotification;\n    }\n    async isStagingMatch(updateInfo) {\n        const rawStagingPercentage = updateInfo.stagingPercentage;\n        let stagingPercentage = rawStagingPercentage;\n        if (stagingPercentage == null) {\n            return true;\n        }\n        stagingPercentage = parseInt(stagingPercentage, 10);\n        if (isNaN(stagingPercentage)) {\n            this._logger.warn(`Staging percentage is NaN: ${rawStagingPercentage}`);\n            return true;\n        }\n        // convert from user 0-100 to internal 0-1\n        stagingPercentage = stagingPercentage / 100;\n        const stagingUserId = await this.stagingUserIdPromise.value;\n        const val = builder_util_runtime_1.UUID.parse(stagingUserId).readUInt32BE(12);\n        const percentage = val / 0xffffffff;\n        this._logger.info(`Staging percentage: ${stagingPercentage}, percentage: ${percentage}, user id: ${stagingUserId}`);\n        return percentage < stagingPercentage;\n    }\n    computeFinalHeaders(headers) {\n        if (this.requestHeaders != null) {\n            Object.assign(headers, this.requestHeaders);\n        }\n        return headers;\n    }\n    async isUpdateAvailable(updateInfo) {\n        const latestVersion = (0, semver_1.parse)(updateInfo.version);\n        if (latestVersion == null) {\n            throw (0, builder_util_runtime_1.newError)(`This file could not be downloaded, or the latest version (from update server) does not have a valid semver version: \"${updateInfo.version}\"`, \"ERR_UPDATER_INVALID_VERSION\");\n        }\n        const currentVersion = this.currentVersion;\n        if ((0, semver_1.eq)(latestVersion, currentVersion)) {\n            return false;\n        }\n        const isStagingMatch = await this.isStagingMatch(updateInfo);\n        if (!isStagingMatch) {\n            return false;\n        }\n        // https://github.com/electron-userland/electron-builder/pull/3111#issuecomment-405033227\n        // https://github.com/electron-userland/electron-builder/pull/3111#issuecomment-405030797\n        const isLatestVersionNewer = (0, semver_1.gt)(latestVersion, currentVersion);\n        const isLatestVersionOlder = (0, semver_1.lt)(latestVersion, currentVersion);\n        if (isLatestVersionNewer) {\n            return true;\n        }\n        return this.allowDowngrade && isLatestVersionOlder;\n    }\n    async getUpdateInfoAndProvider() {\n        await this.app.whenReady();\n        if (this.clientPromise == null) {\n            this.clientPromise = this.configOnDisk.value.then(it => (0, providerFactory_1.createClient)(it, this, this.createProviderRuntimeOptions()));\n        }\n        const client = await this.clientPromise;\n        const stagingUserId = await this.stagingUserIdPromise.value;\n        client.setRequestHeaders(this.computeFinalHeaders({ \"x-user-staging-id\": stagingUserId }));\n        return {\n            info: await client.getLatestVersion(),\n            provider: client,\n        };\n    }\n    // eslint-disable-next-line @typescript-eslint/explicit-function-return-type\n    createProviderRuntimeOptions() {\n        return {\n            isUseMultipleRangeRequest: true,\n            platform: this._testOnlyOptions == null ? process.platform : this._testOnlyOptions.platform,\n            executor: this.httpExecutor,\n        };\n    }\n    async doCheckForUpdates() {\n        this.emit(\"checking-for-update\");\n        const result = await this.getUpdateInfoAndProvider();\n        const updateInfo = result.info;\n        if (!(await this.isUpdateAvailable(updateInfo))) {\n            this._logger.info(`Update for version ${this.currentVersion} is not available (latest version: ${updateInfo.version}, downgrade is ${this.allowDowngrade ? \"allowed\" : \"disallowed\"}).`);\n            this.emit(\"update-not-available\", updateInfo);\n            return {\n                versionInfo: updateInfo,\n                updateInfo,\n            };\n        }\n        this.updateInfoAndProvider = result;\n        this.onUpdateAvailable(updateInfo);\n        const cancellationToken = new builder_util_runtime_1.CancellationToken();\n        //noinspection ES6MissingAwait\n        return {\n            versionInfo: updateInfo,\n            updateInfo,\n            cancellationToken,\n            downloadPromise: this.autoDownload ? this.downloadUpdate(cancellationToken) : null,\n        };\n    }\n    onUpdateAvailable(updateInfo) {\n        this._logger.info(`Found version ${updateInfo.version} (url: ${(0, builder_util_runtime_1.asArray)(updateInfo.files)\n            .map(it => it.url)\n            .join(\", \")})`);\n        this.emit(\"update-available\", updateInfo);\n    }\n    /**\n     * Start downloading update manually. You can use this method if `autoDownload` option is set to `false`.\n     * @returns {Promise<Array<string>>} Paths to downloaded files.\n     */\n    downloadUpdate(cancellationToken = new builder_util_runtime_1.CancellationToken()) {\n        const updateInfoAndProvider = this.updateInfoAndProvider;\n        if (updateInfoAndProvider == null) {\n            const error = new Error(\"Please check update first\");\n            this.dispatchError(error);\n            return Promise.reject(error);\n        }\n        this._logger.info(`Downloading update from ${(0, builder_util_runtime_1.asArray)(updateInfoAndProvider.info.files)\n            .map(it => it.url)\n            .join(\", \")}`);\n        const errorHandler = (e) => {\n            // https://github.com/electron-userland/electron-builder/issues/1150#issuecomment-436891159\n            if (!(e instanceof builder_util_runtime_1.CancellationError)) {\n                try {\n                    this.dispatchError(e);\n                }\n                catch (nestedError) {\n                    this._logger.warn(`Cannot dispatch error event: ${nestedError.stack || nestedError}`);\n                }\n            }\n            return e;\n        };\n        try {\n            return this.doDownloadUpdate({\n                updateInfoAndProvider,\n                requestHeaders: this.computeRequestHeaders(updateInfoAndProvider.provider),\n                cancellationToken,\n                disableWebInstaller: this.disableWebInstaller,\n            }).catch((e) => {\n                throw errorHandler(e);\n            });\n        }\n        catch (e) {\n            return Promise.reject(errorHandler(e));\n        }\n    }\n    dispatchError(e) {\n        this.emit(\"error\", e, (e.stack || e).toString());\n    }\n    dispatchUpdateDownloaded(event) {\n        this.emit(main_1.UPDATE_DOWNLOADED, event);\n    }\n    async loadUpdateConfig() {\n        if (this._appUpdateConfigPath == null) {\n            this._appUpdateConfigPath = this.app.appUpdateConfigPath;\n        }\n        return (0, js_yaml_1.load)(await (0, fs_extra_1.readFile)(this._appUpdateConfigPath, \"utf-8\"));\n    }\n    computeRequestHeaders(provider) {\n        const fileExtraDownloadHeaders = provider.fileExtraDownloadHeaders;\n        if (fileExtraDownloadHeaders != null) {\n            const requestHeaders = this.requestHeaders;\n            return requestHeaders == null\n                ? fileExtraDownloadHeaders\n                : {\n                    ...fileExtraDownloadHeaders,\n                    ...requestHeaders,\n                };\n        }\n        return this.computeFinalHeaders({ accept: \"*/*\" });\n    }\n    async getOrCreateStagingUserId() {\n        const file = path.join(this.app.userDataPath, \".updaterId\");\n        try {\n            const id = await (0, fs_extra_1.readFile)(file, \"utf-8\");\n            if (builder_util_runtime_1.UUID.check(id)) {\n                return id;\n            }\n            else {\n                this._logger.warn(`Staging user id file exists, but content was invalid: ${id}`);\n            }\n        }\n        catch (e) {\n            if (e.code !== \"ENOENT\") {\n                this._logger.warn(`Couldn't read staging user ID, creating a blank one: ${e}`);\n            }\n        }\n        const id = builder_util_runtime_1.UUID.v5((0, crypto_1.randomBytes)(4096), builder_util_runtime_1.UUID.OID);\n        this._logger.info(`Generated new staging user ID: ${id}`);\n        try {\n            await (0, fs_extra_1.outputFile)(file, id);\n        }\n        catch (e) {\n            this._logger.warn(`Couldn't write out staging user ID: ${e}`);\n        }\n        return id;\n    }\n    /** @internal */\n    get isAddNoCacheQuery() {\n        const headers = this.requestHeaders;\n        // https://github.com/electron-userland/electron-builder/issues/3021\n        if (headers == null) {\n            return true;\n        }\n        for (const headerName of Object.keys(headers)) {\n            const s = headerName.toLowerCase();\n            if (s === \"authorization\" || s === \"private-token\") {\n                return false;\n            }\n        }\n        return true;\n    }\n    async getOrCreateDownloadHelper() {\n        let result = this.downloadedUpdateHelper;\n        if (result == null) {\n            const dirName = (await this.configOnDisk.value).updaterCacheDirName;\n            const logger = this._logger;\n            if (dirName == null) {\n                logger.error(\"updaterCacheDirName is not specified in app-update.yml Was app build using at least electron-builder 20.34.0?\");\n            }\n            const cacheDir = path.join(this.app.baseCachePath, dirName || this.app.name);\n            if (logger.debug != null) {\n                logger.debug(`updater cache dir: ${cacheDir}`);\n            }\n            result = new DownloadedUpdateHelper_1.DownloadedUpdateHelper(cacheDir);\n            this.downloadedUpdateHelper = result;\n        }\n        return result;\n    }\n    async executeDownload(taskOptions) {\n        const fileInfo = taskOptions.fileInfo;\n        const downloadOptions = {\n            headers: taskOptions.downloadUpdateOptions.requestHeaders,\n            cancellationToken: taskOptions.downloadUpdateOptions.cancellationToken,\n            sha2: fileInfo.info.sha2,\n            sha512: fileInfo.info.sha512,\n        };\n        if (this.listenerCount(main_1.DOWNLOAD_PROGRESS) > 0) {\n            downloadOptions.onProgress = it => this.emit(main_1.DOWNLOAD_PROGRESS, it);\n        }\n        const updateInfo = taskOptions.downloadUpdateOptions.updateInfoAndProvider.info;\n        const version = updateInfo.version;\n        const packageInfo = fileInfo.packageInfo;\n        function getCacheUpdateFileName() {\n            // NodeJS URL doesn't decode automatically\n            const urlPath = decodeURIComponent(taskOptions.fileInfo.url.pathname);\n            if (urlPath.endsWith(`.${taskOptions.fileExtension}`)) {\n                return path.basename(urlPath);\n            }\n            else {\n                // url like /latest, generate name\n                return taskOptions.fileInfo.info.url;\n            }\n        }\n        const downloadedUpdateHelper = await this.getOrCreateDownloadHelper();\n        const cacheDir = downloadedUpdateHelper.cacheDirForPendingUpdate;\n        await (0, fs_extra_1.mkdir)(cacheDir, { recursive: true });\n        const updateFileName = getCacheUpdateFileName();\n        let updateFile = path.join(cacheDir, updateFileName);\n        const packageFile = packageInfo == null ? null : path.join(cacheDir, `package-${version}${path.extname(packageInfo.path) || \".7z\"}`);\n        const done = async (isSaveCache) => {\n            await downloadedUpdateHelper.setDownloadedFile(updateFile, packageFile, updateInfo, fileInfo, updateFileName, isSaveCache);\n            await taskOptions.done({\n                ...updateInfo,\n                downloadedFile: updateFile,\n            });\n            return packageFile == null ? [updateFile] : [updateFile, packageFile];\n        };\n        const log = this._logger;\n        const cachedUpdateFile = await downloadedUpdateHelper.validateDownloadedPath(updateFile, updateInfo, fileInfo, log);\n        if (cachedUpdateFile != null) {\n            updateFile = cachedUpdateFile;\n            return await done(false);\n        }\n        const removeFileIfAny = async () => {\n            await downloadedUpdateHelper.clear().catch(() => {\n                // ignore\n            });\n            return await (0, fs_extra_1.unlink)(updateFile).catch(() => {\n                // ignore\n            });\n        };\n        const tempUpdateFile = await (0, DownloadedUpdateHelper_1.createTempUpdateFile)(`temp-${updateFileName}`, cacheDir, log);\n        try {\n            await taskOptions.task(tempUpdateFile, downloadOptions, packageFile, removeFileIfAny);\n            await (0, fs_extra_1.rename)(tempUpdateFile, updateFile);\n        }\n        catch (e) {\n            await removeFileIfAny();\n            if (e instanceof builder_util_runtime_1.CancellationError) {\n                log.info(\"cancelled\");\n                this.emit(\"update-cancelled\", updateInfo);\n            }\n            throw e;\n        }\n        log.info(`New version ${version} has been downloaded to ${updateFile}`);\n        return await done(true);\n    }\n}\nexports.AppUpdater = AppUpdater;\nfunction hasPrereleaseComponents(version) {\n    const versionPrereleaseComponent = (0, semver_1.prerelease)(version);\n    return versionPrereleaseComponent != null && versionPrereleaseComponent.length > 0;\n}\n/** @private */\nclass NoOpLogger {\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    info(message) {\n        // ignore\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    warn(message) {\n        // ignore\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    error(message) {\n        // ignore\n    }\n}\nexports.NoOpLogger = NoOpLogger;\n//# sourceMappingURL=AppUpdater.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/AppUpdater.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/BaseUpdater.js":
/*!**********************************************************!*\
  !*** ./node_modules/electron-updater/out/BaseUpdater.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.BaseUpdater = void 0;\nconst child_process_1 = __webpack_require__(/*! child_process */ \"child_process\");\nconst AppUpdater_1 = __webpack_require__(/*! ./AppUpdater */ \"./node_modules/electron-updater/out/AppUpdater.js\");\nclass BaseUpdater extends AppUpdater_1.AppUpdater {\n    constructor(options, app) {\n        super(options, app);\n        this.quitAndInstallCalled = false;\n        this.quitHandlerAdded = false;\n    }\n    quitAndInstall(isSilent = false, isForceRunAfter = false) {\n        this._logger.info(`Install on explicit quitAndInstall`);\n        // If NOT in silent mode use `autoRunAppAfterInstall` to determine whether to force run the app\n        const isInstalled = this.install(isSilent, isSilent ? isForceRunAfter : this.autoRunAppAfterInstall);\n        if (isInstalled) {\n            setImmediate(() => {\n                // this event is normally emitted when calling quitAndInstall, this emulates that\n                (__webpack_require__(/*! electron */ \"electron\").autoUpdater.emit)(\"before-quit-for-update\");\n                this.app.quit();\n            });\n        }\n        else {\n            this.quitAndInstallCalled = false;\n        }\n    }\n    executeDownload(taskOptions) {\n        return super.executeDownload({\n            ...taskOptions,\n            done: event => {\n                this.dispatchUpdateDownloaded(event);\n                this.addQuitHandler();\n                return Promise.resolve();\n            },\n        });\n    }\n    // must be sync (because quit even handler is not async)\n    install(isSilent = false, isForceRunAfter = false) {\n        if (this.quitAndInstallCalled) {\n            this._logger.warn(\"install call ignored: quitAndInstallCalled is set to true\");\n            return false;\n        }\n        const downloadedUpdateHelper = this.downloadedUpdateHelper;\n        const installerPath = downloadedUpdateHelper == null ? null : downloadedUpdateHelper.file;\n        const downloadedFileInfo = downloadedUpdateHelper == null ? null : downloadedUpdateHelper.downloadedFileInfo;\n        if (installerPath == null || downloadedFileInfo == null) {\n            this.dispatchError(new Error(\"No valid update available, can't quit and install\"));\n            return false;\n        }\n        // prevent calling several times\n        this.quitAndInstallCalled = true;\n        try {\n            this._logger.info(`Install: isSilent: ${isSilent}, isForceRunAfter: ${isForceRunAfter}`);\n            return this.doInstall({\n                installerPath,\n                isSilent,\n                isForceRunAfter,\n                isAdminRightsRequired: downloadedFileInfo.isAdminRightsRequired,\n            });\n        }\n        catch (e) {\n            this.dispatchError(e);\n            return false;\n        }\n    }\n    addQuitHandler() {\n        if (this.quitHandlerAdded || !this.autoInstallOnAppQuit) {\n            return;\n        }\n        this.quitHandlerAdded = true;\n        this.app.onQuit(exitCode => {\n            if (this.quitAndInstallCalled) {\n                this._logger.info(\"Update installer has already been triggered. Quitting application.\");\n                return;\n            }\n            if (!this.autoInstallOnAppQuit) {\n                this._logger.info(\"Update will not be installed on quit because autoInstallOnAppQuit is set to false.\");\n                return;\n            }\n            if (exitCode !== 0) {\n                this._logger.info(`Update will be not installed on quit because application is quitting with exit code ${exitCode}`);\n                return;\n            }\n            this._logger.info(\"Auto install update on quit\");\n            this.install(true, false);\n        });\n    }\n    wrapSudo() {\n        const { name } = this.app;\n        const installComment = `\"${name} would like to update\"`;\n        const sudo = this.spawnSyncLog(\"which gksudo || which kdesudo || which pkexec || which beesu\");\n        const command = [sudo];\n        if (/kdesudo/i.test(sudo)) {\n            command.push(\"--comment\", installComment);\n            command.push(\"-c\");\n        }\n        else if (/gksudo/i.test(sudo)) {\n            command.push(\"--message\", installComment);\n        }\n        else if (/pkexec/i.test(sudo)) {\n            command.push(\"--disable-internal-agent\");\n        }\n        return command.join(\" \");\n    }\n    spawnSyncLog(cmd, args = [], env = {}) {\n        this._logger.info(`Executing: ${cmd} with args: ${args}`);\n        const response = (0, child_process_1.spawnSync)(cmd, args, {\n            env: { ...process.env, ...env },\n            encoding: \"utf-8\",\n            shell: true,\n        });\n        return response.stdout.trim();\n    }\n    /**\n     * This handles both node 8 and node 10 way of emitting error when spawning a process\n     *   - node 8: Throws the error\n     *   - node 10: Emit the error(Need to listen with on)\n     */\n    // https://github.com/electron-userland/electron-builder/issues/1129\n    // Node 8 sends errors: https://nodejs.org/dist/latest-v8.x/docs/api/errors.html#errors_common_system_errors\n    async spawnLog(cmd, args = [], env = undefined, stdio = \"ignore\") {\n        this._logger.info(`Executing: ${cmd} with args: ${args}`);\n        return new Promise((resolve, reject) => {\n            try {\n                const params = { stdio, env, detached: true };\n                const p = (0, child_process_1.spawn)(cmd, args, params);\n                p.on(\"error\", error => {\n                    reject(error);\n                });\n                p.unref();\n                if (p.pid !== undefined) {\n                    resolve(true);\n                }\n            }\n            catch (error) {\n                reject(error);\n            }\n        });\n    }\n}\nexports.BaseUpdater = BaseUpdater;\n//# sourceMappingURL=BaseUpdater.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/BaseUpdater.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/DebUpdater.js":
/*!*********************************************************!*\
  !*** ./node_modules/electron-updater/out/DebUpdater.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DebUpdater = void 0;\nconst BaseUpdater_1 = __webpack_require__(/*! ./BaseUpdater */ \"./node_modules/electron-updater/out/BaseUpdater.js\");\nconst main_1 = __webpack_require__(/*! ./main */ \"./node_modules/electron-updater/out/main.js\");\nconst Provider_1 = __webpack_require__(/*! ./providers/Provider */ \"./node_modules/electron-updater/out/providers/Provider.js\");\nclass DebUpdater extends BaseUpdater_1.BaseUpdater {\n    constructor(options, app) {\n        super(options, app);\n    }\n    /*** @private */\n    doDownloadUpdate(downloadUpdateOptions) {\n        const provider = downloadUpdateOptions.updateInfoAndProvider.provider;\n        const fileInfo = (0, Provider_1.findFile)(provider.resolveFiles(downloadUpdateOptions.updateInfoAndProvider.info), \"deb\", [\"AppImage\", \"rpm\"]);\n        return this.executeDownload({\n            fileExtension: \"deb\",\n            fileInfo,\n            downloadUpdateOptions,\n            task: async (updateFile, downloadOptions) => {\n                if (this.listenerCount(main_1.DOWNLOAD_PROGRESS) > 0) {\n                    downloadOptions.onProgress = it => this.emit(main_1.DOWNLOAD_PROGRESS, it);\n                }\n                await this.httpExecutor.download(fileInfo.url, updateFile, downloadOptions);\n            },\n        });\n    }\n    doInstall(options) {\n        const sudo = this.wrapSudo();\n        // pkexec doesn't want the command to be wrapped in \" quotes\n        const wrapper = /pkexec/i.test(sudo) ? \"\" : `\"`;\n        const cmd = [\"dpkg\", \"-i\", options.installerPath, \"||\", \"apt-get\", \"install\", \"-f\", \"-y\"];\n        this.spawnSyncLog(sudo, [`${wrapper}/bin/bash`, \"-c\", `'${cmd.join(\" \")}'${wrapper}`]);\n        if (options.isForceRunAfter) {\n            this.app.relaunch();\n        }\n        return true;\n    }\n}\nexports.DebUpdater = DebUpdater;\n//# sourceMappingURL=DebUpdater.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/DebUpdater.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/DownloadedUpdateHelper.js":
/*!*********************************************************************!*\
  !*** ./node_modules/electron-updater/out/DownloadedUpdateHelper.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.createTempUpdateFile = exports.DownloadedUpdateHelper = void 0;\nconst crypto_1 = __webpack_require__(/*! crypto */ \"crypto\");\nconst fs_1 = __webpack_require__(/*! fs */ \"fs\");\n// @ts-ignore\nconst isEqual = __webpack_require__(/*! lodash.isequal */ \"./node_modules/lodash.isequal/index.js\");\nconst fs_extra_1 = __webpack_require__(/*! fs-extra */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/index.js\");\nconst path = __webpack_require__(/*! path */ \"path\");\n/** @private **/\nclass DownloadedUpdateHelper {\n    constructor(cacheDir) {\n        this.cacheDir = cacheDir;\n        this._file = null;\n        this._packageFile = null;\n        this.versionInfo = null;\n        this.fileInfo = null;\n        this._downloadedFileInfo = null;\n    }\n    get downloadedFileInfo() {\n        return this._downloadedFileInfo;\n    }\n    get file() {\n        return this._file;\n    }\n    get packageFile() {\n        return this._packageFile;\n    }\n    get cacheDirForPendingUpdate() {\n        return path.join(this.cacheDir, \"pending\");\n    }\n    async validateDownloadedPath(updateFile, updateInfo, fileInfo, logger) {\n        if (this.versionInfo != null && this.file === updateFile && this.fileInfo != null) {\n            // update has already been downloaded from this running instance\n            // check here only existence, not checksum\n            if (isEqual(this.versionInfo, updateInfo) && isEqual(this.fileInfo.info, fileInfo.info) && (await (0, fs_extra_1.pathExists)(updateFile))) {\n                return updateFile;\n            }\n            else {\n                return null;\n            }\n        }\n        // update has already been downloaded from some previous app launch\n        const cachedUpdateFile = await this.getValidCachedUpdateFile(fileInfo, logger);\n        if (cachedUpdateFile === null) {\n            return null;\n        }\n        logger.info(`Update has already been downloaded to ${updateFile}).`);\n        this._file = cachedUpdateFile;\n        return cachedUpdateFile;\n    }\n    async setDownloadedFile(downloadedFile, packageFile, versionInfo, fileInfo, updateFileName, isSaveCache) {\n        this._file = downloadedFile;\n        this._packageFile = packageFile;\n        this.versionInfo = versionInfo;\n        this.fileInfo = fileInfo;\n        this._downloadedFileInfo = {\n            fileName: updateFileName,\n            sha512: fileInfo.info.sha512,\n            isAdminRightsRequired: fileInfo.info.isAdminRightsRequired === true,\n        };\n        if (isSaveCache) {\n            await (0, fs_extra_1.outputJson)(this.getUpdateInfoFile(), this._downloadedFileInfo);\n        }\n    }\n    async clear() {\n        this._file = null;\n        this._packageFile = null;\n        this.versionInfo = null;\n        this.fileInfo = null;\n        await this.cleanCacheDirForPendingUpdate();\n    }\n    async cleanCacheDirForPendingUpdate() {\n        try {\n            // remove stale data\n            await (0, fs_extra_1.emptyDir)(this.cacheDirForPendingUpdate);\n        }\n        catch (ignore) {\n            // ignore\n        }\n    }\n    /**\n     * Returns \"update-info.json\" which is created in the update cache directory's \"pending\" subfolder after the first update is downloaded.  If the update file does not exist then the cache is cleared and recreated.  If the update file exists then its properties are validated.\n     * @param fileInfo\n     * @param logger\n     */\n    async getValidCachedUpdateFile(fileInfo, logger) {\n        var _a;\n        const updateInfoFilePath = this.getUpdateInfoFile();\n        const doesUpdateInfoFileExist = await (0, fs_extra_1.pathExists)(updateInfoFilePath);\n        if (!doesUpdateInfoFileExist) {\n            return null;\n        }\n        let cachedInfo;\n        try {\n            cachedInfo = await (0, fs_extra_1.readJson)(updateInfoFilePath);\n        }\n        catch (error) {\n            let message = `No cached update info available`;\n            if (error.code !== \"ENOENT\") {\n                await this.cleanCacheDirForPendingUpdate();\n                message += ` (error on read: ${error.message})`;\n            }\n            logger.info(message);\n            return null;\n        }\n        const isCachedInfoFileNameValid = (_a = (cachedInfo === null || cachedInfo === void 0 ? void 0 : cachedInfo.fileName) !== null) !== null && _a !== void 0 ? _a : false;\n        if (!isCachedInfoFileNameValid) {\n            logger.warn(`Cached update info is corrupted: no fileName, directory for cached update will be cleaned`);\n            await this.cleanCacheDirForPendingUpdate();\n            return null;\n        }\n        if (fileInfo.info.sha512 !== cachedInfo.sha512) {\n            logger.info(`Cached update sha512 checksum doesn't match the latest available update. New update must be downloaded. Cached: ${cachedInfo.sha512}, expected: ${fileInfo.info.sha512}. Directory for cached update will be cleaned`);\n            await this.cleanCacheDirForPendingUpdate();\n            return null;\n        }\n        const updateFile = path.join(this.cacheDirForPendingUpdate, cachedInfo.fileName);\n        if (!(await (0, fs_extra_1.pathExists)(updateFile))) {\n            logger.info(\"Cached update file doesn't exist\");\n            return null;\n        }\n        const sha512 = await hashFile(updateFile);\n        if (fileInfo.info.sha512 !== sha512) {\n            logger.warn(`Sha512 checksum doesn't match the latest available update. New update must be downloaded. Cached: ${sha512}, expected: ${fileInfo.info.sha512}`);\n            await this.cleanCacheDirForPendingUpdate();\n            return null;\n        }\n        this._downloadedFileInfo = cachedInfo;\n        return updateFile;\n    }\n    getUpdateInfoFile() {\n        return path.join(this.cacheDirForPendingUpdate, \"update-info.json\");\n    }\n}\nexports.DownloadedUpdateHelper = DownloadedUpdateHelper;\nfunction hashFile(file, algorithm = \"sha512\", encoding = \"base64\", options) {\n    return new Promise((resolve, reject) => {\n        const hash = (0, crypto_1.createHash)(algorithm);\n        hash.on(\"error\", reject).setEncoding(encoding);\n        (0, fs_1.createReadStream)(file, { ...options, highWaterMark: 1024 * 1024 /* better to use more memory but hash faster */ })\n            .on(\"error\", reject)\n            .on(\"end\", () => {\n            hash.end();\n            resolve(hash.read());\n        })\n            .pipe(hash, { end: false });\n    });\n}\nasync function createTempUpdateFile(name, cacheDir, log) {\n    // https://github.com/electron-userland/electron-builder/pull/2474#issuecomment-366481912\n    let nameCounter = 0;\n    let result = path.join(cacheDir, name);\n    for (let i = 0; i < 3; i++) {\n        try {\n            await (0, fs_extra_1.unlink)(result);\n            return result;\n        }\n        catch (e) {\n            if (e.code === \"ENOENT\") {\n                return result;\n            }\n            log.warn(`Error on remove temp update file: ${e}`);\n            result = path.join(cacheDir, `${nameCounter++}-${name}`);\n        }\n    }\n    return result;\n}\nexports.createTempUpdateFile = createTempUpdateFile;\n//# sourceMappingURL=DownloadedUpdateHelper.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/DownloadedUpdateHelper.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/ElectronAppAdapter.js":
/*!*****************************************************************!*\
  !*** ./node_modules/electron-updater/out/ElectronAppAdapter.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ElectronAppAdapter = void 0;\nconst path = __webpack_require__(/*! path */ \"path\");\nconst AppAdapter_1 = __webpack_require__(/*! ./AppAdapter */ \"./node_modules/electron-updater/out/AppAdapter.js\");\nclass ElectronAppAdapter {\n    constructor(app = (__webpack_require__(/*! electron */ \"electron\").app)) {\n        this.app = app;\n    }\n    whenReady() {\n        return this.app.whenReady();\n    }\n    get version() {\n        return this.app.getVersion();\n    }\n    get name() {\n        return this.app.getName();\n    }\n    get isPackaged() {\n        return this.app.isPackaged === true;\n    }\n    get appUpdateConfigPath() {\n        return this.isPackaged ? path.join(process.resourcesPath, \"app-update.yml\") : path.join(this.app.getAppPath(), \"dev-app-update.yml\");\n    }\n    get userDataPath() {\n        return this.app.getPath(\"userData\");\n    }\n    get baseCachePath() {\n        return (0, AppAdapter_1.getAppCacheDir)();\n    }\n    quit() {\n        this.app.quit();\n    }\n    relaunch() {\n        this.app.relaunch();\n    }\n    onQuit(handler) {\n        this.app.once(\"quit\", (_, exitCode) => handler(exitCode));\n    }\n}\nexports.ElectronAppAdapter = ElectronAppAdapter;\n//# sourceMappingURL=ElectronAppAdapter.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/ElectronAppAdapter.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/MacUpdater.js":
/*!*********************************************************!*\
  !*** ./node_modules/electron-updater/out/MacUpdater.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MacUpdater = void 0;\nconst builder_util_runtime_1 = __webpack_require__(/*! builder-util-runtime */ \"./node_modules/builder-util-runtime/out/index.js\");\nconst fs_extra_1 = __webpack_require__(/*! fs-extra */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/index.js\");\nconst fs_1 = __webpack_require__(/*! fs */ \"fs\");\nconst http_1 = __webpack_require__(/*! http */ \"http\");\nconst AppUpdater_1 = __webpack_require__(/*! ./AppUpdater */ \"./node_modules/electron-updater/out/AppUpdater.js\");\nconst Provider_1 = __webpack_require__(/*! ./providers/Provider */ \"./node_modules/electron-updater/out/providers/Provider.js\");\nconst child_process_1 = __webpack_require__(/*! child_process */ \"child_process\");\nconst crypto_1 = __webpack_require__(/*! crypto */ \"crypto\");\nclass MacUpdater extends AppUpdater_1.AppUpdater {\n    constructor(options, app) {\n        super(options, app);\n        this.nativeUpdater = (__webpack_require__(/*! electron */ \"electron\").autoUpdater);\n        this.squirrelDownloadedUpdate = false;\n        this.nativeUpdater.on(\"error\", it => {\n            this._logger.warn(it);\n            this.emit(\"error\", it);\n        });\n        this.nativeUpdater.on(\"update-downloaded\", () => {\n            this.squirrelDownloadedUpdate = true;\n        });\n    }\n    debug(message) {\n        if (this._logger.debug != null) {\n            this._logger.debug(message);\n        }\n    }\n    async doDownloadUpdate(downloadUpdateOptions) {\n        let files = downloadUpdateOptions.updateInfoAndProvider.provider.resolveFiles(downloadUpdateOptions.updateInfoAndProvider.info);\n        const log = this._logger;\n        // detect if we are running inside Rosetta emulation\n        const sysctlRosettaInfoKey = \"sysctl.proc_translated\";\n        let isRosetta = false;\n        try {\n            this.debug(\"Checking for macOS Rosetta environment\");\n            const result = (0, child_process_1.execFileSync)(\"sysctl\", [sysctlRosettaInfoKey], { encoding: \"utf8\" });\n            isRosetta = result.includes(`${sysctlRosettaInfoKey}: 1`);\n            log.info(`Checked for macOS Rosetta environment (isRosetta=${isRosetta})`);\n        }\n        catch (e) {\n            log.warn(`sysctl shell command to check for macOS Rosetta environment failed: ${e}`);\n        }\n        let isArm64Mac = false;\n        try {\n            this.debug(\"Checking for arm64 in uname\");\n            const result = (0, child_process_1.execFileSync)(\"uname\", [\"-a\"], { encoding: \"utf8\" });\n            const isArm = result.includes(\"ARM\");\n            log.info(`Checked 'uname -a': arm64=${isArm}`);\n            isArm64Mac = isArm64Mac || isArm;\n        }\n        catch (e) {\n            log.warn(`uname shell command to check for arm64 failed: ${e}`);\n        }\n        isArm64Mac = isArm64Mac || process.arch === \"arm64\" || isRosetta;\n        // allow arm64 macs to install universal or rosetta2(x64) - https://github.com/electron-userland/electron-builder/pull/5524\n        const isArm64 = (file) => { var _a; return file.url.pathname.includes(\"arm64\") || ((_a = file.info.url) === null || _a === void 0 ? void 0 : _a.includes(\"arm64\")); };\n        if (isArm64Mac && files.some(isArm64)) {\n            files = files.filter(file => isArm64Mac === isArm64(file));\n        }\n        else {\n            files = files.filter(file => !isArm64(file));\n        }\n        const zipFileInfo = (0, Provider_1.findFile)(files, \"zip\", [\"pkg\", \"dmg\"]);\n        if (zipFileInfo == null) {\n            throw (0, builder_util_runtime_1.newError)(`ZIP file not provided: ${(0, builder_util_runtime_1.safeStringifyJson)(files)}`, \"ERR_UPDATER_ZIP_FILE_NOT_FOUND\");\n        }\n        return this.executeDownload({\n            fileExtension: \"zip\",\n            fileInfo: zipFileInfo,\n            downloadUpdateOptions,\n            task: (destinationFile, downloadOptions) => {\n                return this.httpExecutor.download(zipFileInfo.url, destinationFile, downloadOptions);\n            },\n            done: event => this.updateDownloaded(zipFileInfo, event),\n        });\n    }\n    async updateDownloaded(zipFileInfo, event) {\n        var _a, _b;\n        const downloadedFile = event.downloadedFile;\n        const updateFileSize = (_a = zipFileInfo.info.size) !== null && _a !== void 0 ? _a : (await (0, fs_extra_1.stat)(downloadedFile)).size;\n        const log = this._logger;\n        const logContext = `fileToProxy=${zipFileInfo.url.href}`;\n        this.debug(`Creating proxy server for native Squirrel.Mac (${logContext})`);\n        (_b = this.server) === null || _b === void 0 ? void 0 : _b.close();\n        this.server = (0, http_1.createServer)();\n        this.debug(`Proxy server for native Squirrel.Mac is created (${logContext})`);\n        this.server.on(\"close\", () => {\n            log.info(`Proxy server for native Squirrel.Mac is closed (${logContext})`);\n        });\n        // must be called after server is listening, otherwise address is null\n        const getServerUrl = (s) => {\n            const address = s.address();\n            if (typeof address === \"string\") {\n                return address;\n            }\n            return `http://127.0.0.1:${address === null || address === void 0 ? void 0 : address.port}`;\n        };\n        return await new Promise((resolve, reject) => {\n            const pass = (0, crypto_1.randomBytes)(64).toString(\"base64\").replace(/\\//g, \"_\").replace(/\\+/g, \"-\");\n            const authInfo = Buffer.from(`autoupdater:${pass}`, \"ascii\");\n            // insecure random is ok\n            const fileUrl = `/${(0, crypto_1.randomBytes)(64).toString(\"hex\")}.zip`;\n            this.server.on(\"request\", (request, response) => {\n                const requestUrl = request.url;\n                log.info(`${requestUrl} requested`);\n                if (requestUrl === \"/\") {\n                    // check for basic auth header\n                    if (!request.headers.authorization || request.headers.authorization.indexOf(\"Basic \") === -1) {\n                        response.statusCode = 401;\n                        response.statusMessage = \"Invalid Authentication Credentials\";\n                        response.end();\n                        log.warn(\"No authenthication info\");\n                        return;\n                    }\n                    // verify auth credentials\n                    const base64Credentials = request.headers.authorization.split(\" \")[1];\n                    const credentials = Buffer.from(base64Credentials, \"base64\").toString(\"ascii\");\n                    const [username, password] = credentials.split(\":\");\n                    if (username !== \"autoupdater\" || password !== pass) {\n                        response.statusCode = 401;\n                        response.statusMessage = \"Invalid Authentication Credentials\";\n                        response.end();\n                        log.warn(\"Invalid authenthication credentials\");\n                        return;\n                    }\n                    const data = Buffer.from(`{ \"url\": \"${getServerUrl(this.server)}${fileUrl}\" }`);\n                    response.writeHead(200, { \"Content-Type\": \"application/json\", \"Content-Length\": data.length });\n                    response.end(data);\n                    return;\n                }\n                if (!requestUrl.startsWith(fileUrl)) {\n                    log.warn(`${requestUrl} requested, but not supported`);\n                    response.writeHead(404);\n                    response.end();\n                    return;\n                }\n                log.info(`${fileUrl} requested by Squirrel.Mac, pipe ${downloadedFile}`);\n                let errorOccurred = false;\n                response.on(\"finish\", () => {\n                    if (!errorOccurred) {\n                        this.nativeUpdater.removeListener(\"error\", reject);\n                        resolve([]);\n                    }\n                });\n                const readStream = (0, fs_1.createReadStream)(downloadedFile);\n                readStream.on(\"error\", error => {\n                    try {\n                        response.end();\n                    }\n                    catch (e) {\n                        log.warn(`cannot end response: ${e}`);\n                    }\n                    errorOccurred = true;\n                    this.nativeUpdater.removeListener(\"error\", reject);\n                    reject(new Error(`Cannot pipe \"${downloadedFile}\": ${error}`));\n                });\n                response.writeHead(200, {\n                    \"Content-Type\": \"application/zip\",\n                    \"Content-Length\": updateFileSize,\n                });\n                readStream.pipe(response);\n            });\n            this.debug(`Proxy server for native Squirrel.Mac is starting to listen (${logContext})`);\n            this.server.listen(0, \"127.0.0.1\", () => {\n                this.debug(`Proxy server for native Squirrel.Mac is listening (address=${getServerUrl(this.server)}, ${logContext})`);\n                this.nativeUpdater.setFeedURL({\n                    url: getServerUrl(this.server),\n                    headers: {\n                        \"Cache-Control\": \"no-cache\",\n                        Authorization: `Basic ${authInfo.toString(\"base64\")}`,\n                    },\n                });\n                // The update has been downloaded and is ready to be served to Squirrel\n                this.dispatchUpdateDownloaded(event);\n                if (this.autoInstallOnAppQuit) {\n                    this.nativeUpdater.once(\"error\", reject);\n                    // This will trigger fetching and installing the file on Squirrel side\n                    this.nativeUpdater.checkForUpdates();\n                }\n                else {\n                    resolve([]);\n                }\n            });\n        });\n    }\n    quitAndInstall() {\n        var _a;\n        if (this.squirrelDownloadedUpdate) {\n            // update already fetched by Squirrel, it's ready to install\n            this.nativeUpdater.quitAndInstall();\n            (_a = this.server) === null || _a === void 0 ? void 0 : _a.close();\n        }\n        else {\n            // Quit and install as soon as Squirrel get the update\n            this.nativeUpdater.on(\"update-downloaded\", () => {\n                var _a;\n                this.nativeUpdater.quitAndInstall();\n                (_a = this.server) === null || _a === void 0 ? void 0 : _a.close();\n            });\n            if (!this.autoInstallOnAppQuit) {\n                /**\n                 * If this was not `true` previously then MacUpdater.doDownloadUpdate()\n                 * would not actually initiate the downloading by electron's autoUpdater\n                 */\n                this.nativeUpdater.checkForUpdates();\n            }\n        }\n    }\n}\nexports.MacUpdater = MacUpdater;\n//# sourceMappingURL=MacUpdater.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/MacUpdater.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/NsisUpdater.js":
/*!**********************************************************!*\
  !*** ./node_modules/electron-updater/out/NsisUpdater.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.NsisUpdater = void 0;\nconst builder_util_runtime_1 = __webpack_require__(/*! builder-util-runtime */ \"./node_modules/builder-util-runtime/out/index.js\");\nconst path = __webpack_require__(/*! path */ \"path\");\nconst BaseUpdater_1 = __webpack_require__(/*! ./BaseUpdater */ \"./node_modules/electron-updater/out/BaseUpdater.js\");\nconst FileWithEmbeddedBlockMapDifferentialDownloader_1 = __webpack_require__(/*! ./differentialDownloader/FileWithEmbeddedBlockMapDifferentialDownloader */ \"./node_modules/electron-updater/out/differentialDownloader/FileWithEmbeddedBlockMapDifferentialDownloader.js\");\nconst GenericDifferentialDownloader_1 = __webpack_require__(/*! ./differentialDownloader/GenericDifferentialDownloader */ \"./node_modules/electron-updater/out/differentialDownloader/GenericDifferentialDownloader.js\");\nconst main_1 = __webpack_require__(/*! ./main */ \"./node_modules/electron-updater/out/main.js\");\nconst util_1 = __webpack_require__(/*! ./util */ \"./node_modules/electron-updater/out/util.js\");\nconst Provider_1 = __webpack_require__(/*! ./providers/Provider */ \"./node_modules/electron-updater/out/providers/Provider.js\");\nconst fs_extra_1 = __webpack_require__(/*! fs-extra */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/index.js\");\nconst windowsExecutableCodeSignatureVerifier_1 = __webpack_require__(/*! ./windowsExecutableCodeSignatureVerifier */ \"./node_modules/electron-updater/out/windowsExecutableCodeSignatureVerifier.js\");\nconst url_1 = __webpack_require__(/*! url */ \"url\");\nconst zlib_1 = __webpack_require__(/*! zlib */ \"zlib\");\nclass NsisUpdater extends BaseUpdater_1.BaseUpdater {\n    constructor(options, app) {\n        super(options, app);\n        this._verifyUpdateCodeSignature = (publisherNames, unescapedTempUpdateFile) => (0, windowsExecutableCodeSignatureVerifier_1.verifySignature)(publisherNames, unescapedTempUpdateFile, this._logger);\n    }\n    /**\n     * The verifyUpdateCodeSignature. You can pass [win-verify-signature](https://github.com/beyondkmp/win-verify-trust) or another custom verify function: ` (publisherName: string[], path: string) => Promise<string | null>`.\n     * The default verify function uses [windowsExecutableCodeSignatureVerifier](https://github.com/electron-userland/electron-builder/blob/master/packages/electron-updater/src/windowsExecutableCodeSignatureVerifier.ts)\n     */\n    get verifyUpdateCodeSignature() {\n        return this._verifyUpdateCodeSignature;\n    }\n    set verifyUpdateCodeSignature(value) {\n        if (value) {\n            this._verifyUpdateCodeSignature = value;\n        }\n    }\n    /*** @private */\n    doDownloadUpdate(downloadUpdateOptions) {\n        const provider = downloadUpdateOptions.updateInfoAndProvider.provider;\n        const fileInfo = (0, Provider_1.findFile)(provider.resolveFiles(downloadUpdateOptions.updateInfoAndProvider.info), \"exe\");\n        return this.executeDownload({\n            fileExtension: \"exe\",\n            downloadUpdateOptions,\n            fileInfo,\n            task: async (destinationFile, downloadOptions, packageFile, removeTempDirIfAny) => {\n                const packageInfo = fileInfo.packageInfo;\n                const isWebInstaller = packageInfo != null && packageFile != null;\n                if (isWebInstaller && downloadUpdateOptions.disableWebInstaller) {\n                    throw (0, builder_util_runtime_1.newError)(`Unable to download new version ${downloadUpdateOptions.updateInfoAndProvider.info.version}. Web Installers are disabled`, \"ERR_UPDATER_WEB_INSTALLER_DISABLED\");\n                }\n                if (!isWebInstaller && !downloadUpdateOptions.disableWebInstaller) {\n                    this._logger.warn(\"disableWebInstaller is set to false, you should set it to true if you do not plan on using a web installer. This will default to true in a future version.\");\n                }\n                if (isWebInstaller || (await this.differentialDownloadInstaller(fileInfo, downloadUpdateOptions, destinationFile, provider))) {\n                    await this.httpExecutor.download(fileInfo.url, destinationFile, downloadOptions);\n                }\n                const signatureVerificationStatus = await this.verifySignature(destinationFile);\n                if (signatureVerificationStatus != null) {\n                    await removeTempDirIfAny();\n                    // noinspection ThrowInsideFinallyBlockJS\n                    throw (0, builder_util_runtime_1.newError)(`New version ${downloadUpdateOptions.updateInfoAndProvider.info.version} is not signed by the application owner: ${signatureVerificationStatus}`, \"ERR_UPDATER_INVALID_SIGNATURE\");\n                }\n                if (isWebInstaller) {\n                    if (await this.differentialDownloadWebPackage(downloadUpdateOptions, packageInfo, packageFile, provider)) {\n                        try {\n                            await this.httpExecutor.download(new url_1.URL(packageInfo.path), packageFile, {\n                                headers: downloadUpdateOptions.requestHeaders,\n                                cancellationToken: downloadUpdateOptions.cancellationToken,\n                                sha512: packageInfo.sha512,\n                            });\n                        }\n                        catch (e) {\n                            try {\n                                await (0, fs_extra_1.unlink)(packageFile);\n                            }\n                            catch (ignored) {\n                                // ignore\n                            }\n                            throw e;\n                        }\n                    }\n                }\n            },\n        });\n    }\n    // $certificateInfo = (Get-AuthenticodeSignature 'xxx\\yyy.exe'\n    // | where {$_.Status.Equals([System.Management.Automation.SignatureStatus]::Valid) -and $_.SignerCertificate.Subject.Contains(\"CN=siemens.com\")})\n    // | Out-String ; if ($certificateInfo) { exit 0 } else { exit 1 }\n    async verifySignature(tempUpdateFile) {\n        let publisherName;\n        try {\n            publisherName = (await this.configOnDisk.value).publisherName;\n            if (publisherName == null) {\n                return null;\n            }\n        }\n        catch (e) {\n            if (e.code === \"ENOENT\") {\n                // no app-update.yml\n                return null;\n            }\n            throw e;\n        }\n        return await this._verifyUpdateCodeSignature(Array.isArray(publisherName) ? publisherName : [publisherName], tempUpdateFile);\n    }\n    doInstall(options) {\n        const args = [\"--updated\"];\n        if (options.isSilent) {\n            args.push(\"/S\");\n        }\n        if (options.isForceRunAfter) {\n            args.push(\"--force-run\");\n        }\n        if (this.installDirectory) {\n            // maybe check if folder exists\n            args.push(`/D=${this.installDirectory}`);\n        }\n        const packagePath = this.downloadedUpdateHelper == null ? null : this.downloadedUpdateHelper.packageFile;\n        if (packagePath != null) {\n            // only = form is supported\n            args.push(`--package-file=${packagePath}`);\n        }\n        const callUsingElevation = () => {\n            this.spawnLog(path.join(process.resourcesPath, \"elevate.exe\"), [options.installerPath].concat(args)).catch(e => this.dispatchError(e));\n        };\n        if (options.isAdminRightsRequired) {\n            this._logger.info(\"isAdminRightsRequired is set to true, run installer using elevate.exe\");\n            callUsingElevation();\n            return true;\n        }\n        this.spawnLog(options.installerPath, args).catch((e) => {\n            // https://github.com/electron-userland/electron-builder/issues/1129\n            // Node 8 sends errors: https://nodejs.org/dist/latest-v8.x/docs/api/errors.html#errors_common_system_errors\n            const errorCode = e.code;\n            this._logger.info(`Cannot run installer: error code: ${errorCode}, error message: \"${e.message}\", will be executed again using elevate if EACCES\"`);\n            if (errorCode === \"UNKNOWN\" || errorCode === \"EACCES\") {\n                callUsingElevation();\n            }\n            else {\n                this.dispatchError(e);\n            }\n        });\n        return true;\n    }\n    async differentialDownloadInstaller(fileInfo, downloadUpdateOptions, installerPath, provider) {\n        try {\n            if (this._testOnlyOptions != null && !this._testOnlyOptions.isUseDifferentialDownload) {\n                return true;\n            }\n            const blockmapFileUrls = (0, util_1.blockmapFiles)(fileInfo.url, this.app.version, downloadUpdateOptions.updateInfoAndProvider.info.version);\n            this._logger.info(`Download block maps (old: \"${blockmapFileUrls[0]}\", new: ${blockmapFileUrls[1]})`);\n            const downloadBlockMap = async (url) => {\n                const data = await this.httpExecutor.downloadToBuffer(url, {\n                    headers: downloadUpdateOptions.requestHeaders,\n                    cancellationToken: downloadUpdateOptions.cancellationToken,\n                });\n                if (data == null || data.length === 0) {\n                    throw new Error(`Blockmap \"${url.href}\" is empty`);\n                }\n                try {\n                    return JSON.parse((0, zlib_1.gunzipSync)(data).toString());\n                }\n                catch (e) {\n                    throw new Error(`Cannot parse blockmap \"${url.href}\", error: ${e}`);\n                }\n            };\n            const downloadOptions = {\n                newUrl: fileInfo.url,\n                oldFile: path.join(this.downloadedUpdateHelper.cacheDir, builder_util_runtime_1.CURRENT_APP_INSTALLER_FILE_NAME),\n                logger: this._logger,\n                newFile: installerPath,\n                isUseMultipleRangeRequest: provider.isUseMultipleRangeRequest,\n                requestHeaders: downloadUpdateOptions.requestHeaders,\n                cancellationToken: downloadUpdateOptions.cancellationToken,\n            };\n            if (this.listenerCount(main_1.DOWNLOAD_PROGRESS) > 0) {\n                downloadOptions.onProgress = it => this.emit(main_1.DOWNLOAD_PROGRESS, it);\n            }\n            const blockMapDataList = await Promise.all(blockmapFileUrls.map(u => downloadBlockMap(u)));\n            await new GenericDifferentialDownloader_1.GenericDifferentialDownloader(fileInfo.info, this.httpExecutor, downloadOptions).download(blockMapDataList[0], blockMapDataList[1]);\n            return false;\n        }\n        catch (e) {\n            this._logger.error(`Cannot download differentially, fallback to full download: ${e.stack || e}`);\n            if (this._testOnlyOptions != null) {\n                // test mode\n                throw e;\n            }\n            return true;\n        }\n    }\n    async differentialDownloadWebPackage(downloadUpdateOptions, packageInfo, packagePath, provider) {\n        if (packageInfo.blockMapSize == null) {\n            return true;\n        }\n        try {\n            const downloadOptions = {\n                newUrl: new url_1.URL(packageInfo.path),\n                oldFile: path.join(this.downloadedUpdateHelper.cacheDir, builder_util_runtime_1.CURRENT_APP_PACKAGE_FILE_NAME),\n                logger: this._logger,\n                newFile: packagePath,\n                requestHeaders: this.requestHeaders,\n                isUseMultipleRangeRequest: provider.isUseMultipleRangeRequest,\n                cancellationToken: downloadUpdateOptions.cancellationToken,\n            };\n            if (this.listenerCount(main_1.DOWNLOAD_PROGRESS) > 0) {\n                downloadOptions.onProgress = it => this.emit(main_1.DOWNLOAD_PROGRESS, it);\n            }\n            await new FileWithEmbeddedBlockMapDifferentialDownloader_1.FileWithEmbeddedBlockMapDifferentialDownloader(packageInfo, this.httpExecutor, downloadOptions).download();\n        }\n        catch (e) {\n            this._logger.error(`Cannot download differentially, fallback to full download: ${e.stack || e}`);\n            // during test (developer machine mac or linux) we must throw error\n            return process.platform === \"win32\";\n        }\n        return false;\n    }\n}\nexports.NsisUpdater = NsisUpdater;\n//# sourceMappingURL=NsisUpdater.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/NsisUpdater.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/RpmUpdater.js":
/*!*********************************************************!*\
  !*** ./node_modules/electron-updater/out/RpmUpdater.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RpmUpdater = void 0;\nconst BaseUpdater_1 = __webpack_require__(/*! ./BaseUpdater */ \"./node_modules/electron-updater/out/BaseUpdater.js\");\nconst main_1 = __webpack_require__(/*! ./main */ \"./node_modules/electron-updater/out/main.js\");\nconst Provider_1 = __webpack_require__(/*! ./providers/Provider */ \"./node_modules/electron-updater/out/providers/Provider.js\");\nclass RpmUpdater extends BaseUpdater_1.BaseUpdater {\n    constructor(options, app) {\n        super(options, app);\n    }\n    /*** @private */\n    doDownloadUpdate(downloadUpdateOptions) {\n        const provider = downloadUpdateOptions.updateInfoAndProvider.provider;\n        const fileInfo = (0, Provider_1.findFile)(provider.resolveFiles(downloadUpdateOptions.updateInfoAndProvider.info), \"rpm\", [\"AppImage\", \"deb\"]);\n        return this.executeDownload({\n            fileExtension: \"rpm\",\n            fileInfo,\n            downloadUpdateOptions,\n            task: async (updateFile, downloadOptions) => {\n                if (this.listenerCount(main_1.DOWNLOAD_PROGRESS) > 0) {\n                    downloadOptions.onProgress = it => this.emit(main_1.DOWNLOAD_PROGRESS, it);\n                }\n                await this.httpExecutor.download(fileInfo.url, updateFile, downloadOptions);\n            },\n        });\n    }\n    doInstall(options) {\n        const upgradePath = options.installerPath;\n        const sudo = this.wrapSudo();\n        // pkexec doesn't want the command to be wrapped in \" quotes\n        const wrapper = /pkexec/i.test(sudo) ? \"\" : `\"`;\n        const packageManager = this.spawnSyncLog(\"which zypper\");\n        let cmd;\n        if (!packageManager) {\n            const packageManager = this.spawnSyncLog(\"which dnf || which yum\");\n            cmd = [packageManager, \"-y\", \"remove\", `'${this.app.name}'`, \";\", packageManager, \"-y\", \"install\", upgradePath];\n        }\n        else {\n            cmd = [\n                packageManager,\n                \"remove\",\n                \"-y\",\n                `'${this.app.name}'`,\n                \";\",\n                packageManager,\n                \"clean\",\n                \"--all\",\n                \";\",\n                packageManager,\n                \"--no-refresh\",\n                \"install\",\n                \"--allow-unsigned-rpm\",\n                \"-y\",\n                \"-f\",\n                upgradePath,\n            ];\n        }\n        this.spawnSyncLog(sudo, [`${wrapper}/bin/bash`, \"-c\", `'${cmd.join(\" \")}'${wrapper}`]);\n        if (options.isForceRunAfter) {\n            this.app.relaunch();\n        }\n        return true;\n    }\n}\nexports.RpmUpdater = RpmUpdater;\n//# sourceMappingURL=RpmUpdater.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/RpmUpdater.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/differentialDownloader/DataSplitter.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/electron-updater/out/differentialDownloader/DataSplitter.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DataSplitter = exports.copyData = void 0;\nconst builder_util_runtime_1 = __webpack_require__(/*! builder-util-runtime */ \"./node_modules/builder-util-runtime/out/index.js\");\nconst fs_1 = __webpack_require__(/*! fs */ \"fs\");\nconst stream_1 = __webpack_require__(/*! stream */ \"stream\");\nconst downloadPlanBuilder_1 = __webpack_require__(/*! ./downloadPlanBuilder */ \"./node_modules/electron-updater/out/differentialDownloader/downloadPlanBuilder.js\");\nconst DOUBLE_CRLF = Buffer.from(\"\\r\\n\\r\\n\");\nvar ReadState;\n(function (ReadState) {\n    ReadState[ReadState[\"INIT\"] = 0] = \"INIT\";\n    ReadState[ReadState[\"HEADER\"] = 1] = \"HEADER\";\n    ReadState[ReadState[\"BODY\"] = 2] = \"BODY\";\n})(ReadState || (ReadState = {}));\nfunction copyData(task, out, oldFileFd, reject, resolve) {\n    const readStream = (0, fs_1.createReadStream)(\"\", {\n        fd: oldFileFd,\n        autoClose: false,\n        start: task.start,\n        // end is inclusive\n        end: task.end - 1,\n    });\n    readStream.on(\"error\", reject);\n    readStream.once(\"end\", resolve);\n    readStream.pipe(out, {\n        end: false,\n    });\n}\nexports.copyData = copyData;\nclass DataSplitter extends stream_1.Writable {\n    constructor(out, options, partIndexToTaskIndex, boundary, partIndexToLength, finishHandler) {\n        super();\n        this.out = out;\n        this.options = options;\n        this.partIndexToTaskIndex = partIndexToTaskIndex;\n        this.partIndexToLength = partIndexToLength;\n        this.finishHandler = finishHandler;\n        this.partIndex = -1;\n        this.headerListBuffer = null;\n        this.readState = ReadState.INIT;\n        this.ignoreByteCount = 0;\n        this.remainingPartDataCount = 0;\n        this.actualPartLength = 0;\n        this.boundaryLength = boundary.length + 4; /* size of \\r\\n-- */\n        // first chunk doesn't start with \\r\\n\n        this.ignoreByteCount = this.boundaryLength - 2;\n    }\n    get isFinished() {\n        return this.partIndex === this.partIndexToLength.length;\n    }\n    // noinspection JSUnusedGlobalSymbols\n    _write(data, encoding, callback) {\n        if (this.isFinished) {\n            console.error(`Trailing ignored data: ${data.length} bytes`);\n            return;\n        }\n        this.handleData(data).then(callback).catch(callback);\n    }\n    async handleData(chunk) {\n        let start = 0;\n        if (this.ignoreByteCount !== 0 && this.remainingPartDataCount !== 0) {\n            throw (0, builder_util_runtime_1.newError)(\"Internal error\", \"ERR_DATA_SPLITTER_BYTE_COUNT_MISMATCH\");\n        }\n        if (this.ignoreByteCount > 0) {\n            const toIgnore = Math.min(this.ignoreByteCount, chunk.length);\n            this.ignoreByteCount -= toIgnore;\n            start = toIgnore;\n        }\n        else if (this.remainingPartDataCount > 0) {\n            const toRead = Math.min(this.remainingPartDataCount, chunk.length);\n            this.remainingPartDataCount -= toRead;\n            await this.processPartData(chunk, 0, toRead);\n            start = toRead;\n        }\n        if (start === chunk.length) {\n            return;\n        }\n        if (this.readState === ReadState.HEADER) {\n            const headerListEnd = this.searchHeaderListEnd(chunk, start);\n            if (headerListEnd === -1) {\n                return;\n            }\n            start = headerListEnd;\n            this.readState = ReadState.BODY;\n            // header list is ignored, we don't need it\n            this.headerListBuffer = null;\n        }\n        while (true) {\n            if (this.readState === ReadState.BODY) {\n                this.readState = ReadState.INIT;\n            }\n            else {\n                this.partIndex++;\n                let taskIndex = this.partIndexToTaskIndex.get(this.partIndex);\n                if (taskIndex == null) {\n                    if (this.isFinished) {\n                        taskIndex = this.options.end;\n                    }\n                    else {\n                        throw (0, builder_util_runtime_1.newError)(\"taskIndex is null\", \"ERR_DATA_SPLITTER_TASK_INDEX_IS_NULL\");\n                    }\n                }\n                const prevTaskIndex = this.partIndex === 0 ? this.options.start : this.partIndexToTaskIndex.get(this.partIndex - 1) + 1; /* prev part is download, next maybe copy */\n                if (prevTaskIndex < taskIndex) {\n                    await this.copyExistingData(prevTaskIndex, taskIndex);\n                }\n                else if (prevTaskIndex > taskIndex) {\n                    throw (0, builder_util_runtime_1.newError)(\"prevTaskIndex must be < taskIndex\", \"ERR_DATA_SPLITTER_TASK_INDEX_ASSERT_FAILED\");\n                }\n                if (this.isFinished) {\n                    this.onPartEnd();\n                    this.finishHandler();\n                    return;\n                }\n                start = this.searchHeaderListEnd(chunk, start);\n                if (start === -1) {\n                    this.readState = ReadState.HEADER;\n                    return;\n                }\n            }\n            const partLength = this.partIndexToLength[this.partIndex];\n            const end = start + partLength;\n            const effectiveEnd = Math.min(end, chunk.length);\n            await this.processPartStarted(chunk, start, effectiveEnd);\n            this.remainingPartDataCount = partLength - (effectiveEnd - start);\n            if (this.remainingPartDataCount > 0) {\n                return;\n            }\n            start = end + this.boundaryLength;\n            if (start >= chunk.length) {\n                this.ignoreByteCount = this.boundaryLength - (chunk.length - end);\n                return;\n            }\n        }\n    }\n    copyExistingData(index, end) {\n        return new Promise((resolve, reject) => {\n            const w = () => {\n                if (index === end) {\n                    resolve();\n                    return;\n                }\n                const task = this.options.tasks[index];\n                if (task.kind !== downloadPlanBuilder_1.OperationKind.COPY) {\n                    reject(new Error(\"Task kind must be COPY\"));\n                    return;\n                }\n                copyData(task, this.out, this.options.oldFileFd, reject, () => {\n                    index++;\n                    w();\n                });\n            };\n            w();\n        });\n    }\n    searchHeaderListEnd(chunk, readOffset) {\n        const headerListEnd = chunk.indexOf(DOUBLE_CRLF, readOffset);\n        if (headerListEnd !== -1) {\n            return headerListEnd + DOUBLE_CRLF.length;\n        }\n        // not all headers data were received, save to buffer\n        const partialChunk = readOffset === 0 ? chunk : chunk.slice(readOffset);\n        if (this.headerListBuffer == null) {\n            this.headerListBuffer = partialChunk;\n        }\n        else {\n            this.headerListBuffer = Buffer.concat([this.headerListBuffer, partialChunk]);\n        }\n        return -1;\n    }\n    onPartEnd() {\n        const expectedLength = this.partIndexToLength[this.partIndex - 1];\n        if (this.actualPartLength !== expectedLength) {\n            throw (0, builder_util_runtime_1.newError)(`Expected length: ${expectedLength} differs from actual: ${this.actualPartLength}`, \"ERR_DATA_SPLITTER_LENGTH_MISMATCH\");\n        }\n        this.actualPartLength = 0;\n    }\n    processPartStarted(data, start, end) {\n        if (this.partIndex !== 0) {\n            this.onPartEnd();\n        }\n        return this.processPartData(data, start, end);\n    }\n    processPartData(data, start, end) {\n        this.actualPartLength += end - start;\n        const out = this.out;\n        if (out.write(start === 0 && data.length === end ? data : data.slice(start, end))) {\n            return Promise.resolve();\n        }\n        else {\n            return new Promise((resolve, reject) => {\n                out.on(\"error\", reject);\n                out.once(\"drain\", () => {\n                    out.removeListener(\"error\", reject);\n                    resolve();\n                });\n            });\n        }\n    }\n}\nexports.DataSplitter = DataSplitter;\n//# sourceMappingURL=DataSplitter.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/differentialDownloader/DataSplitter.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/differentialDownloader/DifferentialDownloader.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/electron-updater/out/differentialDownloader/DifferentialDownloader.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DifferentialDownloader = void 0;\nconst builder_util_runtime_1 = __webpack_require__(/*! builder-util-runtime */ \"./node_modules/builder-util-runtime/out/index.js\");\nconst fs_extra_1 = __webpack_require__(/*! fs-extra */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/index.js\");\nconst fs_1 = __webpack_require__(/*! fs */ \"fs\");\nconst DataSplitter_1 = __webpack_require__(/*! ./DataSplitter */ \"./node_modules/electron-updater/out/differentialDownloader/DataSplitter.js\");\nconst url_1 = __webpack_require__(/*! url */ \"url\");\nconst downloadPlanBuilder_1 = __webpack_require__(/*! ./downloadPlanBuilder */ \"./node_modules/electron-updater/out/differentialDownloader/downloadPlanBuilder.js\");\nconst multipleRangeDownloader_1 = __webpack_require__(/*! ./multipleRangeDownloader */ \"./node_modules/electron-updater/out/differentialDownloader/multipleRangeDownloader.js\");\nconst ProgressDifferentialDownloadCallbackTransform_1 = __webpack_require__(/*! ./ProgressDifferentialDownloadCallbackTransform */ \"./node_modules/electron-updater/out/differentialDownloader/ProgressDifferentialDownloadCallbackTransform.js\");\nclass DifferentialDownloader {\n    // noinspection TypeScriptAbstractClassConstructorCanBeMadeProtected\n    constructor(blockAwareFileInfo, httpExecutor, options) {\n        this.blockAwareFileInfo = blockAwareFileInfo;\n        this.httpExecutor = httpExecutor;\n        this.options = options;\n        this.fileMetadataBuffer = null;\n        this.logger = options.logger;\n    }\n    createRequestOptions() {\n        const result = {\n            headers: {\n                ...this.options.requestHeaders,\n                accept: \"*/*\",\n            },\n        };\n        (0, builder_util_runtime_1.configureRequestUrl)(this.options.newUrl, result);\n        // user-agent, cache-control and other common options\n        (0, builder_util_runtime_1.configureRequestOptions)(result);\n        return result;\n    }\n    doDownload(oldBlockMap, newBlockMap) {\n        // we don't check other metadata like compressionMethod - generic check that it is make sense to differentially update is suitable for it\n        if (oldBlockMap.version !== newBlockMap.version) {\n            throw new Error(`version is different (${oldBlockMap.version} - ${newBlockMap.version}), full download is required`);\n        }\n        const logger = this.logger;\n        const operations = (0, downloadPlanBuilder_1.computeOperations)(oldBlockMap, newBlockMap, logger);\n        if (logger.debug != null) {\n            logger.debug(JSON.stringify(operations, null, 2));\n        }\n        let downloadSize = 0;\n        let copySize = 0;\n        for (const operation of operations) {\n            const length = operation.end - operation.start;\n            if (operation.kind === downloadPlanBuilder_1.OperationKind.DOWNLOAD) {\n                downloadSize += length;\n            }\n            else {\n                copySize += length;\n            }\n        }\n        const newSize = this.blockAwareFileInfo.size;\n        if (downloadSize + copySize + (this.fileMetadataBuffer == null ? 0 : this.fileMetadataBuffer.length) !== newSize) {\n            throw new Error(`Internal error, size mismatch: downloadSize: ${downloadSize}, copySize: ${copySize}, newSize: ${newSize}`);\n        }\n        logger.info(`Full: ${formatBytes(newSize)}, To download: ${formatBytes(downloadSize)} (${Math.round(downloadSize / (newSize / 100))}%)`);\n        return this.downloadFile(operations);\n    }\n    downloadFile(tasks) {\n        const fdList = [];\n        const closeFiles = () => {\n            return Promise.all(fdList.map(openedFile => {\n                return (0, fs_extra_1.close)(openedFile.descriptor).catch((e) => {\n                    this.logger.error(`cannot close file \"${openedFile.path}\": ${e}`);\n                });\n            }));\n        };\n        return this.doDownloadFile(tasks, fdList)\n            .then(closeFiles)\n            .catch((e) => {\n            // then must be after catch here (since then always throws error)\n            return closeFiles()\n                .catch(closeFilesError => {\n                // closeFiles never throw error, but just to be sure\n                try {\n                    this.logger.error(`cannot close files: ${closeFilesError}`);\n                }\n                catch (errorOnLog) {\n                    try {\n                        console.error(errorOnLog);\n                    }\n                    catch (ignored) {\n                        // ok, give up and ignore error\n                    }\n                }\n                throw e;\n            })\n                .then(() => {\n                throw e;\n            });\n        });\n    }\n    async doDownloadFile(tasks, fdList) {\n        const oldFileFd = await (0, fs_extra_1.open)(this.options.oldFile, \"r\");\n        fdList.push({ descriptor: oldFileFd, path: this.options.oldFile });\n        const newFileFd = await (0, fs_extra_1.open)(this.options.newFile, \"w\");\n        fdList.push({ descriptor: newFileFd, path: this.options.newFile });\n        const fileOut = (0, fs_1.createWriteStream)(this.options.newFile, { fd: newFileFd });\n        await new Promise((resolve, reject) => {\n            const streams = [];\n            // Create our download info transformer if we have one\n            let downloadInfoTransform = undefined;\n            if (!this.options.isUseMultipleRangeRequest && this.options.onProgress) {\n                // TODO: Does not support multiple ranges (someone feel free to PR this!)\n                const expectedByteCounts = [];\n                let grandTotalBytes = 0;\n                for (const task of tasks) {\n                    if (task.kind === downloadPlanBuilder_1.OperationKind.DOWNLOAD) {\n                        expectedByteCounts.push(task.end - task.start);\n                        grandTotalBytes += task.end - task.start;\n                    }\n                }\n                const progressDifferentialDownloadInfo = {\n                    expectedByteCounts: expectedByteCounts,\n                    grandTotal: grandTotalBytes,\n                };\n                downloadInfoTransform = new ProgressDifferentialDownloadCallbackTransform_1.ProgressDifferentialDownloadCallbackTransform(progressDifferentialDownloadInfo, this.options.cancellationToken, this.options.onProgress);\n                streams.push(downloadInfoTransform);\n            }\n            const digestTransform = new builder_util_runtime_1.DigestTransform(this.blockAwareFileInfo.sha512);\n            // to simply debug, do manual validation to allow file to be fully written\n            digestTransform.isValidateOnEnd = false;\n            streams.push(digestTransform);\n            // noinspection JSArrowFunctionCanBeReplacedWithShorthand\n            fileOut.on(\"finish\", () => {\n                ;\n                fileOut.close(() => {\n                    // remove from fd list because closed successfully\n                    fdList.splice(1, 1);\n                    try {\n                        digestTransform.validate();\n                    }\n                    catch (e) {\n                        reject(e);\n                        return;\n                    }\n                    resolve(undefined);\n                });\n            });\n            streams.push(fileOut);\n            let lastStream = null;\n            for (const stream of streams) {\n                stream.on(\"error\", reject);\n                if (lastStream == null) {\n                    lastStream = stream;\n                }\n                else {\n                    lastStream = lastStream.pipe(stream);\n                }\n            }\n            const firstStream = streams[0];\n            let w;\n            if (this.options.isUseMultipleRangeRequest) {\n                w = (0, multipleRangeDownloader_1.executeTasksUsingMultipleRangeRequests)(this, tasks, firstStream, oldFileFd, reject);\n                w(0);\n                return;\n            }\n            let downloadOperationCount = 0;\n            let actualUrl = null;\n            this.logger.info(`Differential download: ${this.options.newUrl}`);\n            const requestOptions = this.createRequestOptions();\n            requestOptions.redirect = \"manual\";\n            w = (index) => {\n                var _a, _b;\n                if (index >= tasks.length) {\n                    if (this.fileMetadataBuffer != null) {\n                        firstStream.write(this.fileMetadataBuffer);\n                    }\n                    firstStream.end();\n                    return;\n                }\n                const operation = tasks[index++];\n                if (operation.kind === downloadPlanBuilder_1.OperationKind.COPY) {\n                    // We are copying, let's not send status updates to the UI\n                    if (downloadInfoTransform) {\n                        downloadInfoTransform.beginFileCopy();\n                    }\n                    (0, DataSplitter_1.copyData)(operation, firstStream, oldFileFd, reject, () => w(index));\n                    return;\n                }\n                const range = `bytes=${operation.start}-${operation.end - 1}`;\n                requestOptions.headers.range = range;\n                (_b = (_a = this.logger) === null || _a === void 0 ? void 0 : _a.debug) === null || _b === void 0 ? void 0 : _b.call(_a, `download range: ${range}`);\n                // We are starting to download\n                if (downloadInfoTransform) {\n                    downloadInfoTransform.beginRangeDownload();\n                }\n                const request = this.httpExecutor.createRequest(requestOptions, response => {\n                    response.on(\"error\", reject);\n                    response.on(\"abort\", () => {\n                        reject(new Error(\"response has been aborted by the server\"));\n                    });\n                    // Electron net handles redirects automatically, our NodeJS test server doesn't use redirects - so, we don't check 3xx codes.\n                    if (response.statusCode >= 400) {\n                        reject((0, builder_util_runtime_1.createHttpError)(response));\n                    }\n                    response.pipe(firstStream, {\n                        end: false,\n                    });\n                    response.once(\"end\", () => {\n                        // Pass on that we are downloading a segment\n                        if (downloadInfoTransform) {\n                            downloadInfoTransform.endRangeDownload();\n                        }\n                        if (++downloadOperationCount === 100) {\n                            downloadOperationCount = 0;\n                            setTimeout(() => w(index), 1000);\n                        }\n                        else {\n                            w(index);\n                        }\n                    });\n                });\n                request.on(\"redirect\", (statusCode, method, redirectUrl) => {\n                    this.logger.info(`Redirect to ${removeQuery(redirectUrl)}`);\n                    actualUrl = redirectUrl;\n                    (0, builder_util_runtime_1.configureRequestUrl)(new url_1.URL(actualUrl), requestOptions);\n                    request.followRedirect();\n                });\n                this.httpExecutor.addErrorAndTimeoutHandlers(request, reject);\n                request.end();\n            };\n            w(0);\n        });\n    }\n    async readRemoteBytes(start, endInclusive) {\n        const buffer = Buffer.allocUnsafe(endInclusive + 1 - start);\n        const requestOptions = this.createRequestOptions();\n        requestOptions.headers.range = `bytes=${start}-${endInclusive}`;\n        let position = 0;\n        await this.request(requestOptions, chunk => {\n            chunk.copy(buffer, position);\n            position += chunk.length;\n        });\n        if (position !== buffer.length) {\n            throw new Error(`Received data length ${position} is not equal to expected ${buffer.length}`);\n        }\n        return buffer;\n    }\n    request(requestOptions, dataHandler) {\n        return new Promise((resolve, reject) => {\n            const request = this.httpExecutor.createRequest(requestOptions, response => {\n                if (!(0, multipleRangeDownloader_1.checkIsRangesSupported)(response, reject)) {\n                    return;\n                }\n                response.on(\"data\", dataHandler);\n                response.on(\"end\", () => resolve());\n            });\n            this.httpExecutor.addErrorAndTimeoutHandlers(request, reject);\n            request.end();\n        });\n    }\n}\nexports.DifferentialDownloader = DifferentialDownloader;\nfunction formatBytes(value, symbol = \" KB\") {\n    return new Intl.NumberFormat(\"en\").format((value / 1024).toFixed(2)) + symbol;\n}\n// safety\nfunction removeQuery(url) {\n    const index = url.indexOf(\"?\");\n    return index < 0 ? url : url.substring(0, index);\n}\n//# sourceMappingURL=DifferentialDownloader.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/differentialDownloader/DifferentialDownloader.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/differentialDownloader/FileWithEmbeddedBlockMapDifferentialDownloader.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/electron-updater/out/differentialDownloader/FileWithEmbeddedBlockMapDifferentialDownloader.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.FileWithEmbeddedBlockMapDifferentialDownloader = void 0;\nconst fs_extra_1 = __webpack_require__(/*! fs-extra */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/index.js\");\nconst DifferentialDownloader_1 = __webpack_require__(/*! ./DifferentialDownloader */ \"./node_modules/electron-updater/out/differentialDownloader/DifferentialDownloader.js\");\nconst zlib_1 = __webpack_require__(/*! zlib */ \"zlib\");\nclass FileWithEmbeddedBlockMapDifferentialDownloader extends DifferentialDownloader_1.DifferentialDownloader {\n    async download() {\n        const packageInfo = this.blockAwareFileInfo;\n        const fileSize = packageInfo.size;\n        const offset = fileSize - (packageInfo.blockMapSize + 4);\n        this.fileMetadataBuffer = await this.readRemoteBytes(offset, fileSize - 1);\n        const newBlockMap = readBlockMap(this.fileMetadataBuffer.slice(0, this.fileMetadataBuffer.length - 4));\n        await this.doDownload(await readEmbeddedBlockMapData(this.options.oldFile), newBlockMap);\n    }\n}\nexports.FileWithEmbeddedBlockMapDifferentialDownloader = FileWithEmbeddedBlockMapDifferentialDownloader;\nfunction readBlockMap(data) {\n    return JSON.parse((0, zlib_1.inflateRawSync)(data).toString());\n}\nasync function readEmbeddedBlockMapData(file) {\n    const fd = await (0, fs_extra_1.open)(file, \"r\");\n    try {\n        const fileSize = (await (0, fs_extra_1.fstat)(fd)).size;\n        const sizeBuffer = Buffer.allocUnsafe(4);\n        await (0, fs_extra_1.read)(fd, sizeBuffer, 0, sizeBuffer.length, fileSize - sizeBuffer.length);\n        const dataBuffer = Buffer.allocUnsafe(sizeBuffer.readUInt32BE(0));\n        await (0, fs_extra_1.read)(fd, dataBuffer, 0, dataBuffer.length, fileSize - sizeBuffer.length - dataBuffer.length);\n        await (0, fs_extra_1.close)(fd);\n        return readBlockMap(dataBuffer);\n    }\n    catch (e) {\n        await (0, fs_extra_1.close)(fd);\n        throw e;\n    }\n}\n//# sourceMappingURL=FileWithEmbeddedBlockMapDifferentialDownloader.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/differentialDownloader/FileWithEmbeddedBlockMapDifferentialDownloader.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/differentialDownloader/GenericDifferentialDownloader.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/electron-updater/out/differentialDownloader/GenericDifferentialDownloader.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.GenericDifferentialDownloader = void 0;\nconst DifferentialDownloader_1 = __webpack_require__(/*! ./DifferentialDownloader */ \"./node_modules/electron-updater/out/differentialDownloader/DifferentialDownloader.js\");\nclass GenericDifferentialDownloader extends DifferentialDownloader_1.DifferentialDownloader {\n    download(oldBlockMap, newBlockMap) {\n        return this.doDownload(oldBlockMap, newBlockMap);\n    }\n}\nexports.GenericDifferentialDownloader = GenericDifferentialDownloader;\n//# sourceMappingURL=GenericDifferentialDownloader.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/differentialDownloader/GenericDifferentialDownloader.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/differentialDownloader/ProgressDifferentialDownloadCallbackTransform.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/electron-updater/out/differentialDownloader/ProgressDifferentialDownloadCallbackTransform.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ProgressDifferentialDownloadCallbackTransform = void 0;\nconst stream_1 = __webpack_require__(/*! stream */ \"stream\");\nvar OperationKind;\n(function (OperationKind) {\n    OperationKind[OperationKind[\"COPY\"] = 0] = \"COPY\";\n    OperationKind[OperationKind[\"DOWNLOAD\"] = 1] = \"DOWNLOAD\";\n})(OperationKind || (OperationKind = {}));\nclass ProgressDifferentialDownloadCallbackTransform extends stream_1.Transform {\n    constructor(progressDifferentialDownloadInfo, cancellationToken, onProgress) {\n        super();\n        this.progressDifferentialDownloadInfo = progressDifferentialDownloadInfo;\n        this.cancellationToken = cancellationToken;\n        this.onProgress = onProgress;\n        this.start = Date.now();\n        this.transferred = 0;\n        this.delta = 0;\n        this.expectedBytes = 0;\n        this.index = 0;\n        this.operationType = OperationKind.COPY;\n        this.nextUpdate = this.start + 1000;\n    }\n    _transform(chunk, encoding, callback) {\n        if (this.cancellationToken.cancelled) {\n            callback(new Error(\"cancelled\"), null);\n            return;\n        }\n        // Don't send progress update when copying from disk\n        if (this.operationType == OperationKind.COPY) {\n            callback(null, chunk);\n            return;\n        }\n        this.transferred += chunk.length;\n        this.delta += chunk.length;\n        const now = Date.now();\n        if (now >= this.nextUpdate &&\n            this.transferred !== this.expectedBytes /* will be emitted by endRangeDownload() */ &&\n            this.transferred !== this.progressDifferentialDownloadInfo.grandTotal /* will be emitted on _flush */) {\n            this.nextUpdate = now + 1000;\n            this.onProgress({\n                total: this.progressDifferentialDownloadInfo.grandTotal,\n                delta: this.delta,\n                transferred: this.transferred,\n                percent: (this.transferred / this.progressDifferentialDownloadInfo.grandTotal) * 100,\n                bytesPerSecond: Math.round(this.transferred / ((now - this.start) / 1000)),\n            });\n            this.delta = 0;\n        }\n        callback(null, chunk);\n    }\n    beginFileCopy() {\n        this.operationType = OperationKind.COPY;\n    }\n    beginRangeDownload() {\n        this.operationType = OperationKind.DOWNLOAD;\n        this.expectedBytes += this.progressDifferentialDownloadInfo.expectedByteCounts[this.index++];\n    }\n    endRangeDownload() {\n        // _flush() will doour final 100%\n        if (this.transferred !== this.progressDifferentialDownloadInfo.grandTotal) {\n            this.onProgress({\n                total: this.progressDifferentialDownloadInfo.grandTotal,\n                delta: this.delta,\n                transferred: this.transferred,\n                percent: (this.transferred / this.progressDifferentialDownloadInfo.grandTotal) * 100,\n                bytesPerSecond: Math.round(this.transferred / ((Date.now() - this.start) / 1000)),\n            });\n        }\n    }\n    // Called when we are 100% done with the connection/download\n    _flush(callback) {\n        if (this.cancellationToken.cancelled) {\n            callback(new Error(\"cancelled\"));\n            return;\n        }\n        this.onProgress({\n            total: this.progressDifferentialDownloadInfo.grandTotal,\n            delta: this.delta,\n            transferred: this.transferred,\n            percent: 100,\n            bytesPerSecond: Math.round(this.transferred / ((Date.now() - this.start) / 1000)),\n        });\n        this.delta = 0;\n        this.transferred = 0;\n        callback(null);\n    }\n}\nexports.ProgressDifferentialDownloadCallbackTransform = ProgressDifferentialDownloadCallbackTransform;\n//# sourceMappingURL=ProgressDifferentialDownloadCallbackTransform.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/differentialDownloader/ProgressDifferentialDownloadCallbackTransform.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/differentialDownloader/downloadPlanBuilder.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/electron-updater/out/differentialDownloader/downloadPlanBuilder.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.computeOperations = exports.OperationKind = void 0;\nvar OperationKind;\n(function (OperationKind) {\n    OperationKind[OperationKind[\"COPY\"] = 0] = \"COPY\";\n    OperationKind[OperationKind[\"DOWNLOAD\"] = 1] = \"DOWNLOAD\";\n})(OperationKind = exports.OperationKind || (exports.OperationKind = {}));\nfunction computeOperations(oldBlockMap, newBlockMap, logger) {\n    const nameToOldBlocks = buildBlockFileMap(oldBlockMap.files);\n    const nameToNewBlocks = buildBlockFileMap(newBlockMap.files);\n    let lastOperation = null;\n    // for now only one file is supported in block map\n    const blockMapFile = newBlockMap.files[0];\n    const operations = [];\n    const name = blockMapFile.name;\n    const oldEntry = nameToOldBlocks.get(name);\n    if (oldEntry == null) {\n        // new file (unrealistic case for now, because in any case both blockmap contain the only file named as \"file\")\n        throw new Error(`no file ${name} in old blockmap`);\n    }\n    const newFile = nameToNewBlocks.get(name);\n    let changedBlockCount = 0;\n    const { checksumToOffset: checksumToOldOffset, checksumToOldSize } = buildChecksumMap(nameToOldBlocks.get(name), oldEntry.offset, logger);\n    let newOffset = blockMapFile.offset;\n    for (let i = 0; i < newFile.checksums.length; newOffset += newFile.sizes[i], i++) {\n        const blockSize = newFile.sizes[i];\n        const checksum = newFile.checksums[i];\n        let oldOffset = checksumToOldOffset.get(checksum);\n        if (oldOffset != null && checksumToOldSize.get(checksum) !== blockSize) {\n            logger.warn(`Checksum (\"${checksum}\") matches, but size differs (old: ${checksumToOldSize.get(checksum)}, new: ${blockSize})`);\n            oldOffset = undefined;\n        }\n        if (oldOffset === undefined) {\n            // download data from new file\n            changedBlockCount++;\n            if (lastOperation != null && lastOperation.kind === OperationKind.DOWNLOAD && lastOperation.end === newOffset) {\n                lastOperation.end += blockSize;\n            }\n            else {\n                lastOperation = {\n                    kind: OperationKind.DOWNLOAD,\n                    start: newOffset,\n                    end: newOffset + blockSize,\n                    // oldBlocks: null,\n                };\n                validateAndAdd(lastOperation, operations, checksum, i);\n            }\n        }\n        else {\n            // reuse data from old file\n            if (lastOperation != null && lastOperation.kind === OperationKind.COPY && lastOperation.end === oldOffset) {\n                lastOperation.end += blockSize;\n                // lastOperation.oldBlocks!!.push(checksum)\n            }\n            else {\n                lastOperation = {\n                    kind: OperationKind.COPY,\n                    start: oldOffset,\n                    end: oldOffset + blockSize,\n                    // oldBlocks: [checksum]\n                };\n                validateAndAdd(lastOperation, operations, checksum, i);\n            }\n        }\n    }\n    if (changedBlockCount > 0) {\n        logger.info(`File${blockMapFile.name === \"file\" ? \"\" : \" \" + blockMapFile.name} has ${changedBlockCount} changed blocks`);\n    }\n    return operations;\n}\nexports.computeOperations = computeOperations;\nconst isValidateOperationRange = process.env[\"DIFFERENTIAL_DOWNLOAD_PLAN_BUILDER_VALIDATE_RANGES\"] === \"true\";\nfunction validateAndAdd(operation, operations, checksum, index) {\n    if (isValidateOperationRange && operations.length !== 0) {\n        const lastOperation = operations[operations.length - 1];\n        if (lastOperation.kind === operation.kind && operation.start < lastOperation.end && operation.start > lastOperation.start) {\n            const min = [lastOperation.start, lastOperation.end, operation.start, operation.end].reduce((p, v) => (p < v ? p : v));\n            throw new Error(`operation (block index: ${index}, checksum: ${checksum}, kind: ${OperationKind[operation.kind]}) overlaps previous operation (checksum: ${checksum}):\\n` +\n                `abs: ${lastOperation.start} until ${lastOperation.end} and ${operation.start} until ${operation.end}\\n` +\n                `rel: ${lastOperation.start - min} until ${lastOperation.end - min} and ${operation.start - min} until ${operation.end - min}`);\n        }\n    }\n    operations.push(operation);\n}\n// eslint-disable-next-line @typescript-eslint/explicit-function-return-type\nfunction buildChecksumMap(file, fileOffset, logger) {\n    const checksumToOffset = new Map();\n    const checksumToSize = new Map();\n    let offset = fileOffset;\n    for (let i = 0; i < file.checksums.length; i++) {\n        const checksum = file.checksums[i];\n        const size = file.sizes[i];\n        const existing = checksumToSize.get(checksum);\n        if (existing === undefined) {\n            checksumToOffset.set(checksum, offset);\n            checksumToSize.set(checksum, size);\n        }\n        else if (logger.debug != null) {\n            const sizeExplanation = existing === size ? \"(same size)\" : `(size: ${existing}, this size: ${size})`;\n            logger.debug(`${checksum} duplicated in blockmap ${sizeExplanation}, it doesn't lead to broken differential downloader, just corresponding block will be skipped)`);\n        }\n        offset += size;\n    }\n    return { checksumToOffset, checksumToOldSize: checksumToSize };\n}\nfunction buildBlockFileMap(list) {\n    const result = new Map();\n    for (const item of list) {\n        result.set(item.name, item);\n    }\n    return result;\n}\n//# sourceMappingURL=downloadPlanBuilder.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/differentialDownloader/downloadPlanBuilder.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/differentialDownloader/multipleRangeDownloader.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/electron-updater/out/differentialDownloader/multipleRangeDownloader.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.checkIsRangesSupported = exports.executeTasksUsingMultipleRangeRequests = void 0;\nconst builder_util_runtime_1 = __webpack_require__(/*! builder-util-runtime */ \"./node_modules/builder-util-runtime/out/index.js\");\nconst DataSplitter_1 = __webpack_require__(/*! ./DataSplitter */ \"./node_modules/electron-updater/out/differentialDownloader/DataSplitter.js\");\nconst downloadPlanBuilder_1 = __webpack_require__(/*! ./downloadPlanBuilder */ \"./node_modules/electron-updater/out/differentialDownloader/downloadPlanBuilder.js\");\nfunction executeTasksUsingMultipleRangeRequests(differentialDownloader, tasks, out, oldFileFd, reject) {\n    const w = (taskOffset) => {\n        if (taskOffset >= tasks.length) {\n            if (differentialDownloader.fileMetadataBuffer != null) {\n                out.write(differentialDownloader.fileMetadataBuffer);\n            }\n            out.end();\n            return;\n        }\n        const nextOffset = taskOffset + 1000;\n        doExecuteTasks(differentialDownloader, {\n            tasks,\n            start: taskOffset,\n            end: Math.min(tasks.length, nextOffset),\n            oldFileFd,\n        }, out, () => w(nextOffset), reject);\n    };\n    return w;\n}\nexports.executeTasksUsingMultipleRangeRequests = executeTasksUsingMultipleRangeRequests;\nfunction doExecuteTasks(differentialDownloader, options, out, resolve, reject) {\n    let ranges = \"bytes=\";\n    let partCount = 0;\n    const partIndexToTaskIndex = new Map();\n    const partIndexToLength = [];\n    for (let i = options.start; i < options.end; i++) {\n        const task = options.tasks[i];\n        if (task.kind === downloadPlanBuilder_1.OperationKind.DOWNLOAD) {\n            ranges += `${task.start}-${task.end - 1}, `;\n            partIndexToTaskIndex.set(partCount, i);\n            partCount++;\n            partIndexToLength.push(task.end - task.start);\n        }\n    }\n    if (partCount <= 1) {\n        // the only remote range - copy\n        const w = (index) => {\n            if (index >= options.end) {\n                resolve();\n                return;\n            }\n            const task = options.tasks[index++];\n            if (task.kind === downloadPlanBuilder_1.OperationKind.COPY) {\n                (0, DataSplitter_1.copyData)(task, out, options.oldFileFd, reject, () => w(index));\n            }\n            else {\n                const requestOptions = differentialDownloader.createRequestOptions();\n                requestOptions.headers.Range = `bytes=${task.start}-${task.end - 1}`;\n                const request = differentialDownloader.httpExecutor.createRequest(requestOptions, response => {\n                    if (!checkIsRangesSupported(response, reject)) {\n                        return;\n                    }\n                    response.pipe(out, {\n                        end: false,\n                    });\n                    response.once(\"end\", () => w(index));\n                });\n                differentialDownloader.httpExecutor.addErrorAndTimeoutHandlers(request, reject);\n                request.end();\n            }\n        };\n        w(options.start);\n        return;\n    }\n    const requestOptions = differentialDownloader.createRequestOptions();\n    requestOptions.headers.Range = ranges.substring(0, ranges.length - 2);\n    const request = differentialDownloader.httpExecutor.createRequest(requestOptions, response => {\n        if (!checkIsRangesSupported(response, reject)) {\n            return;\n        }\n        const contentType = (0, builder_util_runtime_1.safeGetHeader)(response, \"content-type\");\n        const m = /^multipart\\/.+?(?:; boundary=(?:(?:\"(.+)\")|(?:([^\\s]+))))$/i.exec(contentType);\n        if (m == null) {\n            reject(new Error(`Content-Type \"multipart/byteranges\" is expected, but got \"${contentType}\"`));\n            return;\n        }\n        const dicer = new DataSplitter_1.DataSplitter(out, options, partIndexToTaskIndex, m[1] || m[2], partIndexToLength, resolve);\n        dicer.on(\"error\", reject);\n        response.pipe(dicer);\n        response.on(\"end\", () => {\n            setTimeout(() => {\n                request.abort();\n                reject(new Error(\"Response ends without calling any handlers\"));\n            }, 10000);\n        });\n    });\n    differentialDownloader.httpExecutor.addErrorAndTimeoutHandlers(request, reject);\n    request.end();\n}\nfunction checkIsRangesSupported(response, reject) {\n    // Electron net handles redirects automatically, our NodeJS test server doesn't use redirects - so, we don't check 3xx codes.\n    if (response.statusCode >= 400) {\n        reject((0, builder_util_runtime_1.createHttpError)(response));\n        return false;\n    }\n    if (response.statusCode !== 206) {\n        const acceptRanges = (0, builder_util_runtime_1.safeGetHeader)(response, \"accept-ranges\");\n        if (acceptRanges == null || acceptRanges === \"none\") {\n            reject(new Error(`Server doesn't support Accept-Ranges (response code ${response.statusCode})`));\n            return false;\n        }\n    }\n    return true;\n}\nexports.checkIsRangesSupported = checkIsRangesSupported;\n//# sourceMappingURL=multipleRangeDownloader.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/differentialDownloader/multipleRangeDownloader.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/electronHttpExecutor.js":
/*!*******************************************************************!*\
  !*** ./node_modules/electron-updater/out/electronHttpExecutor.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ElectronHttpExecutor = exports.getNetSession = exports.NET_SESSION_NAME = void 0;\nconst builder_util_runtime_1 = __webpack_require__(/*! builder-util-runtime */ \"./node_modules/builder-util-runtime/out/index.js\");\nexports.NET_SESSION_NAME = \"electron-updater\";\nfunction getNetSession() {\n    return (__webpack_require__(/*! electron */ \"electron\").session.fromPartition)(exports.NET_SESSION_NAME, {\n        cache: false,\n    });\n}\nexports.getNetSession = getNetSession;\nclass ElectronHttpExecutor extends builder_util_runtime_1.HttpExecutor {\n    constructor(proxyLoginCallback) {\n        super();\n        this.proxyLoginCallback = proxyLoginCallback;\n        this.cachedSession = null;\n    }\n    async download(url, destination, options) {\n        return await options.cancellationToken.createPromise((resolve, reject, onCancel) => {\n            const requestOptions = {\n                headers: options.headers || undefined,\n                redirect: \"manual\",\n            };\n            (0, builder_util_runtime_1.configureRequestUrl)(url, requestOptions);\n            (0, builder_util_runtime_1.configureRequestOptions)(requestOptions);\n            this.doDownload(requestOptions, {\n                destination,\n                options,\n                onCancel,\n                callback: error => {\n                    if (error == null) {\n                        resolve(destination);\n                    }\n                    else {\n                        reject(error);\n                    }\n                },\n                responseHandler: null,\n            }, 0);\n        });\n    }\n    createRequest(options, callback) {\n        // fix (node 7+) for making electron updater work when using AWS private buckets, check if headers contain Host property\n        if (options.headers && options.headers.Host) {\n            // set host value from headers.Host\n            options.host = options.headers.Host;\n            // remove header property 'Host', if not removed causes net::ERR_INVALID_ARGUMENT exception\n            delete options.headers.Host;\n        }\n        // differential downloader can call this method very often, so, better to cache session\n        if (this.cachedSession == null) {\n            this.cachedSession = getNetSession();\n        }\n        const request = (__webpack_require__(/*! electron */ \"electron\").net.request)({\n            ...options,\n            session: this.cachedSession,\n        });\n        request.on(\"response\", callback);\n        if (this.proxyLoginCallback != null) {\n            request.on(\"login\", this.proxyLoginCallback);\n        }\n        return request;\n    }\n    addRedirectHandlers(request, options, reject, redirectCount, handler) {\n        request.on(\"redirect\", (statusCode, method, redirectUrl) => {\n            // no way to modify request options, abort old and make a new one\n            // https://github.com/electron/electron/issues/11505\n            request.abort();\n            if (redirectCount > this.maxRedirects) {\n                reject(this.createMaxRedirectError());\n            }\n            else {\n                handler(builder_util_runtime_1.HttpExecutor.prepareRedirectUrlOptions(redirectUrl, options));\n            }\n        });\n    }\n}\nexports.ElectronHttpExecutor = ElectronHttpExecutor;\n//# sourceMappingURL=electronHttpExecutor.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/electronHttpExecutor.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/main.js":
/*!***************************************************!*\
  !*** ./node_modules/electron-updater/out/main.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.UpdaterSignal = exports.UPDATE_DOWNLOADED = exports.DOWNLOAD_PROGRESS = exports.NsisUpdater = exports.MacUpdater = exports.RpmUpdater = exports.DebUpdater = exports.AppImageUpdater = exports.Provider = exports.CancellationToken = exports.NoOpLogger = exports.AppUpdater = void 0;\nconst builder_util_runtime_1 = __webpack_require__(/*! builder-util-runtime */ \"./node_modules/builder-util-runtime/out/index.js\");\nObject.defineProperty(exports, \"CancellationToken\", ({ enumerable: true, get: function () { return builder_util_runtime_1.CancellationToken; } }));\nconst fs_extra_1 = __webpack_require__(/*! fs-extra */ \"./node_modules/electron-updater/node_modules/fs-extra/lib/index.js\");\nconst path = __webpack_require__(/*! path */ \"path\");\nvar AppUpdater_1 = __webpack_require__(/*! ./AppUpdater */ \"./node_modules/electron-updater/out/AppUpdater.js\");\nObject.defineProperty(exports, \"AppUpdater\", ({ enumerable: true, get: function () { return AppUpdater_1.AppUpdater; } }));\nObject.defineProperty(exports, \"NoOpLogger\", ({ enumerable: true, get: function () { return AppUpdater_1.NoOpLogger; } }));\nvar Provider_1 = __webpack_require__(/*! ./providers/Provider */ \"./node_modules/electron-updater/out/providers/Provider.js\");\nObject.defineProperty(exports, \"Provider\", ({ enumerable: true, get: function () { return Provider_1.Provider; } }));\nvar AppImageUpdater_1 = __webpack_require__(/*! ./AppImageUpdater */ \"./node_modules/electron-updater/out/AppImageUpdater.js\");\nObject.defineProperty(exports, \"AppImageUpdater\", ({ enumerable: true, get: function () { return AppImageUpdater_1.AppImageUpdater; } }));\nvar DebUpdater_1 = __webpack_require__(/*! ./DebUpdater */ \"./node_modules/electron-updater/out/DebUpdater.js\");\nObject.defineProperty(exports, \"DebUpdater\", ({ enumerable: true, get: function () { return DebUpdater_1.DebUpdater; } }));\nvar RpmUpdater_1 = __webpack_require__(/*! ./RpmUpdater */ \"./node_modules/electron-updater/out/RpmUpdater.js\");\nObject.defineProperty(exports, \"RpmUpdater\", ({ enumerable: true, get: function () { return RpmUpdater_1.RpmUpdater; } }));\nvar MacUpdater_1 = __webpack_require__(/*! ./MacUpdater */ \"./node_modules/electron-updater/out/MacUpdater.js\");\nObject.defineProperty(exports, \"MacUpdater\", ({ enumerable: true, get: function () { return MacUpdater_1.MacUpdater; } }));\nvar NsisUpdater_1 = __webpack_require__(/*! ./NsisUpdater */ \"./node_modules/electron-updater/out/NsisUpdater.js\");\nObject.defineProperty(exports, \"NsisUpdater\", ({ enumerable: true, get: function () { return NsisUpdater_1.NsisUpdater; } }));\n// autoUpdater to mimic electron bundled autoUpdater\nlet _autoUpdater;\nfunction doLoadAutoUpdater() {\n    // tslint:disable:prefer-conditional-expression\n    if (process.platform === \"win32\") {\n        _autoUpdater = new ((__webpack_require__(/*! ./NsisUpdater */ \"./node_modules/electron-updater/out/NsisUpdater.js\").NsisUpdater))();\n    }\n    else if (process.platform === \"darwin\") {\n        _autoUpdater = new ((__webpack_require__(/*! ./MacUpdater */ \"./node_modules/electron-updater/out/MacUpdater.js\").MacUpdater))();\n    }\n    else {\n        _autoUpdater = new ((__webpack_require__(/*! ./AppImageUpdater */ \"./node_modules/electron-updater/out/AppImageUpdater.js\").AppImageUpdater))();\n        try {\n            const identity = path.join(process.resourcesPath, \"package-type\");\n            if (!(0, fs_extra_1.existsSync)(identity)) {\n                return _autoUpdater;\n            }\n            console.info(\"Checking for beta autoupdate feature for deb/rpm distributions\");\n            const fileType = (0, fs_extra_1.readFileSync)(identity).toString().trim();\n            console.info(\"Found package-type:\", fileType);\n            switch (fileType) {\n                case \"deb\":\n                    _autoUpdater = new ((__webpack_require__(/*! ./DebUpdater */ \"./node_modules/electron-updater/out/DebUpdater.js\").DebUpdater))();\n                    break;\n                case \"rpm\":\n                    _autoUpdater = new ((__webpack_require__(/*! ./RpmUpdater */ \"./node_modules/electron-updater/out/RpmUpdater.js\").RpmUpdater))();\n                    break;\n                default:\n                    break;\n            }\n        }\n        catch (error) {\n            console.warn(\"Unable to detect 'package-type' for autoUpdater (beta rpm/deb support). If you'd like to expand support, please consider contributing to electron-builder\", error.message);\n        }\n    }\n    return _autoUpdater;\n}\nObject.defineProperty(exports, \"autoUpdater\", ({\n    enumerable: true,\n    get: () => {\n        return _autoUpdater || doLoadAutoUpdater();\n    },\n}));\nexports.DOWNLOAD_PROGRESS = \"download-progress\";\nexports.UPDATE_DOWNLOADED = \"update-downloaded\";\nclass UpdaterSignal {\n    constructor(emitter) {\n        this.emitter = emitter;\n    }\n    /**\n     * Emitted when an authenticating proxy is [asking for user credentials](https://github.com/electron/electron/blob/master/docs/api/client-request.md#event-login).\n     */\n    login(handler) {\n        addHandler(this.emitter, \"login\", handler);\n    }\n    progress(handler) {\n        addHandler(this.emitter, exports.DOWNLOAD_PROGRESS, handler);\n    }\n    updateDownloaded(handler) {\n        addHandler(this.emitter, exports.UPDATE_DOWNLOADED, handler);\n    }\n    updateCancelled(handler) {\n        addHandler(this.emitter, \"update-cancelled\", handler);\n    }\n}\nexports.UpdaterSignal = UpdaterSignal;\nconst isLogEvent = false;\nfunction addHandler(emitter, event, handler) {\n    if (isLogEvent) {\n        emitter.on(event, (...args) => {\n            console.log(\"%s %s\", event, args);\n            handler(...args);\n        });\n    }\n    else {\n        emitter.on(event, handler);\n    }\n}\n//# sourceMappingURL=main.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/main.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/providerFactory.js":
/*!**************************************************************!*\
  !*** ./node_modules/electron-updater/out/providerFactory.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.createClient = exports.isUrlProbablySupportMultiRangeRequests = void 0;\nconst builder_util_runtime_1 = __webpack_require__(/*! builder-util-runtime */ \"./node_modules/builder-util-runtime/out/index.js\");\nconst BitbucketProvider_1 = __webpack_require__(/*! ./providers/BitbucketProvider */ \"./node_modules/electron-updater/out/providers/BitbucketProvider.js\");\nconst GenericProvider_1 = __webpack_require__(/*! ./providers/GenericProvider */ \"./node_modules/electron-updater/out/providers/GenericProvider.js\");\nconst GitHubProvider_1 = __webpack_require__(/*! ./providers/GitHubProvider */ \"./node_modules/electron-updater/out/providers/GitHubProvider.js\");\nconst KeygenProvider_1 = __webpack_require__(/*! ./providers/KeygenProvider */ \"./node_modules/electron-updater/out/providers/KeygenProvider.js\");\nconst PrivateGitHubProvider_1 = __webpack_require__(/*! ./providers/PrivateGitHubProvider */ \"./node_modules/electron-updater/out/providers/PrivateGitHubProvider.js\");\nfunction isUrlProbablySupportMultiRangeRequests(url) {\n    return !url.includes(\"s3.amazonaws.com\");\n}\nexports.isUrlProbablySupportMultiRangeRequests = isUrlProbablySupportMultiRangeRequests;\nfunction createClient(data, updater, runtimeOptions) {\n    // noinspection SuspiciousTypeOfGuard\n    if (typeof data === \"string\") {\n        throw (0, builder_util_runtime_1.newError)(\"Please pass PublishConfiguration object\", \"ERR_UPDATER_INVALID_PROVIDER_CONFIGURATION\");\n    }\n    const provider = data.provider;\n    switch (provider) {\n        case \"github\": {\n            const githubOptions = data;\n            const token = (githubOptions.private ? process.env[\"GH_TOKEN\"] || process.env[\"GITHUB_TOKEN\"] : null) || githubOptions.token;\n            if (token == null) {\n                return new GitHubProvider_1.GitHubProvider(githubOptions, updater, runtimeOptions);\n            }\n            else {\n                return new PrivateGitHubProvider_1.PrivateGitHubProvider(githubOptions, updater, token, runtimeOptions);\n            }\n        }\n        case \"bitbucket\":\n            return new BitbucketProvider_1.BitbucketProvider(data, updater, runtimeOptions);\n        case \"keygen\":\n            return new KeygenProvider_1.KeygenProvider(data, updater, runtimeOptions);\n        case \"s3\":\n        case \"spaces\":\n            return new GenericProvider_1.GenericProvider({\n                provider: \"generic\",\n                url: (0, builder_util_runtime_1.getS3LikeProviderBaseUrl)(data),\n                channel: data.channel || null,\n            }, updater, {\n                ...runtimeOptions,\n                // https://github.com/minio/minio/issues/5285#issuecomment-350428955\n                isUseMultipleRangeRequest: false,\n            });\n        case \"generic\": {\n            const options = data;\n            return new GenericProvider_1.GenericProvider(options, updater, {\n                ...runtimeOptions,\n                isUseMultipleRangeRequest: options.useMultipleRangeRequest !== false && isUrlProbablySupportMultiRangeRequests(options.url),\n            });\n        }\n        case \"custom\": {\n            const options = data;\n            const constructor = options.updateProvider;\n            if (!constructor) {\n                throw (0, builder_util_runtime_1.newError)(\"Custom provider not specified\", \"ERR_UPDATER_INVALID_PROVIDER_CONFIGURATION\");\n            }\n            return new constructor(options, updater, runtimeOptions);\n        }\n        default:\n            throw (0, builder_util_runtime_1.newError)(`Unsupported provider: ${provider}`, \"ERR_UPDATER_UNSUPPORTED_PROVIDER\");\n    }\n}\nexports.createClient = createClient;\n//# sourceMappingURL=providerFactory.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/providerFactory.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/providers/BitbucketProvider.js":
/*!**************************************************************************!*\
  !*** ./node_modules/electron-updater/out/providers/BitbucketProvider.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.BitbucketProvider = void 0;\nconst builder_util_runtime_1 = __webpack_require__(/*! builder-util-runtime */ \"./node_modules/builder-util-runtime/out/index.js\");\nconst util_1 = __webpack_require__(/*! ../util */ \"./node_modules/electron-updater/out/util.js\");\nconst Provider_1 = __webpack_require__(/*! ./Provider */ \"./node_modules/electron-updater/out/providers/Provider.js\");\nclass BitbucketProvider extends Provider_1.Provider {\n    constructor(configuration, updater, runtimeOptions) {\n        super({\n            ...runtimeOptions,\n            isUseMultipleRangeRequest: false,\n        });\n        this.configuration = configuration;\n        this.updater = updater;\n        const { owner, slug } = configuration;\n        this.baseUrl = (0, util_1.newBaseUrl)(`https://api.bitbucket.org/2.0/repositories/${owner}/${slug}/downloads`);\n    }\n    get channel() {\n        return this.updater.channel || this.configuration.channel || \"latest\";\n    }\n    async getLatestVersion() {\n        const cancellationToken = new builder_util_runtime_1.CancellationToken();\n        const channelFile = (0, util_1.getChannelFilename)(this.getCustomChannelName(this.channel));\n        const channelUrl = (0, util_1.newUrlFromBase)(channelFile, this.baseUrl, this.updater.isAddNoCacheQuery);\n        try {\n            const updateInfo = await this.httpRequest(channelUrl, undefined, cancellationToken);\n            return (0, Provider_1.parseUpdateInfo)(updateInfo, channelFile, channelUrl);\n        }\n        catch (e) {\n            throw (0, builder_util_runtime_1.newError)(`Unable to find latest version on ${this.toString()}, please ensure release exists: ${e.stack || e.message}`, \"ERR_UPDATER_LATEST_VERSION_NOT_FOUND\");\n        }\n    }\n    resolveFiles(updateInfo) {\n        return (0, Provider_1.resolveFiles)(updateInfo, this.baseUrl);\n    }\n    toString() {\n        const { owner, slug } = this.configuration;\n        return `Bitbucket (owner: ${owner}, slug: ${slug}, channel: ${this.channel})`;\n    }\n}\nexports.BitbucketProvider = BitbucketProvider;\n//# sourceMappingURL=BitbucketProvider.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/providers/BitbucketProvider.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/providers/GenericProvider.js":
/*!************************************************************************!*\
  !*** ./node_modules/electron-updater/out/providers/GenericProvider.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.GenericProvider = void 0;\nconst builder_util_runtime_1 = __webpack_require__(/*! builder-util-runtime */ \"./node_modules/builder-util-runtime/out/index.js\");\nconst util_1 = __webpack_require__(/*! ../util */ \"./node_modules/electron-updater/out/util.js\");\nconst Provider_1 = __webpack_require__(/*! ./Provider */ \"./node_modules/electron-updater/out/providers/Provider.js\");\nclass GenericProvider extends Provider_1.Provider {\n    constructor(configuration, updater, runtimeOptions) {\n        super(runtimeOptions);\n        this.configuration = configuration;\n        this.updater = updater;\n        this.baseUrl = (0, util_1.newBaseUrl)(this.configuration.url);\n    }\n    get channel() {\n        const result = this.updater.channel || this.configuration.channel;\n        return result == null ? this.getDefaultChannelName() : this.getCustomChannelName(result);\n    }\n    async getLatestVersion() {\n        const channelFile = (0, util_1.getChannelFilename)(this.channel);\n        const channelUrl = (0, util_1.newUrlFromBase)(channelFile, this.baseUrl, this.updater.isAddNoCacheQuery);\n        for (let attemptNumber = 0;; attemptNumber++) {\n            try {\n                return (0, Provider_1.parseUpdateInfo)(await this.httpRequest(channelUrl), channelFile, channelUrl);\n            }\n            catch (e) {\n                if (e instanceof builder_util_runtime_1.HttpError && e.statusCode === 404) {\n                    throw (0, builder_util_runtime_1.newError)(`Cannot find channel \"${channelFile}\" update info: ${e.stack || e.message}`, \"ERR_UPDATER_CHANNEL_FILE_NOT_FOUND\");\n                }\n                else if (e.code === \"ECONNREFUSED\") {\n                    if (attemptNumber < 3) {\n                        await new Promise((resolve, reject) => {\n                            try {\n                                setTimeout(resolve, 1000 * attemptNumber);\n                            }\n                            catch (e) {\n                                reject(e);\n                            }\n                        });\n                        continue;\n                    }\n                }\n                throw e;\n            }\n        }\n    }\n    resolveFiles(updateInfo) {\n        return (0, Provider_1.resolveFiles)(updateInfo, this.baseUrl);\n    }\n}\nexports.GenericProvider = GenericProvider;\n//# sourceMappingURL=GenericProvider.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/providers/GenericProvider.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/providers/GitHubProvider.js":
/*!***********************************************************************!*\
  !*** ./node_modules/electron-updater/out/providers/GitHubProvider.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.computeReleaseNotes = exports.GitHubProvider = exports.BaseGitHubProvider = void 0;\nconst builder_util_runtime_1 = __webpack_require__(/*! builder-util-runtime */ \"./node_modules/builder-util-runtime/out/index.js\");\nconst semver = __webpack_require__(/*! semver */ \"./node_modules/semver/index.js\");\nconst url_1 = __webpack_require__(/*! url */ \"url\");\nconst util_1 = __webpack_require__(/*! ../util */ \"./node_modules/electron-updater/out/util.js\");\nconst Provider_1 = __webpack_require__(/*! ./Provider */ \"./node_modules/electron-updater/out/providers/Provider.js\");\nconst hrefRegExp = /\\/tag\\/([^/]+)$/;\nclass BaseGitHubProvider extends Provider_1.Provider {\n    constructor(options, defaultHost, runtimeOptions) {\n        super({\n            ...runtimeOptions,\n            /* because GitHib uses S3 */\n            isUseMultipleRangeRequest: false,\n        });\n        this.options = options;\n        this.baseUrl = (0, util_1.newBaseUrl)((0, builder_util_runtime_1.githubUrl)(options, defaultHost));\n        const apiHost = defaultHost === \"github.com\" ? \"api.github.com\" : defaultHost;\n        this.baseApiUrl = (0, util_1.newBaseUrl)((0, builder_util_runtime_1.githubUrl)(options, apiHost));\n    }\n    computeGithubBasePath(result) {\n        // https://github.com/electron-userland/electron-builder/issues/1903#issuecomment-320881211\n        const host = this.options.host;\n        return host && ![\"github.com\", \"api.github.com\"].includes(host) ? `/api/v3${result}` : result;\n    }\n}\nexports.BaseGitHubProvider = BaseGitHubProvider;\nclass GitHubProvider extends BaseGitHubProvider {\n    constructor(options, updater, runtimeOptions) {\n        super(options, \"github.com\", runtimeOptions);\n        this.options = options;\n        this.updater = updater;\n    }\n    async getLatestVersion() {\n        var _a, _b, _c, _d;\n        const cancellationToken = new builder_util_runtime_1.CancellationToken();\n        const feedXml = (await this.httpRequest((0, util_1.newUrlFromBase)(`${this.basePath}.atom`, this.baseUrl), {\n            accept: \"application/xml, application/atom+xml, text/xml, */*\",\n        }, cancellationToken));\n        const feed = (0, builder_util_runtime_1.parseXml)(feedXml);\n        // noinspection TypeScriptValidateJSTypes\n        let latestRelease = feed.element(\"entry\", false, `No published versions on GitHub`);\n        let tag = null;\n        try {\n            if (this.updater.allowPrerelease) {\n                const currentChannel = ((_a = this.updater) === null || _a === void 0 ? void 0 : _a.channel) || ((_b = semver.prerelease(this.updater.currentVersion)) === null || _b === void 0 ? void 0 : _b[0]) || null;\n                if (currentChannel === null) {\n                    // noinspection TypeScriptValidateJSTypes\n                    tag = hrefRegExp.exec(latestRelease.element(\"link\").attribute(\"href\"))[1];\n                }\n                else {\n                    for (const element of feed.getElements(\"entry\")) {\n                        // noinspection TypeScriptValidateJSTypes\n                        const hrefElement = hrefRegExp.exec(element.element(\"link\").attribute(\"href\"));\n                        // If this is null then something is wrong and skip this release\n                        if (hrefElement === null)\n                            continue;\n                        // This Release's Tag\n                        const hrefTag = hrefElement[1];\n                        //Get Channel from this release's tag\n                        const hrefChannel = ((_c = semver.prerelease(hrefTag)) === null || _c === void 0 ? void 0 : _c[0]) || null;\n                        const shouldFetchVersion = !currentChannel || [\"alpha\", \"beta\"].includes(currentChannel);\n                        const isCustomChannel = hrefChannel !== null && ![\"alpha\", \"beta\"].includes(String(hrefChannel));\n                        // Allow moving from alpha to beta but not down\n                        const channelMismatch = currentChannel === \"beta\" && hrefChannel === \"alpha\";\n                        if (shouldFetchVersion && !isCustomChannel && !channelMismatch) {\n                            tag = hrefTag;\n                            break;\n                        }\n                        const isNextPreRelease = hrefChannel && hrefChannel === currentChannel;\n                        if (isNextPreRelease) {\n                            tag = hrefTag;\n                            break;\n                        }\n                    }\n                }\n            }\n            else {\n                tag = await this.getLatestTagName(cancellationToken);\n                for (const element of feed.getElements(\"entry\")) {\n                    // noinspection TypeScriptValidateJSTypes\n                    if (hrefRegExp.exec(element.element(\"link\").attribute(\"href\"))[1] === tag) {\n                        latestRelease = element;\n                        break;\n                    }\n                }\n            }\n        }\n        catch (e) {\n            throw (0, builder_util_runtime_1.newError)(`Cannot parse releases feed: ${e.stack || e.message},\\nXML:\\n${feedXml}`, \"ERR_UPDATER_INVALID_RELEASE_FEED\");\n        }\n        if (tag == null) {\n            throw (0, builder_util_runtime_1.newError)(`No published versions on GitHub`, \"ERR_UPDATER_NO_PUBLISHED_VERSIONS\");\n        }\n        let rawData;\n        let channelFile = \"\";\n        let channelFileUrl = \"\";\n        const fetchData = async (channelName) => {\n            channelFile = (0, util_1.getChannelFilename)(channelName);\n            channelFileUrl = (0, util_1.newUrlFromBase)(this.getBaseDownloadPath(String(tag), channelFile), this.baseUrl);\n            const requestOptions = this.createRequestOptions(channelFileUrl);\n            try {\n                return (await this.executor.request(requestOptions, cancellationToken));\n            }\n            catch (e) {\n                if (e instanceof builder_util_runtime_1.HttpError && e.statusCode === 404) {\n                    throw (0, builder_util_runtime_1.newError)(`Cannot find ${channelFile} in the latest release artifacts (${channelFileUrl}): ${e.stack || e.message}`, \"ERR_UPDATER_CHANNEL_FILE_NOT_FOUND\");\n                }\n                throw e;\n            }\n        };\n        try {\n            const channel = this.updater.allowPrerelease ? this.getCustomChannelName(String(((_d = semver.prerelease(tag)) === null || _d === void 0 ? void 0 : _d[0]) || \"latest\")) : this.getDefaultChannelName();\n            rawData = await fetchData(channel);\n        }\n        catch (e) {\n            if (this.updater.allowPrerelease) {\n                // Allow fallback to `latest.yml`\n                rawData = await fetchData(this.getDefaultChannelName());\n            }\n            else {\n                throw e;\n            }\n        }\n        const result = (0, Provider_1.parseUpdateInfo)(rawData, channelFile, channelFileUrl);\n        if (result.releaseName == null) {\n            result.releaseName = latestRelease.elementValueOrEmpty(\"title\");\n        }\n        if (result.releaseNotes == null) {\n            result.releaseNotes = computeReleaseNotes(this.updater.currentVersion, this.updater.fullChangelog, feed, latestRelease);\n        }\n        return {\n            tag: tag,\n            ...result,\n        };\n    }\n    async getLatestTagName(cancellationToken) {\n        const options = this.options;\n        // do not use API for GitHub to avoid limit, only for custom host or GitHub Enterprise\n        const url = options.host == null || options.host === \"github.com\"\n            ? (0, util_1.newUrlFromBase)(`${this.basePath}/latest`, this.baseUrl)\n            : new url_1.URL(`${this.computeGithubBasePath(`/repos/${options.owner}/${options.repo}/releases`)}/latest`, this.baseApiUrl);\n        try {\n            const rawData = await this.httpRequest(url, { Accept: \"application/json\" }, cancellationToken);\n            if (rawData == null) {\n                return null;\n            }\n            const releaseInfo = JSON.parse(rawData);\n            return releaseInfo.tag_name;\n        }\n        catch (e) {\n            throw (0, builder_util_runtime_1.newError)(`Unable to find latest version on GitHub (${url}), please ensure a production release exists: ${e.stack || e.message}`, \"ERR_UPDATER_LATEST_VERSION_NOT_FOUND\");\n        }\n    }\n    get basePath() {\n        return `/${this.options.owner}/${this.options.repo}/releases`;\n    }\n    resolveFiles(updateInfo) {\n        // still replace space to - due to backward compatibility\n        return (0, Provider_1.resolveFiles)(updateInfo, this.baseUrl, p => this.getBaseDownloadPath(updateInfo.tag, p.replace(/ /g, \"-\")));\n    }\n    getBaseDownloadPath(tag, fileName) {\n        return `${this.basePath}/download/${tag}/${fileName}`;\n    }\n}\nexports.GitHubProvider = GitHubProvider;\nfunction getNoteValue(parent) {\n    const result = parent.elementValueOrEmpty(\"content\");\n    // GitHub reports empty notes as <content>No content.</content>\n    return result === \"No content.\" ? \"\" : result;\n}\nfunction computeReleaseNotes(currentVersion, isFullChangelog, feed, latestRelease) {\n    if (!isFullChangelog) {\n        return getNoteValue(latestRelease);\n    }\n    const releaseNotes = [];\n    for (const release of feed.getElements(\"entry\")) {\n        // noinspection TypeScriptValidateJSTypes\n        const versionRelease = /\\/tag\\/v?([^/]+)$/.exec(release.element(\"link\").attribute(\"href\"))[1];\n        if (semver.lt(currentVersion, versionRelease)) {\n            releaseNotes.push({\n                version: versionRelease,\n                note: getNoteValue(release),\n            });\n        }\n    }\n    return releaseNotes.sort((a, b) => semver.rcompare(a.version, b.version));\n}\nexports.computeReleaseNotes = computeReleaseNotes;\n//# sourceMappingURL=GitHubProvider.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/providers/GitHubProvider.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/providers/KeygenProvider.js":
/*!***********************************************************************!*\
  !*** ./node_modules/electron-updater/out/providers/KeygenProvider.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.KeygenProvider = void 0;\nconst builder_util_runtime_1 = __webpack_require__(/*! builder-util-runtime */ \"./node_modules/builder-util-runtime/out/index.js\");\nconst util_1 = __webpack_require__(/*! ../util */ \"./node_modules/electron-updater/out/util.js\");\nconst Provider_1 = __webpack_require__(/*! ./Provider */ \"./node_modules/electron-updater/out/providers/Provider.js\");\nclass KeygenProvider extends Provider_1.Provider {\n    constructor(configuration, updater, runtimeOptions) {\n        super({\n            ...runtimeOptions,\n            isUseMultipleRangeRequest: false,\n        });\n        this.configuration = configuration;\n        this.updater = updater;\n        this.baseUrl = (0, util_1.newBaseUrl)(`https://api.keygen.sh/v1/accounts/${this.configuration.account}/artifacts?product=${this.configuration.product}`);\n    }\n    get channel() {\n        return this.updater.channel || this.configuration.channel || \"stable\";\n    }\n    async getLatestVersion() {\n        const cancellationToken = new builder_util_runtime_1.CancellationToken();\n        const channelFile = (0, util_1.getChannelFilename)(this.getCustomChannelName(this.channel));\n        const channelUrl = (0, util_1.newUrlFromBase)(channelFile, this.baseUrl, this.updater.isAddNoCacheQuery);\n        try {\n            const updateInfo = await this.httpRequest(channelUrl, {\n                Accept: \"application/vnd.api+json\",\n                \"Keygen-Version\": \"1.1\",\n            }, cancellationToken);\n            return (0, Provider_1.parseUpdateInfo)(updateInfo, channelFile, channelUrl);\n        }\n        catch (e) {\n            throw (0, builder_util_runtime_1.newError)(`Unable to find latest version on ${this.toString()}, please ensure release exists: ${e.stack || e.message}`, \"ERR_UPDATER_LATEST_VERSION_NOT_FOUND\");\n        }\n    }\n    resolveFiles(updateInfo) {\n        return (0, Provider_1.resolveFiles)(updateInfo, this.baseUrl);\n    }\n    toString() {\n        const { account, product, platform } = this.configuration;\n        return `Keygen (account: ${account}, product: ${product}, platform: ${platform}, channel: ${this.channel})`;\n    }\n}\nexports.KeygenProvider = KeygenProvider;\n//# sourceMappingURL=KeygenProvider.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/providers/KeygenProvider.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/providers/PrivateGitHubProvider.js":
/*!******************************************************************************!*\
  !*** ./node_modules/electron-updater/out/providers/PrivateGitHubProvider.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.PrivateGitHubProvider = void 0;\nconst builder_util_runtime_1 = __webpack_require__(/*! builder-util-runtime */ \"./node_modules/builder-util-runtime/out/index.js\");\nconst js_yaml_1 = __webpack_require__(/*! js-yaml */ \"./node_modules/js-yaml/index.js\");\nconst path = __webpack_require__(/*! path */ \"path\");\nconst url_1 = __webpack_require__(/*! url */ \"url\");\nconst util_1 = __webpack_require__(/*! ../util */ \"./node_modules/electron-updater/out/util.js\");\nconst GitHubProvider_1 = __webpack_require__(/*! ./GitHubProvider */ \"./node_modules/electron-updater/out/providers/GitHubProvider.js\");\nconst Provider_1 = __webpack_require__(/*! ./Provider */ \"./node_modules/electron-updater/out/providers/Provider.js\");\nclass PrivateGitHubProvider extends GitHubProvider_1.BaseGitHubProvider {\n    constructor(options, updater, token, runtimeOptions) {\n        super(options, \"api.github.com\", runtimeOptions);\n        this.updater = updater;\n        this.token = token;\n    }\n    createRequestOptions(url, headers) {\n        const result = super.createRequestOptions(url, headers);\n        result.redirect = \"manual\";\n        return result;\n    }\n    async getLatestVersion() {\n        const cancellationToken = new builder_util_runtime_1.CancellationToken();\n        const channelFile = (0, util_1.getChannelFilename)(this.getDefaultChannelName());\n        const releaseInfo = await this.getLatestVersionInfo(cancellationToken);\n        const asset = releaseInfo.assets.find(it => it.name === channelFile);\n        if (asset == null) {\n            // html_url must be always, but just to be sure\n            throw (0, builder_util_runtime_1.newError)(`Cannot find ${channelFile} in the release ${releaseInfo.html_url || releaseInfo.name}`, \"ERR_UPDATER_CHANNEL_FILE_NOT_FOUND\");\n        }\n        const url = new url_1.URL(asset.url);\n        let result;\n        try {\n            result = (0, js_yaml_1.load)((await this.httpRequest(url, this.configureHeaders(\"application/octet-stream\"), cancellationToken)));\n        }\n        catch (e) {\n            if (e instanceof builder_util_runtime_1.HttpError && e.statusCode === 404) {\n                throw (0, builder_util_runtime_1.newError)(`Cannot find ${channelFile} in the latest release artifacts (${url}): ${e.stack || e.message}`, \"ERR_UPDATER_CHANNEL_FILE_NOT_FOUND\");\n            }\n            throw e;\n        }\n        ;\n        result.assets = releaseInfo.assets;\n        return result;\n    }\n    get fileExtraDownloadHeaders() {\n        return this.configureHeaders(\"application/octet-stream\");\n    }\n    // eslint-disable-next-line @typescript-eslint/explicit-function-return-type\n    configureHeaders(accept) {\n        return {\n            accept,\n            authorization: `token ${this.token}`,\n        };\n    }\n    async getLatestVersionInfo(cancellationToken) {\n        const allowPrerelease = this.updater.allowPrerelease;\n        let basePath = this.basePath;\n        if (!allowPrerelease) {\n            basePath = `${basePath}/latest`;\n        }\n        const url = (0, util_1.newUrlFromBase)(basePath, this.baseUrl);\n        try {\n            const version = JSON.parse((await this.httpRequest(url, this.configureHeaders(\"application/vnd.github.v3+json\"), cancellationToken)));\n            if (allowPrerelease) {\n                return version.find(it => it.prerelease) || version[0];\n            }\n            else {\n                return version;\n            }\n        }\n        catch (e) {\n            throw (0, builder_util_runtime_1.newError)(`Unable to find latest version on GitHub (${url}), please ensure a production release exists: ${e.stack || e.message}`, \"ERR_UPDATER_LATEST_VERSION_NOT_FOUND\");\n        }\n    }\n    get basePath() {\n        return this.computeGithubBasePath(`/repos/${this.options.owner}/${this.options.repo}/releases`);\n    }\n    resolveFiles(updateInfo) {\n        return (0, Provider_1.getFileList)(updateInfo).map(it => {\n            const name = path.posix.basename(it.url).replace(/ /g, \"-\");\n            const asset = updateInfo.assets.find(it => it != null && it.name === name);\n            if (asset == null) {\n                throw (0, builder_util_runtime_1.newError)(`Cannot find asset \"${name}\" in: ${JSON.stringify(updateInfo.assets, null, 2)}`, \"ERR_UPDATER_ASSET_NOT_FOUND\");\n            }\n            return {\n                url: new url_1.URL(asset.url),\n                info: it,\n            };\n        });\n    }\n}\nexports.PrivateGitHubProvider = PrivateGitHubProvider;\n//# sourceMappingURL=PrivateGitHubProvider.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/providers/PrivateGitHubProvider.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/providers/Provider.js":
/*!*****************************************************************!*\
  !*** ./node_modules/electron-updater/out/providers/Provider.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.resolveFiles = exports.getFileList = exports.parseUpdateInfo = exports.findFile = exports.Provider = void 0;\nconst builder_util_runtime_1 = __webpack_require__(/*! builder-util-runtime */ \"./node_modules/builder-util-runtime/out/index.js\");\nconst js_yaml_1 = __webpack_require__(/*! js-yaml */ \"./node_modules/js-yaml/index.js\");\nconst util_1 = __webpack_require__(/*! ../util */ \"./node_modules/electron-updater/out/util.js\");\nclass Provider {\n    constructor(runtimeOptions) {\n        this.runtimeOptions = runtimeOptions;\n        this.requestHeaders = null;\n        this.executor = runtimeOptions.executor;\n    }\n    get isUseMultipleRangeRequest() {\n        return this.runtimeOptions.isUseMultipleRangeRequest !== false;\n    }\n    getChannelFilePrefix() {\n        if (this.runtimeOptions.platform === \"linux\") {\n            const arch = process.env[\"TEST_UPDATER_ARCH\"] || process.arch;\n            const archSuffix = arch === \"x64\" ? \"\" : `-${arch}`;\n            return \"-linux\" + archSuffix;\n        }\n        else {\n            return this.runtimeOptions.platform === \"darwin\" ? \"-mac\" : \"\";\n        }\n    }\n    // due to historical reasons for windows we use channel name without platform specifier\n    getDefaultChannelName() {\n        return this.getCustomChannelName(\"latest\");\n    }\n    getCustomChannelName(channel) {\n        return `${channel}${this.getChannelFilePrefix()}`;\n    }\n    get fileExtraDownloadHeaders() {\n        return null;\n    }\n    setRequestHeaders(value) {\n        this.requestHeaders = value;\n    }\n    /**\n     * Method to perform API request only to resolve update info, but not to download update.\n     */\n    httpRequest(url, headers, cancellationToken) {\n        return this.executor.request(this.createRequestOptions(url, headers), cancellationToken);\n    }\n    createRequestOptions(url, headers) {\n        const result = {};\n        if (this.requestHeaders == null) {\n            if (headers != null) {\n                result.headers = headers;\n            }\n        }\n        else {\n            result.headers = headers == null ? this.requestHeaders : { ...this.requestHeaders, ...headers };\n        }\n        (0, builder_util_runtime_1.configureRequestUrl)(url, result);\n        return result;\n    }\n}\nexports.Provider = Provider;\nfunction findFile(files, extension, not) {\n    if (files.length === 0) {\n        throw (0, builder_util_runtime_1.newError)(\"No files provided\", \"ERR_UPDATER_NO_FILES_PROVIDED\");\n    }\n    const result = files.find(it => it.url.pathname.toLowerCase().endsWith(`.${extension}`));\n    if (result != null) {\n        return result;\n    }\n    else if (not == null) {\n        return files[0];\n    }\n    else {\n        return files.find(fileInfo => !not.some(ext => fileInfo.url.pathname.toLowerCase().endsWith(`.${ext}`)));\n    }\n}\nexports.findFile = findFile;\nfunction parseUpdateInfo(rawData, channelFile, channelFileUrl) {\n    if (rawData == null) {\n        throw (0, builder_util_runtime_1.newError)(`Cannot parse update info from ${channelFile} in the latest release artifacts (${channelFileUrl}): rawData: null`, \"ERR_UPDATER_INVALID_UPDATE_INFO\");\n    }\n    let result;\n    try {\n        result = (0, js_yaml_1.load)(rawData);\n    }\n    catch (e) {\n        throw (0, builder_util_runtime_1.newError)(`Cannot parse update info from ${channelFile} in the latest release artifacts (${channelFileUrl}): ${e.stack || e.message}, rawData: ${rawData}`, \"ERR_UPDATER_INVALID_UPDATE_INFO\");\n    }\n    return result;\n}\nexports.parseUpdateInfo = parseUpdateInfo;\nfunction getFileList(updateInfo) {\n    const files = updateInfo.files;\n    if (files != null && files.length > 0) {\n        return files;\n    }\n    // noinspection JSDeprecatedSymbols\n    if (updateInfo.path != null) {\n        // noinspection JSDeprecatedSymbols\n        return [\n            {\n                url: updateInfo.path,\n                sha2: updateInfo.sha2,\n                sha512: updateInfo.sha512,\n            },\n        ];\n    }\n    else {\n        throw (0, builder_util_runtime_1.newError)(`No files provided: ${(0, builder_util_runtime_1.safeStringifyJson)(updateInfo)}`, \"ERR_UPDATER_NO_FILES_PROVIDED\");\n    }\n}\nexports.getFileList = getFileList;\nfunction resolveFiles(updateInfo, baseUrl, pathTransformer = (p) => p) {\n    const files = getFileList(updateInfo);\n    const result = files.map(fileInfo => {\n        if (fileInfo.sha2 == null && fileInfo.sha512 == null) {\n            throw (0, builder_util_runtime_1.newError)(`Update info doesn't contain nor sha256 neither sha512 checksum: ${(0, builder_util_runtime_1.safeStringifyJson)(fileInfo)}`, \"ERR_UPDATER_NO_CHECKSUM\");\n        }\n        return {\n            url: (0, util_1.newUrlFromBase)(pathTransformer(fileInfo.url), baseUrl),\n            info: fileInfo,\n        };\n    });\n    const packages = updateInfo.packages;\n    const packageInfo = packages == null ? null : packages[process.arch] || packages.ia32;\n    if (packageInfo != null) {\n        ;\n        result[0].packageInfo = {\n            ...packageInfo,\n            path: (0, util_1.newUrlFromBase)(pathTransformer(packageInfo.path), baseUrl).href,\n        };\n    }\n    return result;\n}\nexports.resolveFiles = resolveFiles;\n//# sourceMappingURL=Provider.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/providers/Provider.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/util.js":
/*!***************************************************!*\
  !*** ./node_modules/electron-updater/out/util.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.blockmapFiles = exports.getChannelFilename = exports.newUrlFromBase = exports.newBaseUrl = void 0;\n// if baseUrl path doesn't ends with /, this path will be not prepended to passed pathname for new URL(input, base)\nconst url_1 = __webpack_require__(/*! url */ \"url\");\n// @ts-ignore\nconst escapeRegExp = __webpack_require__(/*! lodash.escaperegexp */ \"./node_modules/lodash.escaperegexp/index.js\");\n/** @internal */\nfunction newBaseUrl(url) {\n    const result = new url_1.URL(url);\n    if (!result.pathname.endsWith(\"/\")) {\n        result.pathname += \"/\";\n    }\n    return result;\n}\nexports.newBaseUrl = newBaseUrl;\n// addRandomQueryToAvoidCaching is false by default because in most cases URL already contains version number,\n// so, it makes sense only for Generic Provider for channel files\nfunction newUrlFromBase(pathname, baseUrl, addRandomQueryToAvoidCaching = false) {\n    const result = new url_1.URL(pathname, baseUrl);\n    // search is not propagated (search is an empty string if not specified)\n    const search = baseUrl.search;\n    if (search != null && search.length !== 0) {\n        result.search = search;\n    }\n    else if (addRandomQueryToAvoidCaching) {\n        result.search = `noCache=${Date.now().toString(32)}`;\n    }\n    return result;\n}\nexports.newUrlFromBase = newUrlFromBase;\nfunction getChannelFilename(channel) {\n    return `${channel}.yml`;\n}\nexports.getChannelFilename = getChannelFilename;\nfunction blockmapFiles(baseUrl, oldVersion, newVersion) {\n    const newBlockMapUrl = newUrlFromBase(`${baseUrl.pathname}.blockmap`, baseUrl);\n    const oldBlockMapUrl = newUrlFromBase(`${baseUrl.pathname.replace(new RegExp(escapeRegExp(newVersion), \"g\"), oldVersion)}.blockmap`, baseUrl);\n    return [oldBlockMapUrl, newBlockMapUrl];\n}\nexports.blockmapFiles = blockmapFiles;\n//# sourceMappingURL=util.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/util.js?");

/***/ }),

/***/ "./node_modules/electron-updater/out/windowsExecutableCodeSignatureVerifier.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/electron-updater/out/windowsExecutableCodeSignatureVerifier.js ***!
  \*************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.verifySignature = void 0;\nconst builder_util_runtime_1 = __webpack_require__(/*! builder-util-runtime */ \"./node_modules/builder-util-runtime/out/index.js\");\nconst child_process_1 = __webpack_require__(/*! child_process */ \"child_process\");\nconst os = __webpack_require__(/*! os */ \"os\");\n// $certificateInfo = (Get-AuthenticodeSignature 'xxx\\yyy.exe'\n// | where {$_.Status.Equals([System.Management.Automation.SignatureStatus]::Valid) -and $_.SignerCertificate.Subject.Contains(\"CN=siemens.com\")})\n// | Out-String ; if ($certificateInfo) { exit 0 } else { exit 1 }\nfunction verifySignature(publisherNames, unescapedTempUpdateFile, logger) {\n    return new Promise((resolve, reject) => {\n        // Escape quotes and backticks in filenames to prevent user from breaking the\n        // arguments and perform a remote command injection.\n        //\n        // Consider example powershell command:\n        // ```powershell\n        // Get-AuthenticodeSignature 'C:\\\\path\\\\my-bad-';calc;'filename.exe'\n        // ```\n        // The above would work expected and find the file name, however, it will also execute `;calc;`\n        // command and start the calculator app.\n        //\n        // From Powershell quoting rules:\n        // https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_quoting_rules?view=powershell-7\n        // * Double quotes `\"` are treated literally within single-quoted strings;\n        // * Single quotes can be escaped by doubling them: 'don''t' -> don't;\n        //\n        // Also note that at this point the file has already been written to the disk, thus we are\n        // guaranteed that the path will not contain any illegal characters like <>:\"/\\|?*\n        // https://docs.microsoft.com/en-us/windows/win32/fileio/naming-a-file\n        const tempUpdateFile = unescapedTempUpdateFile.replace(/'/g, \"''\");\n        // https://github.com/electron-userland/electron-builder/issues/2421\n        // https://github.com/electron-userland/electron-builder/issues/2535\n        (0, child_process_1.execFile)(\"chcp 65001 >NUL & powershell.exe\", [\"-NoProfile\", \"-NonInteractive\", \"-InputFormat\", \"None\", \"-Command\", `\"Get-AuthenticodeSignature -LiteralPath '${tempUpdateFile}' | ConvertTo-Json -Compress\"`], {\n            shell: true,\n            timeout: 20 * 1000,\n        }, (error, stdout, stderr) => {\n            try {\n                if (error != null || stderr) {\n                    handleError(logger, error, stderr, reject);\n                    resolve(null);\n                    return;\n                }\n                const data = parseOut(stdout);\n                if (data.Status === 0) {\n                    const subject = (0, builder_util_runtime_1.parseDn)(data.SignerCertificate.Subject);\n                    let match = false;\n                    for (const name of publisherNames) {\n                        const dn = (0, builder_util_runtime_1.parseDn)(name);\n                        if (dn.size) {\n                            // if we have a full DN, compare all values\n                            const allKeys = Array.from(dn.keys());\n                            match = allKeys.every(key => {\n                                return dn.get(key) === subject.get(key);\n                            });\n                        }\n                        else if (name === subject.get(\"CN\")) {\n                            logger.warn(`Signature validated using only CN ${name}. Please add your full Distinguished Name (DN) to publisherNames configuration`);\n                            match = true;\n                        }\n                        if (match) {\n                            resolve(null);\n                            return;\n                        }\n                    }\n                }\n                const result = `publisherNames: ${publisherNames.join(\" | \")}, raw info: ` + JSON.stringify(data, (name, value) => (name === \"RawData\" ? undefined : value), 2);\n                logger.warn(`Sign verification failed, installer signed with incorrect certificate: ${result}`);\n                resolve(result);\n            }\n            catch (e) {\n                handleError(logger, e, null, reject);\n                resolve(null);\n                return;\n            }\n        });\n    });\n}\nexports.verifySignature = verifySignature;\nfunction parseOut(out) {\n    const data = JSON.parse(out);\n    delete data.PrivateKey;\n    delete data.IsOSBinary;\n    delete data.SignatureType;\n    const signerCertificate = data.SignerCertificate;\n    if (signerCertificate != null) {\n        delete signerCertificate.Archived;\n        delete signerCertificate.Extensions;\n        delete signerCertificate.Handle;\n        delete signerCertificate.HasPrivateKey;\n        // duplicates data.SignerCertificate (contains RawData)\n        delete signerCertificate.SubjectName;\n    }\n    delete data.Path;\n    return data;\n}\nfunction handleError(logger, error, stderr, reject) {\n    if (isOldWin6()) {\n        logger.warn(`Cannot execute Get-AuthenticodeSignature: ${error || stderr}. Ignoring signature validation due to unsupported powershell version. Please upgrade to powershell 3 or higher.`);\n        return;\n    }\n    try {\n        (0, child_process_1.execFileSync)(\"powershell.exe\", [\"-NoProfile\", \"-NonInteractive\", \"-Command\", \"ConvertTo-Json test\"], { timeout: 10 * 1000 });\n    }\n    catch (testError) {\n        logger.warn(`Cannot execute ConvertTo-Json: ${testError.message}. Ignoring signature validation due to unsupported powershell version. Please upgrade to powershell 3 or higher.`);\n        return;\n    }\n    if (error != null) {\n        reject(error);\n    }\n    if (stderr) {\n        reject(new Error(`Cannot execute Get-AuthenticodeSignature, stderr: ${stderr}. Failing signature validation due to unknown stderr.`));\n    }\n}\nfunction isOldWin6() {\n    const winVersion = os.release();\n    return winVersion.startsWith(\"6.\") && !winVersion.startsWith(\"6.3\");\n}\n//# sourceMappingURL=windowsExecutableCodeSignatureVerifier.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/electron-updater/out/windowsExecutableCodeSignatureVerifier.js?");

/***/ }),

/***/ "./node_modules/graceful-fs/clone.js":
/*!*******************************************!*\
  !*** ./node_modules/graceful-fs/clone.js ***!
  \*******************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = clone\n\nvar getPrototypeOf = Object.getPrototypeOf || function (obj) {\n  return obj.__proto__\n}\n\nfunction clone (obj) {\n  if (obj === null || typeof obj !== 'object')\n    return obj\n\n  if (obj instanceof Object)\n    var copy = { __proto__: getPrototypeOf(obj) }\n  else\n    var copy = Object.create(null)\n\n  Object.getOwnPropertyNames(obj).forEach(function (key) {\n    Object.defineProperty(copy, key, Object.getOwnPropertyDescriptor(obj, key))\n  })\n\n  return copy\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/graceful-fs/clone.js?");

/***/ }),

/***/ "./node_modules/graceful-fs/graceful-fs.js":
/*!*************************************************!*\
  !*** ./node_modules/graceful-fs/graceful-fs.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var fs = __webpack_require__(/*! fs */ \"fs\")\nvar polyfills = __webpack_require__(/*! ./polyfills.js */ \"./node_modules/graceful-fs/polyfills.js\")\nvar legacy = __webpack_require__(/*! ./legacy-streams.js */ \"./node_modules/graceful-fs/legacy-streams.js\")\nvar clone = __webpack_require__(/*! ./clone.js */ \"./node_modules/graceful-fs/clone.js\")\n\nvar util = __webpack_require__(/*! util */ \"util\")\n\n/* istanbul ignore next - node 0.x polyfill */\nvar gracefulQueue\nvar previousSymbol\n\n/* istanbul ignore else - node 0.x polyfill */\nif (typeof Symbol === 'function' && typeof Symbol.for === 'function') {\n  gracefulQueue = Symbol.for('graceful-fs.queue')\n  // This is used in testing by future versions\n  previousSymbol = Symbol.for('graceful-fs.previous')\n} else {\n  gracefulQueue = '___graceful-fs.queue'\n  previousSymbol = '___graceful-fs.previous'\n}\n\nfunction noop () {}\n\nfunction publishQueue(context, queue) {\n  Object.defineProperty(context, gracefulQueue, {\n    get: function() {\n      return queue\n    }\n  })\n}\n\nvar debug = noop\nif (util.debuglog)\n  debug = util.debuglog('gfs4')\nelse if (/\\bgfs4\\b/i.test(process.env.NODE_DEBUG || ''))\n  debug = function() {\n    var m = util.format.apply(util, arguments)\n    m = 'GFS4: ' + m.split(/\\n/).join('\\nGFS4: ')\n    console.error(m)\n  }\n\n// Once time initialization\nif (!fs[gracefulQueue]) {\n  // This queue can be shared by multiple loaded instances\n  var queue = global[gracefulQueue] || []\n  publishQueue(fs, queue)\n\n  // Patch fs.close/closeSync to shared queue version, because we need\n  // to retry() whenever a close happens *anywhere* in the program.\n  // This is essential when multiple graceful-fs instances are\n  // in play at the same time.\n  fs.close = (function (fs$close) {\n    function close (fd, cb) {\n      return fs$close.call(fs, fd, function (err) {\n        // This function uses the graceful-fs shared queue\n        if (!err) {\n          resetQueue()\n        }\n\n        if (typeof cb === 'function')\n          cb.apply(this, arguments)\n      })\n    }\n\n    Object.defineProperty(close, previousSymbol, {\n      value: fs$close\n    })\n    return close\n  })(fs.close)\n\n  fs.closeSync = (function (fs$closeSync) {\n    function closeSync (fd) {\n      // This function uses the graceful-fs shared queue\n      fs$closeSync.apply(fs, arguments)\n      resetQueue()\n    }\n\n    Object.defineProperty(closeSync, previousSymbol, {\n      value: fs$closeSync\n    })\n    return closeSync\n  })(fs.closeSync)\n\n  if (/\\bgfs4\\b/i.test(process.env.NODE_DEBUG || '')) {\n    process.on('exit', function() {\n      debug(fs[gracefulQueue])\n      __webpack_require__(/*! assert */ \"assert\").equal(fs[gracefulQueue].length, 0)\n    })\n  }\n}\n\nif (!global[gracefulQueue]) {\n  publishQueue(global, fs[gracefulQueue]);\n}\n\nmodule.exports = patch(clone(fs))\nif (process.env.TEST_GRACEFUL_FS_GLOBAL_PATCH && !fs.__patched) {\n    module.exports = patch(fs)\n    fs.__patched = true;\n}\n\nfunction patch (fs) {\n  // Everything that references the open() function needs to be in here\n  polyfills(fs)\n  fs.gracefulify = patch\n\n  fs.createReadStream = createReadStream\n  fs.createWriteStream = createWriteStream\n  var fs$readFile = fs.readFile\n  fs.readFile = readFile\n  function readFile (path, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    return go$readFile(path, options, cb)\n\n    function go$readFile (path, options, cb, startTime) {\n      return fs$readFile(path, options, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$readFile, [path, options, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  var fs$writeFile = fs.writeFile\n  fs.writeFile = writeFile\n  function writeFile (path, data, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    return go$writeFile(path, data, options, cb)\n\n    function go$writeFile (path, data, options, cb, startTime) {\n      return fs$writeFile(path, data, options, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$writeFile, [path, data, options, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  var fs$appendFile = fs.appendFile\n  if (fs$appendFile)\n    fs.appendFile = appendFile\n  function appendFile (path, data, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    return go$appendFile(path, data, options, cb)\n\n    function go$appendFile (path, data, options, cb, startTime) {\n      return fs$appendFile(path, data, options, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$appendFile, [path, data, options, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  var fs$copyFile = fs.copyFile\n  if (fs$copyFile)\n    fs.copyFile = copyFile\n  function copyFile (src, dest, flags, cb) {\n    if (typeof flags === 'function') {\n      cb = flags\n      flags = 0\n    }\n    return go$copyFile(src, dest, flags, cb)\n\n    function go$copyFile (src, dest, flags, cb, startTime) {\n      return fs$copyFile(src, dest, flags, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$copyFile, [src, dest, flags, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  var fs$readdir = fs.readdir\n  fs.readdir = readdir\n  var noReaddirOptionVersions = /^v[0-5]\\./\n  function readdir (path, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    var go$readdir = noReaddirOptionVersions.test(process.version)\n      ? function go$readdir (path, options, cb, startTime) {\n        return fs$readdir(path, fs$readdirCallback(\n          path, options, cb, startTime\n        ))\n      }\n      : function go$readdir (path, options, cb, startTime) {\n        return fs$readdir(path, options, fs$readdirCallback(\n          path, options, cb, startTime\n        ))\n      }\n\n    return go$readdir(path, options, cb)\n\n    function fs$readdirCallback (path, options, cb, startTime) {\n      return function (err, files) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([\n            go$readdir,\n            [path, options, cb],\n            err,\n            startTime || Date.now(),\n            Date.now()\n          ])\n        else {\n          if (files && files.sort)\n            files.sort()\n\n          if (typeof cb === 'function')\n            cb.call(this, err, files)\n        }\n      }\n    }\n  }\n\n  if (process.version.substr(0, 4) === 'v0.8') {\n    var legStreams = legacy(fs)\n    ReadStream = legStreams.ReadStream\n    WriteStream = legStreams.WriteStream\n  }\n\n  var fs$ReadStream = fs.ReadStream\n  if (fs$ReadStream) {\n    ReadStream.prototype = Object.create(fs$ReadStream.prototype)\n    ReadStream.prototype.open = ReadStream$open\n  }\n\n  var fs$WriteStream = fs.WriteStream\n  if (fs$WriteStream) {\n    WriteStream.prototype = Object.create(fs$WriteStream.prototype)\n    WriteStream.prototype.open = WriteStream$open\n  }\n\n  Object.defineProperty(fs, 'ReadStream', {\n    get: function () {\n      return ReadStream\n    },\n    set: function (val) {\n      ReadStream = val\n    },\n    enumerable: true,\n    configurable: true\n  })\n  Object.defineProperty(fs, 'WriteStream', {\n    get: function () {\n      return WriteStream\n    },\n    set: function (val) {\n      WriteStream = val\n    },\n    enumerable: true,\n    configurable: true\n  })\n\n  // legacy names\n  var FileReadStream = ReadStream\n  Object.defineProperty(fs, 'FileReadStream', {\n    get: function () {\n      return FileReadStream\n    },\n    set: function (val) {\n      FileReadStream = val\n    },\n    enumerable: true,\n    configurable: true\n  })\n  var FileWriteStream = WriteStream\n  Object.defineProperty(fs, 'FileWriteStream', {\n    get: function () {\n      return FileWriteStream\n    },\n    set: function (val) {\n      FileWriteStream = val\n    },\n    enumerable: true,\n    configurable: true\n  })\n\n  function ReadStream (path, options) {\n    if (this instanceof ReadStream)\n      return fs$ReadStream.apply(this, arguments), this\n    else\n      return ReadStream.apply(Object.create(ReadStream.prototype), arguments)\n  }\n\n  function ReadStream$open () {\n    var that = this\n    open(that.path, that.flags, that.mode, function (err, fd) {\n      if (err) {\n        if (that.autoClose)\n          that.destroy()\n\n        that.emit('error', err)\n      } else {\n        that.fd = fd\n        that.emit('open', fd)\n        that.read()\n      }\n    })\n  }\n\n  function WriteStream (path, options) {\n    if (this instanceof WriteStream)\n      return fs$WriteStream.apply(this, arguments), this\n    else\n      return WriteStream.apply(Object.create(WriteStream.prototype), arguments)\n  }\n\n  function WriteStream$open () {\n    var that = this\n    open(that.path, that.flags, that.mode, function (err, fd) {\n      if (err) {\n        that.destroy()\n        that.emit('error', err)\n      } else {\n        that.fd = fd\n        that.emit('open', fd)\n      }\n    })\n  }\n\n  function createReadStream (path, options) {\n    return new fs.ReadStream(path, options)\n  }\n\n  function createWriteStream (path, options) {\n    return new fs.WriteStream(path, options)\n  }\n\n  var fs$open = fs.open\n  fs.open = open\n  function open (path, flags, mode, cb) {\n    if (typeof mode === 'function')\n      cb = mode, mode = null\n\n    return go$open(path, flags, mode, cb)\n\n    function go$open (path, flags, mode, cb, startTime) {\n      return fs$open(path, flags, mode, function (err, fd) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$open, [path, flags, mode, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  return fs\n}\n\nfunction enqueue (elem) {\n  debug('ENQUEUE', elem[0].name, elem[1])\n  fs[gracefulQueue].push(elem)\n  retry()\n}\n\n// keep track of the timeout between retry() calls\nvar retryTimer\n\n// reset the startTime and lastTime to now\n// this resets the start of the 60 second overall timeout as well as the\n// delay between attempts so that we'll retry these jobs sooner\nfunction resetQueue () {\n  var now = Date.now()\n  for (var i = 0; i < fs[gracefulQueue].length; ++i) {\n    // entries that are only a length of 2 are from an older version, don't\n    // bother modifying those since they'll be retried anyway.\n    if (fs[gracefulQueue][i].length > 2) {\n      fs[gracefulQueue][i][3] = now // startTime\n      fs[gracefulQueue][i][4] = now // lastTime\n    }\n  }\n  // call retry to make sure we're actively processing the queue\n  retry()\n}\n\nfunction retry () {\n  // clear the timer and remove it to help prevent unintended concurrency\n  clearTimeout(retryTimer)\n  retryTimer = undefined\n\n  if (fs[gracefulQueue].length === 0)\n    return\n\n  var elem = fs[gracefulQueue].shift()\n  var fn = elem[0]\n  var args = elem[1]\n  // these items may be unset if they were added by an older graceful-fs\n  var err = elem[2]\n  var startTime = elem[3]\n  var lastTime = elem[4]\n\n  // if we don't have a startTime we have no way of knowing if we've waited\n  // long enough, so go ahead and retry this item now\n  if (startTime === undefined) {\n    debug('RETRY', fn.name, args)\n    fn.apply(null, args)\n  } else if (Date.now() - startTime >= 60000) {\n    // it's been more than 60 seconds total, bail now\n    debug('TIMEOUT', fn.name, args)\n    var cb = args.pop()\n    if (typeof cb === 'function')\n      cb.call(null, err)\n  } else {\n    // the amount of time between the last attempt and right now\n    var sinceAttempt = Date.now() - lastTime\n    // the amount of time between when we first tried, and when we last tried\n    // rounded up to at least 1\n    var sinceStart = Math.max(lastTime - startTime, 1)\n    // backoff. wait longer than the total time we've been retrying, but only\n    // up to a maximum of 100ms\n    var desiredDelay = Math.min(sinceStart * 1.2, 100)\n    // it's been long enough since the last retry, do it again\n    if (sinceAttempt >= desiredDelay) {\n      debug('RETRY', fn.name, args)\n      fn.apply(null, args.concat([startTime]))\n    } else {\n      // if we can't do this job yet, push it to the end of the queue\n      // and let the next iteration check again\n      fs[gracefulQueue].push(elem)\n    }\n  }\n\n  // schedule our next run if one isn't already scheduled\n  if (retryTimer === undefined) {\n    retryTimer = setTimeout(retry, 0)\n  }\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/graceful-fs/graceful-fs.js?");

/***/ }),

/***/ "./node_modules/graceful-fs/legacy-streams.js":
/*!****************************************************!*\
  !*** ./node_modules/graceful-fs/legacy-streams.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var Stream = (__webpack_require__(/*! stream */ \"stream\").Stream)\n\nmodule.exports = legacy\n\nfunction legacy (fs) {\n  return {\n    ReadStream: ReadStream,\n    WriteStream: WriteStream\n  }\n\n  function ReadStream (path, options) {\n    if (!(this instanceof ReadStream)) return new ReadStream(path, options);\n\n    Stream.call(this);\n\n    var self = this;\n\n    this.path = path;\n    this.fd = null;\n    this.readable = true;\n    this.paused = false;\n\n    this.flags = 'r';\n    this.mode = 438; /*=0666*/\n    this.bufferSize = 64 * 1024;\n\n    options = options || {};\n\n    // Mixin options into this\n    var keys = Object.keys(options);\n    for (var index = 0, length = keys.length; index < length; index++) {\n      var key = keys[index];\n      this[key] = options[key];\n    }\n\n    if (this.encoding) this.setEncoding(this.encoding);\n\n    if (this.start !== undefined) {\n      if ('number' !== typeof this.start) {\n        throw TypeError('start must be a Number');\n      }\n      if (this.end === undefined) {\n        this.end = Infinity;\n      } else if ('number' !== typeof this.end) {\n        throw TypeError('end must be a Number');\n      }\n\n      if (this.start > this.end) {\n        throw new Error('start must be <= end');\n      }\n\n      this.pos = this.start;\n    }\n\n    if (this.fd !== null) {\n      process.nextTick(function() {\n        self._read();\n      });\n      return;\n    }\n\n    fs.open(this.path, this.flags, this.mode, function (err, fd) {\n      if (err) {\n        self.emit('error', err);\n        self.readable = false;\n        return;\n      }\n\n      self.fd = fd;\n      self.emit('open', fd);\n      self._read();\n    })\n  }\n\n  function WriteStream (path, options) {\n    if (!(this instanceof WriteStream)) return new WriteStream(path, options);\n\n    Stream.call(this);\n\n    this.path = path;\n    this.fd = null;\n    this.writable = true;\n\n    this.flags = 'w';\n    this.encoding = 'binary';\n    this.mode = 438; /*=0666*/\n    this.bytesWritten = 0;\n\n    options = options || {};\n\n    // Mixin options into this\n    var keys = Object.keys(options);\n    for (var index = 0, length = keys.length; index < length; index++) {\n      var key = keys[index];\n      this[key] = options[key];\n    }\n\n    if (this.start !== undefined) {\n      if ('number' !== typeof this.start) {\n        throw TypeError('start must be a Number');\n      }\n      if (this.start < 0) {\n        throw new Error('start must be >= zero');\n      }\n\n      this.pos = this.start;\n    }\n\n    this.busy = false;\n    this._queue = [];\n\n    if (this.fd === null) {\n      this._open = fs.open;\n      this._queue.push([this._open, this.path, this.flags, this.mode, undefined]);\n      this.flush();\n    }\n  }\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/graceful-fs/legacy-streams.js?");

/***/ }),

/***/ "./node_modules/graceful-fs/polyfills.js":
/*!***********************************************!*\
  !*** ./node_modules/graceful-fs/polyfills.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var constants = __webpack_require__(/*! constants */ \"constants\")\n\nvar origCwd = process.cwd\nvar cwd = null\n\nvar platform = process.env.GRACEFUL_FS_PLATFORM || process.platform\n\nprocess.cwd = function() {\n  if (!cwd)\n    cwd = origCwd.call(process)\n  return cwd\n}\ntry {\n  process.cwd()\n} catch (er) {}\n\n// This check is needed until node.js 12 is required\nif (typeof process.chdir === 'function') {\n  var chdir = process.chdir\n  process.chdir = function (d) {\n    cwd = null\n    chdir.call(process, d)\n  }\n  if (Object.setPrototypeOf) Object.setPrototypeOf(process.chdir, chdir)\n}\n\nmodule.exports = patch\n\nfunction patch (fs) {\n  // (re-)implement some things that are known busted or missing.\n\n  // lchmod, broken prior to 0.6.2\n  // back-port the fix here.\n  if (constants.hasOwnProperty('O_SYMLINK') &&\n      process.version.match(/^v0\\.6\\.[0-2]|^v0\\.5\\./)) {\n    patchLchmod(fs)\n  }\n\n  // lutimes implementation, or no-op\n  if (!fs.lutimes) {\n    patchLutimes(fs)\n  }\n\n  // https://github.com/isaacs/node-graceful-fs/issues/4\n  // Chown should not fail on einval or eperm if non-root.\n  // It should not fail on enosys ever, as this just indicates\n  // that a fs doesn't support the intended operation.\n\n  fs.chown = chownFix(fs.chown)\n  fs.fchown = chownFix(fs.fchown)\n  fs.lchown = chownFix(fs.lchown)\n\n  fs.chmod = chmodFix(fs.chmod)\n  fs.fchmod = chmodFix(fs.fchmod)\n  fs.lchmod = chmodFix(fs.lchmod)\n\n  fs.chownSync = chownFixSync(fs.chownSync)\n  fs.fchownSync = chownFixSync(fs.fchownSync)\n  fs.lchownSync = chownFixSync(fs.lchownSync)\n\n  fs.chmodSync = chmodFixSync(fs.chmodSync)\n  fs.fchmodSync = chmodFixSync(fs.fchmodSync)\n  fs.lchmodSync = chmodFixSync(fs.lchmodSync)\n\n  fs.stat = statFix(fs.stat)\n  fs.fstat = statFix(fs.fstat)\n  fs.lstat = statFix(fs.lstat)\n\n  fs.statSync = statFixSync(fs.statSync)\n  fs.fstatSync = statFixSync(fs.fstatSync)\n  fs.lstatSync = statFixSync(fs.lstatSync)\n\n  // if lchmod/lchown do not exist, then make them no-ops\n  if (fs.chmod && !fs.lchmod) {\n    fs.lchmod = function (path, mode, cb) {\n      if (cb) process.nextTick(cb)\n    }\n    fs.lchmodSync = function () {}\n  }\n  if (fs.chown && !fs.lchown) {\n    fs.lchown = function (path, uid, gid, cb) {\n      if (cb) process.nextTick(cb)\n    }\n    fs.lchownSync = function () {}\n  }\n\n  // on Windows, A/V software can lock the directory, causing this\n  // to fail with an EACCES or EPERM if the directory contains newly\n  // created files.  Try again on failure, for up to 60 seconds.\n\n  // Set the timeout this long because some Windows Anti-Virus, such as Parity\n  // bit9, may lock files for up to a minute, causing npm package install\n  // failures. Also, take care to yield the scheduler. Windows scheduling gives\n  // CPU to a busy looping process, which can cause the program causing the lock\n  // contention to be starved of CPU by node, so the contention doesn't resolve.\n  if (platform === \"win32\") {\n    fs.rename = typeof fs.rename !== 'function' ? fs.rename\n    : (function (fs$rename) {\n      function rename (from, to, cb) {\n        var start = Date.now()\n        var backoff = 0;\n        fs$rename(from, to, function CB (er) {\n          if (er\n              && (er.code === \"EACCES\" || er.code === \"EPERM\")\n              && Date.now() - start < 60000) {\n            setTimeout(function() {\n              fs.stat(to, function (stater, st) {\n                if (stater && stater.code === \"ENOENT\")\n                  fs$rename(from, to, CB);\n                else\n                  cb(er)\n              })\n            }, backoff)\n            if (backoff < 100)\n              backoff += 10;\n            return;\n          }\n          if (cb) cb(er)\n        })\n      }\n      if (Object.setPrototypeOf) Object.setPrototypeOf(rename, fs$rename)\n      return rename\n    })(fs.rename)\n  }\n\n  // if read() returns EAGAIN, then just try it again.\n  fs.read = typeof fs.read !== 'function' ? fs.read\n  : (function (fs$read) {\n    function read (fd, buffer, offset, length, position, callback_) {\n      var callback\n      if (callback_ && typeof callback_ === 'function') {\n        var eagCounter = 0\n        callback = function (er, _, __) {\n          if (er && er.code === 'EAGAIN' && eagCounter < 10) {\n            eagCounter ++\n            return fs$read.call(fs, fd, buffer, offset, length, position, callback)\n          }\n          callback_.apply(this, arguments)\n        }\n      }\n      return fs$read.call(fs, fd, buffer, offset, length, position, callback)\n    }\n\n    // This ensures `util.promisify` works as it does for native `fs.read`.\n    if (Object.setPrototypeOf) Object.setPrototypeOf(read, fs$read)\n    return read\n  })(fs.read)\n\n  fs.readSync = typeof fs.readSync !== 'function' ? fs.readSync\n  : (function (fs$readSync) { return function (fd, buffer, offset, length, position) {\n    var eagCounter = 0\n    while (true) {\n      try {\n        return fs$readSync.call(fs, fd, buffer, offset, length, position)\n      } catch (er) {\n        if (er.code === 'EAGAIN' && eagCounter < 10) {\n          eagCounter ++\n          continue\n        }\n        throw er\n      }\n    }\n  }})(fs.readSync)\n\n  function patchLchmod (fs) {\n    fs.lchmod = function (path, mode, callback) {\n      fs.open( path\n             , constants.O_WRONLY | constants.O_SYMLINK\n             , mode\n             , function (err, fd) {\n        if (err) {\n          if (callback) callback(err)\n          return\n        }\n        // prefer to return the chmod error, if one occurs,\n        // but still try to close, and report closing errors if they occur.\n        fs.fchmod(fd, mode, function (err) {\n          fs.close(fd, function(err2) {\n            if (callback) callback(err || err2)\n          })\n        })\n      })\n    }\n\n    fs.lchmodSync = function (path, mode) {\n      var fd = fs.openSync(path, constants.O_WRONLY | constants.O_SYMLINK, mode)\n\n      // prefer to return the chmod error, if one occurs,\n      // but still try to close, and report closing errors if they occur.\n      var threw = true\n      var ret\n      try {\n        ret = fs.fchmodSync(fd, mode)\n        threw = false\n      } finally {\n        if (threw) {\n          try {\n            fs.closeSync(fd)\n          } catch (er) {}\n        } else {\n          fs.closeSync(fd)\n        }\n      }\n      return ret\n    }\n  }\n\n  function patchLutimes (fs) {\n    if (constants.hasOwnProperty(\"O_SYMLINK\") && fs.futimes) {\n      fs.lutimes = function (path, at, mt, cb) {\n        fs.open(path, constants.O_SYMLINK, function (er, fd) {\n          if (er) {\n            if (cb) cb(er)\n            return\n          }\n          fs.futimes(fd, at, mt, function (er) {\n            fs.close(fd, function (er2) {\n              if (cb) cb(er || er2)\n            })\n          })\n        })\n      }\n\n      fs.lutimesSync = function (path, at, mt) {\n        var fd = fs.openSync(path, constants.O_SYMLINK)\n        var ret\n        var threw = true\n        try {\n          ret = fs.futimesSync(fd, at, mt)\n          threw = false\n        } finally {\n          if (threw) {\n            try {\n              fs.closeSync(fd)\n            } catch (er) {}\n          } else {\n            fs.closeSync(fd)\n          }\n        }\n        return ret\n      }\n\n    } else if (fs.futimes) {\n      fs.lutimes = function (_a, _b, _c, cb) { if (cb) process.nextTick(cb) }\n      fs.lutimesSync = function () {}\n    }\n  }\n\n  function chmodFix (orig) {\n    if (!orig) return orig\n    return function (target, mode, cb) {\n      return orig.call(fs, target, mode, function (er) {\n        if (chownErOk(er)) er = null\n        if (cb) cb.apply(this, arguments)\n      })\n    }\n  }\n\n  function chmodFixSync (orig) {\n    if (!orig) return orig\n    return function (target, mode) {\n      try {\n        return orig.call(fs, target, mode)\n      } catch (er) {\n        if (!chownErOk(er)) throw er\n      }\n    }\n  }\n\n\n  function chownFix (orig) {\n    if (!orig) return orig\n    return function (target, uid, gid, cb) {\n      return orig.call(fs, target, uid, gid, function (er) {\n        if (chownErOk(er)) er = null\n        if (cb) cb.apply(this, arguments)\n      })\n    }\n  }\n\n  function chownFixSync (orig) {\n    if (!orig) return orig\n    return function (target, uid, gid) {\n      try {\n        return orig.call(fs, target, uid, gid)\n      } catch (er) {\n        if (!chownErOk(er)) throw er\n      }\n    }\n  }\n\n  function statFix (orig) {\n    if (!orig) return orig\n    // Older versions of Node erroneously returned signed integers for\n    // uid + gid.\n    return function (target, options, cb) {\n      if (typeof options === 'function') {\n        cb = options\n        options = null\n      }\n      function callback (er, stats) {\n        if (stats) {\n          if (stats.uid < 0) stats.uid += 0x100000000\n          if (stats.gid < 0) stats.gid += 0x100000000\n        }\n        if (cb) cb.apply(this, arguments)\n      }\n      return options ? orig.call(fs, target, options, callback)\n        : orig.call(fs, target, callback)\n    }\n  }\n\n  function statFixSync (orig) {\n    if (!orig) return orig\n    // Older versions of Node erroneously returned signed integers for\n    // uid + gid.\n    return function (target, options) {\n      var stats = options ? orig.call(fs, target, options)\n        : orig.call(fs, target)\n      if (stats) {\n        if (stats.uid < 0) stats.uid += 0x100000000\n        if (stats.gid < 0) stats.gid += 0x100000000\n      }\n      return stats;\n    }\n  }\n\n  // ENOSYS means that the fs doesn't support the op. Just ignore\n  // that, because it doesn't matter.\n  //\n  // if there's no getuid, or if getuid() is something other\n  // than 0, and the error is EINVAL or EPERM, then just ignore\n  // it.\n  //\n  // This specific case is a silent failure in cp, install, tar,\n  // and most other unix tools that manage permissions.\n  //\n  // When running as root, or if other types of errors are\n  // encountered, then it's strict.\n  function chownErOk (er) {\n    if (!er)\n      return true\n\n    if (er.code === \"ENOSYS\")\n      return true\n\n    var nonroot = !process.getuid || process.getuid() !== 0\n    if (nonroot) {\n      if (er.code === \"EINVAL\" || er.code === \"EPERM\")\n        return true\n    }\n\n    return false\n  }\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/graceful-fs/polyfills.js?");

/***/ }),

/***/ "./node_modules/ip/lib/ip.js":
/*!***********************************!*\
  !*** ./node_modules/ip/lib/ip.js ***!
  \***********************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("const ip = exports;\nconst { Buffer } = __webpack_require__(/*! buffer */ \"buffer\");\nconst os = __webpack_require__(/*! os */ \"os\");\n\nip.toBuffer = function (ip, buff, offset) {\n  offset = ~~offset;\n\n  let result;\n\n  if (this.isV4Format(ip)) {\n    result = buff || Buffer.alloc(offset + 4);\n    ip.split(/\\./g).map((byte) => {\n      result[offset++] = parseInt(byte, 10) & 0xff;\n    });\n  } else if (this.isV6Format(ip)) {\n    const sections = ip.split(':', 8);\n\n    let i;\n    for (i = 0; i < sections.length; i++) {\n      const isv4 = this.isV4Format(sections[i]);\n      let v4Buffer;\n\n      if (isv4) {\n        v4Buffer = this.toBuffer(sections[i]);\n        sections[i] = v4Buffer.slice(0, 2).toString('hex');\n      }\n\n      if (v4Buffer && ++i < 8) {\n        sections.splice(i, 0, v4Buffer.slice(2, 4).toString('hex'));\n      }\n    }\n\n    if (sections[0] === '') {\n      while (sections.length < 8) sections.unshift('0');\n    } else if (sections[sections.length - 1] === '') {\n      while (sections.length < 8) sections.push('0');\n    } else if (sections.length < 8) {\n      for (i = 0; i < sections.length && sections[i] !== ''; i++);\n      const argv = [i, 1];\n      for (i = 9 - sections.length; i > 0; i--) {\n        argv.push('0');\n      }\n      sections.splice(...argv);\n    }\n\n    result = buff || Buffer.alloc(offset + 16);\n    for (i = 0; i < sections.length; i++) {\n      const word = parseInt(sections[i], 16);\n      result[offset++] = (word >> 8) & 0xff;\n      result[offset++] = word & 0xff;\n    }\n  }\n\n  if (!result) {\n    throw Error(`Invalid ip address: ${ip}`);\n  }\n\n  return result;\n};\n\nip.toString = function (buff, offset, length) {\n  offset = ~~offset;\n  length = length || (buff.length - offset);\n\n  let result = [];\n  if (length === 4) {\n    // IPv4\n    for (let i = 0; i < length; i++) {\n      result.push(buff[offset + i]);\n    }\n    result = result.join('.');\n  } else if (length === 16) {\n    // IPv6\n    for (let i = 0; i < length; i += 2) {\n      result.push(buff.readUInt16BE(offset + i).toString(16));\n    }\n    result = result.join(':');\n    result = result.replace(/(^|:)0(:0)*:0(:|$)/, '$1::$3');\n    result = result.replace(/:{3,4}/, '::');\n  }\n\n  return result;\n};\n\nconst ipv4Regex = /^(\\d{1,3}\\.){3,3}\\d{1,3}$/;\nconst ipv6Regex = /^(::)?(((\\d{1,3}\\.){3}(\\d{1,3}){1})?([0-9a-f]){0,4}:{0,2}){1,8}(::)?$/i;\n\nip.isV4Format = function (ip) {\n  return ipv4Regex.test(ip);\n};\n\nip.isV6Format = function (ip) {\n  return ipv6Regex.test(ip);\n};\n\nfunction _normalizeFamily(family) {\n  if (family === 4) {\n    return 'ipv4';\n  }\n  if (family === 6) {\n    return 'ipv6';\n  }\n  return family ? family.toLowerCase() : 'ipv4';\n}\n\nip.fromPrefixLen = function (prefixlen, family) {\n  if (prefixlen > 32) {\n    family = 'ipv6';\n  } else {\n    family = _normalizeFamily(family);\n  }\n\n  let len = 4;\n  if (family === 'ipv6') {\n    len = 16;\n  }\n  const buff = Buffer.alloc(len);\n\n  for (let i = 0, n = buff.length; i < n; ++i) {\n    let bits = 8;\n    if (prefixlen < 8) {\n      bits = prefixlen;\n    }\n    prefixlen -= bits;\n\n    buff[i] = ~(0xff >> bits) & 0xff;\n  }\n\n  return ip.toString(buff);\n};\n\nip.mask = function (addr, mask) {\n  addr = ip.toBuffer(addr);\n  mask = ip.toBuffer(mask);\n\n  const result = Buffer.alloc(Math.max(addr.length, mask.length));\n\n  // Same protocol - do bitwise and\n  let i;\n  if (addr.length === mask.length) {\n    for (i = 0; i < addr.length; i++) {\n      result[i] = addr[i] & mask[i];\n    }\n  } else if (mask.length === 4) {\n    // IPv6 address and IPv4 mask\n    // (Mask low bits)\n    for (i = 0; i < mask.length; i++) {\n      result[i] = addr[addr.length - 4 + i] & mask[i];\n    }\n  } else {\n    // IPv6 mask and IPv4 addr\n    for (i = 0; i < result.length - 6; i++) {\n      result[i] = 0;\n    }\n\n    // ::ffff:ipv4\n    result[10] = 0xff;\n    result[11] = 0xff;\n    for (i = 0; i < addr.length; i++) {\n      result[i + 12] = addr[i] & mask[i + 12];\n    }\n    i += 12;\n  }\n  for (; i < result.length; i++) {\n    result[i] = 0;\n  }\n\n  return ip.toString(result);\n};\n\nip.cidr = function (cidrString) {\n  const cidrParts = cidrString.split('/');\n\n  const addr = cidrParts[0];\n  if (cidrParts.length !== 2) {\n    throw new Error(`invalid CIDR subnet: ${addr}`);\n  }\n\n  const mask = ip.fromPrefixLen(parseInt(cidrParts[1], 10));\n\n  return ip.mask(addr, mask);\n};\n\nip.subnet = function (addr, mask) {\n  const networkAddress = ip.toLong(ip.mask(addr, mask));\n\n  // Calculate the mask's length.\n  const maskBuffer = ip.toBuffer(mask);\n  let maskLength = 0;\n\n  for (let i = 0; i < maskBuffer.length; i++) {\n    if (maskBuffer[i] === 0xff) {\n      maskLength += 8;\n    } else {\n      let octet = maskBuffer[i] & 0xff;\n      while (octet) {\n        octet = (octet << 1) & 0xff;\n        maskLength++;\n      }\n    }\n  }\n\n  const numberOfAddresses = 2 ** (32 - maskLength);\n\n  return {\n    networkAddress: ip.fromLong(networkAddress),\n    firstAddress: numberOfAddresses <= 2\n      ? ip.fromLong(networkAddress)\n      : ip.fromLong(networkAddress + 1),\n    lastAddress: numberOfAddresses <= 2\n      ? ip.fromLong(networkAddress + numberOfAddresses - 1)\n      : ip.fromLong(networkAddress + numberOfAddresses - 2),\n    broadcastAddress: ip.fromLong(networkAddress + numberOfAddresses - 1),\n    subnetMask: mask,\n    subnetMaskLength: maskLength,\n    numHosts: numberOfAddresses <= 2\n      ? numberOfAddresses : numberOfAddresses - 2,\n    length: numberOfAddresses,\n    contains(other) {\n      return networkAddress === ip.toLong(ip.mask(other, mask));\n    },\n  };\n};\n\nip.cidrSubnet = function (cidrString) {\n  const cidrParts = cidrString.split('/');\n\n  const addr = cidrParts[0];\n  if (cidrParts.length !== 2) {\n    throw new Error(`invalid CIDR subnet: ${addr}`);\n  }\n\n  const mask = ip.fromPrefixLen(parseInt(cidrParts[1], 10));\n\n  return ip.subnet(addr, mask);\n};\n\nip.not = function (addr) {\n  const buff = ip.toBuffer(addr);\n  for (let i = 0; i < buff.length; i++) {\n    buff[i] = 0xff ^ buff[i];\n  }\n  return ip.toString(buff);\n};\n\nip.or = function (a, b) {\n  a = ip.toBuffer(a);\n  b = ip.toBuffer(b);\n\n  // same protocol\n  if (a.length === b.length) {\n    for (let i = 0; i < a.length; ++i) {\n      a[i] |= b[i];\n    }\n    return ip.toString(a);\n\n  // mixed protocols\n  }\n  let buff = a;\n  let other = b;\n  if (b.length > a.length) {\n    buff = b;\n    other = a;\n  }\n\n  const offset = buff.length - other.length;\n  for (let i = offset; i < buff.length; ++i) {\n    buff[i] |= other[i - offset];\n  }\n\n  return ip.toString(buff);\n};\n\nip.isEqual = function (a, b) {\n  a = ip.toBuffer(a);\n  b = ip.toBuffer(b);\n\n  // Same protocol\n  if (a.length === b.length) {\n    for (let i = 0; i < a.length; i++) {\n      if (a[i] !== b[i]) return false;\n    }\n    return true;\n  }\n\n  // Swap\n  if (b.length === 4) {\n    const t = b;\n    b = a;\n    a = t;\n  }\n\n  // a - IPv4, b - IPv6\n  for (let i = 0; i < 10; i++) {\n    if (b[i] !== 0) return false;\n  }\n\n  const word = b.readUInt16BE(10);\n  if (word !== 0 && word !== 0xffff) return false;\n\n  for (let i = 0; i < 4; i++) {\n    if (a[i] !== b[i + 12]) return false;\n  }\n\n  return true;\n};\n\nip.isPrivate = function (addr) {\n  return /^(::f{4}:)?10\\.([0-9]{1,3})\\.([0-9]{1,3})\\.([0-9]{1,3})$/i\n    .test(addr)\n    || /^(::f{4}:)?192\\.168\\.([0-9]{1,3})\\.([0-9]{1,3})$/i.test(addr)\n    || /^(::f{4}:)?172\\.(1[6-9]|2\\d|30|31)\\.([0-9]{1,3})\\.([0-9]{1,3})$/i\n      .test(addr)\n    || /^(::f{4}:)?127\\.([0-9]{1,3})\\.([0-9]{1,3})\\.([0-9]{1,3})$/i.test(addr)\n    || /^(::f{4}:)?169\\.254\\.([0-9]{1,3})\\.([0-9]{1,3})$/i.test(addr)\n    || /^f[cd][0-9a-f]{2}:/i.test(addr)\n    || /^fe80:/i.test(addr)\n    || /^::1$/.test(addr)\n    || /^::$/.test(addr);\n};\n\nip.isPublic = function (addr) {\n  return !ip.isPrivate(addr);\n};\n\nip.isLoopback = function (addr) {\n  return /^(::f{4}:)?127\\.([0-9]{1,3})\\.([0-9]{1,3})\\.([0-9]{1,3})/\n    .test(addr)\n    || /^fe80::1$/.test(addr)\n    || /^::1$/.test(addr)\n    || /^::$/.test(addr);\n};\n\nip.loopback = function (family) {\n  //\n  // Default to `ipv4`\n  //\n  family = _normalizeFamily(family);\n\n  if (family !== 'ipv4' && family !== 'ipv6') {\n    throw new Error('family must be ipv4 or ipv6');\n  }\n\n  return family === 'ipv4' ? '127.0.0.1' : 'fe80::1';\n};\n\n//\n// ### function address (name, family)\n// #### @name {string|'public'|'private'} **Optional** Name or security\n//      of the network interface.\n// #### @family {ipv4|ipv6} **Optional** IP family of the address (defaults\n//      to ipv4).\n//\n// Returns the address for the network interface on the current system with\n// the specified `name`:\n//   * String: First `family` address of the interface.\n//             If not found see `undefined`.\n//   * 'public': the first public ip address of family.\n//   * 'private': the first private ip address of family.\n//   * undefined: First address with `ipv4` or loopback address `127.0.0.1`.\n//\nip.address = function (name, family) {\n  const interfaces = os.networkInterfaces();\n\n  //\n  // Default to `ipv4`\n  //\n  family = _normalizeFamily(family);\n\n  //\n  // If a specific network interface has been named,\n  // return the address.\n  //\n  if (name && name !== 'private' && name !== 'public') {\n    const res = interfaces[name].filter((details) => {\n      const itemFamily = _normalizeFamily(details.family);\n      return itemFamily === family;\n    });\n    if (res.length === 0) {\n      return undefined;\n    }\n    return res[0].address;\n  }\n\n  const all = Object.keys(interfaces).map((nic) => {\n    //\n    // Note: name will only be `public` or `private`\n    // when this is called.\n    //\n    const addresses = interfaces[nic].filter((details) => {\n      details.family = _normalizeFamily(details.family);\n      if (details.family !== family || ip.isLoopback(details.address)) {\n        return false;\n      } if (!name) {\n        return true;\n      }\n\n      return name === 'public' ? ip.isPrivate(details.address)\n        : ip.isPublic(details.address);\n    });\n\n    return addresses.length ? addresses[0].address : undefined;\n  }).filter(Boolean);\n\n  return !all.length ? ip.loopback(family) : all[0];\n};\n\nip.toLong = function (ip) {\n  let ipl = 0;\n  ip.split('.').forEach((octet) => {\n    ipl <<= 8;\n    ipl += parseInt(octet);\n  });\n  return (ipl >>> 0);\n};\n\nip.fromLong = function (ipl) {\n  return (`${ipl >>> 24}.${\n    ipl >> 16 & 255}.${\n    ipl >> 8 & 255}.${\n    ipl & 255}`);\n};\n\n\n//# sourceURL=webpack://renderer/./node_modules/ip/lib/ip.js?");

/***/ }),

/***/ "./node_modules/js-yaml/index.js":
/*!***************************************!*\
  !*** ./node_modules/js-yaml/index.js ***!
  \***************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n\nvar loader = __webpack_require__(/*! ./lib/loader */ \"./node_modules/js-yaml/lib/loader.js\");\nvar dumper = __webpack_require__(/*! ./lib/dumper */ \"./node_modules/js-yaml/lib/dumper.js\");\n\n\nfunction renamed(from, to) {\n  return function () {\n    throw new Error('Function yaml.' + from + ' is removed in js-yaml 4. ' +\n      'Use yaml.' + to + ' instead, which is now safe by default.');\n  };\n}\n\n\nmodule.exports.Type = __webpack_require__(/*! ./lib/type */ \"./node_modules/js-yaml/lib/type.js\");\nmodule.exports.Schema = __webpack_require__(/*! ./lib/schema */ \"./node_modules/js-yaml/lib/schema.js\");\nmodule.exports.FAILSAFE_SCHEMA = __webpack_require__(/*! ./lib/schema/failsafe */ \"./node_modules/js-yaml/lib/schema/failsafe.js\");\nmodule.exports.JSON_SCHEMA = __webpack_require__(/*! ./lib/schema/json */ \"./node_modules/js-yaml/lib/schema/json.js\");\nmodule.exports.CORE_SCHEMA = __webpack_require__(/*! ./lib/schema/core */ \"./node_modules/js-yaml/lib/schema/core.js\");\nmodule.exports.DEFAULT_SCHEMA = __webpack_require__(/*! ./lib/schema/default */ \"./node_modules/js-yaml/lib/schema/default.js\");\nmodule.exports.load                = loader.load;\nmodule.exports.loadAll             = loader.loadAll;\nmodule.exports.dump                = dumper.dump;\nmodule.exports.YAMLException = __webpack_require__(/*! ./lib/exception */ \"./node_modules/js-yaml/lib/exception.js\");\n\n// Re-export all types in case user wants to create custom schema\nmodule.exports.types = {\n  binary:    __webpack_require__(/*! ./lib/type/binary */ \"./node_modules/js-yaml/lib/type/binary.js\"),\n  float:     __webpack_require__(/*! ./lib/type/float */ \"./node_modules/js-yaml/lib/type/float.js\"),\n  map:       __webpack_require__(/*! ./lib/type/map */ \"./node_modules/js-yaml/lib/type/map.js\"),\n  null:      __webpack_require__(/*! ./lib/type/null */ \"./node_modules/js-yaml/lib/type/null.js\"),\n  pairs:     __webpack_require__(/*! ./lib/type/pairs */ \"./node_modules/js-yaml/lib/type/pairs.js\"),\n  set:       __webpack_require__(/*! ./lib/type/set */ \"./node_modules/js-yaml/lib/type/set.js\"),\n  timestamp: __webpack_require__(/*! ./lib/type/timestamp */ \"./node_modules/js-yaml/lib/type/timestamp.js\"),\n  bool:      __webpack_require__(/*! ./lib/type/bool */ \"./node_modules/js-yaml/lib/type/bool.js\"),\n  int:       __webpack_require__(/*! ./lib/type/int */ \"./node_modules/js-yaml/lib/type/int.js\"),\n  merge:     __webpack_require__(/*! ./lib/type/merge */ \"./node_modules/js-yaml/lib/type/merge.js\"),\n  omap:      __webpack_require__(/*! ./lib/type/omap */ \"./node_modules/js-yaml/lib/type/omap.js\"),\n  seq:       __webpack_require__(/*! ./lib/type/seq */ \"./node_modules/js-yaml/lib/type/seq.js\"),\n  str:       __webpack_require__(/*! ./lib/type/str */ \"./node_modules/js-yaml/lib/type/str.js\")\n};\n\n// Removed functions from JS-YAML 3.0.x\nmodule.exports.safeLoad            = renamed('safeLoad', 'load');\nmodule.exports.safeLoadAll         = renamed('safeLoadAll', 'loadAll');\nmodule.exports.safeDump            = renamed('safeDump', 'dump');\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/index.js?");

/***/ }),

/***/ "./node_modules/js-yaml/lib/common.js":
/*!********************************************!*\
  !*** ./node_modules/js-yaml/lib/common.js ***!
  \********************************************/
/***/ ((module) => {

"use strict";
eval("\n\n\nfunction isNothing(subject) {\n  return (typeof subject === 'undefined') || (subject === null);\n}\n\n\nfunction isObject(subject) {\n  return (typeof subject === 'object') && (subject !== null);\n}\n\n\nfunction toArray(sequence) {\n  if (Array.isArray(sequence)) return sequence;\n  else if (isNothing(sequence)) return [];\n\n  return [ sequence ];\n}\n\n\nfunction extend(target, source) {\n  var index, length, key, sourceKeys;\n\n  if (source) {\n    sourceKeys = Object.keys(source);\n\n    for (index = 0, length = sourceKeys.length; index < length; index += 1) {\n      key = sourceKeys[index];\n      target[key] = source[key];\n    }\n  }\n\n  return target;\n}\n\n\nfunction repeat(string, count) {\n  var result = '', cycle;\n\n  for (cycle = 0; cycle < count; cycle += 1) {\n    result += string;\n  }\n\n  return result;\n}\n\n\nfunction isNegativeZero(number) {\n  return (number === 0) && (Number.NEGATIVE_INFINITY === 1 / number);\n}\n\n\nmodule.exports.isNothing      = isNothing;\nmodule.exports.isObject       = isObject;\nmodule.exports.toArray        = toArray;\nmodule.exports.repeat         = repeat;\nmodule.exports.isNegativeZero = isNegativeZero;\nmodule.exports.extend         = extend;\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/lib/common.js?");

/***/ }),

/***/ "./node_modules/js-yaml/lib/dumper.js":
/*!********************************************!*\
  !*** ./node_modules/js-yaml/lib/dumper.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*eslint-disable no-use-before-define*/\n\nvar common              = __webpack_require__(/*! ./common */ \"./node_modules/js-yaml/lib/common.js\");\nvar YAMLException       = __webpack_require__(/*! ./exception */ \"./node_modules/js-yaml/lib/exception.js\");\nvar DEFAULT_SCHEMA      = __webpack_require__(/*! ./schema/default */ \"./node_modules/js-yaml/lib/schema/default.js\");\n\nvar _toString       = Object.prototype.toString;\nvar _hasOwnProperty = Object.prototype.hasOwnProperty;\n\nvar CHAR_BOM                  = 0xFEFF;\nvar CHAR_TAB                  = 0x09; /* Tab */\nvar CHAR_LINE_FEED            = 0x0A; /* LF */\nvar CHAR_CARRIAGE_RETURN      = 0x0D; /* CR */\nvar CHAR_SPACE                = 0x20; /* Space */\nvar CHAR_EXCLAMATION          = 0x21; /* ! */\nvar CHAR_DOUBLE_QUOTE         = 0x22; /* \" */\nvar CHAR_SHARP                = 0x23; /* # */\nvar CHAR_PERCENT              = 0x25; /* % */\nvar CHAR_AMPERSAND            = 0x26; /* & */\nvar CHAR_SINGLE_QUOTE         = 0x27; /* ' */\nvar CHAR_ASTERISK             = 0x2A; /* * */\nvar CHAR_COMMA                = 0x2C; /* , */\nvar CHAR_MINUS                = 0x2D; /* - */\nvar CHAR_COLON                = 0x3A; /* : */\nvar CHAR_EQUALS               = 0x3D; /* = */\nvar CHAR_GREATER_THAN         = 0x3E; /* > */\nvar CHAR_QUESTION             = 0x3F; /* ? */\nvar CHAR_COMMERCIAL_AT        = 0x40; /* @ */\nvar CHAR_LEFT_SQUARE_BRACKET  = 0x5B; /* [ */\nvar CHAR_RIGHT_SQUARE_BRACKET = 0x5D; /* ] */\nvar CHAR_GRAVE_ACCENT         = 0x60; /* ` */\nvar CHAR_LEFT_CURLY_BRACKET   = 0x7B; /* { */\nvar CHAR_VERTICAL_LINE        = 0x7C; /* | */\nvar CHAR_RIGHT_CURLY_BRACKET  = 0x7D; /* } */\n\nvar ESCAPE_SEQUENCES = {};\n\nESCAPE_SEQUENCES[0x00]   = '\\\\0';\nESCAPE_SEQUENCES[0x07]   = '\\\\a';\nESCAPE_SEQUENCES[0x08]   = '\\\\b';\nESCAPE_SEQUENCES[0x09]   = '\\\\t';\nESCAPE_SEQUENCES[0x0A]   = '\\\\n';\nESCAPE_SEQUENCES[0x0B]   = '\\\\v';\nESCAPE_SEQUENCES[0x0C]   = '\\\\f';\nESCAPE_SEQUENCES[0x0D]   = '\\\\r';\nESCAPE_SEQUENCES[0x1B]   = '\\\\e';\nESCAPE_SEQUENCES[0x22]   = '\\\\\"';\nESCAPE_SEQUENCES[0x5C]   = '\\\\\\\\';\nESCAPE_SEQUENCES[0x85]   = '\\\\N';\nESCAPE_SEQUENCES[0xA0]   = '\\\\_';\nESCAPE_SEQUENCES[0x2028] = '\\\\L';\nESCAPE_SEQUENCES[0x2029] = '\\\\P';\n\nvar DEPRECATED_BOOLEANS_SYNTAX = [\n  'y', 'Y', 'yes', 'Yes', 'YES', 'on', 'On', 'ON',\n  'n', 'N', 'no', 'No', 'NO', 'off', 'Off', 'OFF'\n];\n\nvar DEPRECATED_BASE60_SYNTAX = /^[-+]?[0-9_]+(?::[0-9_]+)+(?:\\.[0-9_]*)?$/;\n\nfunction compileStyleMap(schema, map) {\n  var result, keys, index, length, tag, style, type;\n\n  if (map === null) return {};\n\n  result = {};\n  keys = Object.keys(map);\n\n  for (index = 0, length = keys.length; index < length; index += 1) {\n    tag = keys[index];\n    style = String(map[tag]);\n\n    if (tag.slice(0, 2) === '!!') {\n      tag = 'tag:yaml.org,2002:' + tag.slice(2);\n    }\n    type = schema.compiledTypeMap['fallback'][tag];\n\n    if (type && _hasOwnProperty.call(type.styleAliases, style)) {\n      style = type.styleAliases[style];\n    }\n\n    result[tag] = style;\n  }\n\n  return result;\n}\n\nfunction encodeHex(character) {\n  var string, handle, length;\n\n  string = character.toString(16).toUpperCase();\n\n  if (character <= 0xFF) {\n    handle = 'x';\n    length = 2;\n  } else if (character <= 0xFFFF) {\n    handle = 'u';\n    length = 4;\n  } else if (character <= 0xFFFFFFFF) {\n    handle = 'U';\n    length = 8;\n  } else {\n    throw new YAMLException('code point within a string may not be greater than 0xFFFFFFFF');\n  }\n\n  return '\\\\' + handle + common.repeat('0', length - string.length) + string;\n}\n\n\nvar QUOTING_TYPE_SINGLE = 1,\n    QUOTING_TYPE_DOUBLE = 2;\n\nfunction State(options) {\n  this.schema        = options['schema'] || DEFAULT_SCHEMA;\n  this.indent        = Math.max(1, (options['indent'] || 2));\n  this.noArrayIndent = options['noArrayIndent'] || false;\n  this.skipInvalid   = options['skipInvalid'] || false;\n  this.flowLevel     = (common.isNothing(options['flowLevel']) ? -1 : options['flowLevel']);\n  this.styleMap      = compileStyleMap(this.schema, options['styles'] || null);\n  this.sortKeys      = options['sortKeys'] || false;\n  this.lineWidth     = options['lineWidth'] || 80;\n  this.noRefs        = options['noRefs'] || false;\n  this.noCompatMode  = options['noCompatMode'] || false;\n  this.condenseFlow  = options['condenseFlow'] || false;\n  this.quotingType   = options['quotingType'] === '\"' ? QUOTING_TYPE_DOUBLE : QUOTING_TYPE_SINGLE;\n  this.forceQuotes   = options['forceQuotes'] || false;\n  this.replacer      = typeof options['replacer'] === 'function' ? options['replacer'] : null;\n\n  this.implicitTypes = this.schema.compiledImplicit;\n  this.explicitTypes = this.schema.compiledExplicit;\n\n  this.tag = null;\n  this.result = '';\n\n  this.duplicates = [];\n  this.usedDuplicates = null;\n}\n\n// Indents every line in a string. Empty lines (\\n only) are not indented.\nfunction indentString(string, spaces) {\n  var ind = common.repeat(' ', spaces),\n      position = 0,\n      next = -1,\n      result = '',\n      line,\n      length = string.length;\n\n  while (position < length) {\n    next = string.indexOf('\\n', position);\n    if (next === -1) {\n      line = string.slice(position);\n      position = length;\n    } else {\n      line = string.slice(position, next + 1);\n      position = next + 1;\n    }\n\n    if (line.length && line !== '\\n') result += ind;\n\n    result += line;\n  }\n\n  return result;\n}\n\nfunction generateNextLine(state, level) {\n  return '\\n' + common.repeat(' ', state.indent * level);\n}\n\nfunction testImplicitResolving(state, str) {\n  var index, length, type;\n\n  for (index = 0, length = state.implicitTypes.length; index < length; index += 1) {\n    type = state.implicitTypes[index];\n\n    if (type.resolve(str)) {\n      return true;\n    }\n  }\n\n  return false;\n}\n\n// [33] s-white ::= s-space | s-tab\nfunction isWhitespace(c) {\n  return c === CHAR_SPACE || c === CHAR_TAB;\n}\n\n// Returns true if the character can be printed without escaping.\n// From YAML 1.2: \"any allowed characters known to be non-printable\n// should also be escaped. [However,] This isnt mandatory\"\n// Derived from nb-char - \\t - #x85 - #xA0 - #x2028 - #x2029.\nfunction isPrintable(c) {\n  return  (0x00020 <= c && c <= 0x00007E)\n      || ((0x000A1 <= c && c <= 0x00D7FF) && c !== 0x2028 && c !== 0x2029)\n      || ((0x0E000 <= c && c <= 0x00FFFD) && c !== CHAR_BOM)\n      ||  (0x10000 <= c && c <= 0x10FFFF);\n}\n\n// [34] ns-char ::= nb-char - s-white\n// [27] nb-char ::= c-printable - b-char - c-byte-order-mark\n// [26] b-char  ::= b-line-feed | b-carriage-return\n// Including s-white (for some reason, examples doesn't match specs in this aspect)\n// ns-char ::= c-printable - b-line-feed - b-carriage-return - c-byte-order-mark\nfunction isNsCharOrWhitespace(c) {\n  return isPrintable(c)\n    && c !== CHAR_BOM\n    // - b-char\n    && c !== CHAR_CARRIAGE_RETURN\n    && c !== CHAR_LINE_FEED;\n}\n\n// [127]  ns-plain-safe(c) ::= c = flow-out   ns-plain-safe-out\n//                             c = flow-in    ns-plain-safe-in\n//                             c = block-key  ns-plain-safe-out\n//                             c = flow-key   ns-plain-safe-in\n// [128] ns-plain-safe-out ::= ns-char\n// [129]  ns-plain-safe-in ::= ns-char - c-flow-indicator\n// [130]  ns-plain-char(c) ::=  ( ns-plain-safe(c) - : - # )\n//                            | ( /* An ns-char preceding */ # )\n//                            | ( : /* Followed by an ns-plain-safe(c) */ )\nfunction isPlainSafe(c, prev, inblock) {\n  var cIsNsCharOrWhitespace = isNsCharOrWhitespace(c);\n  var cIsNsChar = cIsNsCharOrWhitespace && !isWhitespace(c);\n  return (\n    // ns-plain-safe\n    inblock ? // c = flow-in\n      cIsNsCharOrWhitespace\n      : cIsNsCharOrWhitespace\n        // - c-flow-indicator\n        && c !== CHAR_COMMA\n        && c !== CHAR_LEFT_SQUARE_BRACKET\n        && c !== CHAR_RIGHT_SQUARE_BRACKET\n        && c !== CHAR_LEFT_CURLY_BRACKET\n        && c !== CHAR_RIGHT_CURLY_BRACKET\n  )\n    // ns-plain-char\n    && c !== CHAR_SHARP // false on '#'\n    && !(prev === CHAR_COLON && !cIsNsChar) // false on ': '\n    || (isNsCharOrWhitespace(prev) && !isWhitespace(prev) && c === CHAR_SHARP) // change to true on '[^ ]#'\n    || (prev === CHAR_COLON && cIsNsChar); // change to true on ':[^ ]'\n}\n\n// Simplified test for values allowed as the first character in plain style.\nfunction isPlainSafeFirst(c) {\n  // Uses a subset of ns-char - c-indicator\n  // where ns-char = nb-char - s-white.\n  // No support of ( ( ? | : | - ) /* Followed by an ns-plain-safe(c)) */ ) part\n  return isPrintable(c) && c !== CHAR_BOM\n    && !isWhitespace(c) // - s-white\n    // - (c-indicator ::=\n    // - | ? | : | , | [ | ] | { | }\n    && c !== CHAR_MINUS\n    && c !== CHAR_QUESTION\n    && c !== CHAR_COLON\n    && c !== CHAR_COMMA\n    && c !== CHAR_LEFT_SQUARE_BRACKET\n    && c !== CHAR_RIGHT_SQUARE_BRACKET\n    && c !== CHAR_LEFT_CURLY_BRACKET\n    && c !== CHAR_RIGHT_CURLY_BRACKET\n    // | # | & | * | ! | | | = | > | ' | \"\n    && c !== CHAR_SHARP\n    && c !== CHAR_AMPERSAND\n    && c !== CHAR_ASTERISK\n    && c !== CHAR_EXCLAMATION\n    && c !== CHAR_VERTICAL_LINE\n    && c !== CHAR_EQUALS\n    && c !== CHAR_GREATER_THAN\n    && c !== CHAR_SINGLE_QUOTE\n    && c !== CHAR_DOUBLE_QUOTE\n    // | % | @ | `)\n    && c !== CHAR_PERCENT\n    && c !== CHAR_COMMERCIAL_AT\n    && c !== CHAR_GRAVE_ACCENT;\n}\n\n// Simplified test for values allowed as the last character in plain style.\nfunction isPlainSafeLast(c) {\n  // just not whitespace or colon, it will be checked to be plain character later\n  return !isWhitespace(c) && c !== CHAR_COLON;\n}\n\n// Same as 'string'.codePointAt(pos), but works in older browsers.\nfunction codePointAt(string, pos) {\n  var first = string.charCodeAt(pos), second;\n  if (first >= 0xD800 && first <= 0xDBFF && pos + 1 < string.length) {\n    second = string.charCodeAt(pos + 1);\n    if (second >= 0xDC00 && second <= 0xDFFF) {\n      // https://mathiasbynens.be/notes/javascript-encoding#surrogate-formulae\n      return (first - 0xD800) * 0x400 + second - 0xDC00 + 0x10000;\n    }\n  }\n  return first;\n}\n\n// Determines whether block indentation indicator is required.\nfunction needIndentIndicator(string) {\n  var leadingSpaceRe = /^\\n* /;\n  return leadingSpaceRe.test(string);\n}\n\nvar STYLE_PLAIN   = 1,\n    STYLE_SINGLE  = 2,\n    STYLE_LITERAL = 3,\n    STYLE_FOLDED  = 4,\n    STYLE_DOUBLE  = 5;\n\n// Determines which scalar styles are possible and returns the preferred style.\n// lineWidth = -1 => no limit.\n// Pre-conditions: str.length > 0.\n// Post-conditions:\n//    STYLE_PLAIN or STYLE_SINGLE => no \\n are in the string.\n//    STYLE_LITERAL => no lines are suitable for folding (or lineWidth is -1).\n//    STYLE_FOLDED => a line > lineWidth and can be folded (and lineWidth != -1).\nfunction chooseScalarStyle(string, singleLineOnly, indentPerLevel, lineWidth,\n  testAmbiguousType, quotingType, forceQuotes, inblock) {\n\n  var i;\n  var char = 0;\n  var prevChar = null;\n  var hasLineBreak = false;\n  var hasFoldableLine = false; // only checked if shouldTrackWidth\n  var shouldTrackWidth = lineWidth !== -1;\n  var previousLineBreak = -1; // count the first line correctly\n  var plain = isPlainSafeFirst(codePointAt(string, 0))\n          && isPlainSafeLast(codePointAt(string, string.length - 1));\n\n  if (singleLineOnly || forceQuotes) {\n    // Case: no block styles.\n    // Check for disallowed characters to rule out plain and single.\n    for (i = 0; i < string.length; char >= 0x10000 ? i += 2 : i++) {\n      char = codePointAt(string, i);\n      if (!isPrintable(char)) {\n        return STYLE_DOUBLE;\n      }\n      plain = plain && isPlainSafe(char, prevChar, inblock);\n      prevChar = char;\n    }\n  } else {\n    // Case: block styles permitted.\n    for (i = 0; i < string.length; char >= 0x10000 ? i += 2 : i++) {\n      char = codePointAt(string, i);\n      if (char === CHAR_LINE_FEED) {\n        hasLineBreak = true;\n        // Check if any line can be folded.\n        if (shouldTrackWidth) {\n          hasFoldableLine = hasFoldableLine ||\n            // Foldable line = too long, and not more-indented.\n            (i - previousLineBreak - 1 > lineWidth &&\n             string[previousLineBreak + 1] !== ' ');\n          previousLineBreak = i;\n        }\n      } else if (!isPrintable(char)) {\n        return STYLE_DOUBLE;\n      }\n      plain = plain && isPlainSafe(char, prevChar, inblock);\n      prevChar = char;\n    }\n    // in case the end is missing a \\n\n    hasFoldableLine = hasFoldableLine || (shouldTrackWidth &&\n      (i - previousLineBreak - 1 > lineWidth &&\n       string[previousLineBreak + 1] !== ' '));\n  }\n  // Although every style can represent \\n without escaping, prefer block styles\n  // for multiline, since they're more readable and they don't add empty lines.\n  // Also prefer folding a super-long line.\n  if (!hasLineBreak && !hasFoldableLine) {\n    // Strings interpretable as another type have to be quoted;\n    // e.g. the string 'true' vs. the boolean true.\n    if (plain && !forceQuotes && !testAmbiguousType(string)) {\n      return STYLE_PLAIN;\n    }\n    return quotingType === QUOTING_TYPE_DOUBLE ? STYLE_DOUBLE : STYLE_SINGLE;\n  }\n  // Edge case: block indentation indicator can only have one digit.\n  if (indentPerLevel > 9 && needIndentIndicator(string)) {\n    return STYLE_DOUBLE;\n  }\n  // At this point we know block styles are valid.\n  // Prefer literal style unless we want to fold.\n  if (!forceQuotes) {\n    return hasFoldableLine ? STYLE_FOLDED : STYLE_LITERAL;\n  }\n  return quotingType === QUOTING_TYPE_DOUBLE ? STYLE_DOUBLE : STYLE_SINGLE;\n}\n\n// Note: line breaking/folding is implemented for only the folded style.\n// NB. We drop the last trailing newline (if any) of a returned block scalar\n//  since the dumper adds its own newline. This always works:\n//     No ending newline => unaffected; already using strip \"-\" chomping.\n//     Ending newline    => removed then restored.\n//  Importantly, this keeps the \"+\" chomp indicator from gaining an extra line.\nfunction writeScalar(state, string, level, iskey, inblock) {\n  state.dump = (function () {\n    if (string.length === 0) {\n      return state.quotingType === QUOTING_TYPE_DOUBLE ? '\"\"' : \"''\";\n    }\n    if (!state.noCompatMode) {\n      if (DEPRECATED_BOOLEANS_SYNTAX.indexOf(string) !== -1 || DEPRECATED_BASE60_SYNTAX.test(string)) {\n        return state.quotingType === QUOTING_TYPE_DOUBLE ? ('\"' + string + '\"') : (\"'\" + string + \"'\");\n      }\n    }\n\n    var indent = state.indent * Math.max(1, level); // no 0-indent scalars\n    // As indentation gets deeper, let the width decrease monotonically\n    // to the lower bound min(state.lineWidth, 40).\n    // Note that this implies\n    //  state.lineWidth  40 + state.indent: width is fixed at the lower bound.\n    //  state.lineWidth > 40 + state.indent: width decreases until the lower bound.\n    // This behaves better than a constant minimum width which disallows narrower options,\n    // or an indent threshold which causes the width to suddenly increase.\n    var lineWidth = state.lineWidth === -1\n      ? -1 : Math.max(Math.min(state.lineWidth, 40), state.lineWidth - indent);\n\n    // Without knowing if keys are implicit/explicit, assume implicit for safety.\n    var singleLineOnly = iskey\n      // No block styles in flow mode.\n      || (state.flowLevel > -1 && level >= state.flowLevel);\n    function testAmbiguity(string) {\n      return testImplicitResolving(state, string);\n    }\n\n    switch (chooseScalarStyle(string, singleLineOnly, state.indent, lineWidth,\n      testAmbiguity, state.quotingType, state.forceQuotes && !iskey, inblock)) {\n\n      case STYLE_PLAIN:\n        return string;\n      case STYLE_SINGLE:\n        return \"'\" + string.replace(/'/g, \"''\") + \"'\";\n      case STYLE_LITERAL:\n        return '|' + blockHeader(string, state.indent)\n          + dropEndingNewline(indentString(string, indent));\n      case STYLE_FOLDED:\n        return '>' + blockHeader(string, state.indent)\n          + dropEndingNewline(indentString(foldString(string, lineWidth), indent));\n      case STYLE_DOUBLE:\n        return '\"' + escapeString(string, lineWidth) + '\"';\n      default:\n        throw new YAMLException('impossible error: invalid scalar style');\n    }\n  }());\n}\n\n// Pre-conditions: string is valid for a block scalar, 1 <= indentPerLevel <= 9.\nfunction blockHeader(string, indentPerLevel) {\n  var indentIndicator = needIndentIndicator(string) ? String(indentPerLevel) : '';\n\n  // note the special case: the string '\\n' counts as a \"trailing\" empty line.\n  var clip =          string[string.length - 1] === '\\n';\n  var keep = clip && (string[string.length - 2] === '\\n' || string === '\\n');\n  var chomp = keep ? '+' : (clip ? '' : '-');\n\n  return indentIndicator + chomp + '\\n';\n}\n\n// (See the note for writeScalar.)\nfunction dropEndingNewline(string) {\n  return string[string.length - 1] === '\\n' ? string.slice(0, -1) : string;\n}\n\n// Note: a long line without a suitable break point will exceed the width limit.\n// Pre-conditions: every char in str isPrintable, str.length > 0, width > 0.\nfunction foldString(string, width) {\n  // In folded style, $k$ consecutive newlines output as $k+1$ newlines\n  // unless they're before or after a more-indented line, or at the very\n  // beginning or end, in which case $k$ maps to $k$.\n  // Therefore, parse each chunk as newline(s) followed by a content line.\n  var lineRe = /(\\n+)([^\\n]*)/g;\n\n  // first line (possibly an empty line)\n  var result = (function () {\n    var nextLF = string.indexOf('\\n');\n    nextLF = nextLF !== -1 ? nextLF : string.length;\n    lineRe.lastIndex = nextLF;\n    return foldLine(string.slice(0, nextLF), width);\n  }());\n  // If we haven't reached the first content line yet, don't add an extra \\n.\n  var prevMoreIndented = string[0] === '\\n' || string[0] === ' ';\n  var moreIndented;\n\n  // rest of the lines\n  var match;\n  while ((match = lineRe.exec(string))) {\n    var prefix = match[1], line = match[2];\n    moreIndented = (line[0] === ' ');\n    result += prefix\n      + (!prevMoreIndented && !moreIndented && line !== ''\n        ? '\\n' : '')\n      + foldLine(line, width);\n    prevMoreIndented = moreIndented;\n  }\n\n  return result;\n}\n\n// Greedy line breaking.\n// Picks the longest line under the limit each time,\n// otherwise settles for the shortest line over the limit.\n// NB. More-indented lines *cannot* be folded, as that would add an extra \\n.\nfunction foldLine(line, width) {\n  if (line === '' || line[0] === ' ') return line;\n\n  // Since a more-indented line adds a \\n, breaks can't be followed by a space.\n  var breakRe = / [^ ]/g; // note: the match index will always be <= length-2.\n  var match;\n  // start is an inclusive index. end, curr, and next are exclusive.\n  var start = 0, end, curr = 0, next = 0;\n  var result = '';\n\n  // Invariants: 0 <= start <= length-1.\n  //   0 <= curr <= next <= max(0, length-2). curr - start <= width.\n  // Inside the loop:\n  //   A match implies length >= 2, so curr and next are <= length-2.\n  while ((match = breakRe.exec(line))) {\n    next = match.index;\n    // maintain invariant: curr - start <= width\n    if (next - start > width) {\n      end = (curr > start) ? curr : next; // derive end <= length-2\n      result += '\\n' + line.slice(start, end);\n      // skip the space that was output as \\n\n      start = end + 1;                    // derive start <= length-1\n    }\n    curr = next;\n  }\n\n  // By the invariants, start <= length-1, so there is something left over.\n  // It is either the whole string or a part starting from non-whitespace.\n  result += '\\n';\n  // Insert a break if the remainder is too long and there is a break available.\n  if (line.length - start > width && curr > start) {\n    result += line.slice(start, curr) + '\\n' + line.slice(curr + 1);\n  } else {\n    result += line.slice(start);\n  }\n\n  return result.slice(1); // drop extra \\n joiner\n}\n\n// Escapes a double-quoted string.\nfunction escapeString(string) {\n  var result = '';\n  var char = 0;\n  var escapeSeq;\n\n  for (var i = 0; i < string.length; char >= 0x10000 ? i += 2 : i++) {\n    char = codePointAt(string, i);\n    escapeSeq = ESCAPE_SEQUENCES[char];\n\n    if (!escapeSeq && isPrintable(char)) {\n      result += string[i];\n      if (char >= 0x10000) result += string[i + 1];\n    } else {\n      result += escapeSeq || encodeHex(char);\n    }\n  }\n\n  return result;\n}\n\nfunction writeFlowSequence(state, level, object) {\n  var _result = '',\n      _tag    = state.tag,\n      index,\n      length,\n      value;\n\n  for (index = 0, length = object.length; index < length; index += 1) {\n    value = object[index];\n\n    if (state.replacer) {\n      value = state.replacer.call(object, String(index), value);\n    }\n\n    // Write only valid elements, put null instead of invalid elements.\n    if (writeNode(state, level, value, false, false) ||\n        (typeof value === 'undefined' &&\n         writeNode(state, level, null, false, false))) {\n\n      if (_result !== '') _result += ',' + (!state.condenseFlow ? ' ' : '');\n      _result += state.dump;\n    }\n  }\n\n  state.tag = _tag;\n  state.dump = '[' + _result + ']';\n}\n\nfunction writeBlockSequence(state, level, object, compact) {\n  var _result = '',\n      _tag    = state.tag,\n      index,\n      length,\n      value;\n\n  for (index = 0, length = object.length; index < length; index += 1) {\n    value = object[index];\n\n    if (state.replacer) {\n      value = state.replacer.call(object, String(index), value);\n    }\n\n    // Write only valid elements, put null instead of invalid elements.\n    if (writeNode(state, level + 1, value, true, true, false, true) ||\n        (typeof value === 'undefined' &&\n         writeNode(state, level + 1, null, true, true, false, true))) {\n\n      if (!compact || _result !== '') {\n        _result += generateNextLine(state, level);\n      }\n\n      if (state.dump && CHAR_LINE_FEED === state.dump.charCodeAt(0)) {\n        _result += '-';\n      } else {\n        _result += '- ';\n      }\n\n      _result += state.dump;\n    }\n  }\n\n  state.tag = _tag;\n  state.dump = _result || '[]'; // Empty sequence if no valid values.\n}\n\nfunction writeFlowMapping(state, level, object) {\n  var _result       = '',\n      _tag          = state.tag,\n      objectKeyList = Object.keys(object),\n      index,\n      length,\n      objectKey,\n      objectValue,\n      pairBuffer;\n\n  for (index = 0, length = objectKeyList.length; index < length; index += 1) {\n\n    pairBuffer = '';\n    if (_result !== '') pairBuffer += ', ';\n\n    if (state.condenseFlow) pairBuffer += '\"';\n\n    objectKey = objectKeyList[index];\n    objectValue = object[objectKey];\n\n    if (state.replacer) {\n      objectValue = state.replacer.call(object, objectKey, objectValue);\n    }\n\n    if (!writeNode(state, level, objectKey, false, false)) {\n      continue; // Skip this pair because of invalid key;\n    }\n\n    if (state.dump.length > 1024) pairBuffer += '? ';\n\n    pairBuffer += state.dump + (state.condenseFlow ? '\"' : '') + ':' + (state.condenseFlow ? '' : ' ');\n\n    if (!writeNode(state, level, objectValue, false, false)) {\n      continue; // Skip this pair because of invalid value.\n    }\n\n    pairBuffer += state.dump;\n\n    // Both key and value are valid.\n    _result += pairBuffer;\n  }\n\n  state.tag = _tag;\n  state.dump = '{' + _result + '}';\n}\n\nfunction writeBlockMapping(state, level, object, compact) {\n  var _result       = '',\n      _tag          = state.tag,\n      objectKeyList = Object.keys(object),\n      index,\n      length,\n      objectKey,\n      objectValue,\n      explicitPair,\n      pairBuffer;\n\n  // Allow sorting keys so that the output file is deterministic\n  if (state.sortKeys === true) {\n    // Default sorting\n    objectKeyList.sort();\n  } else if (typeof state.sortKeys === 'function') {\n    // Custom sort function\n    objectKeyList.sort(state.sortKeys);\n  } else if (state.sortKeys) {\n    // Something is wrong\n    throw new YAMLException('sortKeys must be a boolean or a function');\n  }\n\n  for (index = 0, length = objectKeyList.length; index < length; index += 1) {\n    pairBuffer = '';\n\n    if (!compact || _result !== '') {\n      pairBuffer += generateNextLine(state, level);\n    }\n\n    objectKey = objectKeyList[index];\n    objectValue = object[objectKey];\n\n    if (state.replacer) {\n      objectValue = state.replacer.call(object, objectKey, objectValue);\n    }\n\n    if (!writeNode(state, level + 1, objectKey, true, true, true)) {\n      continue; // Skip this pair because of invalid key.\n    }\n\n    explicitPair = (state.tag !== null && state.tag !== '?') ||\n                   (state.dump && state.dump.length > 1024);\n\n    if (explicitPair) {\n      if (state.dump && CHAR_LINE_FEED === state.dump.charCodeAt(0)) {\n        pairBuffer += '?';\n      } else {\n        pairBuffer += '? ';\n      }\n    }\n\n    pairBuffer += state.dump;\n\n    if (explicitPair) {\n      pairBuffer += generateNextLine(state, level);\n    }\n\n    if (!writeNode(state, level + 1, objectValue, true, explicitPair)) {\n      continue; // Skip this pair because of invalid value.\n    }\n\n    if (state.dump && CHAR_LINE_FEED === state.dump.charCodeAt(0)) {\n      pairBuffer += ':';\n    } else {\n      pairBuffer += ': ';\n    }\n\n    pairBuffer += state.dump;\n\n    // Both key and value are valid.\n    _result += pairBuffer;\n  }\n\n  state.tag = _tag;\n  state.dump = _result || '{}'; // Empty mapping if no valid pairs.\n}\n\nfunction detectType(state, object, explicit) {\n  var _result, typeList, index, length, type, style;\n\n  typeList = explicit ? state.explicitTypes : state.implicitTypes;\n\n  for (index = 0, length = typeList.length; index < length; index += 1) {\n    type = typeList[index];\n\n    if ((type.instanceOf  || type.predicate) &&\n        (!type.instanceOf || ((typeof object === 'object') && (object instanceof type.instanceOf))) &&\n        (!type.predicate  || type.predicate(object))) {\n\n      if (explicit) {\n        if (type.multi && type.representName) {\n          state.tag = type.representName(object);\n        } else {\n          state.tag = type.tag;\n        }\n      } else {\n        state.tag = '?';\n      }\n\n      if (type.represent) {\n        style = state.styleMap[type.tag] || type.defaultStyle;\n\n        if (_toString.call(type.represent) === '[object Function]') {\n          _result = type.represent(object, style);\n        } else if (_hasOwnProperty.call(type.represent, style)) {\n          _result = type.represent[style](object, style);\n        } else {\n          throw new YAMLException('!<' + type.tag + '> tag resolver accepts not \"' + style + '\" style');\n        }\n\n        state.dump = _result;\n      }\n\n      return true;\n    }\n  }\n\n  return false;\n}\n\n// Serializes `object` and writes it to global `result`.\n// Returns true on success, or false on invalid object.\n//\nfunction writeNode(state, level, object, block, compact, iskey, isblockseq) {\n  state.tag = null;\n  state.dump = object;\n\n  if (!detectType(state, object, false)) {\n    detectType(state, object, true);\n  }\n\n  var type = _toString.call(state.dump);\n  var inblock = block;\n  var tagStr;\n\n  if (block) {\n    block = (state.flowLevel < 0 || state.flowLevel > level);\n  }\n\n  var objectOrArray = type === '[object Object]' || type === '[object Array]',\n      duplicateIndex,\n      duplicate;\n\n  if (objectOrArray) {\n    duplicateIndex = state.duplicates.indexOf(object);\n    duplicate = duplicateIndex !== -1;\n  }\n\n  if ((state.tag !== null && state.tag !== '?') || duplicate || (state.indent !== 2 && level > 0)) {\n    compact = false;\n  }\n\n  if (duplicate && state.usedDuplicates[duplicateIndex]) {\n    state.dump = '*ref_' + duplicateIndex;\n  } else {\n    if (objectOrArray && duplicate && !state.usedDuplicates[duplicateIndex]) {\n      state.usedDuplicates[duplicateIndex] = true;\n    }\n    if (type === '[object Object]') {\n      if (block && (Object.keys(state.dump).length !== 0)) {\n        writeBlockMapping(state, level, state.dump, compact);\n        if (duplicate) {\n          state.dump = '&ref_' + duplicateIndex + state.dump;\n        }\n      } else {\n        writeFlowMapping(state, level, state.dump);\n        if (duplicate) {\n          state.dump = '&ref_' + duplicateIndex + ' ' + state.dump;\n        }\n      }\n    } else if (type === '[object Array]') {\n      if (block && (state.dump.length !== 0)) {\n        if (state.noArrayIndent && !isblockseq && level > 0) {\n          writeBlockSequence(state, level - 1, state.dump, compact);\n        } else {\n          writeBlockSequence(state, level, state.dump, compact);\n        }\n        if (duplicate) {\n          state.dump = '&ref_' + duplicateIndex + state.dump;\n        }\n      } else {\n        writeFlowSequence(state, level, state.dump);\n        if (duplicate) {\n          state.dump = '&ref_' + duplicateIndex + ' ' + state.dump;\n        }\n      }\n    } else if (type === '[object String]') {\n      if (state.tag !== '?') {\n        writeScalar(state, state.dump, level, iskey, inblock);\n      }\n    } else if (type === '[object Undefined]') {\n      return false;\n    } else {\n      if (state.skipInvalid) return false;\n      throw new YAMLException('unacceptable kind of an object to dump ' + type);\n    }\n\n    if (state.tag !== null && state.tag !== '?') {\n      // Need to encode all characters except those allowed by the spec:\n      //\n      // [35] ns-dec-digit    ::=  [#x30-#x39] /* 0-9 */\n      // [36] ns-hex-digit    ::=  ns-dec-digit\n      //                         | [#x41-#x46] /* A-F */ | [#x61-#x66] /* a-f */\n      // [37] ns-ascii-letter ::=  [#x41-#x5A] /* A-Z */ | [#x61-#x7A] /* a-z */\n      // [38] ns-word-char    ::=  ns-dec-digit | ns-ascii-letter | -\n      // [39] ns-uri-char     ::=  % ns-hex-digit ns-hex-digit | ns-word-char | #\n      //                         | ; | / | ? | : | @ | & | = | + | $ | ,\n      //                         | _ | . | ! | ~ | * | ' | ( | ) | [ | ]\n      //\n      // Also need to encode '!' because it has special meaning (end of tag prefix).\n      //\n      tagStr = encodeURI(\n        state.tag[0] === '!' ? state.tag.slice(1) : state.tag\n      ).replace(/!/g, '%21');\n\n      if (state.tag[0] === '!') {\n        tagStr = '!' + tagStr;\n      } else if (tagStr.slice(0, 18) === 'tag:yaml.org,2002:') {\n        tagStr = '!!' + tagStr.slice(18);\n      } else {\n        tagStr = '!<' + tagStr + '>';\n      }\n\n      state.dump = tagStr + ' ' + state.dump;\n    }\n  }\n\n  return true;\n}\n\nfunction getDuplicateReferences(object, state) {\n  var objects = [],\n      duplicatesIndexes = [],\n      index,\n      length;\n\n  inspectNode(object, objects, duplicatesIndexes);\n\n  for (index = 0, length = duplicatesIndexes.length; index < length; index += 1) {\n    state.duplicates.push(objects[duplicatesIndexes[index]]);\n  }\n  state.usedDuplicates = new Array(length);\n}\n\nfunction inspectNode(object, objects, duplicatesIndexes) {\n  var objectKeyList,\n      index,\n      length;\n\n  if (object !== null && typeof object === 'object') {\n    index = objects.indexOf(object);\n    if (index !== -1) {\n      if (duplicatesIndexes.indexOf(index) === -1) {\n        duplicatesIndexes.push(index);\n      }\n    } else {\n      objects.push(object);\n\n      if (Array.isArray(object)) {\n        for (index = 0, length = object.length; index < length; index += 1) {\n          inspectNode(object[index], objects, duplicatesIndexes);\n        }\n      } else {\n        objectKeyList = Object.keys(object);\n\n        for (index = 0, length = objectKeyList.length; index < length; index += 1) {\n          inspectNode(object[objectKeyList[index]], objects, duplicatesIndexes);\n        }\n      }\n    }\n  }\n}\n\nfunction dump(input, options) {\n  options = options || {};\n\n  var state = new State(options);\n\n  if (!state.noRefs) getDuplicateReferences(input, state);\n\n  var value = input;\n\n  if (state.replacer) {\n    value = state.replacer.call({ '': value }, '', value);\n  }\n\n  if (writeNode(state, 0, value, true, true)) return state.dump + '\\n';\n\n  return '';\n}\n\nmodule.exports.dump = dump;\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/lib/dumper.js?");

/***/ }),

/***/ "./node_modules/js-yaml/lib/exception.js":
/*!***********************************************!*\
  !*** ./node_modules/js-yaml/lib/exception.js ***!
  \***********************************************/
/***/ ((module) => {

"use strict";
eval("// YAML error class. http://stackoverflow.com/questions/8458984\n//\n\n\n\nfunction formatError(exception, compact) {\n  var where = '', message = exception.reason || '(unknown reason)';\n\n  if (!exception.mark) return message;\n\n  if (exception.mark.name) {\n    where += 'in \"' + exception.mark.name + '\" ';\n  }\n\n  where += '(' + (exception.mark.line + 1) + ':' + (exception.mark.column + 1) + ')';\n\n  if (!compact && exception.mark.snippet) {\n    where += '\\n\\n' + exception.mark.snippet;\n  }\n\n  return message + ' ' + where;\n}\n\n\nfunction YAMLException(reason, mark) {\n  // Super constructor\n  Error.call(this);\n\n  this.name = 'YAMLException';\n  this.reason = reason;\n  this.mark = mark;\n  this.message = formatError(this, false);\n\n  // Include stack trace in error object\n  if (Error.captureStackTrace) {\n    // Chrome and NodeJS\n    Error.captureStackTrace(this, this.constructor);\n  } else {\n    // FF, IE 10+ and Safari 6+. Fallback for others\n    this.stack = (new Error()).stack || '';\n  }\n}\n\n\n// Inherit from Error\nYAMLException.prototype = Object.create(Error.prototype);\nYAMLException.prototype.constructor = YAMLException;\n\n\nYAMLException.prototype.toString = function toString(compact) {\n  return this.name + ': ' + formatError(this, compact);\n};\n\n\nmodule.exports = YAMLException;\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/lib/exception.js?");

/***/ }),

/***/ "./node_modules/js-yaml/lib/loader.js":
/*!********************************************!*\
  !*** ./node_modules/js-yaml/lib/loader.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*eslint-disable max-len,no-use-before-define*/\n\nvar common              = __webpack_require__(/*! ./common */ \"./node_modules/js-yaml/lib/common.js\");\nvar YAMLException       = __webpack_require__(/*! ./exception */ \"./node_modules/js-yaml/lib/exception.js\");\nvar makeSnippet         = __webpack_require__(/*! ./snippet */ \"./node_modules/js-yaml/lib/snippet.js\");\nvar DEFAULT_SCHEMA      = __webpack_require__(/*! ./schema/default */ \"./node_modules/js-yaml/lib/schema/default.js\");\n\n\nvar _hasOwnProperty = Object.prototype.hasOwnProperty;\n\n\nvar CONTEXT_FLOW_IN   = 1;\nvar CONTEXT_FLOW_OUT  = 2;\nvar CONTEXT_BLOCK_IN  = 3;\nvar CONTEXT_BLOCK_OUT = 4;\n\n\nvar CHOMPING_CLIP  = 1;\nvar CHOMPING_STRIP = 2;\nvar CHOMPING_KEEP  = 3;\n\n\nvar PATTERN_NON_PRINTABLE         = /[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F-\\x84\\x86-\\x9F\\uFFFE\\uFFFF]|[\\uD800-\\uDBFF](?![\\uDC00-\\uDFFF])|(?:[^\\uD800-\\uDBFF]|^)[\\uDC00-\\uDFFF]/;\nvar PATTERN_NON_ASCII_LINE_BREAKS = /[\\x85\\u2028\\u2029]/;\nvar PATTERN_FLOW_INDICATORS       = /[,\\[\\]\\{\\}]/;\nvar PATTERN_TAG_HANDLE            = /^(?:!|!!|![a-z\\-]+!)$/i;\nvar PATTERN_TAG_URI               = /^(?:!|[^,\\[\\]\\{\\}])(?:%[0-9a-f]{2}|[0-9a-z\\-#;\\/\\?:@&=\\+\\$,_\\.!~\\*'\\(\\)\\[\\]])*$/i;\n\n\nfunction _class(obj) { return Object.prototype.toString.call(obj); }\n\nfunction is_EOL(c) {\n  return (c === 0x0A/* LF */) || (c === 0x0D/* CR */);\n}\n\nfunction is_WHITE_SPACE(c) {\n  return (c === 0x09/* Tab */) || (c === 0x20/* Space */);\n}\n\nfunction is_WS_OR_EOL(c) {\n  return (c === 0x09/* Tab */) ||\n         (c === 0x20/* Space */) ||\n         (c === 0x0A/* LF */) ||\n         (c === 0x0D/* CR */);\n}\n\nfunction is_FLOW_INDICATOR(c) {\n  return c === 0x2C/* , */ ||\n         c === 0x5B/* [ */ ||\n         c === 0x5D/* ] */ ||\n         c === 0x7B/* { */ ||\n         c === 0x7D/* } */;\n}\n\nfunction fromHexCode(c) {\n  var lc;\n\n  if ((0x30/* 0 */ <= c) && (c <= 0x39/* 9 */)) {\n    return c - 0x30;\n  }\n\n  /*eslint-disable no-bitwise*/\n  lc = c | 0x20;\n\n  if ((0x61/* a */ <= lc) && (lc <= 0x66/* f */)) {\n    return lc - 0x61 + 10;\n  }\n\n  return -1;\n}\n\nfunction escapedHexLen(c) {\n  if (c === 0x78/* x */) { return 2; }\n  if (c === 0x75/* u */) { return 4; }\n  if (c === 0x55/* U */) { return 8; }\n  return 0;\n}\n\nfunction fromDecimalCode(c) {\n  if ((0x30/* 0 */ <= c) && (c <= 0x39/* 9 */)) {\n    return c - 0x30;\n  }\n\n  return -1;\n}\n\nfunction simpleEscapeSequence(c) {\n  /* eslint-disable indent */\n  return (c === 0x30/* 0 */) ? '\\x00' :\n        (c === 0x61/* a */) ? '\\x07' :\n        (c === 0x62/* b */) ? '\\x08' :\n        (c === 0x74/* t */) ? '\\x09' :\n        (c === 0x09/* Tab */) ? '\\x09' :\n        (c === 0x6E/* n */) ? '\\x0A' :\n        (c === 0x76/* v */) ? '\\x0B' :\n        (c === 0x66/* f */) ? '\\x0C' :\n        (c === 0x72/* r */) ? '\\x0D' :\n        (c === 0x65/* e */) ? '\\x1B' :\n        (c === 0x20/* Space */) ? ' ' :\n        (c === 0x22/* \" */) ? '\\x22' :\n        (c === 0x2F/* / */) ? '/' :\n        (c === 0x5C/* \\ */) ? '\\x5C' :\n        (c === 0x4E/* N */) ? '\\x85' :\n        (c === 0x5F/* _ */) ? '\\xA0' :\n        (c === 0x4C/* L */) ? '\\u2028' :\n        (c === 0x50/* P */) ? '\\u2029' : '';\n}\n\nfunction charFromCodepoint(c) {\n  if (c <= 0xFFFF) {\n    return String.fromCharCode(c);\n  }\n  // Encode UTF-16 surrogate pair\n  // https://en.wikipedia.org/wiki/UTF-16#Code_points_U.2B010000_to_U.2B10FFFF\n  return String.fromCharCode(\n    ((c - 0x010000) >> 10) + 0xD800,\n    ((c - 0x010000) & 0x03FF) + 0xDC00\n  );\n}\n\nvar simpleEscapeCheck = new Array(256); // integer, for fast access\nvar simpleEscapeMap = new Array(256);\nfor (var i = 0; i < 256; i++) {\n  simpleEscapeCheck[i] = simpleEscapeSequence(i) ? 1 : 0;\n  simpleEscapeMap[i] = simpleEscapeSequence(i);\n}\n\n\nfunction State(input, options) {\n  this.input = input;\n\n  this.filename  = options['filename']  || null;\n  this.schema    = options['schema']    || DEFAULT_SCHEMA;\n  this.onWarning = options['onWarning'] || null;\n  // (Hidden) Remove? makes the loader to expect YAML 1.1 documents\n  // if such documents have no explicit %YAML directive\n  this.legacy    = options['legacy']    || false;\n\n  this.json      = options['json']      || false;\n  this.listener  = options['listener']  || null;\n\n  this.implicitTypes = this.schema.compiledImplicit;\n  this.typeMap       = this.schema.compiledTypeMap;\n\n  this.length     = input.length;\n  this.position   = 0;\n  this.line       = 0;\n  this.lineStart  = 0;\n  this.lineIndent = 0;\n\n  // position of first leading tab in the current line,\n  // used to make sure there are no tabs in the indentation\n  this.firstTabInLine = -1;\n\n  this.documents = [];\n\n  /*\n  this.version;\n  this.checkLineBreaks;\n  this.tagMap;\n  this.anchorMap;\n  this.tag;\n  this.anchor;\n  this.kind;\n  this.result;*/\n\n}\n\n\nfunction generateError(state, message) {\n  var mark = {\n    name:     state.filename,\n    buffer:   state.input.slice(0, -1), // omit trailing \\0\n    position: state.position,\n    line:     state.line,\n    column:   state.position - state.lineStart\n  };\n\n  mark.snippet = makeSnippet(mark);\n\n  return new YAMLException(message, mark);\n}\n\nfunction throwError(state, message) {\n  throw generateError(state, message);\n}\n\nfunction throwWarning(state, message) {\n  if (state.onWarning) {\n    state.onWarning.call(null, generateError(state, message));\n  }\n}\n\n\nvar directiveHandlers = {\n\n  YAML: function handleYamlDirective(state, name, args) {\n\n    var match, major, minor;\n\n    if (state.version !== null) {\n      throwError(state, 'duplication of %YAML directive');\n    }\n\n    if (args.length !== 1) {\n      throwError(state, 'YAML directive accepts exactly one argument');\n    }\n\n    match = /^([0-9]+)\\.([0-9]+)$/.exec(args[0]);\n\n    if (match === null) {\n      throwError(state, 'ill-formed argument of the YAML directive');\n    }\n\n    major = parseInt(match[1], 10);\n    minor = parseInt(match[2], 10);\n\n    if (major !== 1) {\n      throwError(state, 'unacceptable YAML version of the document');\n    }\n\n    state.version = args[0];\n    state.checkLineBreaks = (minor < 2);\n\n    if (minor !== 1 && minor !== 2) {\n      throwWarning(state, 'unsupported YAML version of the document');\n    }\n  },\n\n  TAG: function handleTagDirective(state, name, args) {\n\n    var handle, prefix;\n\n    if (args.length !== 2) {\n      throwError(state, 'TAG directive accepts exactly two arguments');\n    }\n\n    handle = args[0];\n    prefix = args[1];\n\n    if (!PATTERN_TAG_HANDLE.test(handle)) {\n      throwError(state, 'ill-formed tag handle (first argument) of the TAG directive');\n    }\n\n    if (_hasOwnProperty.call(state.tagMap, handle)) {\n      throwError(state, 'there is a previously declared suffix for \"' + handle + '\" tag handle');\n    }\n\n    if (!PATTERN_TAG_URI.test(prefix)) {\n      throwError(state, 'ill-formed tag prefix (second argument) of the TAG directive');\n    }\n\n    try {\n      prefix = decodeURIComponent(prefix);\n    } catch (err) {\n      throwError(state, 'tag prefix is malformed: ' + prefix);\n    }\n\n    state.tagMap[handle] = prefix;\n  }\n};\n\n\nfunction captureSegment(state, start, end, checkJson) {\n  var _position, _length, _character, _result;\n\n  if (start < end) {\n    _result = state.input.slice(start, end);\n\n    if (checkJson) {\n      for (_position = 0, _length = _result.length; _position < _length; _position += 1) {\n        _character = _result.charCodeAt(_position);\n        if (!(_character === 0x09 ||\n              (0x20 <= _character && _character <= 0x10FFFF))) {\n          throwError(state, 'expected valid JSON character');\n        }\n      }\n    } else if (PATTERN_NON_PRINTABLE.test(_result)) {\n      throwError(state, 'the stream contains non-printable characters');\n    }\n\n    state.result += _result;\n  }\n}\n\nfunction mergeMappings(state, destination, source, overridableKeys) {\n  var sourceKeys, key, index, quantity;\n\n  if (!common.isObject(source)) {\n    throwError(state, 'cannot merge mappings; the provided source object is unacceptable');\n  }\n\n  sourceKeys = Object.keys(source);\n\n  for (index = 0, quantity = sourceKeys.length; index < quantity; index += 1) {\n    key = sourceKeys[index];\n\n    if (!_hasOwnProperty.call(destination, key)) {\n      destination[key] = source[key];\n      overridableKeys[key] = true;\n    }\n  }\n}\n\nfunction storeMappingPair(state, _result, overridableKeys, keyTag, keyNode, valueNode,\n  startLine, startLineStart, startPos) {\n\n  var index, quantity;\n\n  // The output is a plain object here, so keys can only be strings.\n  // We need to convert keyNode to a string, but doing so can hang the process\n  // (deeply nested arrays that explode exponentially using aliases).\n  if (Array.isArray(keyNode)) {\n    keyNode = Array.prototype.slice.call(keyNode);\n\n    for (index = 0, quantity = keyNode.length; index < quantity; index += 1) {\n      if (Array.isArray(keyNode[index])) {\n        throwError(state, 'nested arrays are not supported inside keys');\n      }\n\n      if (typeof keyNode === 'object' && _class(keyNode[index]) === '[object Object]') {\n        keyNode[index] = '[object Object]';\n      }\n    }\n  }\n\n  // Avoid code execution in load() via toString property\n  // (still use its own toString for arrays, timestamps,\n  // and whatever user schema extensions happen to have @@toStringTag)\n  if (typeof keyNode === 'object' && _class(keyNode) === '[object Object]') {\n    keyNode = '[object Object]';\n  }\n\n\n  keyNode = String(keyNode);\n\n  if (_result === null) {\n    _result = {};\n  }\n\n  if (keyTag === 'tag:yaml.org,2002:merge') {\n    if (Array.isArray(valueNode)) {\n      for (index = 0, quantity = valueNode.length; index < quantity; index += 1) {\n        mergeMappings(state, _result, valueNode[index], overridableKeys);\n      }\n    } else {\n      mergeMappings(state, _result, valueNode, overridableKeys);\n    }\n  } else {\n    if (!state.json &&\n        !_hasOwnProperty.call(overridableKeys, keyNode) &&\n        _hasOwnProperty.call(_result, keyNode)) {\n      state.line = startLine || state.line;\n      state.lineStart = startLineStart || state.lineStart;\n      state.position = startPos || state.position;\n      throwError(state, 'duplicated mapping key');\n    }\n\n    // used for this specific key only because Object.defineProperty is slow\n    if (keyNode === '__proto__') {\n      Object.defineProperty(_result, keyNode, {\n        configurable: true,\n        enumerable: true,\n        writable: true,\n        value: valueNode\n      });\n    } else {\n      _result[keyNode] = valueNode;\n    }\n    delete overridableKeys[keyNode];\n  }\n\n  return _result;\n}\n\nfunction readLineBreak(state) {\n  var ch;\n\n  ch = state.input.charCodeAt(state.position);\n\n  if (ch === 0x0A/* LF */) {\n    state.position++;\n  } else if (ch === 0x0D/* CR */) {\n    state.position++;\n    if (state.input.charCodeAt(state.position) === 0x0A/* LF */) {\n      state.position++;\n    }\n  } else {\n    throwError(state, 'a line break is expected');\n  }\n\n  state.line += 1;\n  state.lineStart = state.position;\n  state.firstTabInLine = -1;\n}\n\nfunction skipSeparationSpace(state, allowComments, checkIndent) {\n  var lineBreaks = 0,\n      ch = state.input.charCodeAt(state.position);\n\n  while (ch !== 0) {\n    while (is_WHITE_SPACE(ch)) {\n      if (ch === 0x09/* Tab */ && state.firstTabInLine === -1) {\n        state.firstTabInLine = state.position;\n      }\n      ch = state.input.charCodeAt(++state.position);\n    }\n\n    if (allowComments && ch === 0x23/* # */) {\n      do {\n        ch = state.input.charCodeAt(++state.position);\n      } while (ch !== 0x0A/* LF */ && ch !== 0x0D/* CR */ && ch !== 0);\n    }\n\n    if (is_EOL(ch)) {\n      readLineBreak(state);\n\n      ch = state.input.charCodeAt(state.position);\n      lineBreaks++;\n      state.lineIndent = 0;\n\n      while (ch === 0x20/* Space */) {\n        state.lineIndent++;\n        ch = state.input.charCodeAt(++state.position);\n      }\n    } else {\n      break;\n    }\n  }\n\n  if (checkIndent !== -1 && lineBreaks !== 0 && state.lineIndent < checkIndent) {\n    throwWarning(state, 'deficient indentation');\n  }\n\n  return lineBreaks;\n}\n\nfunction testDocumentSeparator(state) {\n  var _position = state.position,\n      ch;\n\n  ch = state.input.charCodeAt(_position);\n\n  // Condition state.position === state.lineStart is tested\n  // in parent on each call, for efficiency. No needs to test here again.\n  if ((ch === 0x2D/* - */ || ch === 0x2E/* . */) &&\n      ch === state.input.charCodeAt(_position + 1) &&\n      ch === state.input.charCodeAt(_position + 2)) {\n\n    _position += 3;\n\n    ch = state.input.charCodeAt(_position);\n\n    if (ch === 0 || is_WS_OR_EOL(ch)) {\n      return true;\n    }\n  }\n\n  return false;\n}\n\nfunction writeFoldedLines(state, count) {\n  if (count === 1) {\n    state.result += ' ';\n  } else if (count > 1) {\n    state.result += common.repeat('\\n', count - 1);\n  }\n}\n\n\nfunction readPlainScalar(state, nodeIndent, withinFlowCollection) {\n  var preceding,\n      following,\n      captureStart,\n      captureEnd,\n      hasPendingContent,\n      _line,\n      _lineStart,\n      _lineIndent,\n      _kind = state.kind,\n      _result = state.result,\n      ch;\n\n  ch = state.input.charCodeAt(state.position);\n\n  if (is_WS_OR_EOL(ch)      ||\n      is_FLOW_INDICATOR(ch) ||\n      ch === 0x23/* # */    ||\n      ch === 0x26/* & */    ||\n      ch === 0x2A/* * */    ||\n      ch === 0x21/* ! */    ||\n      ch === 0x7C/* | */    ||\n      ch === 0x3E/* > */    ||\n      ch === 0x27/* ' */    ||\n      ch === 0x22/* \" */    ||\n      ch === 0x25/* % */    ||\n      ch === 0x40/* @ */    ||\n      ch === 0x60/* ` */) {\n    return false;\n  }\n\n  if (ch === 0x3F/* ? */ || ch === 0x2D/* - */) {\n    following = state.input.charCodeAt(state.position + 1);\n\n    if (is_WS_OR_EOL(following) ||\n        withinFlowCollection && is_FLOW_INDICATOR(following)) {\n      return false;\n    }\n  }\n\n  state.kind = 'scalar';\n  state.result = '';\n  captureStart = captureEnd = state.position;\n  hasPendingContent = false;\n\n  while (ch !== 0) {\n    if (ch === 0x3A/* : */) {\n      following = state.input.charCodeAt(state.position + 1);\n\n      if (is_WS_OR_EOL(following) ||\n          withinFlowCollection && is_FLOW_INDICATOR(following)) {\n        break;\n      }\n\n    } else if (ch === 0x23/* # */) {\n      preceding = state.input.charCodeAt(state.position - 1);\n\n      if (is_WS_OR_EOL(preceding)) {\n        break;\n      }\n\n    } else if ((state.position === state.lineStart && testDocumentSeparator(state)) ||\n               withinFlowCollection && is_FLOW_INDICATOR(ch)) {\n      break;\n\n    } else if (is_EOL(ch)) {\n      _line = state.line;\n      _lineStart = state.lineStart;\n      _lineIndent = state.lineIndent;\n      skipSeparationSpace(state, false, -1);\n\n      if (state.lineIndent >= nodeIndent) {\n        hasPendingContent = true;\n        ch = state.input.charCodeAt(state.position);\n        continue;\n      } else {\n        state.position = captureEnd;\n        state.line = _line;\n        state.lineStart = _lineStart;\n        state.lineIndent = _lineIndent;\n        break;\n      }\n    }\n\n    if (hasPendingContent) {\n      captureSegment(state, captureStart, captureEnd, false);\n      writeFoldedLines(state, state.line - _line);\n      captureStart = captureEnd = state.position;\n      hasPendingContent = false;\n    }\n\n    if (!is_WHITE_SPACE(ch)) {\n      captureEnd = state.position + 1;\n    }\n\n    ch = state.input.charCodeAt(++state.position);\n  }\n\n  captureSegment(state, captureStart, captureEnd, false);\n\n  if (state.result) {\n    return true;\n  }\n\n  state.kind = _kind;\n  state.result = _result;\n  return false;\n}\n\nfunction readSingleQuotedScalar(state, nodeIndent) {\n  var ch,\n      captureStart, captureEnd;\n\n  ch = state.input.charCodeAt(state.position);\n\n  if (ch !== 0x27/* ' */) {\n    return false;\n  }\n\n  state.kind = 'scalar';\n  state.result = '';\n  state.position++;\n  captureStart = captureEnd = state.position;\n\n  while ((ch = state.input.charCodeAt(state.position)) !== 0) {\n    if (ch === 0x27/* ' */) {\n      captureSegment(state, captureStart, state.position, true);\n      ch = state.input.charCodeAt(++state.position);\n\n      if (ch === 0x27/* ' */) {\n        captureStart = state.position;\n        state.position++;\n        captureEnd = state.position;\n      } else {\n        return true;\n      }\n\n    } else if (is_EOL(ch)) {\n      captureSegment(state, captureStart, captureEnd, true);\n      writeFoldedLines(state, skipSeparationSpace(state, false, nodeIndent));\n      captureStart = captureEnd = state.position;\n\n    } else if (state.position === state.lineStart && testDocumentSeparator(state)) {\n      throwError(state, 'unexpected end of the document within a single quoted scalar');\n\n    } else {\n      state.position++;\n      captureEnd = state.position;\n    }\n  }\n\n  throwError(state, 'unexpected end of the stream within a single quoted scalar');\n}\n\nfunction readDoubleQuotedScalar(state, nodeIndent) {\n  var captureStart,\n      captureEnd,\n      hexLength,\n      hexResult,\n      tmp,\n      ch;\n\n  ch = state.input.charCodeAt(state.position);\n\n  if (ch !== 0x22/* \" */) {\n    return false;\n  }\n\n  state.kind = 'scalar';\n  state.result = '';\n  state.position++;\n  captureStart = captureEnd = state.position;\n\n  while ((ch = state.input.charCodeAt(state.position)) !== 0) {\n    if (ch === 0x22/* \" */) {\n      captureSegment(state, captureStart, state.position, true);\n      state.position++;\n      return true;\n\n    } else if (ch === 0x5C/* \\ */) {\n      captureSegment(state, captureStart, state.position, true);\n      ch = state.input.charCodeAt(++state.position);\n\n      if (is_EOL(ch)) {\n        skipSeparationSpace(state, false, nodeIndent);\n\n        // TODO: rework to inline fn with no type cast?\n      } else if (ch < 256 && simpleEscapeCheck[ch]) {\n        state.result += simpleEscapeMap[ch];\n        state.position++;\n\n      } else if ((tmp = escapedHexLen(ch)) > 0) {\n        hexLength = tmp;\n        hexResult = 0;\n\n        for (; hexLength > 0; hexLength--) {\n          ch = state.input.charCodeAt(++state.position);\n\n          if ((tmp = fromHexCode(ch)) >= 0) {\n            hexResult = (hexResult << 4) + tmp;\n\n          } else {\n            throwError(state, 'expected hexadecimal character');\n          }\n        }\n\n        state.result += charFromCodepoint(hexResult);\n\n        state.position++;\n\n      } else {\n        throwError(state, 'unknown escape sequence');\n      }\n\n      captureStart = captureEnd = state.position;\n\n    } else if (is_EOL(ch)) {\n      captureSegment(state, captureStart, captureEnd, true);\n      writeFoldedLines(state, skipSeparationSpace(state, false, nodeIndent));\n      captureStart = captureEnd = state.position;\n\n    } else if (state.position === state.lineStart && testDocumentSeparator(state)) {\n      throwError(state, 'unexpected end of the document within a double quoted scalar');\n\n    } else {\n      state.position++;\n      captureEnd = state.position;\n    }\n  }\n\n  throwError(state, 'unexpected end of the stream within a double quoted scalar');\n}\n\nfunction readFlowCollection(state, nodeIndent) {\n  var readNext = true,\n      _line,\n      _lineStart,\n      _pos,\n      _tag     = state.tag,\n      _result,\n      _anchor  = state.anchor,\n      following,\n      terminator,\n      isPair,\n      isExplicitPair,\n      isMapping,\n      overridableKeys = Object.create(null),\n      keyNode,\n      keyTag,\n      valueNode,\n      ch;\n\n  ch = state.input.charCodeAt(state.position);\n\n  if (ch === 0x5B/* [ */) {\n    terminator = 0x5D;/* ] */\n    isMapping = false;\n    _result = [];\n  } else if (ch === 0x7B/* { */) {\n    terminator = 0x7D;/* } */\n    isMapping = true;\n    _result = {};\n  } else {\n    return false;\n  }\n\n  if (state.anchor !== null) {\n    state.anchorMap[state.anchor] = _result;\n  }\n\n  ch = state.input.charCodeAt(++state.position);\n\n  while (ch !== 0) {\n    skipSeparationSpace(state, true, nodeIndent);\n\n    ch = state.input.charCodeAt(state.position);\n\n    if (ch === terminator) {\n      state.position++;\n      state.tag = _tag;\n      state.anchor = _anchor;\n      state.kind = isMapping ? 'mapping' : 'sequence';\n      state.result = _result;\n      return true;\n    } else if (!readNext) {\n      throwError(state, 'missed comma between flow collection entries');\n    } else if (ch === 0x2C/* , */) {\n      // \"flow collection entries can never be completely empty\", as per YAML 1.2, section 7.4\n      throwError(state, \"expected the node content, but found ','\");\n    }\n\n    keyTag = keyNode = valueNode = null;\n    isPair = isExplicitPair = false;\n\n    if (ch === 0x3F/* ? */) {\n      following = state.input.charCodeAt(state.position + 1);\n\n      if (is_WS_OR_EOL(following)) {\n        isPair = isExplicitPair = true;\n        state.position++;\n        skipSeparationSpace(state, true, nodeIndent);\n      }\n    }\n\n    _line = state.line; // Save the current line.\n    _lineStart = state.lineStart;\n    _pos = state.position;\n    composeNode(state, nodeIndent, CONTEXT_FLOW_IN, false, true);\n    keyTag = state.tag;\n    keyNode = state.result;\n    skipSeparationSpace(state, true, nodeIndent);\n\n    ch = state.input.charCodeAt(state.position);\n\n    if ((isExplicitPair || state.line === _line) && ch === 0x3A/* : */) {\n      isPair = true;\n      ch = state.input.charCodeAt(++state.position);\n      skipSeparationSpace(state, true, nodeIndent);\n      composeNode(state, nodeIndent, CONTEXT_FLOW_IN, false, true);\n      valueNode = state.result;\n    }\n\n    if (isMapping) {\n      storeMappingPair(state, _result, overridableKeys, keyTag, keyNode, valueNode, _line, _lineStart, _pos);\n    } else if (isPair) {\n      _result.push(storeMappingPair(state, null, overridableKeys, keyTag, keyNode, valueNode, _line, _lineStart, _pos));\n    } else {\n      _result.push(keyNode);\n    }\n\n    skipSeparationSpace(state, true, nodeIndent);\n\n    ch = state.input.charCodeAt(state.position);\n\n    if (ch === 0x2C/* , */) {\n      readNext = true;\n      ch = state.input.charCodeAt(++state.position);\n    } else {\n      readNext = false;\n    }\n  }\n\n  throwError(state, 'unexpected end of the stream within a flow collection');\n}\n\nfunction readBlockScalar(state, nodeIndent) {\n  var captureStart,\n      folding,\n      chomping       = CHOMPING_CLIP,\n      didReadContent = false,\n      detectedIndent = false,\n      textIndent     = nodeIndent,\n      emptyLines     = 0,\n      atMoreIndented = false,\n      tmp,\n      ch;\n\n  ch = state.input.charCodeAt(state.position);\n\n  if (ch === 0x7C/* | */) {\n    folding = false;\n  } else if (ch === 0x3E/* > */) {\n    folding = true;\n  } else {\n    return false;\n  }\n\n  state.kind = 'scalar';\n  state.result = '';\n\n  while (ch !== 0) {\n    ch = state.input.charCodeAt(++state.position);\n\n    if (ch === 0x2B/* + */ || ch === 0x2D/* - */) {\n      if (CHOMPING_CLIP === chomping) {\n        chomping = (ch === 0x2B/* + */) ? CHOMPING_KEEP : CHOMPING_STRIP;\n      } else {\n        throwError(state, 'repeat of a chomping mode identifier');\n      }\n\n    } else if ((tmp = fromDecimalCode(ch)) >= 0) {\n      if (tmp === 0) {\n        throwError(state, 'bad explicit indentation width of a block scalar; it cannot be less than one');\n      } else if (!detectedIndent) {\n        textIndent = nodeIndent + tmp - 1;\n        detectedIndent = true;\n      } else {\n        throwError(state, 'repeat of an indentation width identifier');\n      }\n\n    } else {\n      break;\n    }\n  }\n\n  if (is_WHITE_SPACE(ch)) {\n    do { ch = state.input.charCodeAt(++state.position); }\n    while (is_WHITE_SPACE(ch));\n\n    if (ch === 0x23/* # */) {\n      do { ch = state.input.charCodeAt(++state.position); }\n      while (!is_EOL(ch) && (ch !== 0));\n    }\n  }\n\n  while (ch !== 0) {\n    readLineBreak(state);\n    state.lineIndent = 0;\n\n    ch = state.input.charCodeAt(state.position);\n\n    while ((!detectedIndent || state.lineIndent < textIndent) &&\n           (ch === 0x20/* Space */)) {\n      state.lineIndent++;\n      ch = state.input.charCodeAt(++state.position);\n    }\n\n    if (!detectedIndent && state.lineIndent > textIndent) {\n      textIndent = state.lineIndent;\n    }\n\n    if (is_EOL(ch)) {\n      emptyLines++;\n      continue;\n    }\n\n    // End of the scalar.\n    if (state.lineIndent < textIndent) {\n\n      // Perform the chomping.\n      if (chomping === CHOMPING_KEEP) {\n        state.result += common.repeat('\\n', didReadContent ? 1 + emptyLines : emptyLines);\n      } else if (chomping === CHOMPING_CLIP) {\n        if (didReadContent) { // i.e. only if the scalar is not empty.\n          state.result += '\\n';\n        }\n      }\n\n      // Break this `while` cycle and go to the funciton's epilogue.\n      break;\n    }\n\n    // Folded style: use fancy rules to handle line breaks.\n    if (folding) {\n\n      // Lines starting with white space characters (more-indented lines) are not folded.\n      if (is_WHITE_SPACE(ch)) {\n        atMoreIndented = true;\n        // except for the first content line (cf. Example 8.1)\n        state.result += common.repeat('\\n', didReadContent ? 1 + emptyLines : emptyLines);\n\n      // End of more-indented block.\n      } else if (atMoreIndented) {\n        atMoreIndented = false;\n        state.result += common.repeat('\\n', emptyLines + 1);\n\n      // Just one line break - perceive as the same line.\n      } else if (emptyLines === 0) {\n        if (didReadContent) { // i.e. only if we have already read some scalar content.\n          state.result += ' ';\n        }\n\n      // Several line breaks - perceive as different lines.\n      } else {\n        state.result += common.repeat('\\n', emptyLines);\n      }\n\n    // Literal style: just add exact number of line breaks between content lines.\n    } else {\n      // Keep all line breaks except the header line break.\n      state.result += common.repeat('\\n', didReadContent ? 1 + emptyLines : emptyLines);\n    }\n\n    didReadContent = true;\n    detectedIndent = true;\n    emptyLines = 0;\n    captureStart = state.position;\n\n    while (!is_EOL(ch) && (ch !== 0)) {\n      ch = state.input.charCodeAt(++state.position);\n    }\n\n    captureSegment(state, captureStart, state.position, false);\n  }\n\n  return true;\n}\n\nfunction readBlockSequence(state, nodeIndent) {\n  var _line,\n      _tag      = state.tag,\n      _anchor   = state.anchor,\n      _result   = [],\n      following,\n      detected  = false,\n      ch;\n\n  // there is a leading tab before this token, so it can't be a block sequence/mapping;\n  // it can still be flow sequence/mapping or a scalar\n  if (state.firstTabInLine !== -1) return false;\n\n  if (state.anchor !== null) {\n    state.anchorMap[state.anchor] = _result;\n  }\n\n  ch = state.input.charCodeAt(state.position);\n\n  while (ch !== 0) {\n    if (state.firstTabInLine !== -1) {\n      state.position = state.firstTabInLine;\n      throwError(state, 'tab characters must not be used in indentation');\n    }\n\n    if (ch !== 0x2D/* - */) {\n      break;\n    }\n\n    following = state.input.charCodeAt(state.position + 1);\n\n    if (!is_WS_OR_EOL(following)) {\n      break;\n    }\n\n    detected = true;\n    state.position++;\n\n    if (skipSeparationSpace(state, true, -1)) {\n      if (state.lineIndent <= nodeIndent) {\n        _result.push(null);\n        ch = state.input.charCodeAt(state.position);\n        continue;\n      }\n    }\n\n    _line = state.line;\n    composeNode(state, nodeIndent, CONTEXT_BLOCK_IN, false, true);\n    _result.push(state.result);\n    skipSeparationSpace(state, true, -1);\n\n    ch = state.input.charCodeAt(state.position);\n\n    if ((state.line === _line || state.lineIndent > nodeIndent) && (ch !== 0)) {\n      throwError(state, 'bad indentation of a sequence entry');\n    } else if (state.lineIndent < nodeIndent) {\n      break;\n    }\n  }\n\n  if (detected) {\n    state.tag = _tag;\n    state.anchor = _anchor;\n    state.kind = 'sequence';\n    state.result = _result;\n    return true;\n  }\n  return false;\n}\n\nfunction readBlockMapping(state, nodeIndent, flowIndent) {\n  var following,\n      allowCompact,\n      _line,\n      _keyLine,\n      _keyLineStart,\n      _keyPos,\n      _tag          = state.tag,\n      _anchor       = state.anchor,\n      _result       = {},\n      overridableKeys = Object.create(null),\n      keyTag        = null,\n      keyNode       = null,\n      valueNode     = null,\n      atExplicitKey = false,\n      detected      = false,\n      ch;\n\n  // there is a leading tab before this token, so it can't be a block sequence/mapping;\n  // it can still be flow sequence/mapping or a scalar\n  if (state.firstTabInLine !== -1) return false;\n\n  if (state.anchor !== null) {\n    state.anchorMap[state.anchor] = _result;\n  }\n\n  ch = state.input.charCodeAt(state.position);\n\n  while (ch !== 0) {\n    if (!atExplicitKey && state.firstTabInLine !== -1) {\n      state.position = state.firstTabInLine;\n      throwError(state, 'tab characters must not be used in indentation');\n    }\n\n    following = state.input.charCodeAt(state.position + 1);\n    _line = state.line; // Save the current line.\n\n    //\n    // Explicit notation case. There are two separate blocks:\n    // first for the key (denoted by \"?\") and second for the value (denoted by \":\")\n    //\n    if ((ch === 0x3F/* ? */ || ch === 0x3A/* : */) && is_WS_OR_EOL(following)) {\n\n      if (ch === 0x3F/* ? */) {\n        if (atExplicitKey) {\n          storeMappingPair(state, _result, overridableKeys, keyTag, keyNode, null, _keyLine, _keyLineStart, _keyPos);\n          keyTag = keyNode = valueNode = null;\n        }\n\n        detected = true;\n        atExplicitKey = true;\n        allowCompact = true;\n\n      } else if (atExplicitKey) {\n        // i.e. 0x3A/* : */ === character after the explicit key.\n        atExplicitKey = false;\n        allowCompact = true;\n\n      } else {\n        throwError(state, 'incomplete explicit mapping pair; a key node is missed; or followed by a non-tabulated empty line');\n      }\n\n      state.position += 1;\n      ch = following;\n\n    //\n    // Implicit notation case. Flow-style node as the key first, then \":\", and the value.\n    //\n    } else {\n      _keyLine = state.line;\n      _keyLineStart = state.lineStart;\n      _keyPos = state.position;\n\n      if (!composeNode(state, flowIndent, CONTEXT_FLOW_OUT, false, true)) {\n        // Neither implicit nor explicit notation.\n        // Reading is done. Go to the epilogue.\n        break;\n      }\n\n      if (state.line === _line) {\n        ch = state.input.charCodeAt(state.position);\n\n        while (is_WHITE_SPACE(ch)) {\n          ch = state.input.charCodeAt(++state.position);\n        }\n\n        if (ch === 0x3A/* : */) {\n          ch = state.input.charCodeAt(++state.position);\n\n          if (!is_WS_OR_EOL(ch)) {\n            throwError(state, 'a whitespace character is expected after the key-value separator within a block mapping');\n          }\n\n          if (atExplicitKey) {\n            storeMappingPair(state, _result, overridableKeys, keyTag, keyNode, null, _keyLine, _keyLineStart, _keyPos);\n            keyTag = keyNode = valueNode = null;\n          }\n\n          detected = true;\n          atExplicitKey = false;\n          allowCompact = false;\n          keyTag = state.tag;\n          keyNode = state.result;\n\n        } else if (detected) {\n          throwError(state, 'can not read an implicit mapping pair; a colon is missed');\n\n        } else {\n          state.tag = _tag;\n          state.anchor = _anchor;\n          return true; // Keep the result of `composeNode`.\n        }\n\n      } else if (detected) {\n        throwError(state, 'can not read a block mapping entry; a multiline key may not be an implicit key');\n\n      } else {\n        state.tag = _tag;\n        state.anchor = _anchor;\n        return true; // Keep the result of `composeNode`.\n      }\n    }\n\n    //\n    // Common reading code for both explicit and implicit notations.\n    //\n    if (state.line === _line || state.lineIndent > nodeIndent) {\n      if (atExplicitKey) {\n        _keyLine = state.line;\n        _keyLineStart = state.lineStart;\n        _keyPos = state.position;\n      }\n\n      if (composeNode(state, nodeIndent, CONTEXT_BLOCK_OUT, true, allowCompact)) {\n        if (atExplicitKey) {\n          keyNode = state.result;\n        } else {\n          valueNode = state.result;\n        }\n      }\n\n      if (!atExplicitKey) {\n        storeMappingPair(state, _result, overridableKeys, keyTag, keyNode, valueNode, _keyLine, _keyLineStart, _keyPos);\n        keyTag = keyNode = valueNode = null;\n      }\n\n      skipSeparationSpace(state, true, -1);\n      ch = state.input.charCodeAt(state.position);\n    }\n\n    if ((state.line === _line || state.lineIndent > nodeIndent) && (ch !== 0)) {\n      throwError(state, 'bad indentation of a mapping entry');\n    } else if (state.lineIndent < nodeIndent) {\n      break;\n    }\n  }\n\n  //\n  // Epilogue.\n  //\n\n  // Special case: last mapping's node contains only the key in explicit notation.\n  if (atExplicitKey) {\n    storeMappingPair(state, _result, overridableKeys, keyTag, keyNode, null, _keyLine, _keyLineStart, _keyPos);\n  }\n\n  // Expose the resulting mapping.\n  if (detected) {\n    state.tag = _tag;\n    state.anchor = _anchor;\n    state.kind = 'mapping';\n    state.result = _result;\n  }\n\n  return detected;\n}\n\nfunction readTagProperty(state) {\n  var _position,\n      isVerbatim = false,\n      isNamed    = false,\n      tagHandle,\n      tagName,\n      ch;\n\n  ch = state.input.charCodeAt(state.position);\n\n  if (ch !== 0x21/* ! */) return false;\n\n  if (state.tag !== null) {\n    throwError(state, 'duplication of a tag property');\n  }\n\n  ch = state.input.charCodeAt(++state.position);\n\n  if (ch === 0x3C/* < */) {\n    isVerbatim = true;\n    ch = state.input.charCodeAt(++state.position);\n\n  } else if (ch === 0x21/* ! */) {\n    isNamed = true;\n    tagHandle = '!!';\n    ch = state.input.charCodeAt(++state.position);\n\n  } else {\n    tagHandle = '!';\n  }\n\n  _position = state.position;\n\n  if (isVerbatim) {\n    do { ch = state.input.charCodeAt(++state.position); }\n    while (ch !== 0 && ch !== 0x3E/* > */);\n\n    if (state.position < state.length) {\n      tagName = state.input.slice(_position, state.position);\n      ch = state.input.charCodeAt(++state.position);\n    } else {\n      throwError(state, 'unexpected end of the stream within a verbatim tag');\n    }\n  } else {\n    while (ch !== 0 && !is_WS_OR_EOL(ch)) {\n\n      if (ch === 0x21/* ! */) {\n        if (!isNamed) {\n          tagHandle = state.input.slice(_position - 1, state.position + 1);\n\n          if (!PATTERN_TAG_HANDLE.test(tagHandle)) {\n            throwError(state, 'named tag handle cannot contain such characters');\n          }\n\n          isNamed = true;\n          _position = state.position + 1;\n        } else {\n          throwError(state, 'tag suffix cannot contain exclamation marks');\n        }\n      }\n\n      ch = state.input.charCodeAt(++state.position);\n    }\n\n    tagName = state.input.slice(_position, state.position);\n\n    if (PATTERN_FLOW_INDICATORS.test(tagName)) {\n      throwError(state, 'tag suffix cannot contain flow indicator characters');\n    }\n  }\n\n  if (tagName && !PATTERN_TAG_URI.test(tagName)) {\n    throwError(state, 'tag name cannot contain such characters: ' + tagName);\n  }\n\n  try {\n    tagName = decodeURIComponent(tagName);\n  } catch (err) {\n    throwError(state, 'tag name is malformed: ' + tagName);\n  }\n\n  if (isVerbatim) {\n    state.tag = tagName;\n\n  } else if (_hasOwnProperty.call(state.tagMap, tagHandle)) {\n    state.tag = state.tagMap[tagHandle] + tagName;\n\n  } else if (tagHandle === '!') {\n    state.tag = '!' + tagName;\n\n  } else if (tagHandle === '!!') {\n    state.tag = 'tag:yaml.org,2002:' + tagName;\n\n  } else {\n    throwError(state, 'undeclared tag handle \"' + tagHandle + '\"');\n  }\n\n  return true;\n}\n\nfunction readAnchorProperty(state) {\n  var _position,\n      ch;\n\n  ch = state.input.charCodeAt(state.position);\n\n  if (ch !== 0x26/* & */) return false;\n\n  if (state.anchor !== null) {\n    throwError(state, 'duplication of an anchor property');\n  }\n\n  ch = state.input.charCodeAt(++state.position);\n  _position = state.position;\n\n  while (ch !== 0 && !is_WS_OR_EOL(ch) && !is_FLOW_INDICATOR(ch)) {\n    ch = state.input.charCodeAt(++state.position);\n  }\n\n  if (state.position === _position) {\n    throwError(state, 'name of an anchor node must contain at least one character');\n  }\n\n  state.anchor = state.input.slice(_position, state.position);\n  return true;\n}\n\nfunction readAlias(state) {\n  var _position, alias,\n      ch;\n\n  ch = state.input.charCodeAt(state.position);\n\n  if (ch !== 0x2A/* * */) return false;\n\n  ch = state.input.charCodeAt(++state.position);\n  _position = state.position;\n\n  while (ch !== 0 && !is_WS_OR_EOL(ch) && !is_FLOW_INDICATOR(ch)) {\n    ch = state.input.charCodeAt(++state.position);\n  }\n\n  if (state.position === _position) {\n    throwError(state, 'name of an alias node must contain at least one character');\n  }\n\n  alias = state.input.slice(_position, state.position);\n\n  if (!_hasOwnProperty.call(state.anchorMap, alias)) {\n    throwError(state, 'unidentified alias \"' + alias + '\"');\n  }\n\n  state.result = state.anchorMap[alias];\n  skipSeparationSpace(state, true, -1);\n  return true;\n}\n\nfunction composeNode(state, parentIndent, nodeContext, allowToSeek, allowCompact) {\n  var allowBlockStyles,\n      allowBlockScalars,\n      allowBlockCollections,\n      indentStatus = 1, // 1: this>parent, 0: this=parent, -1: this<parent\n      atNewLine  = false,\n      hasContent = false,\n      typeIndex,\n      typeQuantity,\n      typeList,\n      type,\n      flowIndent,\n      blockIndent;\n\n  if (state.listener !== null) {\n    state.listener('open', state);\n  }\n\n  state.tag    = null;\n  state.anchor = null;\n  state.kind   = null;\n  state.result = null;\n\n  allowBlockStyles = allowBlockScalars = allowBlockCollections =\n    CONTEXT_BLOCK_OUT === nodeContext ||\n    CONTEXT_BLOCK_IN  === nodeContext;\n\n  if (allowToSeek) {\n    if (skipSeparationSpace(state, true, -1)) {\n      atNewLine = true;\n\n      if (state.lineIndent > parentIndent) {\n        indentStatus = 1;\n      } else if (state.lineIndent === parentIndent) {\n        indentStatus = 0;\n      } else if (state.lineIndent < parentIndent) {\n        indentStatus = -1;\n      }\n    }\n  }\n\n  if (indentStatus === 1) {\n    while (readTagProperty(state) || readAnchorProperty(state)) {\n      if (skipSeparationSpace(state, true, -1)) {\n        atNewLine = true;\n        allowBlockCollections = allowBlockStyles;\n\n        if (state.lineIndent > parentIndent) {\n          indentStatus = 1;\n        } else if (state.lineIndent === parentIndent) {\n          indentStatus = 0;\n        } else if (state.lineIndent < parentIndent) {\n          indentStatus = -1;\n        }\n      } else {\n        allowBlockCollections = false;\n      }\n    }\n  }\n\n  if (allowBlockCollections) {\n    allowBlockCollections = atNewLine || allowCompact;\n  }\n\n  if (indentStatus === 1 || CONTEXT_BLOCK_OUT === nodeContext) {\n    if (CONTEXT_FLOW_IN === nodeContext || CONTEXT_FLOW_OUT === nodeContext) {\n      flowIndent = parentIndent;\n    } else {\n      flowIndent = parentIndent + 1;\n    }\n\n    blockIndent = state.position - state.lineStart;\n\n    if (indentStatus === 1) {\n      if (allowBlockCollections &&\n          (readBlockSequence(state, blockIndent) ||\n           readBlockMapping(state, blockIndent, flowIndent)) ||\n          readFlowCollection(state, flowIndent)) {\n        hasContent = true;\n      } else {\n        if ((allowBlockScalars && readBlockScalar(state, flowIndent)) ||\n            readSingleQuotedScalar(state, flowIndent) ||\n            readDoubleQuotedScalar(state, flowIndent)) {\n          hasContent = true;\n\n        } else if (readAlias(state)) {\n          hasContent = true;\n\n          if (state.tag !== null || state.anchor !== null) {\n            throwError(state, 'alias node should not have any properties');\n          }\n\n        } else if (readPlainScalar(state, flowIndent, CONTEXT_FLOW_IN === nodeContext)) {\n          hasContent = true;\n\n          if (state.tag === null) {\n            state.tag = '?';\n          }\n        }\n\n        if (state.anchor !== null) {\n          state.anchorMap[state.anchor] = state.result;\n        }\n      }\n    } else if (indentStatus === 0) {\n      // Special case: block sequences are allowed to have same indentation level as the parent.\n      // http://www.yaml.org/spec/1.2/spec.html#id2799784\n      hasContent = allowBlockCollections && readBlockSequence(state, blockIndent);\n    }\n  }\n\n  if (state.tag === null) {\n    if (state.anchor !== null) {\n      state.anchorMap[state.anchor] = state.result;\n    }\n\n  } else if (state.tag === '?') {\n    // Implicit resolving is not allowed for non-scalar types, and '?'\n    // non-specific tag is only automatically assigned to plain scalars.\n    //\n    // We only need to check kind conformity in case user explicitly assigns '?'\n    // tag, for example like this: \"!<?> [0]\"\n    //\n    if (state.result !== null && state.kind !== 'scalar') {\n      throwError(state, 'unacceptable node kind for !<?> tag; it should be \"scalar\", not \"' + state.kind + '\"');\n    }\n\n    for (typeIndex = 0, typeQuantity = state.implicitTypes.length; typeIndex < typeQuantity; typeIndex += 1) {\n      type = state.implicitTypes[typeIndex];\n\n      if (type.resolve(state.result)) { // `state.result` updated in resolver if matched\n        state.result = type.construct(state.result);\n        state.tag = type.tag;\n        if (state.anchor !== null) {\n          state.anchorMap[state.anchor] = state.result;\n        }\n        break;\n      }\n    }\n  } else if (state.tag !== '!') {\n    if (_hasOwnProperty.call(state.typeMap[state.kind || 'fallback'], state.tag)) {\n      type = state.typeMap[state.kind || 'fallback'][state.tag];\n    } else {\n      // looking for multi type\n      type = null;\n      typeList = state.typeMap.multi[state.kind || 'fallback'];\n\n      for (typeIndex = 0, typeQuantity = typeList.length; typeIndex < typeQuantity; typeIndex += 1) {\n        if (state.tag.slice(0, typeList[typeIndex].tag.length) === typeList[typeIndex].tag) {\n          type = typeList[typeIndex];\n          break;\n        }\n      }\n    }\n\n    if (!type) {\n      throwError(state, 'unknown tag !<' + state.tag + '>');\n    }\n\n    if (state.result !== null && type.kind !== state.kind) {\n      throwError(state, 'unacceptable node kind for !<' + state.tag + '> tag; it should be \"' + type.kind + '\", not \"' + state.kind + '\"');\n    }\n\n    if (!type.resolve(state.result, state.tag)) { // `state.result` updated in resolver if matched\n      throwError(state, 'cannot resolve a node with !<' + state.tag + '> explicit tag');\n    } else {\n      state.result = type.construct(state.result, state.tag);\n      if (state.anchor !== null) {\n        state.anchorMap[state.anchor] = state.result;\n      }\n    }\n  }\n\n  if (state.listener !== null) {\n    state.listener('close', state);\n  }\n  return state.tag !== null ||  state.anchor !== null || hasContent;\n}\n\nfunction readDocument(state) {\n  var documentStart = state.position,\n      _position,\n      directiveName,\n      directiveArgs,\n      hasDirectives = false,\n      ch;\n\n  state.version = null;\n  state.checkLineBreaks = state.legacy;\n  state.tagMap = Object.create(null);\n  state.anchorMap = Object.create(null);\n\n  while ((ch = state.input.charCodeAt(state.position)) !== 0) {\n    skipSeparationSpace(state, true, -1);\n\n    ch = state.input.charCodeAt(state.position);\n\n    if (state.lineIndent > 0 || ch !== 0x25/* % */) {\n      break;\n    }\n\n    hasDirectives = true;\n    ch = state.input.charCodeAt(++state.position);\n    _position = state.position;\n\n    while (ch !== 0 && !is_WS_OR_EOL(ch)) {\n      ch = state.input.charCodeAt(++state.position);\n    }\n\n    directiveName = state.input.slice(_position, state.position);\n    directiveArgs = [];\n\n    if (directiveName.length < 1) {\n      throwError(state, 'directive name must not be less than one character in length');\n    }\n\n    while (ch !== 0) {\n      while (is_WHITE_SPACE(ch)) {\n        ch = state.input.charCodeAt(++state.position);\n      }\n\n      if (ch === 0x23/* # */) {\n        do { ch = state.input.charCodeAt(++state.position); }\n        while (ch !== 0 && !is_EOL(ch));\n        break;\n      }\n\n      if (is_EOL(ch)) break;\n\n      _position = state.position;\n\n      while (ch !== 0 && !is_WS_OR_EOL(ch)) {\n        ch = state.input.charCodeAt(++state.position);\n      }\n\n      directiveArgs.push(state.input.slice(_position, state.position));\n    }\n\n    if (ch !== 0) readLineBreak(state);\n\n    if (_hasOwnProperty.call(directiveHandlers, directiveName)) {\n      directiveHandlers[directiveName](state, directiveName, directiveArgs);\n    } else {\n      throwWarning(state, 'unknown document directive \"' + directiveName + '\"');\n    }\n  }\n\n  skipSeparationSpace(state, true, -1);\n\n  if (state.lineIndent === 0 &&\n      state.input.charCodeAt(state.position)     === 0x2D/* - */ &&\n      state.input.charCodeAt(state.position + 1) === 0x2D/* - */ &&\n      state.input.charCodeAt(state.position + 2) === 0x2D/* - */) {\n    state.position += 3;\n    skipSeparationSpace(state, true, -1);\n\n  } else if (hasDirectives) {\n    throwError(state, 'directives end mark is expected');\n  }\n\n  composeNode(state, state.lineIndent - 1, CONTEXT_BLOCK_OUT, false, true);\n  skipSeparationSpace(state, true, -1);\n\n  if (state.checkLineBreaks &&\n      PATTERN_NON_ASCII_LINE_BREAKS.test(state.input.slice(documentStart, state.position))) {\n    throwWarning(state, 'non-ASCII line breaks are interpreted as content');\n  }\n\n  state.documents.push(state.result);\n\n  if (state.position === state.lineStart && testDocumentSeparator(state)) {\n\n    if (state.input.charCodeAt(state.position) === 0x2E/* . */) {\n      state.position += 3;\n      skipSeparationSpace(state, true, -1);\n    }\n    return;\n  }\n\n  if (state.position < (state.length - 1)) {\n    throwError(state, 'end of the stream or a document separator is expected');\n  } else {\n    return;\n  }\n}\n\n\nfunction loadDocuments(input, options) {\n  input = String(input);\n  options = options || {};\n\n  if (input.length !== 0) {\n\n    // Add tailing `\\n` if not exists\n    if (input.charCodeAt(input.length - 1) !== 0x0A/* LF */ &&\n        input.charCodeAt(input.length - 1) !== 0x0D/* CR */) {\n      input += '\\n';\n    }\n\n    // Strip BOM\n    if (input.charCodeAt(0) === 0xFEFF) {\n      input = input.slice(1);\n    }\n  }\n\n  var state = new State(input, options);\n\n  var nullpos = input.indexOf('\\0');\n\n  if (nullpos !== -1) {\n    state.position = nullpos;\n    throwError(state, 'null byte is not allowed in input');\n  }\n\n  // Use 0 as string terminator. That significantly simplifies bounds check.\n  state.input += '\\0';\n\n  while (state.input.charCodeAt(state.position) === 0x20/* Space */) {\n    state.lineIndent += 1;\n    state.position += 1;\n  }\n\n  while (state.position < (state.length - 1)) {\n    readDocument(state);\n  }\n\n  return state.documents;\n}\n\n\nfunction loadAll(input, iterator, options) {\n  if (iterator !== null && typeof iterator === 'object' && typeof options === 'undefined') {\n    options = iterator;\n    iterator = null;\n  }\n\n  var documents = loadDocuments(input, options);\n\n  if (typeof iterator !== 'function') {\n    return documents;\n  }\n\n  for (var index = 0, length = documents.length; index < length; index += 1) {\n    iterator(documents[index]);\n  }\n}\n\n\nfunction load(input, options) {\n  var documents = loadDocuments(input, options);\n\n  if (documents.length === 0) {\n    /*eslint-disable no-undefined*/\n    return undefined;\n  } else if (documents.length === 1) {\n    return documents[0];\n  }\n  throw new YAMLException('expected a single document in the stream, but found more');\n}\n\n\nmodule.exports.loadAll = loadAll;\nmodule.exports.load    = load;\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/lib/loader.js?");

/***/ }),

/***/ "./node_modules/js-yaml/lib/schema.js":
/*!********************************************!*\
  !*** ./node_modules/js-yaml/lib/schema.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*eslint-disable max-len*/\n\nvar YAMLException = __webpack_require__(/*! ./exception */ \"./node_modules/js-yaml/lib/exception.js\");\nvar Type          = __webpack_require__(/*! ./type */ \"./node_modules/js-yaml/lib/type.js\");\n\n\nfunction compileList(schema, name) {\n  var result = [];\n\n  schema[name].forEach(function (currentType) {\n    var newIndex = result.length;\n\n    result.forEach(function (previousType, previousIndex) {\n      if (previousType.tag === currentType.tag &&\n          previousType.kind === currentType.kind &&\n          previousType.multi === currentType.multi) {\n\n        newIndex = previousIndex;\n      }\n    });\n\n    result[newIndex] = currentType;\n  });\n\n  return result;\n}\n\n\nfunction compileMap(/* lists... */) {\n  var result = {\n        scalar: {},\n        sequence: {},\n        mapping: {},\n        fallback: {},\n        multi: {\n          scalar: [],\n          sequence: [],\n          mapping: [],\n          fallback: []\n        }\n      }, index, length;\n\n  function collectType(type) {\n    if (type.multi) {\n      result.multi[type.kind].push(type);\n      result.multi['fallback'].push(type);\n    } else {\n      result[type.kind][type.tag] = result['fallback'][type.tag] = type;\n    }\n  }\n\n  for (index = 0, length = arguments.length; index < length; index += 1) {\n    arguments[index].forEach(collectType);\n  }\n  return result;\n}\n\n\nfunction Schema(definition) {\n  return this.extend(definition);\n}\n\n\nSchema.prototype.extend = function extend(definition) {\n  var implicit = [];\n  var explicit = [];\n\n  if (definition instanceof Type) {\n    // Schema.extend(type)\n    explicit.push(definition);\n\n  } else if (Array.isArray(definition)) {\n    // Schema.extend([ type1, type2, ... ])\n    explicit = explicit.concat(definition);\n\n  } else if (definition && (Array.isArray(definition.implicit) || Array.isArray(definition.explicit))) {\n    // Schema.extend({ explicit: [ type1, type2, ... ], implicit: [ type1, type2, ... ] })\n    if (definition.implicit) implicit = implicit.concat(definition.implicit);\n    if (definition.explicit) explicit = explicit.concat(definition.explicit);\n\n  } else {\n    throw new YAMLException('Schema.extend argument should be a Type, [ Type ], ' +\n      'or a schema definition ({ implicit: [...], explicit: [...] })');\n  }\n\n  implicit.forEach(function (type) {\n    if (!(type instanceof Type)) {\n      throw new YAMLException('Specified list of YAML types (or a single Type object) contains a non-Type object.');\n    }\n\n    if (type.loadKind && type.loadKind !== 'scalar') {\n      throw new YAMLException('There is a non-scalar type in the implicit list of a schema. Implicit resolving of such types is not supported.');\n    }\n\n    if (type.multi) {\n      throw new YAMLException('There is a multi type in the implicit list of a schema. Multi tags can only be listed as explicit.');\n    }\n  });\n\n  explicit.forEach(function (type) {\n    if (!(type instanceof Type)) {\n      throw new YAMLException('Specified list of YAML types (or a single Type object) contains a non-Type object.');\n    }\n  });\n\n  var result = Object.create(Schema.prototype);\n\n  result.implicit = (this.implicit || []).concat(implicit);\n  result.explicit = (this.explicit || []).concat(explicit);\n\n  result.compiledImplicit = compileList(result, 'implicit');\n  result.compiledExplicit = compileList(result, 'explicit');\n  result.compiledTypeMap  = compileMap(result.compiledImplicit, result.compiledExplicit);\n\n  return result;\n};\n\n\nmodule.exports = Schema;\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/lib/schema.js?");

/***/ }),

/***/ "./node_modules/js-yaml/lib/schema/core.js":
/*!*************************************************!*\
  !*** ./node_modules/js-yaml/lib/schema/core.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Standard YAML's Core schema.\n// http://www.yaml.org/spec/1.2/spec.html#id2804923\n//\n// NOTE: JS-YAML does not support schema-specific tag resolution restrictions.\n// So, Core schema has no distinctions from JSON schema is JS-YAML.\n\n\n\n\n\nmodule.exports = __webpack_require__(/*! ./json */ \"./node_modules/js-yaml/lib/schema/json.js\");\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/lib/schema/core.js?");

/***/ }),

/***/ "./node_modules/js-yaml/lib/schema/default.js":
/*!****************************************************!*\
  !*** ./node_modules/js-yaml/lib/schema/default.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// JS-YAML's default schema for `safeLoad` function.\n// It is not described in the YAML specification.\n//\n// This schema is based on standard YAML's Core schema and includes most of\n// extra types described at YAML tag repository. (http://yaml.org/type/)\n\n\n\n\n\nmodule.exports = (__webpack_require__(/*! ./core */ \"./node_modules/js-yaml/lib/schema/core.js\").extend)({\n  implicit: [\n    __webpack_require__(/*! ../type/timestamp */ \"./node_modules/js-yaml/lib/type/timestamp.js\"),\n    __webpack_require__(/*! ../type/merge */ \"./node_modules/js-yaml/lib/type/merge.js\")\n  ],\n  explicit: [\n    __webpack_require__(/*! ../type/binary */ \"./node_modules/js-yaml/lib/type/binary.js\"),\n    __webpack_require__(/*! ../type/omap */ \"./node_modules/js-yaml/lib/type/omap.js\"),\n    __webpack_require__(/*! ../type/pairs */ \"./node_modules/js-yaml/lib/type/pairs.js\"),\n    __webpack_require__(/*! ../type/set */ \"./node_modules/js-yaml/lib/type/set.js\")\n  ]\n});\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/lib/schema/default.js?");

/***/ }),

/***/ "./node_modules/js-yaml/lib/schema/failsafe.js":
/*!*****************************************************!*\
  !*** ./node_modules/js-yaml/lib/schema/failsafe.js ***!
  \*****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Standard YAML's Failsafe schema.\n// http://www.yaml.org/spec/1.2/spec.html#id2802346\n\n\n\n\n\nvar Schema = __webpack_require__(/*! ../schema */ \"./node_modules/js-yaml/lib/schema.js\");\n\n\nmodule.exports = new Schema({\n  explicit: [\n    __webpack_require__(/*! ../type/str */ \"./node_modules/js-yaml/lib/type/str.js\"),\n    __webpack_require__(/*! ../type/seq */ \"./node_modules/js-yaml/lib/type/seq.js\"),\n    __webpack_require__(/*! ../type/map */ \"./node_modules/js-yaml/lib/type/map.js\")\n  ]\n});\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/lib/schema/failsafe.js?");

/***/ }),

/***/ "./node_modules/js-yaml/lib/schema/json.js":
/*!*************************************************!*\
  !*** ./node_modules/js-yaml/lib/schema/json.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Standard YAML's JSON schema.\n// http://www.yaml.org/spec/1.2/spec.html#id2803231\n//\n// NOTE: JS-YAML does not support schema-specific tag resolution restrictions.\n// So, this schema is not such strict as defined in the YAML specification.\n// It allows numbers in binary notaion, use `Null` and `NULL` as `null`, etc.\n\n\n\n\n\nmodule.exports = (__webpack_require__(/*! ./failsafe */ \"./node_modules/js-yaml/lib/schema/failsafe.js\").extend)({\n  implicit: [\n    __webpack_require__(/*! ../type/null */ \"./node_modules/js-yaml/lib/type/null.js\"),\n    __webpack_require__(/*! ../type/bool */ \"./node_modules/js-yaml/lib/type/bool.js\"),\n    __webpack_require__(/*! ../type/int */ \"./node_modules/js-yaml/lib/type/int.js\"),\n    __webpack_require__(/*! ../type/float */ \"./node_modules/js-yaml/lib/type/float.js\")\n  ]\n});\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/lib/schema/json.js?");

/***/ }),

/***/ "./node_modules/js-yaml/lib/snippet.js":
/*!*********************************************!*\
  !*** ./node_modules/js-yaml/lib/snippet.js ***!
  \*********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n\nvar common = __webpack_require__(/*! ./common */ \"./node_modules/js-yaml/lib/common.js\");\n\n\n// get snippet for a single line, respecting maxLength\nfunction getLine(buffer, lineStart, lineEnd, position, maxLineLength) {\n  var head = '';\n  var tail = '';\n  var maxHalfLength = Math.floor(maxLineLength / 2) - 1;\n\n  if (position - lineStart > maxHalfLength) {\n    head = ' ... ';\n    lineStart = position - maxHalfLength + head.length;\n  }\n\n  if (lineEnd - position > maxHalfLength) {\n    tail = ' ...';\n    lineEnd = position + maxHalfLength - tail.length;\n  }\n\n  return {\n    str: head + buffer.slice(lineStart, lineEnd).replace(/\\t/g, '') + tail,\n    pos: position - lineStart + head.length // relative position\n  };\n}\n\n\nfunction padStart(string, max) {\n  return common.repeat(' ', max - string.length) + string;\n}\n\n\nfunction makeSnippet(mark, options) {\n  options = Object.create(options || null);\n\n  if (!mark.buffer) return null;\n\n  if (!options.maxLength) options.maxLength = 79;\n  if (typeof options.indent      !== 'number') options.indent      = 1;\n  if (typeof options.linesBefore !== 'number') options.linesBefore = 3;\n  if (typeof options.linesAfter  !== 'number') options.linesAfter  = 2;\n\n  var re = /\\r?\\n|\\r|\\0/g;\n  var lineStarts = [ 0 ];\n  var lineEnds = [];\n  var match;\n  var foundLineNo = -1;\n\n  while ((match = re.exec(mark.buffer))) {\n    lineEnds.push(match.index);\n    lineStarts.push(match.index + match[0].length);\n\n    if (mark.position <= match.index && foundLineNo < 0) {\n      foundLineNo = lineStarts.length - 2;\n    }\n  }\n\n  if (foundLineNo < 0) foundLineNo = lineStarts.length - 1;\n\n  var result = '', i, line;\n  var lineNoLength = Math.min(mark.line + options.linesAfter, lineEnds.length).toString().length;\n  var maxLineLength = options.maxLength - (options.indent + lineNoLength + 3);\n\n  for (i = 1; i <= options.linesBefore; i++) {\n    if (foundLineNo - i < 0) break;\n    line = getLine(\n      mark.buffer,\n      lineStarts[foundLineNo - i],\n      lineEnds[foundLineNo - i],\n      mark.position - (lineStarts[foundLineNo] - lineStarts[foundLineNo - i]),\n      maxLineLength\n    );\n    result = common.repeat(' ', options.indent) + padStart((mark.line - i + 1).toString(), lineNoLength) +\n      ' | ' + line.str + '\\n' + result;\n  }\n\n  line = getLine(mark.buffer, lineStarts[foundLineNo], lineEnds[foundLineNo], mark.position, maxLineLength);\n  result += common.repeat(' ', options.indent) + padStart((mark.line + 1).toString(), lineNoLength) +\n    ' | ' + line.str + '\\n';\n  result += common.repeat('-', options.indent + lineNoLength + 3 + line.pos) + '^' + '\\n';\n\n  for (i = 1; i <= options.linesAfter; i++) {\n    if (foundLineNo + i >= lineEnds.length) break;\n    line = getLine(\n      mark.buffer,\n      lineStarts[foundLineNo + i],\n      lineEnds[foundLineNo + i],\n      mark.position - (lineStarts[foundLineNo] - lineStarts[foundLineNo + i]),\n      maxLineLength\n    );\n    result += common.repeat(' ', options.indent) + padStart((mark.line + i + 1).toString(), lineNoLength) +\n      ' | ' + line.str + '\\n';\n  }\n\n  return result.replace(/\\n$/, '');\n}\n\n\nmodule.exports = makeSnippet;\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/lib/snippet.js?");

/***/ }),

/***/ "./node_modules/js-yaml/lib/type.js":
/*!******************************************!*\
  !*** ./node_modules/js-yaml/lib/type.js ***!
  \******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar YAMLException = __webpack_require__(/*! ./exception */ \"./node_modules/js-yaml/lib/exception.js\");\n\nvar TYPE_CONSTRUCTOR_OPTIONS = [\n  'kind',\n  'multi',\n  'resolve',\n  'construct',\n  'instanceOf',\n  'predicate',\n  'represent',\n  'representName',\n  'defaultStyle',\n  'styleAliases'\n];\n\nvar YAML_NODE_KINDS = [\n  'scalar',\n  'sequence',\n  'mapping'\n];\n\nfunction compileStyleAliases(map) {\n  var result = {};\n\n  if (map !== null) {\n    Object.keys(map).forEach(function (style) {\n      map[style].forEach(function (alias) {\n        result[String(alias)] = style;\n      });\n    });\n  }\n\n  return result;\n}\n\nfunction Type(tag, options) {\n  options = options || {};\n\n  Object.keys(options).forEach(function (name) {\n    if (TYPE_CONSTRUCTOR_OPTIONS.indexOf(name) === -1) {\n      throw new YAMLException('Unknown option \"' + name + '\" is met in definition of \"' + tag + '\" YAML type.');\n    }\n  });\n\n  // TODO: Add tag format check.\n  this.options       = options; // keep original options in case user wants to extend this type later\n  this.tag           = tag;\n  this.kind          = options['kind']          || null;\n  this.resolve       = options['resolve']       || function () { return true; };\n  this.construct     = options['construct']     || function (data) { return data; };\n  this.instanceOf    = options['instanceOf']    || null;\n  this.predicate     = options['predicate']     || null;\n  this.represent     = options['represent']     || null;\n  this.representName = options['representName'] || null;\n  this.defaultStyle  = options['defaultStyle']  || null;\n  this.multi         = options['multi']         || false;\n  this.styleAliases  = compileStyleAliases(options['styleAliases'] || null);\n\n  if (YAML_NODE_KINDS.indexOf(this.kind) === -1) {\n    throw new YAMLException('Unknown kind \"' + this.kind + '\" is specified for \"' + tag + '\" YAML type.');\n  }\n}\n\nmodule.exports = Type;\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/lib/type.js?");

/***/ }),

/***/ "./node_modules/js-yaml/lib/type/binary.js":
/*!*************************************************!*\
  !*** ./node_modules/js-yaml/lib/type/binary.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*eslint-disable no-bitwise*/\n\n\nvar Type = __webpack_require__(/*! ../type */ \"./node_modules/js-yaml/lib/type.js\");\n\n\n// [ 64, 65, 66 ] -> [ padding, CR, LF ]\nvar BASE64_MAP = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=\\n\\r';\n\n\nfunction resolveYamlBinary(data) {\n  if (data === null) return false;\n\n  var code, idx, bitlen = 0, max = data.length, map = BASE64_MAP;\n\n  // Convert one by one.\n  for (idx = 0; idx < max; idx++) {\n    code = map.indexOf(data.charAt(idx));\n\n    // Skip CR/LF\n    if (code > 64) continue;\n\n    // Fail on illegal characters\n    if (code < 0) return false;\n\n    bitlen += 6;\n  }\n\n  // If there are any bits left, source was corrupted\n  return (bitlen % 8) === 0;\n}\n\nfunction constructYamlBinary(data) {\n  var idx, tailbits,\n      input = data.replace(/[\\r\\n=]/g, ''), // remove CR/LF & padding to simplify scan\n      max = input.length,\n      map = BASE64_MAP,\n      bits = 0,\n      result = [];\n\n  // Collect by 6*4 bits (3 bytes)\n\n  for (idx = 0; idx < max; idx++) {\n    if ((idx % 4 === 0) && idx) {\n      result.push((bits >> 16) & 0xFF);\n      result.push((bits >> 8) & 0xFF);\n      result.push(bits & 0xFF);\n    }\n\n    bits = (bits << 6) | map.indexOf(input.charAt(idx));\n  }\n\n  // Dump tail\n\n  tailbits = (max % 4) * 6;\n\n  if (tailbits === 0) {\n    result.push((bits >> 16) & 0xFF);\n    result.push((bits >> 8) & 0xFF);\n    result.push(bits & 0xFF);\n  } else if (tailbits === 18) {\n    result.push((bits >> 10) & 0xFF);\n    result.push((bits >> 2) & 0xFF);\n  } else if (tailbits === 12) {\n    result.push((bits >> 4) & 0xFF);\n  }\n\n  return new Uint8Array(result);\n}\n\nfunction representYamlBinary(object /*, style*/) {\n  var result = '', bits = 0, idx, tail,\n      max = object.length,\n      map = BASE64_MAP;\n\n  // Convert every three bytes to 4 ASCII characters.\n\n  for (idx = 0; idx < max; idx++) {\n    if ((idx % 3 === 0) && idx) {\n      result += map[(bits >> 18) & 0x3F];\n      result += map[(bits >> 12) & 0x3F];\n      result += map[(bits >> 6) & 0x3F];\n      result += map[bits & 0x3F];\n    }\n\n    bits = (bits << 8) + object[idx];\n  }\n\n  // Dump tail\n\n  tail = max % 3;\n\n  if (tail === 0) {\n    result += map[(bits >> 18) & 0x3F];\n    result += map[(bits >> 12) & 0x3F];\n    result += map[(bits >> 6) & 0x3F];\n    result += map[bits & 0x3F];\n  } else if (tail === 2) {\n    result += map[(bits >> 10) & 0x3F];\n    result += map[(bits >> 4) & 0x3F];\n    result += map[(bits << 2) & 0x3F];\n    result += map[64];\n  } else if (tail === 1) {\n    result += map[(bits >> 2) & 0x3F];\n    result += map[(bits << 4) & 0x3F];\n    result += map[64];\n    result += map[64];\n  }\n\n  return result;\n}\n\nfunction isBinary(obj) {\n  return Object.prototype.toString.call(obj) ===  '[object Uint8Array]';\n}\n\nmodule.exports = new Type('tag:yaml.org,2002:binary', {\n  kind: 'scalar',\n  resolve: resolveYamlBinary,\n  construct: constructYamlBinary,\n  predicate: isBinary,\n  represent: representYamlBinary\n});\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/lib/type/binary.js?");

/***/ }),

/***/ "./node_modules/js-yaml/lib/type/bool.js":
/*!***********************************************!*\
  !*** ./node_modules/js-yaml/lib/type/bool.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar Type = __webpack_require__(/*! ../type */ \"./node_modules/js-yaml/lib/type.js\");\n\nfunction resolveYamlBoolean(data) {\n  if (data === null) return false;\n\n  var max = data.length;\n\n  return (max === 4 && (data === 'true' || data === 'True' || data === 'TRUE')) ||\n         (max === 5 && (data === 'false' || data === 'False' || data === 'FALSE'));\n}\n\nfunction constructYamlBoolean(data) {\n  return data === 'true' ||\n         data === 'True' ||\n         data === 'TRUE';\n}\n\nfunction isBoolean(object) {\n  return Object.prototype.toString.call(object) === '[object Boolean]';\n}\n\nmodule.exports = new Type('tag:yaml.org,2002:bool', {\n  kind: 'scalar',\n  resolve: resolveYamlBoolean,\n  construct: constructYamlBoolean,\n  predicate: isBoolean,\n  represent: {\n    lowercase: function (object) { return object ? 'true' : 'false'; },\n    uppercase: function (object) { return object ? 'TRUE' : 'FALSE'; },\n    camelcase: function (object) { return object ? 'True' : 'False'; }\n  },\n  defaultStyle: 'lowercase'\n});\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/lib/type/bool.js?");

/***/ }),

/***/ "./node_modules/js-yaml/lib/type/float.js":
/*!************************************************!*\
  !*** ./node_modules/js-yaml/lib/type/float.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar common = __webpack_require__(/*! ../common */ \"./node_modules/js-yaml/lib/common.js\");\nvar Type   = __webpack_require__(/*! ../type */ \"./node_modules/js-yaml/lib/type.js\");\n\nvar YAML_FLOAT_PATTERN = new RegExp(\n  // 2.5e4, 2.5 and integers\n  '^(?:[-+]?(?:[0-9][0-9_]*)(?:\\\\.[0-9_]*)?(?:[eE][-+]?[0-9]+)?' +\n  // .2e4, .2\n  // special case, seems not from spec\n  '|\\\\.[0-9_]+(?:[eE][-+]?[0-9]+)?' +\n  // .inf\n  '|[-+]?\\\\.(?:inf|Inf|INF)' +\n  // .nan\n  '|\\\\.(?:nan|NaN|NAN))$');\n\nfunction resolveYamlFloat(data) {\n  if (data === null) return false;\n\n  if (!YAML_FLOAT_PATTERN.test(data) ||\n      // Quick hack to not allow integers end with `_`\n      // Probably should update regexp & check speed\n      data[data.length - 1] === '_') {\n    return false;\n  }\n\n  return true;\n}\n\nfunction constructYamlFloat(data) {\n  var value, sign;\n\n  value  = data.replace(/_/g, '').toLowerCase();\n  sign   = value[0] === '-' ? -1 : 1;\n\n  if ('+-'.indexOf(value[0]) >= 0) {\n    value = value.slice(1);\n  }\n\n  if (value === '.inf') {\n    return (sign === 1) ? Number.POSITIVE_INFINITY : Number.NEGATIVE_INFINITY;\n\n  } else if (value === '.nan') {\n    return NaN;\n  }\n  return sign * parseFloat(value, 10);\n}\n\n\nvar SCIENTIFIC_WITHOUT_DOT = /^[-+]?[0-9]+e/;\n\nfunction representYamlFloat(object, style) {\n  var res;\n\n  if (isNaN(object)) {\n    switch (style) {\n      case 'lowercase': return '.nan';\n      case 'uppercase': return '.NAN';\n      case 'camelcase': return '.NaN';\n    }\n  } else if (Number.POSITIVE_INFINITY === object) {\n    switch (style) {\n      case 'lowercase': return '.inf';\n      case 'uppercase': return '.INF';\n      case 'camelcase': return '.Inf';\n    }\n  } else if (Number.NEGATIVE_INFINITY === object) {\n    switch (style) {\n      case 'lowercase': return '-.inf';\n      case 'uppercase': return '-.INF';\n      case 'camelcase': return '-.Inf';\n    }\n  } else if (common.isNegativeZero(object)) {\n    return '-0.0';\n  }\n\n  res = object.toString(10);\n\n  // JS stringifier can build scientific format without dots: 5e-100,\n  // while YAML requres dot: 5.e-100. Fix it with simple hack\n\n  return SCIENTIFIC_WITHOUT_DOT.test(res) ? res.replace('e', '.e') : res;\n}\n\nfunction isFloat(object) {\n  return (Object.prototype.toString.call(object) === '[object Number]') &&\n         (object % 1 !== 0 || common.isNegativeZero(object));\n}\n\nmodule.exports = new Type('tag:yaml.org,2002:float', {\n  kind: 'scalar',\n  resolve: resolveYamlFloat,\n  construct: constructYamlFloat,\n  predicate: isFloat,\n  represent: representYamlFloat,\n  defaultStyle: 'lowercase'\n});\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/lib/type/float.js?");

/***/ }),

/***/ "./node_modules/js-yaml/lib/type/int.js":
/*!**********************************************!*\
  !*** ./node_modules/js-yaml/lib/type/int.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar common = __webpack_require__(/*! ../common */ \"./node_modules/js-yaml/lib/common.js\");\nvar Type   = __webpack_require__(/*! ../type */ \"./node_modules/js-yaml/lib/type.js\");\n\nfunction isHexCode(c) {\n  return ((0x30/* 0 */ <= c) && (c <= 0x39/* 9 */)) ||\n         ((0x41/* A */ <= c) && (c <= 0x46/* F */)) ||\n         ((0x61/* a */ <= c) && (c <= 0x66/* f */));\n}\n\nfunction isOctCode(c) {\n  return ((0x30/* 0 */ <= c) && (c <= 0x37/* 7 */));\n}\n\nfunction isDecCode(c) {\n  return ((0x30/* 0 */ <= c) && (c <= 0x39/* 9 */));\n}\n\nfunction resolveYamlInteger(data) {\n  if (data === null) return false;\n\n  var max = data.length,\n      index = 0,\n      hasDigits = false,\n      ch;\n\n  if (!max) return false;\n\n  ch = data[index];\n\n  // sign\n  if (ch === '-' || ch === '+') {\n    ch = data[++index];\n  }\n\n  if (ch === '0') {\n    // 0\n    if (index + 1 === max) return true;\n    ch = data[++index];\n\n    // base 2, base 8, base 16\n\n    if (ch === 'b') {\n      // base 2\n      index++;\n\n      for (; index < max; index++) {\n        ch = data[index];\n        if (ch === '_') continue;\n        if (ch !== '0' && ch !== '1') return false;\n        hasDigits = true;\n      }\n      return hasDigits && ch !== '_';\n    }\n\n\n    if (ch === 'x') {\n      // base 16\n      index++;\n\n      for (; index < max; index++) {\n        ch = data[index];\n        if (ch === '_') continue;\n        if (!isHexCode(data.charCodeAt(index))) return false;\n        hasDigits = true;\n      }\n      return hasDigits && ch !== '_';\n    }\n\n\n    if (ch === 'o') {\n      // base 8\n      index++;\n\n      for (; index < max; index++) {\n        ch = data[index];\n        if (ch === '_') continue;\n        if (!isOctCode(data.charCodeAt(index))) return false;\n        hasDigits = true;\n      }\n      return hasDigits && ch !== '_';\n    }\n  }\n\n  // base 10 (except 0)\n\n  // value should not start with `_`;\n  if (ch === '_') return false;\n\n  for (; index < max; index++) {\n    ch = data[index];\n    if (ch === '_') continue;\n    if (!isDecCode(data.charCodeAt(index))) {\n      return false;\n    }\n    hasDigits = true;\n  }\n\n  // Should have digits and should not end with `_`\n  if (!hasDigits || ch === '_') return false;\n\n  return true;\n}\n\nfunction constructYamlInteger(data) {\n  var value = data, sign = 1, ch;\n\n  if (value.indexOf('_') !== -1) {\n    value = value.replace(/_/g, '');\n  }\n\n  ch = value[0];\n\n  if (ch === '-' || ch === '+') {\n    if (ch === '-') sign = -1;\n    value = value.slice(1);\n    ch = value[0];\n  }\n\n  if (value === '0') return 0;\n\n  if (ch === '0') {\n    if (value[1] === 'b') return sign * parseInt(value.slice(2), 2);\n    if (value[1] === 'x') return sign * parseInt(value.slice(2), 16);\n    if (value[1] === 'o') return sign * parseInt(value.slice(2), 8);\n  }\n\n  return sign * parseInt(value, 10);\n}\n\nfunction isInteger(object) {\n  return (Object.prototype.toString.call(object)) === '[object Number]' &&\n         (object % 1 === 0 && !common.isNegativeZero(object));\n}\n\nmodule.exports = new Type('tag:yaml.org,2002:int', {\n  kind: 'scalar',\n  resolve: resolveYamlInteger,\n  construct: constructYamlInteger,\n  predicate: isInteger,\n  represent: {\n    binary:      function (obj) { return obj >= 0 ? '0b' + obj.toString(2) : '-0b' + obj.toString(2).slice(1); },\n    octal:       function (obj) { return obj >= 0 ? '0o'  + obj.toString(8) : '-0o'  + obj.toString(8).slice(1); },\n    decimal:     function (obj) { return obj.toString(10); },\n    /* eslint-disable max-len */\n    hexadecimal: function (obj) { return obj >= 0 ? '0x' + obj.toString(16).toUpperCase() :  '-0x' + obj.toString(16).toUpperCase().slice(1); }\n  },\n  defaultStyle: 'decimal',\n  styleAliases: {\n    binary:      [ 2,  'bin' ],\n    octal:       [ 8,  'oct' ],\n    decimal:     [ 10, 'dec' ],\n    hexadecimal: [ 16, 'hex' ]\n  }\n});\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/lib/type/int.js?");

/***/ }),

/***/ "./node_modules/js-yaml/lib/type/map.js":
/*!**********************************************!*\
  !*** ./node_modules/js-yaml/lib/type/map.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar Type = __webpack_require__(/*! ../type */ \"./node_modules/js-yaml/lib/type.js\");\n\nmodule.exports = new Type('tag:yaml.org,2002:map', {\n  kind: 'mapping',\n  construct: function (data) { return data !== null ? data : {}; }\n});\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/lib/type/map.js?");

/***/ }),

/***/ "./node_modules/js-yaml/lib/type/merge.js":
/*!************************************************!*\
  !*** ./node_modules/js-yaml/lib/type/merge.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar Type = __webpack_require__(/*! ../type */ \"./node_modules/js-yaml/lib/type.js\");\n\nfunction resolveYamlMerge(data) {\n  return data === '<<' || data === null;\n}\n\nmodule.exports = new Type('tag:yaml.org,2002:merge', {\n  kind: 'scalar',\n  resolve: resolveYamlMerge\n});\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/lib/type/merge.js?");

/***/ }),

/***/ "./node_modules/js-yaml/lib/type/null.js":
/*!***********************************************!*\
  !*** ./node_modules/js-yaml/lib/type/null.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar Type = __webpack_require__(/*! ../type */ \"./node_modules/js-yaml/lib/type.js\");\n\nfunction resolveYamlNull(data) {\n  if (data === null) return true;\n\n  var max = data.length;\n\n  return (max === 1 && data === '~') ||\n         (max === 4 && (data === 'null' || data === 'Null' || data === 'NULL'));\n}\n\nfunction constructYamlNull() {\n  return null;\n}\n\nfunction isNull(object) {\n  return object === null;\n}\n\nmodule.exports = new Type('tag:yaml.org,2002:null', {\n  kind: 'scalar',\n  resolve: resolveYamlNull,\n  construct: constructYamlNull,\n  predicate: isNull,\n  represent: {\n    canonical: function () { return '~';    },\n    lowercase: function () { return 'null'; },\n    uppercase: function () { return 'NULL'; },\n    camelcase: function () { return 'Null'; },\n    empty:     function () { return '';     }\n  },\n  defaultStyle: 'lowercase'\n});\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/lib/type/null.js?");

/***/ }),

/***/ "./node_modules/js-yaml/lib/type/omap.js":
/*!***********************************************!*\
  !*** ./node_modules/js-yaml/lib/type/omap.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar Type = __webpack_require__(/*! ../type */ \"./node_modules/js-yaml/lib/type.js\");\n\nvar _hasOwnProperty = Object.prototype.hasOwnProperty;\nvar _toString       = Object.prototype.toString;\n\nfunction resolveYamlOmap(data) {\n  if (data === null) return true;\n\n  var objectKeys = [], index, length, pair, pairKey, pairHasKey,\n      object = data;\n\n  for (index = 0, length = object.length; index < length; index += 1) {\n    pair = object[index];\n    pairHasKey = false;\n\n    if (_toString.call(pair) !== '[object Object]') return false;\n\n    for (pairKey in pair) {\n      if (_hasOwnProperty.call(pair, pairKey)) {\n        if (!pairHasKey) pairHasKey = true;\n        else return false;\n      }\n    }\n\n    if (!pairHasKey) return false;\n\n    if (objectKeys.indexOf(pairKey) === -1) objectKeys.push(pairKey);\n    else return false;\n  }\n\n  return true;\n}\n\nfunction constructYamlOmap(data) {\n  return data !== null ? data : [];\n}\n\nmodule.exports = new Type('tag:yaml.org,2002:omap', {\n  kind: 'sequence',\n  resolve: resolveYamlOmap,\n  construct: constructYamlOmap\n});\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/lib/type/omap.js?");

/***/ }),

/***/ "./node_modules/js-yaml/lib/type/pairs.js":
/*!************************************************!*\
  !*** ./node_modules/js-yaml/lib/type/pairs.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar Type = __webpack_require__(/*! ../type */ \"./node_modules/js-yaml/lib/type.js\");\n\nvar _toString = Object.prototype.toString;\n\nfunction resolveYamlPairs(data) {\n  if (data === null) return true;\n\n  var index, length, pair, keys, result,\n      object = data;\n\n  result = new Array(object.length);\n\n  for (index = 0, length = object.length; index < length; index += 1) {\n    pair = object[index];\n\n    if (_toString.call(pair) !== '[object Object]') return false;\n\n    keys = Object.keys(pair);\n\n    if (keys.length !== 1) return false;\n\n    result[index] = [ keys[0], pair[keys[0]] ];\n  }\n\n  return true;\n}\n\nfunction constructYamlPairs(data) {\n  if (data === null) return [];\n\n  var index, length, pair, keys, result,\n      object = data;\n\n  result = new Array(object.length);\n\n  for (index = 0, length = object.length; index < length; index += 1) {\n    pair = object[index];\n\n    keys = Object.keys(pair);\n\n    result[index] = [ keys[0], pair[keys[0]] ];\n  }\n\n  return result;\n}\n\nmodule.exports = new Type('tag:yaml.org,2002:pairs', {\n  kind: 'sequence',\n  resolve: resolveYamlPairs,\n  construct: constructYamlPairs\n});\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/lib/type/pairs.js?");

/***/ }),

/***/ "./node_modules/js-yaml/lib/type/seq.js":
/*!**********************************************!*\
  !*** ./node_modules/js-yaml/lib/type/seq.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar Type = __webpack_require__(/*! ../type */ \"./node_modules/js-yaml/lib/type.js\");\n\nmodule.exports = new Type('tag:yaml.org,2002:seq', {\n  kind: 'sequence',\n  construct: function (data) { return data !== null ? data : []; }\n});\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/lib/type/seq.js?");

/***/ }),

/***/ "./node_modules/js-yaml/lib/type/set.js":
/*!**********************************************!*\
  !*** ./node_modules/js-yaml/lib/type/set.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar Type = __webpack_require__(/*! ../type */ \"./node_modules/js-yaml/lib/type.js\");\n\nvar _hasOwnProperty = Object.prototype.hasOwnProperty;\n\nfunction resolveYamlSet(data) {\n  if (data === null) return true;\n\n  var key, object = data;\n\n  for (key in object) {\n    if (_hasOwnProperty.call(object, key)) {\n      if (object[key] !== null) return false;\n    }\n  }\n\n  return true;\n}\n\nfunction constructYamlSet(data) {\n  return data !== null ? data : {};\n}\n\nmodule.exports = new Type('tag:yaml.org,2002:set', {\n  kind: 'mapping',\n  resolve: resolveYamlSet,\n  construct: constructYamlSet\n});\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/lib/type/set.js?");

/***/ }),

/***/ "./node_modules/js-yaml/lib/type/str.js":
/*!**********************************************!*\
  !*** ./node_modules/js-yaml/lib/type/str.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar Type = __webpack_require__(/*! ../type */ \"./node_modules/js-yaml/lib/type.js\");\n\nmodule.exports = new Type('tag:yaml.org,2002:str', {\n  kind: 'scalar',\n  construct: function (data) { return data !== null ? data : ''; }\n});\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/lib/type/str.js?");

/***/ }),

/***/ "./node_modules/js-yaml/lib/type/timestamp.js":
/*!****************************************************!*\
  !*** ./node_modules/js-yaml/lib/type/timestamp.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar Type = __webpack_require__(/*! ../type */ \"./node_modules/js-yaml/lib/type.js\");\n\nvar YAML_DATE_REGEXP = new RegExp(\n  '^([0-9][0-9][0-9][0-9])'          + // [1] year\n  '-([0-9][0-9])'                    + // [2] month\n  '-([0-9][0-9])$');                   // [3] day\n\nvar YAML_TIMESTAMP_REGEXP = new RegExp(\n  '^([0-9][0-9][0-9][0-9])'          + // [1] year\n  '-([0-9][0-9]?)'                   + // [2] month\n  '-([0-9][0-9]?)'                   + // [3] day\n  '(?:[Tt]|[ \\\\t]+)'                 + // ...\n  '([0-9][0-9]?)'                    + // [4] hour\n  ':([0-9][0-9])'                    + // [5] minute\n  ':([0-9][0-9])'                    + // [6] second\n  '(?:\\\\.([0-9]*))?'                 + // [7] fraction\n  '(?:[ \\\\t]*(Z|([-+])([0-9][0-9]?)' + // [8] tz [9] tz_sign [10] tz_hour\n  '(?::([0-9][0-9]))?))?$');           // [11] tz_minute\n\nfunction resolveYamlTimestamp(data) {\n  if (data === null) return false;\n  if (YAML_DATE_REGEXP.exec(data) !== null) return true;\n  if (YAML_TIMESTAMP_REGEXP.exec(data) !== null) return true;\n  return false;\n}\n\nfunction constructYamlTimestamp(data) {\n  var match, year, month, day, hour, minute, second, fraction = 0,\n      delta = null, tz_hour, tz_minute, date;\n\n  match = YAML_DATE_REGEXP.exec(data);\n  if (match === null) match = YAML_TIMESTAMP_REGEXP.exec(data);\n\n  if (match === null) throw new Error('Date resolve error');\n\n  // match: [1] year [2] month [3] day\n\n  year = +(match[1]);\n  month = +(match[2]) - 1; // JS month starts with 0\n  day = +(match[3]);\n\n  if (!match[4]) { // no hour\n    return new Date(Date.UTC(year, month, day));\n  }\n\n  // match: [4] hour [5] minute [6] second [7] fraction\n\n  hour = +(match[4]);\n  minute = +(match[5]);\n  second = +(match[6]);\n\n  if (match[7]) {\n    fraction = match[7].slice(0, 3);\n    while (fraction.length < 3) { // milli-seconds\n      fraction += '0';\n    }\n    fraction = +fraction;\n  }\n\n  // match: [8] tz [9] tz_sign [10] tz_hour [11] tz_minute\n\n  if (match[9]) {\n    tz_hour = +(match[10]);\n    tz_minute = +(match[11] || 0);\n    delta = (tz_hour * 60 + tz_minute) * 60000; // delta in mili-seconds\n    if (match[9] === '-') delta = -delta;\n  }\n\n  date = new Date(Date.UTC(year, month, day, hour, minute, second, fraction));\n\n  if (delta) date.setTime(date.getTime() - delta);\n\n  return date;\n}\n\nfunction representYamlTimestamp(object /*, style*/) {\n  return object.toISOString();\n}\n\nmodule.exports = new Type('tag:yaml.org,2002:timestamp', {\n  kind: 'scalar',\n  resolve: resolveYamlTimestamp,\n  construct: constructYamlTimestamp,\n  instanceOf: Date,\n  represent: representYamlTimestamp\n});\n\n\n//# sourceURL=webpack://renderer/./node_modules/js-yaml/lib/type/timestamp.js?");

/***/ }),

/***/ "./node_modules/jsonfile/index.js":
/*!****************************************!*\
  !*** ./node_modules/jsonfile/index.js ***!
  \****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("let _fs\ntry {\n  _fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\n} catch (_) {\n  _fs = __webpack_require__(/*! fs */ \"fs\")\n}\nconst universalify = __webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\")\nconst { stringify, stripBom } = __webpack_require__(/*! ./utils */ \"./node_modules/jsonfile/utils.js\")\n\nasync function _readFile (file, options = {}) {\n  if (typeof options === 'string') {\n    options = { encoding: options }\n  }\n\n  const fs = options.fs || _fs\n\n  const shouldThrow = 'throws' in options ? options.throws : true\n\n  let data = await universalify.fromCallback(fs.readFile)(file, options)\n\n  data = stripBom(data)\n\n  let obj\n  try {\n    obj = JSON.parse(data, options ? options.reviver : null)\n  } catch (err) {\n    if (shouldThrow) {\n      err.message = `${file}: ${err.message}`\n      throw err\n    } else {\n      return null\n    }\n  }\n\n  return obj\n}\n\nconst readFile = universalify.fromPromise(_readFile)\n\nfunction readFileSync (file, options = {}) {\n  if (typeof options === 'string') {\n    options = { encoding: options }\n  }\n\n  const fs = options.fs || _fs\n\n  const shouldThrow = 'throws' in options ? options.throws : true\n\n  try {\n    let content = fs.readFileSync(file, options)\n    content = stripBom(content)\n    return JSON.parse(content, options.reviver)\n  } catch (err) {\n    if (shouldThrow) {\n      err.message = `${file}: ${err.message}`\n      throw err\n    } else {\n      return null\n    }\n  }\n}\n\nasync function _writeFile (file, obj, options = {}) {\n  const fs = options.fs || _fs\n\n  const str = stringify(obj, options)\n\n  await universalify.fromCallback(fs.writeFile)(file, str, options)\n}\n\nconst writeFile = universalify.fromPromise(_writeFile)\n\nfunction writeFileSync (file, obj, options = {}) {\n  const fs = options.fs || _fs\n\n  const str = stringify(obj, options)\n  // not sure if fs.writeFileSync returns anything, but just in case\n  return fs.writeFileSync(file, str, options)\n}\n\nconst jsonfile = {\n  readFile,\n  readFileSync,\n  writeFile,\n  writeFileSync\n}\n\nmodule.exports = jsonfile\n\n\n//# sourceURL=webpack://renderer/./node_modules/jsonfile/index.js?");

/***/ }),

/***/ "./node_modules/jsonfile/utils.js":
/*!****************************************!*\
  !*** ./node_modules/jsonfile/utils.js ***!
  \****************************************/
/***/ ((module) => {

eval("function stringify (obj, { EOL = '\\n', finalEOL = true, replacer = null, spaces } = {}) {\n  const EOF = finalEOL ? EOL : ''\n  const str = JSON.stringify(obj, replacer, spaces)\n\n  return str.replace(/\\n/g, EOL) + EOF\n}\n\nfunction stripBom (content) {\n  // we do this because JSON.parse would convert it to a utf8 string if encoding wasn't specified\n  if (Buffer.isBuffer(content)) content = content.toString('utf8')\n  return content.replace(/^\\uFEFF/, '')\n}\n\nmodule.exports = { stringify, stripBom }\n\n\n//# sourceURL=webpack://renderer/./node_modules/jsonfile/utils.js?");

/***/ }),

/***/ "./node_modules/keyboardevent-from-electron-accelerator/index.js":
/*!***********************************************************************!*\
  !*** ./node_modules/keyboardevent-from-electron-accelerator/index.js ***!
  \***********************************************************************/
/***/ ((module) => {

eval("const modifiers = /^(CommandOrControl|CmdOrCtrl|Command|Cmd|Control|Ctrl|AltGr|Option|Alt|Shift|Super)/i;\nconst keyCodes = /^(Plus|Space|Tab|Backspace|Delete|Insert|Return|Enter|Up|Down|Left|Right|Home|End|PageUp|PageDown|Escape|Esc|VolumeUp|VolumeDown|VolumeMute|MediaNextTrack|MediaPreviousTrack|MediaStop|MediaPlayPause|PrintScreen|F24|F23|F22|F21|F20|F19|F18|F17|F16|F15|F14|F13|F12|F11|F10|F9|F8|F7|F6|F5|F4|F3|F2|F1|[0-9A-Z)!@#$%^&*(:+<_>?~{|}\";=,\\-./`[\\\\\\]'])/i;\nconst UNSUPPORTED = {};\n\nfunction _command(accelerator, event, modifier) {\n\tif (process.platform !== 'darwin') {\n\t\treturn UNSUPPORTED;\n\t}\n\n\tif (event.metaKey) {\n\t\tthrow new Error('Double `Command` modifier specified.');\n\t}\n\n\treturn {\n\t\tevent: Object.assign({}, event, {metaKey: true}),\n\t\taccelerator: accelerator.slice(modifier.length)\n\t};\n}\n\nfunction _super(accelerator, event, modifier) {\n\tif (event.metaKey) {\n\t\tthrow new Error('Double `Super` modifier specified.');\n\t}\n\n\treturn {\n\t\tevent: Object.assign({}, event, {metaKey: true}),\n\t\taccelerator: accelerator.slice(modifier.length)\n\t};\n}\n\nfunction _commandorcontrol(accelerator, event, modifier) {\n\tif (process.platform === 'darwin') {\n\t\tif (event.metaKey) {\n\t\t\tthrow new Error('Double `Command` modifier specified.');\n\t\t}\n\n\t\treturn {\n\t\t\tevent: Object.assign({}, event, {metaKey: true}),\n\t\t\taccelerator: accelerator.slice(modifier.length)\n\t\t};\n\t}\n\n\tif (event.ctrlKey) {\n\t\tthrow new Error('Double `Control` modifier specified.');\n\t}\n\n\treturn {\n\t\tevent: Object.assign({}, event, {ctrlKey: true}),\n\t\taccelerator: accelerator.slice(modifier.length)\n\t};\n}\n\nfunction _alt(accelerator, event, modifier) {\n\tif (modifier === 'option' && process.platform !== 'darwin') {\n\t\treturn UNSUPPORTED;\n\t}\n\n\tif (event.altKey) {\n\t\tthrow new Error('Double `Alt` modifier specified.');\n\t}\n\n\treturn {\n\t\tevent: Object.assign({}, event, {altKey: true}),\n\t\taccelerator: accelerator.slice(modifier.length)\n\t};\n}\n\nfunction _shift(accelerator, event, modifier) {\n\tif (event.shiftKey) {\n\t\tthrow new Error('Double `Shift` modifier specified.');\n\t}\n\n\treturn {\n\t\tevent: Object.assign({}, event, {shiftKey: true}),\n\t\taccelerator: accelerator.slice(modifier.length)\n\t};\n}\n\nfunction _control(accelerator, event, modifier) {\n\tif (event.ctrlKey) {\n\t\tthrow new Error('Double `Control` modifier specified.');\n\t}\n\n\treturn {\n\t\tevent: Object.assign({}, event, {ctrlKey: true}),\n\t\taccelerator: accelerator.slice(modifier.length)\n\t};\n}\n\nfunction reduceModifier({accelerator, event}, modifier) {\n\tswitch (modifier) {\n\t\tcase 'command':\n\t\tcase 'cmd': {\n\t\t\treturn _command(accelerator, event, modifier);\n\t\t}\n\n\t\tcase 'super': {\n\t\t\treturn _super(accelerator, event, modifier);\n\t\t}\n\n\t\tcase 'control':\n\t\tcase 'ctrl': {\n\t\t\treturn _control(accelerator, event, modifier);\n\t\t}\n\n\t\tcase 'commandorcontrol':\n\t\tcase 'cmdorctrl': {\n\t\t\treturn _commandorcontrol(accelerator, event, modifier);\n\t\t}\n\n\t\tcase 'option':\n\t\tcase 'altgr':\n\t\tcase 'alt': {\n\t\t\treturn _alt(accelerator, event, modifier);\n\t\t}\n\n\t\tcase 'shift': {\n\t\t\treturn _shift(accelerator, event, modifier);\n\t\t}\n\n\t\tdefault:\n\t\t\tconsole.error(modifier);\n\t}\n}\n\nfunction reducePlus({accelerator, event}) {\n\treturn {\n\t\tevent,\n\t\taccelerator: accelerator.trim().slice(1)\n\t};\n}\n\nconst virtualKeyCodes = {\n\t0: 'Digit0',\n\t1: 'Digit1',\n\t2: 'Digit2',\n\t3: 'Digit3',\n\t4: 'Digit4',\n\t5: 'Digit5',\n\t6: 'Digit6',\n\t7: 'Digit7',\n\t8: 'Digit8',\n\t9: 'Digit9',\n\t'-': 'Minus',\n\t'=': 'Equal',\n\tQ: 'KeyQ',\n\tW: 'KeyW',\n\tE: 'KeyE',\n\tR: 'KeyR',\n\tT: 'KeyT',\n\tY: 'KeyY',\n\tU: 'KeyU',\n\tI: 'KeyI',\n\tO: 'KeyO',\n\tP: 'KeyP',\n\t'[': 'BracketLeft',\n\t']': 'BracketRight',\n\tA: 'KeyA',\n\tS: 'KeyS',\n\tD: 'KeyD',\n\tF: 'KeyF',\n\tG: 'KeyG',\n\tH: 'KeyH',\n\tJ: 'KeyJ',\n\tK: 'KeyK',\n\tL: 'KeyL',\n\t';': 'Semicolon',\n\t'\\'': 'Quote',\n\t'`': 'Backquote',\n\t'/': 'Backslash',\n\tZ: 'KeyZ',\n\tX: 'KeyX',\n\tC: 'KeyC',\n\tV: 'KeyV',\n\tB: 'KeyB',\n\tN: 'KeyN',\n\tM: 'KeyM',\n\t',': 'Comma',\n\t'.': 'Period',\n\t'\\\\': 'Slash',\n\t' ': 'Space'\n};\n\nfunction reduceKey({accelerator, event}, key) {\n\tif (key.length > 1 || event.key) {\n\t\tthrow new Error(`Unvalid keycode \\`${key}\\`.`);\n\t}\n\n\tconst code =\n\t\tkey.toUpperCase() in virtualKeyCodes ?\n\t\t\tvirtualKeyCodes[key.toUpperCase()] :\n\t\t\tnull;\n\n\treturn {\n\t\tevent: Object.assign({}, event, {key}, code ? {code} : null),\n\t\taccelerator: accelerator.trim().slice(key.length)\n\t};\n}\n\nconst domKeys = Object.assign(Object.create(null), {\n\tplus: 'Add',\n\tspace: 'Space',\n\ttab: 'Tab',\n\tbackspace: 'Backspace',\n\tdelete: 'Delete',\n\tinsert: 'Insert',\n\treturn: 'Return',\n\tenter: 'Return',\n\tup: 'ArrowUp',\n\tdown: 'ArrowDown',\n\tleft: 'ArrowLeft',\n\tright: 'ArrowRight',\n\thome: 'Home',\n\tend: 'End',\n\tpageup: 'PageUp',\n\tpagedown: 'PageDown',\n\tescape: 'Escape',\n\tesc: 'Escape',\n\tvolumeup: 'AudioVolumeUp',\n\tvolumedown: 'AudioVolumeDown',\n\tvolumemute: 'AudioVolumeMute',\n\tmedianexttrack: 'MediaTrackNext',\n\tmediaprevioustrack: 'MediaTrackPrevious',\n\tmediastop: 'MediaStop',\n\tmediaplaypause: 'MediaPlayPause',\n\tprintscreen: 'PrintScreen'\n});\n\n// Add function keys\nfor (let i = 1; i <= 24; i++) {\n\tdomKeys[`f${i}`] = `F${i}`;\n}\n\nfunction reduceCode({accelerator, event}, {code, key}) {\n\tif (event.code) {\n\t\tthrow new Error(`Duplicated keycode \\`${key}\\`.`);\n\t}\n\n\treturn {\n\t\tevent: Object.assign({}, event, {key}, code ? {code} : null),\n\t\taccelerator: accelerator.trim().slice((key && key.length) || 0)\n\t};\n}\n\n/**\n * This function transform an Electron Accelerator string into\n * a DOM KeyboardEvent object.\n *\n * @param  {string} accelerator an Electron Accelerator string, e.g. `Ctrl+C` or `Shift+Space`.\n * @return {object} a DOM KeyboardEvent object derivate from the `accelerator` argument.\n */\nfunction toKeyEvent(accelerator) {\n\tlet state = {accelerator, event: {}};\n\twhile (state.accelerator !== '') {\n\t\tconst modifierMatch = state.accelerator.match(modifiers);\n\t\tif (modifierMatch) {\n\t\t\tconst modifier = modifierMatch[0].toLowerCase();\n\t\t\tstate = reduceModifier(state, modifier);\n\t\t\tif (state === UNSUPPORTED) {\n\t\t\t\treturn {unsupportedKeyForPlatform: true};\n\t\t\t}\n\t\t} else if (state.accelerator.trim()[0] === '+') {\n\t\t\tstate = reducePlus(state);\n\t\t} else {\n\t\t\tconst codeMatch = state.accelerator.match(keyCodes);\n\t\t\tif (codeMatch) {\n\t\t\t\tconst code = codeMatch[0].toLowerCase();\n\t\t\t\tif (code in domKeys) {\n\t\t\t\t\tstate = reduceCode(state, {\n\t\t\t\t\t\tcode: domKeys[code],\n\t\t\t\t\t\tkey: code\n\t\t\t\t\t});\n\t\t\t\t} else {\n\t\t\t\t\tstate = reduceKey(state, code);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tthrow new Error(`Unvalid accelerator: \"${state.accelerator}\"`);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn state.event;\n}\n\nmodule.exports = {\n\tUNSUPPORTED,\n\treduceModifier,\n\treducePlus,\n\treduceKey,\n\treduceCode,\n\ttoKeyEvent\n};\n\n\n//# sourceURL=webpack://renderer/./node_modules/keyboardevent-from-electron-accelerator/index.js?");

/***/ }),

/***/ "./node_modules/keyboardevents-areequal/index.js":
/*!*******************************************************!*\
  !*** ./node_modules/keyboardevents-areequal/index.js ***!
  \*******************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nfunction _lower(key) {\n\tif (typeof key !== 'string') {\n\t\treturn key;\n\t}\n\treturn key.toLowerCase();\n}\n\nfunction areEqual(ev1, ev2) {\n\tif (ev1 === ev2) {\n\t\t// Same object\n\t\t// console.log(`Events are same.`)\n\t\treturn true;\n\t}\n\n\tfor (const prop of ['altKey', 'ctrlKey', 'shiftKey', 'metaKey']) {\n\t\tconst [value1, value2] = [ev1[prop], ev2[prop]];\n\n\t\tif (Boolean(value1) !== Boolean(value2)) {\n\t\t\t// One of the prop is different\n\t\t\t// console.log(`Comparing prop ${prop}: ${value1} ${value2}`);\n\t\t\treturn false;\n\t\t}\n\t}\n\n\tif ((_lower(ev1.key) === _lower(ev2.key) && ev1.key !== undefined) ||\n\t\t(ev1.code === ev2.code && ev1.code !== undefined)) {\n\t\t// Events are equals\n\t\treturn true;\n\t}\n\n\t// Key or code are differents\n\t// console.log(`key or code are differents. ${ev1.key} !== ${ev2.key} ${ev1.code} !== ${ev2.code}`);\n\n\treturn false;\n}\n\nmodule.exports = areEqual;\n\n\n//# sourceURL=webpack://renderer/./node_modules/keyboardevents-areequal/index.js?");

/***/ }),

/***/ "./node_modules/lazy-val/out/main.js":
/*!*******************************************!*\
  !*** ./node_modules/lazy-val/out/main.js ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Lazy = void 0;\nclass Lazy {\n    constructor(creator) {\n        this._value = null;\n        this.creator = creator;\n    }\n    get hasValue() {\n        return this.creator == null;\n    }\n    get value() {\n        if (this.creator == null) {\n            return this._value;\n        }\n        const result = this.creator();\n        this.value = result;\n        return result;\n    }\n    set value(value) {\n        this._value = value;\n        this.creator = null;\n    }\n}\nexports.Lazy = Lazy;\n//# sourceMappingURL=main.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/lazy-val/out/main.js?");

/***/ }),

/***/ "./node_modules/lodash.escaperegexp/index.js":
/*!***************************************************!*\
  !*** ./node_modules/lodash.escaperegexp/index.js ***!
  \***************************************************/
/***/ ((module) => {

eval("/**\n * lodash (Custom Build) <https://lodash.com/>\n * Build: `lodash modularize exports=\"npm\" -o ./`\n * Copyright jQuery Foundation and other contributors <https://jquery.org/>\n * Released under MIT license <https://lodash.com/license>\n * Based on Underscore.js 1.8.3 <http://underscorejs.org/LICENSE>\n * Copyright Jeremy Ashkenas, DocumentCloud and Investigative Reporters & Editors\n */\n\n/** Used as references for various `Number` constants. */\nvar INFINITY = 1 / 0;\n\n/** `Object#toString` result references. */\nvar symbolTag = '[object Symbol]';\n\n/**\n * Used to match `RegExp`\n * [syntax characters](http://ecma-international.org/ecma-262/6.0/#sec-patterns).\n */\nvar reRegExpChar = /[\\\\^$.*+?()[\\]{}|]/g,\n    reHasRegExpChar = RegExp(reRegExpChar.source);\n\n/** Detect free variable `global` from Node.js. */\nvar freeGlobal = typeof global == 'object' && global && global.Object === Object && global;\n\n/** Detect free variable `self`. */\nvar freeSelf = typeof self == 'object' && self && self.Object === Object && self;\n\n/** Used as a reference to the global object. */\nvar root = freeGlobal || freeSelf || Function('return this')();\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/**\n * Used to resolve the\n * [`toStringTag`](http://ecma-international.org/ecma-262/6.0/#sec-object.prototype.tostring)\n * of values.\n */\nvar objectToString = objectProto.toString;\n\n/** Built-in value references. */\nvar Symbol = root.Symbol;\n\n/** Used to convert symbols to primitives and strings. */\nvar symbolProto = Symbol ? Symbol.prototype : undefined,\n    symbolToString = symbolProto ? symbolProto.toString : undefined;\n\n/**\n * The base implementation of `_.toString` which doesn't convert nullish\n * values to empty strings.\n *\n * @private\n * @param {*} value The value to process.\n * @returns {string} Returns the string.\n */\nfunction baseToString(value) {\n  // Exit early for strings to avoid a performance hit in some environments.\n  if (typeof value == 'string') {\n    return value;\n  }\n  if (isSymbol(value)) {\n    return symbolToString ? symbolToString.call(value) : '';\n  }\n  var result = (value + '');\n  return (result == '0' && (1 / value) == -INFINITY) ? '-0' : result;\n}\n\n/**\n * Checks if `value` is object-like. A value is object-like if it's not `null`\n * and has a `typeof` result of \"object\".\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is object-like, else `false`.\n * @example\n *\n * _.isObjectLike({});\n * // => true\n *\n * _.isObjectLike([1, 2, 3]);\n * // => true\n *\n * _.isObjectLike(_.noop);\n * // => false\n *\n * _.isObjectLike(null);\n * // => false\n */\nfunction isObjectLike(value) {\n  return !!value && typeof value == 'object';\n}\n\n/**\n * Checks if `value` is classified as a `Symbol` primitive or object.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a symbol, else `false`.\n * @example\n *\n * _.isSymbol(Symbol.iterator);\n * // => true\n *\n * _.isSymbol('abc');\n * // => false\n */\nfunction isSymbol(value) {\n  return typeof value == 'symbol' ||\n    (isObjectLike(value) && objectToString.call(value) == symbolTag);\n}\n\n/**\n * Converts `value` to a string. An empty string is returned for `null`\n * and `undefined` values. The sign of `-0` is preserved.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to process.\n * @returns {string} Returns the string.\n * @example\n *\n * _.toString(null);\n * // => ''\n *\n * _.toString(-0);\n * // => '-0'\n *\n * _.toString([1, 2, 3]);\n * // => '1,2,3'\n */\nfunction toString(value) {\n  return value == null ? '' : baseToString(value);\n}\n\n/**\n * Escapes the `RegExp` special characters \"^\", \"$\", \"\\\", \".\", \"*\", \"+\",\n * \"?\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", and \"|\" in `string`.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category String\n * @param {string} [string=''] The string to escape.\n * @returns {string} Returns the escaped string.\n * @example\n *\n * _.escapeRegExp('[lodash](https://lodash.com/)');\n * // => '\\[lodash\\]\\(https://lodash\\.com/\\)'\n */\nfunction escapeRegExp(string) {\n  string = toString(string);\n  return (string && reHasRegExpChar.test(string))\n    ? string.replace(reRegExpChar, '\\\\$&')\n    : string;\n}\n\nmodule.exports = escapeRegExp;\n\n\n//# sourceURL=webpack://renderer/./node_modules/lodash.escaperegexp/index.js?");

/***/ }),

/***/ "./node_modules/lodash.isequal/index.js":
/*!**********************************************!*\
  !*** ./node_modules/lodash.isequal/index.js ***!
  \**********************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("/* module decorator */ module = __webpack_require__.nmd(module);\n/**\n * Lodash (Custom Build) <https://lodash.com/>\n * Build: `lodash modularize exports=\"npm\" -o ./`\n * Copyright JS Foundation and other contributors <https://js.foundation/>\n * Released under MIT license <https://lodash.com/license>\n * Based on Underscore.js 1.8.3 <http://underscorejs.org/LICENSE>\n * Copyright Jeremy Ashkenas, DocumentCloud and Investigative Reporters & Editors\n */\n\n/** Used as the size to enable large array optimizations. */\nvar LARGE_ARRAY_SIZE = 200;\n\n/** Used to stand-in for `undefined` hash values. */\nvar HASH_UNDEFINED = '__lodash_hash_undefined__';\n\n/** Used to compose bitmasks for value comparisons. */\nvar COMPARE_PARTIAL_FLAG = 1,\n    COMPARE_UNORDERED_FLAG = 2;\n\n/** Used as references for various `Number` constants. */\nvar MAX_SAFE_INTEGER = 9007199254740991;\n\n/** `Object#toString` result references. */\nvar argsTag = '[object Arguments]',\n    arrayTag = '[object Array]',\n    asyncTag = '[object AsyncFunction]',\n    boolTag = '[object Boolean]',\n    dateTag = '[object Date]',\n    errorTag = '[object Error]',\n    funcTag = '[object Function]',\n    genTag = '[object GeneratorFunction]',\n    mapTag = '[object Map]',\n    numberTag = '[object Number]',\n    nullTag = '[object Null]',\n    objectTag = '[object Object]',\n    promiseTag = '[object Promise]',\n    proxyTag = '[object Proxy]',\n    regexpTag = '[object RegExp]',\n    setTag = '[object Set]',\n    stringTag = '[object String]',\n    symbolTag = '[object Symbol]',\n    undefinedTag = '[object Undefined]',\n    weakMapTag = '[object WeakMap]';\n\nvar arrayBufferTag = '[object ArrayBuffer]',\n    dataViewTag = '[object DataView]',\n    float32Tag = '[object Float32Array]',\n    float64Tag = '[object Float64Array]',\n    int8Tag = '[object Int8Array]',\n    int16Tag = '[object Int16Array]',\n    int32Tag = '[object Int32Array]',\n    uint8Tag = '[object Uint8Array]',\n    uint8ClampedTag = '[object Uint8ClampedArray]',\n    uint16Tag = '[object Uint16Array]',\n    uint32Tag = '[object Uint32Array]';\n\n/**\n * Used to match `RegExp`\n * [syntax characters](http://ecma-international.org/ecma-262/7.0/#sec-patterns).\n */\nvar reRegExpChar = /[\\\\^$.*+?()[\\]{}|]/g;\n\n/** Used to detect host constructors (Safari). */\nvar reIsHostCtor = /^\\[object .+?Constructor\\]$/;\n\n/** Used to detect unsigned integer values. */\nvar reIsUint = /^(?:0|[1-9]\\d*)$/;\n\n/** Used to identify `toStringTag` values of typed arrays. */\nvar typedArrayTags = {};\ntypedArrayTags[float32Tag] = typedArrayTags[float64Tag] =\ntypedArrayTags[int8Tag] = typedArrayTags[int16Tag] =\ntypedArrayTags[int32Tag] = typedArrayTags[uint8Tag] =\ntypedArrayTags[uint8ClampedTag] = typedArrayTags[uint16Tag] =\ntypedArrayTags[uint32Tag] = true;\ntypedArrayTags[argsTag] = typedArrayTags[arrayTag] =\ntypedArrayTags[arrayBufferTag] = typedArrayTags[boolTag] =\ntypedArrayTags[dataViewTag] = typedArrayTags[dateTag] =\ntypedArrayTags[errorTag] = typedArrayTags[funcTag] =\ntypedArrayTags[mapTag] = typedArrayTags[numberTag] =\ntypedArrayTags[objectTag] = typedArrayTags[regexpTag] =\ntypedArrayTags[setTag] = typedArrayTags[stringTag] =\ntypedArrayTags[weakMapTag] = false;\n\n/** Detect free variable `global` from Node.js. */\nvar freeGlobal = typeof global == 'object' && global && global.Object === Object && global;\n\n/** Detect free variable `self`. */\nvar freeSelf = typeof self == 'object' && self && self.Object === Object && self;\n\n/** Used as a reference to the global object. */\nvar root = freeGlobal || freeSelf || Function('return this')();\n\n/** Detect free variable `exports`. */\nvar freeExports =  true && exports && !exports.nodeType && exports;\n\n/** Detect free variable `module`. */\nvar freeModule = freeExports && \"object\" == 'object' && module && !module.nodeType && module;\n\n/** Detect the popular CommonJS extension `module.exports`. */\nvar moduleExports = freeModule && freeModule.exports === freeExports;\n\n/** Detect free variable `process` from Node.js. */\nvar freeProcess = moduleExports && freeGlobal.process;\n\n/** Used to access faster Node.js helpers. */\nvar nodeUtil = (function() {\n  try {\n    return freeProcess && freeProcess.binding && freeProcess.binding('util');\n  } catch (e) {}\n}());\n\n/* Node.js helper references. */\nvar nodeIsTypedArray = nodeUtil && nodeUtil.isTypedArray;\n\n/**\n * A specialized version of `_.filter` for arrays without support for\n * iteratee shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} predicate The function invoked per iteration.\n * @returns {Array} Returns the new filtered array.\n */\nfunction arrayFilter(array, predicate) {\n  var index = -1,\n      length = array == null ? 0 : array.length,\n      resIndex = 0,\n      result = [];\n\n  while (++index < length) {\n    var value = array[index];\n    if (predicate(value, index, array)) {\n      result[resIndex++] = value;\n    }\n  }\n  return result;\n}\n\n/**\n * Appends the elements of `values` to `array`.\n *\n * @private\n * @param {Array} array The array to modify.\n * @param {Array} values The values to append.\n * @returns {Array} Returns `array`.\n */\nfunction arrayPush(array, values) {\n  var index = -1,\n      length = values.length,\n      offset = array.length;\n\n  while (++index < length) {\n    array[offset + index] = values[index];\n  }\n  return array;\n}\n\n/**\n * A specialized version of `_.some` for arrays without support for iteratee\n * shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} predicate The function invoked per iteration.\n * @returns {boolean} Returns `true` if any element passes the predicate check,\n *  else `false`.\n */\nfunction arraySome(array, predicate) {\n  var index = -1,\n      length = array == null ? 0 : array.length;\n\n  while (++index < length) {\n    if (predicate(array[index], index, array)) {\n      return true;\n    }\n  }\n  return false;\n}\n\n/**\n * The base implementation of `_.times` without support for iteratee shorthands\n * or max array length checks.\n *\n * @private\n * @param {number} n The number of times to invoke `iteratee`.\n * @param {Function} iteratee The function invoked per iteration.\n * @returns {Array} Returns the array of results.\n */\nfunction baseTimes(n, iteratee) {\n  var index = -1,\n      result = Array(n);\n\n  while (++index < n) {\n    result[index] = iteratee(index);\n  }\n  return result;\n}\n\n/**\n * The base implementation of `_.unary` without support for storing metadata.\n *\n * @private\n * @param {Function} func The function to cap arguments for.\n * @returns {Function} Returns the new capped function.\n */\nfunction baseUnary(func) {\n  return function(value) {\n    return func(value);\n  };\n}\n\n/**\n * Checks if a `cache` value for `key` exists.\n *\n * @private\n * @param {Object} cache The cache to query.\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction cacheHas(cache, key) {\n  return cache.has(key);\n}\n\n/**\n * Gets the value at `key` of `object`.\n *\n * @private\n * @param {Object} [object] The object to query.\n * @param {string} key The key of the property to get.\n * @returns {*} Returns the property value.\n */\nfunction getValue(object, key) {\n  return object == null ? undefined : object[key];\n}\n\n/**\n * Converts `map` to its key-value pairs.\n *\n * @private\n * @param {Object} map The map to convert.\n * @returns {Array} Returns the key-value pairs.\n */\nfunction mapToArray(map) {\n  var index = -1,\n      result = Array(map.size);\n\n  map.forEach(function(value, key) {\n    result[++index] = [key, value];\n  });\n  return result;\n}\n\n/**\n * Creates a unary function that invokes `func` with its argument transformed.\n *\n * @private\n * @param {Function} func The function to wrap.\n * @param {Function} transform The argument transform.\n * @returns {Function} Returns the new function.\n */\nfunction overArg(func, transform) {\n  return function(arg) {\n    return func(transform(arg));\n  };\n}\n\n/**\n * Converts `set` to an array of its values.\n *\n * @private\n * @param {Object} set The set to convert.\n * @returns {Array} Returns the values.\n */\nfunction setToArray(set) {\n  var index = -1,\n      result = Array(set.size);\n\n  set.forEach(function(value) {\n    result[++index] = value;\n  });\n  return result;\n}\n\n/** Used for built-in method references. */\nvar arrayProto = Array.prototype,\n    funcProto = Function.prototype,\n    objectProto = Object.prototype;\n\n/** Used to detect overreaching core-js shims. */\nvar coreJsData = root['__core-js_shared__'];\n\n/** Used to resolve the decompiled source of functions. */\nvar funcToString = funcProto.toString;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/** Used to detect methods masquerading as native. */\nvar maskSrcKey = (function() {\n  var uid = /[^.]+$/.exec(coreJsData && coreJsData.keys && coreJsData.keys.IE_PROTO || '');\n  return uid ? ('Symbol(src)_1.' + uid) : '';\n}());\n\n/**\n * Used to resolve the\n * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)\n * of values.\n */\nvar nativeObjectToString = objectProto.toString;\n\n/** Used to detect if a method is native. */\nvar reIsNative = RegExp('^' +\n  funcToString.call(hasOwnProperty).replace(reRegExpChar, '\\\\$&')\n  .replace(/hasOwnProperty|(function).*?(?=\\\\\\()| for .+?(?=\\\\\\])/g, '$1.*?') + '$'\n);\n\n/** Built-in value references. */\nvar Buffer = moduleExports ? root.Buffer : undefined,\n    Symbol = root.Symbol,\n    Uint8Array = root.Uint8Array,\n    propertyIsEnumerable = objectProto.propertyIsEnumerable,\n    splice = arrayProto.splice,\n    symToStringTag = Symbol ? Symbol.toStringTag : undefined;\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeGetSymbols = Object.getOwnPropertySymbols,\n    nativeIsBuffer = Buffer ? Buffer.isBuffer : undefined,\n    nativeKeys = overArg(Object.keys, Object);\n\n/* Built-in method references that are verified to be native. */\nvar DataView = getNative(root, 'DataView'),\n    Map = getNative(root, 'Map'),\n    Promise = getNative(root, 'Promise'),\n    Set = getNative(root, 'Set'),\n    WeakMap = getNative(root, 'WeakMap'),\n    nativeCreate = getNative(Object, 'create');\n\n/** Used to detect maps, sets, and weakmaps. */\nvar dataViewCtorString = toSource(DataView),\n    mapCtorString = toSource(Map),\n    promiseCtorString = toSource(Promise),\n    setCtorString = toSource(Set),\n    weakMapCtorString = toSource(WeakMap);\n\n/** Used to convert symbols to primitives and strings. */\nvar symbolProto = Symbol ? Symbol.prototype : undefined,\n    symbolValueOf = symbolProto ? symbolProto.valueOf : undefined;\n\n/**\n * Creates a hash object.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction Hash(entries) {\n  var index = -1,\n      length = entries == null ? 0 : entries.length;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n/**\n * Removes all key-value entries from the hash.\n *\n * @private\n * @name clear\n * @memberOf Hash\n */\nfunction hashClear() {\n  this.__data__ = nativeCreate ? nativeCreate(null) : {};\n  this.size = 0;\n}\n\n/**\n * Removes `key` and its value from the hash.\n *\n * @private\n * @name delete\n * @memberOf Hash\n * @param {Object} hash The hash to modify.\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction hashDelete(key) {\n  var result = this.has(key) && delete this.__data__[key];\n  this.size -= result ? 1 : 0;\n  return result;\n}\n\n/**\n * Gets the hash value for `key`.\n *\n * @private\n * @name get\n * @memberOf Hash\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction hashGet(key) {\n  var data = this.__data__;\n  if (nativeCreate) {\n    var result = data[key];\n    return result === HASH_UNDEFINED ? undefined : result;\n  }\n  return hasOwnProperty.call(data, key) ? data[key] : undefined;\n}\n\n/**\n * Checks if a hash value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf Hash\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction hashHas(key) {\n  var data = this.__data__;\n  return nativeCreate ? (data[key] !== undefined) : hasOwnProperty.call(data, key);\n}\n\n/**\n * Sets the hash `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf Hash\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the hash instance.\n */\nfunction hashSet(key, value) {\n  var data = this.__data__;\n  this.size += this.has(key) ? 0 : 1;\n  data[key] = (nativeCreate && value === undefined) ? HASH_UNDEFINED : value;\n  return this;\n}\n\n// Add methods to `Hash`.\nHash.prototype.clear = hashClear;\nHash.prototype['delete'] = hashDelete;\nHash.prototype.get = hashGet;\nHash.prototype.has = hashHas;\nHash.prototype.set = hashSet;\n\n/**\n * Creates an list cache object.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction ListCache(entries) {\n  var index = -1,\n      length = entries == null ? 0 : entries.length;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n/**\n * Removes all key-value entries from the list cache.\n *\n * @private\n * @name clear\n * @memberOf ListCache\n */\nfunction listCacheClear() {\n  this.__data__ = [];\n  this.size = 0;\n}\n\n/**\n * Removes `key` and its value from the list cache.\n *\n * @private\n * @name delete\n * @memberOf ListCache\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction listCacheDelete(key) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  if (index < 0) {\n    return false;\n  }\n  var lastIndex = data.length - 1;\n  if (index == lastIndex) {\n    data.pop();\n  } else {\n    splice.call(data, index, 1);\n  }\n  --this.size;\n  return true;\n}\n\n/**\n * Gets the list cache value for `key`.\n *\n * @private\n * @name get\n * @memberOf ListCache\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction listCacheGet(key) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  return index < 0 ? undefined : data[index][1];\n}\n\n/**\n * Checks if a list cache value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf ListCache\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction listCacheHas(key) {\n  return assocIndexOf(this.__data__, key) > -1;\n}\n\n/**\n * Sets the list cache `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf ListCache\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the list cache instance.\n */\nfunction listCacheSet(key, value) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  if (index < 0) {\n    ++this.size;\n    data.push([key, value]);\n  } else {\n    data[index][1] = value;\n  }\n  return this;\n}\n\n// Add methods to `ListCache`.\nListCache.prototype.clear = listCacheClear;\nListCache.prototype['delete'] = listCacheDelete;\nListCache.prototype.get = listCacheGet;\nListCache.prototype.has = listCacheHas;\nListCache.prototype.set = listCacheSet;\n\n/**\n * Creates a map cache object to store key-value pairs.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction MapCache(entries) {\n  var index = -1,\n      length = entries == null ? 0 : entries.length;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n/**\n * Removes all key-value entries from the map.\n *\n * @private\n * @name clear\n * @memberOf MapCache\n */\nfunction mapCacheClear() {\n  this.size = 0;\n  this.__data__ = {\n    'hash': new Hash,\n    'map': new (Map || ListCache),\n    'string': new Hash\n  };\n}\n\n/**\n * Removes `key` and its value from the map.\n *\n * @private\n * @name delete\n * @memberOf MapCache\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction mapCacheDelete(key) {\n  var result = getMapData(this, key)['delete'](key);\n  this.size -= result ? 1 : 0;\n  return result;\n}\n\n/**\n * Gets the map value for `key`.\n *\n * @private\n * @name get\n * @memberOf MapCache\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction mapCacheGet(key) {\n  return getMapData(this, key).get(key);\n}\n\n/**\n * Checks if a map value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf MapCache\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction mapCacheHas(key) {\n  return getMapData(this, key).has(key);\n}\n\n/**\n * Sets the map `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf MapCache\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the map cache instance.\n */\nfunction mapCacheSet(key, value) {\n  var data = getMapData(this, key),\n      size = data.size;\n\n  data.set(key, value);\n  this.size += data.size == size ? 0 : 1;\n  return this;\n}\n\n// Add methods to `MapCache`.\nMapCache.prototype.clear = mapCacheClear;\nMapCache.prototype['delete'] = mapCacheDelete;\nMapCache.prototype.get = mapCacheGet;\nMapCache.prototype.has = mapCacheHas;\nMapCache.prototype.set = mapCacheSet;\n\n/**\n *\n * Creates an array cache object to store unique values.\n *\n * @private\n * @constructor\n * @param {Array} [values] The values to cache.\n */\nfunction SetCache(values) {\n  var index = -1,\n      length = values == null ? 0 : values.length;\n\n  this.__data__ = new MapCache;\n  while (++index < length) {\n    this.add(values[index]);\n  }\n}\n\n/**\n * Adds `value` to the array cache.\n *\n * @private\n * @name add\n * @memberOf SetCache\n * @alias push\n * @param {*} value The value to cache.\n * @returns {Object} Returns the cache instance.\n */\nfunction setCacheAdd(value) {\n  this.__data__.set(value, HASH_UNDEFINED);\n  return this;\n}\n\n/**\n * Checks if `value` is in the array cache.\n *\n * @private\n * @name has\n * @memberOf SetCache\n * @param {*} value The value to search for.\n * @returns {number} Returns `true` if `value` is found, else `false`.\n */\nfunction setCacheHas(value) {\n  return this.__data__.has(value);\n}\n\n// Add methods to `SetCache`.\nSetCache.prototype.add = SetCache.prototype.push = setCacheAdd;\nSetCache.prototype.has = setCacheHas;\n\n/**\n * Creates a stack cache object to store key-value pairs.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction Stack(entries) {\n  var data = this.__data__ = new ListCache(entries);\n  this.size = data.size;\n}\n\n/**\n * Removes all key-value entries from the stack.\n *\n * @private\n * @name clear\n * @memberOf Stack\n */\nfunction stackClear() {\n  this.__data__ = new ListCache;\n  this.size = 0;\n}\n\n/**\n * Removes `key` and its value from the stack.\n *\n * @private\n * @name delete\n * @memberOf Stack\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction stackDelete(key) {\n  var data = this.__data__,\n      result = data['delete'](key);\n\n  this.size = data.size;\n  return result;\n}\n\n/**\n * Gets the stack value for `key`.\n *\n * @private\n * @name get\n * @memberOf Stack\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction stackGet(key) {\n  return this.__data__.get(key);\n}\n\n/**\n * Checks if a stack value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf Stack\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction stackHas(key) {\n  return this.__data__.has(key);\n}\n\n/**\n * Sets the stack `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf Stack\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the stack cache instance.\n */\nfunction stackSet(key, value) {\n  var data = this.__data__;\n  if (data instanceof ListCache) {\n    var pairs = data.__data__;\n    if (!Map || (pairs.length < LARGE_ARRAY_SIZE - 1)) {\n      pairs.push([key, value]);\n      this.size = ++data.size;\n      return this;\n    }\n    data = this.__data__ = new MapCache(pairs);\n  }\n  data.set(key, value);\n  this.size = data.size;\n  return this;\n}\n\n// Add methods to `Stack`.\nStack.prototype.clear = stackClear;\nStack.prototype['delete'] = stackDelete;\nStack.prototype.get = stackGet;\nStack.prototype.has = stackHas;\nStack.prototype.set = stackSet;\n\n/**\n * Creates an array of the enumerable property names of the array-like `value`.\n *\n * @private\n * @param {*} value The value to query.\n * @param {boolean} inherited Specify returning inherited property names.\n * @returns {Array} Returns the array of property names.\n */\nfunction arrayLikeKeys(value, inherited) {\n  var isArr = isArray(value),\n      isArg = !isArr && isArguments(value),\n      isBuff = !isArr && !isArg && isBuffer(value),\n      isType = !isArr && !isArg && !isBuff && isTypedArray(value),\n      skipIndexes = isArr || isArg || isBuff || isType,\n      result = skipIndexes ? baseTimes(value.length, String) : [],\n      length = result.length;\n\n  for (var key in value) {\n    if ((inherited || hasOwnProperty.call(value, key)) &&\n        !(skipIndexes && (\n           // Safari 9 has enumerable `arguments.length` in strict mode.\n           key == 'length' ||\n           // Node.js 0.10 has enumerable non-index properties on buffers.\n           (isBuff && (key == 'offset' || key == 'parent')) ||\n           // PhantomJS 2 has enumerable non-index properties on typed arrays.\n           (isType && (key == 'buffer' || key == 'byteLength' || key == 'byteOffset')) ||\n           // Skip index properties.\n           isIndex(key, length)\n        ))) {\n      result.push(key);\n    }\n  }\n  return result;\n}\n\n/**\n * Gets the index at which the `key` is found in `array` of key-value pairs.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {*} key The key to search for.\n * @returns {number} Returns the index of the matched value, else `-1`.\n */\nfunction assocIndexOf(array, key) {\n  var length = array.length;\n  while (length--) {\n    if (eq(array[length][0], key)) {\n      return length;\n    }\n  }\n  return -1;\n}\n\n/**\n * The base implementation of `getAllKeys` and `getAllKeysIn` which uses\n * `keysFunc` and `symbolsFunc` to get the enumerable property names and\n * symbols of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @param {Function} keysFunc The function to get the keys of `object`.\n * @param {Function} symbolsFunc The function to get the symbols of `object`.\n * @returns {Array} Returns the array of property names and symbols.\n */\nfunction baseGetAllKeys(object, keysFunc, symbolsFunc) {\n  var result = keysFunc(object);\n  return isArray(object) ? result : arrayPush(result, symbolsFunc(object));\n}\n\n/**\n * The base implementation of `getTag` without fallbacks for buggy environments.\n *\n * @private\n * @param {*} value The value to query.\n * @returns {string} Returns the `toStringTag`.\n */\nfunction baseGetTag(value) {\n  if (value == null) {\n    return value === undefined ? undefinedTag : nullTag;\n  }\n  return (symToStringTag && symToStringTag in Object(value))\n    ? getRawTag(value)\n    : objectToString(value);\n}\n\n/**\n * The base implementation of `_.isArguments`.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an `arguments` object,\n */\nfunction baseIsArguments(value) {\n  return isObjectLike(value) && baseGetTag(value) == argsTag;\n}\n\n/**\n * The base implementation of `_.isEqual` which supports partial comparisons\n * and tracks traversed objects.\n *\n * @private\n * @param {*} value The value to compare.\n * @param {*} other The other value to compare.\n * @param {boolean} bitmask The bitmask flags.\n *  1 - Unordered comparison\n *  2 - Partial comparison\n * @param {Function} [customizer] The function to customize comparisons.\n * @param {Object} [stack] Tracks traversed `value` and `other` objects.\n * @returns {boolean} Returns `true` if the values are equivalent, else `false`.\n */\nfunction baseIsEqual(value, other, bitmask, customizer, stack) {\n  if (value === other) {\n    return true;\n  }\n  if (value == null || other == null || (!isObjectLike(value) && !isObjectLike(other))) {\n    return value !== value && other !== other;\n  }\n  return baseIsEqualDeep(value, other, bitmask, customizer, baseIsEqual, stack);\n}\n\n/**\n * A specialized version of `baseIsEqual` for arrays and objects which performs\n * deep comparisons and tracks traversed objects enabling objects with circular\n * references to be compared.\n *\n * @private\n * @param {Object} object The object to compare.\n * @param {Object} other The other object to compare.\n * @param {number} bitmask The bitmask flags. See `baseIsEqual` for more details.\n * @param {Function} customizer The function to customize comparisons.\n * @param {Function} equalFunc The function to determine equivalents of values.\n * @param {Object} [stack] Tracks traversed `object` and `other` objects.\n * @returns {boolean} Returns `true` if the objects are equivalent, else `false`.\n */\nfunction baseIsEqualDeep(object, other, bitmask, customizer, equalFunc, stack) {\n  var objIsArr = isArray(object),\n      othIsArr = isArray(other),\n      objTag = objIsArr ? arrayTag : getTag(object),\n      othTag = othIsArr ? arrayTag : getTag(other);\n\n  objTag = objTag == argsTag ? objectTag : objTag;\n  othTag = othTag == argsTag ? objectTag : othTag;\n\n  var objIsObj = objTag == objectTag,\n      othIsObj = othTag == objectTag,\n      isSameTag = objTag == othTag;\n\n  if (isSameTag && isBuffer(object)) {\n    if (!isBuffer(other)) {\n      return false;\n    }\n    objIsArr = true;\n    objIsObj = false;\n  }\n  if (isSameTag && !objIsObj) {\n    stack || (stack = new Stack);\n    return (objIsArr || isTypedArray(object))\n      ? equalArrays(object, other, bitmask, customizer, equalFunc, stack)\n      : equalByTag(object, other, objTag, bitmask, customizer, equalFunc, stack);\n  }\n  if (!(bitmask & COMPARE_PARTIAL_FLAG)) {\n    var objIsWrapped = objIsObj && hasOwnProperty.call(object, '__wrapped__'),\n        othIsWrapped = othIsObj && hasOwnProperty.call(other, '__wrapped__');\n\n    if (objIsWrapped || othIsWrapped) {\n      var objUnwrapped = objIsWrapped ? object.value() : object,\n          othUnwrapped = othIsWrapped ? other.value() : other;\n\n      stack || (stack = new Stack);\n      return equalFunc(objUnwrapped, othUnwrapped, bitmask, customizer, stack);\n    }\n  }\n  if (!isSameTag) {\n    return false;\n  }\n  stack || (stack = new Stack);\n  return equalObjects(object, other, bitmask, customizer, equalFunc, stack);\n}\n\n/**\n * The base implementation of `_.isNative` without bad shim checks.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a native function,\n *  else `false`.\n */\nfunction baseIsNative(value) {\n  if (!isObject(value) || isMasked(value)) {\n    return false;\n  }\n  var pattern = isFunction(value) ? reIsNative : reIsHostCtor;\n  return pattern.test(toSource(value));\n}\n\n/**\n * The base implementation of `_.isTypedArray` without Node.js optimizations.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a typed array, else `false`.\n */\nfunction baseIsTypedArray(value) {\n  return isObjectLike(value) &&\n    isLength(value.length) && !!typedArrayTags[baseGetTag(value)];\n}\n\n/**\n * The base implementation of `_.keys` which doesn't treat sparse arrays as dense.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n */\nfunction baseKeys(object) {\n  if (!isPrototype(object)) {\n    return nativeKeys(object);\n  }\n  var result = [];\n  for (var key in Object(object)) {\n    if (hasOwnProperty.call(object, key) && key != 'constructor') {\n      result.push(key);\n    }\n  }\n  return result;\n}\n\n/**\n * A specialized version of `baseIsEqualDeep` for arrays with support for\n * partial deep comparisons.\n *\n * @private\n * @param {Array} array The array to compare.\n * @param {Array} other The other array to compare.\n * @param {number} bitmask The bitmask flags. See `baseIsEqual` for more details.\n * @param {Function} customizer The function to customize comparisons.\n * @param {Function} equalFunc The function to determine equivalents of values.\n * @param {Object} stack Tracks traversed `array` and `other` objects.\n * @returns {boolean} Returns `true` if the arrays are equivalent, else `false`.\n */\nfunction equalArrays(array, other, bitmask, customizer, equalFunc, stack) {\n  var isPartial = bitmask & COMPARE_PARTIAL_FLAG,\n      arrLength = array.length,\n      othLength = other.length;\n\n  if (arrLength != othLength && !(isPartial && othLength > arrLength)) {\n    return false;\n  }\n  // Assume cyclic values are equal.\n  var stacked = stack.get(array);\n  if (stacked && stack.get(other)) {\n    return stacked == other;\n  }\n  var index = -1,\n      result = true,\n      seen = (bitmask & COMPARE_UNORDERED_FLAG) ? new SetCache : undefined;\n\n  stack.set(array, other);\n  stack.set(other, array);\n\n  // Ignore non-index properties.\n  while (++index < arrLength) {\n    var arrValue = array[index],\n        othValue = other[index];\n\n    if (customizer) {\n      var compared = isPartial\n        ? customizer(othValue, arrValue, index, other, array, stack)\n        : customizer(arrValue, othValue, index, array, other, stack);\n    }\n    if (compared !== undefined) {\n      if (compared) {\n        continue;\n      }\n      result = false;\n      break;\n    }\n    // Recursively compare arrays (susceptible to call stack limits).\n    if (seen) {\n      if (!arraySome(other, function(othValue, othIndex) {\n            if (!cacheHas(seen, othIndex) &&\n                (arrValue === othValue || equalFunc(arrValue, othValue, bitmask, customizer, stack))) {\n              return seen.push(othIndex);\n            }\n          })) {\n        result = false;\n        break;\n      }\n    } else if (!(\n          arrValue === othValue ||\n            equalFunc(arrValue, othValue, bitmask, customizer, stack)\n        )) {\n      result = false;\n      break;\n    }\n  }\n  stack['delete'](array);\n  stack['delete'](other);\n  return result;\n}\n\n/**\n * A specialized version of `baseIsEqualDeep` for comparing objects of\n * the same `toStringTag`.\n *\n * **Note:** This function only supports comparing values with tags of\n * `Boolean`, `Date`, `Error`, `Number`, `RegExp`, or `String`.\n *\n * @private\n * @param {Object} object The object to compare.\n * @param {Object} other The other object to compare.\n * @param {string} tag The `toStringTag` of the objects to compare.\n * @param {number} bitmask The bitmask flags. See `baseIsEqual` for more details.\n * @param {Function} customizer The function to customize comparisons.\n * @param {Function} equalFunc The function to determine equivalents of values.\n * @param {Object} stack Tracks traversed `object` and `other` objects.\n * @returns {boolean} Returns `true` if the objects are equivalent, else `false`.\n */\nfunction equalByTag(object, other, tag, bitmask, customizer, equalFunc, stack) {\n  switch (tag) {\n    case dataViewTag:\n      if ((object.byteLength != other.byteLength) ||\n          (object.byteOffset != other.byteOffset)) {\n        return false;\n      }\n      object = object.buffer;\n      other = other.buffer;\n\n    case arrayBufferTag:\n      if ((object.byteLength != other.byteLength) ||\n          !equalFunc(new Uint8Array(object), new Uint8Array(other))) {\n        return false;\n      }\n      return true;\n\n    case boolTag:\n    case dateTag:\n    case numberTag:\n      // Coerce booleans to `1` or `0` and dates to milliseconds.\n      // Invalid dates are coerced to `NaN`.\n      return eq(+object, +other);\n\n    case errorTag:\n      return object.name == other.name && object.message == other.message;\n\n    case regexpTag:\n    case stringTag:\n      // Coerce regexes to strings and treat strings, primitives and objects,\n      // as equal. See http://www.ecma-international.org/ecma-262/7.0/#sec-regexp.prototype.tostring\n      // for more details.\n      return object == (other + '');\n\n    case mapTag:\n      var convert = mapToArray;\n\n    case setTag:\n      var isPartial = bitmask & COMPARE_PARTIAL_FLAG;\n      convert || (convert = setToArray);\n\n      if (object.size != other.size && !isPartial) {\n        return false;\n      }\n      // Assume cyclic values are equal.\n      var stacked = stack.get(object);\n      if (stacked) {\n        return stacked == other;\n      }\n      bitmask |= COMPARE_UNORDERED_FLAG;\n\n      // Recursively compare objects (susceptible to call stack limits).\n      stack.set(object, other);\n      var result = equalArrays(convert(object), convert(other), bitmask, customizer, equalFunc, stack);\n      stack['delete'](object);\n      return result;\n\n    case symbolTag:\n      if (symbolValueOf) {\n        return symbolValueOf.call(object) == symbolValueOf.call(other);\n      }\n  }\n  return false;\n}\n\n/**\n * A specialized version of `baseIsEqualDeep` for objects with support for\n * partial deep comparisons.\n *\n * @private\n * @param {Object} object The object to compare.\n * @param {Object} other The other object to compare.\n * @param {number} bitmask The bitmask flags. See `baseIsEqual` for more details.\n * @param {Function} customizer The function to customize comparisons.\n * @param {Function} equalFunc The function to determine equivalents of values.\n * @param {Object} stack Tracks traversed `object` and `other` objects.\n * @returns {boolean} Returns `true` if the objects are equivalent, else `false`.\n */\nfunction equalObjects(object, other, bitmask, customizer, equalFunc, stack) {\n  var isPartial = bitmask & COMPARE_PARTIAL_FLAG,\n      objProps = getAllKeys(object),\n      objLength = objProps.length,\n      othProps = getAllKeys(other),\n      othLength = othProps.length;\n\n  if (objLength != othLength && !isPartial) {\n    return false;\n  }\n  var index = objLength;\n  while (index--) {\n    var key = objProps[index];\n    if (!(isPartial ? key in other : hasOwnProperty.call(other, key))) {\n      return false;\n    }\n  }\n  // Assume cyclic values are equal.\n  var stacked = stack.get(object);\n  if (stacked && stack.get(other)) {\n    return stacked == other;\n  }\n  var result = true;\n  stack.set(object, other);\n  stack.set(other, object);\n\n  var skipCtor = isPartial;\n  while (++index < objLength) {\n    key = objProps[index];\n    var objValue = object[key],\n        othValue = other[key];\n\n    if (customizer) {\n      var compared = isPartial\n        ? customizer(othValue, objValue, key, other, object, stack)\n        : customizer(objValue, othValue, key, object, other, stack);\n    }\n    // Recursively compare objects (susceptible to call stack limits).\n    if (!(compared === undefined\n          ? (objValue === othValue || equalFunc(objValue, othValue, bitmask, customizer, stack))\n          : compared\n        )) {\n      result = false;\n      break;\n    }\n    skipCtor || (skipCtor = key == 'constructor');\n  }\n  if (result && !skipCtor) {\n    var objCtor = object.constructor,\n        othCtor = other.constructor;\n\n    // Non `Object` object instances with different constructors are not equal.\n    if (objCtor != othCtor &&\n        ('constructor' in object && 'constructor' in other) &&\n        !(typeof objCtor == 'function' && objCtor instanceof objCtor &&\n          typeof othCtor == 'function' && othCtor instanceof othCtor)) {\n      result = false;\n    }\n  }\n  stack['delete'](object);\n  stack['delete'](other);\n  return result;\n}\n\n/**\n * Creates an array of own enumerable property names and symbols of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names and symbols.\n */\nfunction getAllKeys(object) {\n  return baseGetAllKeys(object, keys, getSymbols);\n}\n\n/**\n * Gets the data for `map`.\n *\n * @private\n * @param {Object} map The map to query.\n * @param {string} key The reference key.\n * @returns {*} Returns the map data.\n */\nfunction getMapData(map, key) {\n  var data = map.__data__;\n  return isKeyable(key)\n    ? data[typeof key == 'string' ? 'string' : 'hash']\n    : data.map;\n}\n\n/**\n * Gets the native function at `key` of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @param {string} key The key of the method to get.\n * @returns {*} Returns the function if it's native, else `undefined`.\n */\nfunction getNative(object, key) {\n  var value = getValue(object, key);\n  return baseIsNative(value) ? value : undefined;\n}\n\n/**\n * A specialized version of `baseGetTag` which ignores `Symbol.toStringTag` values.\n *\n * @private\n * @param {*} value The value to query.\n * @returns {string} Returns the raw `toStringTag`.\n */\nfunction getRawTag(value) {\n  var isOwn = hasOwnProperty.call(value, symToStringTag),\n      tag = value[symToStringTag];\n\n  try {\n    value[symToStringTag] = undefined;\n    var unmasked = true;\n  } catch (e) {}\n\n  var result = nativeObjectToString.call(value);\n  if (unmasked) {\n    if (isOwn) {\n      value[symToStringTag] = tag;\n    } else {\n      delete value[symToStringTag];\n    }\n  }\n  return result;\n}\n\n/**\n * Creates an array of the own enumerable symbols of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of symbols.\n */\nvar getSymbols = !nativeGetSymbols ? stubArray : function(object) {\n  if (object == null) {\n    return [];\n  }\n  object = Object(object);\n  return arrayFilter(nativeGetSymbols(object), function(symbol) {\n    return propertyIsEnumerable.call(object, symbol);\n  });\n};\n\n/**\n * Gets the `toStringTag` of `value`.\n *\n * @private\n * @param {*} value The value to query.\n * @returns {string} Returns the `toStringTag`.\n */\nvar getTag = baseGetTag;\n\n// Fallback for data views, maps, sets, and weak maps in IE 11 and promises in Node.js < 6.\nif ((DataView && getTag(new DataView(new ArrayBuffer(1))) != dataViewTag) ||\n    (Map && getTag(new Map) != mapTag) ||\n    (Promise && getTag(Promise.resolve()) != promiseTag) ||\n    (Set && getTag(new Set) != setTag) ||\n    (WeakMap && getTag(new WeakMap) != weakMapTag)) {\n  getTag = function(value) {\n    var result = baseGetTag(value),\n        Ctor = result == objectTag ? value.constructor : undefined,\n        ctorString = Ctor ? toSource(Ctor) : '';\n\n    if (ctorString) {\n      switch (ctorString) {\n        case dataViewCtorString: return dataViewTag;\n        case mapCtorString: return mapTag;\n        case promiseCtorString: return promiseTag;\n        case setCtorString: return setTag;\n        case weakMapCtorString: return weakMapTag;\n      }\n    }\n    return result;\n  };\n}\n\n/**\n * Checks if `value` is a valid array-like index.\n *\n * @private\n * @param {*} value The value to check.\n * @param {number} [length=MAX_SAFE_INTEGER] The upper bounds of a valid index.\n * @returns {boolean} Returns `true` if `value` is a valid index, else `false`.\n */\nfunction isIndex(value, length) {\n  length = length == null ? MAX_SAFE_INTEGER : length;\n  return !!length &&\n    (typeof value == 'number' || reIsUint.test(value)) &&\n    (value > -1 && value % 1 == 0 && value < length);\n}\n\n/**\n * Checks if `value` is suitable for use as unique object key.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is suitable, else `false`.\n */\nfunction isKeyable(value) {\n  var type = typeof value;\n  return (type == 'string' || type == 'number' || type == 'symbol' || type == 'boolean')\n    ? (value !== '__proto__')\n    : (value === null);\n}\n\n/**\n * Checks if `func` has its source masked.\n *\n * @private\n * @param {Function} func The function to check.\n * @returns {boolean} Returns `true` if `func` is masked, else `false`.\n */\nfunction isMasked(func) {\n  return !!maskSrcKey && (maskSrcKey in func);\n}\n\n/**\n * Checks if `value` is likely a prototype object.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a prototype, else `false`.\n */\nfunction isPrototype(value) {\n  var Ctor = value && value.constructor,\n      proto = (typeof Ctor == 'function' && Ctor.prototype) || objectProto;\n\n  return value === proto;\n}\n\n/**\n * Converts `value` to a string using `Object.prototype.toString`.\n *\n * @private\n * @param {*} value The value to convert.\n * @returns {string} Returns the converted string.\n */\nfunction objectToString(value) {\n  return nativeObjectToString.call(value);\n}\n\n/**\n * Converts `func` to its source code.\n *\n * @private\n * @param {Function} func The function to convert.\n * @returns {string} Returns the source code.\n */\nfunction toSource(func) {\n  if (func != null) {\n    try {\n      return funcToString.call(func);\n    } catch (e) {}\n    try {\n      return (func + '');\n    } catch (e) {}\n  }\n  return '';\n}\n\n/**\n * Performs a\n * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * comparison between two values to determine if they are equivalent.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to compare.\n * @param {*} other The other value to compare.\n * @returns {boolean} Returns `true` if the values are equivalent, else `false`.\n * @example\n *\n * var object = { 'a': 1 };\n * var other = { 'a': 1 };\n *\n * _.eq(object, object);\n * // => true\n *\n * _.eq(object, other);\n * // => false\n *\n * _.eq('a', 'a');\n * // => true\n *\n * _.eq('a', Object('a'));\n * // => false\n *\n * _.eq(NaN, NaN);\n * // => true\n */\nfunction eq(value, other) {\n  return value === other || (value !== value && other !== other);\n}\n\n/**\n * Checks if `value` is likely an `arguments` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an `arguments` object,\n *  else `false`.\n * @example\n *\n * _.isArguments(function() { return arguments; }());\n * // => true\n *\n * _.isArguments([1, 2, 3]);\n * // => false\n */\nvar isArguments = baseIsArguments(function() { return arguments; }()) ? baseIsArguments : function(value) {\n  return isObjectLike(value) && hasOwnProperty.call(value, 'callee') &&\n    !propertyIsEnumerable.call(value, 'callee');\n};\n\n/**\n * Checks if `value` is classified as an `Array` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an array, else `false`.\n * @example\n *\n * _.isArray([1, 2, 3]);\n * // => true\n *\n * _.isArray(document.body.children);\n * // => false\n *\n * _.isArray('abc');\n * // => false\n *\n * _.isArray(_.noop);\n * // => false\n */\nvar isArray = Array.isArray;\n\n/**\n * Checks if `value` is array-like. A value is considered array-like if it's\n * not a function and has a `value.length` that's an integer greater than or\n * equal to `0` and less than or equal to `Number.MAX_SAFE_INTEGER`.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is array-like, else `false`.\n * @example\n *\n * _.isArrayLike([1, 2, 3]);\n * // => true\n *\n * _.isArrayLike(document.body.children);\n * // => true\n *\n * _.isArrayLike('abc');\n * // => true\n *\n * _.isArrayLike(_.noop);\n * // => false\n */\nfunction isArrayLike(value) {\n  return value != null && isLength(value.length) && !isFunction(value);\n}\n\n/**\n * Checks if `value` is a buffer.\n *\n * @static\n * @memberOf _\n * @since 4.3.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a buffer, else `false`.\n * @example\n *\n * _.isBuffer(new Buffer(2));\n * // => true\n *\n * _.isBuffer(new Uint8Array(2));\n * // => false\n */\nvar isBuffer = nativeIsBuffer || stubFalse;\n\n/**\n * Performs a deep comparison between two values to determine if they are\n * equivalent.\n *\n * **Note:** This method supports comparing arrays, array buffers, booleans,\n * date objects, error objects, maps, numbers, `Object` objects, regexes,\n * sets, strings, symbols, and typed arrays. `Object` objects are compared\n * by their own, not inherited, enumerable properties. Functions and DOM\n * nodes are compared by strict equality, i.e. `===`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to compare.\n * @param {*} other The other value to compare.\n * @returns {boolean} Returns `true` if the values are equivalent, else `false`.\n * @example\n *\n * var object = { 'a': 1 };\n * var other = { 'a': 1 };\n *\n * _.isEqual(object, other);\n * // => true\n *\n * object === other;\n * // => false\n */\nfunction isEqual(value, other) {\n  return baseIsEqual(value, other);\n}\n\n/**\n * Checks if `value` is classified as a `Function` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a function, else `false`.\n * @example\n *\n * _.isFunction(_);\n * // => true\n *\n * _.isFunction(/abc/);\n * // => false\n */\nfunction isFunction(value) {\n  if (!isObject(value)) {\n    return false;\n  }\n  // The use of `Object#toString` avoids issues with the `typeof` operator\n  // in Safari 9 which returns 'object' for typed arrays and other constructors.\n  var tag = baseGetTag(value);\n  return tag == funcTag || tag == genTag || tag == asyncTag || tag == proxyTag;\n}\n\n/**\n * Checks if `value` is a valid array-like length.\n *\n * **Note:** This method is loosely based on\n * [`ToLength`](http://ecma-international.org/ecma-262/7.0/#sec-tolength).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a valid length, else `false`.\n * @example\n *\n * _.isLength(3);\n * // => true\n *\n * _.isLength(Number.MIN_VALUE);\n * // => false\n *\n * _.isLength(Infinity);\n * // => false\n *\n * _.isLength('3');\n * // => false\n */\nfunction isLength(value) {\n  return typeof value == 'number' &&\n    value > -1 && value % 1 == 0 && value <= MAX_SAFE_INTEGER;\n}\n\n/**\n * Checks if `value` is the\n * [language type](http://www.ecma-international.org/ecma-262/7.0/#sec-ecmascript-language-types)\n * of `Object`. (e.g. arrays, functions, objects, regexes, `new Number(0)`, and `new String('')`)\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an object, else `false`.\n * @example\n *\n * _.isObject({});\n * // => true\n *\n * _.isObject([1, 2, 3]);\n * // => true\n *\n * _.isObject(_.noop);\n * // => true\n *\n * _.isObject(null);\n * // => false\n */\nfunction isObject(value) {\n  var type = typeof value;\n  return value != null && (type == 'object' || type == 'function');\n}\n\n/**\n * Checks if `value` is object-like. A value is object-like if it's not `null`\n * and has a `typeof` result of \"object\".\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is object-like, else `false`.\n * @example\n *\n * _.isObjectLike({});\n * // => true\n *\n * _.isObjectLike([1, 2, 3]);\n * // => true\n *\n * _.isObjectLike(_.noop);\n * // => false\n *\n * _.isObjectLike(null);\n * // => false\n */\nfunction isObjectLike(value) {\n  return value != null && typeof value == 'object';\n}\n\n/**\n * Checks if `value` is classified as a typed array.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a typed array, else `false`.\n * @example\n *\n * _.isTypedArray(new Uint8Array);\n * // => true\n *\n * _.isTypedArray([]);\n * // => false\n */\nvar isTypedArray = nodeIsTypedArray ? baseUnary(nodeIsTypedArray) : baseIsTypedArray;\n\n/**\n * Creates an array of the own enumerable property names of `object`.\n *\n * **Note:** Non-object values are coerced to objects. See the\n * [ES spec](http://ecma-international.org/ecma-262/7.0/#sec-object.keys)\n * for more details.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Object\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n * @example\n *\n * function Foo() {\n *   this.a = 1;\n *   this.b = 2;\n * }\n *\n * Foo.prototype.c = 3;\n *\n * _.keys(new Foo);\n * // => ['a', 'b'] (iteration order is not guaranteed)\n *\n * _.keys('hi');\n * // => ['0', '1']\n */\nfunction keys(object) {\n  return isArrayLike(object) ? arrayLikeKeys(object) : baseKeys(object);\n}\n\n/**\n * This method returns a new empty array.\n *\n * @static\n * @memberOf _\n * @since 4.13.0\n * @category Util\n * @returns {Array} Returns the new empty array.\n * @example\n *\n * var arrays = _.times(2, _.stubArray);\n *\n * console.log(arrays);\n * // => [[], []]\n *\n * console.log(arrays[0] === arrays[1]);\n * // => false\n */\nfunction stubArray() {\n  return [];\n}\n\n/**\n * This method returns `false`.\n *\n * @static\n * @memberOf _\n * @since 4.13.0\n * @category Util\n * @returns {boolean} Returns `false`.\n * @example\n *\n * _.times(2, _.stubFalse);\n * // => [false, false]\n */\nfunction stubFalse() {\n  return false;\n}\n\nmodule.exports = isEqual;\n\n\n//# sourceURL=webpack://renderer/./node_modules/lodash.isequal/index.js?");

/***/ }),

/***/ "./node_modules/memory-pager/index.js":
/*!********************************************!*\
  !*** ./node_modules/memory-pager/index.js ***!
  \********************************************/
/***/ ((module) => {

eval("module.exports = Pager\n\nfunction Pager (pageSize, opts) {\n  if (!(this instanceof Pager)) return new Pager(pageSize, opts)\n\n  this.length = 0\n  this.updates = []\n  this.path = new Uint16Array(4)\n  this.pages = new Array(32768)\n  this.maxPages = this.pages.length\n  this.level = 0\n  this.pageSize = pageSize || 1024\n  this.deduplicate = opts ? opts.deduplicate : null\n  this.zeros = this.deduplicate ? alloc(this.deduplicate.length) : null\n}\n\nPager.prototype.updated = function (page) {\n  while (this.deduplicate && page.buffer[page.deduplicate] === this.deduplicate[page.deduplicate]) {\n    page.deduplicate++\n    if (page.deduplicate === this.deduplicate.length) {\n      page.deduplicate = 0\n      if (page.buffer.equals && page.buffer.equals(this.deduplicate)) page.buffer = this.deduplicate\n      break\n    }\n  }\n  if (page.updated || !this.updates) return\n  page.updated = true\n  this.updates.push(page)\n}\n\nPager.prototype.lastUpdate = function () {\n  if (!this.updates || !this.updates.length) return null\n  var page = this.updates.pop()\n  page.updated = false\n  return page\n}\n\nPager.prototype._array = function (i, noAllocate) {\n  if (i >= this.maxPages) {\n    if (noAllocate) return\n    grow(this, i)\n  }\n\n  factor(i, this.path)\n\n  var arr = this.pages\n\n  for (var j = this.level; j > 0; j--) {\n    var p = this.path[j]\n    var next = arr[p]\n\n    if (!next) {\n      if (noAllocate) return\n      next = arr[p] = new Array(32768)\n    }\n\n    arr = next\n  }\n\n  return arr\n}\n\nPager.prototype.get = function (i, noAllocate) {\n  var arr = this._array(i, noAllocate)\n  var first = this.path[0]\n  var page = arr && arr[first]\n\n  if (!page && !noAllocate) {\n    page = arr[first] = new Page(i, alloc(this.pageSize))\n    if (i >= this.length) this.length = i + 1\n  }\n\n  if (page && page.buffer === this.deduplicate && this.deduplicate && !noAllocate) {\n    page.buffer = copy(page.buffer)\n    page.deduplicate = 0\n  }\n\n  return page\n}\n\nPager.prototype.set = function (i, buf) {\n  var arr = this._array(i, false)\n  var first = this.path[0]\n\n  if (i >= this.length) this.length = i + 1\n\n  if (!buf || (this.zeros && buf.equals && buf.equals(this.zeros))) {\n    arr[first] = undefined\n    return\n  }\n\n  if (this.deduplicate && buf.equals && buf.equals(this.deduplicate)) {\n    buf = this.deduplicate\n  }\n\n  var page = arr[first]\n  var b = truncate(buf, this.pageSize)\n\n  if (page) page.buffer = b\n  else arr[first] = new Page(i, b)\n}\n\nPager.prototype.toBuffer = function () {\n  var list = new Array(this.length)\n  var empty = alloc(this.pageSize)\n  var ptr = 0\n\n  while (ptr < list.length) {\n    var arr = this._array(ptr, true)\n    for (var i = 0; i < 32768 && ptr < list.length; i++) {\n      list[ptr++] = (arr && arr[i]) ? arr[i].buffer : empty\n    }\n  }\n\n  return Buffer.concat(list)\n}\n\nfunction grow (pager, index) {\n  while (pager.maxPages < index) {\n    var old = pager.pages\n    pager.pages = new Array(32768)\n    pager.pages[0] = old\n    pager.level++\n    pager.maxPages *= 32768\n  }\n}\n\nfunction truncate (buf, len) {\n  if (buf.length === len) return buf\n  if (buf.length > len) return buf.slice(0, len)\n  var cpy = alloc(len)\n  buf.copy(cpy)\n  return cpy\n}\n\nfunction alloc (size) {\n  if (Buffer.alloc) return Buffer.alloc(size)\n  var buf = new Buffer(size)\n  buf.fill(0)\n  return buf\n}\n\nfunction copy (buf) {\n  var cpy = Buffer.allocUnsafe ? Buffer.allocUnsafe(buf.length) : new Buffer(buf.length)\n  buf.copy(cpy)\n  return cpy\n}\n\nfunction Page (i, buf) {\n  this.offset = i * buf.length\n  this.buffer = buf\n  this.updated = false\n  this.deduplicate = 0\n}\n\nfunction factor (n, out) {\n  n = (n - (out[0] = (n & 32767))) / 32768\n  n = (n - (out[1] = (n & 32767))) / 32768\n  out[3] = ((n - (out[2] = (n & 32767))) / 32768) & 32767\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/memory-pager/index.js?");

/***/ }),

/***/ "./node_modules/mongodb-connection-string-url/lib/index.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mongodb-connection-string-url/lib/index.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CommaAndColonSeparatedRecord = exports.ConnectionString = exports.redactConnectionString = void 0;\nconst whatwg_url_1 = __webpack_require__(/*! whatwg-url */ \"./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/index.js\");\nconst redact_1 = __webpack_require__(/*! ./redact */ \"./node_modules/mongodb-connection-string-url/lib/redact.js\");\nObject.defineProperty(exports, \"redactConnectionString\", ({ enumerable: true, get: function () { return redact_1.redactConnectionString; } }));\nconst DUMMY_HOSTNAME = '__this_is_a_placeholder__';\nfunction connectionStringHasValidScheme(connectionString) {\n    return (connectionString.startsWith('mongodb://') ||\n        connectionString.startsWith('mongodb+srv://'));\n}\nconst HOSTS_REGEX = /^(?<protocol>[^/]+):\\/\\/(?:(?<username>[^:@]*)(?::(?<password>[^@]*))?@)?(?<hosts>(?!:)[^/?@]*)(?<rest>.*)/;\nclass CaseInsensitiveMap extends Map {\n    delete(name) {\n        return super.delete(this._normalizeKey(name));\n    }\n    get(name) {\n        return super.get(this._normalizeKey(name));\n    }\n    has(name) {\n        return super.has(this._normalizeKey(name));\n    }\n    set(name, value) {\n        return super.set(this._normalizeKey(name), value);\n    }\n    _normalizeKey(name) {\n        name = `${name}`;\n        for (const key of this.keys()) {\n            if (key.toLowerCase() === name.toLowerCase()) {\n                name = key;\n                break;\n            }\n        }\n        return name;\n    }\n}\nfunction caseInsenstiveURLSearchParams(Ctor) {\n    return class CaseInsenstiveURLSearchParams extends Ctor {\n        append(name, value) {\n            return super.append(this._normalizeKey(name), value);\n        }\n        delete(name) {\n            return super.delete(this._normalizeKey(name));\n        }\n        get(name) {\n            return super.get(this._normalizeKey(name));\n        }\n        getAll(name) {\n            return super.getAll(this._normalizeKey(name));\n        }\n        has(name) {\n            return super.has(this._normalizeKey(name));\n        }\n        set(name, value) {\n            return super.set(this._normalizeKey(name), value);\n        }\n        keys() {\n            return super.keys();\n        }\n        values() {\n            return super.values();\n        }\n        entries() {\n            return super.entries();\n        }\n        [Symbol.iterator]() {\n            return super[Symbol.iterator]();\n        }\n        _normalizeKey(name) {\n            return CaseInsensitiveMap.prototype._normalizeKey.call(this, name);\n        }\n    };\n}\nclass URLWithoutHost extends whatwg_url_1.URL {\n}\nclass MongoParseError extends Error {\n    get name() {\n        return 'MongoParseError';\n    }\n}\nclass ConnectionString extends URLWithoutHost {\n    constructor(uri, options = {}) {\n        var _a;\n        const { looseValidation } = options;\n        if (!looseValidation && !connectionStringHasValidScheme(uri)) {\n            throw new MongoParseError('Invalid scheme, expected connection string to start with \"mongodb://\" or \"mongodb+srv://\"');\n        }\n        const match = uri.match(HOSTS_REGEX);\n        if (!match) {\n            throw new MongoParseError(`Invalid connection string \"${uri}\"`);\n        }\n        const { protocol, username, password, hosts, rest } = (_a = match.groups) !== null && _a !== void 0 ? _a : {};\n        if (!looseValidation) {\n            if (!protocol || !hosts) {\n                throw new MongoParseError(`Protocol and host list are required in \"${uri}\"`);\n            }\n            try {\n                decodeURIComponent(username !== null && username !== void 0 ? username : '');\n                decodeURIComponent(password !== null && password !== void 0 ? password : '');\n            }\n            catch (err) {\n                throw new MongoParseError(err.message);\n            }\n            const illegalCharacters = /[:/?#[\\]@]/gi;\n            if (username === null || username === void 0 ? void 0 : username.match(illegalCharacters)) {\n                throw new MongoParseError(`Username contains unescaped characters ${username}`);\n            }\n            if (!username || !password) {\n                const uriWithoutProtocol = uri.replace(`${protocol}://`, '');\n                if (uriWithoutProtocol.startsWith('@') || uriWithoutProtocol.startsWith(':')) {\n                    throw new MongoParseError('URI contained empty userinfo section');\n                }\n            }\n            if (password === null || password === void 0 ? void 0 : password.match(illegalCharacters)) {\n                throw new MongoParseError('Password contains unescaped characters');\n            }\n        }\n        let authString = '';\n        if (typeof username === 'string')\n            authString += username;\n        if (typeof password === 'string')\n            authString += `:${password}`;\n        if (authString)\n            authString += '@';\n        try {\n            super(`${protocol.toLowerCase()}://${authString}${DUMMY_HOSTNAME}${rest}`);\n        }\n        catch (err) {\n            if (looseValidation) {\n                new ConnectionString(uri, {\n                    ...options,\n                    looseValidation: false\n                });\n            }\n            if (typeof err.message === 'string') {\n                err.message = err.message.replace(DUMMY_HOSTNAME, hosts);\n            }\n            throw err;\n        }\n        this._hosts = hosts.split(',');\n        if (!looseValidation) {\n            if (this.isSRV && this.hosts.length !== 1) {\n                throw new MongoParseError('mongodb+srv URI cannot have multiple service names');\n            }\n            if (this.isSRV && this.hosts.some(host => host.includes(':'))) {\n                throw new MongoParseError('mongodb+srv URI cannot have port number');\n            }\n        }\n        if (!this.pathname) {\n            this.pathname = '/';\n        }\n        Object.setPrototypeOf(this.searchParams, caseInsenstiveURLSearchParams(this.searchParams.constructor).prototype);\n    }\n    get host() { return DUMMY_HOSTNAME; }\n    set host(_ignored) { throw new Error('No single host for connection string'); }\n    get hostname() { return DUMMY_HOSTNAME; }\n    set hostname(_ignored) { throw new Error('No single host for connection string'); }\n    get port() { return ''; }\n    set port(_ignored) { throw new Error('No single host for connection string'); }\n    get href() { return this.toString(); }\n    set href(_ignored) { throw new Error('Cannot set href for connection strings'); }\n    get isSRV() {\n        return this.protocol.includes('srv');\n    }\n    get hosts() {\n        return this._hosts;\n    }\n    set hosts(list) {\n        this._hosts = list;\n    }\n    toString() {\n        return super.toString().replace(DUMMY_HOSTNAME, this.hosts.join(','));\n    }\n    clone() {\n        return new ConnectionString(this.toString(), {\n            looseValidation: true\n        });\n    }\n    redact(options) {\n        return (0, redact_1.redactValidConnectionString)(this, options);\n    }\n    typedSearchParams() {\n        const sametype =  false && 0;\n        return this.searchParams;\n    }\n    [Symbol.for('nodejs.util.inspect.custom')]() {\n        const { href, origin, protocol, username, password, hosts, pathname, search, searchParams, hash } = this;\n        return { href, origin, protocol, username, password, hosts, pathname, search, searchParams, hash };\n    }\n}\nexports.ConnectionString = ConnectionString;\nclass CommaAndColonSeparatedRecord extends CaseInsensitiveMap {\n    constructor(from) {\n        super();\n        for (const entry of (from !== null && from !== void 0 ? from : '').split(',')) {\n            if (!entry)\n                continue;\n            const colonIndex = entry.indexOf(':');\n            if (colonIndex === -1) {\n                this.set(entry, '');\n            }\n            else {\n                this.set(entry.slice(0, colonIndex), entry.slice(colonIndex + 1));\n            }\n        }\n    }\n    toString() {\n        return [...this].map(entry => entry.join(':')).join(',');\n    }\n}\nexports.CommaAndColonSeparatedRecord = CommaAndColonSeparatedRecord;\nexports[\"default\"] = ConnectionString;\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb-connection-string-url/lib/index.js?");

/***/ }),

/***/ "./node_modules/mongodb-connection-string-url/lib/redact.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongodb-connection-string-url/lib/redact.js ***!
  \******************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.redactConnectionString = exports.redactValidConnectionString = void 0;\nconst index_1 = __importStar(__webpack_require__(/*! ./index */ \"./node_modules/mongodb-connection-string-url/lib/index.js\"));\nfunction redactValidConnectionString(inputUrl, options) {\n    var _a, _b;\n    const url = inputUrl.clone();\n    const replacementString = (_a = options === null || options === void 0 ? void 0 : options.replacementString) !== null && _a !== void 0 ? _a : '_credentials_';\n    const redactUsernames = (_b = options === null || options === void 0 ? void 0 : options.redactUsernames) !== null && _b !== void 0 ? _b : true;\n    if ((url.username || url.password) && redactUsernames) {\n        url.username = replacementString;\n        url.password = '';\n    }\n    else if (url.password) {\n        url.password = replacementString;\n    }\n    if (url.searchParams.has('authMechanismProperties')) {\n        const props = new index_1.CommaAndColonSeparatedRecord(url.searchParams.get('authMechanismProperties'));\n        if (props.get('AWS_SESSION_TOKEN')) {\n            props.set('AWS_SESSION_TOKEN', replacementString);\n            url.searchParams.set('authMechanismProperties', props.toString());\n        }\n    }\n    if (url.searchParams.has('tlsCertificateKeyFilePassword')) {\n        url.searchParams.set('tlsCertificateKeyFilePassword', replacementString);\n    }\n    if (url.searchParams.has('proxyUsername') && redactUsernames) {\n        url.searchParams.set('proxyUsername', replacementString);\n    }\n    if (url.searchParams.has('proxyPassword')) {\n        url.searchParams.set('proxyPassword', replacementString);\n    }\n    return url;\n}\nexports.redactValidConnectionString = redactValidConnectionString;\nfunction redactConnectionString(uri, options) {\n    var _a, _b;\n    const replacementString = (_a = options === null || options === void 0 ? void 0 : options.replacementString) !== null && _a !== void 0 ? _a : '<credentials>';\n    const redactUsernames = (_b = options === null || options === void 0 ? void 0 : options.redactUsernames) !== null && _b !== void 0 ? _b : true;\n    let parsed;\n    try {\n        parsed = new index_1.default(uri);\n    }\n    catch (_c) { }\n    if (parsed) {\n        options = { ...options, replacementString: '___credentials___' };\n        return parsed.redact(options).toString().replace(/___credentials___/g, replacementString);\n    }\n    const R = replacementString;\n    const replacements = [\n        uri => uri.replace(redactUsernames ? /(\\/\\/)(.*)(@)/g : /(\\/\\/[^@]*:)(.*)(@)/g, `$1${R}$3`),\n        uri => uri.replace(/(AWS_SESSION_TOKEN(:|%3A))([^,&]+)/gi, `$1${R}`),\n        uri => uri.replace(/(tlsCertificateKeyFilePassword=)([^&]+)/gi, `$1${R}`),\n        uri => redactUsernames ? uri.replace(/(proxyUsername=)([^&]+)/gi, `$1${R}`) : uri,\n        uri => uri.replace(/(proxyPassword=)([^&]+)/gi, `$1${R}`)\n    ];\n    for (const replacer of replacements) {\n        uri = replacer(uri);\n    }\n    return uri;\n}\nexports.redactConnectionString = redactConnectionString;\n//# sourceMappingURL=redact.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb-connection-string-url/lib/redact.js?");

/***/ }),

/***/ "./node_modules/mongodb-connection-string-url/node_modules/tr46/index.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/mongodb-connection-string-url/node_modules/tr46/index.js ***!
  \*******************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst punycode = __webpack_require__(/*! punycode/ */ \"./node_modules/punycode/punycode.es6.js\");\nconst regexes = __webpack_require__(/*! ./lib/regexes.js */ \"./node_modules/mongodb-connection-string-url/node_modules/tr46/lib/regexes.js\");\nconst mappingTable = __webpack_require__(/*! ./lib/mappingTable.json */ \"./node_modules/mongodb-connection-string-url/node_modules/tr46/lib/mappingTable.json\");\nconst { STATUS_MAPPING } = __webpack_require__(/*! ./lib/statusMapping.js */ \"./node_modules/mongodb-connection-string-url/node_modules/tr46/lib/statusMapping.js\");\n\nfunction containsNonASCII(str) {\n  return /[^\\x00-\\x7F]/u.test(str);\n}\n\nfunction findStatus(val, { useSTD3ASCIIRules }) {\n  let start = 0;\n  let end = mappingTable.length - 1;\n\n  while (start <= end) {\n    const mid = Math.floor((start + end) / 2);\n\n    const target = mappingTable[mid];\n    const min = Array.isArray(target[0]) ? target[0][0] : target[0];\n    const max = Array.isArray(target[0]) ? target[0][1] : target[0];\n\n    if (min <= val && max >= val) {\n      if (useSTD3ASCIIRules &&\n          (target[1] === STATUS_MAPPING.disallowed_STD3_valid || target[1] === STATUS_MAPPING.disallowed_STD3_mapped)) {\n        return [STATUS_MAPPING.disallowed, ...target.slice(2)];\n      } else if (target[1] === STATUS_MAPPING.disallowed_STD3_valid) {\n        return [STATUS_MAPPING.valid, ...target.slice(2)];\n      } else if (target[1] === STATUS_MAPPING.disallowed_STD3_mapped) {\n        return [STATUS_MAPPING.mapped, ...target.slice(2)];\n      }\n\n      return target.slice(1);\n    } else if (min > val) {\n      end = mid - 1;\n    } else {\n      start = mid + 1;\n    }\n  }\n\n  return null;\n}\n\nfunction mapChars(domainName, { useSTD3ASCIIRules, processingOption }) {\n  let hasError = false;\n  let processed = \"\";\n\n  for (const ch of domainName) {\n    const [status, mapping] = findStatus(ch.codePointAt(0), { useSTD3ASCIIRules });\n\n    switch (status) {\n      case STATUS_MAPPING.disallowed:\n        hasError = true;\n        processed += ch;\n        break;\n      case STATUS_MAPPING.ignored:\n        break;\n      case STATUS_MAPPING.mapped:\n        processed += mapping;\n        break;\n      case STATUS_MAPPING.deviation:\n        if (processingOption === \"transitional\") {\n          processed += mapping;\n        } else {\n          processed += ch;\n        }\n        break;\n      case STATUS_MAPPING.valid:\n        processed += ch;\n        break;\n    }\n  }\n\n  return {\n    string: processed,\n    error: hasError\n  };\n}\n\nfunction validateLabel(label, { checkHyphens, checkBidi, checkJoiners, processingOption, useSTD3ASCIIRules }) {\n  if (label.normalize(\"NFC\") !== label) {\n    return false;\n  }\n\n  const codePoints = Array.from(label);\n\n  if (checkHyphens) {\n    if ((codePoints[2] === \"-\" && codePoints[3] === \"-\") ||\n        (label.startsWith(\"-\") || label.endsWith(\"-\"))) {\n      return false;\n    }\n  }\n\n  if (label.includes(\".\") ||\n      (codePoints.length > 0 && regexes.combiningMarks.test(codePoints[0]))) {\n    return false;\n  }\n\n  for (const ch of codePoints) {\n    const [status] = findStatus(ch.codePointAt(0), { useSTD3ASCIIRules });\n    if ((processingOption === \"transitional\" && status !== STATUS_MAPPING.valid) ||\n        (processingOption === \"nontransitional\" &&\n         status !== STATUS_MAPPING.valid && status !== STATUS_MAPPING.deviation)) {\n      return false;\n    }\n  }\n\n  // https://tools.ietf.org/html/rfc5892#appendix-A\n  if (checkJoiners) {\n    let last = 0;\n    for (const [i, ch] of codePoints.entries()) {\n      if (ch === \"\\u200C\" || ch === \"\\u200D\") {\n        if (i > 0) {\n          if (regexes.combiningClassVirama.test(codePoints[i - 1])) {\n            continue;\n          }\n          if (ch === \"\\u200C\") {\n            // TODO: make this more efficient\n            const next = codePoints.indexOf(\"\\u200C\", i + 1);\n            const test = next < 0 ? codePoints.slice(last) : codePoints.slice(last, next);\n            if (regexes.validZWNJ.test(test.join(\"\"))) {\n              last = i + 1;\n              continue;\n            }\n          }\n        }\n        return false;\n      }\n    }\n  }\n\n  // https://tools.ietf.org/html/rfc5893#section-2\n  // For the codePoints length check, see discussion in https://github.com/jsdom/whatwg-url/pull/250 and the second item\n  // in https://github.com/whatwg/url/issues/744.\n  if (checkBidi && codePoints.length > 0) {\n    let rtl;\n\n    // 1\n    if (regexes.bidiS1LTR.test(codePoints[0])) {\n      rtl = false;\n    } else if (regexes.bidiS1RTL.test(codePoints[0])) {\n      rtl = true;\n    } else {\n      return false;\n    }\n\n    if (rtl) {\n      // 2-4\n      if (!regexes.bidiS2.test(label) ||\n          !regexes.bidiS3.test(label) ||\n          (regexes.bidiS4EN.test(label) && regexes.bidiS4AN.test(label))) {\n        return false;\n      }\n    } else if (!regexes.bidiS5.test(label) ||\n               !regexes.bidiS6.test(label)) { // 5-6\n      return false;\n    }\n  }\n\n  return true;\n}\n\nfunction isBidiDomain(labels) {\n  const domain = labels.map(label => {\n    if (label.startsWith(\"xn--\")) {\n      try {\n        return punycode.decode(label.substring(4));\n      } catch (err) {\n        return \"\";\n      }\n    }\n    return label;\n  }).join(\".\");\n  return regexes.bidiDomain.test(domain);\n}\n\nfunction processing(domainName, options) {\n  const { processingOption } = options;\n\n  // 1. Map.\n  let { string, error } = mapChars(domainName, options);\n\n  // 2. Normalize.\n  string = string.normalize(\"NFC\");\n\n  // 3. Break.\n  const labels = string.split(\".\");\n  const isBidi = isBidiDomain(labels);\n\n  // 4. Convert/Validate.\n  for (const [i, origLabel] of labels.entries()) {\n    let label = origLabel;\n    let curProcessing = processingOption;\n    if (label.startsWith(\"xn--\")) {\n      try {\n        label = punycode.decode(label.substring(4));\n        labels[i] = label;\n      } catch (err) {\n        error = true;\n        continue;\n      }\n      curProcessing = \"nontransitional\";\n    }\n\n    // No need to validate if we already know there is an error.\n    if (error) {\n      continue;\n    }\n    const validation = validateLabel(label, {\n      ...options,\n      processingOption: curProcessing,\n      checkBidi: options.checkBidi && isBidi\n    });\n    if (!validation) {\n      error = true;\n    }\n  }\n\n  return {\n    string: labels.join(\".\"),\n    error\n  };\n}\n\nfunction toASCII(domainName, {\n  checkHyphens = false,\n  checkBidi = false,\n  checkJoiners = false,\n  useSTD3ASCIIRules = false,\n  processingOption = \"nontransitional\",\n  verifyDNSLength = false\n} = {}) {\n  if (processingOption !== \"transitional\" && processingOption !== \"nontransitional\") {\n    throw new RangeError(\"processingOption must be either transitional or nontransitional\");\n  }\n\n  const result = processing(domainName, {\n    processingOption,\n    checkHyphens,\n    checkBidi,\n    checkJoiners,\n    useSTD3ASCIIRules\n  });\n  let labels = result.string.split(\".\");\n  labels = labels.map(l => {\n    if (containsNonASCII(l)) {\n      try {\n        return `xn--${punycode.encode(l)}`;\n      } catch (e) {\n        result.error = true;\n      }\n    }\n    return l;\n  });\n\n  if (verifyDNSLength) {\n    const total = labels.join(\".\").length;\n    if (total > 253 || total === 0) {\n      result.error = true;\n    }\n\n    for (let i = 0; i < labels.length; ++i) {\n      if (labels[i].length > 63 || labels[i].length === 0) {\n        result.error = true;\n        break;\n      }\n    }\n  }\n\n  if (result.error) {\n    return null;\n  }\n  return labels.join(\".\");\n}\n\nfunction toUnicode(domainName, {\n  checkHyphens = false,\n  checkBidi = false,\n  checkJoiners = false,\n  useSTD3ASCIIRules = false,\n  processingOption = \"nontransitional\"\n} = {}) {\n  const result = processing(domainName, {\n    processingOption,\n    checkHyphens,\n    checkBidi,\n    checkJoiners,\n    useSTD3ASCIIRules\n  });\n\n  return {\n    domain: result.string,\n    error: result.error\n  };\n}\n\nmodule.exports = {\n  toASCII,\n  toUnicode\n};\n\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb-connection-string-url/node_modules/tr46/index.js?");

/***/ }),

/***/ "./node_modules/mongodb-connection-string-url/node_modules/tr46/lib/regexes.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/mongodb-connection-string-url/node_modules/tr46/lib/regexes.js ***!
  \*************************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nconst combiningMarks = /[\\u0300-\\u036F\\u0483-\\u0489\\u0591-\\u05BD\\u05BF\\u05C1\\u05C2\\u05C4\\u05C5\\u05C7\\u0610-\\u061A\\u064B-\\u065F\\u0670\\u06D6-\\u06DC\\u06DF-\\u06E4\\u06E7\\u06E8\\u06EA-\\u06ED\\u0711\\u0730-\\u074A\\u07A6-\\u07B0\\u07EB-\\u07F3\\u07FD\\u0816-\\u0819\\u081B-\\u0823\\u0825-\\u0827\\u0829-\\u082D\\u0859-\\u085B\\u0898-\\u089F\\u08CA-\\u08E1\\u08E3-\\u0903\\u093A-\\u093C\\u093E-\\u094F\\u0951-\\u0957\\u0962\\u0963\\u0981-\\u0983\\u09BC\\u09BE-\\u09C4\\u09C7\\u09C8\\u09CB-\\u09CD\\u09D7\\u09E2\\u09E3\\u09FE\\u0A01-\\u0A03\\u0A3C\\u0A3E-\\u0A42\\u0A47\\u0A48\\u0A4B-\\u0A4D\\u0A51\\u0A70\\u0A71\\u0A75\\u0A81-\\u0A83\\u0ABC\\u0ABE-\\u0AC5\\u0AC7-\\u0AC9\\u0ACB-\\u0ACD\\u0AE2\\u0AE3\\u0AFA-\\u0AFF\\u0B01-\\u0B03\\u0B3C\\u0B3E-\\u0B44\\u0B47\\u0B48\\u0B4B-\\u0B4D\\u0B55-\\u0B57\\u0B62\\u0B63\\u0B82\\u0BBE-\\u0BC2\\u0BC6-\\u0BC8\\u0BCA-\\u0BCD\\u0BD7\\u0C00-\\u0C04\\u0C3C\\u0C3E-\\u0C44\\u0C46-\\u0C48\\u0C4A-\\u0C4D\\u0C55\\u0C56\\u0C62\\u0C63\\u0C81-\\u0C83\\u0CBC\\u0CBE-\\u0CC4\\u0CC6-\\u0CC8\\u0CCA-\\u0CCD\\u0CD5\\u0CD6\\u0CE2\\u0CE3\\u0CF3\\u0D00-\\u0D03\\u0D3B\\u0D3C\\u0D3E-\\u0D44\\u0D46-\\u0D48\\u0D4A-\\u0D4D\\u0D57\\u0D62\\u0D63\\u0D81-\\u0D83\\u0DCA\\u0DCF-\\u0DD4\\u0DD6\\u0DD8-\\u0DDF\\u0DF2\\u0DF3\\u0E31\\u0E34-\\u0E3A\\u0E47-\\u0E4E\\u0EB1\\u0EB4-\\u0EBC\\u0EC8-\\u0ECE\\u0F18\\u0F19\\u0F35\\u0F37\\u0F39\\u0F3E\\u0F3F\\u0F71-\\u0F84\\u0F86\\u0F87\\u0F8D-\\u0F97\\u0F99-\\u0FBC\\u0FC6\\u102B-\\u103E\\u1056-\\u1059\\u105E-\\u1060\\u1062-\\u1064\\u1067-\\u106D\\u1071-\\u1074\\u1082-\\u108D\\u108F\\u109A-\\u109D\\u135D-\\u135F\\u1712-\\u1715\\u1732-\\u1734\\u1752\\u1753\\u1772\\u1773\\u17B4-\\u17D3\\u17DD\\u180B-\\u180D\\u180F\\u1885\\u1886\\u18A9\\u1920-\\u192B\\u1930-\\u193B\\u1A17-\\u1A1B\\u1A55-\\u1A5E\\u1A60-\\u1A7C\\u1A7F\\u1AB0-\\u1ACE\\u1B00-\\u1B04\\u1B34-\\u1B44\\u1B6B-\\u1B73\\u1B80-\\u1B82\\u1BA1-\\u1BAD\\u1BE6-\\u1BF3\\u1C24-\\u1C37\\u1CD0-\\u1CD2\\u1CD4-\\u1CE8\\u1CED\\u1CF4\\u1CF7-\\u1CF9\\u1DC0-\\u1DFF\\u20D0-\\u20F0\\u2CEF-\\u2CF1\\u2D7F\\u2DE0-\\u2DFF\\u302A-\\u302F\\u3099\\u309A\\uA66F-\\uA672\\uA674-\\uA67D\\uA69E\\uA69F\\uA6F0\\uA6F1\\uA802\\uA806\\uA80B\\uA823-\\uA827\\uA82C\\uA880\\uA881\\uA8B4-\\uA8C5\\uA8E0-\\uA8F1\\uA8FF\\uA926-\\uA92D\\uA947-\\uA953\\uA980-\\uA983\\uA9B3-\\uA9C0\\uA9E5\\uAA29-\\uAA36\\uAA43\\uAA4C\\uAA4D\\uAA7B-\\uAA7D\\uAAB0\\uAAB2-\\uAAB4\\uAAB7\\uAAB8\\uAABE\\uAABF\\uAAC1\\uAAEB-\\uAAEF\\uAAF5\\uAAF6\\uABE3-\\uABEA\\uABEC\\uABED\\uFB1E\\uFE00-\\uFE0F\\uFE20-\\uFE2F\\u{101FD}\\u{102E0}\\u{10376}-\\u{1037A}\\u{10A01}-\\u{10A03}\\u{10A05}\\u{10A06}\\u{10A0C}-\\u{10A0F}\\u{10A38}-\\u{10A3A}\\u{10A3F}\\u{10AE5}\\u{10AE6}\\u{10D24}-\\u{10D27}\\u{10EAB}\\u{10EAC}\\u{10EFD}-\\u{10EFF}\\u{10F46}-\\u{10F50}\\u{10F82}-\\u{10F85}\\u{11000}-\\u{11002}\\u{11038}-\\u{11046}\\u{11070}\\u{11073}\\u{11074}\\u{1107F}-\\u{11082}\\u{110B0}-\\u{110BA}\\u{110C2}\\u{11100}-\\u{11102}\\u{11127}-\\u{11134}\\u{11145}\\u{11146}\\u{11173}\\u{11180}-\\u{11182}\\u{111B3}-\\u{111C0}\\u{111C9}-\\u{111CC}\\u{111CE}\\u{111CF}\\u{1122C}-\\u{11237}\\u{1123E}\\u{11241}\\u{112DF}-\\u{112EA}\\u{11300}-\\u{11303}\\u{1133B}\\u{1133C}\\u{1133E}-\\u{11344}\\u{11347}\\u{11348}\\u{1134B}-\\u{1134D}\\u{11357}\\u{11362}\\u{11363}\\u{11366}-\\u{1136C}\\u{11370}-\\u{11374}\\u{11435}-\\u{11446}\\u{1145E}\\u{114B0}-\\u{114C3}\\u{115AF}-\\u{115B5}\\u{115B8}-\\u{115C0}\\u{115DC}\\u{115DD}\\u{11630}-\\u{11640}\\u{116AB}-\\u{116B7}\\u{1171D}-\\u{1172B}\\u{1182C}-\\u{1183A}\\u{11930}-\\u{11935}\\u{11937}\\u{11938}\\u{1193B}-\\u{1193E}\\u{11940}\\u{11942}\\u{11943}\\u{119D1}-\\u{119D7}\\u{119DA}-\\u{119E0}\\u{119E4}\\u{11A01}-\\u{11A0A}\\u{11A33}-\\u{11A39}\\u{11A3B}-\\u{11A3E}\\u{11A47}\\u{11A51}-\\u{11A5B}\\u{11A8A}-\\u{11A99}\\u{11C2F}-\\u{11C36}\\u{11C38}-\\u{11C3F}\\u{11C92}-\\u{11CA7}\\u{11CA9}-\\u{11CB6}\\u{11D31}-\\u{11D36}\\u{11D3A}\\u{11D3C}\\u{11D3D}\\u{11D3F}-\\u{11D45}\\u{11D47}\\u{11D8A}-\\u{11D8E}\\u{11D90}\\u{11D91}\\u{11D93}-\\u{11D97}\\u{11EF3}-\\u{11EF6}\\u{11F00}\\u{11F01}\\u{11F03}\\u{11F34}-\\u{11F3A}\\u{11F3E}-\\u{11F42}\\u{13440}\\u{13447}-\\u{13455}\\u{16AF0}-\\u{16AF4}\\u{16B30}-\\u{16B36}\\u{16F4F}\\u{16F51}-\\u{16F87}\\u{16F8F}-\\u{16F92}\\u{16FE4}\\u{16FF0}\\u{16FF1}\\u{1BC9D}\\u{1BC9E}\\u{1CF00}-\\u{1CF2D}\\u{1CF30}-\\u{1CF46}\\u{1D165}-\\u{1D169}\\u{1D16D}-\\u{1D172}\\u{1D17B}-\\u{1D182}\\u{1D185}-\\u{1D18B}\\u{1D1AA}-\\u{1D1AD}\\u{1D242}-\\u{1D244}\\u{1DA00}-\\u{1DA36}\\u{1DA3B}-\\u{1DA6C}\\u{1DA75}\\u{1DA84}\\u{1DA9B}-\\u{1DA9F}\\u{1DAA1}-\\u{1DAAF}\\u{1E000}-\\u{1E006}\\u{1E008}-\\u{1E018}\\u{1E01B}-\\u{1E021}\\u{1E023}\\u{1E024}\\u{1E026}-\\u{1E02A}\\u{1E08F}\\u{1E130}-\\u{1E136}\\u{1E2AE}\\u{1E2EC}-\\u{1E2EF}\\u{1E4EC}-\\u{1E4EF}\\u{1E8D0}-\\u{1E8D6}\\u{1E944}-\\u{1E94A}\\u{E0100}-\\u{E01EF}]/u;\nconst combiningClassVirama = /[\\u094D\\u09CD\\u0A4D\\u0ACD\\u0B4D\\u0BCD\\u0C4D\\u0CCD\\u0D3B\\u0D3C\\u0D4D\\u0DCA\\u0E3A\\u0EBA\\u0F84\\u1039\\u103A\\u1714\\u1734\\u17D2\\u1A60\\u1B44\\u1BAA\\u1BAB\\u1BF2\\u1BF3\\u2D7F\\uA806\\uA8C4\\uA953\\uA9C0\\uAAF6\\uABED\\u{10A3F}\\u{11046}\\u{1107F}\\u{110B9}\\u{11133}\\u{11134}\\u{111C0}\\u{11235}\\u{112EA}\\u{1134D}\\u{11442}\\u{114C2}\\u{115BF}\\u{1163F}\\u{116B6}\\u{1172B}\\u{11839}\\u{119E0}\\u{11A34}\\u{11A47}\\u{11A99}\\u{11C3F}\\u{11D44}\\u{11D45}\\u{11D97}]/u;\nconst validZWNJ = /[\\u0620\\u0626\\u0628\\u062A-\\u062E\\u0633-\\u063F\\u0641-\\u0647\\u0649\\u064A\\u066E\\u066F\\u0678-\\u0687\\u069A-\\u06BF\\u06C1\\u06C2\\u06CC\\u06CE\\u06D0\\u06D1\\u06FA-\\u06FC\\u06FF\\u0712-\\u0714\\u071A-\\u071D\\u071F-\\u0727\\u0729\\u072B\\u072D\\u072E\\u074E-\\u0758\\u075C-\\u076A\\u076D-\\u0770\\u0772\\u0775-\\u0777\\u077A-\\u077F\\u07CA-\\u07EA\\u0841-\\u0845\\u0848\\u084A-\\u0853\\u0855\\u0860\\u0862-\\u0865\\u0868\\u08A0-\\u08A9\\u08AF\\u08B0\\u08B3\\u08B4\\u08B6-\\u08B8\\u08BA-\\u08BD\\u1807\\u1820-\\u1878\\u1887-\\u18A8\\u18AA\\uA840-\\uA872\\u{10AC0}-\\u{10AC4}\\u{10ACD}\\u{10AD3}-\\u{10ADC}\\u{10ADE}-\\u{10AE0}\\u{10AEB}-\\u{10AEE}\\u{10B80}\\u{10B82}\\u{10B86}-\\u{10B88}\\u{10B8A}\\u{10B8B}\\u{10B8D}\\u{10B90}\\u{10BAD}\\u{10BAE}\\u{10D00}-\\u{10D21}\\u{10D23}\\u{10F30}-\\u{10F32}\\u{10F34}-\\u{10F44}\\u{10F51}-\\u{10F53}\\u{1E900}-\\u{1E943}][\\xAD\\u0300-\\u036F\\u0483-\\u0489\\u0591-\\u05BD\\u05BF\\u05C1\\u05C2\\u05C4\\u05C5\\u05C7\\u0610-\\u061A\\u061C\\u064B-\\u065F\\u0670\\u06D6-\\u06DC\\u06DF-\\u06E4\\u06E7\\u06E8\\u06EA-\\u06ED\\u070F\\u0711\\u0730-\\u074A\\u07A6-\\u07B0\\u07EB-\\u07F3\\u07FD\\u0816-\\u0819\\u081B-\\u0823\\u0825-\\u0827\\u0829-\\u082D\\u0859-\\u085B\\u08D3-\\u08E1\\u08E3-\\u0902\\u093A\\u093C\\u0941-\\u0948\\u094D\\u0951-\\u0957\\u0962\\u0963\\u0981\\u09BC\\u09C1-\\u09C4\\u09CD\\u09E2\\u09E3\\u09FE\\u0A01\\u0A02\\u0A3C\\u0A41\\u0A42\\u0A47\\u0A48\\u0A4B-\\u0A4D\\u0A51\\u0A70\\u0A71\\u0A75\\u0A81\\u0A82\\u0ABC\\u0AC1-\\u0AC5\\u0AC7\\u0AC8\\u0ACD\\u0AE2\\u0AE3\\u0AFA-\\u0AFF\\u0B01\\u0B3C\\u0B3F\\u0B41-\\u0B44\\u0B4D\\u0B56\\u0B62\\u0B63\\u0B82\\u0BC0\\u0BCD\\u0C00\\u0C04\\u0C3E-\\u0C40\\u0C46-\\u0C48\\u0C4A-\\u0C4D\\u0C55\\u0C56\\u0C62\\u0C63\\u0C81\\u0CBC\\u0CBF\\u0CC6\\u0CCC\\u0CCD\\u0CE2\\u0CE3\\u0D00\\u0D01\\u0D3B\\u0D3C\\u0D41-\\u0D44\\u0D4D\\u0D62\\u0D63\\u0DCA\\u0DD2-\\u0DD4\\u0DD6\\u0E31\\u0E34-\\u0E3A\\u0E47-\\u0E4E\\u0EB1\\u0EB4-\\u0EBC\\u0EC8-\\u0ECD\\u0F18\\u0F19\\u0F35\\u0F37\\u0F39\\u0F71-\\u0F7E\\u0F80-\\u0F84\\u0F86\\u0F87\\u0F8D-\\u0F97\\u0F99-\\u0FBC\\u0FC6\\u102D-\\u1030\\u1032-\\u1037\\u1039\\u103A\\u103D\\u103E\\u1058\\u1059\\u105E-\\u1060\\u1071-\\u1074\\u1082\\u1085\\u1086\\u108D\\u109D\\u135D-\\u135F\\u1712-\\u1714\\u1732-\\u1734\\u1752\\u1753\\u1772\\u1773\\u17B4\\u17B5\\u17B7-\\u17BD\\u17C6\\u17C9-\\u17D3\\u17DD\\u180B-\\u180D\\u1885\\u1886\\u18A9\\u1920-\\u1922\\u1927\\u1928\\u1932\\u1939-\\u193B\\u1A17\\u1A18\\u1A1B\\u1A56\\u1A58-\\u1A5E\\u1A60\\u1A62\\u1A65-\\u1A6C\\u1A73-\\u1A7C\\u1A7F\\u1AB0-\\u1ABE\\u1B00-\\u1B03\\u1B34\\u1B36-\\u1B3A\\u1B3C\\u1B42\\u1B6B-\\u1B73\\u1B80\\u1B81\\u1BA2-\\u1BA5\\u1BA8\\u1BA9\\u1BAB-\\u1BAD\\u1BE6\\u1BE8\\u1BE9\\u1BED\\u1BEF-\\u1BF1\\u1C2C-\\u1C33\\u1C36\\u1C37\\u1CD0-\\u1CD2\\u1CD4-\\u1CE0\\u1CE2-\\u1CE8\\u1CED\\u1CF4\\u1CF8\\u1CF9\\u1DC0-\\u1DF9\\u1DFB-\\u1DFF\\u200B\\u200E\\u200F\\u202A-\\u202E\\u2060-\\u2064\\u206A-\\u206F\\u20D0-\\u20F0\\u2CEF-\\u2CF1\\u2D7F\\u2DE0-\\u2DFF\\u302A-\\u302D\\u3099\\u309A\\uA66F-\\uA672\\uA674-\\uA67D\\uA69E\\uA69F\\uA6F0\\uA6F1\\uA802\\uA806\\uA80B\\uA825\\uA826\\uA8C4\\uA8C5\\uA8E0-\\uA8F1\\uA8FF\\uA926-\\uA92D\\uA947-\\uA951\\uA980-\\uA982\\uA9B3\\uA9B6-\\uA9B9\\uA9BC\\uA9BD\\uA9E5\\uAA29-\\uAA2E\\uAA31\\uAA32\\uAA35\\uAA36\\uAA43\\uAA4C\\uAA7C\\uAAB0\\uAAB2-\\uAAB4\\uAAB7\\uAAB8\\uAABE\\uAABF\\uAAC1\\uAAEC\\uAAED\\uAAF6\\uABE5\\uABE8\\uABED\\uFB1E\\uFE00-\\uFE0F\\uFE20-\\uFE2F\\uFEFF\\uFFF9-\\uFFFB\\u{101FD}\\u{102E0}\\u{10376}-\\u{1037A}\\u{10A01}-\\u{10A03}\\u{10A05}\\u{10A06}\\u{10A0C}-\\u{10A0F}\\u{10A38}-\\u{10A3A}\\u{10A3F}\\u{10AE5}\\u{10AE6}\\u{10D24}-\\u{10D27}\\u{10F46}-\\u{10F50}\\u{11001}\\u{11038}-\\u{11046}\\u{1107F}-\\u{11081}\\u{110B3}-\\u{110B6}\\u{110B9}\\u{110BA}\\u{11100}-\\u{11102}\\u{11127}-\\u{1112B}\\u{1112D}-\\u{11134}\\u{11173}\\u{11180}\\u{11181}\\u{111B6}-\\u{111BE}\\u{111C9}-\\u{111CC}\\u{1122F}-\\u{11231}\\u{11234}\\u{11236}\\u{11237}\\u{1123E}\\u{112DF}\\u{112E3}-\\u{112EA}\\u{11300}\\u{11301}\\u{1133B}\\u{1133C}\\u{11340}\\u{11366}-\\u{1136C}\\u{11370}-\\u{11374}\\u{11438}-\\u{1143F}\\u{11442}-\\u{11444}\\u{11446}\\u{1145E}\\u{114B3}-\\u{114B8}\\u{114BA}\\u{114BF}\\u{114C0}\\u{114C2}\\u{114C3}\\u{115B2}-\\u{115B5}\\u{115BC}\\u{115BD}\\u{115BF}\\u{115C0}\\u{115DC}\\u{115DD}\\u{11633}-\\u{1163A}\\u{1163D}\\u{1163F}\\u{11640}\\u{116AB}\\u{116AD}\\u{116B0}-\\u{116B5}\\u{116B7}\\u{1171D}-\\u{1171F}\\u{11722}-\\u{11725}\\u{11727}-\\u{1172B}\\u{1182F}-\\u{11837}\\u{11839}\\u{1183A}\\u{119D4}-\\u{119D7}\\u{119DA}\\u{119DB}\\u{119E0}\\u{11A01}-\\u{11A0A}\\u{11A33}-\\u{11A38}\\u{11A3B}-\\u{11A3E}\\u{11A47}\\u{11A51}-\\u{11A56}\\u{11A59}-\\u{11A5B}\\u{11A8A}-\\u{11A96}\\u{11A98}\\u{11A99}\\u{11C30}-\\u{11C36}\\u{11C38}-\\u{11C3D}\\u{11C3F}\\u{11C92}-\\u{11CA7}\\u{11CAA}-\\u{11CB0}\\u{11CB2}\\u{11CB3}\\u{11CB5}\\u{11CB6}\\u{11D31}-\\u{11D36}\\u{11D3A}\\u{11D3C}\\u{11D3D}\\u{11D3F}-\\u{11D45}\\u{11D47}\\u{11D90}\\u{11D91}\\u{11D95}\\u{11D97}\\u{11EF3}\\u{11EF4}\\u{13430}-\\u{13438}\\u{16AF0}-\\u{16AF4}\\u{16B30}-\\u{16B36}\\u{16F4F}\\u{16F8F}-\\u{16F92}\\u{1BC9D}\\u{1BC9E}\\u{1BCA0}-\\u{1BCA3}\\u{1D167}-\\u{1D169}\\u{1D173}-\\u{1D182}\\u{1D185}-\\u{1D18B}\\u{1D1AA}-\\u{1D1AD}\\u{1D242}-\\u{1D244}\\u{1DA00}-\\u{1DA36}\\u{1DA3B}-\\u{1DA6C}\\u{1DA75}\\u{1DA84}\\u{1DA9B}-\\u{1DA9F}\\u{1DAA1}-\\u{1DAAF}\\u{1E000}-\\u{1E006}\\u{1E008}-\\u{1E018}\\u{1E01B}-\\u{1E021}\\u{1E023}\\u{1E024}\\u{1E026}-\\u{1E02A}\\u{1E130}-\\u{1E136}\\u{1E2EC}-\\u{1E2EF}\\u{1E8D0}-\\u{1E8D6}\\u{1E944}-\\u{1E94B}\\u{E0001}\\u{E0020}-\\u{E007F}\\u{E0100}-\\u{E01EF}]*\\u200C[\\xAD\\u0300-\\u036F\\u0483-\\u0489\\u0591-\\u05BD\\u05BF\\u05C1\\u05C2\\u05C4\\u05C5\\u05C7\\u0610-\\u061A\\u061C\\u064B-\\u065F\\u0670\\u06D6-\\u06DC\\u06DF-\\u06E4\\u06E7\\u06E8\\u06EA-\\u06ED\\u070F\\u0711\\u0730-\\u074A\\u07A6-\\u07B0\\u07EB-\\u07F3\\u07FD\\u0816-\\u0819\\u081B-\\u0823\\u0825-\\u0827\\u0829-\\u082D\\u0859-\\u085B\\u08D3-\\u08E1\\u08E3-\\u0902\\u093A\\u093C\\u0941-\\u0948\\u094D\\u0951-\\u0957\\u0962\\u0963\\u0981\\u09BC\\u09C1-\\u09C4\\u09CD\\u09E2\\u09E3\\u09FE\\u0A01\\u0A02\\u0A3C\\u0A41\\u0A42\\u0A47\\u0A48\\u0A4B-\\u0A4D\\u0A51\\u0A70\\u0A71\\u0A75\\u0A81\\u0A82\\u0ABC\\u0AC1-\\u0AC5\\u0AC7\\u0AC8\\u0ACD\\u0AE2\\u0AE3\\u0AFA-\\u0AFF\\u0B01\\u0B3C\\u0B3F\\u0B41-\\u0B44\\u0B4D\\u0B56\\u0B62\\u0B63\\u0B82\\u0BC0\\u0BCD\\u0C00\\u0C04\\u0C3E-\\u0C40\\u0C46-\\u0C48\\u0C4A-\\u0C4D\\u0C55\\u0C56\\u0C62\\u0C63\\u0C81\\u0CBC\\u0CBF\\u0CC6\\u0CCC\\u0CCD\\u0CE2\\u0CE3\\u0D00\\u0D01\\u0D3B\\u0D3C\\u0D41-\\u0D44\\u0D4D\\u0D62\\u0D63\\u0DCA\\u0DD2-\\u0DD4\\u0DD6\\u0E31\\u0E34-\\u0E3A\\u0E47-\\u0E4E\\u0EB1\\u0EB4-\\u0EBC\\u0EC8-\\u0ECD\\u0F18\\u0F19\\u0F35\\u0F37\\u0F39\\u0F71-\\u0F7E\\u0F80-\\u0F84\\u0F86\\u0F87\\u0F8D-\\u0F97\\u0F99-\\u0FBC\\u0FC6\\u102D-\\u1030\\u1032-\\u1037\\u1039\\u103A\\u103D\\u103E\\u1058\\u1059\\u105E-\\u1060\\u1071-\\u1074\\u1082\\u1085\\u1086\\u108D\\u109D\\u135D-\\u135F\\u1712-\\u1714\\u1732-\\u1734\\u1752\\u1753\\u1772\\u1773\\u17B4\\u17B5\\u17B7-\\u17BD\\u17C6\\u17C9-\\u17D3\\u17DD\\u180B-\\u180D\\u1885\\u1886\\u18A9\\u1920-\\u1922\\u1927\\u1928\\u1932\\u1939-\\u193B\\u1A17\\u1A18\\u1A1B\\u1A56\\u1A58-\\u1A5E\\u1A60\\u1A62\\u1A65-\\u1A6C\\u1A73-\\u1A7C\\u1A7F\\u1AB0-\\u1ABE\\u1B00-\\u1B03\\u1B34\\u1B36-\\u1B3A\\u1B3C\\u1B42\\u1B6B-\\u1B73\\u1B80\\u1B81\\u1BA2-\\u1BA5\\u1BA8\\u1BA9\\u1BAB-\\u1BAD\\u1BE6\\u1BE8\\u1BE9\\u1BED\\u1BEF-\\u1BF1\\u1C2C-\\u1C33\\u1C36\\u1C37\\u1CD0-\\u1CD2\\u1CD4-\\u1CE0\\u1CE2-\\u1CE8\\u1CED\\u1CF4\\u1CF8\\u1CF9\\u1DC0-\\u1DF9\\u1DFB-\\u1DFF\\u200B\\u200E\\u200F\\u202A-\\u202E\\u2060-\\u2064\\u206A-\\u206F\\u20D0-\\u20F0\\u2CEF-\\u2CF1\\u2D7F\\u2DE0-\\u2DFF\\u302A-\\u302D\\u3099\\u309A\\uA66F-\\uA672\\uA674-\\uA67D\\uA69E\\uA69F\\uA6F0\\uA6F1\\uA802\\uA806\\uA80B\\uA825\\uA826\\uA8C4\\uA8C5\\uA8E0-\\uA8F1\\uA8FF\\uA926-\\uA92D\\uA947-\\uA951\\uA980-\\uA982\\uA9B3\\uA9B6-\\uA9B9\\uA9BC\\uA9BD\\uA9E5\\uAA29-\\uAA2E\\uAA31\\uAA32\\uAA35\\uAA36\\uAA43\\uAA4C\\uAA7C\\uAAB0\\uAAB2-\\uAAB4\\uAAB7\\uAAB8\\uAABE\\uAABF\\uAAC1\\uAAEC\\uAAED\\uAAF6\\uABE5\\uABE8\\uABED\\uFB1E\\uFE00-\\uFE0F\\uFE20-\\uFE2F\\uFEFF\\uFFF9-\\uFFFB\\u{101FD}\\u{102E0}\\u{10376}-\\u{1037A}\\u{10A01}-\\u{10A03}\\u{10A05}\\u{10A06}\\u{10A0C}-\\u{10A0F}\\u{10A38}-\\u{10A3A}\\u{10A3F}\\u{10AE5}\\u{10AE6}\\u{10D24}-\\u{10D27}\\u{10F46}-\\u{10F50}\\u{11001}\\u{11038}-\\u{11046}\\u{1107F}-\\u{11081}\\u{110B3}-\\u{110B6}\\u{110B9}\\u{110BA}\\u{11100}-\\u{11102}\\u{11127}-\\u{1112B}\\u{1112D}-\\u{11134}\\u{11173}\\u{11180}\\u{11181}\\u{111B6}-\\u{111BE}\\u{111C9}-\\u{111CC}\\u{1122F}-\\u{11231}\\u{11234}\\u{11236}\\u{11237}\\u{1123E}\\u{112DF}\\u{112E3}-\\u{112EA}\\u{11300}\\u{11301}\\u{1133B}\\u{1133C}\\u{11340}\\u{11366}-\\u{1136C}\\u{11370}-\\u{11374}\\u{11438}-\\u{1143F}\\u{11442}-\\u{11444}\\u{11446}\\u{1145E}\\u{114B3}-\\u{114B8}\\u{114BA}\\u{114BF}\\u{114C0}\\u{114C2}\\u{114C3}\\u{115B2}-\\u{115B5}\\u{115BC}\\u{115BD}\\u{115BF}\\u{115C0}\\u{115DC}\\u{115DD}\\u{11633}-\\u{1163A}\\u{1163D}\\u{1163F}\\u{11640}\\u{116AB}\\u{116AD}\\u{116B0}-\\u{116B5}\\u{116B7}\\u{1171D}-\\u{1171F}\\u{11722}-\\u{11725}\\u{11727}-\\u{1172B}\\u{1182F}-\\u{11837}\\u{11839}\\u{1183A}\\u{119D4}-\\u{119D7}\\u{119DA}\\u{119DB}\\u{119E0}\\u{11A01}-\\u{11A0A}\\u{11A33}-\\u{11A38}\\u{11A3B}-\\u{11A3E}\\u{11A47}\\u{11A51}-\\u{11A56}\\u{11A59}-\\u{11A5B}\\u{11A8A}-\\u{11A96}\\u{11A98}\\u{11A99}\\u{11C30}-\\u{11C36}\\u{11C38}-\\u{11C3D}\\u{11C3F}\\u{11C92}-\\u{11CA7}\\u{11CAA}-\\u{11CB0}\\u{11CB2}\\u{11CB3}\\u{11CB5}\\u{11CB6}\\u{11D31}-\\u{11D36}\\u{11D3A}\\u{11D3C}\\u{11D3D}\\u{11D3F}-\\u{11D45}\\u{11D47}\\u{11D90}\\u{11D91}\\u{11D95}\\u{11D97}\\u{11EF3}\\u{11EF4}\\u{13430}-\\u{13438}\\u{16AF0}-\\u{16AF4}\\u{16B30}-\\u{16B36}\\u{16F4F}\\u{16F8F}-\\u{16F92}\\u{1BC9D}\\u{1BC9E}\\u{1BCA0}-\\u{1BCA3}\\u{1D167}-\\u{1D169}\\u{1D173}-\\u{1D182}\\u{1D185}-\\u{1D18B}\\u{1D1AA}-\\u{1D1AD}\\u{1D242}-\\u{1D244}\\u{1DA00}-\\u{1DA36}\\u{1DA3B}-\\u{1DA6C}\\u{1DA75}\\u{1DA84}\\u{1DA9B}-\\u{1DA9F}\\u{1DAA1}-\\u{1DAAF}\\u{1E000}-\\u{1E006}\\u{1E008}-\\u{1E018}\\u{1E01B}-\\u{1E021}\\u{1E023}\\u{1E024}\\u{1E026}-\\u{1E02A}\\u{1E130}-\\u{1E136}\\u{1E2EC}-\\u{1E2EF}\\u{1E8D0}-\\u{1E8D6}\\u{1E944}-\\u{1E94B}\\u{E0001}\\u{E0020}-\\u{E007F}\\u{E0100}-\\u{E01EF}]*[\\u0620\\u0622-\\u063F\\u0641-\\u064A\\u066E\\u066F\\u0671-\\u0673\\u0675-\\u06D3\\u06D5\\u06EE\\u06EF\\u06FA-\\u06FC\\u06FF\\u0710\\u0712-\\u072F\\u074D-\\u077F\\u07CA-\\u07EA\\u0840-\\u0855\\u0860\\u0862-\\u0865\\u0867-\\u086A\\u08A0-\\u08AC\\u08AE-\\u08B4\\u08B6-\\u08BD\\u1807\\u1820-\\u1878\\u1887-\\u18A8\\u18AA\\uA840-\\uA871\\u{10AC0}-\\u{10AC5}\\u{10AC7}\\u{10AC9}\\u{10ACA}\\u{10ACE}-\\u{10AD6}\\u{10AD8}-\\u{10AE1}\\u{10AE4}\\u{10AEB}-\\u{10AEF}\\u{10B80}-\\u{10B91}\\u{10BA9}-\\u{10BAE}\\u{10D01}-\\u{10D23}\\u{10F30}-\\u{10F44}\\u{10F51}-\\u{10F54}\\u{1E900}-\\u{1E943}]/u;\nconst bidiDomain = /[\\u05BE\\u05C0\\u05C3\\u05C6\\u05D0-\\u05EA\\u05EF-\\u05F4\\u0600-\\u0605\\u0608\\u060B\\u060D\\u061B-\\u064A\\u0660-\\u0669\\u066B-\\u066F\\u0671-\\u06D5\\u06DD\\u06E5\\u06E6\\u06EE\\u06EF\\u06FA-\\u070D\\u070F\\u0710\\u0712-\\u072F\\u074D-\\u07A5\\u07B1\\u07C0-\\u07EA\\u07F4\\u07F5\\u07FA\\u07FE-\\u0815\\u081A\\u0824\\u0828\\u0830-\\u083E\\u0840-\\u0858\\u085E\\u0860-\\u086A\\u0870-\\u088E\\u0890\\u0891\\u08A0-\\u08C9\\u08E2\\u200F\\uFB1D\\uFB1F-\\uFB28\\uFB2A-\\uFB36\\uFB38-\\uFB3C\\uFB3E\\uFB40\\uFB41\\uFB43\\uFB44\\uFB46-\\uFBC2\\uFBD3-\\uFD3D\\uFD50-\\uFD8F\\uFD92-\\uFDC7\\uFDF0-\\uFDFC\\uFE70-\\uFE74\\uFE76-\\uFEFC\\u{10800}-\\u{10805}\\u{10808}\\u{1080A}-\\u{10835}\\u{10837}\\u{10838}\\u{1083C}\\u{1083F}-\\u{10855}\\u{10857}-\\u{1089E}\\u{108A7}-\\u{108AF}\\u{108E0}-\\u{108F2}\\u{108F4}\\u{108F5}\\u{108FB}-\\u{1091B}\\u{10920}-\\u{10939}\\u{1093F}\\u{10980}-\\u{109B7}\\u{109BC}-\\u{109CF}\\u{109D2}-\\u{10A00}\\u{10A10}-\\u{10A13}\\u{10A15}-\\u{10A17}\\u{10A19}-\\u{10A35}\\u{10A40}-\\u{10A48}\\u{10A50}-\\u{10A58}\\u{10A60}-\\u{10A9F}\\u{10AC0}-\\u{10AE4}\\u{10AEB}-\\u{10AF6}\\u{10B00}-\\u{10B35}\\u{10B40}-\\u{10B55}\\u{10B58}-\\u{10B72}\\u{10B78}-\\u{10B91}\\u{10B99}-\\u{10B9C}\\u{10BA9}-\\u{10BAF}\\u{10C00}-\\u{10C48}\\u{10C80}-\\u{10CB2}\\u{10CC0}-\\u{10CF2}\\u{10CFA}-\\u{10D23}\\u{10D30}-\\u{10D39}\\u{10E60}-\\u{10E7E}\\u{10E80}-\\u{10EA9}\\u{10EAD}\\u{10EB0}\\u{10EB1}\\u{10F00}-\\u{10F27}\\u{10F30}-\\u{10F45}\\u{10F51}-\\u{10F59}\\u{10F70}-\\u{10F81}\\u{10F86}-\\u{10F89}\\u{10FB0}-\\u{10FCB}\\u{10FE0}-\\u{10FF6}\\u{1E800}-\\u{1E8C4}\\u{1E8C7}-\\u{1E8CF}\\u{1E900}-\\u{1E943}\\u{1E94B}\\u{1E950}-\\u{1E959}\\u{1E95E}\\u{1E95F}\\u{1EC71}-\\u{1ECB4}\\u{1ED01}-\\u{1ED3D}\\u{1EE00}-\\u{1EE03}\\u{1EE05}-\\u{1EE1F}\\u{1EE21}\\u{1EE22}\\u{1EE24}\\u{1EE27}\\u{1EE29}-\\u{1EE32}\\u{1EE34}-\\u{1EE37}\\u{1EE39}\\u{1EE3B}\\u{1EE42}\\u{1EE47}\\u{1EE49}\\u{1EE4B}\\u{1EE4D}-\\u{1EE4F}\\u{1EE51}\\u{1EE52}\\u{1EE54}\\u{1EE57}\\u{1EE59}\\u{1EE5B}\\u{1EE5D}\\u{1EE5F}\\u{1EE61}\\u{1EE62}\\u{1EE64}\\u{1EE67}-\\u{1EE6A}\\u{1EE6C}-\\u{1EE72}\\u{1EE74}-\\u{1EE77}\\u{1EE79}-\\u{1EE7C}\\u{1EE7E}\\u{1EE80}-\\u{1EE89}\\u{1EE8B}-\\u{1EE9B}\\u{1EEA1}-\\u{1EEA3}\\u{1EEA5}-\\u{1EEA9}\\u{1EEAB}-\\u{1EEBB}]/u;\nconst bidiS1LTR = /[A-Za-z\\xAA\\xB5\\xBA\\xC0-\\xD6\\xD8-\\xF6\\xF8-\\u02B8\\u02BB-\\u02C1\\u02D0\\u02D1\\u02E0-\\u02E4\\u02EE\\u0370-\\u0373\\u0376\\u0377\\u037A-\\u037D\\u037F\\u0386\\u0388-\\u038A\\u038C\\u038E-\\u03A1\\u03A3-\\u03F5\\u03F7-\\u0482\\u048A-\\u052F\\u0531-\\u0556\\u0559-\\u0589\\u0903-\\u0939\\u093B\\u093D-\\u0940\\u0949-\\u094C\\u094E-\\u0950\\u0958-\\u0961\\u0964-\\u0980\\u0982\\u0983\\u0985-\\u098C\\u098F\\u0990\\u0993-\\u09A8\\u09AA-\\u09B0\\u09B2\\u09B6-\\u09B9\\u09BD-\\u09C0\\u09C7\\u09C8\\u09CB\\u09CC\\u09CE\\u09D7\\u09DC\\u09DD\\u09DF-\\u09E1\\u09E6-\\u09F1\\u09F4-\\u09FA\\u09FC\\u09FD\\u0A03\\u0A05-\\u0A0A\\u0A0F\\u0A10\\u0A13-\\u0A28\\u0A2A-\\u0A30\\u0A32\\u0A33\\u0A35\\u0A36\\u0A38\\u0A39\\u0A3E-\\u0A40\\u0A59-\\u0A5C\\u0A5E\\u0A66-\\u0A6F\\u0A72-\\u0A74\\u0A76\\u0A83\\u0A85-\\u0A8D\\u0A8F-\\u0A91\\u0A93-\\u0AA8\\u0AAA-\\u0AB0\\u0AB2\\u0AB3\\u0AB5-\\u0AB9\\u0ABD-\\u0AC0\\u0AC9\\u0ACB\\u0ACC\\u0AD0\\u0AE0\\u0AE1\\u0AE6-\\u0AF0\\u0AF9\\u0B02\\u0B03\\u0B05-\\u0B0C\\u0B0F\\u0B10\\u0B13-\\u0B28\\u0B2A-\\u0B30\\u0B32\\u0B33\\u0B35-\\u0B39\\u0B3D\\u0B3E\\u0B40\\u0B47\\u0B48\\u0B4B\\u0B4C\\u0B57\\u0B5C\\u0B5D\\u0B5F-\\u0B61\\u0B66-\\u0B77\\u0B83\\u0B85-\\u0B8A\\u0B8E-\\u0B90\\u0B92-\\u0B95\\u0B99\\u0B9A\\u0B9C\\u0B9E\\u0B9F\\u0BA3\\u0BA4\\u0BA8-\\u0BAA\\u0BAE-\\u0BB9\\u0BBE\\u0BBF\\u0BC1\\u0BC2\\u0BC6-\\u0BC8\\u0BCA-\\u0BCC\\u0BD0\\u0BD7\\u0BE6-\\u0BF2\\u0C01-\\u0C03\\u0C05-\\u0C0C\\u0C0E-\\u0C10\\u0C12-\\u0C28\\u0C2A-\\u0C39\\u0C3D\\u0C41-\\u0C44\\u0C58-\\u0C5A\\u0C5D\\u0C60\\u0C61\\u0C66-\\u0C6F\\u0C77\\u0C7F\\u0C80\\u0C82-\\u0C8C\\u0C8E-\\u0C90\\u0C92-\\u0CA8\\u0CAA-\\u0CB3\\u0CB5-\\u0CB9\\u0CBD-\\u0CC4\\u0CC6-\\u0CC8\\u0CCA\\u0CCB\\u0CD5\\u0CD6\\u0CDD\\u0CDE\\u0CE0\\u0CE1\\u0CE6-\\u0CEF\\u0CF1-\\u0CF3\\u0D02-\\u0D0C\\u0D0E-\\u0D10\\u0D12-\\u0D3A\\u0D3D-\\u0D40\\u0D46-\\u0D48\\u0D4A-\\u0D4C\\u0D4E\\u0D4F\\u0D54-\\u0D61\\u0D66-\\u0D7F\\u0D82\\u0D83\\u0D85-\\u0D96\\u0D9A-\\u0DB1\\u0DB3-\\u0DBB\\u0DBD\\u0DC0-\\u0DC6\\u0DCF-\\u0DD1\\u0DD8-\\u0DDF\\u0DE6-\\u0DEF\\u0DF2-\\u0DF4\\u0E01-\\u0E30\\u0E32\\u0E33\\u0E40-\\u0E46\\u0E4F-\\u0E5B\\u0E81\\u0E82\\u0E84\\u0E86-\\u0E8A\\u0E8C-\\u0EA3\\u0EA5\\u0EA7-\\u0EB0\\u0EB2\\u0EB3\\u0EBD\\u0EC0-\\u0EC4\\u0EC6\\u0ED0-\\u0ED9\\u0EDC-\\u0EDF\\u0F00-\\u0F17\\u0F1A-\\u0F34\\u0F36\\u0F38\\u0F3E-\\u0F47\\u0F49-\\u0F6C\\u0F7F\\u0F85\\u0F88-\\u0F8C\\u0FBE-\\u0FC5\\u0FC7-\\u0FCC\\u0FCE-\\u0FDA\\u1000-\\u102C\\u1031\\u1038\\u103B\\u103C\\u103F-\\u1057\\u105A-\\u105D\\u1061-\\u1070\\u1075-\\u1081\\u1083\\u1084\\u1087-\\u108C\\u108E-\\u109C\\u109E-\\u10C5\\u10C7\\u10CD\\u10D0-\\u1248\\u124A-\\u124D\\u1250-\\u1256\\u1258\\u125A-\\u125D\\u1260-\\u1288\\u128A-\\u128D\\u1290-\\u12B0\\u12B2-\\u12B5\\u12B8-\\u12BE\\u12C0\\u12C2-\\u12C5\\u12C8-\\u12D6\\u12D8-\\u1310\\u1312-\\u1315\\u1318-\\u135A\\u1360-\\u137C\\u1380-\\u138F\\u13A0-\\u13F5\\u13F8-\\u13FD\\u1401-\\u167F\\u1681-\\u169A\\u16A0-\\u16F8\\u1700-\\u1711\\u1715\\u171F-\\u1731\\u1734-\\u1736\\u1740-\\u1751\\u1760-\\u176C\\u176E-\\u1770\\u1780-\\u17B3\\u17B6\\u17BE-\\u17C5\\u17C7\\u17C8\\u17D4-\\u17DA\\u17DC\\u17E0-\\u17E9\\u1810-\\u1819\\u1820-\\u1878\\u1880-\\u1884\\u1887-\\u18A8\\u18AA\\u18B0-\\u18F5\\u1900-\\u191E\\u1923-\\u1926\\u1929-\\u192B\\u1930\\u1931\\u1933-\\u1938\\u1946-\\u196D\\u1970-\\u1974\\u1980-\\u19AB\\u19B0-\\u19C9\\u19D0-\\u19DA\\u1A00-\\u1A16\\u1A19\\u1A1A\\u1A1E-\\u1A55\\u1A57\\u1A61\\u1A63\\u1A64\\u1A6D-\\u1A72\\u1A80-\\u1A89\\u1A90-\\u1A99\\u1AA0-\\u1AAD\\u1B04-\\u1B33\\u1B35\\u1B3B\\u1B3D-\\u1B41\\u1B43-\\u1B4C\\u1B50-\\u1B6A\\u1B74-\\u1B7E\\u1B82-\\u1BA1\\u1BA6\\u1BA7\\u1BAA\\u1BAE-\\u1BE5\\u1BE7\\u1BEA-\\u1BEC\\u1BEE\\u1BF2\\u1BF3\\u1BFC-\\u1C2B\\u1C34\\u1C35\\u1C3B-\\u1C49\\u1C4D-\\u1C88\\u1C90-\\u1CBA\\u1CBD-\\u1CC7\\u1CD3\\u1CE1\\u1CE9-\\u1CEC\\u1CEE-\\u1CF3\\u1CF5-\\u1CF7\\u1CFA\\u1D00-\\u1DBF\\u1E00-\\u1F15\\u1F18-\\u1F1D\\u1F20-\\u1F45\\u1F48-\\u1F4D\\u1F50-\\u1F57\\u1F59\\u1F5B\\u1F5D\\u1F5F-\\u1F7D\\u1F80-\\u1FB4\\u1FB6-\\u1FBC\\u1FBE\\u1FC2-\\u1FC4\\u1FC6-\\u1FCC\\u1FD0-\\u1FD3\\u1FD6-\\u1FDB\\u1FE0-\\u1FEC\\u1FF2-\\u1FF4\\u1FF6-\\u1FFC\\u200E\\u2071\\u207F\\u2090-\\u209C\\u2102\\u2107\\u210A-\\u2113\\u2115\\u2119-\\u211D\\u2124\\u2126\\u2128\\u212A-\\u212D\\u212F-\\u2139\\u213C-\\u213F\\u2145-\\u2149\\u214E\\u214F\\u2160-\\u2188\\u2336-\\u237A\\u2395\\u249C-\\u24E9\\u26AC\\u2800-\\u28FF\\u2C00-\\u2CE4\\u2CEB-\\u2CEE\\u2CF2\\u2CF3\\u2D00-\\u2D25\\u2D27\\u2D2D\\u2D30-\\u2D67\\u2D6F\\u2D70\\u2D80-\\u2D96\\u2DA0-\\u2DA6\\u2DA8-\\u2DAE\\u2DB0-\\u2DB6\\u2DB8-\\u2DBE\\u2DC0-\\u2DC6\\u2DC8-\\u2DCE\\u2DD0-\\u2DD6\\u2DD8-\\u2DDE\\u3005-\\u3007\\u3021-\\u3029\\u302E\\u302F\\u3031-\\u3035\\u3038-\\u303C\\u3041-\\u3096\\u309D-\\u309F\\u30A1-\\u30FA\\u30FC-\\u30FF\\u3105-\\u312F\\u3131-\\u318E\\u3190-\\u31BF\\u31F0-\\u321C\\u3220-\\u324F\\u3260-\\u327B\\u327F-\\u32B0\\u32C0-\\u32CB\\u32D0-\\u3376\\u337B-\\u33DD\\u33E0-\\u33FE\\u3400-\\u4DBF\\u4E00-\\uA48C\\uA4D0-\\uA60C\\uA610-\\uA62B\\uA640-\\uA66E\\uA680-\\uA69D\\uA6A0-\\uA6EF\\uA6F2-\\uA6F7\\uA722-\\uA787\\uA789-\\uA7CA\\uA7D0\\uA7D1\\uA7D3\\uA7D5-\\uA7D9\\uA7F2-\\uA801\\uA803-\\uA805\\uA807-\\uA80A\\uA80C-\\uA824\\uA827\\uA830-\\uA837\\uA840-\\uA873\\uA880-\\uA8C3\\uA8CE-\\uA8D9\\uA8F2-\\uA8FE\\uA900-\\uA925\\uA92E-\\uA946\\uA952\\uA953\\uA95F-\\uA97C\\uA983-\\uA9B2\\uA9B4\\uA9B5\\uA9BA\\uA9BB\\uA9BE-\\uA9CD\\uA9CF-\\uA9D9\\uA9DE-\\uA9E4\\uA9E6-\\uA9FE\\uAA00-\\uAA28\\uAA2F\\uAA30\\uAA33\\uAA34\\uAA40-\\uAA42\\uAA44-\\uAA4B\\uAA4D\\uAA50-\\uAA59\\uAA5C-\\uAA7B\\uAA7D-\\uAAAF\\uAAB1\\uAAB5\\uAAB6\\uAAB9-\\uAABD\\uAAC0\\uAAC2\\uAADB-\\uAAEB\\uAAEE-\\uAAF5\\uAB01-\\uAB06\\uAB09-\\uAB0E\\uAB11-\\uAB16\\uAB20-\\uAB26\\uAB28-\\uAB2E\\uAB30-\\uAB69\\uAB70-\\uABE4\\uABE6\\uABE7\\uABE9-\\uABEC\\uABF0-\\uABF9\\uAC00-\\uD7A3\\uD7B0-\\uD7C6\\uD7CB-\\uD7FB\\uD800-\\uFA6D\\uFA70-\\uFAD9\\uFB00-\\uFB06\\uFB13-\\uFB17\\uFF21-\\uFF3A\\uFF41-\\uFF5A\\uFF66-\\uFFBE\\uFFC2-\\uFFC7\\uFFCA-\\uFFCF\\uFFD2-\\uFFD7\\uFFDA-\\uFFDC\\u{10000}-\\u{1000B}\\u{1000D}-\\u{10026}\\u{10028}-\\u{1003A}\\u{1003C}\\u{1003D}\\u{1003F}-\\u{1004D}\\u{10050}-\\u{1005D}\\u{10080}-\\u{100FA}\\u{10100}\\u{10102}\\u{10107}-\\u{10133}\\u{10137}-\\u{1013F}\\u{1018D}\\u{1018E}\\u{101D0}-\\u{101FC}\\u{10280}-\\u{1029C}\\u{102A0}-\\u{102D0}\\u{10300}-\\u{10323}\\u{1032D}-\\u{1034A}\\u{10350}-\\u{10375}\\u{10380}-\\u{1039D}\\u{1039F}-\\u{103C3}\\u{103C8}-\\u{103D5}\\u{10400}-\\u{1049D}\\u{104A0}-\\u{104A9}\\u{104B0}-\\u{104D3}\\u{104D8}-\\u{104FB}\\u{10500}-\\u{10527}\\u{10530}-\\u{10563}\\u{1056F}-\\u{1057A}\\u{1057C}-\\u{1058A}\\u{1058C}-\\u{10592}\\u{10594}\\u{10595}\\u{10597}-\\u{105A1}\\u{105A3}-\\u{105B1}\\u{105B3}-\\u{105B9}\\u{105BB}\\u{105BC}\\u{10600}-\\u{10736}\\u{10740}-\\u{10755}\\u{10760}-\\u{10767}\\u{10780}-\\u{10785}\\u{10787}-\\u{107B0}\\u{107B2}-\\u{107BA}\\u{11000}\\u{11002}-\\u{11037}\\u{11047}-\\u{1104D}\\u{11066}-\\u{1106F}\\u{11071}\\u{11072}\\u{11075}\\u{11082}-\\u{110B2}\\u{110B7}\\u{110B8}\\u{110BB}-\\u{110C1}\\u{110CD}\\u{110D0}-\\u{110E8}\\u{110F0}-\\u{110F9}\\u{11103}-\\u{11126}\\u{1112C}\\u{11136}-\\u{11147}\\u{11150}-\\u{11172}\\u{11174}-\\u{11176}\\u{11182}-\\u{111B5}\\u{111BF}-\\u{111C8}\\u{111CD}\\u{111CE}\\u{111D0}-\\u{111DF}\\u{111E1}-\\u{111F4}\\u{11200}-\\u{11211}\\u{11213}-\\u{1122E}\\u{11232}\\u{11233}\\u{11235}\\u{11238}-\\u{1123D}\\u{1123F}\\u{11240}\\u{11280}-\\u{11286}\\u{11288}\\u{1128A}-\\u{1128D}\\u{1128F}-\\u{1129D}\\u{1129F}-\\u{112A9}\\u{112B0}-\\u{112DE}\\u{112E0}-\\u{112E2}\\u{112F0}-\\u{112F9}\\u{11302}\\u{11303}\\u{11305}-\\u{1130C}\\u{1130F}\\u{11310}\\u{11313}-\\u{11328}\\u{1132A}-\\u{11330}\\u{11332}\\u{11333}\\u{11335}-\\u{11339}\\u{1133D}-\\u{1133F}\\u{11341}-\\u{11344}\\u{11347}\\u{11348}\\u{1134B}-\\u{1134D}\\u{11350}\\u{11357}\\u{1135D}-\\u{11363}\\u{11400}-\\u{11437}\\u{11440}\\u{11441}\\u{11445}\\u{11447}-\\u{1145B}\\u{1145D}\\u{1145F}-\\u{11461}\\u{11480}-\\u{114B2}\\u{114B9}\\u{114BB}-\\u{114BE}\\u{114C1}\\u{114C4}-\\u{114C7}\\u{114D0}-\\u{114D9}\\u{11580}-\\u{115B1}\\u{115B8}-\\u{115BB}\\u{115BE}\\u{115C1}-\\u{115DB}\\u{11600}-\\u{11632}\\u{1163B}\\u{1163C}\\u{1163E}\\u{11641}-\\u{11644}\\u{11650}-\\u{11659}\\u{11680}-\\u{116AA}\\u{116AC}\\u{116AE}\\u{116AF}\\u{116B6}\\u{116B8}\\u{116B9}\\u{116C0}-\\u{116C9}\\u{11700}-\\u{1171A}\\u{11720}\\u{11721}\\u{11726}\\u{11730}-\\u{11746}\\u{11800}-\\u{1182E}\\u{11838}\\u{1183B}\\u{118A0}-\\u{118F2}\\u{118FF}-\\u{11906}\\u{11909}\\u{1190C}-\\u{11913}\\u{11915}\\u{11916}\\u{11918}-\\u{11935}\\u{11937}\\u{11938}\\u{1193D}\\u{1193F}-\\u{11942}\\u{11944}-\\u{11946}\\u{11950}-\\u{11959}\\u{119A0}-\\u{119A7}\\u{119AA}-\\u{119D3}\\u{119DC}-\\u{119DF}\\u{119E1}-\\u{119E4}\\u{11A00}\\u{11A07}\\u{11A08}\\u{11A0B}-\\u{11A32}\\u{11A39}\\u{11A3A}\\u{11A3F}-\\u{11A46}\\u{11A50}\\u{11A57}\\u{11A58}\\u{11A5C}-\\u{11A89}\\u{11A97}\\u{11A9A}-\\u{11AA2}\\u{11AB0}-\\u{11AF8}\\u{11B00}-\\u{11B09}\\u{11C00}-\\u{11C08}\\u{11C0A}-\\u{11C2F}\\u{11C3E}-\\u{11C45}\\u{11C50}-\\u{11C6C}\\u{11C70}-\\u{11C8F}\\u{11CA9}\\u{11CB1}\\u{11CB4}\\u{11D00}-\\u{11D06}\\u{11D08}\\u{11D09}\\u{11D0B}-\\u{11D30}\\u{11D46}\\u{11D50}-\\u{11D59}\\u{11D60}-\\u{11D65}\\u{11D67}\\u{11D68}\\u{11D6A}-\\u{11D8E}\\u{11D93}\\u{11D94}\\u{11D96}\\u{11D98}\\u{11DA0}-\\u{11DA9}\\u{11EE0}-\\u{11EF2}\\u{11EF5}-\\u{11EF8}\\u{11F02}-\\u{11F10}\\u{11F12}-\\u{11F35}\\u{11F3E}\\u{11F3F}\\u{11F41}\\u{11F43}-\\u{11F59}\\u{11FB0}\\u{11FC0}-\\u{11FD4}\\u{11FFF}-\\u{12399}\\u{12400}-\\u{1246E}\\u{12470}-\\u{12474}\\u{12480}-\\u{12543}\\u{12F90}-\\u{12FF2}\\u{13000}-\\u{1343F}\\u{13441}-\\u{13446}\\u{14400}-\\u{14646}\\u{16800}-\\u{16A38}\\u{16A40}-\\u{16A5E}\\u{16A60}-\\u{16A69}\\u{16A6E}-\\u{16ABE}\\u{16AC0}-\\u{16AC9}\\u{16AD0}-\\u{16AED}\\u{16AF5}\\u{16B00}-\\u{16B2F}\\u{16B37}-\\u{16B45}\\u{16B50}-\\u{16B59}\\u{16B5B}-\\u{16B61}\\u{16B63}-\\u{16B77}\\u{16B7D}-\\u{16B8F}\\u{16E40}-\\u{16E9A}\\u{16F00}-\\u{16F4A}\\u{16F50}-\\u{16F87}\\u{16F93}-\\u{16F9F}\\u{16FE0}\\u{16FE1}\\u{16FE3}\\u{16FF0}\\u{16FF1}\\u{17000}-\\u{187F7}\\u{18800}-\\u{18CD5}\\u{18D00}-\\u{18D08}\\u{1AFF0}-\\u{1AFF3}\\u{1AFF5}-\\u{1AFFB}\\u{1AFFD}\\u{1AFFE}\\u{1B000}-\\u{1B122}\\u{1B132}\\u{1B150}-\\u{1B152}\\u{1B155}\\u{1B164}-\\u{1B167}\\u{1B170}-\\u{1B2FB}\\u{1BC00}-\\u{1BC6A}\\u{1BC70}-\\u{1BC7C}\\u{1BC80}-\\u{1BC88}\\u{1BC90}-\\u{1BC99}\\u{1BC9C}\\u{1BC9F}\\u{1CF50}-\\u{1CFC3}\\u{1D000}-\\u{1D0F5}\\u{1D100}-\\u{1D126}\\u{1D129}-\\u{1D166}\\u{1D16A}-\\u{1D172}\\u{1D183}\\u{1D184}\\u{1D18C}-\\u{1D1A9}\\u{1D1AE}-\\u{1D1E8}\\u{1D2C0}-\\u{1D2D3}\\u{1D2E0}-\\u{1D2F3}\\u{1D360}-\\u{1D378}\\u{1D400}-\\u{1D454}\\u{1D456}-\\u{1D49C}\\u{1D49E}\\u{1D49F}\\u{1D4A2}\\u{1D4A5}\\u{1D4A6}\\u{1D4A9}-\\u{1D4AC}\\u{1D4AE}-\\u{1D4B9}\\u{1D4BB}\\u{1D4BD}-\\u{1D4C3}\\u{1D4C5}-\\u{1D505}\\u{1D507}-\\u{1D50A}\\u{1D50D}-\\u{1D514}\\u{1D516}-\\u{1D51C}\\u{1D51E}-\\u{1D539}\\u{1D53B}-\\u{1D53E}\\u{1D540}-\\u{1D544}\\u{1D546}\\u{1D54A}-\\u{1D550}\\u{1D552}-\\u{1D6A5}\\u{1D6A8}-\\u{1D6DA}\\u{1D6DC}-\\u{1D714}\\u{1D716}-\\u{1D74E}\\u{1D750}-\\u{1D788}\\u{1D78A}-\\u{1D7C2}\\u{1D7C4}-\\u{1D7CB}\\u{1D800}-\\u{1D9FF}\\u{1DA37}-\\u{1DA3A}\\u{1DA6D}-\\u{1DA74}\\u{1DA76}-\\u{1DA83}\\u{1DA85}-\\u{1DA8B}\\u{1DF00}-\\u{1DF1E}\\u{1DF25}-\\u{1DF2A}\\u{1E030}-\\u{1E06D}\\u{1E100}-\\u{1E12C}\\u{1E137}-\\u{1E13D}\\u{1E140}-\\u{1E149}\\u{1E14E}\\u{1E14F}\\u{1E290}-\\u{1E2AD}\\u{1E2C0}-\\u{1E2EB}\\u{1E2F0}-\\u{1E2F9}\\u{1E4D0}-\\u{1E4EB}\\u{1E4F0}-\\u{1E4F9}\\u{1E7E0}-\\u{1E7E6}\\u{1E7E8}-\\u{1E7EB}\\u{1E7ED}\\u{1E7EE}\\u{1E7F0}-\\u{1E7FE}\\u{1F110}-\\u{1F12E}\\u{1F130}-\\u{1F169}\\u{1F170}-\\u{1F1AC}\\u{1F1E6}-\\u{1F202}\\u{1F210}-\\u{1F23B}\\u{1F240}-\\u{1F248}\\u{1F250}\\u{1F251}\\u{20000}-\\u{2A6DF}\\u{2A700}-\\u{2B739}\\u{2B740}-\\u{2B81D}\\u{2B820}-\\u{2CEA1}\\u{2CEB0}-\\u{2EBE0}\\u{2F800}-\\u{2FA1D}\\u{30000}-\\u{3134A}\\u{31350}-\\u{323AF}\\u{F0000}-\\u{FFFFD}\\u{100000}-\\u{10FFFD}]/u;\nconst bidiS1RTL = /[\\u05BE\\u05C0\\u05C3\\u05C6\\u05D0-\\u05EA\\u05EF-\\u05F4\\u0608\\u060B\\u060D\\u061B-\\u064A\\u066D-\\u066F\\u0671-\\u06D5\\u06E5\\u06E6\\u06EE\\u06EF\\u06FA-\\u070D\\u070F\\u0710\\u0712-\\u072F\\u074D-\\u07A5\\u07B1\\u07C0-\\u07EA\\u07F4\\u07F5\\u07FA\\u07FE-\\u0815\\u081A\\u0824\\u0828\\u0830-\\u083E\\u0840-\\u0858\\u085E\\u0860-\\u086A\\u0870-\\u088E\\u08A0-\\u08C9\\u200F\\uFB1D\\uFB1F-\\uFB28\\uFB2A-\\uFB36\\uFB38-\\uFB3C\\uFB3E\\uFB40\\uFB41\\uFB43\\uFB44\\uFB46-\\uFBC2\\uFBD3-\\uFD3D\\uFD50-\\uFD8F\\uFD92-\\uFDC7\\uFDF0-\\uFDFC\\uFE70-\\uFE74\\uFE76-\\uFEFC\\u{10800}-\\u{10805}\\u{10808}\\u{1080A}-\\u{10835}\\u{10837}\\u{10838}\\u{1083C}\\u{1083F}-\\u{10855}\\u{10857}-\\u{1089E}\\u{108A7}-\\u{108AF}\\u{108E0}-\\u{108F2}\\u{108F4}\\u{108F5}\\u{108FB}-\\u{1091B}\\u{10920}-\\u{10939}\\u{1093F}\\u{10980}-\\u{109B7}\\u{109BC}-\\u{109CF}\\u{109D2}-\\u{10A00}\\u{10A10}-\\u{10A13}\\u{10A15}-\\u{10A17}\\u{10A19}-\\u{10A35}\\u{10A40}-\\u{10A48}\\u{10A50}-\\u{10A58}\\u{10A60}-\\u{10A9F}\\u{10AC0}-\\u{10AE4}\\u{10AEB}-\\u{10AF6}\\u{10B00}-\\u{10B35}\\u{10B40}-\\u{10B55}\\u{10B58}-\\u{10B72}\\u{10B78}-\\u{10B91}\\u{10B99}-\\u{10B9C}\\u{10BA9}-\\u{10BAF}\\u{10C00}-\\u{10C48}\\u{10C80}-\\u{10CB2}\\u{10CC0}-\\u{10CF2}\\u{10CFA}-\\u{10D23}\\u{10E80}-\\u{10EA9}\\u{10EAD}\\u{10EB0}\\u{10EB1}\\u{10F00}-\\u{10F27}\\u{10F30}-\\u{10F45}\\u{10F51}-\\u{10F59}\\u{10F70}-\\u{10F81}\\u{10F86}-\\u{10F89}\\u{10FB0}-\\u{10FCB}\\u{10FE0}-\\u{10FF6}\\u{1E800}-\\u{1E8C4}\\u{1E8C7}-\\u{1E8CF}\\u{1E900}-\\u{1E943}\\u{1E94B}\\u{1E950}-\\u{1E959}\\u{1E95E}\\u{1E95F}\\u{1EC71}-\\u{1ECB4}\\u{1ED01}-\\u{1ED3D}\\u{1EE00}-\\u{1EE03}\\u{1EE05}-\\u{1EE1F}\\u{1EE21}\\u{1EE22}\\u{1EE24}\\u{1EE27}\\u{1EE29}-\\u{1EE32}\\u{1EE34}-\\u{1EE37}\\u{1EE39}\\u{1EE3B}\\u{1EE42}\\u{1EE47}\\u{1EE49}\\u{1EE4B}\\u{1EE4D}-\\u{1EE4F}\\u{1EE51}\\u{1EE52}\\u{1EE54}\\u{1EE57}\\u{1EE59}\\u{1EE5B}\\u{1EE5D}\\u{1EE5F}\\u{1EE61}\\u{1EE62}\\u{1EE64}\\u{1EE67}-\\u{1EE6A}\\u{1EE6C}-\\u{1EE72}\\u{1EE74}-\\u{1EE77}\\u{1EE79}-\\u{1EE7C}\\u{1EE7E}\\u{1EE80}-\\u{1EE89}\\u{1EE8B}-\\u{1EE9B}\\u{1EEA1}-\\u{1EEA3}\\u{1EEA5}-\\u{1EEA9}\\u{1EEAB}-\\u{1EEBB}]/u;\nconst bidiS2 = /^[\\0-\\x08\\x0E-\\x1B!-@\\[-`\\{-\\x84\\x86-\\xA9\\xAB-\\xB4\\xB6-\\xB9\\xBB-\\xBF\\xD7\\xF7\\u02B9\\u02BA\\u02C2-\\u02CF\\u02D2-\\u02DF\\u02E5-\\u02ED\\u02EF-\\u036F\\u0374\\u0375\\u037E\\u0384\\u0385\\u0387\\u03F6\\u0483-\\u0489\\u058A\\u058D-\\u058F\\u0591-\\u05C7\\u05D0-\\u05EA\\u05EF-\\u05F4\\u0600-\\u070D\\u070F-\\u074A\\u074D-\\u07B1\\u07C0-\\u07FA\\u07FD-\\u082D\\u0830-\\u083E\\u0840-\\u085B\\u085E\\u0860-\\u086A\\u0870-\\u088E\\u0890\\u0891\\u0898-\\u0902\\u093A\\u093C\\u0941-\\u0948\\u094D\\u0951-\\u0957\\u0962\\u0963\\u0981\\u09BC\\u09C1-\\u09C4\\u09CD\\u09E2\\u09E3\\u09F2\\u09F3\\u09FB\\u09FE\\u0A01\\u0A02\\u0A3C\\u0A41\\u0A42\\u0A47\\u0A48\\u0A4B-\\u0A4D\\u0A51\\u0A70\\u0A71\\u0A75\\u0A81\\u0A82\\u0ABC\\u0AC1-\\u0AC5\\u0AC7\\u0AC8\\u0ACD\\u0AE2\\u0AE3\\u0AF1\\u0AFA-\\u0AFF\\u0B01\\u0B3C\\u0B3F\\u0B41-\\u0B44\\u0B4D\\u0B55\\u0B56\\u0B62\\u0B63\\u0B82\\u0BC0\\u0BCD\\u0BF3-\\u0BFA\\u0C00\\u0C04\\u0C3C\\u0C3E-\\u0C40\\u0C46-\\u0C48\\u0C4A-\\u0C4D\\u0C55\\u0C56\\u0C62\\u0C63\\u0C78-\\u0C7E\\u0C81\\u0CBC\\u0CCC\\u0CCD\\u0CE2\\u0CE3\\u0D00\\u0D01\\u0D3B\\u0D3C\\u0D41-\\u0D44\\u0D4D\\u0D62\\u0D63\\u0D81\\u0DCA\\u0DD2-\\u0DD4\\u0DD6\\u0E31\\u0E34-\\u0E3A\\u0E3F\\u0E47-\\u0E4E\\u0EB1\\u0EB4-\\u0EBC\\u0EC8-\\u0ECE\\u0F18\\u0F19\\u0F35\\u0F37\\u0F39-\\u0F3D\\u0F71-\\u0F7E\\u0F80-\\u0F84\\u0F86\\u0F87\\u0F8D-\\u0F97\\u0F99-\\u0FBC\\u0FC6\\u102D-\\u1030\\u1032-\\u1037\\u1039\\u103A\\u103D\\u103E\\u1058\\u1059\\u105E-\\u1060\\u1071-\\u1074\\u1082\\u1085\\u1086\\u108D\\u109D\\u135D-\\u135F\\u1390-\\u1399\\u1400\\u169B\\u169C\\u1712-\\u1714\\u1732\\u1733\\u1752\\u1753\\u1772\\u1773\\u17B4\\u17B5\\u17B7-\\u17BD\\u17C6\\u17C9-\\u17D3\\u17DB\\u17DD\\u17F0-\\u17F9\\u1800-\\u180F\\u1885\\u1886\\u18A9\\u1920-\\u1922\\u1927\\u1928\\u1932\\u1939-\\u193B\\u1940\\u1944\\u1945\\u19DE-\\u19FF\\u1A17\\u1A18\\u1A1B\\u1A56\\u1A58-\\u1A5E\\u1A60\\u1A62\\u1A65-\\u1A6C\\u1A73-\\u1A7C\\u1A7F\\u1AB0-\\u1ACE\\u1B00-\\u1B03\\u1B34\\u1B36-\\u1B3A\\u1B3C\\u1B42\\u1B6B-\\u1B73\\u1B80\\u1B81\\u1BA2-\\u1BA5\\u1BA8\\u1BA9\\u1BAB-\\u1BAD\\u1BE6\\u1BE8\\u1BE9\\u1BED\\u1BEF-\\u1BF1\\u1C2C-\\u1C33\\u1C36\\u1C37\\u1CD0-\\u1CD2\\u1CD4-\\u1CE0\\u1CE2-\\u1CE8\\u1CED\\u1CF4\\u1CF8\\u1CF9\\u1DC0-\\u1DFF\\u1FBD\\u1FBF-\\u1FC1\\u1FCD-\\u1FCF\\u1FDD-\\u1FDF\\u1FED-\\u1FEF\\u1FFD\\u1FFE\\u200B-\\u200D\\u200F-\\u2027\\u202F-\\u205E\\u2060-\\u2064\\u206A-\\u2070\\u2074-\\u207E\\u2080-\\u208E\\u20A0-\\u20C0\\u20D0-\\u20F0\\u2100\\u2101\\u2103-\\u2106\\u2108\\u2109\\u2114\\u2116-\\u2118\\u211E-\\u2123\\u2125\\u2127\\u2129\\u212E\\u213A\\u213B\\u2140-\\u2144\\u214A-\\u214D\\u2150-\\u215F\\u2189-\\u218B\\u2190-\\u2335\\u237B-\\u2394\\u2396-\\u2426\\u2440-\\u244A\\u2460-\\u249B\\u24EA-\\u26AB\\u26AD-\\u27FF\\u2900-\\u2B73\\u2B76-\\u2B95\\u2B97-\\u2BFF\\u2CE5-\\u2CEA\\u2CEF-\\u2CF1\\u2CF9-\\u2CFF\\u2D7F\\u2DE0-\\u2E5D\\u2E80-\\u2E99\\u2E9B-\\u2EF3\\u2F00-\\u2FD5\\u2FF0-\\u2FFB\\u3001-\\u3004\\u3008-\\u3020\\u302A-\\u302D\\u3030\\u3036\\u3037\\u303D-\\u303F\\u3099-\\u309C\\u30A0\\u30FB\\u31C0-\\u31E3\\u321D\\u321E\\u3250-\\u325F\\u327C-\\u327E\\u32B1-\\u32BF\\u32CC-\\u32CF\\u3377-\\u337A\\u33DE\\u33DF\\u33FF\\u4DC0-\\u4DFF\\uA490-\\uA4C6\\uA60D-\\uA60F\\uA66F-\\uA67F\\uA69E\\uA69F\\uA6F0\\uA6F1\\uA700-\\uA721\\uA788\\uA802\\uA806\\uA80B\\uA825\\uA826\\uA828-\\uA82C\\uA838\\uA839\\uA874-\\uA877\\uA8C4\\uA8C5\\uA8E0-\\uA8F1\\uA8FF\\uA926-\\uA92D\\uA947-\\uA951\\uA980-\\uA982\\uA9B3\\uA9B6-\\uA9B9\\uA9BC\\uA9BD\\uA9E5\\uAA29-\\uAA2E\\uAA31\\uAA32\\uAA35\\uAA36\\uAA43\\uAA4C\\uAA7C\\uAAB0\\uAAB2-\\uAAB4\\uAAB7\\uAAB8\\uAABE\\uAABF\\uAAC1\\uAAEC\\uAAED\\uAAF6\\uAB6A\\uAB6B\\uABE5\\uABE8\\uABED\\uFB1D-\\uFB36\\uFB38-\\uFB3C\\uFB3E\\uFB40\\uFB41\\uFB43\\uFB44\\uFB46-\\uFBC2\\uFBD3-\\uFD8F\\uFD92-\\uFDC7\\uFDCF\\uFDF0-\\uFE19\\uFE20-\\uFE52\\uFE54-\\uFE66\\uFE68-\\uFE6B\\uFE70-\\uFE74\\uFE76-\\uFEFC\\uFEFF\\uFF01-\\uFF20\\uFF3B-\\uFF40\\uFF5B-\\uFF65\\uFFE0-\\uFFE6\\uFFE8-\\uFFEE\\uFFF9-\\uFFFD\\u{10101}\\u{10140}-\\u{1018C}\\u{10190}-\\u{1019C}\\u{101A0}\\u{101FD}\\u{102E0}-\\u{102FB}\\u{10376}-\\u{1037A}\\u{10800}-\\u{10805}\\u{10808}\\u{1080A}-\\u{10835}\\u{10837}\\u{10838}\\u{1083C}\\u{1083F}-\\u{10855}\\u{10857}-\\u{1089E}\\u{108A7}-\\u{108AF}\\u{108E0}-\\u{108F2}\\u{108F4}\\u{108F5}\\u{108FB}-\\u{1091B}\\u{1091F}-\\u{10939}\\u{1093F}\\u{10980}-\\u{109B7}\\u{109BC}-\\u{109CF}\\u{109D2}-\\u{10A03}\\u{10A05}\\u{10A06}\\u{10A0C}-\\u{10A13}\\u{10A15}-\\u{10A17}\\u{10A19}-\\u{10A35}\\u{10A38}-\\u{10A3A}\\u{10A3F}-\\u{10A48}\\u{10A50}-\\u{10A58}\\u{10A60}-\\u{10A9F}\\u{10AC0}-\\u{10AE6}\\u{10AEB}-\\u{10AF6}\\u{10B00}-\\u{10B35}\\u{10B39}-\\u{10B55}\\u{10B58}-\\u{10B72}\\u{10B78}-\\u{10B91}\\u{10B99}-\\u{10B9C}\\u{10BA9}-\\u{10BAF}\\u{10C00}-\\u{10C48}\\u{10C80}-\\u{10CB2}\\u{10CC0}-\\u{10CF2}\\u{10CFA}-\\u{10D27}\\u{10D30}-\\u{10D39}\\u{10E60}-\\u{10E7E}\\u{10E80}-\\u{10EA9}\\u{10EAB}-\\u{10EAD}\\u{10EB0}\\u{10EB1}\\u{10EFD}-\\u{10F27}\\u{10F30}-\\u{10F59}\\u{10F70}-\\u{10F89}\\u{10FB0}-\\u{10FCB}\\u{10FE0}-\\u{10FF6}\\u{11001}\\u{11038}-\\u{11046}\\u{11052}-\\u{11065}\\u{11070}\\u{11073}\\u{11074}\\u{1107F}-\\u{11081}\\u{110B3}-\\u{110B6}\\u{110B9}\\u{110BA}\\u{110C2}\\u{11100}-\\u{11102}\\u{11127}-\\u{1112B}\\u{1112D}-\\u{11134}\\u{11173}\\u{11180}\\u{11181}\\u{111B6}-\\u{111BE}\\u{111C9}-\\u{111CC}\\u{111CF}\\u{1122F}-\\u{11231}\\u{11234}\\u{11236}\\u{11237}\\u{1123E}\\u{11241}\\u{112DF}\\u{112E3}-\\u{112EA}\\u{11300}\\u{11301}\\u{1133B}\\u{1133C}\\u{11340}\\u{11366}-\\u{1136C}\\u{11370}-\\u{11374}\\u{11438}-\\u{1143F}\\u{11442}-\\u{11444}\\u{11446}\\u{1145E}\\u{114B3}-\\u{114B8}\\u{114BA}\\u{114BF}\\u{114C0}\\u{114C2}\\u{114C3}\\u{115B2}-\\u{115B5}\\u{115BC}\\u{115BD}\\u{115BF}\\u{115C0}\\u{115DC}\\u{115DD}\\u{11633}-\\u{1163A}\\u{1163D}\\u{1163F}\\u{11640}\\u{11660}-\\u{1166C}\\u{116AB}\\u{116AD}\\u{116B0}-\\u{116B5}\\u{116B7}\\u{1171D}-\\u{1171F}\\u{11722}-\\u{11725}\\u{11727}-\\u{1172B}\\u{1182F}-\\u{11837}\\u{11839}\\u{1183A}\\u{1193B}\\u{1193C}\\u{1193E}\\u{11943}\\u{119D4}-\\u{119D7}\\u{119DA}\\u{119DB}\\u{119E0}\\u{11A01}-\\u{11A06}\\u{11A09}\\u{11A0A}\\u{11A33}-\\u{11A38}\\u{11A3B}-\\u{11A3E}\\u{11A47}\\u{11A51}-\\u{11A56}\\u{11A59}-\\u{11A5B}\\u{11A8A}-\\u{11A96}\\u{11A98}\\u{11A99}\\u{11C30}-\\u{11C36}\\u{11C38}-\\u{11C3D}\\u{11C92}-\\u{11CA7}\\u{11CAA}-\\u{11CB0}\\u{11CB2}\\u{11CB3}\\u{11CB5}\\u{11CB6}\\u{11D31}-\\u{11D36}\\u{11D3A}\\u{11D3C}\\u{11D3D}\\u{11D3F}-\\u{11D45}\\u{11D47}\\u{11D90}\\u{11D91}\\u{11D95}\\u{11D97}\\u{11EF3}\\u{11EF4}\\u{11F00}\\u{11F01}\\u{11F36}-\\u{11F3A}\\u{11F40}\\u{11F42}\\u{11FD5}-\\u{11FF1}\\u{13440}\\u{13447}-\\u{13455}\\u{16AF0}-\\u{16AF4}\\u{16B30}-\\u{16B36}\\u{16F4F}\\u{16F8F}-\\u{16F92}\\u{16FE2}\\u{16FE4}\\u{1BC9D}\\u{1BC9E}\\u{1BCA0}-\\u{1BCA3}\\u{1CF00}-\\u{1CF2D}\\u{1CF30}-\\u{1CF46}\\u{1D167}-\\u{1D169}\\u{1D173}-\\u{1D182}\\u{1D185}-\\u{1D18B}\\u{1D1AA}-\\u{1D1AD}\\u{1D1E9}\\u{1D1EA}\\u{1D200}-\\u{1D245}\\u{1D300}-\\u{1D356}\\u{1D6DB}\\u{1D715}\\u{1D74F}\\u{1D789}\\u{1D7C3}\\u{1D7CE}-\\u{1D7FF}\\u{1DA00}-\\u{1DA36}\\u{1DA3B}-\\u{1DA6C}\\u{1DA75}\\u{1DA84}\\u{1DA9B}-\\u{1DA9F}\\u{1DAA1}-\\u{1DAAF}\\u{1E000}-\\u{1E006}\\u{1E008}-\\u{1E018}\\u{1E01B}-\\u{1E021}\\u{1E023}\\u{1E024}\\u{1E026}-\\u{1E02A}\\u{1E08F}\\u{1E130}-\\u{1E136}\\u{1E2AE}\\u{1E2EC}-\\u{1E2EF}\\u{1E2FF}\\u{1E4EC}-\\u{1E4EF}\\u{1E800}-\\u{1E8C4}\\u{1E8C7}-\\u{1E8D6}\\u{1E900}-\\u{1E94B}\\u{1E950}-\\u{1E959}\\u{1E95E}\\u{1E95F}\\u{1EC71}-\\u{1ECB4}\\u{1ED01}-\\u{1ED3D}\\u{1EE00}-\\u{1EE03}\\u{1EE05}-\\u{1EE1F}\\u{1EE21}\\u{1EE22}\\u{1EE24}\\u{1EE27}\\u{1EE29}-\\u{1EE32}\\u{1EE34}-\\u{1EE37}\\u{1EE39}\\u{1EE3B}\\u{1EE42}\\u{1EE47}\\u{1EE49}\\u{1EE4B}\\u{1EE4D}-\\u{1EE4F}\\u{1EE51}\\u{1EE52}\\u{1EE54}\\u{1EE57}\\u{1EE59}\\u{1EE5B}\\u{1EE5D}\\u{1EE5F}\\u{1EE61}\\u{1EE62}\\u{1EE64}\\u{1EE67}-\\u{1EE6A}\\u{1EE6C}-\\u{1EE72}\\u{1EE74}-\\u{1EE77}\\u{1EE79}-\\u{1EE7C}\\u{1EE7E}\\u{1EE80}-\\u{1EE89}\\u{1EE8B}-\\u{1EE9B}\\u{1EEA1}-\\u{1EEA3}\\u{1EEA5}-\\u{1EEA9}\\u{1EEAB}-\\u{1EEBB}\\u{1EEF0}\\u{1EEF1}\\u{1F000}-\\u{1F02B}\\u{1F030}-\\u{1F093}\\u{1F0A0}-\\u{1F0AE}\\u{1F0B1}-\\u{1F0BF}\\u{1F0C1}-\\u{1F0CF}\\u{1F0D1}-\\u{1F0F5}\\u{1F100}-\\u{1F10F}\\u{1F12F}\\u{1F16A}-\\u{1F16F}\\u{1F1AD}\\u{1F260}-\\u{1F265}\\u{1F300}-\\u{1F6D7}\\u{1F6DC}-\\u{1F6EC}\\u{1F6F0}-\\u{1F6FC}\\u{1F700}-\\u{1F776}\\u{1F77B}-\\u{1F7D9}\\u{1F7E0}-\\u{1F7EB}\\u{1F7F0}\\u{1F800}-\\u{1F80B}\\u{1F810}-\\u{1F847}\\u{1F850}-\\u{1F859}\\u{1F860}-\\u{1F887}\\u{1F890}-\\u{1F8AD}\\u{1F8B0}\\u{1F8B1}\\u{1F900}-\\u{1FA53}\\u{1FA60}-\\u{1FA6D}\\u{1FA70}-\\u{1FA7C}\\u{1FA80}-\\u{1FA88}\\u{1FA90}-\\u{1FABD}\\u{1FABF}-\\u{1FAC5}\\u{1FACE}-\\u{1FADB}\\u{1FAE0}-\\u{1FAE8}\\u{1FAF0}-\\u{1FAF8}\\u{1FB00}-\\u{1FB92}\\u{1FB94}-\\u{1FBCA}\\u{1FBF0}-\\u{1FBF9}\\u{E0001}\\u{E0020}-\\u{E007F}\\u{E0100}-\\u{E01EF}]*$/u;\nconst bidiS3 = /[0-9\\xB2\\xB3\\xB9\\u05BE\\u05C0\\u05C3\\u05C6\\u05D0-\\u05EA\\u05EF-\\u05F4\\u0600-\\u0605\\u0608\\u060B\\u060D\\u061B-\\u064A\\u0660-\\u0669\\u066B-\\u066F\\u0671-\\u06D5\\u06DD\\u06E5\\u06E6\\u06EE-\\u070D\\u070F\\u0710\\u0712-\\u072F\\u074D-\\u07A5\\u07B1\\u07C0-\\u07EA\\u07F4\\u07F5\\u07FA\\u07FE-\\u0815\\u081A\\u0824\\u0828\\u0830-\\u083E\\u0840-\\u0858\\u085E\\u0860-\\u086A\\u0870-\\u088E\\u0890\\u0891\\u08A0-\\u08C9\\u08E2\\u200F\\u2070\\u2074-\\u2079\\u2080-\\u2089\\u2488-\\u249B\\uFB1D\\uFB1F-\\uFB28\\uFB2A-\\uFB36\\uFB38-\\uFB3C\\uFB3E\\uFB40\\uFB41\\uFB43\\uFB44\\uFB46-\\uFBC2\\uFBD3-\\uFD3D\\uFD50-\\uFD8F\\uFD92-\\uFDC7\\uFDF0-\\uFDFC\\uFE70-\\uFE74\\uFE76-\\uFEFC\\uFF10-\\uFF19\\u{102E1}-\\u{102FB}\\u{10800}-\\u{10805}\\u{10808}\\u{1080A}-\\u{10835}\\u{10837}\\u{10838}\\u{1083C}\\u{1083F}-\\u{10855}\\u{10857}-\\u{1089E}\\u{108A7}-\\u{108AF}\\u{108E0}-\\u{108F2}\\u{108F4}\\u{108F5}\\u{108FB}-\\u{1091B}\\u{10920}-\\u{10939}\\u{1093F}\\u{10980}-\\u{109B7}\\u{109BC}-\\u{109CF}\\u{109D2}-\\u{10A00}\\u{10A10}-\\u{10A13}\\u{10A15}-\\u{10A17}\\u{10A19}-\\u{10A35}\\u{10A40}-\\u{10A48}\\u{10A50}-\\u{10A58}\\u{10A60}-\\u{10A9F}\\u{10AC0}-\\u{10AE4}\\u{10AEB}-\\u{10AF6}\\u{10B00}-\\u{10B35}\\u{10B40}-\\u{10B55}\\u{10B58}-\\u{10B72}\\u{10B78}-\\u{10B91}\\u{10B99}-\\u{10B9C}\\u{10BA9}-\\u{10BAF}\\u{10C00}-\\u{10C48}\\u{10C80}-\\u{10CB2}\\u{10CC0}-\\u{10CF2}\\u{10CFA}-\\u{10D23}\\u{10D30}-\\u{10D39}\\u{10E60}-\\u{10E7E}\\u{10E80}-\\u{10EA9}\\u{10EAD}\\u{10EB0}\\u{10EB1}\\u{10F00}-\\u{10F27}\\u{10F30}-\\u{10F45}\\u{10F51}-\\u{10F59}\\u{10F70}-\\u{10F81}\\u{10F86}-\\u{10F89}\\u{10FB0}-\\u{10FCB}\\u{10FE0}-\\u{10FF6}\\u{1D7CE}-\\u{1D7FF}\\u{1E800}-\\u{1E8C4}\\u{1E8C7}-\\u{1E8CF}\\u{1E900}-\\u{1E943}\\u{1E94B}\\u{1E950}-\\u{1E959}\\u{1E95E}\\u{1E95F}\\u{1EC71}-\\u{1ECB4}\\u{1ED01}-\\u{1ED3D}\\u{1EE00}-\\u{1EE03}\\u{1EE05}-\\u{1EE1F}\\u{1EE21}\\u{1EE22}\\u{1EE24}\\u{1EE27}\\u{1EE29}-\\u{1EE32}\\u{1EE34}-\\u{1EE37}\\u{1EE39}\\u{1EE3B}\\u{1EE42}\\u{1EE47}\\u{1EE49}\\u{1EE4B}\\u{1EE4D}-\\u{1EE4F}\\u{1EE51}\\u{1EE52}\\u{1EE54}\\u{1EE57}\\u{1EE59}\\u{1EE5B}\\u{1EE5D}\\u{1EE5F}\\u{1EE61}\\u{1EE62}\\u{1EE64}\\u{1EE67}-\\u{1EE6A}\\u{1EE6C}-\\u{1EE72}\\u{1EE74}-\\u{1EE77}\\u{1EE79}-\\u{1EE7C}\\u{1EE7E}\\u{1EE80}-\\u{1EE89}\\u{1EE8B}-\\u{1EE9B}\\u{1EEA1}-\\u{1EEA3}\\u{1EEA5}-\\u{1EEA9}\\u{1EEAB}-\\u{1EEBB}\\u{1F100}-\\u{1F10A}\\u{1FBF0}-\\u{1FBF9}][\\u0300-\\u036F\\u0483-\\u0489\\u0591-\\u05BD\\u05BF\\u05C1\\u05C2\\u05C4\\u05C5\\u05C7\\u0610-\\u061A\\u064B-\\u065F\\u0670\\u06D6-\\u06DC\\u06DF-\\u06E4\\u06E7\\u06E8\\u06EA-\\u06ED\\u0711\\u0730-\\u074A\\u07A6-\\u07B0\\u07EB-\\u07F3\\u07FD\\u0816-\\u0819\\u081B-\\u0823\\u0825-\\u0827\\u0829-\\u082D\\u0859-\\u085B\\u0898-\\u089F\\u08CA-\\u08E1\\u08E3-\\u0902\\u093A\\u093C\\u0941-\\u0948\\u094D\\u0951-\\u0957\\u0962\\u0963\\u0981\\u09BC\\u09C1-\\u09C4\\u09CD\\u09E2\\u09E3\\u09FE\\u0A01\\u0A02\\u0A3C\\u0A41\\u0A42\\u0A47\\u0A48\\u0A4B-\\u0A4D\\u0A51\\u0A70\\u0A71\\u0A75\\u0A81\\u0A82\\u0ABC\\u0AC1-\\u0AC5\\u0AC7\\u0AC8\\u0ACD\\u0AE2\\u0AE3\\u0AFA-\\u0AFF\\u0B01\\u0B3C\\u0B3F\\u0B41-\\u0B44\\u0B4D\\u0B55\\u0B56\\u0B62\\u0B63\\u0B82\\u0BC0\\u0BCD\\u0C00\\u0C04\\u0C3C\\u0C3E-\\u0C40\\u0C46-\\u0C48\\u0C4A-\\u0C4D\\u0C55\\u0C56\\u0C62\\u0C63\\u0C81\\u0CBC\\u0CCC\\u0CCD\\u0CE2\\u0CE3\\u0D00\\u0D01\\u0D3B\\u0D3C\\u0D41-\\u0D44\\u0D4D\\u0D62\\u0D63\\u0D81\\u0DCA\\u0DD2-\\u0DD4\\u0DD6\\u0E31\\u0E34-\\u0E3A\\u0E47-\\u0E4E\\u0EB1\\u0EB4-\\u0EBC\\u0EC8-\\u0ECE\\u0F18\\u0F19\\u0F35\\u0F37\\u0F39\\u0F71-\\u0F7E\\u0F80-\\u0F84\\u0F86\\u0F87\\u0F8D-\\u0F97\\u0F99-\\u0FBC\\u0FC6\\u102D-\\u1030\\u1032-\\u1037\\u1039\\u103A\\u103D\\u103E\\u1058\\u1059\\u105E-\\u1060\\u1071-\\u1074\\u1082\\u1085\\u1086\\u108D\\u109D\\u135D-\\u135F\\u1712-\\u1714\\u1732\\u1733\\u1752\\u1753\\u1772\\u1773\\u17B4\\u17B5\\u17B7-\\u17BD\\u17C6\\u17C9-\\u17D3\\u17DD\\u180B-\\u180D\\u180F\\u1885\\u1886\\u18A9\\u1920-\\u1922\\u1927\\u1928\\u1932\\u1939-\\u193B\\u1A17\\u1A18\\u1A1B\\u1A56\\u1A58-\\u1A5E\\u1A60\\u1A62\\u1A65-\\u1A6C\\u1A73-\\u1A7C\\u1A7F\\u1AB0-\\u1ACE\\u1B00-\\u1B03\\u1B34\\u1B36-\\u1B3A\\u1B3C\\u1B42\\u1B6B-\\u1B73\\u1B80\\u1B81\\u1BA2-\\u1BA5\\u1BA8\\u1BA9\\u1BAB-\\u1BAD\\u1BE6\\u1BE8\\u1BE9\\u1BED\\u1BEF-\\u1BF1\\u1C2C-\\u1C33\\u1C36\\u1C37\\u1CD0-\\u1CD2\\u1CD4-\\u1CE0\\u1CE2-\\u1CE8\\u1CED\\u1CF4\\u1CF8\\u1CF9\\u1DC0-\\u1DFF\\u20D0-\\u20F0\\u2CEF-\\u2CF1\\u2D7F\\u2DE0-\\u2DFF\\u302A-\\u302D\\u3099\\u309A\\uA66F-\\uA672\\uA674-\\uA67D\\uA69E\\uA69F\\uA6F0\\uA6F1\\uA802\\uA806\\uA80B\\uA825\\uA826\\uA82C\\uA8C4\\uA8C5\\uA8E0-\\uA8F1\\uA8FF\\uA926-\\uA92D\\uA947-\\uA951\\uA980-\\uA982\\uA9B3\\uA9B6-\\uA9B9\\uA9BC\\uA9BD\\uA9E5\\uAA29-\\uAA2E\\uAA31\\uAA32\\uAA35\\uAA36\\uAA43\\uAA4C\\uAA7C\\uAAB0\\uAAB2-\\uAAB4\\uAAB7\\uAAB8\\uAABE\\uAABF\\uAAC1\\uAAEC\\uAAED\\uAAF6\\uABE5\\uABE8\\uABED\\uFB1E\\uFE00-\\uFE0F\\uFE20-\\uFE2F\\u{101FD}\\u{102E0}\\u{10376}-\\u{1037A}\\u{10A01}-\\u{10A03}\\u{10A05}\\u{10A06}\\u{10A0C}-\\u{10A0F}\\u{10A38}-\\u{10A3A}\\u{10A3F}\\u{10AE5}\\u{10AE6}\\u{10D24}-\\u{10D27}\\u{10EAB}\\u{10EAC}\\u{10EFD}-\\u{10EFF}\\u{10F46}-\\u{10F50}\\u{10F82}-\\u{10F85}\\u{11001}\\u{11038}-\\u{11046}\\u{11070}\\u{11073}\\u{11074}\\u{1107F}-\\u{11081}\\u{110B3}-\\u{110B6}\\u{110B9}\\u{110BA}\\u{110C2}\\u{11100}-\\u{11102}\\u{11127}-\\u{1112B}\\u{1112D}-\\u{11134}\\u{11173}\\u{11180}\\u{11181}\\u{111B6}-\\u{111BE}\\u{111C9}-\\u{111CC}\\u{111CF}\\u{1122F}-\\u{11231}\\u{11234}\\u{11236}\\u{11237}\\u{1123E}\\u{11241}\\u{112DF}\\u{112E3}-\\u{112EA}\\u{11300}\\u{11301}\\u{1133B}\\u{1133C}\\u{11340}\\u{11366}-\\u{1136C}\\u{11370}-\\u{11374}\\u{11438}-\\u{1143F}\\u{11442}-\\u{11444}\\u{11446}\\u{1145E}\\u{114B3}-\\u{114B8}\\u{114BA}\\u{114BF}\\u{114C0}\\u{114C2}\\u{114C3}\\u{115B2}-\\u{115B5}\\u{115BC}\\u{115BD}\\u{115BF}\\u{115C0}\\u{115DC}\\u{115DD}\\u{11633}-\\u{1163A}\\u{1163D}\\u{1163F}\\u{11640}\\u{116AB}\\u{116AD}\\u{116B0}-\\u{116B5}\\u{116B7}\\u{1171D}-\\u{1171F}\\u{11722}-\\u{11725}\\u{11727}-\\u{1172B}\\u{1182F}-\\u{11837}\\u{11839}\\u{1183A}\\u{1193B}\\u{1193C}\\u{1193E}\\u{11943}\\u{119D4}-\\u{119D7}\\u{119DA}\\u{119DB}\\u{119E0}\\u{11A01}-\\u{11A06}\\u{11A09}\\u{11A0A}\\u{11A33}-\\u{11A38}\\u{11A3B}-\\u{11A3E}\\u{11A47}\\u{11A51}-\\u{11A56}\\u{11A59}-\\u{11A5B}\\u{11A8A}-\\u{11A96}\\u{11A98}\\u{11A99}\\u{11C30}-\\u{11C36}\\u{11C38}-\\u{11C3D}\\u{11C92}-\\u{11CA7}\\u{11CAA}-\\u{11CB0}\\u{11CB2}\\u{11CB3}\\u{11CB5}\\u{11CB6}\\u{11D31}-\\u{11D36}\\u{11D3A}\\u{11D3C}\\u{11D3D}\\u{11D3F}-\\u{11D45}\\u{11D47}\\u{11D90}\\u{11D91}\\u{11D95}\\u{11D97}\\u{11EF3}\\u{11EF4}\\u{11F00}\\u{11F01}\\u{11F36}-\\u{11F3A}\\u{11F40}\\u{11F42}\\u{13440}\\u{13447}-\\u{13455}\\u{16AF0}-\\u{16AF4}\\u{16B30}-\\u{16B36}\\u{16F4F}\\u{16F8F}-\\u{16F92}\\u{16FE4}\\u{1BC9D}\\u{1BC9E}\\u{1CF00}-\\u{1CF2D}\\u{1CF30}-\\u{1CF46}\\u{1D167}-\\u{1D169}\\u{1D17B}-\\u{1D182}\\u{1D185}-\\u{1D18B}\\u{1D1AA}-\\u{1D1AD}\\u{1D242}-\\u{1D244}\\u{1DA00}-\\u{1DA36}\\u{1DA3B}-\\u{1DA6C}\\u{1DA75}\\u{1DA84}\\u{1DA9B}-\\u{1DA9F}\\u{1DAA1}-\\u{1DAAF}\\u{1E000}-\\u{1E006}\\u{1E008}-\\u{1E018}\\u{1E01B}-\\u{1E021}\\u{1E023}\\u{1E024}\\u{1E026}-\\u{1E02A}\\u{1E08F}\\u{1E130}-\\u{1E136}\\u{1E2AE}\\u{1E2EC}-\\u{1E2EF}\\u{1E4EC}-\\u{1E4EF}\\u{1E8D0}-\\u{1E8D6}\\u{1E944}-\\u{1E94A}\\u{E0100}-\\u{E01EF}]*$/u;\nconst bidiS4EN = /[0-9\\xB2\\xB3\\xB9\\u06F0-\\u06F9\\u2070\\u2074-\\u2079\\u2080-\\u2089\\u2488-\\u249B\\uFF10-\\uFF19\\u{102E1}-\\u{102FB}\\u{1D7CE}-\\u{1D7FF}\\u{1F100}-\\u{1F10A}\\u{1FBF0}-\\u{1FBF9}]/u;\nconst bidiS4AN = /[\\u0600-\\u0605\\u0660-\\u0669\\u066B\\u066C\\u06DD\\u0890\\u0891\\u08E2\\u{10D30}-\\u{10D39}\\u{10E60}-\\u{10E7E}]/u;\nconst bidiS5 = /^[\\0-\\x08\\x0E-\\x1B!-\\x84\\x86-\\u0377\\u037A-\\u037F\\u0384-\\u038A\\u038C\\u038E-\\u03A1\\u03A3-\\u052F\\u0531-\\u0556\\u0559-\\u058A\\u058D-\\u058F\\u0591-\\u05BD\\u05BF\\u05C1\\u05C2\\u05C4\\u05C5\\u05C7\\u0606\\u0607\\u0609\\u060A\\u060C\\u060E-\\u061A\\u064B-\\u065F\\u066A\\u0670\\u06D6-\\u06DC\\u06DE-\\u06E4\\u06E7-\\u06ED\\u06F0-\\u06F9\\u0711\\u0730-\\u074A\\u07A6-\\u07B0\\u07EB-\\u07F3\\u07F6-\\u07F9\\u07FD\\u0816-\\u0819\\u081B-\\u0823\\u0825-\\u0827\\u0829-\\u082D\\u0859-\\u085B\\u0898-\\u089F\\u08CA-\\u08E1\\u08E3-\\u0983\\u0985-\\u098C\\u098F\\u0990\\u0993-\\u09A8\\u09AA-\\u09B0\\u09B2\\u09B6-\\u09B9\\u09BC-\\u09C4\\u09C7\\u09C8\\u09CB-\\u09CE\\u09D7\\u09DC\\u09DD\\u09DF-\\u09E3\\u09E6-\\u09FE\\u0A01-\\u0A03\\u0A05-\\u0A0A\\u0A0F\\u0A10\\u0A13-\\u0A28\\u0A2A-\\u0A30\\u0A32\\u0A33\\u0A35\\u0A36\\u0A38\\u0A39\\u0A3C\\u0A3E-\\u0A42\\u0A47\\u0A48\\u0A4B-\\u0A4D\\u0A51\\u0A59-\\u0A5C\\u0A5E\\u0A66-\\u0A76\\u0A81-\\u0A83\\u0A85-\\u0A8D\\u0A8F-\\u0A91\\u0A93-\\u0AA8\\u0AAA-\\u0AB0\\u0AB2\\u0AB3\\u0AB5-\\u0AB9\\u0ABC-\\u0AC5\\u0AC7-\\u0AC9\\u0ACB-\\u0ACD\\u0AD0\\u0AE0-\\u0AE3\\u0AE6-\\u0AF1\\u0AF9-\\u0AFF\\u0B01-\\u0B03\\u0B05-\\u0B0C\\u0B0F\\u0B10\\u0B13-\\u0B28\\u0B2A-\\u0B30\\u0B32\\u0B33\\u0B35-\\u0B39\\u0B3C-\\u0B44\\u0B47\\u0B48\\u0B4B-\\u0B4D\\u0B55-\\u0B57\\u0B5C\\u0B5D\\u0B5F-\\u0B63\\u0B66-\\u0B77\\u0B82\\u0B83\\u0B85-\\u0B8A\\u0B8E-\\u0B90\\u0B92-\\u0B95\\u0B99\\u0B9A\\u0B9C\\u0B9E\\u0B9F\\u0BA3\\u0BA4\\u0BA8-\\u0BAA\\u0BAE-\\u0BB9\\u0BBE-\\u0BC2\\u0BC6-\\u0BC8\\u0BCA-\\u0BCD\\u0BD0\\u0BD7\\u0BE6-\\u0BFA\\u0C00-\\u0C0C\\u0C0E-\\u0C10\\u0C12-\\u0C28\\u0C2A-\\u0C39\\u0C3C-\\u0C44\\u0C46-\\u0C48\\u0C4A-\\u0C4D\\u0C55\\u0C56\\u0C58-\\u0C5A\\u0C5D\\u0C60-\\u0C63\\u0C66-\\u0C6F\\u0C77-\\u0C8C\\u0C8E-\\u0C90\\u0C92-\\u0CA8\\u0CAA-\\u0CB3\\u0CB5-\\u0CB9\\u0CBC-\\u0CC4\\u0CC6-\\u0CC8\\u0CCA-\\u0CCD\\u0CD5\\u0CD6\\u0CDD\\u0CDE\\u0CE0-\\u0CE3\\u0CE6-\\u0CEF\\u0CF1-\\u0CF3\\u0D00-\\u0D0C\\u0D0E-\\u0D10\\u0D12-\\u0D44\\u0D46-\\u0D48\\u0D4A-\\u0D4F\\u0D54-\\u0D63\\u0D66-\\u0D7F\\u0D81-\\u0D83\\u0D85-\\u0D96\\u0D9A-\\u0DB1\\u0DB3-\\u0DBB\\u0DBD\\u0DC0-\\u0DC6\\u0DCA\\u0DCF-\\u0DD4\\u0DD6\\u0DD8-\\u0DDF\\u0DE6-\\u0DEF\\u0DF2-\\u0DF4\\u0E01-\\u0E3A\\u0E3F-\\u0E5B\\u0E81\\u0E82\\u0E84\\u0E86-\\u0E8A\\u0E8C-\\u0EA3\\u0EA5\\u0EA7-\\u0EBD\\u0EC0-\\u0EC4\\u0EC6\\u0EC8-\\u0ECE\\u0ED0-\\u0ED9\\u0EDC-\\u0EDF\\u0F00-\\u0F47\\u0F49-\\u0F6C\\u0F71-\\u0F97\\u0F99-\\u0FBC\\u0FBE-\\u0FCC\\u0FCE-\\u0FDA\\u1000-\\u10C5\\u10C7\\u10CD\\u10D0-\\u1248\\u124A-\\u124D\\u1250-\\u1256\\u1258\\u125A-\\u125D\\u1260-\\u1288\\u128A-\\u128D\\u1290-\\u12B0\\u12B2-\\u12B5\\u12B8-\\u12BE\\u12C0\\u12C2-\\u12C5\\u12C8-\\u12D6\\u12D8-\\u1310\\u1312-\\u1315\\u1318-\\u135A\\u135D-\\u137C\\u1380-\\u1399\\u13A0-\\u13F5\\u13F8-\\u13FD\\u1400-\\u167F\\u1681-\\u169C\\u16A0-\\u16F8\\u1700-\\u1715\\u171F-\\u1736\\u1740-\\u1753\\u1760-\\u176C\\u176E-\\u1770\\u1772\\u1773\\u1780-\\u17DD\\u17E0-\\u17E9\\u17F0-\\u17F9\\u1800-\\u1819\\u1820-\\u1878\\u1880-\\u18AA\\u18B0-\\u18F5\\u1900-\\u191E\\u1920-\\u192B\\u1930-\\u193B\\u1940\\u1944-\\u196D\\u1970-\\u1974\\u1980-\\u19AB\\u19B0-\\u19C9\\u19D0-\\u19DA\\u19DE-\\u1A1B\\u1A1E-\\u1A5E\\u1A60-\\u1A7C\\u1A7F-\\u1A89\\u1A90-\\u1A99\\u1AA0-\\u1AAD\\u1AB0-\\u1ACE\\u1B00-\\u1B4C\\u1B50-\\u1B7E\\u1B80-\\u1BF3\\u1BFC-\\u1C37\\u1C3B-\\u1C49\\u1C4D-\\u1C88\\u1C90-\\u1CBA\\u1CBD-\\u1CC7\\u1CD0-\\u1CFA\\u1D00-\\u1F15\\u1F18-\\u1F1D\\u1F20-\\u1F45\\u1F48-\\u1F4D\\u1F50-\\u1F57\\u1F59\\u1F5B\\u1F5D\\u1F5F-\\u1F7D\\u1F80-\\u1FB4\\u1FB6-\\u1FC4\\u1FC6-\\u1FD3\\u1FD6-\\u1FDB\\u1FDD-\\u1FEF\\u1FF2-\\u1FF4\\u1FF6-\\u1FFE\\u200B-\\u200E\\u2010-\\u2027\\u202F-\\u205E\\u2060-\\u2064\\u206A-\\u2071\\u2074-\\u208E\\u2090-\\u209C\\u20A0-\\u20C0\\u20D0-\\u20F0\\u2100-\\u218B\\u2190-\\u2426\\u2440-\\u244A\\u2460-\\u2B73\\u2B76-\\u2B95\\u2B97-\\u2CF3\\u2CF9-\\u2D25\\u2D27\\u2D2D\\u2D30-\\u2D67\\u2D6F\\u2D70\\u2D7F-\\u2D96\\u2DA0-\\u2DA6\\u2DA8-\\u2DAE\\u2DB0-\\u2DB6\\u2DB8-\\u2DBE\\u2DC0-\\u2DC6\\u2DC8-\\u2DCE\\u2DD0-\\u2DD6\\u2DD8-\\u2DDE\\u2DE0-\\u2E5D\\u2E80-\\u2E99\\u2E9B-\\u2EF3\\u2F00-\\u2FD5\\u2FF0-\\u2FFB\\u3001-\\u303F\\u3041-\\u3096\\u3099-\\u30FF\\u3105-\\u312F\\u3131-\\u318E\\u3190-\\u31E3\\u31F0-\\u321E\\u3220-\\uA48C\\uA490-\\uA4C6\\uA4D0-\\uA62B\\uA640-\\uA6F7\\uA700-\\uA7CA\\uA7D0\\uA7D1\\uA7D3\\uA7D5-\\uA7D9\\uA7F2-\\uA82C\\uA830-\\uA839\\uA840-\\uA877\\uA880-\\uA8C5\\uA8CE-\\uA8D9\\uA8E0-\\uA953\\uA95F-\\uA97C\\uA980-\\uA9CD\\uA9CF-\\uA9D9\\uA9DE-\\uA9FE\\uAA00-\\uAA36\\uAA40-\\uAA4D\\uAA50-\\uAA59\\uAA5C-\\uAAC2\\uAADB-\\uAAF6\\uAB01-\\uAB06\\uAB09-\\uAB0E\\uAB11-\\uAB16\\uAB20-\\uAB26\\uAB28-\\uAB2E\\uAB30-\\uAB6B\\uAB70-\\uABED\\uABF0-\\uABF9\\uAC00-\\uD7A3\\uD7B0-\\uD7C6\\uD7CB-\\uD7FB\\uD800-\\uFA6D\\uFA70-\\uFAD9\\uFB00-\\uFB06\\uFB13-\\uFB17\\uFB1E\\uFB29\\uFD3E-\\uFD4F\\uFDCF\\uFDFD-\\uFE19\\uFE20-\\uFE52\\uFE54-\\uFE66\\uFE68-\\uFE6B\\uFEFF\\uFF01-\\uFFBE\\uFFC2-\\uFFC7\\uFFCA-\\uFFCF\\uFFD2-\\uFFD7\\uFFDA-\\uFFDC\\uFFE0-\\uFFE6\\uFFE8-\\uFFEE\\uFFF9-\\uFFFD\\u{10000}-\\u{1000B}\\u{1000D}-\\u{10026}\\u{10028}-\\u{1003A}\\u{1003C}\\u{1003D}\\u{1003F}-\\u{1004D}\\u{10050}-\\u{1005D}\\u{10080}-\\u{100FA}\\u{10100}-\\u{10102}\\u{10107}-\\u{10133}\\u{10137}-\\u{1018E}\\u{10190}-\\u{1019C}\\u{101A0}\\u{101D0}-\\u{101FD}\\u{10280}-\\u{1029C}\\u{102A0}-\\u{102D0}\\u{102E0}-\\u{102FB}\\u{10300}-\\u{10323}\\u{1032D}-\\u{1034A}\\u{10350}-\\u{1037A}\\u{10380}-\\u{1039D}\\u{1039F}-\\u{103C3}\\u{103C8}-\\u{103D5}\\u{10400}-\\u{1049D}\\u{104A0}-\\u{104A9}\\u{104B0}-\\u{104D3}\\u{104D8}-\\u{104FB}\\u{10500}-\\u{10527}\\u{10530}-\\u{10563}\\u{1056F}-\\u{1057A}\\u{1057C}-\\u{1058A}\\u{1058C}-\\u{10592}\\u{10594}\\u{10595}\\u{10597}-\\u{105A1}\\u{105A3}-\\u{105B1}\\u{105B3}-\\u{105B9}\\u{105BB}\\u{105BC}\\u{10600}-\\u{10736}\\u{10740}-\\u{10755}\\u{10760}-\\u{10767}\\u{10780}-\\u{10785}\\u{10787}-\\u{107B0}\\u{107B2}-\\u{107BA}\\u{1091F}\\u{10A01}-\\u{10A03}\\u{10A05}\\u{10A06}\\u{10A0C}-\\u{10A0F}\\u{10A38}-\\u{10A3A}\\u{10A3F}\\u{10AE5}\\u{10AE6}\\u{10B39}-\\u{10B3F}\\u{10D24}-\\u{10D27}\\u{10EAB}\\u{10EAC}\\u{10EFD}-\\u{10EFF}\\u{10F46}-\\u{10F50}\\u{10F82}-\\u{10F85}\\u{11000}-\\u{1104D}\\u{11052}-\\u{11075}\\u{1107F}-\\u{110C2}\\u{110CD}\\u{110D0}-\\u{110E8}\\u{110F0}-\\u{110F9}\\u{11100}-\\u{11134}\\u{11136}-\\u{11147}\\u{11150}-\\u{11176}\\u{11180}-\\u{111DF}\\u{111E1}-\\u{111F4}\\u{11200}-\\u{11211}\\u{11213}-\\u{11241}\\u{11280}-\\u{11286}\\u{11288}\\u{1128A}-\\u{1128D}\\u{1128F}-\\u{1129D}\\u{1129F}-\\u{112A9}\\u{112B0}-\\u{112EA}\\u{112F0}-\\u{112F9}\\u{11300}-\\u{11303}\\u{11305}-\\u{1130C}\\u{1130F}\\u{11310}\\u{11313}-\\u{11328}\\u{1132A}-\\u{11330}\\u{11332}\\u{11333}\\u{11335}-\\u{11339}\\u{1133B}-\\u{11344}\\u{11347}\\u{11348}\\u{1134B}-\\u{1134D}\\u{11350}\\u{11357}\\u{1135D}-\\u{11363}\\u{11366}-\\u{1136C}\\u{11370}-\\u{11374}\\u{11400}-\\u{1145B}\\u{1145D}-\\u{11461}\\u{11480}-\\u{114C7}\\u{114D0}-\\u{114D9}\\u{11580}-\\u{115B5}\\u{115B8}-\\u{115DD}\\u{11600}-\\u{11644}\\u{11650}-\\u{11659}\\u{11660}-\\u{1166C}\\u{11680}-\\u{116B9}\\u{116C0}-\\u{116C9}\\u{11700}-\\u{1171A}\\u{1171D}-\\u{1172B}\\u{11730}-\\u{11746}\\u{11800}-\\u{1183B}\\u{118A0}-\\u{118F2}\\u{118FF}-\\u{11906}\\u{11909}\\u{1190C}-\\u{11913}\\u{11915}\\u{11916}\\u{11918}-\\u{11935}\\u{11937}\\u{11938}\\u{1193B}-\\u{11946}\\u{11950}-\\u{11959}\\u{119A0}-\\u{119A7}\\u{119AA}-\\u{119D7}\\u{119DA}-\\u{119E4}\\u{11A00}-\\u{11A47}\\u{11A50}-\\u{11AA2}\\u{11AB0}-\\u{11AF8}\\u{11B00}-\\u{11B09}\\u{11C00}-\\u{11C08}\\u{11C0A}-\\u{11C36}\\u{11C38}-\\u{11C45}\\u{11C50}-\\u{11C6C}\\u{11C70}-\\u{11C8F}\\u{11C92}-\\u{11CA7}\\u{11CA9}-\\u{11CB6}\\u{11D00}-\\u{11D06}\\u{11D08}\\u{11D09}\\u{11D0B}-\\u{11D36}\\u{11D3A}\\u{11D3C}\\u{11D3D}\\u{11D3F}-\\u{11D47}\\u{11D50}-\\u{11D59}\\u{11D60}-\\u{11D65}\\u{11D67}\\u{11D68}\\u{11D6A}-\\u{11D8E}\\u{11D90}\\u{11D91}\\u{11D93}-\\u{11D98}\\u{11DA0}-\\u{11DA9}\\u{11EE0}-\\u{11EF8}\\u{11F00}-\\u{11F10}\\u{11F12}-\\u{11F3A}\\u{11F3E}-\\u{11F59}\\u{11FB0}\\u{11FC0}-\\u{11FF1}\\u{11FFF}-\\u{12399}\\u{12400}-\\u{1246E}\\u{12470}-\\u{12474}\\u{12480}-\\u{12543}\\u{12F90}-\\u{12FF2}\\u{13000}-\\u{13455}\\u{14400}-\\u{14646}\\u{16800}-\\u{16A38}\\u{16A40}-\\u{16A5E}\\u{16A60}-\\u{16A69}\\u{16A6E}-\\u{16ABE}\\u{16AC0}-\\u{16AC9}\\u{16AD0}-\\u{16AED}\\u{16AF0}-\\u{16AF5}\\u{16B00}-\\u{16B45}\\u{16B50}-\\u{16B59}\\u{16B5B}-\\u{16B61}\\u{16B63}-\\u{16B77}\\u{16B7D}-\\u{16B8F}\\u{16E40}-\\u{16E9A}\\u{16F00}-\\u{16F4A}\\u{16F4F}-\\u{16F87}\\u{16F8F}-\\u{16F9F}\\u{16FE0}-\\u{16FE4}\\u{16FF0}\\u{16FF1}\\u{17000}-\\u{187F7}\\u{18800}-\\u{18CD5}\\u{18D00}-\\u{18D08}\\u{1AFF0}-\\u{1AFF3}\\u{1AFF5}-\\u{1AFFB}\\u{1AFFD}\\u{1AFFE}\\u{1B000}-\\u{1B122}\\u{1B132}\\u{1B150}-\\u{1B152}\\u{1B155}\\u{1B164}-\\u{1B167}\\u{1B170}-\\u{1B2FB}\\u{1BC00}-\\u{1BC6A}\\u{1BC70}-\\u{1BC7C}\\u{1BC80}-\\u{1BC88}\\u{1BC90}-\\u{1BC99}\\u{1BC9C}-\\u{1BCA3}\\u{1CF00}-\\u{1CF2D}\\u{1CF30}-\\u{1CF46}\\u{1CF50}-\\u{1CFC3}\\u{1D000}-\\u{1D0F5}\\u{1D100}-\\u{1D126}\\u{1D129}-\\u{1D1EA}\\u{1D200}-\\u{1D245}\\u{1D2C0}-\\u{1D2D3}\\u{1D2E0}-\\u{1D2F3}\\u{1D300}-\\u{1D356}\\u{1D360}-\\u{1D378}\\u{1D400}-\\u{1D454}\\u{1D456}-\\u{1D49C}\\u{1D49E}\\u{1D49F}\\u{1D4A2}\\u{1D4A5}\\u{1D4A6}\\u{1D4A9}-\\u{1D4AC}\\u{1D4AE}-\\u{1D4B9}\\u{1D4BB}\\u{1D4BD}-\\u{1D4C3}\\u{1D4C5}-\\u{1D505}\\u{1D507}-\\u{1D50A}\\u{1D50D}-\\u{1D514}\\u{1D516}-\\u{1D51C}\\u{1D51E}-\\u{1D539}\\u{1D53B}-\\u{1D53E}\\u{1D540}-\\u{1D544}\\u{1D546}\\u{1D54A}-\\u{1D550}\\u{1D552}-\\u{1D6A5}\\u{1D6A8}-\\u{1D7CB}\\u{1D7CE}-\\u{1DA8B}\\u{1DA9B}-\\u{1DA9F}\\u{1DAA1}-\\u{1DAAF}\\u{1DF00}-\\u{1DF1E}\\u{1DF25}-\\u{1DF2A}\\u{1E000}-\\u{1E006}\\u{1E008}-\\u{1E018}\\u{1E01B}-\\u{1E021}\\u{1E023}\\u{1E024}\\u{1E026}-\\u{1E02A}\\u{1E030}-\\u{1E06D}\\u{1E08F}\\u{1E100}-\\u{1E12C}\\u{1E130}-\\u{1E13D}\\u{1E140}-\\u{1E149}\\u{1E14E}\\u{1E14F}\\u{1E290}-\\u{1E2AE}\\u{1E2C0}-\\u{1E2F9}\\u{1E2FF}\\u{1E4D0}-\\u{1E4F9}\\u{1E7E0}-\\u{1E7E6}\\u{1E7E8}-\\u{1E7EB}\\u{1E7ED}\\u{1E7EE}\\u{1E7F0}-\\u{1E7FE}\\u{1E8D0}-\\u{1E8D6}\\u{1E944}-\\u{1E94A}\\u{1EEF0}\\u{1EEF1}\\u{1F000}-\\u{1F02B}\\u{1F030}-\\u{1F093}\\u{1F0A0}-\\u{1F0AE}\\u{1F0B1}-\\u{1F0BF}\\u{1F0C1}-\\u{1F0CF}\\u{1F0D1}-\\u{1F0F5}\\u{1F100}-\\u{1F1AD}\\u{1F1E6}-\\u{1F202}\\u{1F210}-\\u{1F23B}\\u{1F240}-\\u{1F248}\\u{1F250}\\u{1F251}\\u{1F260}-\\u{1F265}\\u{1F300}-\\u{1F6D7}\\u{1F6DC}-\\u{1F6EC}\\u{1F6F0}-\\u{1F6FC}\\u{1F700}-\\u{1F776}\\u{1F77B}-\\u{1F7D9}\\u{1F7E0}-\\u{1F7EB}\\u{1F7F0}\\u{1F800}-\\u{1F80B}\\u{1F810}-\\u{1F847}\\u{1F850}-\\u{1F859}\\u{1F860}-\\u{1F887}\\u{1F890}-\\u{1F8AD}\\u{1F8B0}\\u{1F8B1}\\u{1F900}-\\u{1FA53}\\u{1FA60}-\\u{1FA6D}\\u{1FA70}-\\u{1FA7C}\\u{1FA80}-\\u{1FA88}\\u{1FA90}-\\u{1FABD}\\u{1FABF}-\\u{1FAC5}\\u{1FACE}-\\u{1FADB}\\u{1FAE0}-\\u{1FAE8}\\u{1FAF0}-\\u{1FAF8}\\u{1FB00}-\\u{1FB92}\\u{1FB94}-\\u{1FBCA}\\u{1FBF0}-\\u{1FBF9}\\u{20000}-\\u{2A6DF}\\u{2A700}-\\u{2B739}\\u{2B740}-\\u{2B81D}\\u{2B820}-\\u{2CEA1}\\u{2CEB0}-\\u{2EBE0}\\u{2F800}-\\u{2FA1D}\\u{30000}-\\u{3134A}\\u{31350}-\\u{323AF}\\u{E0001}\\u{E0020}-\\u{E007F}\\u{E0100}-\\u{E01EF}\\u{F0000}-\\u{FFFFD}\\u{100000}-\\u{10FFFD}]*$/u;\nconst bidiS6 = /[0-9A-Za-z\\xAA\\xB2\\xB3\\xB5\\xB9\\xBA\\xC0-\\xD6\\xD8-\\xF6\\xF8-\\u02B8\\u02BB-\\u02C1\\u02D0\\u02D1\\u02E0-\\u02E4\\u02EE\\u0370-\\u0373\\u0376\\u0377\\u037A-\\u037D\\u037F\\u0386\\u0388-\\u038A\\u038C\\u038E-\\u03A1\\u03A3-\\u03F5\\u03F7-\\u0482\\u048A-\\u052F\\u0531-\\u0556\\u0559-\\u0589\\u06F0-\\u06F9\\u0903-\\u0939\\u093B\\u093D-\\u0940\\u0949-\\u094C\\u094E-\\u0950\\u0958-\\u0961\\u0964-\\u0980\\u0982\\u0983\\u0985-\\u098C\\u098F\\u0990\\u0993-\\u09A8\\u09AA-\\u09B0\\u09B2\\u09B6-\\u09B9\\u09BD-\\u09C0\\u09C7\\u09C8\\u09CB\\u09CC\\u09CE\\u09D7\\u09DC\\u09DD\\u09DF-\\u09E1\\u09E6-\\u09F1\\u09F4-\\u09FA\\u09FC\\u09FD\\u0A03\\u0A05-\\u0A0A\\u0A0F\\u0A10\\u0A13-\\u0A28\\u0A2A-\\u0A30\\u0A32\\u0A33\\u0A35\\u0A36\\u0A38\\u0A39\\u0A3E-\\u0A40\\u0A59-\\u0A5C\\u0A5E\\u0A66-\\u0A6F\\u0A72-\\u0A74\\u0A76\\u0A83\\u0A85-\\u0A8D\\u0A8F-\\u0A91\\u0A93-\\u0AA8\\u0AAA-\\u0AB0\\u0AB2\\u0AB3\\u0AB5-\\u0AB9\\u0ABD-\\u0AC0\\u0AC9\\u0ACB\\u0ACC\\u0AD0\\u0AE0\\u0AE1\\u0AE6-\\u0AF0\\u0AF9\\u0B02\\u0B03\\u0B05-\\u0B0C\\u0B0F\\u0B10\\u0B13-\\u0B28\\u0B2A-\\u0B30\\u0B32\\u0B33\\u0B35-\\u0B39\\u0B3D\\u0B3E\\u0B40\\u0B47\\u0B48\\u0B4B\\u0B4C\\u0B57\\u0B5C\\u0B5D\\u0B5F-\\u0B61\\u0B66-\\u0B77\\u0B83\\u0B85-\\u0B8A\\u0B8E-\\u0B90\\u0B92-\\u0B95\\u0B99\\u0B9A\\u0B9C\\u0B9E\\u0B9F\\u0BA3\\u0BA4\\u0BA8-\\u0BAA\\u0BAE-\\u0BB9\\u0BBE\\u0BBF\\u0BC1\\u0BC2\\u0BC6-\\u0BC8\\u0BCA-\\u0BCC\\u0BD0\\u0BD7\\u0BE6-\\u0BF2\\u0C01-\\u0C03\\u0C05-\\u0C0C\\u0C0E-\\u0C10\\u0C12-\\u0C28\\u0C2A-\\u0C39\\u0C3D\\u0C41-\\u0C44\\u0C58-\\u0C5A\\u0C5D\\u0C60\\u0C61\\u0C66-\\u0C6F\\u0C77\\u0C7F\\u0C80\\u0C82-\\u0C8C\\u0C8E-\\u0C90\\u0C92-\\u0CA8\\u0CAA-\\u0CB3\\u0CB5-\\u0CB9\\u0CBD-\\u0CC4\\u0CC6-\\u0CC8\\u0CCA\\u0CCB\\u0CD5\\u0CD6\\u0CDD\\u0CDE\\u0CE0\\u0CE1\\u0CE6-\\u0CEF\\u0CF1-\\u0CF3\\u0D02-\\u0D0C\\u0D0E-\\u0D10\\u0D12-\\u0D3A\\u0D3D-\\u0D40\\u0D46-\\u0D48\\u0D4A-\\u0D4C\\u0D4E\\u0D4F\\u0D54-\\u0D61\\u0D66-\\u0D7F\\u0D82\\u0D83\\u0D85-\\u0D96\\u0D9A-\\u0DB1\\u0DB3-\\u0DBB\\u0DBD\\u0DC0-\\u0DC6\\u0DCF-\\u0DD1\\u0DD8-\\u0DDF\\u0DE6-\\u0DEF\\u0DF2-\\u0DF4\\u0E01-\\u0E30\\u0E32\\u0E33\\u0E40-\\u0E46\\u0E4F-\\u0E5B\\u0E81\\u0E82\\u0E84\\u0E86-\\u0E8A\\u0E8C-\\u0EA3\\u0EA5\\u0EA7-\\u0EB0\\u0EB2\\u0EB3\\u0EBD\\u0EC0-\\u0EC4\\u0EC6\\u0ED0-\\u0ED9\\u0EDC-\\u0EDF\\u0F00-\\u0F17\\u0F1A-\\u0F34\\u0F36\\u0F38\\u0F3E-\\u0F47\\u0F49-\\u0F6C\\u0F7F\\u0F85\\u0F88-\\u0F8C\\u0FBE-\\u0FC5\\u0FC7-\\u0FCC\\u0FCE-\\u0FDA\\u1000-\\u102C\\u1031\\u1038\\u103B\\u103C\\u103F-\\u1057\\u105A-\\u105D\\u1061-\\u1070\\u1075-\\u1081\\u1083\\u1084\\u1087-\\u108C\\u108E-\\u109C\\u109E-\\u10C5\\u10C7\\u10CD\\u10D0-\\u1248\\u124A-\\u124D\\u1250-\\u1256\\u1258\\u125A-\\u125D\\u1260-\\u1288\\u128A-\\u128D\\u1290-\\u12B0\\u12B2-\\u12B5\\u12B8-\\u12BE\\u12C0\\u12C2-\\u12C5\\u12C8-\\u12D6\\u12D8-\\u1310\\u1312-\\u1315\\u1318-\\u135A\\u1360-\\u137C\\u1380-\\u138F\\u13A0-\\u13F5\\u13F8-\\u13FD\\u1401-\\u167F\\u1681-\\u169A\\u16A0-\\u16F8\\u1700-\\u1711\\u1715\\u171F-\\u1731\\u1734-\\u1736\\u1740-\\u1751\\u1760-\\u176C\\u176E-\\u1770\\u1780-\\u17B3\\u17B6\\u17BE-\\u17C5\\u17C7\\u17C8\\u17D4-\\u17DA\\u17DC\\u17E0-\\u17E9\\u1810-\\u1819\\u1820-\\u1878\\u1880-\\u1884\\u1887-\\u18A8\\u18AA\\u18B0-\\u18F5\\u1900-\\u191E\\u1923-\\u1926\\u1929-\\u192B\\u1930\\u1931\\u1933-\\u1938\\u1946-\\u196D\\u1970-\\u1974\\u1980-\\u19AB\\u19B0-\\u19C9\\u19D0-\\u19DA\\u1A00-\\u1A16\\u1A19\\u1A1A\\u1A1E-\\u1A55\\u1A57\\u1A61\\u1A63\\u1A64\\u1A6D-\\u1A72\\u1A80-\\u1A89\\u1A90-\\u1A99\\u1AA0-\\u1AAD\\u1B04-\\u1B33\\u1B35\\u1B3B\\u1B3D-\\u1B41\\u1B43-\\u1B4C\\u1B50-\\u1B6A\\u1B74-\\u1B7E\\u1B82-\\u1BA1\\u1BA6\\u1BA7\\u1BAA\\u1BAE-\\u1BE5\\u1BE7\\u1BEA-\\u1BEC\\u1BEE\\u1BF2\\u1BF3\\u1BFC-\\u1C2B\\u1C34\\u1C35\\u1C3B-\\u1C49\\u1C4D-\\u1C88\\u1C90-\\u1CBA\\u1CBD-\\u1CC7\\u1CD3\\u1CE1\\u1CE9-\\u1CEC\\u1CEE-\\u1CF3\\u1CF5-\\u1CF7\\u1CFA\\u1D00-\\u1DBF\\u1E00-\\u1F15\\u1F18-\\u1F1D\\u1F20-\\u1F45\\u1F48-\\u1F4D\\u1F50-\\u1F57\\u1F59\\u1F5B\\u1F5D\\u1F5F-\\u1F7D\\u1F80-\\u1FB4\\u1FB6-\\u1FBC\\u1FBE\\u1FC2-\\u1FC4\\u1FC6-\\u1FCC\\u1FD0-\\u1FD3\\u1FD6-\\u1FDB\\u1FE0-\\u1FEC\\u1FF2-\\u1FF4\\u1FF6-\\u1FFC\\u200E\\u2070\\u2071\\u2074-\\u2079\\u207F-\\u2089\\u2090-\\u209C\\u2102\\u2107\\u210A-\\u2113\\u2115\\u2119-\\u211D\\u2124\\u2126\\u2128\\u212A-\\u212D\\u212F-\\u2139\\u213C-\\u213F\\u2145-\\u2149\\u214E\\u214F\\u2160-\\u2188\\u2336-\\u237A\\u2395\\u2488-\\u24E9\\u26AC\\u2800-\\u28FF\\u2C00-\\u2CE4\\u2CEB-\\u2CEE\\u2CF2\\u2CF3\\u2D00-\\u2D25\\u2D27\\u2D2D\\u2D30-\\u2D67\\u2D6F\\u2D70\\u2D80-\\u2D96\\u2DA0-\\u2DA6\\u2DA8-\\u2DAE\\u2DB0-\\u2DB6\\u2DB8-\\u2DBE\\u2DC0-\\u2DC6\\u2DC8-\\u2DCE\\u2DD0-\\u2DD6\\u2DD8-\\u2DDE\\u3005-\\u3007\\u3021-\\u3029\\u302E\\u302F\\u3031-\\u3035\\u3038-\\u303C\\u3041-\\u3096\\u309D-\\u309F\\u30A1-\\u30FA\\u30FC-\\u30FF\\u3105-\\u312F\\u3131-\\u318E\\u3190-\\u31BF\\u31F0-\\u321C\\u3220-\\u324F\\u3260-\\u327B\\u327F-\\u32B0\\u32C0-\\u32CB\\u32D0-\\u3376\\u337B-\\u33DD\\u33E0-\\u33FE\\u3400-\\u4DBF\\u4E00-\\uA48C\\uA4D0-\\uA60C\\uA610-\\uA62B\\uA640-\\uA66E\\uA680-\\uA69D\\uA6A0-\\uA6EF\\uA6F2-\\uA6F7\\uA722-\\uA787\\uA789-\\uA7CA\\uA7D0\\uA7D1\\uA7D3\\uA7D5-\\uA7D9\\uA7F2-\\uA801\\uA803-\\uA805\\uA807-\\uA80A\\uA80C-\\uA824\\uA827\\uA830-\\uA837\\uA840-\\uA873\\uA880-\\uA8C3\\uA8CE-\\uA8D9\\uA8F2-\\uA8FE\\uA900-\\uA925\\uA92E-\\uA946\\uA952\\uA953\\uA95F-\\uA97C\\uA983-\\uA9B2\\uA9B4\\uA9B5\\uA9BA\\uA9BB\\uA9BE-\\uA9CD\\uA9CF-\\uA9D9\\uA9DE-\\uA9E4\\uA9E6-\\uA9FE\\uAA00-\\uAA28\\uAA2F\\uAA30\\uAA33\\uAA34\\uAA40-\\uAA42\\uAA44-\\uAA4B\\uAA4D\\uAA50-\\uAA59\\uAA5C-\\uAA7B\\uAA7D-\\uAAAF\\uAAB1\\uAAB5\\uAAB6\\uAAB9-\\uAABD\\uAAC0\\uAAC2\\uAADB-\\uAAEB\\uAAEE-\\uAAF5\\uAB01-\\uAB06\\uAB09-\\uAB0E\\uAB11-\\uAB16\\uAB20-\\uAB26\\uAB28-\\uAB2E\\uAB30-\\uAB69\\uAB70-\\uABE4\\uABE6\\uABE7\\uABE9-\\uABEC\\uABF0-\\uABF9\\uAC00-\\uD7A3\\uD7B0-\\uD7C6\\uD7CB-\\uD7FB\\uD800-\\uFA6D\\uFA70-\\uFAD9\\uFB00-\\uFB06\\uFB13-\\uFB17\\uFF10-\\uFF19\\uFF21-\\uFF3A\\uFF41-\\uFF5A\\uFF66-\\uFFBE\\uFFC2-\\uFFC7\\uFFCA-\\uFFCF\\uFFD2-\\uFFD7\\uFFDA-\\uFFDC\\u{10000}-\\u{1000B}\\u{1000D}-\\u{10026}\\u{10028}-\\u{1003A}\\u{1003C}\\u{1003D}\\u{1003F}-\\u{1004D}\\u{10050}-\\u{1005D}\\u{10080}-\\u{100FA}\\u{10100}\\u{10102}\\u{10107}-\\u{10133}\\u{10137}-\\u{1013F}\\u{1018D}\\u{1018E}\\u{101D0}-\\u{101FC}\\u{10280}-\\u{1029C}\\u{102A0}-\\u{102D0}\\u{102E1}-\\u{102FB}\\u{10300}-\\u{10323}\\u{1032D}-\\u{1034A}\\u{10350}-\\u{10375}\\u{10380}-\\u{1039D}\\u{1039F}-\\u{103C3}\\u{103C8}-\\u{103D5}\\u{10400}-\\u{1049D}\\u{104A0}-\\u{104A9}\\u{104B0}-\\u{104D3}\\u{104D8}-\\u{104FB}\\u{10500}-\\u{10527}\\u{10530}-\\u{10563}\\u{1056F}-\\u{1057A}\\u{1057C}-\\u{1058A}\\u{1058C}-\\u{10592}\\u{10594}\\u{10595}\\u{10597}-\\u{105A1}\\u{105A3}-\\u{105B1}\\u{105B3}-\\u{105B9}\\u{105BB}\\u{105BC}\\u{10600}-\\u{10736}\\u{10740}-\\u{10755}\\u{10760}-\\u{10767}\\u{10780}-\\u{10785}\\u{10787}-\\u{107B0}\\u{107B2}-\\u{107BA}\\u{11000}\\u{11002}-\\u{11037}\\u{11047}-\\u{1104D}\\u{11066}-\\u{1106F}\\u{11071}\\u{11072}\\u{11075}\\u{11082}-\\u{110B2}\\u{110B7}\\u{110B8}\\u{110BB}-\\u{110C1}\\u{110CD}\\u{110D0}-\\u{110E8}\\u{110F0}-\\u{110F9}\\u{11103}-\\u{11126}\\u{1112C}\\u{11136}-\\u{11147}\\u{11150}-\\u{11172}\\u{11174}-\\u{11176}\\u{11182}-\\u{111B5}\\u{111BF}-\\u{111C8}\\u{111CD}\\u{111CE}\\u{111D0}-\\u{111DF}\\u{111E1}-\\u{111F4}\\u{11200}-\\u{11211}\\u{11213}-\\u{1122E}\\u{11232}\\u{11233}\\u{11235}\\u{11238}-\\u{1123D}\\u{1123F}\\u{11240}\\u{11280}-\\u{11286}\\u{11288}\\u{1128A}-\\u{1128D}\\u{1128F}-\\u{1129D}\\u{1129F}-\\u{112A9}\\u{112B0}-\\u{112DE}\\u{112E0}-\\u{112E2}\\u{112F0}-\\u{112F9}\\u{11302}\\u{11303}\\u{11305}-\\u{1130C}\\u{1130F}\\u{11310}\\u{11313}-\\u{11328}\\u{1132A}-\\u{11330}\\u{11332}\\u{11333}\\u{11335}-\\u{11339}\\u{1133D}-\\u{1133F}\\u{11341}-\\u{11344}\\u{11347}\\u{11348}\\u{1134B}-\\u{1134D}\\u{11350}\\u{11357}\\u{1135D}-\\u{11363}\\u{11400}-\\u{11437}\\u{11440}\\u{11441}\\u{11445}\\u{11447}-\\u{1145B}\\u{1145D}\\u{1145F}-\\u{11461}\\u{11480}-\\u{114B2}\\u{114B9}\\u{114BB}-\\u{114BE}\\u{114C1}\\u{114C4}-\\u{114C7}\\u{114D0}-\\u{114D9}\\u{11580}-\\u{115B1}\\u{115B8}-\\u{115BB}\\u{115BE}\\u{115C1}-\\u{115DB}\\u{11600}-\\u{11632}\\u{1163B}\\u{1163C}\\u{1163E}\\u{11641}-\\u{11644}\\u{11650}-\\u{11659}\\u{11680}-\\u{116AA}\\u{116AC}\\u{116AE}\\u{116AF}\\u{116B6}\\u{116B8}\\u{116B9}\\u{116C0}-\\u{116C9}\\u{11700}-\\u{1171A}\\u{11720}\\u{11721}\\u{11726}\\u{11730}-\\u{11746}\\u{11800}-\\u{1182E}\\u{11838}\\u{1183B}\\u{118A0}-\\u{118F2}\\u{118FF}-\\u{11906}\\u{11909}\\u{1190C}-\\u{11913}\\u{11915}\\u{11916}\\u{11918}-\\u{11935}\\u{11937}\\u{11938}\\u{1193D}\\u{1193F}-\\u{11942}\\u{11944}-\\u{11946}\\u{11950}-\\u{11959}\\u{119A0}-\\u{119A7}\\u{119AA}-\\u{119D3}\\u{119DC}-\\u{119DF}\\u{119E1}-\\u{119E4}\\u{11A00}\\u{11A07}\\u{11A08}\\u{11A0B}-\\u{11A32}\\u{11A39}\\u{11A3A}\\u{11A3F}-\\u{11A46}\\u{11A50}\\u{11A57}\\u{11A58}\\u{11A5C}-\\u{11A89}\\u{11A97}\\u{11A9A}-\\u{11AA2}\\u{11AB0}-\\u{11AF8}\\u{11B00}-\\u{11B09}\\u{11C00}-\\u{11C08}\\u{11C0A}-\\u{11C2F}\\u{11C3E}-\\u{11C45}\\u{11C50}-\\u{11C6C}\\u{11C70}-\\u{11C8F}\\u{11CA9}\\u{11CB1}\\u{11CB4}\\u{11D00}-\\u{11D06}\\u{11D08}\\u{11D09}\\u{11D0B}-\\u{11D30}\\u{11D46}\\u{11D50}-\\u{11D59}\\u{11D60}-\\u{11D65}\\u{11D67}\\u{11D68}\\u{11D6A}-\\u{11D8E}\\u{11D93}\\u{11D94}\\u{11D96}\\u{11D98}\\u{11DA0}-\\u{11DA9}\\u{11EE0}-\\u{11EF2}\\u{11EF5}-\\u{11EF8}\\u{11F02}-\\u{11F10}\\u{11F12}-\\u{11F35}\\u{11F3E}\\u{11F3F}\\u{11F41}\\u{11F43}-\\u{11F59}\\u{11FB0}\\u{11FC0}-\\u{11FD4}\\u{11FFF}-\\u{12399}\\u{12400}-\\u{1246E}\\u{12470}-\\u{12474}\\u{12480}-\\u{12543}\\u{12F90}-\\u{12FF2}\\u{13000}-\\u{1343F}\\u{13441}-\\u{13446}\\u{14400}-\\u{14646}\\u{16800}-\\u{16A38}\\u{16A40}-\\u{16A5E}\\u{16A60}-\\u{16A69}\\u{16A6E}-\\u{16ABE}\\u{16AC0}-\\u{16AC9}\\u{16AD0}-\\u{16AED}\\u{16AF5}\\u{16B00}-\\u{16B2F}\\u{16B37}-\\u{16B45}\\u{16B50}-\\u{16B59}\\u{16B5B}-\\u{16B61}\\u{16B63}-\\u{16B77}\\u{16B7D}-\\u{16B8F}\\u{16E40}-\\u{16E9A}\\u{16F00}-\\u{16F4A}\\u{16F50}-\\u{16F87}\\u{16F93}-\\u{16F9F}\\u{16FE0}\\u{16FE1}\\u{16FE3}\\u{16FF0}\\u{16FF1}\\u{17000}-\\u{187F7}\\u{18800}-\\u{18CD5}\\u{18D00}-\\u{18D08}\\u{1AFF0}-\\u{1AFF3}\\u{1AFF5}-\\u{1AFFB}\\u{1AFFD}\\u{1AFFE}\\u{1B000}-\\u{1B122}\\u{1B132}\\u{1B150}-\\u{1B152}\\u{1B155}\\u{1B164}-\\u{1B167}\\u{1B170}-\\u{1B2FB}\\u{1BC00}-\\u{1BC6A}\\u{1BC70}-\\u{1BC7C}\\u{1BC80}-\\u{1BC88}\\u{1BC90}-\\u{1BC99}\\u{1BC9C}\\u{1BC9F}\\u{1CF50}-\\u{1CFC3}\\u{1D000}-\\u{1D0F5}\\u{1D100}-\\u{1D126}\\u{1D129}-\\u{1D166}\\u{1D16A}-\\u{1D172}\\u{1D183}\\u{1D184}\\u{1D18C}-\\u{1D1A9}\\u{1D1AE}-\\u{1D1E8}\\u{1D2C0}-\\u{1D2D3}\\u{1D2E0}-\\u{1D2F3}\\u{1D360}-\\u{1D378}\\u{1D400}-\\u{1D454}\\u{1D456}-\\u{1D49C}\\u{1D49E}\\u{1D49F}\\u{1D4A2}\\u{1D4A5}\\u{1D4A6}\\u{1D4A9}-\\u{1D4AC}\\u{1D4AE}-\\u{1D4B9}\\u{1D4BB}\\u{1D4BD}-\\u{1D4C3}\\u{1D4C5}-\\u{1D505}\\u{1D507}-\\u{1D50A}\\u{1D50D}-\\u{1D514}\\u{1D516}-\\u{1D51C}\\u{1D51E}-\\u{1D539}\\u{1D53B}-\\u{1D53E}\\u{1D540}-\\u{1D544}\\u{1D546}\\u{1D54A}-\\u{1D550}\\u{1D552}-\\u{1D6A5}\\u{1D6A8}-\\u{1D6DA}\\u{1D6DC}-\\u{1D714}\\u{1D716}-\\u{1D74E}\\u{1D750}-\\u{1D788}\\u{1D78A}-\\u{1D7C2}\\u{1D7C4}-\\u{1D7CB}\\u{1D7CE}-\\u{1D9FF}\\u{1DA37}-\\u{1DA3A}\\u{1DA6D}-\\u{1DA74}\\u{1DA76}-\\u{1DA83}\\u{1DA85}-\\u{1DA8B}\\u{1DF00}-\\u{1DF1E}\\u{1DF25}-\\u{1DF2A}\\u{1E030}-\\u{1E06D}\\u{1E100}-\\u{1E12C}\\u{1E137}-\\u{1E13D}\\u{1E140}-\\u{1E149}\\u{1E14E}\\u{1E14F}\\u{1E290}-\\u{1E2AD}\\u{1E2C0}-\\u{1E2EB}\\u{1E2F0}-\\u{1E2F9}\\u{1E4D0}-\\u{1E4EB}\\u{1E4F0}-\\u{1E4F9}\\u{1E7E0}-\\u{1E7E6}\\u{1E7E8}-\\u{1E7EB}\\u{1E7ED}\\u{1E7EE}\\u{1E7F0}-\\u{1E7FE}\\u{1F100}-\\u{1F10A}\\u{1F110}-\\u{1F12E}\\u{1F130}-\\u{1F169}\\u{1F170}-\\u{1F1AC}\\u{1F1E6}-\\u{1F202}\\u{1F210}-\\u{1F23B}\\u{1F240}-\\u{1F248}\\u{1F250}\\u{1F251}\\u{1FBF0}-\\u{1FBF9}\\u{20000}-\\u{2A6DF}\\u{2A700}-\\u{2B739}\\u{2B740}-\\u{2B81D}\\u{2B820}-\\u{2CEA1}\\u{2CEB0}-\\u{2EBE0}\\u{2F800}-\\u{2FA1D}\\u{30000}-\\u{3134A}\\u{31350}-\\u{323AF}\\u{F0000}-\\u{FFFFD}\\u{100000}-\\u{10FFFD}][\\u0300-\\u036F\\u0483-\\u0489\\u0591-\\u05BD\\u05BF\\u05C1\\u05C2\\u05C4\\u05C5\\u05C7\\u0610-\\u061A\\u064B-\\u065F\\u0670\\u06D6-\\u06DC\\u06DF-\\u06E4\\u06E7\\u06E8\\u06EA-\\u06ED\\u0711\\u0730-\\u074A\\u07A6-\\u07B0\\u07EB-\\u07F3\\u07FD\\u0816-\\u0819\\u081B-\\u0823\\u0825-\\u0827\\u0829-\\u082D\\u0859-\\u085B\\u0898-\\u089F\\u08CA-\\u08E1\\u08E3-\\u0902\\u093A\\u093C\\u0941-\\u0948\\u094D\\u0951-\\u0957\\u0962\\u0963\\u0981\\u09BC\\u09C1-\\u09C4\\u09CD\\u09E2\\u09E3\\u09FE\\u0A01\\u0A02\\u0A3C\\u0A41\\u0A42\\u0A47\\u0A48\\u0A4B-\\u0A4D\\u0A51\\u0A70\\u0A71\\u0A75\\u0A81\\u0A82\\u0ABC\\u0AC1-\\u0AC5\\u0AC7\\u0AC8\\u0ACD\\u0AE2\\u0AE3\\u0AFA-\\u0AFF\\u0B01\\u0B3C\\u0B3F\\u0B41-\\u0B44\\u0B4D\\u0B55\\u0B56\\u0B62\\u0B63\\u0B82\\u0BC0\\u0BCD\\u0C00\\u0C04\\u0C3C\\u0C3E-\\u0C40\\u0C46-\\u0C48\\u0C4A-\\u0C4D\\u0C55\\u0C56\\u0C62\\u0C63\\u0C81\\u0CBC\\u0CCC\\u0CCD\\u0CE2\\u0CE3\\u0D00\\u0D01\\u0D3B\\u0D3C\\u0D41-\\u0D44\\u0D4D\\u0D62\\u0D63\\u0D81\\u0DCA\\u0DD2-\\u0DD4\\u0DD6\\u0E31\\u0E34-\\u0E3A\\u0E47-\\u0E4E\\u0EB1\\u0EB4-\\u0EBC\\u0EC8-\\u0ECE\\u0F18\\u0F19\\u0F35\\u0F37\\u0F39\\u0F71-\\u0F7E\\u0F80-\\u0F84\\u0F86\\u0F87\\u0F8D-\\u0F97\\u0F99-\\u0FBC\\u0FC6\\u102D-\\u1030\\u1032-\\u1037\\u1039\\u103A\\u103D\\u103E\\u1058\\u1059\\u105E-\\u1060\\u1071-\\u1074\\u1082\\u1085\\u1086\\u108D\\u109D\\u135D-\\u135F\\u1712-\\u1714\\u1732\\u1733\\u1752\\u1753\\u1772\\u1773\\u17B4\\u17B5\\u17B7-\\u17BD\\u17C6\\u17C9-\\u17D3\\u17DD\\u180B-\\u180D\\u180F\\u1885\\u1886\\u18A9\\u1920-\\u1922\\u1927\\u1928\\u1932\\u1939-\\u193B\\u1A17\\u1A18\\u1A1B\\u1A56\\u1A58-\\u1A5E\\u1A60\\u1A62\\u1A65-\\u1A6C\\u1A73-\\u1A7C\\u1A7F\\u1AB0-\\u1ACE\\u1B00-\\u1B03\\u1B34\\u1B36-\\u1B3A\\u1B3C\\u1B42\\u1B6B-\\u1B73\\u1B80\\u1B81\\u1BA2-\\u1BA5\\u1BA8\\u1BA9\\u1BAB-\\u1BAD\\u1BE6\\u1BE8\\u1BE9\\u1BED\\u1BEF-\\u1BF1\\u1C2C-\\u1C33\\u1C36\\u1C37\\u1CD0-\\u1CD2\\u1CD4-\\u1CE0\\u1CE2-\\u1CE8\\u1CED\\u1CF4\\u1CF8\\u1CF9\\u1DC0-\\u1DFF\\u20D0-\\u20F0\\u2CEF-\\u2CF1\\u2D7F\\u2DE0-\\u2DFF\\u302A-\\u302D\\u3099\\u309A\\uA66F-\\uA672\\uA674-\\uA67D\\uA69E\\uA69F\\uA6F0\\uA6F1\\uA802\\uA806\\uA80B\\uA825\\uA826\\uA82C\\uA8C4\\uA8C5\\uA8E0-\\uA8F1\\uA8FF\\uA926-\\uA92D\\uA947-\\uA951\\uA980-\\uA982\\uA9B3\\uA9B6-\\uA9B9\\uA9BC\\uA9BD\\uA9E5\\uAA29-\\uAA2E\\uAA31\\uAA32\\uAA35\\uAA36\\uAA43\\uAA4C\\uAA7C\\uAAB0\\uAAB2-\\uAAB4\\uAAB7\\uAAB8\\uAABE\\uAABF\\uAAC1\\uAAEC\\uAAED\\uAAF6\\uABE5\\uABE8\\uABED\\uFB1E\\uFE00-\\uFE0F\\uFE20-\\uFE2F\\u{101FD}\\u{102E0}\\u{10376}-\\u{1037A}\\u{10A01}-\\u{10A03}\\u{10A05}\\u{10A06}\\u{10A0C}-\\u{10A0F}\\u{10A38}-\\u{10A3A}\\u{10A3F}\\u{10AE5}\\u{10AE6}\\u{10D24}-\\u{10D27}\\u{10EAB}\\u{10EAC}\\u{10EFD}-\\u{10EFF}\\u{10F46}-\\u{10F50}\\u{10F82}-\\u{10F85}\\u{11001}\\u{11038}-\\u{11046}\\u{11070}\\u{11073}\\u{11074}\\u{1107F}-\\u{11081}\\u{110B3}-\\u{110B6}\\u{110B9}\\u{110BA}\\u{110C2}\\u{11100}-\\u{11102}\\u{11127}-\\u{1112B}\\u{1112D}-\\u{11134}\\u{11173}\\u{11180}\\u{11181}\\u{111B6}-\\u{111BE}\\u{111C9}-\\u{111CC}\\u{111CF}\\u{1122F}-\\u{11231}\\u{11234}\\u{11236}\\u{11237}\\u{1123E}\\u{11241}\\u{112DF}\\u{112E3}-\\u{112EA}\\u{11300}\\u{11301}\\u{1133B}\\u{1133C}\\u{11340}\\u{11366}-\\u{1136C}\\u{11370}-\\u{11374}\\u{11438}-\\u{1143F}\\u{11442}-\\u{11444}\\u{11446}\\u{1145E}\\u{114B3}-\\u{114B8}\\u{114BA}\\u{114BF}\\u{114C0}\\u{114C2}\\u{114C3}\\u{115B2}-\\u{115B5}\\u{115BC}\\u{115BD}\\u{115BF}\\u{115C0}\\u{115DC}\\u{115DD}\\u{11633}-\\u{1163A}\\u{1163D}\\u{1163F}\\u{11640}\\u{116AB}\\u{116AD}\\u{116B0}-\\u{116B5}\\u{116B7}\\u{1171D}-\\u{1171F}\\u{11722}-\\u{11725}\\u{11727}-\\u{1172B}\\u{1182F}-\\u{11837}\\u{11839}\\u{1183A}\\u{1193B}\\u{1193C}\\u{1193E}\\u{11943}\\u{119D4}-\\u{119D7}\\u{119DA}\\u{119DB}\\u{119E0}\\u{11A01}-\\u{11A06}\\u{11A09}\\u{11A0A}\\u{11A33}-\\u{11A38}\\u{11A3B}-\\u{11A3E}\\u{11A47}\\u{11A51}-\\u{11A56}\\u{11A59}-\\u{11A5B}\\u{11A8A}-\\u{11A96}\\u{11A98}\\u{11A99}\\u{11C30}-\\u{11C36}\\u{11C38}-\\u{11C3D}\\u{11C92}-\\u{11CA7}\\u{11CAA}-\\u{11CB0}\\u{11CB2}\\u{11CB3}\\u{11CB5}\\u{11CB6}\\u{11D31}-\\u{11D36}\\u{11D3A}\\u{11D3C}\\u{11D3D}\\u{11D3F}-\\u{11D45}\\u{11D47}\\u{11D90}\\u{11D91}\\u{11D95}\\u{11D97}\\u{11EF3}\\u{11EF4}\\u{11F00}\\u{11F01}\\u{11F36}-\\u{11F3A}\\u{11F40}\\u{11F42}\\u{13440}\\u{13447}-\\u{13455}\\u{16AF0}-\\u{16AF4}\\u{16B30}-\\u{16B36}\\u{16F4F}\\u{16F8F}-\\u{16F92}\\u{16FE4}\\u{1BC9D}\\u{1BC9E}\\u{1CF00}-\\u{1CF2D}\\u{1CF30}-\\u{1CF46}\\u{1D167}-\\u{1D169}\\u{1D17B}-\\u{1D182}\\u{1D185}-\\u{1D18B}\\u{1D1AA}-\\u{1D1AD}\\u{1D242}-\\u{1D244}\\u{1DA00}-\\u{1DA36}\\u{1DA3B}-\\u{1DA6C}\\u{1DA75}\\u{1DA84}\\u{1DA9B}-\\u{1DA9F}\\u{1DAA1}-\\u{1DAAF}\\u{1E000}-\\u{1E006}\\u{1E008}-\\u{1E018}\\u{1E01B}-\\u{1E021}\\u{1E023}\\u{1E024}\\u{1E026}-\\u{1E02A}\\u{1E08F}\\u{1E130}-\\u{1E136}\\u{1E2AE}\\u{1E2EC}-\\u{1E2EF}\\u{1E4EC}-\\u{1E4EF}\\u{1E8D0}-\\u{1E8D6}\\u{1E944}-\\u{1E94A}\\u{E0100}-\\u{E01EF}]*$/u;\n\nmodule.exports = {\n  combiningMarks,\n  combiningClassVirama,\n  validZWNJ,\n  bidiDomain,\n  bidiS1LTR,\n  bidiS1RTL,\n  bidiS2,\n  bidiS3,\n  bidiS4EN,\n  bidiS4AN,\n  bidiS5,\n  bidiS6\n};\n\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb-connection-string-url/node_modules/tr46/lib/regexes.js?");

/***/ }),

/***/ "./node_modules/mongodb-connection-string-url/node_modules/tr46/lib/statusMapping.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/mongodb-connection-string-url/node_modules/tr46/lib/statusMapping.js ***!
  \*******************************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports.STATUS_MAPPING = {\n  mapped: 1,\n  valid: 2,\n  disallowed: 3,\n  disallowed_STD3_valid: 4,\n  disallowed_STD3_mapped: 5,\n  deviation: 6,\n  ignored: 7\n};\n\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb-connection-string-url/node_modules/tr46/lib/statusMapping.js?");

/***/ }),

/***/ "./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/index.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/index.js ***!
  \*************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nconst { URL, URLSearchParams } = __webpack_require__(/*! ./webidl2js-wrapper */ \"./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/webidl2js-wrapper.js\");\nconst urlStateMachine = __webpack_require__(/*! ./lib/url-state-machine */ \"./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/url-state-machine.js\");\nconst percentEncoding = __webpack_require__(/*! ./lib/percent-encoding */ \"./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/percent-encoding.js\");\n\nconst sharedGlobalObject = { Array, Object, Promise, String, TypeError };\nURL.install(sharedGlobalObject, [\"Window\"]);\nURLSearchParams.install(sharedGlobalObject, [\"Window\"]);\n\nexports.URL = sharedGlobalObject.URL;\nexports.URLSearchParams = sharedGlobalObject.URLSearchParams;\n\nexports.parseURL = urlStateMachine.parseURL;\nexports.basicURLParse = urlStateMachine.basicURLParse;\nexports.serializeURL = urlStateMachine.serializeURL;\nexports.serializePath = urlStateMachine.serializePath;\nexports.serializeHost = urlStateMachine.serializeHost;\nexports.serializeInteger = urlStateMachine.serializeInteger;\nexports.serializeURLOrigin = urlStateMachine.serializeURLOrigin;\nexports.setTheUsername = urlStateMachine.setTheUsername;\nexports.setThePassword = urlStateMachine.setThePassword;\nexports.cannotHaveAUsernamePasswordPort = urlStateMachine.cannotHaveAUsernamePasswordPort;\nexports.hasAnOpaquePath = urlStateMachine.hasAnOpaquePath;\n\nexports.percentDecodeString = percentEncoding.percentDecodeString;\nexports.percentDecodeBytes = percentEncoding.percentDecodeBytes;\n\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/index.js?");

/***/ }),

/***/ "./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/Function.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/Function.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nconst conversions = __webpack_require__(/*! webidl-conversions */ \"./node_modules/webidl-conversions/lib/index.js\");\nconst utils = __webpack_require__(/*! ./utils.js */ \"./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/utils.js\");\n\nexports.convert = (globalObject, value, { context = \"The provided value\" } = {}) => {\n  if (typeof value !== \"function\") {\n    throw new globalObject.TypeError(context + \" is not a function\");\n  }\n\n  function invokeTheCallbackFunction(...args) {\n    const thisArg = utils.tryWrapperForImpl(this);\n    let callResult;\n\n    for (let i = 0; i < args.length; i++) {\n      args[i] = utils.tryWrapperForImpl(args[i]);\n    }\n\n    callResult = Reflect.apply(value, thisArg, args);\n\n    callResult = conversions[\"any\"](callResult, { context: context, globals: globalObject });\n\n    return callResult;\n  }\n\n  invokeTheCallbackFunction.construct = (...args) => {\n    for (let i = 0; i < args.length; i++) {\n      args[i] = utils.tryWrapperForImpl(args[i]);\n    }\n\n    let callResult = Reflect.construct(value, args);\n\n    callResult = conversions[\"any\"](callResult, { context: context, globals: globalObject });\n\n    return callResult;\n  };\n\n  invokeTheCallbackFunction[utils.wrapperSymbol] = value;\n  invokeTheCallbackFunction.objectReference = value;\n\n  return invokeTheCallbackFunction;\n};\n\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/Function.js?");

/***/ }),

/***/ "./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/URL-impl.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/URL-impl.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nconst usm = __webpack_require__(/*! ./url-state-machine */ \"./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/url-state-machine.js\");\nconst urlencoded = __webpack_require__(/*! ./urlencoded */ \"./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/urlencoded.js\");\nconst URLSearchParams = __webpack_require__(/*! ./URLSearchParams */ \"./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/URLSearchParams.js\");\n\nexports.implementation = class URLImpl {\n  // Unlike the spec, we duplicate some code between the constructor and canParse, because we want to give useful error\n  // messages in the constructor that distinguish between the different causes of failure.\n  constructor(globalObject, constructorArgs) {\n    const url = constructorArgs[0];\n    const base = constructorArgs[1];\n\n    let parsedBase = null;\n    if (base !== undefined) {\n      parsedBase = usm.basicURLParse(base);\n      if (parsedBase === null) {\n        throw new TypeError(`Invalid base URL: ${base}`);\n      }\n    }\n\n    const parsedURL = usm.basicURLParse(url, { baseURL: parsedBase });\n    if (parsedURL === null) {\n      throw new TypeError(`Invalid URL: ${url}`);\n    }\n\n    const query = parsedURL.query !== null ? parsedURL.query : \"\";\n\n    this._url = parsedURL;\n\n    // We cannot invoke the \"new URLSearchParams object\" algorithm without going through the constructor, which strips\n    // question mark by default. Therefore the doNotStripQMark hack is used.\n    this._query = URLSearchParams.createImpl(globalObject, [query], { doNotStripQMark: true });\n    this._query._url = this;\n  }\n\n  static canParse(url, base) {\n    let parsedBase = null;\n    if (base !== undefined) {\n      parsedBase = usm.basicURLParse(base);\n      if (parsedBase === null) {\n        return false;\n      }\n    }\n\n    const parsedURL = usm.basicURLParse(url, { baseURL: parsedBase });\n    if (parsedURL === null) {\n      return false;\n    }\n\n    return true;\n  }\n\n  get href() {\n    return usm.serializeURL(this._url);\n  }\n\n  set href(v) {\n    const parsedURL = usm.basicURLParse(v);\n    if (parsedURL === null) {\n      throw new TypeError(`Invalid URL: ${v}`);\n    }\n\n    this._url = parsedURL;\n\n    this._query._list.splice(0);\n    const { query } = parsedURL;\n    if (query !== null) {\n      this._query._list = urlencoded.parseUrlencodedString(query);\n    }\n  }\n\n  get origin() {\n    return usm.serializeURLOrigin(this._url);\n  }\n\n  get protocol() {\n    return `${this._url.scheme}:`;\n  }\n\n  set protocol(v) {\n    usm.basicURLParse(`${v}:`, { url: this._url, stateOverride: \"scheme start\" });\n  }\n\n  get username() {\n    return this._url.username;\n  }\n\n  set username(v) {\n    if (usm.cannotHaveAUsernamePasswordPort(this._url)) {\n      return;\n    }\n\n    usm.setTheUsername(this._url, v);\n  }\n\n  get password() {\n    return this._url.password;\n  }\n\n  set password(v) {\n    if (usm.cannotHaveAUsernamePasswordPort(this._url)) {\n      return;\n    }\n\n    usm.setThePassword(this._url, v);\n  }\n\n  get host() {\n    const url = this._url;\n\n    if (url.host === null) {\n      return \"\";\n    }\n\n    if (url.port === null) {\n      return usm.serializeHost(url.host);\n    }\n\n    return `${usm.serializeHost(url.host)}:${usm.serializeInteger(url.port)}`;\n  }\n\n  set host(v) {\n    if (usm.hasAnOpaquePath(this._url)) {\n      return;\n    }\n\n    usm.basicURLParse(v, { url: this._url, stateOverride: \"host\" });\n  }\n\n  get hostname() {\n    if (this._url.host === null) {\n      return \"\";\n    }\n\n    return usm.serializeHost(this._url.host);\n  }\n\n  set hostname(v) {\n    if (usm.hasAnOpaquePath(this._url)) {\n      return;\n    }\n\n    usm.basicURLParse(v, { url: this._url, stateOverride: \"hostname\" });\n  }\n\n  get port() {\n    if (this._url.port === null) {\n      return \"\";\n    }\n\n    return usm.serializeInteger(this._url.port);\n  }\n\n  set port(v) {\n    if (usm.cannotHaveAUsernamePasswordPort(this._url)) {\n      return;\n    }\n\n    if (v === \"\") {\n      this._url.port = null;\n    } else {\n      usm.basicURLParse(v, { url: this._url, stateOverride: \"port\" });\n    }\n  }\n\n  get pathname() {\n    return usm.serializePath(this._url);\n  }\n\n  set pathname(v) {\n    if (usm.hasAnOpaquePath(this._url)) {\n      return;\n    }\n\n    this._url.path = [];\n    usm.basicURLParse(v, { url: this._url, stateOverride: \"path start\" });\n  }\n\n  get search() {\n    if (this._url.query === null || this._url.query === \"\") {\n      return \"\";\n    }\n\n    return `?${this._url.query}`;\n  }\n\n  set search(v) {\n    const url = this._url;\n\n    if (v === \"\") {\n      url.query = null;\n      this._query._list = [];\n      this._potentiallyStripTrailingSpacesFromAnOpaquePath();\n      return;\n    }\n\n    const input = v[0] === \"?\" ? v.substring(1) : v;\n    url.query = \"\";\n    usm.basicURLParse(input, { url, stateOverride: \"query\" });\n    this._query._list = urlencoded.parseUrlencodedString(input);\n  }\n\n  get searchParams() {\n    return this._query;\n  }\n\n  get hash() {\n    if (this._url.fragment === null || this._url.fragment === \"\") {\n      return \"\";\n    }\n\n    return `#${this._url.fragment}`;\n  }\n\n  set hash(v) {\n    if (v === \"\") {\n      this._url.fragment = null;\n      this._potentiallyStripTrailingSpacesFromAnOpaquePath();\n      return;\n    }\n\n    const input = v[0] === \"#\" ? v.substring(1) : v;\n    this._url.fragment = \"\";\n    usm.basicURLParse(input, { url: this._url, stateOverride: \"fragment\" });\n  }\n\n  toJSON() {\n    return this.href;\n  }\n\n  _potentiallyStripTrailingSpacesFromAnOpaquePath() {\n    if (!usm.hasAnOpaquePath(this._url)) {\n      return;\n    }\n\n    if (this._url.fragment !== null) {\n      return;\n    }\n\n    if (this._url.query !== null) {\n      return;\n    }\n\n    this._url.path = this._url.path.replace(/\\u0020+$/u, \"\");\n  }\n};\n\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/URL-impl.js?");

/***/ }),

/***/ "./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/URL.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/URL.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nconst conversions = __webpack_require__(/*! webidl-conversions */ \"./node_modules/webidl-conversions/lib/index.js\");\nconst utils = __webpack_require__(/*! ./utils.js */ \"./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/utils.js\");\n\nconst implSymbol = utils.implSymbol;\nconst ctorRegistrySymbol = utils.ctorRegistrySymbol;\n\nconst interfaceName = \"URL\";\n\nexports.is = value => {\n  return utils.isObject(value) && utils.hasOwn(value, implSymbol) && value[implSymbol] instanceof Impl.implementation;\n};\nexports.isImpl = value => {\n  return utils.isObject(value) && value instanceof Impl.implementation;\n};\nexports.convert = (globalObject, value, { context = \"The provided value\" } = {}) => {\n  if (exports.is(value)) {\n    return utils.implForWrapper(value);\n  }\n  throw new globalObject.TypeError(`${context} is not of type 'URL'.`);\n};\n\nfunction makeWrapper(globalObject, newTarget) {\n  let proto;\n  if (newTarget !== undefined) {\n    proto = newTarget.prototype;\n  }\n\n  if (!utils.isObject(proto)) {\n    proto = globalObject[ctorRegistrySymbol][\"URL\"].prototype;\n  }\n\n  return Object.create(proto);\n}\n\nexports.create = (globalObject, constructorArgs, privateData) => {\n  const wrapper = makeWrapper(globalObject);\n  return exports.setup(wrapper, globalObject, constructorArgs, privateData);\n};\n\nexports.createImpl = (globalObject, constructorArgs, privateData) => {\n  const wrapper = exports.create(globalObject, constructorArgs, privateData);\n  return utils.implForWrapper(wrapper);\n};\n\nexports._internalSetup = (wrapper, globalObject) => {};\n\nexports.setup = (wrapper, globalObject, constructorArgs = [], privateData = {}) => {\n  privateData.wrapper = wrapper;\n\n  exports._internalSetup(wrapper, globalObject);\n  Object.defineProperty(wrapper, implSymbol, {\n    value: new Impl.implementation(globalObject, constructorArgs, privateData),\n    configurable: true\n  });\n\n  wrapper[implSymbol][utils.wrapperSymbol] = wrapper;\n  if (Impl.init) {\n    Impl.init(wrapper[implSymbol]);\n  }\n  return wrapper;\n};\n\nexports[\"new\"] = (globalObject, newTarget) => {\n  const wrapper = makeWrapper(globalObject, newTarget);\n\n  exports._internalSetup(wrapper, globalObject);\n  Object.defineProperty(wrapper, implSymbol, {\n    value: Object.create(Impl.implementation.prototype),\n    configurable: true\n  });\n\n  wrapper[implSymbol][utils.wrapperSymbol] = wrapper;\n  if (Impl.init) {\n    Impl.init(wrapper[implSymbol]);\n  }\n  return wrapper[implSymbol];\n};\n\nconst exposed = new Set([\"Window\", \"Worker\"]);\n\nexports.install = (globalObject, globalNames) => {\n  if (!globalNames.some(globalName => exposed.has(globalName))) {\n    return;\n  }\n\n  const ctorRegistry = utils.initCtorRegistry(globalObject);\n  class URL {\n    constructor(url) {\n      if (arguments.length < 1) {\n        throw new globalObject.TypeError(\n          `Failed to construct 'URL': 1 argument required, but only ${arguments.length} present.`\n        );\n      }\n      const args = [];\n      {\n        let curArg = arguments[0];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to construct 'URL': parameter 1\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      {\n        let curArg = arguments[1];\n        if (curArg !== undefined) {\n          curArg = conversions[\"USVString\"](curArg, {\n            context: \"Failed to construct 'URL': parameter 2\",\n            globals: globalObject\n          });\n        }\n        args.push(curArg);\n      }\n      return exports.setup(Object.create(new.target.prototype), globalObject, args);\n    }\n\n    toJSON() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'toJSON' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol].toJSON();\n    }\n\n    get href() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get href' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"href\"];\n    }\n\n    set href(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set href' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'href' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"href\"] = V;\n    }\n\n    toString() {\n      const esValue = this;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'toString' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"href\"];\n    }\n\n    get origin() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get origin' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"origin\"];\n    }\n\n    get protocol() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get protocol' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"protocol\"];\n    }\n\n    set protocol(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set protocol' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'protocol' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"protocol\"] = V;\n    }\n\n    get username() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get username' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"username\"];\n    }\n\n    set username(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set username' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'username' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"username\"] = V;\n    }\n\n    get password() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get password' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"password\"];\n    }\n\n    set password(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set password' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'password' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"password\"] = V;\n    }\n\n    get host() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get host' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"host\"];\n    }\n\n    set host(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set host' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'host' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"host\"] = V;\n    }\n\n    get hostname() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get hostname' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"hostname\"];\n    }\n\n    set hostname(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set hostname' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'hostname' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"hostname\"] = V;\n    }\n\n    get port() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get port' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"port\"];\n    }\n\n    set port(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set port' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'port' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"port\"] = V;\n    }\n\n    get pathname() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get pathname' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"pathname\"];\n    }\n\n    set pathname(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set pathname' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'pathname' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"pathname\"] = V;\n    }\n\n    get search() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get search' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"search\"];\n    }\n\n    set search(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set search' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'search' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"search\"] = V;\n    }\n\n    get searchParams() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get searchParams' called on an object that is not a valid instance of URL.\");\n      }\n\n      return utils.getSameObject(this, \"searchParams\", () => {\n        return utils.tryWrapperForImpl(esValue[implSymbol][\"searchParams\"]);\n      });\n    }\n\n    get hash() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get hash' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"hash\"];\n    }\n\n    set hash(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set hash' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'hash' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"hash\"] = V;\n    }\n\n    static canParse(url) {\n      if (arguments.length < 1) {\n        throw new globalObject.TypeError(\n          `Failed to execute 'canParse' on 'URL': 1 argument required, but only ${arguments.length} present.`\n        );\n      }\n      const args = [];\n      {\n        let curArg = arguments[0];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'canParse' on 'URL': parameter 1\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      {\n        let curArg = arguments[1];\n        if (curArg !== undefined) {\n          curArg = conversions[\"USVString\"](curArg, {\n            context: \"Failed to execute 'canParse' on 'URL': parameter 2\",\n            globals: globalObject\n          });\n        }\n        args.push(curArg);\n      }\n      return Impl.implementation.canParse(...args);\n    }\n  }\n  Object.defineProperties(URL.prototype, {\n    toJSON: { enumerable: true },\n    href: { enumerable: true },\n    toString: { enumerable: true },\n    origin: { enumerable: true },\n    protocol: { enumerable: true },\n    username: { enumerable: true },\n    password: { enumerable: true },\n    host: { enumerable: true },\n    hostname: { enumerable: true },\n    port: { enumerable: true },\n    pathname: { enumerable: true },\n    search: { enumerable: true },\n    searchParams: { enumerable: true },\n    hash: { enumerable: true },\n    [Symbol.toStringTag]: { value: \"URL\", configurable: true }\n  });\n  Object.defineProperties(URL, { canParse: { enumerable: true } });\n  ctorRegistry[interfaceName] = URL;\n\n  Object.defineProperty(globalObject, interfaceName, {\n    configurable: true,\n    writable: true,\n    value: URL\n  });\n\n  if (globalNames.includes(\"Window\")) {\n    Object.defineProperty(globalObject, \"webkitURL\", {\n      configurable: true,\n      writable: true,\n      value: URL\n    });\n  }\n};\n\nconst Impl = __webpack_require__(/*! ./URL-impl.js */ \"./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/URL-impl.js\");\n\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/URL.js?");

/***/ }),

/***/ "./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/URLSearchParams-impl.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/URLSearchParams-impl.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nconst urlencoded = __webpack_require__(/*! ./urlencoded */ \"./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/urlencoded.js\");\n\nexports.implementation = class URLSearchParamsImpl {\n  constructor(globalObject, constructorArgs, { doNotStripQMark = false }) {\n    let init = constructorArgs[0];\n    this._list = [];\n    this._url = null;\n\n    if (!doNotStripQMark && typeof init === \"string\" && init[0] === \"?\") {\n      init = init.slice(1);\n    }\n\n    if (Array.isArray(init)) {\n      for (const pair of init) {\n        if (pair.length !== 2) {\n          throw new TypeError(\"Failed to construct 'URLSearchParams': parameter 1 sequence's element does not \" +\n                              \"contain exactly two elements.\");\n        }\n        this._list.push([pair[0], pair[1]]);\n      }\n    } else if (typeof init === \"object\" && Object.getPrototypeOf(init) === null) {\n      for (const name of Object.keys(init)) {\n        const value = init[name];\n        this._list.push([name, value]);\n      }\n    } else {\n      this._list = urlencoded.parseUrlencodedString(init);\n    }\n  }\n\n  _updateSteps() {\n    if (this._url !== null) {\n      let serializedQuery = urlencoded.serializeUrlencoded(this._list);\n      if (serializedQuery === \"\") {\n        serializedQuery = null;\n      }\n\n      this._url._url.query = serializedQuery;\n\n      if (serializedQuery === null) {\n        this._url._potentiallyStripTrailingSpacesFromAnOpaquePath();\n      }\n    }\n  }\n\n  get size() {\n    return this._list.length;\n  }\n\n  append(name, value) {\n    this._list.push([name, value]);\n    this._updateSteps();\n  }\n\n  delete(name, value) {\n    let i = 0;\n    while (i < this._list.length) {\n      if (this._list[i][0] === name && (value === undefined || this._list[i][1] === value)) {\n        this._list.splice(i, 1);\n      } else {\n        i++;\n      }\n    }\n    this._updateSteps();\n  }\n\n  get(name) {\n    for (const tuple of this._list) {\n      if (tuple[0] === name) {\n        return tuple[1];\n      }\n    }\n    return null;\n  }\n\n  getAll(name) {\n    const output = [];\n    for (const tuple of this._list) {\n      if (tuple[0] === name) {\n        output.push(tuple[1]);\n      }\n    }\n    return output;\n  }\n\n  has(name, value) {\n    for (const tuple of this._list) {\n      if (tuple[0] === name && (value === undefined || tuple[1] === value)) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  set(name, value) {\n    let found = false;\n    let i = 0;\n    while (i < this._list.length) {\n      if (this._list[i][0] === name) {\n        if (found) {\n          this._list.splice(i, 1);\n        } else {\n          found = true;\n          this._list[i][1] = value;\n          i++;\n        }\n      } else {\n        i++;\n      }\n    }\n    if (!found) {\n      this._list.push([name, value]);\n    }\n    this._updateSteps();\n  }\n\n  sort() {\n    this._list.sort((a, b) => {\n      if (a[0] < b[0]) {\n        return -1;\n      }\n      if (a[0] > b[0]) {\n        return 1;\n      }\n      return 0;\n    });\n\n    this._updateSteps();\n  }\n\n  [Symbol.iterator]() {\n    return this._list[Symbol.iterator]();\n  }\n\n  toString() {\n    return urlencoded.serializeUrlencoded(this._list);\n  }\n};\n\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/URLSearchParams-impl.js?");

/***/ }),

/***/ "./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/URLSearchParams.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/URLSearchParams.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nconst conversions = __webpack_require__(/*! webidl-conversions */ \"./node_modules/webidl-conversions/lib/index.js\");\nconst utils = __webpack_require__(/*! ./utils.js */ \"./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/utils.js\");\n\nconst Function = __webpack_require__(/*! ./Function.js */ \"./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/Function.js\");\nconst newObjectInRealm = utils.newObjectInRealm;\nconst implSymbol = utils.implSymbol;\nconst ctorRegistrySymbol = utils.ctorRegistrySymbol;\n\nconst interfaceName = \"URLSearchParams\";\n\nexports.is = value => {\n  return utils.isObject(value) && utils.hasOwn(value, implSymbol) && value[implSymbol] instanceof Impl.implementation;\n};\nexports.isImpl = value => {\n  return utils.isObject(value) && value instanceof Impl.implementation;\n};\nexports.convert = (globalObject, value, { context = \"The provided value\" } = {}) => {\n  if (exports.is(value)) {\n    return utils.implForWrapper(value);\n  }\n  throw new globalObject.TypeError(`${context} is not of type 'URLSearchParams'.`);\n};\n\nexports.createDefaultIterator = (globalObject, target, kind) => {\n  const ctorRegistry = globalObject[ctorRegistrySymbol];\n  const iteratorPrototype = ctorRegistry[\"URLSearchParams Iterator\"];\n  const iterator = Object.create(iteratorPrototype);\n  Object.defineProperty(iterator, utils.iterInternalSymbol, {\n    value: { target, kind, index: 0 },\n    configurable: true\n  });\n  return iterator;\n};\n\nfunction makeWrapper(globalObject, newTarget) {\n  let proto;\n  if (newTarget !== undefined) {\n    proto = newTarget.prototype;\n  }\n\n  if (!utils.isObject(proto)) {\n    proto = globalObject[ctorRegistrySymbol][\"URLSearchParams\"].prototype;\n  }\n\n  return Object.create(proto);\n}\n\nexports.create = (globalObject, constructorArgs, privateData) => {\n  const wrapper = makeWrapper(globalObject);\n  return exports.setup(wrapper, globalObject, constructorArgs, privateData);\n};\n\nexports.createImpl = (globalObject, constructorArgs, privateData) => {\n  const wrapper = exports.create(globalObject, constructorArgs, privateData);\n  return utils.implForWrapper(wrapper);\n};\n\nexports._internalSetup = (wrapper, globalObject) => {};\n\nexports.setup = (wrapper, globalObject, constructorArgs = [], privateData = {}) => {\n  privateData.wrapper = wrapper;\n\n  exports._internalSetup(wrapper, globalObject);\n  Object.defineProperty(wrapper, implSymbol, {\n    value: new Impl.implementation(globalObject, constructorArgs, privateData),\n    configurable: true\n  });\n\n  wrapper[implSymbol][utils.wrapperSymbol] = wrapper;\n  if (Impl.init) {\n    Impl.init(wrapper[implSymbol]);\n  }\n  return wrapper;\n};\n\nexports[\"new\"] = (globalObject, newTarget) => {\n  const wrapper = makeWrapper(globalObject, newTarget);\n\n  exports._internalSetup(wrapper, globalObject);\n  Object.defineProperty(wrapper, implSymbol, {\n    value: Object.create(Impl.implementation.prototype),\n    configurable: true\n  });\n\n  wrapper[implSymbol][utils.wrapperSymbol] = wrapper;\n  if (Impl.init) {\n    Impl.init(wrapper[implSymbol]);\n  }\n  return wrapper[implSymbol];\n};\n\nconst exposed = new Set([\"Window\", \"Worker\"]);\n\nexports.install = (globalObject, globalNames) => {\n  if (!globalNames.some(globalName => exposed.has(globalName))) {\n    return;\n  }\n\n  const ctorRegistry = utils.initCtorRegistry(globalObject);\n  class URLSearchParams {\n    constructor() {\n      const args = [];\n      {\n        let curArg = arguments[0];\n        if (curArg !== undefined) {\n          if (utils.isObject(curArg)) {\n            if (curArg[Symbol.iterator] !== undefined) {\n              if (!utils.isObject(curArg)) {\n                throw new globalObject.TypeError(\n                  \"Failed to construct 'URLSearchParams': parameter 1\" + \" sequence\" + \" is not an iterable object.\"\n                );\n              } else {\n                const V = [];\n                const tmp = curArg;\n                for (let nextItem of tmp) {\n                  if (!utils.isObject(nextItem)) {\n                    throw new globalObject.TypeError(\n                      \"Failed to construct 'URLSearchParams': parameter 1\" +\n                        \" sequence\" +\n                        \"'s element\" +\n                        \" is not an iterable object.\"\n                    );\n                  } else {\n                    const V = [];\n                    const tmp = nextItem;\n                    for (let nextItem of tmp) {\n                      nextItem = conversions[\"USVString\"](nextItem, {\n                        context:\n                          \"Failed to construct 'URLSearchParams': parameter 1\" +\n                          \" sequence\" +\n                          \"'s element\" +\n                          \"'s element\",\n                        globals: globalObject\n                      });\n\n                      V.push(nextItem);\n                    }\n                    nextItem = V;\n                  }\n\n                  V.push(nextItem);\n                }\n                curArg = V;\n              }\n            } else {\n              if (!utils.isObject(curArg)) {\n                throw new globalObject.TypeError(\n                  \"Failed to construct 'URLSearchParams': parameter 1\" + \" record\" + \" is not an object.\"\n                );\n              } else {\n                const result = Object.create(null);\n                for (const key of Reflect.ownKeys(curArg)) {\n                  const desc = Object.getOwnPropertyDescriptor(curArg, key);\n                  if (desc && desc.enumerable) {\n                    let typedKey = key;\n\n                    typedKey = conversions[\"USVString\"](typedKey, {\n                      context: \"Failed to construct 'URLSearchParams': parameter 1\" + \" record\" + \"'s key\",\n                      globals: globalObject\n                    });\n\n                    let typedValue = curArg[key];\n\n                    typedValue = conversions[\"USVString\"](typedValue, {\n                      context: \"Failed to construct 'URLSearchParams': parameter 1\" + \" record\" + \"'s value\",\n                      globals: globalObject\n                    });\n\n                    result[typedKey] = typedValue;\n                  }\n                }\n                curArg = result;\n              }\n            }\n          } else {\n            curArg = conversions[\"USVString\"](curArg, {\n              context: \"Failed to construct 'URLSearchParams': parameter 1\",\n              globals: globalObject\n            });\n          }\n        } else {\n          curArg = \"\";\n        }\n        args.push(curArg);\n      }\n      return exports.setup(Object.create(new.target.prototype), globalObject, args);\n    }\n\n    append(name, value) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\n          \"'append' called on an object that is not a valid instance of URLSearchParams.\"\n        );\n      }\n\n      if (arguments.length < 2) {\n        throw new globalObject.TypeError(\n          `Failed to execute 'append' on 'URLSearchParams': 2 arguments required, but only ${arguments.length} present.`\n        );\n      }\n      const args = [];\n      {\n        let curArg = arguments[0];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'append' on 'URLSearchParams': parameter 1\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      {\n        let curArg = arguments[1];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'append' on 'URLSearchParams': parameter 2\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      return utils.tryWrapperForImpl(esValue[implSymbol].append(...args));\n    }\n\n    delete(name) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\n          \"'delete' called on an object that is not a valid instance of URLSearchParams.\"\n        );\n      }\n\n      if (arguments.length < 1) {\n        throw new globalObject.TypeError(\n          `Failed to execute 'delete' on 'URLSearchParams': 1 argument required, but only ${arguments.length} present.`\n        );\n      }\n      const args = [];\n      {\n        let curArg = arguments[0];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'delete' on 'URLSearchParams': parameter 1\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      {\n        let curArg = arguments[1];\n        if (curArg !== undefined) {\n          curArg = conversions[\"USVString\"](curArg, {\n            context: \"Failed to execute 'delete' on 'URLSearchParams': parameter 2\",\n            globals: globalObject\n          });\n        }\n        args.push(curArg);\n      }\n      return utils.tryWrapperForImpl(esValue[implSymbol].delete(...args));\n    }\n\n    get(name) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get' called on an object that is not a valid instance of URLSearchParams.\");\n      }\n\n      if (arguments.length < 1) {\n        throw new globalObject.TypeError(\n          `Failed to execute 'get' on 'URLSearchParams': 1 argument required, but only ${arguments.length} present.`\n        );\n      }\n      const args = [];\n      {\n        let curArg = arguments[0];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'get' on 'URLSearchParams': parameter 1\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      return esValue[implSymbol].get(...args);\n    }\n\n    getAll(name) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\n          \"'getAll' called on an object that is not a valid instance of URLSearchParams.\"\n        );\n      }\n\n      if (arguments.length < 1) {\n        throw new globalObject.TypeError(\n          `Failed to execute 'getAll' on 'URLSearchParams': 1 argument required, but only ${arguments.length} present.`\n        );\n      }\n      const args = [];\n      {\n        let curArg = arguments[0];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'getAll' on 'URLSearchParams': parameter 1\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      return utils.tryWrapperForImpl(esValue[implSymbol].getAll(...args));\n    }\n\n    has(name) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'has' called on an object that is not a valid instance of URLSearchParams.\");\n      }\n\n      if (arguments.length < 1) {\n        throw new globalObject.TypeError(\n          `Failed to execute 'has' on 'URLSearchParams': 1 argument required, but only ${arguments.length} present.`\n        );\n      }\n      const args = [];\n      {\n        let curArg = arguments[0];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'has' on 'URLSearchParams': parameter 1\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      {\n        let curArg = arguments[1];\n        if (curArg !== undefined) {\n          curArg = conversions[\"USVString\"](curArg, {\n            context: \"Failed to execute 'has' on 'URLSearchParams': parameter 2\",\n            globals: globalObject\n          });\n        }\n        args.push(curArg);\n      }\n      return esValue[implSymbol].has(...args);\n    }\n\n    set(name, value) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set' called on an object that is not a valid instance of URLSearchParams.\");\n      }\n\n      if (arguments.length < 2) {\n        throw new globalObject.TypeError(\n          `Failed to execute 'set' on 'URLSearchParams': 2 arguments required, but only ${arguments.length} present.`\n        );\n      }\n      const args = [];\n      {\n        let curArg = arguments[0];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'set' on 'URLSearchParams': parameter 1\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      {\n        let curArg = arguments[1];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'set' on 'URLSearchParams': parameter 2\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      return utils.tryWrapperForImpl(esValue[implSymbol].set(...args));\n    }\n\n    sort() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'sort' called on an object that is not a valid instance of URLSearchParams.\");\n      }\n\n      return utils.tryWrapperForImpl(esValue[implSymbol].sort());\n    }\n\n    toString() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\n          \"'toString' called on an object that is not a valid instance of URLSearchParams.\"\n        );\n      }\n\n      return esValue[implSymbol].toString();\n    }\n\n    keys() {\n      if (!exports.is(this)) {\n        throw new globalObject.TypeError(\"'keys' called on an object that is not a valid instance of URLSearchParams.\");\n      }\n      return exports.createDefaultIterator(globalObject, this, \"key\");\n    }\n\n    values() {\n      if (!exports.is(this)) {\n        throw new globalObject.TypeError(\n          \"'values' called on an object that is not a valid instance of URLSearchParams.\"\n        );\n      }\n      return exports.createDefaultIterator(globalObject, this, \"value\");\n    }\n\n    entries() {\n      if (!exports.is(this)) {\n        throw new globalObject.TypeError(\n          \"'entries' called on an object that is not a valid instance of URLSearchParams.\"\n        );\n      }\n      return exports.createDefaultIterator(globalObject, this, \"key+value\");\n    }\n\n    forEach(callback) {\n      if (!exports.is(this)) {\n        throw new globalObject.TypeError(\n          \"'forEach' called on an object that is not a valid instance of URLSearchParams.\"\n        );\n      }\n      if (arguments.length < 1) {\n        throw new globalObject.TypeError(\n          \"Failed to execute 'forEach' on 'iterable': 1 argument required, but only 0 present.\"\n        );\n      }\n      callback = Function.convert(globalObject, callback, {\n        context: \"Failed to execute 'forEach' on 'iterable': The callback provided as parameter 1\"\n      });\n      const thisArg = arguments[1];\n      let pairs = Array.from(this[implSymbol]);\n      let i = 0;\n      while (i < pairs.length) {\n        const [key, value] = pairs[i].map(utils.tryWrapperForImpl);\n        callback.call(thisArg, value, key, this);\n        pairs = Array.from(this[implSymbol]);\n        i++;\n      }\n    }\n\n    get size() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\n          \"'get size' called on an object that is not a valid instance of URLSearchParams.\"\n        );\n      }\n\n      return esValue[implSymbol][\"size\"];\n    }\n  }\n  Object.defineProperties(URLSearchParams.prototype, {\n    append: { enumerable: true },\n    delete: { enumerable: true },\n    get: { enumerable: true },\n    getAll: { enumerable: true },\n    has: { enumerable: true },\n    set: { enumerable: true },\n    sort: { enumerable: true },\n    toString: { enumerable: true },\n    keys: { enumerable: true },\n    values: { enumerable: true },\n    entries: { enumerable: true },\n    forEach: { enumerable: true },\n    size: { enumerable: true },\n    [Symbol.toStringTag]: { value: \"URLSearchParams\", configurable: true },\n    [Symbol.iterator]: { value: URLSearchParams.prototype.entries, configurable: true, writable: true }\n  });\n  ctorRegistry[interfaceName] = URLSearchParams;\n\n  ctorRegistry[\"URLSearchParams Iterator\"] = Object.create(ctorRegistry[\"%IteratorPrototype%\"], {\n    [Symbol.toStringTag]: {\n      configurable: true,\n      value: \"URLSearchParams Iterator\"\n    }\n  });\n  utils.define(ctorRegistry[\"URLSearchParams Iterator\"], {\n    next() {\n      const internal = this && this[utils.iterInternalSymbol];\n      if (!internal) {\n        throw new globalObject.TypeError(\"next() called on a value that is not a URLSearchParams iterator object\");\n      }\n\n      const { target, kind, index } = internal;\n      const values = Array.from(target[implSymbol]);\n      const len = values.length;\n      if (index >= len) {\n        return newObjectInRealm(globalObject, { value: undefined, done: true });\n      }\n\n      const pair = values[index];\n      internal.index = index + 1;\n      return newObjectInRealm(globalObject, utils.iteratorResult(pair.map(utils.tryWrapperForImpl), kind));\n    }\n  });\n\n  Object.defineProperty(globalObject, interfaceName, {\n    configurable: true,\n    writable: true,\n    value: URLSearchParams\n  });\n};\n\nconst Impl = __webpack_require__(/*! ./URLSearchParams-impl.js */ \"./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/URLSearchParams-impl.js\");\n\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/URLSearchParams.js?");

/***/ }),

/***/ "./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/encoding.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/encoding.js ***!
  \********************************************************************************************/
/***/ ((module) => {

"use strict";
eval("\nconst utf8Encoder = new TextEncoder();\nconst utf8Decoder = new TextDecoder(\"utf-8\", { ignoreBOM: true });\n\nfunction utf8Encode(string) {\n  return utf8Encoder.encode(string);\n}\n\nfunction utf8DecodeWithoutBOM(bytes) {\n  return utf8Decoder.decode(bytes);\n}\n\nmodule.exports = {\n  utf8Encode,\n  utf8DecodeWithoutBOM\n};\n\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/encoding.js?");

/***/ }),

/***/ "./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/infra.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/infra.js ***!
  \*****************************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n// Note that we take code points as JS numbers, not JS strings.\n\nfunction isASCIIDigit(c) {\n  return c >= 0x30 && c <= 0x39;\n}\n\nfunction isASCIIAlpha(c) {\n  return (c >= 0x41 && c <= 0x5A) || (c >= 0x61 && c <= 0x7A);\n}\n\nfunction isASCIIAlphanumeric(c) {\n  return isASCIIAlpha(c) || isASCIIDigit(c);\n}\n\nfunction isASCIIHex(c) {\n  return isASCIIDigit(c) || (c >= 0x41 && c <= 0x46) || (c >= 0x61 && c <= 0x66);\n}\n\nmodule.exports = {\n  isASCIIDigit,\n  isASCIIAlpha,\n  isASCIIAlphanumeric,\n  isASCIIHex\n};\n\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/infra.js?");

/***/ }),

/***/ "./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/percent-encoding.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/percent-encoding.js ***!
  \****************************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst { isASCIIHex } = __webpack_require__(/*! ./infra */ \"./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/infra.js\");\nconst { utf8Encode } = __webpack_require__(/*! ./encoding */ \"./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/encoding.js\");\n\nfunction p(char) {\n  return char.codePointAt(0);\n}\n\n// https://url.spec.whatwg.org/#percent-encode\nfunction percentEncode(c) {\n  let hex = c.toString(16).toUpperCase();\n  if (hex.length === 1) {\n    hex = `0${hex}`;\n  }\n\n  return `%${hex}`;\n}\n\n// https://url.spec.whatwg.org/#percent-decode\nfunction percentDecodeBytes(input) {\n  const output = new Uint8Array(input.byteLength);\n  let outputIndex = 0;\n  for (let i = 0; i < input.byteLength; ++i) {\n    const byte = input[i];\n    if (byte !== 0x25) {\n      output[outputIndex++] = byte;\n    } else if (byte === 0x25 && (!isASCIIHex(input[i + 1]) || !isASCIIHex(input[i + 2]))) {\n      output[outputIndex++] = byte;\n    } else {\n      const bytePoint = parseInt(String.fromCodePoint(input[i + 1], input[i + 2]), 16);\n      output[outputIndex++] = bytePoint;\n      i += 2;\n    }\n  }\n\n  return output.slice(0, outputIndex);\n}\n\n// https://url.spec.whatwg.org/#string-percent-decode\nfunction percentDecodeString(input) {\n  const bytes = utf8Encode(input);\n  return percentDecodeBytes(bytes);\n}\n\n// https://url.spec.whatwg.org/#c0-control-percent-encode-set\nfunction isC0ControlPercentEncode(c) {\n  return c <= 0x1F || c > 0x7E;\n}\n\n// https://url.spec.whatwg.org/#fragment-percent-encode-set\nconst extraFragmentPercentEncodeSet = new Set([p(\" \"), p(\"\\\"\"), p(\"<\"), p(\">\"), p(\"`\")]);\nfunction isFragmentPercentEncode(c) {\n  return isC0ControlPercentEncode(c) || extraFragmentPercentEncodeSet.has(c);\n}\n\n// https://url.spec.whatwg.org/#query-percent-encode-set\nconst extraQueryPercentEncodeSet = new Set([p(\" \"), p(\"\\\"\"), p(\"#\"), p(\"<\"), p(\">\")]);\nfunction isQueryPercentEncode(c) {\n  return isC0ControlPercentEncode(c) || extraQueryPercentEncodeSet.has(c);\n}\n\n// https://url.spec.whatwg.org/#special-query-percent-encode-set\nfunction isSpecialQueryPercentEncode(c) {\n  return isQueryPercentEncode(c) || c === p(\"'\");\n}\n\n// https://url.spec.whatwg.org/#path-percent-encode-set\nconst extraPathPercentEncodeSet = new Set([p(\"?\"), p(\"`\"), p(\"{\"), p(\"}\")]);\nfunction isPathPercentEncode(c) {\n  return isQueryPercentEncode(c) || extraPathPercentEncodeSet.has(c);\n}\n\n// https://url.spec.whatwg.org/#userinfo-percent-encode-set\nconst extraUserinfoPercentEncodeSet =\n  new Set([p(\"/\"), p(\":\"), p(\";\"), p(\"=\"), p(\"@\"), p(\"[\"), p(\"\\\\\"), p(\"]\"), p(\"^\"), p(\"|\")]);\nfunction isUserinfoPercentEncode(c) {\n  return isPathPercentEncode(c) || extraUserinfoPercentEncodeSet.has(c);\n}\n\n// https://url.spec.whatwg.org/#component-percent-encode-set\nconst extraComponentPercentEncodeSet = new Set([p(\"$\"), p(\"%\"), p(\"&\"), p(\"+\"), p(\",\")]);\nfunction isComponentPercentEncode(c) {\n  return isUserinfoPercentEncode(c) || extraComponentPercentEncodeSet.has(c);\n}\n\n// https://url.spec.whatwg.org/#application-x-www-form-urlencoded-percent-encode-set\nconst extraURLEncodedPercentEncodeSet = new Set([p(\"!\"), p(\"'\"), p(\"(\"), p(\")\"), p(\"~\")]);\nfunction isURLEncodedPercentEncode(c) {\n  return isComponentPercentEncode(c) || extraURLEncodedPercentEncodeSet.has(c);\n}\n\n// https://url.spec.whatwg.org/#code-point-percent-encode-after-encoding\n// https://url.spec.whatwg.org/#utf-8-percent-encode\n// Assuming encoding is always utf-8 allows us to trim one of the logic branches. TODO: support encoding.\n// The \"-Internal\" variant here has code points as JS strings. The external version used by other files has code points\n// as JS numbers, like the rest of the codebase.\nfunction utf8PercentEncodeCodePointInternal(codePoint, percentEncodePredicate) {\n  const bytes = utf8Encode(codePoint);\n  let output = \"\";\n  for (const byte of bytes) {\n    // Our percentEncodePredicate operates on bytes, not code points, so this is slightly different from the spec.\n    if (!percentEncodePredicate(byte)) {\n      output += String.fromCharCode(byte);\n    } else {\n      output += percentEncode(byte);\n    }\n  }\n\n  return output;\n}\n\nfunction utf8PercentEncodeCodePoint(codePoint, percentEncodePredicate) {\n  return utf8PercentEncodeCodePointInternal(String.fromCodePoint(codePoint), percentEncodePredicate);\n}\n\n// https://url.spec.whatwg.org/#string-percent-encode-after-encoding\n// https://url.spec.whatwg.org/#string-utf-8-percent-encode\nfunction utf8PercentEncodeString(input, percentEncodePredicate, spaceAsPlus = false) {\n  let output = \"\";\n  for (const codePoint of input) {\n    if (spaceAsPlus && codePoint === \" \") {\n      output += \"+\";\n    } else {\n      output += utf8PercentEncodeCodePointInternal(codePoint, percentEncodePredicate);\n    }\n  }\n  return output;\n}\n\nmodule.exports = {\n  isC0ControlPercentEncode,\n  isFragmentPercentEncode,\n  isQueryPercentEncode,\n  isSpecialQueryPercentEncode,\n  isPathPercentEncode,\n  isUserinfoPercentEncode,\n  isURLEncodedPercentEncode,\n  percentDecodeString,\n  percentDecodeBytes,\n  utf8PercentEncodeString,\n  utf8PercentEncodeCodePoint\n};\n\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/percent-encoding.js?");

/***/ }),

/***/ "./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/url-state-machine.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/url-state-machine.js ***!
  \*****************************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst tr46 = __webpack_require__(/*! tr46 */ \"./node_modules/mongodb-connection-string-url/node_modules/tr46/index.js\");\n\nconst infra = __webpack_require__(/*! ./infra */ \"./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/infra.js\");\nconst { utf8DecodeWithoutBOM } = __webpack_require__(/*! ./encoding */ \"./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/encoding.js\");\nconst { percentDecodeString, utf8PercentEncodeCodePoint, utf8PercentEncodeString, isC0ControlPercentEncode,\n  isFragmentPercentEncode, isQueryPercentEncode, isSpecialQueryPercentEncode, isPathPercentEncode,\n  isUserinfoPercentEncode } = __webpack_require__(/*! ./percent-encoding */ \"./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/percent-encoding.js\");\n\nfunction p(char) {\n  return char.codePointAt(0);\n}\n\nconst specialSchemes = {\n  ftp: 21,\n  file: null,\n  http: 80,\n  https: 443,\n  ws: 80,\n  wss: 443\n};\n\nconst failure = Symbol(\"failure\");\n\nfunction countSymbols(str) {\n  return [...str].length;\n}\n\nfunction at(input, idx) {\n  const c = input[idx];\n  return isNaN(c) ? undefined : String.fromCodePoint(c);\n}\n\nfunction isSingleDot(buffer) {\n  return buffer === \".\" || buffer.toLowerCase() === \"%2e\";\n}\n\nfunction isDoubleDot(buffer) {\n  buffer = buffer.toLowerCase();\n  return buffer === \"..\" || buffer === \"%2e.\" || buffer === \".%2e\" || buffer === \"%2e%2e\";\n}\n\nfunction isWindowsDriveLetterCodePoints(cp1, cp2) {\n  return infra.isASCIIAlpha(cp1) && (cp2 === p(\":\") || cp2 === p(\"|\"));\n}\n\nfunction isWindowsDriveLetterString(string) {\n  return string.length === 2 && infra.isASCIIAlpha(string.codePointAt(0)) && (string[1] === \":\" || string[1] === \"|\");\n}\n\nfunction isNormalizedWindowsDriveLetterString(string) {\n  return string.length === 2 && infra.isASCIIAlpha(string.codePointAt(0)) && string[1] === \":\";\n}\n\nfunction containsForbiddenHostCodePoint(string) {\n  return string.search(/\\u0000|\\u0009|\\u000A|\\u000D|\\u0020|#|\\/|:|<|>|\\?|@|\\[|\\\\|\\]|\\^|\\|/u) !== -1;\n}\n\nfunction containsForbiddenDomainCodePoint(string) {\n  return containsForbiddenHostCodePoint(string) || string.search(/[\\u0000-\\u001F]|%|\\u007F/u) !== -1;\n}\n\nfunction isSpecialScheme(scheme) {\n  return specialSchemes[scheme] !== undefined;\n}\n\nfunction isSpecial(url) {\n  return isSpecialScheme(url.scheme);\n}\n\nfunction isNotSpecial(url) {\n  return !isSpecialScheme(url.scheme);\n}\n\nfunction defaultPort(scheme) {\n  return specialSchemes[scheme];\n}\n\nfunction parseIPv4Number(input) {\n  if (input === \"\") {\n    return failure;\n  }\n\n  let R = 10;\n\n  if (input.length >= 2 && input.charAt(0) === \"0\" && input.charAt(1).toLowerCase() === \"x\") {\n    input = input.substring(2);\n    R = 16;\n  } else if (input.length >= 2 && input.charAt(0) === \"0\") {\n    input = input.substring(1);\n    R = 8;\n  }\n\n  if (input === \"\") {\n    return 0;\n  }\n\n  let regex = /[^0-7]/u;\n  if (R === 10) {\n    regex = /[^0-9]/u;\n  }\n  if (R === 16) {\n    regex = /[^0-9A-Fa-f]/u;\n  }\n\n  if (regex.test(input)) {\n    return failure;\n  }\n\n  return parseInt(input, R);\n}\n\nfunction parseIPv4(input) {\n  const parts = input.split(\".\");\n  if (parts[parts.length - 1] === \"\") {\n    if (parts.length > 1) {\n      parts.pop();\n    }\n  }\n\n  if (parts.length > 4) {\n    return failure;\n  }\n\n  const numbers = [];\n  for (const part of parts) {\n    const n = parseIPv4Number(part);\n    if (n === failure) {\n      return failure;\n    }\n\n    numbers.push(n);\n  }\n\n  for (let i = 0; i < numbers.length - 1; ++i) {\n    if (numbers[i] > 255) {\n      return failure;\n    }\n  }\n  if (numbers[numbers.length - 1] >= 256 ** (5 - numbers.length)) {\n    return failure;\n  }\n\n  let ipv4 = numbers.pop();\n  let counter = 0;\n\n  for (const n of numbers) {\n    ipv4 += n * 256 ** (3 - counter);\n    ++counter;\n  }\n\n  return ipv4;\n}\n\nfunction serializeIPv4(address) {\n  let output = \"\";\n  let n = address;\n\n  for (let i = 1; i <= 4; ++i) {\n    output = String(n % 256) + output;\n    if (i !== 4) {\n      output = `.${output}`;\n    }\n    n = Math.floor(n / 256);\n  }\n\n  return output;\n}\n\nfunction parseIPv6(input) {\n  const address = [0, 0, 0, 0, 0, 0, 0, 0];\n  let pieceIndex = 0;\n  let compress = null;\n  let pointer = 0;\n\n  input = Array.from(input, c => c.codePointAt(0));\n\n  if (input[pointer] === p(\":\")) {\n    if (input[pointer + 1] !== p(\":\")) {\n      return failure;\n    }\n\n    pointer += 2;\n    ++pieceIndex;\n    compress = pieceIndex;\n  }\n\n  while (pointer < input.length) {\n    if (pieceIndex === 8) {\n      return failure;\n    }\n\n    if (input[pointer] === p(\":\")) {\n      if (compress !== null) {\n        return failure;\n      }\n      ++pointer;\n      ++pieceIndex;\n      compress = pieceIndex;\n      continue;\n    }\n\n    let value = 0;\n    let length = 0;\n\n    while (length < 4 && infra.isASCIIHex(input[pointer])) {\n      value = value * 0x10 + parseInt(at(input, pointer), 16);\n      ++pointer;\n      ++length;\n    }\n\n    if (input[pointer] === p(\".\")) {\n      if (length === 0) {\n        return failure;\n      }\n\n      pointer -= length;\n\n      if (pieceIndex > 6) {\n        return failure;\n      }\n\n      let numbersSeen = 0;\n\n      while (input[pointer] !== undefined) {\n        let ipv4Piece = null;\n\n        if (numbersSeen > 0) {\n          if (input[pointer] === p(\".\") && numbersSeen < 4) {\n            ++pointer;\n          } else {\n            return failure;\n          }\n        }\n\n        if (!infra.isASCIIDigit(input[pointer])) {\n          return failure;\n        }\n\n        while (infra.isASCIIDigit(input[pointer])) {\n          const number = parseInt(at(input, pointer));\n          if (ipv4Piece === null) {\n            ipv4Piece = number;\n          } else if (ipv4Piece === 0) {\n            return failure;\n          } else {\n            ipv4Piece = ipv4Piece * 10 + number;\n          }\n          if (ipv4Piece > 255) {\n            return failure;\n          }\n          ++pointer;\n        }\n\n        address[pieceIndex] = address[pieceIndex] * 0x100 + ipv4Piece;\n\n        ++numbersSeen;\n\n        if (numbersSeen === 2 || numbersSeen === 4) {\n          ++pieceIndex;\n        }\n      }\n\n      if (numbersSeen !== 4) {\n        return failure;\n      }\n\n      break;\n    } else if (input[pointer] === p(\":\")) {\n      ++pointer;\n      if (input[pointer] === undefined) {\n        return failure;\n      }\n    } else if (input[pointer] !== undefined) {\n      return failure;\n    }\n\n    address[pieceIndex] = value;\n    ++pieceIndex;\n  }\n\n  if (compress !== null) {\n    let swaps = pieceIndex - compress;\n    pieceIndex = 7;\n    while (pieceIndex !== 0 && swaps > 0) {\n      const temp = address[compress + swaps - 1];\n      address[compress + swaps - 1] = address[pieceIndex];\n      address[pieceIndex] = temp;\n      --pieceIndex;\n      --swaps;\n    }\n  } else if (compress === null && pieceIndex !== 8) {\n    return failure;\n  }\n\n  return address;\n}\n\nfunction serializeIPv6(address) {\n  let output = \"\";\n  const compress = findLongestZeroSequence(address);\n  let ignore0 = false;\n\n  for (let pieceIndex = 0; pieceIndex <= 7; ++pieceIndex) {\n    if (ignore0 && address[pieceIndex] === 0) {\n      continue;\n    } else if (ignore0) {\n      ignore0 = false;\n    }\n\n    if (compress === pieceIndex) {\n      const separator = pieceIndex === 0 ? \"::\" : \":\";\n      output += separator;\n      ignore0 = true;\n      continue;\n    }\n\n    output += address[pieceIndex].toString(16);\n\n    if (pieceIndex !== 7) {\n      output += \":\";\n    }\n  }\n\n  return output;\n}\n\nfunction parseHost(input, isNotSpecialArg = false) {\n  if (input[0] === \"[\") {\n    if (input[input.length - 1] !== \"]\") {\n      return failure;\n    }\n\n    return parseIPv6(input.substring(1, input.length - 1));\n  }\n\n  if (isNotSpecialArg) {\n    return parseOpaqueHost(input);\n  }\n\n  const domain = utf8DecodeWithoutBOM(percentDecodeString(input));\n  const asciiDomain = domainToASCII(domain);\n  if (asciiDomain === failure) {\n    return failure;\n  }\n\n  if (containsForbiddenDomainCodePoint(asciiDomain)) {\n    return failure;\n  }\n\n  if (endsInANumber(asciiDomain)) {\n    return parseIPv4(asciiDomain);\n  }\n\n  return asciiDomain;\n}\n\nfunction endsInANumber(input) {\n  const parts = input.split(\".\");\n  if (parts[parts.length - 1] === \"\") {\n    if (parts.length === 1) {\n      return false;\n    }\n    parts.pop();\n  }\n\n  const last = parts[parts.length - 1];\n  if (parseIPv4Number(last) !== failure) {\n    return true;\n  }\n\n  if (/^[0-9]+$/u.test(last)) {\n    return true;\n  }\n\n  return false;\n}\n\nfunction parseOpaqueHost(input) {\n  if (containsForbiddenHostCodePoint(input)) {\n    return failure;\n  }\n\n  return utf8PercentEncodeString(input, isC0ControlPercentEncode);\n}\n\nfunction findLongestZeroSequence(arr) {\n  let maxIdx = null;\n  let maxLen = 1; // only find elements > 1\n  let currStart = null;\n  let currLen = 0;\n\n  for (let i = 0; i < arr.length; ++i) {\n    if (arr[i] !== 0) {\n      if (currLen > maxLen) {\n        maxIdx = currStart;\n        maxLen = currLen;\n      }\n\n      currStart = null;\n      currLen = 0;\n    } else {\n      if (currStart === null) {\n        currStart = i;\n      }\n      ++currLen;\n    }\n  }\n\n  // if trailing zeros\n  if (currLen > maxLen) {\n    return currStart;\n  }\n\n  return maxIdx;\n}\n\nfunction serializeHost(host) {\n  if (typeof host === \"number\") {\n    return serializeIPv4(host);\n  }\n\n  // IPv6 serializer\n  if (host instanceof Array) {\n    return `[${serializeIPv6(host)}]`;\n  }\n\n  return host;\n}\n\nfunction domainToASCII(domain, beStrict = false) {\n  const result = tr46.toASCII(domain, {\n    checkBidi: true,\n    checkHyphens: false,\n    checkJoiners: true,\n    useSTD3ASCIIRules: beStrict,\n    verifyDNSLength: beStrict\n  });\n  if (result === null || result === \"\") {\n    return failure;\n  }\n  return result;\n}\n\nfunction trimControlChars(url) {\n  return url.replace(/^[\\u0000-\\u001F\\u0020]+|[\\u0000-\\u001F\\u0020]+$/ug, \"\");\n}\n\nfunction trimTabAndNewline(url) {\n  return url.replace(/\\u0009|\\u000A|\\u000D/ug, \"\");\n}\n\nfunction shortenPath(url) {\n  const { path } = url;\n  if (path.length === 0) {\n    return;\n  }\n  if (url.scheme === \"file\" && path.length === 1 && isNormalizedWindowsDriveLetter(path[0])) {\n    return;\n  }\n\n  path.pop();\n}\n\nfunction includesCredentials(url) {\n  return url.username !== \"\" || url.password !== \"\";\n}\n\nfunction cannotHaveAUsernamePasswordPort(url) {\n  return url.host === null || url.host === \"\" || url.scheme === \"file\";\n}\n\nfunction hasAnOpaquePath(url) {\n  return typeof url.path === \"string\";\n}\n\nfunction isNormalizedWindowsDriveLetter(string) {\n  return /^[A-Za-z]:$/u.test(string);\n}\n\nfunction URLStateMachine(input, base, encodingOverride, url, stateOverride) {\n  this.pointer = 0;\n  this.input = input;\n  this.base = base || null;\n  this.encodingOverride = encodingOverride || \"utf-8\";\n  this.stateOverride = stateOverride;\n  this.url = url;\n  this.failure = false;\n  this.parseError = false;\n\n  if (!this.url) {\n    this.url = {\n      scheme: \"\",\n      username: \"\",\n      password: \"\",\n      host: null,\n      port: null,\n      path: [],\n      query: null,\n      fragment: null\n    };\n\n    const res = trimControlChars(this.input);\n    if (res !== this.input) {\n      this.parseError = true;\n    }\n    this.input = res;\n  }\n\n  const res = trimTabAndNewline(this.input);\n  if (res !== this.input) {\n    this.parseError = true;\n  }\n  this.input = res;\n\n  this.state = stateOverride || \"scheme start\";\n\n  this.buffer = \"\";\n  this.atFlag = false;\n  this.arrFlag = false;\n  this.passwordTokenSeenFlag = false;\n\n  this.input = Array.from(this.input, c => c.codePointAt(0));\n\n  for (; this.pointer <= this.input.length; ++this.pointer) {\n    const c = this.input[this.pointer];\n    const cStr = isNaN(c) ? undefined : String.fromCodePoint(c);\n\n    // exec state machine\n    const ret = this[`parse ${this.state}`](c, cStr);\n    if (!ret) {\n      break; // terminate algorithm\n    } else if (ret === failure) {\n      this.failure = true;\n      break;\n    }\n  }\n}\n\nURLStateMachine.prototype[\"parse scheme start\"] = function parseSchemeStart(c, cStr) {\n  if (infra.isASCIIAlpha(c)) {\n    this.buffer += cStr.toLowerCase();\n    this.state = \"scheme\";\n  } else if (!this.stateOverride) {\n    this.state = \"no scheme\";\n    --this.pointer;\n  } else {\n    this.parseError = true;\n    return failure;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse scheme\"] = function parseScheme(c, cStr) {\n  if (infra.isASCIIAlphanumeric(c) || c === p(\"+\") || c === p(\"-\") || c === p(\".\")) {\n    this.buffer += cStr.toLowerCase();\n  } else if (c === p(\":\")) {\n    if (this.stateOverride) {\n      if (isSpecial(this.url) && !isSpecialScheme(this.buffer)) {\n        return false;\n      }\n\n      if (!isSpecial(this.url) && isSpecialScheme(this.buffer)) {\n        return false;\n      }\n\n      if ((includesCredentials(this.url) || this.url.port !== null) && this.buffer === \"file\") {\n        return false;\n      }\n\n      if (this.url.scheme === \"file\" && this.url.host === \"\") {\n        return false;\n      }\n    }\n    this.url.scheme = this.buffer;\n    if (this.stateOverride) {\n      if (this.url.port === defaultPort(this.url.scheme)) {\n        this.url.port = null;\n      }\n      return false;\n    }\n    this.buffer = \"\";\n    if (this.url.scheme === \"file\") {\n      if (this.input[this.pointer + 1] !== p(\"/\") || this.input[this.pointer + 2] !== p(\"/\")) {\n        this.parseError = true;\n      }\n      this.state = \"file\";\n    } else if (isSpecial(this.url) && this.base !== null && this.base.scheme === this.url.scheme) {\n      this.state = \"special relative or authority\";\n    } else if (isSpecial(this.url)) {\n      this.state = \"special authority slashes\";\n    } else if (this.input[this.pointer + 1] === p(\"/\")) {\n      this.state = \"path or authority\";\n      ++this.pointer;\n    } else {\n      this.url.path = \"\";\n      this.state = \"opaque path\";\n    }\n  } else if (!this.stateOverride) {\n    this.buffer = \"\";\n    this.state = \"no scheme\";\n    this.pointer = -1;\n  } else {\n    this.parseError = true;\n    return failure;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse no scheme\"] = function parseNoScheme(c) {\n  if (this.base === null || (hasAnOpaquePath(this.base) && c !== p(\"#\"))) {\n    return failure;\n  } else if (hasAnOpaquePath(this.base) && c === p(\"#\")) {\n    this.url.scheme = this.base.scheme;\n    this.url.path = this.base.path;\n    this.url.query = this.base.query;\n    this.url.fragment = \"\";\n    this.state = \"fragment\";\n  } else if (this.base.scheme === \"file\") {\n    this.state = \"file\";\n    --this.pointer;\n  } else {\n    this.state = \"relative\";\n    --this.pointer;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse special relative or authority\"] = function parseSpecialRelativeOrAuthority(c) {\n  if (c === p(\"/\") && this.input[this.pointer + 1] === p(\"/\")) {\n    this.state = \"special authority ignore slashes\";\n    ++this.pointer;\n  } else {\n    this.parseError = true;\n    this.state = \"relative\";\n    --this.pointer;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse path or authority\"] = function parsePathOrAuthority(c) {\n  if (c === p(\"/\")) {\n    this.state = \"authority\";\n  } else {\n    this.state = \"path\";\n    --this.pointer;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse relative\"] = function parseRelative(c) {\n  this.url.scheme = this.base.scheme;\n  if (c === p(\"/\")) {\n    this.state = \"relative slash\";\n  } else if (isSpecial(this.url) && c === p(\"\\\\\")) {\n    this.parseError = true;\n    this.state = \"relative slash\";\n  } else {\n    this.url.username = this.base.username;\n    this.url.password = this.base.password;\n    this.url.host = this.base.host;\n    this.url.port = this.base.port;\n    this.url.path = this.base.path.slice();\n    this.url.query = this.base.query;\n    if (c === p(\"?\")) {\n      this.url.query = \"\";\n      this.state = \"query\";\n    } else if (c === p(\"#\")) {\n      this.url.fragment = \"\";\n      this.state = \"fragment\";\n    } else if (!isNaN(c)) {\n      this.url.query = null;\n      this.url.path.pop();\n      this.state = \"path\";\n      --this.pointer;\n    }\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse relative slash\"] = function parseRelativeSlash(c) {\n  if (isSpecial(this.url) && (c === p(\"/\") || c === p(\"\\\\\"))) {\n    if (c === p(\"\\\\\")) {\n      this.parseError = true;\n    }\n    this.state = \"special authority ignore slashes\";\n  } else if (c === p(\"/\")) {\n    this.state = \"authority\";\n  } else {\n    this.url.username = this.base.username;\n    this.url.password = this.base.password;\n    this.url.host = this.base.host;\n    this.url.port = this.base.port;\n    this.state = \"path\";\n    --this.pointer;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse special authority slashes\"] = function parseSpecialAuthoritySlashes(c) {\n  if (c === p(\"/\") && this.input[this.pointer + 1] === p(\"/\")) {\n    this.state = \"special authority ignore slashes\";\n    ++this.pointer;\n  } else {\n    this.parseError = true;\n    this.state = \"special authority ignore slashes\";\n    --this.pointer;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse special authority ignore slashes\"] = function parseSpecialAuthorityIgnoreSlashes(c) {\n  if (c !== p(\"/\") && c !== p(\"\\\\\")) {\n    this.state = \"authority\";\n    --this.pointer;\n  } else {\n    this.parseError = true;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse authority\"] = function parseAuthority(c, cStr) {\n  if (c === p(\"@\")) {\n    this.parseError = true;\n    if (this.atFlag) {\n      this.buffer = `%40${this.buffer}`;\n    }\n    this.atFlag = true;\n\n    // careful, this is based on buffer and has its own pointer (this.pointer != pointer) and inner chars\n    const len = countSymbols(this.buffer);\n    for (let pointer = 0; pointer < len; ++pointer) {\n      const codePoint = this.buffer.codePointAt(pointer);\n\n      if (codePoint === p(\":\") && !this.passwordTokenSeenFlag) {\n        this.passwordTokenSeenFlag = true;\n        continue;\n      }\n      const encodedCodePoints = utf8PercentEncodeCodePoint(codePoint, isUserinfoPercentEncode);\n      if (this.passwordTokenSeenFlag) {\n        this.url.password += encodedCodePoints;\n      } else {\n        this.url.username += encodedCodePoints;\n      }\n    }\n    this.buffer = \"\";\n  } else if (isNaN(c) || c === p(\"/\") || c === p(\"?\") || c === p(\"#\") ||\n             (isSpecial(this.url) && c === p(\"\\\\\"))) {\n    if (this.atFlag && this.buffer === \"\") {\n      this.parseError = true;\n      return failure;\n    }\n    this.pointer -= countSymbols(this.buffer) + 1;\n    this.buffer = \"\";\n    this.state = \"host\";\n  } else {\n    this.buffer += cStr;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse hostname\"] =\nURLStateMachine.prototype[\"parse host\"] = function parseHostName(c, cStr) {\n  if (this.stateOverride && this.url.scheme === \"file\") {\n    --this.pointer;\n    this.state = \"file host\";\n  } else if (c === p(\":\") && !this.arrFlag) {\n    if (this.buffer === \"\") {\n      this.parseError = true;\n      return failure;\n    }\n\n    if (this.stateOverride === \"hostname\") {\n      return false;\n    }\n\n    const host = parseHost(this.buffer, isNotSpecial(this.url));\n    if (host === failure) {\n      return failure;\n    }\n\n    this.url.host = host;\n    this.buffer = \"\";\n    this.state = \"port\";\n  } else if (isNaN(c) || c === p(\"/\") || c === p(\"?\") || c === p(\"#\") ||\n             (isSpecial(this.url) && c === p(\"\\\\\"))) {\n    --this.pointer;\n    if (isSpecial(this.url) && this.buffer === \"\") {\n      this.parseError = true;\n      return failure;\n    } else if (this.stateOverride && this.buffer === \"\" &&\n               (includesCredentials(this.url) || this.url.port !== null)) {\n      this.parseError = true;\n      return false;\n    }\n\n    const host = parseHost(this.buffer, isNotSpecial(this.url));\n    if (host === failure) {\n      return failure;\n    }\n\n    this.url.host = host;\n    this.buffer = \"\";\n    this.state = \"path start\";\n    if (this.stateOverride) {\n      return false;\n    }\n  } else {\n    if (c === p(\"[\")) {\n      this.arrFlag = true;\n    } else if (c === p(\"]\")) {\n      this.arrFlag = false;\n    }\n    this.buffer += cStr;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse port\"] = function parsePort(c, cStr) {\n  if (infra.isASCIIDigit(c)) {\n    this.buffer += cStr;\n  } else if (isNaN(c) || c === p(\"/\") || c === p(\"?\") || c === p(\"#\") ||\n             (isSpecial(this.url) && c === p(\"\\\\\")) ||\n             this.stateOverride) {\n    if (this.buffer !== \"\") {\n      const port = parseInt(this.buffer);\n      if (port > 2 ** 16 - 1) {\n        this.parseError = true;\n        return failure;\n      }\n      this.url.port = port === defaultPort(this.url.scheme) ? null : port;\n      this.buffer = \"\";\n    }\n    if (this.stateOverride) {\n      return false;\n    }\n    this.state = \"path start\";\n    --this.pointer;\n  } else {\n    this.parseError = true;\n    return failure;\n  }\n\n  return true;\n};\n\nconst fileOtherwiseCodePoints = new Set([p(\"/\"), p(\"\\\\\"), p(\"?\"), p(\"#\")]);\n\nfunction startsWithWindowsDriveLetter(input, pointer) {\n  const length = input.length - pointer;\n  return length >= 2 &&\n    isWindowsDriveLetterCodePoints(input[pointer], input[pointer + 1]) &&\n    (length === 2 || fileOtherwiseCodePoints.has(input[pointer + 2]));\n}\n\nURLStateMachine.prototype[\"parse file\"] = function parseFile(c) {\n  this.url.scheme = \"file\";\n  this.url.host = \"\";\n\n  if (c === p(\"/\") || c === p(\"\\\\\")) {\n    if (c === p(\"\\\\\")) {\n      this.parseError = true;\n    }\n    this.state = \"file slash\";\n  } else if (this.base !== null && this.base.scheme === \"file\") {\n    this.url.host = this.base.host;\n    this.url.path = this.base.path.slice();\n    this.url.query = this.base.query;\n    if (c === p(\"?\")) {\n      this.url.query = \"\";\n      this.state = \"query\";\n    } else if (c === p(\"#\")) {\n      this.url.fragment = \"\";\n      this.state = \"fragment\";\n    } else if (!isNaN(c)) {\n      this.url.query = null;\n      if (!startsWithWindowsDriveLetter(this.input, this.pointer)) {\n        shortenPath(this.url);\n      } else {\n        this.parseError = true;\n        this.url.path = [];\n      }\n\n      this.state = \"path\";\n      --this.pointer;\n    }\n  } else {\n    this.state = \"path\";\n    --this.pointer;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse file slash\"] = function parseFileSlash(c) {\n  if (c === p(\"/\") || c === p(\"\\\\\")) {\n    if (c === p(\"\\\\\")) {\n      this.parseError = true;\n    }\n    this.state = \"file host\";\n  } else {\n    if (this.base !== null && this.base.scheme === \"file\") {\n      if (!startsWithWindowsDriveLetter(this.input, this.pointer) &&\n          isNormalizedWindowsDriveLetterString(this.base.path[0])) {\n        this.url.path.push(this.base.path[0]);\n      }\n      this.url.host = this.base.host;\n    }\n    this.state = \"path\";\n    --this.pointer;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse file host\"] = function parseFileHost(c, cStr) {\n  if (isNaN(c) || c === p(\"/\") || c === p(\"\\\\\") || c === p(\"?\") || c === p(\"#\")) {\n    --this.pointer;\n    if (!this.stateOverride && isWindowsDriveLetterString(this.buffer)) {\n      this.parseError = true;\n      this.state = \"path\";\n    } else if (this.buffer === \"\") {\n      this.url.host = \"\";\n      if (this.stateOverride) {\n        return false;\n      }\n      this.state = \"path start\";\n    } else {\n      let host = parseHost(this.buffer, isNotSpecial(this.url));\n      if (host === failure) {\n        return failure;\n      }\n      if (host === \"localhost\") {\n        host = \"\";\n      }\n      this.url.host = host;\n\n      if (this.stateOverride) {\n        return false;\n      }\n\n      this.buffer = \"\";\n      this.state = \"path start\";\n    }\n  } else {\n    this.buffer += cStr;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse path start\"] = function parsePathStart(c) {\n  if (isSpecial(this.url)) {\n    if (c === p(\"\\\\\")) {\n      this.parseError = true;\n    }\n    this.state = \"path\";\n\n    if (c !== p(\"/\") && c !== p(\"\\\\\")) {\n      --this.pointer;\n    }\n  } else if (!this.stateOverride && c === p(\"?\")) {\n    this.url.query = \"\";\n    this.state = \"query\";\n  } else if (!this.stateOverride && c === p(\"#\")) {\n    this.url.fragment = \"\";\n    this.state = \"fragment\";\n  } else if (c !== undefined) {\n    this.state = \"path\";\n    if (c !== p(\"/\")) {\n      --this.pointer;\n    }\n  } else if (this.stateOverride && this.url.host === null) {\n    this.url.path.push(\"\");\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse path\"] = function parsePath(c) {\n  if (isNaN(c) || c === p(\"/\") || (isSpecial(this.url) && c === p(\"\\\\\")) ||\n      (!this.stateOverride && (c === p(\"?\") || c === p(\"#\")))) {\n    if (isSpecial(this.url) && c === p(\"\\\\\")) {\n      this.parseError = true;\n    }\n\n    if (isDoubleDot(this.buffer)) {\n      shortenPath(this.url);\n      if (c !== p(\"/\") && !(isSpecial(this.url) && c === p(\"\\\\\"))) {\n        this.url.path.push(\"\");\n      }\n    } else if (isSingleDot(this.buffer) && c !== p(\"/\") &&\n               !(isSpecial(this.url) && c === p(\"\\\\\"))) {\n      this.url.path.push(\"\");\n    } else if (!isSingleDot(this.buffer)) {\n      if (this.url.scheme === \"file\" && this.url.path.length === 0 && isWindowsDriveLetterString(this.buffer)) {\n        this.buffer = `${this.buffer[0]}:`;\n      }\n      this.url.path.push(this.buffer);\n    }\n    this.buffer = \"\";\n    if (c === p(\"?\")) {\n      this.url.query = \"\";\n      this.state = \"query\";\n    }\n    if (c === p(\"#\")) {\n      this.url.fragment = \"\";\n      this.state = \"fragment\";\n    }\n  } else {\n    // TODO: If c is not a URL code point and not \"%\", parse error.\n\n    if (c === p(\"%\") &&\n      (!infra.isASCIIHex(this.input[this.pointer + 1]) ||\n        !infra.isASCIIHex(this.input[this.pointer + 2]))) {\n      this.parseError = true;\n    }\n\n    this.buffer += utf8PercentEncodeCodePoint(c, isPathPercentEncode);\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse opaque path\"] = function parseOpaquePath(c) {\n  if (c === p(\"?\")) {\n    this.url.query = \"\";\n    this.state = \"query\";\n  } else if (c === p(\"#\")) {\n    this.url.fragment = \"\";\n    this.state = \"fragment\";\n  } else {\n    // TODO: Add: not a URL code point\n    if (!isNaN(c) && c !== p(\"%\")) {\n      this.parseError = true;\n    }\n\n    if (c === p(\"%\") &&\n        (!infra.isASCIIHex(this.input[this.pointer + 1]) ||\n         !infra.isASCIIHex(this.input[this.pointer + 2]))) {\n      this.parseError = true;\n    }\n\n    if (!isNaN(c)) {\n      this.url.path += utf8PercentEncodeCodePoint(c, isC0ControlPercentEncode);\n    }\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse query\"] = function parseQuery(c, cStr) {\n  if (!isSpecial(this.url) || this.url.scheme === \"ws\" || this.url.scheme === \"wss\") {\n    this.encodingOverride = \"utf-8\";\n  }\n\n  if ((!this.stateOverride && c === p(\"#\")) || isNaN(c)) {\n    const queryPercentEncodePredicate = isSpecial(this.url) ? isSpecialQueryPercentEncode : isQueryPercentEncode;\n    this.url.query += utf8PercentEncodeString(this.buffer, queryPercentEncodePredicate);\n\n    this.buffer = \"\";\n\n    if (c === p(\"#\")) {\n      this.url.fragment = \"\";\n      this.state = \"fragment\";\n    }\n  } else if (!isNaN(c)) {\n    // TODO: If c is not a URL code point and not \"%\", parse error.\n\n    if (c === p(\"%\") &&\n      (!infra.isASCIIHex(this.input[this.pointer + 1]) ||\n        !infra.isASCIIHex(this.input[this.pointer + 2]))) {\n      this.parseError = true;\n    }\n\n    this.buffer += cStr;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse fragment\"] = function parseFragment(c) {\n  if (!isNaN(c)) {\n    // TODO: If c is not a URL code point and not \"%\", parse error.\n    if (c === p(\"%\") &&\n      (!infra.isASCIIHex(this.input[this.pointer + 1]) ||\n        !infra.isASCIIHex(this.input[this.pointer + 2]))) {\n      this.parseError = true;\n    }\n\n    this.url.fragment += utf8PercentEncodeCodePoint(c, isFragmentPercentEncode);\n  }\n\n  return true;\n};\n\nfunction serializeURL(url, excludeFragment) {\n  let output = `${url.scheme}:`;\n  if (url.host !== null) {\n    output += \"//\";\n\n    if (url.username !== \"\" || url.password !== \"\") {\n      output += url.username;\n      if (url.password !== \"\") {\n        output += `:${url.password}`;\n      }\n      output += \"@\";\n    }\n\n    output += serializeHost(url.host);\n\n    if (url.port !== null) {\n      output += `:${url.port}`;\n    }\n  }\n\n  if (url.host === null && !hasAnOpaquePath(url) && url.path.length > 1 && url.path[0] === \"\") {\n    output += \"/.\";\n  }\n  output += serializePath(url);\n\n  if (url.query !== null) {\n    output += `?${url.query}`;\n  }\n\n  if (!excludeFragment && url.fragment !== null) {\n    output += `#${url.fragment}`;\n  }\n\n  return output;\n}\n\nfunction serializeOrigin(tuple) {\n  let result = `${tuple.scheme}://`;\n  result += serializeHost(tuple.host);\n\n  if (tuple.port !== null) {\n    result += `:${tuple.port}`;\n  }\n\n  return result;\n}\n\nfunction serializePath(url) {\n  if (hasAnOpaquePath(url)) {\n    return url.path;\n  }\n\n  let output = \"\";\n  for (const segment of url.path) {\n    output += `/${segment}`;\n  }\n  return output;\n}\n\nmodule.exports.serializeURL = serializeURL;\n\nmodule.exports.serializePath = serializePath;\n\nmodule.exports.serializeURLOrigin = function (url) {\n  // https://url.spec.whatwg.org/#concept-url-origin\n  switch (url.scheme) {\n    case \"blob\": {\n      const pathURL = module.exports.parseURL(serializePath(url));\n      if (pathURL === null) {\n        return \"null\";\n      }\n      if (pathURL.scheme !== \"http\" && pathURL.scheme !== \"https\") {\n        return \"null\";\n      }\n      return module.exports.serializeURLOrigin(pathURL);\n    }\n    case \"ftp\":\n    case \"http\":\n    case \"https\":\n    case \"ws\":\n    case \"wss\":\n      return serializeOrigin({\n        scheme: url.scheme,\n        host: url.host,\n        port: url.port\n      });\n    case \"file\":\n      // The spec says:\n      // > Unfortunate as it is, this is left as an exercise to the reader. When in doubt, return a new opaque origin.\n      // Browsers tested so far:\n      // - Chrome says \"file://\", but treats file: URLs as cross-origin for most (all?) purposes; see e.g.\n      //   https://bugs.chromium.org/p/chromium/issues/detail?id=37586\n      // - Firefox says \"null\", but treats file: URLs as same-origin sometimes based on directory stuff; see\n      //   https://developer.mozilla.org/en-US/docs/Archive/Misc_top_level/Same-origin_policy_for_file:_URIs\n      return \"null\";\n    default:\n      // serializing an opaque origin returns \"null\"\n      return \"null\";\n  }\n};\n\nmodule.exports.basicURLParse = function (input, options) {\n  if (options === undefined) {\n    options = {};\n  }\n\n  const usm = new URLStateMachine(input, options.baseURL, options.encodingOverride, options.url, options.stateOverride);\n  if (usm.failure) {\n    return null;\n  }\n\n  return usm.url;\n};\n\nmodule.exports.setTheUsername = function (url, username) {\n  url.username = utf8PercentEncodeString(username, isUserinfoPercentEncode);\n};\n\nmodule.exports.setThePassword = function (url, password) {\n  url.password = utf8PercentEncodeString(password, isUserinfoPercentEncode);\n};\n\nmodule.exports.serializeHost = serializeHost;\n\nmodule.exports.cannotHaveAUsernamePasswordPort = cannotHaveAUsernamePasswordPort;\n\nmodule.exports.hasAnOpaquePath = hasAnOpaquePath;\n\nmodule.exports.serializeInteger = function (integer) {\n  return String(integer);\n};\n\nmodule.exports.parseURL = function (input, options) {\n  if (options === undefined) {\n    options = {};\n  }\n\n  // We don't handle blobs, so this just delegates:\n  return module.exports.basicURLParse(input, { baseURL: options.baseURL, encodingOverride: options.encodingOverride });\n};\n\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/url-state-machine.js?");

/***/ }),

/***/ "./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/urlencoded.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/urlencoded.js ***!
  \**********************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst { utf8Encode, utf8DecodeWithoutBOM } = __webpack_require__(/*! ./encoding */ \"./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/encoding.js\");\nconst { percentDecodeBytes, utf8PercentEncodeString, isURLEncodedPercentEncode } = __webpack_require__(/*! ./percent-encoding */ \"./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/percent-encoding.js\");\n\nfunction p(char) {\n  return char.codePointAt(0);\n}\n\n// https://url.spec.whatwg.org/#concept-urlencoded-parser\nfunction parseUrlencoded(input) {\n  const sequences = strictlySplitByteSequence(input, p(\"&\"));\n  const output = [];\n  for (const bytes of sequences) {\n    if (bytes.length === 0) {\n      continue;\n    }\n\n    let name, value;\n    const indexOfEqual = bytes.indexOf(p(\"=\"));\n\n    if (indexOfEqual >= 0) {\n      name = bytes.slice(0, indexOfEqual);\n      value = bytes.slice(indexOfEqual + 1);\n    } else {\n      name = bytes;\n      value = new Uint8Array(0);\n    }\n\n    name = replaceByteInByteSequence(name, 0x2B, 0x20);\n    value = replaceByteInByteSequence(value, 0x2B, 0x20);\n\n    const nameString = utf8DecodeWithoutBOM(percentDecodeBytes(name));\n    const valueString = utf8DecodeWithoutBOM(percentDecodeBytes(value));\n\n    output.push([nameString, valueString]);\n  }\n  return output;\n}\n\n// https://url.spec.whatwg.org/#concept-urlencoded-string-parser\nfunction parseUrlencodedString(input) {\n  return parseUrlencoded(utf8Encode(input));\n}\n\n// https://url.spec.whatwg.org/#concept-urlencoded-serializer\nfunction serializeUrlencoded(tuples, encodingOverride = undefined) {\n  let encoding = \"utf-8\";\n  if (encodingOverride !== undefined) {\n    // TODO \"get the output encoding\", i.e. handle encoding labels vs. names.\n    encoding = encodingOverride;\n  }\n\n  let output = \"\";\n  for (const [i, tuple] of tuples.entries()) {\n    // TODO: handle encoding override\n\n    const name = utf8PercentEncodeString(tuple[0], isURLEncodedPercentEncode, true);\n\n    let value = tuple[1];\n    if (tuple.length > 2 && tuple[2] !== undefined) {\n      if (tuple[2] === \"hidden\" && name === \"_charset_\") {\n        value = encoding;\n      } else if (tuple[2] === \"file\") {\n        // value is a File object\n        value = value.name;\n      }\n    }\n\n    value = utf8PercentEncodeString(value, isURLEncodedPercentEncode, true);\n\n    if (i !== 0) {\n      output += \"&\";\n    }\n    output += `${name}=${value}`;\n  }\n  return output;\n}\n\nfunction strictlySplitByteSequence(buf, cp) {\n  const list = [];\n  let last = 0;\n  let i = buf.indexOf(cp);\n  while (i >= 0) {\n    list.push(buf.slice(last, i));\n    last = i + 1;\n    i = buf.indexOf(cp, last);\n  }\n  if (last !== buf.length) {\n    list.push(buf.slice(last));\n  }\n  return list;\n}\n\nfunction replaceByteInByteSequence(buf, from, to) {\n  let i = buf.indexOf(from);\n  while (i >= 0) {\n    buf[i] = to;\n    i = buf.indexOf(from, i + 1);\n  }\n  return buf;\n}\n\nmodule.exports = {\n  parseUrlencodedString,\n  serializeUrlencoded\n};\n\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/urlencoded.js?");

/***/ }),

/***/ "./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/utils.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/utils.js ***!
  \*****************************************************************************************/
/***/ ((module, exports) => {

"use strict";
eval("\n\n// Returns \"Type(value) is Object\" in ES terminology.\nfunction isObject(value) {\n  return (typeof value === \"object\" && value !== null) || typeof value === \"function\";\n}\n\nconst hasOwn = Function.prototype.call.bind(Object.prototype.hasOwnProperty);\n\n// Like `Object.assign`, but using `[[GetOwnProperty]]` and `[[DefineOwnProperty]]`\n// instead of `[[Get]]` and `[[Set]]` and only allowing objects\nfunction define(target, source) {\n  for (const key of Reflect.ownKeys(source)) {\n    const descriptor = Reflect.getOwnPropertyDescriptor(source, key);\n    if (descriptor && !Reflect.defineProperty(target, key, descriptor)) {\n      throw new TypeError(`Cannot redefine property: ${String(key)}`);\n    }\n  }\n}\n\nfunction newObjectInRealm(globalObject, object) {\n  const ctorRegistry = initCtorRegistry(globalObject);\n  return Object.defineProperties(\n    Object.create(ctorRegistry[\"%Object.prototype%\"]),\n    Object.getOwnPropertyDescriptors(object)\n  );\n}\n\nconst wrapperSymbol = Symbol(\"wrapper\");\nconst implSymbol = Symbol(\"impl\");\nconst sameObjectCaches = Symbol(\"SameObject caches\");\nconst ctorRegistrySymbol = Symbol.for(\"[webidl2js] constructor registry\");\n\nconst AsyncIteratorPrototype = Object.getPrototypeOf(Object.getPrototypeOf(async function* () {}).prototype);\n\nfunction initCtorRegistry(globalObject) {\n  if (hasOwn(globalObject, ctorRegistrySymbol)) {\n    return globalObject[ctorRegistrySymbol];\n  }\n\n  const ctorRegistry = Object.create(null);\n\n  // In addition to registering all the WebIDL2JS-generated types in the constructor registry,\n  // we also register a few intrinsics that we make use of in generated code, since they are not\n  // easy to grab from the globalObject variable.\n  ctorRegistry[\"%Object.prototype%\"] = globalObject.Object.prototype;\n  ctorRegistry[\"%IteratorPrototype%\"] = Object.getPrototypeOf(\n    Object.getPrototypeOf(new globalObject.Array()[Symbol.iterator]())\n  );\n\n  try {\n    ctorRegistry[\"%AsyncIteratorPrototype%\"] = Object.getPrototypeOf(\n      Object.getPrototypeOf(\n        globalObject.eval(\"(async function* () {})\").prototype\n      )\n    );\n  } catch {\n    ctorRegistry[\"%AsyncIteratorPrototype%\"] = AsyncIteratorPrototype;\n  }\n\n  globalObject[ctorRegistrySymbol] = ctorRegistry;\n  return ctorRegistry;\n}\n\nfunction getSameObject(wrapper, prop, creator) {\n  if (!wrapper[sameObjectCaches]) {\n    wrapper[sameObjectCaches] = Object.create(null);\n  }\n\n  if (prop in wrapper[sameObjectCaches]) {\n    return wrapper[sameObjectCaches][prop];\n  }\n\n  wrapper[sameObjectCaches][prop] = creator();\n  return wrapper[sameObjectCaches][prop];\n}\n\nfunction wrapperForImpl(impl) {\n  return impl ? impl[wrapperSymbol] : null;\n}\n\nfunction implForWrapper(wrapper) {\n  return wrapper ? wrapper[implSymbol] : null;\n}\n\nfunction tryWrapperForImpl(impl) {\n  const wrapper = wrapperForImpl(impl);\n  return wrapper ? wrapper : impl;\n}\n\nfunction tryImplForWrapper(wrapper) {\n  const impl = implForWrapper(wrapper);\n  return impl ? impl : wrapper;\n}\n\nconst iterInternalSymbol = Symbol(\"internal\");\n\nfunction isArrayIndexPropName(P) {\n  if (typeof P !== \"string\") {\n    return false;\n  }\n  const i = P >>> 0;\n  if (i === 2 ** 32 - 1) {\n    return false;\n  }\n  const s = `${i}`;\n  if (P !== s) {\n    return false;\n  }\n  return true;\n}\n\nconst byteLengthGetter =\n    Object.getOwnPropertyDescriptor(ArrayBuffer.prototype, \"byteLength\").get;\nfunction isArrayBuffer(value) {\n  try {\n    byteLengthGetter.call(value);\n    return true;\n  } catch (e) {\n    return false;\n  }\n}\n\nfunction iteratorResult([key, value], kind) {\n  let result;\n  switch (kind) {\n    case \"key\":\n      result = key;\n      break;\n    case \"value\":\n      result = value;\n      break;\n    case \"key+value\":\n      result = [key, value];\n      break;\n  }\n  return { value: result, done: false };\n}\n\nconst supportsPropertyIndex = Symbol(\"supports property index\");\nconst supportedPropertyIndices = Symbol(\"supported property indices\");\nconst supportsPropertyName = Symbol(\"supports property name\");\nconst supportedPropertyNames = Symbol(\"supported property names\");\nconst indexedGet = Symbol(\"indexed property get\");\nconst indexedSetNew = Symbol(\"indexed property set new\");\nconst indexedSetExisting = Symbol(\"indexed property set existing\");\nconst namedGet = Symbol(\"named property get\");\nconst namedSetNew = Symbol(\"named property set new\");\nconst namedSetExisting = Symbol(\"named property set existing\");\nconst namedDelete = Symbol(\"named property delete\");\n\nconst asyncIteratorNext = Symbol(\"async iterator get the next iteration result\");\nconst asyncIteratorReturn = Symbol(\"async iterator return steps\");\nconst asyncIteratorInit = Symbol(\"async iterator initialization steps\");\nconst asyncIteratorEOI = Symbol(\"async iterator end of iteration\");\n\nmodule.exports = exports = {\n  isObject,\n  hasOwn,\n  define,\n  newObjectInRealm,\n  wrapperSymbol,\n  implSymbol,\n  getSameObject,\n  ctorRegistrySymbol,\n  initCtorRegistry,\n  wrapperForImpl,\n  implForWrapper,\n  tryWrapperForImpl,\n  tryImplForWrapper,\n  iterInternalSymbol,\n  isArrayBuffer,\n  isArrayIndexPropName,\n  supportsPropertyIndex,\n  supportedPropertyIndices,\n  supportsPropertyName,\n  supportedPropertyNames,\n  indexedGet,\n  indexedSetNew,\n  indexedSetExisting,\n  namedGet,\n  namedSetNew,\n  namedSetExisting,\n  namedDelete,\n  asyncIteratorNext,\n  asyncIteratorReturn,\n  asyncIteratorInit,\n  asyncIteratorEOI,\n  iteratorResult\n};\n\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/utils.js?");

/***/ }),

/***/ "./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/webidl2js-wrapper.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/webidl2js-wrapper.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nconst URL = __webpack_require__(/*! ./lib/URL */ \"./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/URL.js\");\nconst URLSearchParams = __webpack_require__(/*! ./lib/URLSearchParams */ \"./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/lib/URLSearchParams.js\");\n\nexports.URL = URL;\nexports.URLSearchParams = URLSearchParams;\n\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb-connection-string-url/node_modules/whatwg-url/webidl2js-wrapper.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/admin.js":
/*!*******************************************!*\
  !*** ./node_modules/mongodb/lib/admin.js ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Admin = void 0;\nconst bson_1 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst execute_operation_1 = __webpack_require__(/*! ./operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst list_databases_1 = __webpack_require__(/*! ./operations/list_databases */ \"./node_modules/mongodb/lib/operations/list_databases.js\");\nconst remove_user_1 = __webpack_require__(/*! ./operations/remove_user */ \"./node_modules/mongodb/lib/operations/remove_user.js\");\nconst run_command_1 = __webpack_require__(/*! ./operations/run_command */ \"./node_modules/mongodb/lib/operations/run_command.js\");\nconst validate_collection_1 = __webpack_require__(/*! ./operations/validate_collection */ \"./node_modules/mongodb/lib/operations/validate_collection.js\");\n/**\n * The **Admin** class is an internal class that allows convenient access to\n * the admin functionality and commands for MongoDB.\n *\n * **ADMIN Cannot directly be instantiated**\n * @public\n *\n * @example\n * ```ts\n * import { MongoClient } from 'mongodb';\n *\n * const client = new MongoClient('mongodb://localhost:27017');\n * const admin = client.db().admin();\n * const dbInfo = await admin.listDatabases();\n * for (const db of dbInfo.databases) {\n *   console.log(db.name);\n * }\n * ```\n */\nclass Admin {\n    /**\n     * Create a new Admin instance\n     * @internal\n     */\n    constructor(db) {\n        this.s = { db };\n    }\n    /**\n     * Execute a command\n     *\n     * The driver will ensure the following fields are attached to the command sent to the server:\n     * - `lsid` - sourced from an implicit session or options.session\n     * - `$readPreference` - defaults to primary or can be configured by options.readPreference\n     * - `$db` - sourced from the name of this database\n     *\n     * If the client has a serverApi setting:\n     * - `apiVersion`\n     * - `apiStrict`\n     * - `apiDeprecationErrors`\n     *\n     * When in a transaction:\n     * - `readConcern` - sourced from readConcern set on the TransactionOptions\n     * - `writeConcern` - sourced from writeConcern set on the TransactionOptions\n     *\n     * Attaching any of the above fields to the command will have no effect as the driver will overwrite the value.\n     *\n     * @param command - The command to execute\n     * @param options - Optional settings for the command\n     */\n    async command(command, options) {\n        return (0, execute_operation_1.executeOperation)(this.s.db.client, new run_command_1.RunAdminCommandOperation(command, {\n            ...(0, bson_1.resolveBSONOptions)(options),\n            session: options?.session,\n            readPreference: options?.readPreference\n        }));\n    }\n    /**\n     * Retrieve the server build information\n     *\n     * @param options - Optional settings for the command\n     */\n    async buildInfo(options) {\n        return this.command({ buildinfo: 1 }, options);\n    }\n    /**\n     * Retrieve the server build information\n     *\n     * @param options - Optional settings for the command\n     */\n    async serverInfo(options) {\n        return this.command({ buildinfo: 1 }, options);\n    }\n    /**\n     * Retrieve this db's server status.\n     *\n     * @param options - Optional settings for the command\n     */\n    async serverStatus(options) {\n        return this.command({ serverStatus: 1 }, options);\n    }\n    /**\n     * Ping the MongoDB server and retrieve results\n     *\n     * @param options - Optional settings for the command\n     */\n    async ping(options) {\n        return this.command({ ping: 1 }, options);\n    }\n    /**\n     * Remove a user from a database\n     *\n     * @param username - The username to remove\n     * @param options - Optional settings for the command\n     */\n    async removeUser(username, options) {\n        return (0, execute_operation_1.executeOperation)(this.s.db.client, new remove_user_1.RemoveUserOperation(this.s.db, username, { dbName: 'admin', ...options }));\n    }\n    /**\n     * Validate an existing collection\n     *\n     * @param collectionName - The name of the collection to validate.\n     * @param options - Optional settings for the command\n     */\n    async validateCollection(collectionName, options = {}) {\n        return (0, execute_operation_1.executeOperation)(this.s.db.client, new validate_collection_1.ValidateCollectionOperation(this, collectionName, options));\n    }\n    /**\n     * List the available databases\n     *\n     * @param options - Optional settings for the command\n     */\n    async listDatabases(options) {\n        return (0, execute_operation_1.executeOperation)(this.s.db.client, new list_databases_1.ListDatabasesOperation(this.s.db, options));\n    }\n    /**\n     * Get ReplicaSet status\n     *\n     * @param options - Optional settings for the command\n     */\n    async replSetGetStatus(options) {\n        return this.command({ replSetGetStatus: 1 }, options);\n    }\n}\nexports.Admin = Admin;\n//# sourceMappingURL=admin.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/admin.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/bson.js":
/*!******************************************!*\
  !*** ./node_modules/mongodb/lib/bson.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.resolveBSONOptions = exports.pluckBSONSerializeOptions = exports.UUID = exports.Timestamp = exports.serialize = exports.ObjectId = exports.MinKey = exports.MaxKey = exports.Long = exports.Int32 = exports.Double = exports.deserialize = exports.Decimal128 = exports.DBRef = exports.Code = exports.calculateObjectSize = exports.BSONType = exports.BSONSymbol = exports.BSONRegExp = exports.BSON = exports.Binary = void 0;\nvar bson_1 = __webpack_require__(/*! bson */ \"./node_modules/bson/lib/bson.cjs\");\nObject.defineProperty(exports, \"Binary\", ({ enumerable: true, get: function () { return bson_1.Binary; } }));\nObject.defineProperty(exports, \"BSON\", ({ enumerable: true, get: function () { return bson_1.BSON; } }));\nObject.defineProperty(exports, \"BSONRegExp\", ({ enumerable: true, get: function () { return bson_1.BSONRegExp; } }));\nObject.defineProperty(exports, \"BSONSymbol\", ({ enumerable: true, get: function () { return bson_1.BSONSymbol; } }));\nObject.defineProperty(exports, \"BSONType\", ({ enumerable: true, get: function () { return bson_1.BSONType; } }));\nObject.defineProperty(exports, \"calculateObjectSize\", ({ enumerable: true, get: function () { return bson_1.calculateObjectSize; } }));\nObject.defineProperty(exports, \"Code\", ({ enumerable: true, get: function () { return bson_1.Code; } }));\nObject.defineProperty(exports, \"DBRef\", ({ enumerable: true, get: function () { return bson_1.DBRef; } }));\nObject.defineProperty(exports, \"Decimal128\", ({ enumerable: true, get: function () { return bson_1.Decimal128; } }));\nObject.defineProperty(exports, \"deserialize\", ({ enumerable: true, get: function () { return bson_1.deserialize; } }));\nObject.defineProperty(exports, \"Double\", ({ enumerable: true, get: function () { return bson_1.Double; } }));\nObject.defineProperty(exports, \"Int32\", ({ enumerable: true, get: function () { return bson_1.Int32; } }));\nObject.defineProperty(exports, \"Long\", ({ enumerable: true, get: function () { return bson_1.Long; } }));\nObject.defineProperty(exports, \"MaxKey\", ({ enumerable: true, get: function () { return bson_1.MaxKey; } }));\nObject.defineProperty(exports, \"MinKey\", ({ enumerable: true, get: function () { return bson_1.MinKey; } }));\nObject.defineProperty(exports, \"ObjectId\", ({ enumerable: true, get: function () { return bson_1.ObjectId; } }));\nObject.defineProperty(exports, \"serialize\", ({ enumerable: true, get: function () { return bson_1.serialize; } }));\nObject.defineProperty(exports, \"Timestamp\", ({ enumerable: true, get: function () { return bson_1.Timestamp; } }));\nObject.defineProperty(exports, \"UUID\", ({ enumerable: true, get: function () { return bson_1.UUID; } }));\nfunction pluckBSONSerializeOptions(options) {\n    const { fieldsAsRaw, useBigInt64, promoteValues, promoteBuffers, promoteLongs, serializeFunctions, ignoreUndefined, bsonRegExp, raw, enableUtf8Validation } = options;\n    return {\n        fieldsAsRaw,\n        useBigInt64,\n        promoteValues,\n        promoteBuffers,\n        promoteLongs,\n        serializeFunctions,\n        ignoreUndefined,\n        bsonRegExp,\n        raw,\n        enableUtf8Validation\n    };\n}\nexports.pluckBSONSerializeOptions = pluckBSONSerializeOptions;\n/**\n * Merge the given BSONSerializeOptions, preferring options over the parent's options, and\n * substituting defaults for values not set.\n *\n * @internal\n */\nfunction resolveBSONOptions(options, parent) {\n    const parentOptions = parent?.bsonOptions;\n    return {\n        raw: options?.raw ?? parentOptions?.raw ?? false,\n        useBigInt64: options?.useBigInt64 ?? parentOptions?.useBigInt64 ?? false,\n        promoteLongs: options?.promoteLongs ?? parentOptions?.promoteLongs ?? true,\n        promoteValues: options?.promoteValues ?? parentOptions?.promoteValues ?? true,\n        promoteBuffers: options?.promoteBuffers ?? parentOptions?.promoteBuffers ?? false,\n        ignoreUndefined: options?.ignoreUndefined ?? parentOptions?.ignoreUndefined ?? false,\n        bsonRegExp: options?.bsonRegExp ?? parentOptions?.bsonRegExp ?? false,\n        serializeFunctions: options?.serializeFunctions ?? parentOptions?.serializeFunctions ?? false,\n        fieldsAsRaw: options?.fieldsAsRaw ?? parentOptions?.fieldsAsRaw ?? {},\n        enableUtf8Validation: options?.enableUtf8Validation ?? parentOptions?.enableUtf8Validation ?? true\n    };\n}\nexports.resolveBSONOptions = resolveBSONOptions;\n//# sourceMappingURL=bson.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/bson.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/bulk/common.js":
/*!*************************************************!*\
  !*** ./node_modules/mongodb/lib/bulk/common.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.BulkOperationBase = exports.FindOperators = exports.MongoBulkWriteError = exports.mergeBatchResults = exports.WriteError = exports.WriteConcernError = exports.BulkWriteResult = exports.Batch = exports.BatchType = void 0;\nconst util_1 = __webpack_require__(/*! util */ \"util\");\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst delete_1 = __webpack_require__(/*! ../operations/delete */ \"./node_modules/mongodb/lib/operations/delete.js\");\nconst execute_operation_1 = __webpack_require__(/*! ../operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst insert_1 = __webpack_require__(/*! ../operations/insert */ \"./node_modules/mongodb/lib/operations/insert.js\");\nconst operation_1 = __webpack_require__(/*! ../operations/operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\nconst update_1 = __webpack_require__(/*! ../operations/update */ \"./node_modules/mongodb/lib/operations/update.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst write_concern_1 = __webpack_require__(/*! ../write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\n/** @internal */\nconst kServerError = Symbol('serverError');\n/** @public */\nexports.BatchType = Object.freeze({\n    INSERT: 1,\n    UPDATE: 2,\n    DELETE: 3\n});\n/**\n * Keeps the state of a unordered batch so we can rewrite the results\n * correctly after command execution\n *\n * @public\n */\nclass Batch {\n    constructor(batchType, originalZeroIndex) {\n        this.originalZeroIndex = originalZeroIndex;\n        this.currentIndex = 0;\n        this.originalIndexes = [];\n        this.batchType = batchType;\n        this.operations = [];\n        this.size = 0;\n        this.sizeBytes = 0;\n    }\n}\nexports.Batch = Batch;\n/**\n * @public\n * The result of a bulk write.\n */\nclass BulkWriteResult {\n    static generateIdMap(ids) {\n        const idMap = {};\n        for (const doc of ids) {\n            idMap[doc.index] = doc._id;\n        }\n        return idMap;\n    }\n    /**\n     * Create a new BulkWriteResult instance\n     * @internal\n     */\n    constructor(bulkResult, isOrdered) {\n        this.result = bulkResult;\n        this.insertedCount = this.result.nInserted ?? 0;\n        this.matchedCount = this.result.nMatched ?? 0;\n        this.modifiedCount = this.result.nModified ?? 0;\n        this.deletedCount = this.result.nRemoved ?? 0;\n        this.upsertedCount = this.result.upserted.length ?? 0;\n        this.upsertedIds = BulkWriteResult.generateIdMap(this.result.upserted);\n        this.insertedIds = BulkWriteResult.generateIdMap(this.getSuccessfullyInsertedIds(bulkResult, isOrdered));\n        Object.defineProperty(this, 'result', { value: this.result, enumerable: false });\n    }\n    /** Evaluates to true if the bulk operation correctly executes */\n    get ok() {\n        return this.result.ok;\n    }\n    /**\n     * Returns document_ids that were actually inserted\n     * @internal\n     */\n    getSuccessfullyInsertedIds(bulkResult, isOrdered) {\n        if (bulkResult.writeErrors.length === 0)\n            return bulkResult.insertedIds;\n        if (isOrdered) {\n            return bulkResult.insertedIds.slice(0, bulkResult.writeErrors[0].index);\n        }\n        return bulkResult.insertedIds.filter(({ index }) => !bulkResult.writeErrors.some(writeError => index === writeError.index));\n    }\n    /** Returns the upserted id at the given index */\n    getUpsertedIdAt(index) {\n        return this.result.upserted[index];\n    }\n    /** Returns raw internal result */\n    getRawResponse() {\n        return this.result;\n    }\n    /** Returns true if the bulk operation contains a write error */\n    hasWriteErrors() {\n        return this.result.writeErrors.length > 0;\n    }\n    /** Returns the number of write errors off the bulk operation */\n    getWriteErrorCount() {\n        return this.result.writeErrors.length;\n    }\n    /** Returns a specific write error object */\n    getWriteErrorAt(index) {\n        return index < this.result.writeErrors.length ? this.result.writeErrors[index] : undefined;\n    }\n    /** Retrieve all write errors */\n    getWriteErrors() {\n        return this.result.writeErrors;\n    }\n    /** Retrieve the write concern error if one exists */\n    getWriteConcernError() {\n        if (this.result.writeConcernErrors.length === 0) {\n            return;\n        }\n        else if (this.result.writeConcernErrors.length === 1) {\n            // Return the error\n            return this.result.writeConcernErrors[0];\n        }\n        else {\n            // Combine the errors\n            let errmsg = '';\n            for (let i = 0; i < this.result.writeConcernErrors.length; i++) {\n                const err = this.result.writeConcernErrors[i];\n                errmsg = errmsg + err.errmsg;\n                // TODO: Something better\n                if (i === 0)\n                    errmsg = errmsg + ' and ';\n            }\n            return new WriteConcernError({ errmsg, code: error_1.MONGODB_ERROR_CODES.WriteConcernFailed });\n        }\n    }\n    toString() {\n        return `BulkWriteResult(${this.result})`;\n    }\n    isOk() {\n        return this.result.ok === 1;\n    }\n}\nexports.BulkWriteResult = BulkWriteResult;\n/**\n * An error representing a failure by the server to apply the requested write concern to the bulk operation.\n * @public\n * @category Error\n */\nclass WriteConcernError {\n    constructor(error) {\n        this[kServerError] = error;\n    }\n    /** Write concern error code. */\n    get code() {\n        return this[kServerError].code;\n    }\n    /** Write concern error message. */\n    get errmsg() {\n        return this[kServerError].errmsg;\n    }\n    /** Write concern error info. */\n    get errInfo() {\n        return this[kServerError].errInfo;\n    }\n    toJSON() {\n        return this[kServerError];\n    }\n    toString() {\n        return `WriteConcernError(${this.errmsg})`;\n    }\n}\nexports.WriteConcernError = WriteConcernError;\n/**\n * An error that occurred during a BulkWrite on the server.\n * @public\n * @category Error\n */\nclass WriteError {\n    constructor(err) {\n        this.err = err;\n    }\n    /** WriteError code. */\n    get code() {\n        return this.err.code;\n    }\n    /** WriteError original bulk operation index. */\n    get index() {\n        return this.err.index;\n    }\n    /** WriteError message. */\n    get errmsg() {\n        return this.err.errmsg;\n    }\n    /** WriteError details. */\n    get errInfo() {\n        return this.err.errInfo;\n    }\n    /** Returns the underlying operation that caused the error */\n    getOperation() {\n        return this.err.op;\n    }\n    toJSON() {\n        return { code: this.err.code, index: this.err.index, errmsg: this.err.errmsg, op: this.err.op };\n    }\n    toString() {\n        return `WriteError(${JSON.stringify(this.toJSON())})`;\n    }\n}\nexports.WriteError = WriteError;\n/** Merges results into shared data structure */\nfunction mergeBatchResults(batch, bulkResult, err, result) {\n    // If we have an error set the result to be the err object\n    if (err) {\n        result = err;\n    }\n    else if (result && result.result) {\n        result = result.result;\n    }\n    if (result == null) {\n        return;\n    }\n    // Do we have a top level error stop processing and return\n    if (result.ok === 0 && bulkResult.ok === 1) {\n        bulkResult.ok = 0;\n        const writeError = {\n            index: 0,\n            code: result.code || 0,\n            errmsg: result.message,\n            errInfo: result.errInfo,\n            op: batch.operations[0]\n        };\n        bulkResult.writeErrors.push(new WriteError(writeError));\n        return;\n    }\n    else if (result.ok === 0 && bulkResult.ok === 0) {\n        return;\n    }\n    // If we have an insert Batch type\n    if (isInsertBatch(batch) && result.n) {\n        bulkResult.nInserted = bulkResult.nInserted + result.n;\n    }\n    // If we have an insert Batch type\n    if (isDeleteBatch(batch) && result.n) {\n        bulkResult.nRemoved = bulkResult.nRemoved + result.n;\n    }\n    let nUpserted = 0;\n    // We have an array of upserted values, we need to rewrite the indexes\n    if (Array.isArray(result.upserted)) {\n        nUpserted = result.upserted.length;\n        for (let i = 0; i < result.upserted.length; i++) {\n            bulkResult.upserted.push({\n                index: result.upserted[i].index + batch.originalZeroIndex,\n                _id: result.upserted[i]._id\n            });\n        }\n    }\n    else if (result.upserted) {\n        nUpserted = 1;\n        bulkResult.upserted.push({\n            index: batch.originalZeroIndex,\n            _id: result.upserted\n        });\n    }\n    // If we have an update Batch type\n    if (isUpdateBatch(batch) && result.n) {\n        const nModified = result.nModified;\n        bulkResult.nUpserted = bulkResult.nUpserted + nUpserted;\n        bulkResult.nMatched = bulkResult.nMatched + (result.n - nUpserted);\n        if (typeof nModified === 'number') {\n            bulkResult.nModified = bulkResult.nModified + nModified;\n        }\n        else {\n            bulkResult.nModified = 0;\n        }\n    }\n    if (Array.isArray(result.writeErrors)) {\n        for (let i = 0; i < result.writeErrors.length; i++) {\n            const writeError = {\n                index: batch.originalIndexes[result.writeErrors[i].index],\n                code: result.writeErrors[i].code,\n                errmsg: result.writeErrors[i].errmsg,\n                errInfo: result.writeErrors[i].errInfo,\n                op: batch.operations[result.writeErrors[i].index]\n            };\n            bulkResult.writeErrors.push(new WriteError(writeError));\n        }\n    }\n    if (result.writeConcernError) {\n        bulkResult.writeConcernErrors.push(new WriteConcernError(result.writeConcernError));\n    }\n}\nexports.mergeBatchResults = mergeBatchResults;\nfunction executeCommands(bulkOperation, options, callback) {\n    if (bulkOperation.s.batches.length === 0) {\n        return callback(undefined, new BulkWriteResult(bulkOperation.s.bulkResult, bulkOperation.isOrdered));\n    }\n    const batch = bulkOperation.s.batches.shift();\n    function resultHandler(err, result) {\n        // Error is a driver related error not a bulk op error, return early\n        if (err && 'message' in err && !(err instanceof error_1.MongoWriteConcernError)) {\n            return callback(new MongoBulkWriteError(err, new BulkWriteResult(bulkOperation.s.bulkResult, bulkOperation.isOrdered)));\n        }\n        if (err instanceof error_1.MongoWriteConcernError) {\n            return handleMongoWriteConcernError(batch, bulkOperation.s.bulkResult, bulkOperation.isOrdered, err, callback);\n        }\n        // Merge the results together\n        mergeBatchResults(batch, bulkOperation.s.bulkResult, err, result);\n        const writeResult = new BulkWriteResult(bulkOperation.s.bulkResult, bulkOperation.isOrdered);\n        if (bulkOperation.handleWriteError(callback, writeResult))\n            return;\n        // Execute the next command in line\n        executeCommands(bulkOperation, options, callback);\n    }\n    const finalOptions = (0, utils_1.resolveOptions)(bulkOperation, {\n        ...options,\n        ordered: bulkOperation.isOrdered\n    });\n    if (finalOptions.bypassDocumentValidation !== true) {\n        delete finalOptions.bypassDocumentValidation;\n    }\n    // Set an operationIf if provided\n    if (bulkOperation.operationId) {\n        resultHandler.operationId = bulkOperation.operationId;\n    }\n    // Is the bypassDocumentValidation options specific\n    if (bulkOperation.s.bypassDocumentValidation === true) {\n        finalOptions.bypassDocumentValidation = true;\n    }\n    // Is the checkKeys option disabled\n    if (bulkOperation.s.checkKeys === false) {\n        finalOptions.checkKeys = false;\n    }\n    if (finalOptions.retryWrites) {\n        if (isUpdateBatch(batch)) {\n            finalOptions.retryWrites = finalOptions.retryWrites && !batch.operations.some(op => op.multi);\n        }\n        if (isDeleteBatch(batch)) {\n            finalOptions.retryWrites =\n                finalOptions.retryWrites && !batch.operations.some(op => op.limit === 0);\n        }\n    }\n    try {\n        if (isInsertBatch(batch)) {\n            (0, execute_operation_1.executeOperation)(bulkOperation.s.collection.client, new insert_1.InsertOperation(bulkOperation.s.namespace, batch.operations, finalOptions), resultHandler);\n        }\n        else if (isUpdateBatch(batch)) {\n            (0, execute_operation_1.executeOperation)(bulkOperation.s.collection.client, new update_1.UpdateOperation(bulkOperation.s.namespace, batch.operations, finalOptions), resultHandler);\n        }\n        else if (isDeleteBatch(batch)) {\n            (0, execute_operation_1.executeOperation)(bulkOperation.s.collection.client, new delete_1.DeleteOperation(bulkOperation.s.namespace, batch.operations, finalOptions), resultHandler);\n        }\n    }\n    catch (err) {\n        // Force top level error\n        err.ok = 0;\n        // Merge top level error and return\n        mergeBatchResults(batch, bulkOperation.s.bulkResult, err, undefined);\n        callback();\n    }\n}\nfunction handleMongoWriteConcernError(batch, bulkResult, isOrdered, err, callback) {\n    mergeBatchResults(batch, bulkResult, undefined, err.result);\n    callback(new MongoBulkWriteError({\n        message: err.result?.writeConcernError.errmsg,\n        code: err.result?.writeConcernError.result\n    }, new BulkWriteResult(bulkResult, isOrdered)));\n}\n/**\n * An error indicating an unsuccessful Bulk Write\n * @public\n * @category Error\n */\nclass MongoBulkWriteError extends error_1.MongoServerError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(error, result) {\n        super(error);\n        this.writeErrors = [];\n        if (error instanceof WriteConcernError)\n            this.err = error;\n        else if (!(error instanceof Error)) {\n            this.message = error.message;\n            this.code = error.code;\n            this.writeErrors = error.writeErrors ?? [];\n        }\n        this.result = result;\n        Object.assign(this, error);\n    }\n    get name() {\n        return 'MongoBulkWriteError';\n    }\n    /** Number of documents inserted. */\n    get insertedCount() {\n        return this.result.insertedCount;\n    }\n    /** Number of documents matched for update. */\n    get matchedCount() {\n        return this.result.matchedCount;\n    }\n    /** Number of documents modified. */\n    get modifiedCount() {\n        return this.result.modifiedCount;\n    }\n    /** Number of documents deleted. */\n    get deletedCount() {\n        return this.result.deletedCount;\n    }\n    /** Number of documents upserted. */\n    get upsertedCount() {\n        return this.result.upsertedCount;\n    }\n    /** Inserted document generated Id's, hash key is the index of the originating operation */\n    get insertedIds() {\n        return this.result.insertedIds;\n    }\n    /** Upserted document generated Id's, hash key is the index of the originating operation */\n    get upsertedIds() {\n        return this.result.upsertedIds;\n    }\n}\nexports.MongoBulkWriteError = MongoBulkWriteError;\n/**\n * A builder object that is returned from {@link BulkOperationBase#find}.\n * Is used to build a write operation that involves a query filter.\n *\n * @public\n */\nclass FindOperators {\n    /**\n     * Creates a new FindOperators object.\n     * @internal\n     */\n    constructor(bulkOperation) {\n        this.bulkOperation = bulkOperation;\n    }\n    /** Add a multiple update operation to the bulk operation */\n    update(updateDocument) {\n        const currentOp = buildCurrentOp(this.bulkOperation);\n        return this.bulkOperation.addToOperationsList(exports.BatchType.UPDATE, (0, update_1.makeUpdateStatement)(currentOp.selector, updateDocument, {\n            ...currentOp,\n            multi: true\n        }));\n    }\n    /** Add a single update operation to the bulk operation */\n    updateOne(updateDocument) {\n        if (!(0, utils_1.hasAtomicOperators)(updateDocument)) {\n            throw new error_1.MongoInvalidArgumentError('Update document requires atomic operators');\n        }\n        const currentOp = buildCurrentOp(this.bulkOperation);\n        return this.bulkOperation.addToOperationsList(exports.BatchType.UPDATE, (0, update_1.makeUpdateStatement)(currentOp.selector, updateDocument, { ...currentOp, multi: false }));\n    }\n    /** Add a replace one operation to the bulk operation */\n    replaceOne(replacement) {\n        if ((0, utils_1.hasAtomicOperators)(replacement)) {\n            throw new error_1.MongoInvalidArgumentError('Replacement document must not use atomic operators');\n        }\n        const currentOp = buildCurrentOp(this.bulkOperation);\n        return this.bulkOperation.addToOperationsList(exports.BatchType.UPDATE, (0, update_1.makeUpdateStatement)(currentOp.selector, replacement, { ...currentOp, multi: false }));\n    }\n    /** Add a delete one operation to the bulk operation */\n    deleteOne() {\n        const currentOp = buildCurrentOp(this.bulkOperation);\n        return this.bulkOperation.addToOperationsList(exports.BatchType.DELETE, (0, delete_1.makeDeleteStatement)(currentOp.selector, { ...currentOp, limit: 1 }));\n    }\n    /** Add a delete many operation to the bulk operation */\n    delete() {\n        const currentOp = buildCurrentOp(this.bulkOperation);\n        return this.bulkOperation.addToOperationsList(exports.BatchType.DELETE, (0, delete_1.makeDeleteStatement)(currentOp.selector, { ...currentOp, limit: 0 }));\n    }\n    /** Upsert modifier for update bulk operation, noting that this operation is an upsert. */\n    upsert() {\n        if (!this.bulkOperation.s.currentOp) {\n            this.bulkOperation.s.currentOp = {};\n        }\n        this.bulkOperation.s.currentOp.upsert = true;\n        return this;\n    }\n    /** Specifies the collation for the query condition. */\n    collation(collation) {\n        if (!this.bulkOperation.s.currentOp) {\n            this.bulkOperation.s.currentOp = {};\n        }\n        this.bulkOperation.s.currentOp.collation = collation;\n        return this;\n    }\n    /** Specifies arrayFilters for UpdateOne or UpdateMany bulk operations. */\n    arrayFilters(arrayFilters) {\n        if (!this.bulkOperation.s.currentOp) {\n            this.bulkOperation.s.currentOp = {};\n        }\n        this.bulkOperation.s.currentOp.arrayFilters = arrayFilters;\n        return this;\n    }\n    /** Specifies hint for the bulk operation. */\n    hint(hint) {\n        if (!this.bulkOperation.s.currentOp) {\n            this.bulkOperation.s.currentOp = {};\n        }\n        this.bulkOperation.s.currentOp.hint = hint;\n        return this;\n    }\n}\nexports.FindOperators = FindOperators;\nconst executeCommandsAsync = (0, util_1.promisify)(executeCommands);\n/**\n * TODO(NODE-4063)\n * BulkWrites merge complexity is implemented in executeCommands\n * This provides a vehicle to treat bulkOperations like any other operation (hence \"shim\")\n * We would like this logic to simply live inside the BulkWriteOperation class\n * @internal\n */\nclass BulkWriteShimOperation extends operation_1.AbstractOperation {\n    constructor(bulkOperation, options) {\n        super(options);\n        this.bulkOperation = bulkOperation;\n    }\n    execute(_server, session) {\n        if (this.options.session == null) {\n            // An implicit session could have been created by 'executeOperation'\n            // So if we stick it on finalOptions here, each bulk operation\n            // will use this same session, it'll be passed in the same way\n            // an explicit session would be\n            this.options.session = session;\n        }\n        return executeCommandsAsync(this.bulkOperation, this.options);\n    }\n}\n/** @public */\nclass BulkOperationBase {\n    /**\n     * Create a new OrderedBulkOperation or UnorderedBulkOperation instance\n     * @internal\n     */\n    constructor(collection, options, isOrdered) {\n        // determine whether bulkOperation is ordered or unordered\n        this.isOrdered = isOrdered;\n        const topology = (0, utils_1.getTopology)(collection);\n        options = options == null ? {} : options;\n        // TODO Bring from driver information in hello\n        // Get the namespace for the write operations\n        const namespace = collection.s.namespace;\n        // Used to mark operation as executed\n        const executed = false;\n        // Current item\n        const currentOp = undefined;\n        // Set max byte size\n        const hello = topology.lastHello();\n        // If we have autoEncryption on, batch-splitting must be done on 2mb chunks, but single documents\n        // over 2mb are still allowed\n        const usingAutoEncryption = !!(topology.s.options && topology.s.options.autoEncrypter);\n        const maxBsonObjectSize = hello && hello.maxBsonObjectSize ? hello.maxBsonObjectSize : 1024 * 1024 * 16;\n        const maxBatchSizeBytes = usingAutoEncryption ? 1024 * 1024 * 2 : maxBsonObjectSize;\n        const maxWriteBatchSize = hello && hello.maxWriteBatchSize ? hello.maxWriteBatchSize : 1000;\n        // Calculates the largest possible size of an Array key, represented as a BSON string\n        // element. This calculation:\n        //     1 byte for BSON type\n        //     # of bytes = length of (string representation of (maxWriteBatchSize - 1))\n        //   + 1 bytes for null terminator\n        const maxKeySize = (maxWriteBatchSize - 1).toString(10).length + 2;\n        // Final options for retryable writes\n        let finalOptions = Object.assign({}, options);\n        finalOptions = (0, utils_1.applyRetryableWrites)(finalOptions, collection.s.db);\n        // Final results\n        const bulkResult = {\n            ok: 1,\n            writeErrors: [],\n            writeConcernErrors: [],\n            insertedIds: [],\n            nInserted: 0,\n            nUpserted: 0,\n            nMatched: 0,\n            nModified: 0,\n            nRemoved: 0,\n            upserted: []\n        };\n        // Internal state\n        this.s = {\n            // Final result\n            bulkResult,\n            // Current batch state\n            currentBatch: undefined,\n            currentIndex: 0,\n            // ordered specific\n            currentBatchSize: 0,\n            currentBatchSizeBytes: 0,\n            // unordered specific\n            currentInsertBatch: undefined,\n            currentUpdateBatch: undefined,\n            currentRemoveBatch: undefined,\n            batches: [],\n            // Write concern\n            writeConcern: write_concern_1.WriteConcern.fromOptions(options),\n            // Max batch size options\n            maxBsonObjectSize,\n            maxBatchSizeBytes,\n            maxWriteBatchSize,\n            maxKeySize,\n            // Namespace\n            namespace,\n            // Topology\n            topology,\n            // Options\n            options: finalOptions,\n            // BSON options\n            bsonOptions: (0, bson_1.resolveBSONOptions)(options),\n            // Current operation\n            currentOp,\n            // Executed\n            executed,\n            // Collection\n            collection,\n            // Fundamental error\n            err: undefined,\n            // check keys\n            checkKeys: typeof options.checkKeys === 'boolean' ? options.checkKeys : false\n        };\n        // bypass Validation\n        if (options.bypassDocumentValidation === true) {\n            this.s.bypassDocumentValidation = true;\n        }\n    }\n    /**\n     * Add a single insert document to the bulk operation\n     *\n     * @example\n     * ```ts\n     * const bulkOp = collection.initializeOrderedBulkOp();\n     *\n     * // Adds three inserts to the bulkOp.\n     * bulkOp\n     *   .insert({ a: 1 })\n     *   .insert({ b: 2 })\n     *   .insert({ c: 3 });\n     * await bulkOp.execute();\n     * ```\n     */\n    insert(document) {\n        if (document._id == null && !shouldForceServerObjectId(this)) {\n            document._id = new bson_1.ObjectId();\n        }\n        return this.addToOperationsList(exports.BatchType.INSERT, document);\n    }\n    /**\n     * Builds a find operation for an update/updateOne/delete/deleteOne/replaceOne.\n     * Returns a builder object used to complete the definition of the operation.\n     *\n     * @example\n     * ```ts\n     * const bulkOp = collection.initializeOrderedBulkOp();\n     *\n     * // Add an updateOne to the bulkOp\n     * bulkOp.find({ a: 1 }).updateOne({ $set: { b: 2 } });\n     *\n     * // Add an updateMany to the bulkOp\n     * bulkOp.find({ c: 3 }).update({ $set: { d: 4 } });\n     *\n     * // Add an upsert\n     * bulkOp.find({ e: 5 }).upsert().updateOne({ $set: { f: 6 } });\n     *\n     * // Add a deletion\n     * bulkOp.find({ g: 7 }).deleteOne();\n     *\n     * // Add a multi deletion\n     * bulkOp.find({ h: 8 }).delete();\n     *\n     * // Add a replaceOne\n     * bulkOp.find({ i: 9 }).replaceOne({writeConcern: { j: 10 }});\n     *\n     * // Update using a pipeline (requires Mongodb 4.2 or higher)\n     * bulk.find({ k: 11, y: { $exists: true }, z: { $exists: true } }).updateOne([\n     *   { $set: { total: { $sum: [ '$y', '$z' ] } } }\n     * ]);\n     *\n     * // All of the ops will now be executed\n     * await bulkOp.execute();\n     * ```\n     */\n    find(selector) {\n        if (!selector) {\n            throw new error_1.MongoInvalidArgumentError('Bulk find operation must specify a selector');\n        }\n        // Save a current selector\n        this.s.currentOp = {\n            selector: selector\n        };\n        return new FindOperators(this);\n    }\n    /** Specifies a raw operation to perform in the bulk write. */\n    raw(op) {\n        if (op == null || typeof op !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('Operation must be an object with an operation key');\n        }\n        if ('insertOne' in op) {\n            const forceServerObjectId = shouldForceServerObjectId(this);\n            if (op.insertOne && op.insertOne.document == null) {\n                // NOTE: provided for legacy support, but this is a malformed operation\n                if (forceServerObjectId !== true && op.insertOne._id == null) {\n                    op.insertOne._id = new bson_1.ObjectId();\n                }\n                return this.addToOperationsList(exports.BatchType.INSERT, op.insertOne);\n            }\n            if (forceServerObjectId !== true && op.insertOne.document._id == null) {\n                op.insertOne.document._id = new bson_1.ObjectId();\n            }\n            return this.addToOperationsList(exports.BatchType.INSERT, op.insertOne.document);\n        }\n        if ('replaceOne' in op || 'updateOne' in op || 'updateMany' in op) {\n            if ('replaceOne' in op) {\n                if ('q' in op.replaceOne) {\n                    throw new error_1.MongoInvalidArgumentError('Raw operations are not allowed');\n                }\n                const updateStatement = (0, update_1.makeUpdateStatement)(op.replaceOne.filter, op.replaceOne.replacement, { ...op.replaceOne, multi: false });\n                if ((0, utils_1.hasAtomicOperators)(updateStatement.u)) {\n                    throw new error_1.MongoInvalidArgumentError('Replacement document must not use atomic operators');\n                }\n                return this.addToOperationsList(exports.BatchType.UPDATE, updateStatement);\n            }\n            if ('updateOne' in op) {\n                if ('q' in op.updateOne) {\n                    throw new error_1.MongoInvalidArgumentError('Raw operations are not allowed');\n                }\n                const updateStatement = (0, update_1.makeUpdateStatement)(op.updateOne.filter, op.updateOne.update, {\n                    ...op.updateOne,\n                    multi: false\n                });\n                if (!(0, utils_1.hasAtomicOperators)(updateStatement.u)) {\n                    throw new error_1.MongoInvalidArgumentError('Update document requires atomic operators');\n                }\n                return this.addToOperationsList(exports.BatchType.UPDATE, updateStatement);\n            }\n            if ('updateMany' in op) {\n                if ('q' in op.updateMany) {\n                    throw new error_1.MongoInvalidArgumentError('Raw operations are not allowed');\n                }\n                const updateStatement = (0, update_1.makeUpdateStatement)(op.updateMany.filter, op.updateMany.update, {\n                    ...op.updateMany,\n                    multi: true\n                });\n                if (!(0, utils_1.hasAtomicOperators)(updateStatement.u)) {\n                    throw new error_1.MongoInvalidArgumentError('Update document requires atomic operators');\n                }\n                return this.addToOperationsList(exports.BatchType.UPDATE, updateStatement);\n            }\n        }\n        if ('deleteOne' in op) {\n            if ('q' in op.deleteOne) {\n                throw new error_1.MongoInvalidArgumentError('Raw operations are not allowed');\n            }\n            return this.addToOperationsList(exports.BatchType.DELETE, (0, delete_1.makeDeleteStatement)(op.deleteOne.filter, { ...op.deleteOne, limit: 1 }));\n        }\n        if ('deleteMany' in op) {\n            if ('q' in op.deleteMany) {\n                throw new error_1.MongoInvalidArgumentError('Raw operations are not allowed');\n            }\n            return this.addToOperationsList(exports.BatchType.DELETE, (0, delete_1.makeDeleteStatement)(op.deleteMany.filter, { ...op.deleteMany, limit: 0 }));\n        }\n        // otherwise an unknown operation was provided\n        throw new error_1.MongoInvalidArgumentError('bulkWrite only supports insertOne, updateOne, updateMany, deleteOne, deleteMany');\n    }\n    get bsonOptions() {\n        return this.s.bsonOptions;\n    }\n    get writeConcern() {\n        return this.s.writeConcern;\n    }\n    get batches() {\n        const batches = [...this.s.batches];\n        if (this.isOrdered) {\n            if (this.s.currentBatch)\n                batches.push(this.s.currentBatch);\n        }\n        else {\n            if (this.s.currentInsertBatch)\n                batches.push(this.s.currentInsertBatch);\n            if (this.s.currentUpdateBatch)\n                batches.push(this.s.currentUpdateBatch);\n            if (this.s.currentRemoveBatch)\n                batches.push(this.s.currentRemoveBatch);\n        }\n        return batches;\n    }\n    async execute(options = {}) {\n        if (this.s.executed) {\n            throw new error_1.MongoBatchReExecutionError();\n        }\n        const writeConcern = write_concern_1.WriteConcern.fromOptions(options);\n        if (writeConcern) {\n            this.s.writeConcern = writeConcern;\n        }\n        // If we have current batch\n        if (this.isOrdered) {\n            if (this.s.currentBatch)\n                this.s.batches.push(this.s.currentBatch);\n        }\n        else {\n            if (this.s.currentInsertBatch)\n                this.s.batches.push(this.s.currentInsertBatch);\n            if (this.s.currentUpdateBatch)\n                this.s.batches.push(this.s.currentUpdateBatch);\n            if (this.s.currentRemoveBatch)\n                this.s.batches.push(this.s.currentRemoveBatch);\n        }\n        // If we have no operations in the bulk raise an error\n        if (this.s.batches.length === 0) {\n            throw new error_1.MongoInvalidArgumentError('Invalid BulkOperation, Batch cannot be empty');\n        }\n        this.s.executed = true;\n        const finalOptions = { ...this.s.options, ...options };\n        const operation = new BulkWriteShimOperation(this, finalOptions);\n        return (0, execute_operation_1.executeOperation)(this.s.collection.client, operation);\n    }\n    /**\n     * Handles the write error before executing commands\n     * @internal\n     */\n    handleWriteError(callback, writeResult) {\n        if (this.s.bulkResult.writeErrors.length > 0) {\n            const msg = this.s.bulkResult.writeErrors[0].errmsg\n                ? this.s.bulkResult.writeErrors[0].errmsg\n                : 'write operation failed';\n            callback(new MongoBulkWriteError({\n                message: msg,\n                code: this.s.bulkResult.writeErrors[0].code,\n                writeErrors: this.s.bulkResult.writeErrors\n            }, writeResult));\n            return true;\n        }\n        const writeConcernError = writeResult.getWriteConcernError();\n        if (writeConcernError) {\n            callback(new MongoBulkWriteError(writeConcernError, writeResult));\n            return true;\n        }\n        return false;\n    }\n}\nexports.BulkOperationBase = BulkOperationBase;\nObject.defineProperty(BulkOperationBase.prototype, 'length', {\n    enumerable: true,\n    get() {\n        return this.s.currentIndex;\n    }\n});\nfunction shouldForceServerObjectId(bulkOperation) {\n    if (typeof bulkOperation.s.options.forceServerObjectId === 'boolean') {\n        return bulkOperation.s.options.forceServerObjectId;\n    }\n    if (typeof bulkOperation.s.collection.s.db.options?.forceServerObjectId === 'boolean') {\n        return bulkOperation.s.collection.s.db.options?.forceServerObjectId;\n    }\n    return false;\n}\nfunction isInsertBatch(batch) {\n    return batch.batchType === exports.BatchType.INSERT;\n}\nfunction isUpdateBatch(batch) {\n    return batch.batchType === exports.BatchType.UPDATE;\n}\nfunction isDeleteBatch(batch) {\n    return batch.batchType === exports.BatchType.DELETE;\n}\nfunction buildCurrentOp(bulkOp) {\n    let { currentOp } = bulkOp.s;\n    bulkOp.s.currentOp = undefined;\n    if (!currentOp)\n        currentOp = {};\n    return currentOp;\n}\n//# sourceMappingURL=common.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/bulk/common.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/bulk/ordered.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/bulk/ordered.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.OrderedBulkOperation = void 0;\nconst BSON = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst common_1 = __webpack_require__(/*! ./common */ \"./node_modules/mongodb/lib/bulk/common.js\");\n/** @public */\nclass OrderedBulkOperation extends common_1.BulkOperationBase {\n    /** @internal */\n    constructor(collection, options) {\n        super(collection, options, true);\n    }\n    addToOperationsList(batchType, document) {\n        // Get the bsonSize\n        const bsonSize = BSON.calculateObjectSize(document, {\n            checkKeys: false,\n            // Since we don't know what the user selected for BSON options here,\n            // err on the safe side, and check the size with ignoreUndefined: false.\n            ignoreUndefined: false\n        });\n        // Throw error if the doc is bigger than the max BSON size\n        if (bsonSize >= this.s.maxBsonObjectSize)\n            // TODO(NODE-3483): Change this to MongoBSONError\n            throw new error_1.MongoInvalidArgumentError(`Document is larger than the maximum size ${this.s.maxBsonObjectSize}`);\n        // Create a new batch object if we don't have a current one\n        if (this.s.currentBatch == null) {\n            this.s.currentBatch = new common_1.Batch(batchType, this.s.currentIndex);\n        }\n        const maxKeySize = this.s.maxKeySize;\n        // Check if we need to create a new batch\n        if (\n        // New batch if we exceed the max batch op size\n        this.s.currentBatchSize + 1 >= this.s.maxWriteBatchSize ||\n            // New batch if we exceed the maxBatchSizeBytes. Only matters if batch already has a doc,\n            // since we can't sent an empty batch\n            (this.s.currentBatchSize > 0 &&\n                this.s.currentBatchSizeBytes + maxKeySize + bsonSize >= this.s.maxBatchSizeBytes) ||\n            // New batch if the new op does not have the same op type as the current batch\n            this.s.currentBatch.batchType !== batchType) {\n            // Save the batch to the execution stack\n            this.s.batches.push(this.s.currentBatch);\n            // Create a new batch\n            this.s.currentBatch = new common_1.Batch(batchType, this.s.currentIndex);\n            // Reset the current size trackers\n            this.s.currentBatchSize = 0;\n            this.s.currentBatchSizeBytes = 0;\n        }\n        if (batchType === common_1.BatchType.INSERT) {\n            this.s.bulkResult.insertedIds.push({\n                index: this.s.currentIndex,\n                _id: document._id\n            });\n        }\n        // We have an array of documents\n        if (Array.isArray(document)) {\n            throw new error_1.MongoInvalidArgumentError('Operation passed in cannot be an Array');\n        }\n        this.s.currentBatch.originalIndexes.push(this.s.currentIndex);\n        this.s.currentBatch.operations.push(document);\n        this.s.currentBatchSize += 1;\n        this.s.currentBatchSizeBytes += maxKeySize + bsonSize;\n        this.s.currentIndex += 1;\n        return this;\n    }\n}\nexports.OrderedBulkOperation = OrderedBulkOperation;\n//# sourceMappingURL=ordered.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/bulk/ordered.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/bulk/unordered.js":
/*!****************************************************!*\
  !*** ./node_modules/mongodb/lib/bulk/unordered.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.UnorderedBulkOperation = void 0;\nconst BSON = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst common_1 = __webpack_require__(/*! ./common */ \"./node_modules/mongodb/lib/bulk/common.js\");\n/** @public */\nclass UnorderedBulkOperation extends common_1.BulkOperationBase {\n    /** @internal */\n    constructor(collection, options) {\n        super(collection, options, false);\n    }\n    handleWriteError(callback, writeResult) {\n        if (this.s.batches.length) {\n            return false;\n        }\n        return super.handleWriteError(callback, writeResult);\n    }\n    addToOperationsList(batchType, document) {\n        // Get the bsonSize\n        const bsonSize = BSON.calculateObjectSize(document, {\n            checkKeys: false,\n            // Since we don't know what the user selected for BSON options here,\n            // err on the safe side, and check the size with ignoreUndefined: false.\n            ignoreUndefined: false\n        });\n        // Throw error if the doc is bigger than the max BSON size\n        if (bsonSize >= this.s.maxBsonObjectSize) {\n            // TODO(NODE-3483): Change this to MongoBSONError\n            throw new error_1.MongoInvalidArgumentError(`Document is larger than the maximum size ${this.s.maxBsonObjectSize}`);\n        }\n        // Holds the current batch\n        this.s.currentBatch = undefined;\n        // Get the right type of batch\n        if (batchType === common_1.BatchType.INSERT) {\n            this.s.currentBatch = this.s.currentInsertBatch;\n        }\n        else if (batchType === common_1.BatchType.UPDATE) {\n            this.s.currentBatch = this.s.currentUpdateBatch;\n        }\n        else if (batchType === common_1.BatchType.DELETE) {\n            this.s.currentBatch = this.s.currentRemoveBatch;\n        }\n        const maxKeySize = this.s.maxKeySize;\n        // Create a new batch object if we don't have a current one\n        if (this.s.currentBatch == null) {\n            this.s.currentBatch = new common_1.Batch(batchType, this.s.currentIndex);\n        }\n        // Check if we need to create a new batch\n        if (\n        // New batch if we exceed the max batch op size\n        this.s.currentBatch.size + 1 >= this.s.maxWriteBatchSize ||\n            // New batch if we exceed the maxBatchSizeBytes. Only matters if batch already has a doc,\n            // since we can't sent an empty batch\n            (this.s.currentBatch.size > 0 &&\n                this.s.currentBatch.sizeBytes + maxKeySize + bsonSize >= this.s.maxBatchSizeBytes) ||\n            // New batch if the new op does not have the same op type as the current batch\n            this.s.currentBatch.batchType !== batchType) {\n            // Save the batch to the execution stack\n            this.s.batches.push(this.s.currentBatch);\n            // Create a new batch\n            this.s.currentBatch = new common_1.Batch(batchType, this.s.currentIndex);\n        }\n        // We have an array of documents\n        if (Array.isArray(document)) {\n            throw new error_1.MongoInvalidArgumentError('Operation passed in cannot be an Array');\n        }\n        this.s.currentBatch.operations.push(document);\n        this.s.currentBatch.originalIndexes.push(this.s.currentIndex);\n        this.s.currentIndex = this.s.currentIndex + 1;\n        // Save back the current Batch to the right type\n        if (batchType === common_1.BatchType.INSERT) {\n            this.s.currentInsertBatch = this.s.currentBatch;\n            this.s.bulkResult.insertedIds.push({\n                index: this.s.bulkResult.insertedIds.length,\n                _id: document._id\n            });\n        }\n        else if (batchType === common_1.BatchType.UPDATE) {\n            this.s.currentUpdateBatch = this.s.currentBatch;\n        }\n        else if (batchType === common_1.BatchType.DELETE) {\n            this.s.currentRemoveBatch = this.s.currentBatch;\n        }\n        // Update current batch size\n        this.s.currentBatch.size += 1;\n        this.s.currentBatch.sizeBytes += maxKeySize + bsonSize;\n        return this;\n    }\n}\nexports.UnorderedBulkOperation = UnorderedBulkOperation;\n//# sourceMappingURL=unordered.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/bulk/unordered.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/change_stream.js":
/*!***************************************************!*\
  !*** ./node_modules/mongodb/lib/change_stream.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ChangeStream = void 0;\nconst collection_1 = __webpack_require__(/*! ./collection */ \"./node_modules/mongodb/lib/collection.js\");\nconst constants_1 = __webpack_require__(/*! ./constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst change_stream_cursor_1 = __webpack_require__(/*! ./cursor/change_stream_cursor */ \"./node_modules/mongodb/lib/cursor/change_stream_cursor.js\");\nconst db_1 = __webpack_require__(/*! ./db */ \"./node_modules/mongodb/lib/db.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_client_1 = __webpack_require__(/*! ./mongo_client */ \"./node_modules/mongodb/lib/mongo_client.js\");\nconst mongo_types_1 = __webpack_require__(/*! ./mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/mongodb/lib/utils.js\");\n/** @internal */\nconst kCursorStream = Symbol('cursorStream');\n/** @internal */\nconst kClosed = Symbol('closed');\n/** @internal */\nconst kMode = Symbol('mode');\nconst CHANGE_STREAM_OPTIONS = [\n    'resumeAfter',\n    'startAfter',\n    'startAtOperationTime',\n    'fullDocument',\n    'fullDocumentBeforeChange',\n    'showExpandedEvents'\n];\nconst CHANGE_DOMAIN_TYPES = {\n    COLLECTION: Symbol('Collection'),\n    DATABASE: Symbol('Database'),\n    CLUSTER: Symbol('Cluster')\n};\nconst CHANGE_STREAM_EVENTS = [constants_1.RESUME_TOKEN_CHANGED, constants_1.END, constants_1.CLOSE];\nconst NO_RESUME_TOKEN_ERROR = 'A change stream document has been received that lacks a resume token (_id).';\nconst CHANGESTREAM_CLOSED_ERROR = 'ChangeStream is closed';\n/**\n * Creates a new Change Stream instance. Normally created using {@link Collection#watch|Collection.watch()}.\n * @public\n */\nclass ChangeStream extends mongo_types_1.TypedEventEmitter {\n    /**\n     * @internal\n     *\n     * @param parent - The parent object that created this change stream\n     * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents\n     */\n    constructor(parent, pipeline = [], options = {}) {\n        super();\n        this.pipeline = pipeline;\n        this.options = { ...options };\n        delete this.options.writeConcern;\n        if (parent instanceof collection_1.Collection) {\n            this.type = CHANGE_DOMAIN_TYPES.COLLECTION;\n        }\n        else if (parent instanceof db_1.Db) {\n            this.type = CHANGE_DOMAIN_TYPES.DATABASE;\n        }\n        else if (parent instanceof mongo_client_1.MongoClient) {\n            this.type = CHANGE_DOMAIN_TYPES.CLUSTER;\n        }\n        else {\n            throw new error_1.MongoChangeStreamError('Parent provided to ChangeStream constructor must be an instance of Collection, Db, or MongoClient');\n        }\n        this.parent = parent;\n        this.namespace = parent.s.namespace;\n        if (!this.options.readPreference && parent.readPreference) {\n            this.options.readPreference = parent.readPreference;\n        }\n        // Create contained Change Stream cursor\n        this.cursor = this._createChangeStreamCursor(options);\n        this[kClosed] = false;\n        this[kMode] = false;\n        // Listen for any `change` listeners being added to ChangeStream\n        this.on('newListener', eventName => {\n            if (eventName === 'change' && this.cursor && this.listenerCount('change') === 0) {\n                this._streamEvents(this.cursor);\n            }\n        });\n        this.on('removeListener', eventName => {\n            if (eventName === 'change' && this.listenerCount('change') === 0 && this.cursor) {\n                this[kCursorStream]?.removeAllListeners('data');\n            }\n        });\n    }\n    /** @internal */\n    get cursorStream() {\n        return this[kCursorStream];\n    }\n    /** The cached resume token that is used to resume after the most recently returned change. */\n    get resumeToken() {\n        return this.cursor?.resumeToken;\n    }\n    /** Check if there is any document still available in the Change Stream */\n    async hasNext() {\n        this._setIsIterator();\n        // Change streams must resume indefinitely while each resume event succeeds.\n        // This loop continues until either a change event is received or until a resume attempt\n        // fails.\n        // eslint-disable-next-line no-constant-condition\n        while (true) {\n            try {\n                const hasNext = await this.cursor.hasNext();\n                return hasNext;\n            }\n            catch (error) {\n                try {\n                    await this._processErrorIteratorMode(error);\n                }\n                catch (error) {\n                    try {\n                        await this.close();\n                    }\n                    catch {\n                        // We are not concerned with errors from close()\n                    }\n                    throw error;\n                }\n            }\n        }\n    }\n    /** Get the next available document from the Change Stream. */\n    async next() {\n        this._setIsIterator();\n        // Change streams must resume indefinitely while each resume event succeeds.\n        // This loop continues until either a change event is received or until a resume attempt\n        // fails.\n        // eslint-disable-next-line no-constant-condition\n        while (true) {\n            try {\n                const change = await this.cursor.next();\n                const processedChange = this._processChange(change ?? null);\n                return processedChange;\n            }\n            catch (error) {\n                try {\n                    await this._processErrorIteratorMode(error);\n                }\n                catch (error) {\n                    try {\n                        await this.close();\n                    }\n                    catch {\n                        // We are not concerned with errors from close()\n                    }\n                    throw error;\n                }\n            }\n        }\n    }\n    /**\n     * Try to get the next available document from the Change Stream's cursor or `null` if an empty batch is returned\n     */\n    async tryNext() {\n        this._setIsIterator();\n        // Change streams must resume indefinitely while each resume event succeeds.\n        // This loop continues until either a change event is received or until a resume attempt\n        // fails.\n        // eslint-disable-next-line no-constant-condition\n        while (true) {\n            try {\n                const change = await this.cursor.tryNext();\n                return change ?? null;\n            }\n            catch (error) {\n                try {\n                    await this._processErrorIteratorMode(error);\n                }\n                catch (error) {\n                    try {\n                        await this.close();\n                    }\n                    catch {\n                        // We are not concerned with errors from close()\n                    }\n                    throw error;\n                }\n            }\n        }\n    }\n    async *[Symbol.asyncIterator]() {\n        if (this.closed) {\n            return;\n        }\n        try {\n            // Change streams run indefinitely as long as errors are resumable\n            // So the only loop breaking condition is if `next()` throws\n            while (true) {\n                yield await this.next();\n            }\n        }\n        finally {\n            try {\n                await this.close();\n            }\n            catch {\n                // we're not concerned with errors from close()\n            }\n        }\n    }\n    /** Is the cursor closed */\n    get closed() {\n        return this[kClosed] || this.cursor.closed;\n    }\n    /** Close the Change Stream */\n    async close() {\n        this[kClosed] = true;\n        const cursor = this.cursor;\n        try {\n            await cursor.close();\n        }\n        finally {\n            this._endStream();\n        }\n    }\n    /**\n     * Return a modified Readable stream including a possible transform method.\n     *\n     * NOTE: When using a Stream to process change stream events, the stream will\n     * NOT automatically resume in the case a resumable error is encountered.\n     *\n     * @throws MongoChangeStreamError if the underlying cursor or the change stream is closed\n     */\n    stream(options) {\n        if (this.closed) {\n            throw new error_1.MongoChangeStreamError(CHANGESTREAM_CLOSED_ERROR);\n        }\n        this.streamOptions = options;\n        return this.cursor.stream(options);\n    }\n    /** @internal */\n    _setIsEmitter() {\n        if (this[kMode] === 'iterator') {\n            // TODO(NODE-3485): Replace with MongoChangeStreamModeError\n            throw new error_1.MongoAPIError('ChangeStream cannot be used as an EventEmitter after being used as an iterator');\n        }\n        this[kMode] = 'emitter';\n    }\n    /** @internal */\n    _setIsIterator() {\n        if (this[kMode] === 'emitter') {\n            // TODO(NODE-3485): Replace with MongoChangeStreamModeError\n            throw new error_1.MongoAPIError('ChangeStream cannot be used as an iterator after being used as an EventEmitter');\n        }\n        this[kMode] = 'iterator';\n    }\n    /**\n     * Create a new change stream cursor based on self's configuration\n     * @internal\n     */\n    _createChangeStreamCursor(options) {\n        const changeStreamStageOptions = (0, utils_1.filterOptions)(options, CHANGE_STREAM_OPTIONS);\n        if (this.type === CHANGE_DOMAIN_TYPES.CLUSTER) {\n            changeStreamStageOptions.allChangesForCluster = true;\n        }\n        const pipeline = [{ $changeStream: changeStreamStageOptions }, ...this.pipeline];\n        const client = this.type === CHANGE_DOMAIN_TYPES.CLUSTER\n            ? this.parent\n            : this.type === CHANGE_DOMAIN_TYPES.DATABASE\n                ? this.parent.client\n                : this.type === CHANGE_DOMAIN_TYPES.COLLECTION\n                    ? this.parent.client\n                    : null;\n        if (client == null) {\n            // This should never happen because of the assertion in the constructor\n            throw new error_1.MongoRuntimeError(`Changestream type should only be one of cluster, database, collection. Found ${this.type.toString()}`);\n        }\n        const changeStreamCursor = new change_stream_cursor_1.ChangeStreamCursor(client, this.namespace, pipeline, options);\n        for (const event of CHANGE_STREAM_EVENTS) {\n            changeStreamCursor.on(event, e => this.emit(event, e));\n        }\n        if (this.listenerCount(ChangeStream.CHANGE) > 0) {\n            this._streamEvents(changeStreamCursor);\n        }\n        return changeStreamCursor;\n    }\n    /** @internal */\n    _closeEmitterModeWithError(error) {\n        this.emit(ChangeStream.ERROR, error);\n        this.close().catch(() => null);\n    }\n    /** @internal */\n    _streamEvents(cursor) {\n        this._setIsEmitter();\n        const stream = this[kCursorStream] ?? cursor.stream();\n        this[kCursorStream] = stream;\n        stream.on('data', change => {\n            try {\n                const processedChange = this._processChange(change);\n                this.emit(ChangeStream.CHANGE, processedChange);\n            }\n            catch (error) {\n                this.emit(ChangeStream.ERROR, error);\n            }\n        });\n        stream.on('error', error => this._processErrorStreamMode(error));\n    }\n    /** @internal */\n    _endStream() {\n        const cursorStream = this[kCursorStream];\n        if (cursorStream) {\n            ['data', 'close', 'end', 'error'].forEach(event => cursorStream.removeAllListeners(event));\n            cursorStream.destroy();\n        }\n        this[kCursorStream] = undefined;\n    }\n    /** @internal */\n    _processChange(change) {\n        if (this[kClosed]) {\n            // TODO(NODE-3485): Replace with MongoChangeStreamClosedError\n            throw new error_1.MongoAPIError(CHANGESTREAM_CLOSED_ERROR);\n        }\n        // a null change means the cursor has been notified, implicitly closing the change stream\n        if (change == null) {\n            // TODO(NODE-3485): Replace with MongoChangeStreamClosedError\n            throw new error_1.MongoRuntimeError(CHANGESTREAM_CLOSED_ERROR);\n        }\n        if (change && !change._id) {\n            throw new error_1.MongoChangeStreamError(NO_RESUME_TOKEN_ERROR);\n        }\n        // cache the resume token\n        this.cursor.cacheResumeToken(change._id);\n        // wipe the startAtOperationTime if there was one so that there won't be a conflict\n        // between resumeToken and startAtOperationTime if we need to reconnect the cursor\n        this.options.startAtOperationTime = undefined;\n        return change;\n    }\n    /** @internal */\n    _processErrorStreamMode(changeStreamError) {\n        // If the change stream has been closed explicitly, do not process error.\n        if (this[kClosed])\n            return;\n        if ((0, error_1.isResumableError)(changeStreamError, this.cursor.maxWireVersion)) {\n            this._endStream();\n            this.cursor.close().catch(() => null);\n            const topology = (0, utils_1.getTopology)(this.parent);\n            topology.selectServer(this.cursor.readPreference, {}, serverSelectionError => {\n                if (serverSelectionError)\n                    return this._closeEmitterModeWithError(changeStreamError);\n                this.cursor = this._createChangeStreamCursor(this.cursor.resumeOptions);\n            });\n        }\n        else {\n            this._closeEmitterModeWithError(changeStreamError);\n        }\n    }\n    /** @internal */\n    async _processErrorIteratorMode(changeStreamError) {\n        if (this[kClosed]) {\n            // TODO(NODE-3485): Replace with MongoChangeStreamClosedError\n            throw new error_1.MongoAPIError(CHANGESTREAM_CLOSED_ERROR);\n        }\n        if (!(0, error_1.isResumableError)(changeStreamError, this.cursor.maxWireVersion)) {\n            try {\n                await this.close();\n            }\n            catch {\n                // ignore errors from close\n            }\n            throw changeStreamError;\n        }\n        await this.cursor.close().catch(() => null);\n        const topology = (0, utils_1.getTopology)(this.parent);\n        try {\n            await topology.selectServerAsync(this.cursor.readPreference, {});\n            this.cursor = this._createChangeStreamCursor(this.cursor.resumeOptions);\n        }\n        catch {\n            // if the topology can't reconnect, close the stream\n            await this.close();\n            throw changeStreamError;\n        }\n    }\n}\n/** @event */\nChangeStream.RESPONSE = constants_1.RESPONSE;\n/** @event */\nChangeStream.MORE = constants_1.MORE;\n/** @event */\nChangeStream.INIT = constants_1.INIT;\n/** @event */\nChangeStream.CLOSE = constants_1.CLOSE;\n/**\n * Fired for each new matching change in the specified namespace. Attaching a `change`\n * event listener to a Change Stream will switch the stream into flowing mode. Data will\n * then be passed as soon as it is available.\n * @event\n */\nChangeStream.CHANGE = constants_1.CHANGE;\n/** @event */\nChangeStream.END = constants_1.END;\n/** @event */\nChangeStream.ERROR = constants_1.ERROR;\n/**\n * Emitted each time the change stream stores a new resume token.\n * @event\n */\nChangeStream.RESUME_TOKEN_CHANGED = constants_1.RESUME_TOKEN_CHANGED;\nexports.ChangeStream = ChangeStream;\n//# sourceMappingURL=change_stream.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/change_stream.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/auto_encrypter.js":
/*!***************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/auto_encrypter.js ***!
  \***************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nvar _a;\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AutoEncrypter = exports.AutoEncryptionLoggerLevel = void 0;\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst deps_1 = __webpack_require__(/*! ../deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_client_1 = __webpack_require__(/*! ../mongo_client */ \"./node_modules/mongodb/lib/mongo_client.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst cryptoCallbacks = __webpack_require__(/*! ./crypto_callbacks */ \"./node_modules/mongodb/lib/client-side-encryption/crypto_callbacks.js\");\nconst errors_1 = __webpack_require__(/*! ./errors */ \"./node_modules/mongodb/lib/client-side-encryption/errors.js\");\nconst mongocryptd_manager_1 = __webpack_require__(/*! ./mongocryptd_manager */ \"./node_modules/mongodb/lib/client-side-encryption/mongocryptd_manager.js\");\nconst providers_1 = __webpack_require__(/*! ./providers */ \"./node_modules/mongodb/lib/client-side-encryption/providers/index.js\");\nconst state_machine_1 = __webpack_require__(/*! ./state_machine */ \"./node_modules/mongodb/lib/client-side-encryption/state_machine.js\");\n/** @public */\nexports.AutoEncryptionLoggerLevel = Object.freeze({\n    FatalError: 0,\n    Error: 1,\n    Warning: 2,\n    Info: 3,\n    Trace: 4\n});\n// Typescript errors if we index objects with `Symbol.for(...)`, so\n// to avoid TS errors we pull them out into variables.  Then we can type\n// the objects (and class) that we expect to see them on and prevent TS\n// errors.\n/** @internal */\nconst kDecorateResult = Symbol.for('@@mdb.decorateDecryptionResult');\n/** @internal */\nconst kDecoratedKeys = Symbol.for('@@mdb.decryptedKeys');\n/**\n * @internal An internal class to be used by the driver for auto encryption\n * **NOTE**: Not meant to be instantiated directly, this is for internal use only.\n */\nclass AutoEncrypter {\n    /** @internal */\n    static getMongoCrypt() {\n        const encryption = (0, deps_1.getMongoDBClientEncryption)();\n        if ('kModuleError' in encryption) {\n            throw encryption.kModuleError;\n        }\n        return encryption.MongoCrypt;\n    }\n    /**\n     * Create an AutoEncrypter\n     *\n     * **Note**: Do not instantiate this class directly. Rather, supply the relevant options to a MongoClient\n     *\n     * **Note**: Supplying `options.schemaMap` provides more security than relying on JSON Schemas obtained from the server.\n     * It protects against a malicious server advertising a false JSON Schema, which could trick the client into sending unencrypted data that should be encrypted.\n     * Schemas supplied in the schemaMap only apply to configuring automatic encryption for Client-Side Field Level Encryption.\n     * Other validation rules in the JSON schema will not be enforced by the driver and will result in an error.\n     *\n     * @example <caption>Create an AutoEncrypter that makes use of mongocryptd</caption>\n     * ```ts\n     * // Enabling autoEncryption via a MongoClient using mongocryptd\n     * const { MongoClient } = require('mongodb');\n     * const client = new MongoClient(URL, {\n     *   autoEncryption: {\n     *     kmsProviders: {\n     *       aws: {\n     *         accessKeyId: AWS_ACCESS_KEY,\n     *         secretAccessKey: AWS_SECRET_KEY\n     *       }\n     *     }\n     *   }\n     * });\n     * ```\n     *\n     * await client.connect();\n     * // From here on, the client will be encrypting / decrypting automatically\n     * @example <caption>Create an AutoEncrypter that makes use of libmongocrypt's CSFLE shared library</caption>\n     * ```ts\n     * // Enabling autoEncryption via a MongoClient using CSFLE shared library\n     * const { MongoClient } = require('mongodb');\n     * const client = new MongoClient(URL, {\n     *   autoEncryption: {\n     *     kmsProviders: {\n     *       aws: {}\n     *     },\n     *     extraOptions: {\n     *       cryptSharedLibPath: '/path/to/local/crypt/shared/lib',\n     *       cryptSharedLibRequired: true\n     *     }\n     *   }\n     * });\n     * ```\n     *\n     * await client.connect();\n     * // From here on, the client will be encrypting / decrypting automatically\n     */\n    constructor(client, options) {\n        /**\n         * Used by devtools to enable decorating decryption results.\n         *\n         * When set and enabled, `decrypt` will automatically recursively\n         * traverse a decrypted document and if a field has been decrypted,\n         * it will mark it as decrypted.  Compass uses this to determine which\n         * fields were decrypted.\n         */\n        this[_a] = false;\n        this._client = client;\n        this._bypassEncryption = options.bypassAutoEncryption === true;\n        this._keyVaultNamespace = options.keyVaultNamespace || 'admin.datakeys';\n        this._keyVaultClient = options.keyVaultClient || client;\n        this._metaDataClient = options.metadataClient || client;\n        this._proxyOptions = options.proxyOptions || {};\n        this._tlsOptions = options.tlsOptions || {};\n        this._kmsProviders = options.kmsProviders || {};\n        const mongoCryptOptions = {\n            cryptoCallbacks\n        };\n        if (options.schemaMap) {\n            mongoCryptOptions.schemaMap = Buffer.isBuffer(options.schemaMap)\n                ? options.schemaMap\n                : (0, bson_1.serialize)(options.schemaMap);\n        }\n        if (options.encryptedFieldsMap) {\n            mongoCryptOptions.encryptedFieldsMap = Buffer.isBuffer(options.encryptedFieldsMap)\n                ? options.encryptedFieldsMap\n                : (0, bson_1.serialize)(options.encryptedFieldsMap);\n        }\n        mongoCryptOptions.kmsProviders = !Buffer.isBuffer(this._kmsProviders)\n            ? (0, bson_1.serialize)(this._kmsProviders)\n            : this._kmsProviders;\n        if (options.options?.logger) {\n            mongoCryptOptions.logger = options.options.logger;\n        }\n        if (options.extraOptions && options.extraOptions.cryptSharedLibPath) {\n            mongoCryptOptions.cryptSharedLibPath = options.extraOptions.cryptSharedLibPath;\n        }\n        if (options.bypassQueryAnalysis) {\n            mongoCryptOptions.bypassQueryAnalysis = options.bypassQueryAnalysis;\n        }\n        this._bypassMongocryptdAndCryptShared = this._bypassEncryption || !!options.bypassQueryAnalysis;\n        if (options.extraOptions && options.extraOptions.cryptSharedLibSearchPaths) {\n            // Only for driver testing\n            mongoCryptOptions.cryptSharedLibSearchPaths = options.extraOptions.cryptSharedLibSearchPaths;\n        }\n        else if (!this._bypassMongocryptdAndCryptShared) {\n            mongoCryptOptions.cryptSharedLibSearchPaths = ['$SYSTEM'];\n        }\n        const MongoCrypt = AutoEncrypter.getMongoCrypt();\n        this._mongocrypt = new MongoCrypt(mongoCryptOptions);\n        this._contextCounter = 0;\n        if (options.extraOptions &&\n            options.extraOptions.cryptSharedLibRequired &&\n            !this.cryptSharedLibVersionInfo) {\n            throw new errors_1.MongoCryptInvalidArgumentError('`cryptSharedLibRequired` set but no crypt_shared library loaded');\n        }\n        // Only instantiate mongocryptd manager/client once we know for sure\n        // that we are not using the CSFLE shared library.\n        if (!this._bypassMongocryptdAndCryptShared && !this.cryptSharedLibVersionInfo) {\n            this._mongocryptdManager = new mongocryptd_manager_1.MongocryptdManager(options.extraOptions);\n            const clientOptions = {\n                serverSelectionTimeoutMS: 10000\n            };\n            if (options.extraOptions == null || typeof options.extraOptions.mongocryptdURI !== 'string') {\n                clientOptions.family = 4;\n            }\n            this._mongocryptdClient = new mongo_client_1.MongoClient(this._mongocryptdManager.uri, clientOptions);\n        }\n    }\n    /**\n     * Initializes the auto encrypter by spawning a mongocryptd and connecting to it.\n     *\n     * This function is a no-op when bypassSpawn is set or the crypt shared library is used.\n     */\n    async init() {\n        if (this._bypassMongocryptdAndCryptShared || this.cryptSharedLibVersionInfo) {\n            return;\n        }\n        if (!this._mongocryptdManager) {\n            throw new error_1.MongoRuntimeError('Reached impossible state: mongocryptdManager is undefined when neither bypassSpawn nor the shared lib are specified.');\n        }\n        if (!this._mongocryptdClient) {\n            throw new error_1.MongoRuntimeError('Reached impossible state: mongocryptdClient is undefined when neither bypassSpawn nor the shared lib are specified.');\n        }\n        if (!this._mongocryptdManager.bypassSpawn) {\n            await this._mongocryptdManager.spawn();\n        }\n        try {\n            const client = await this._mongocryptdClient.connect();\n            return client;\n        }\n        catch (error) {\n            const { message } = error;\n            if (message && (message.match(/timed out after/) || message.match(/ENOTFOUND/))) {\n                throw new error_1.MongoRuntimeError('Unable to connect to `mongocryptd`, please make sure it is running or in your PATH for auto-spawn', { cause: error });\n            }\n            throw error;\n        }\n    }\n    /**\n     * Cleans up the `_mongocryptdClient`, if present.\n     */\n    async teardown(force) {\n        await this._mongocryptdClient?.close(force);\n    }\n    /**\n     * Encrypt a command for a given namespace.\n     */\n    async encrypt(ns, cmd, options = {}) {\n        if (this._bypassEncryption) {\n            // If `bypassAutoEncryption` has been specified, don't encrypt\n            return cmd;\n        }\n        const commandBuffer = Buffer.isBuffer(cmd) ? cmd : (0, bson_1.serialize)(cmd, options);\n        const context = this._mongocrypt.makeEncryptionContext(utils_1.MongoDBCollectionNamespace.fromString(ns).db, commandBuffer);\n        context.id = this._contextCounter++;\n        context.ns = ns;\n        context.document = cmd;\n        const stateMachine = new state_machine_1.StateMachine({\n            promoteValues: false,\n            promoteLongs: false,\n            proxyOptions: this._proxyOptions,\n            tlsOptions: this._tlsOptions\n        });\n        return stateMachine.execute(this, context);\n    }\n    /**\n     * Decrypt a command response\n     */\n    async decrypt(response, options = {}) {\n        const buffer = Buffer.isBuffer(response) ? response : (0, bson_1.serialize)(response, options);\n        const context = this._mongocrypt.makeDecryptionContext(buffer);\n        context.id = this._contextCounter++;\n        const stateMachine = new state_machine_1.StateMachine({\n            ...options,\n            proxyOptions: this._proxyOptions,\n            tlsOptions: this._tlsOptions\n        });\n        const decorateResult = this[kDecorateResult];\n        const result = await stateMachine.execute(this, context);\n        if (decorateResult) {\n            decorateDecryptionResult(result, response);\n        }\n        return result;\n    }\n    /**\n     * Ask the user for KMS credentials.\n     *\n     * This returns anything that looks like the kmsProviders original input\n     * option. It can be empty, and any provider specified here will override\n     * the original ones.\n     */\n    async askForKMSCredentials() {\n        return (0, providers_1.refreshKMSCredentials)(this._kmsProviders);\n    }\n    /**\n     * Return the current libmongocrypt's CSFLE shared library version\n     * as `{ version: bigint, versionStr: string }`, or `null` if no CSFLE\n     * shared library was loaded.\n     */\n    get cryptSharedLibVersionInfo() {\n        return this._mongocrypt.cryptSharedLibVersionInfo;\n    }\n    static get libmongocryptVersion() {\n        return AutoEncrypter.getMongoCrypt().libmongocryptVersion;\n    }\n}\nexports.AutoEncrypter = AutoEncrypter;\n_a = kDecorateResult;\n/**\n * Recurse through the (identically-shaped) `decrypted` and `original`\n * objects and attach a `decryptedKeys` property on each sub-object that\n * contained encrypted fields. Because we only call this on BSON responses,\n * we do not need to worry about circular references.\n *\n * @internal\n */\nfunction decorateDecryptionResult(decrypted, original, isTopLevelDecorateCall = true) {\n    if (isTopLevelDecorateCall) {\n        // The original value could have been either a JS object or a BSON buffer\n        if (Buffer.isBuffer(original)) {\n            original = (0, bson_1.deserialize)(original);\n        }\n        if (Buffer.isBuffer(decrypted)) {\n            throw new error_1.MongoRuntimeError('Expected result of decryption to be deserialized BSON object');\n        }\n    }\n    if (!decrypted || typeof decrypted !== 'object')\n        return;\n    for (const k of Object.keys(decrypted)) {\n        const originalValue = original[k];\n        // An object was decrypted by libmongocrypt if and only if it was\n        // a BSON Binary object with subtype 6.\n        if (originalValue && originalValue._bsontype === 'Binary' && originalValue.sub_type === 6) {\n            if (!decrypted[kDecoratedKeys]) {\n                Object.defineProperty(decrypted, kDecoratedKeys, {\n                    value: [],\n                    configurable: true,\n                    enumerable: false,\n                    writable: false\n                });\n            }\n            // this is defined in the preceding if-statement\n            // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n            decrypted[kDecoratedKeys].push(k);\n            // Do not recurse into this decrypted value. It could be a sub-document/array,\n            // in which case there is no original value associated with its subfields.\n            continue;\n        }\n        decorateDecryptionResult(decrypted[k], originalValue, false);\n    }\n}\n//# sourceMappingURL=auto_encrypter.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/client-side-encryption/auto_encrypter.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/client_encryption.js":
/*!******************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/client_encryption.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ClientEncryption = void 0;\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst deps_1 = __webpack_require__(/*! ../deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst cryptoCallbacks = __webpack_require__(/*! ./crypto_callbacks */ \"./node_modules/mongodb/lib/client-side-encryption/crypto_callbacks.js\");\nconst errors_1 = __webpack_require__(/*! ./errors */ \"./node_modules/mongodb/lib/client-side-encryption/errors.js\");\nconst index_1 = __webpack_require__(/*! ./providers/index */ \"./node_modules/mongodb/lib/client-side-encryption/providers/index.js\");\nconst state_machine_1 = __webpack_require__(/*! ./state_machine */ \"./node_modules/mongodb/lib/client-side-encryption/state_machine.js\");\n/**\n * @public\n * The public interface for explicit in-use encryption\n */\nclass ClientEncryption {\n    /** @internal */\n    static getMongoCrypt() {\n        const encryption = (0, deps_1.getMongoDBClientEncryption)();\n        if ('kModuleError' in encryption) {\n            throw encryption.kModuleError;\n        }\n        return encryption.MongoCrypt;\n    }\n    /**\n     * Create a new encryption instance\n     *\n     * @example\n     * ```ts\n     * new ClientEncryption(mongoClient, {\n     *   keyVaultNamespace: 'client.encryption',\n     *   kmsProviders: {\n     *     local: {\n     *       key: masterKey // The master key used for encryption/decryption. A 96-byte long Buffer\n     *     }\n     *   }\n     * });\n     * ```\n     *\n     * @example\n     * ```ts\n     * new ClientEncryption(mongoClient, {\n     *   keyVaultNamespace: 'client.encryption',\n     *   kmsProviders: {\n     *     aws: {\n     *       accessKeyId: AWS_ACCESS_KEY,\n     *       secretAccessKey: AWS_SECRET_KEY\n     *     }\n     *   }\n     * });\n     * ```\n     */\n    constructor(client, options) {\n        this._client = client;\n        this._proxyOptions = options.proxyOptions ?? {};\n        this._tlsOptions = options.tlsOptions ?? {};\n        this._kmsProviders = options.kmsProviders || {};\n        if (options.keyVaultNamespace == null) {\n            throw new errors_1.MongoCryptInvalidArgumentError('Missing required option `keyVaultNamespace`');\n        }\n        const mongoCryptOptions = {\n            ...options,\n            cryptoCallbacks,\n            kmsProviders: !Buffer.isBuffer(this._kmsProviders)\n                ? (0, bson_1.serialize)(this._kmsProviders)\n                : this._kmsProviders\n        };\n        this._keyVaultNamespace = options.keyVaultNamespace;\n        this._keyVaultClient = options.keyVaultClient || client;\n        const MongoCrypt = ClientEncryption.getMongoCrypt();\n        this._mongoCrypt = new MongoCrypt(mongoCryptOptions);\n    }\n    /**\n     * Creates a data key used for explicit encryption and inserts it into the key vault namespace\n     *\n     * @example\n     * ```ts\n     * // Using async/await to create a local key\n     * const dataKeyId = await clientEncryption.createDataKey('local');\n     * ```\n     *\n     * @example\n     * ```ts\n     * // Using async/await to create an aws key\n     * const dataKeyId = await clientEncryption.createDataKey('aws', {\n     *   masterKey: {\n     *     region: 'us-east-1',\n     *     key: 'xxxxxxxxxxxxxx' // CMK ARN here\n     *   }\n     * });\n     * ```\n     *\n     * @example\n     * ```ts\n     * // Using async/await to create an aws key with a keyAltName\n     * const dataKeyId = await clientEncryption.createDataKey('aws', {\n     *   masterKey: {\n     *     region: 'us-east-1',\n     *     key: 'xxxxxxxxxxxxxx' // CMK ARN here\n     *   },\n     *   keyAltNames: [ 'mySpecialKey' ]\n     * });\n     * ```\n     */\n    async createDataKey(provider, options = {}) {\n        if (options.keyAltNames && !Array.isArray(options.keyAltNames)) {\n            throw new errors_1.MongoCryptInvalidArgumentError(`Option \"keyAltNames\" must be an array of strings, but was of type ${typeof options.keyAltNames}.`);\n        }\n        let keyAltNames = undefined;\n        if (options.keyAltNames && options.keyAltNames.length > 0) {\n            keyAltNames = options.keyAltNames.map((keyAltName, i) => {\n                if (typeof keyAltName !== 'string') {\n                    throw new errors_1.MongoCryptInvalidArgumentError(`Option \"keyAltNames\" must be an array of strings, but item at index ${i} was of type ${typeof keyAltName}`);\n                }\n                return (0, bson_1.serialize)({ keyAltName });\n            });\n        }\n        let keyMaterial = undefined;\n        if (options.keyMaterial) {\n            keyMaterial = (0, bson_1.serialize)({ keyMaterial: options.keyMaterial });\n        }\n        const dataKeyBson = (0, bson_1.serialize)({\n            provider,\n            ...options.masterKey\n        });\n        const context = this._mongoCrypt.makeDataKeyContext(dataKeyBson, {\n            keyAltNames,\n            keyMaterial\n        });\n        const stateMachine = new state_machine_1.StateMachine({\n            proxyOptions: this._proxyOptions,\n            tlsOptions: this._tlsOptions\n        });\n        const dataKey = await stateMachine.execute(this, context);\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);\n        const { insertedId } = await this._keyVaultClient\n            .db(dbName)\n            .collection(collectionName)\n            .insertOne(dataKey, { writeConcern: { w: 'majority' } });\n        return insertedId;\n    }\n    /**\n     * Searches the keyvault for any data keys matching the provided filter.  If there are matches, rewrapManyDataKey then attempts to re-wrap the data keys using the provided options.\n     *\n     * If no matches are found, then no bulk write is performed.\n     *\n     * @example\n     * ```ts\n     * // rewrapping all data data keys (using a filter that matches all documents)\n     * const filter = {};\n     *\n     * const result = await clientEncryption.rewrapManyDataKey(filter);\n     * if (result.bulkWriteResult != null) {\n     *  // keys were re-wrapped, results will be available in the bulkWrite object.\n     * }\n     * ```\n     *\n     * @example\n     * ```ts\n     * // attempting to rewrap all data keys with no matches\n     * const filter = { _id: new Binary() } // assume _id matches no documents in the database\n     * const result = await clientEncryption.rewrapManyDataKey(filter);\n     *\n     * if (result.bulkWriteResult == null) {\n     *  // no keys matched, `bulkWriteResult` does not exist on the result object\n     * }\n     * ```\n     */\n    async rewrapManyDataKey(filter, options) {\n        let keyEncryptionKeyBson = undefined;\n        if (options) {\n            const keyEncryptionKey = Object.assign({ provider: options.provider }, options.masterKey);\n            keyEncryptionKeyBson = (0, bson_1.serialize)(keyEncryptionKey);\n        }\n        const filterBson = (0, bson_1.serialize)(filter);\n        const context = this._mongoCrypt.makeRewrapManyDataKeyContext(filterBson, keyEncryptionKeyBson);\n        const stateMachine = new state_machine_1.StateMachine({\n            proxyOptions: this._proxyOptions,\n            tlsOptions: this._tlsOptions\n        });\n        const { v: dataKeys } = await stateMachine.execute(this, context);\n        if (dataKeys.length === 0) {\n            return {};\n        }\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);\n        const replacements = dataKeys.map((key) => ({\n            updateOne: {\n                filter: { _id: key._id },\n                update: {\n                    $set: {\n                        masterKey: key.masterKey,\n                        keyMaterial: key.keyMaterial\n                    },\n                    $currentDate: {\n                        updateDate: true\n                    }\n                }\n            }\n        }));\n        const result = await this._keyVaultClient\n            .db(dbName)\n            .collection(collectionName)\n            .bulkWrite(replacements, {\n            writeConcern: { w: 'majority' }\n        });\n        return { bulkWriteResult: result };\n    }\n    /**\n     * Deletes the key with the provided id from the keyvault, if it exists.\n     *\n     * @example\n     * ```ts\n     * // delete a key by _id\n     * const id = new Binary(); // id is a bson binary subtype 4 object\n     * const { deletedCount } = await clientEncryption.deleteKey(id);\n     *\n     * if (deletedCount != null && deletedCount > 0) {\n     *   // successful deletion\n     * }\n     * ```\n     *\n     */\n    async deleteKey(_id) {\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);\n        return this._keyVaultClient\n            .db(dbName)\n            .collection(collectionName)\n            .deleteOne({ _id }, { writeConcern: { w: 'majority' } });\n    }\n    /**\n     * Finds all the keys currently stored in the keyvault.\n     *\n     * This method will not throw.\n     *\n     * @returns a FindCursor over all keys in the keyvault.\n     * @example\n     * ```ts\n     * // fetching all keys\n     * const keys = await clientEncryption.getKeys().toArray();\n     * ```\n     */\n    getKeys() {\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);\n        return this._keyVaultClient\n            .db(dbName)\n            .collection(collectionName)\n            .find({}, { readConcern: { level: 'majority' } });\n    }\n    /**\n     * Finds a key in the keyvault with the specified _id.\n     *\n     * Returns a promise that either resolves to a {@link DataKey} if a document matches the key or null if no documents\n     * match the id.  The promise rejects with an error if an error is thrown.\n     * @example\n     * ```ts\n     * // getting a key by id\n     * const id = new Binary(); // id is a bson binary subtype 4 object\n     * const key = await clientEncryption.getKey(id);\n     * if (!key) {\n     *  // key is null if there was no matching key\n     * }\n     * ```\n     */\n    async getKey(_id) {\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);\n        return this._keyVaultClient\n            .db(dbName)\n            .collection(collectionName)\n            .findOne({ _id }, { readConcern: { level: 'majority' } });\n    }\n    /**\n     * Finds a key in the keyvault which has the specified keyAltName.\n     *\n     * @param keyAltName - a keyAltName to search for a key\n     * @returns Returns a promise that either resolves to a {@link DataKey} if a document matches the key or null if no documents\n     * match the keyAltName.  The promise rejects with an error if an error is thrown.\n     * @example\n     * ```ts\n     * // get a key by alt name\n     * const keyAltName = 'keyAltName';\n     * const key = await clientEncryption.getKeyByAltName(keyAltName);\n     * if (!key) {\n     *  // key is null if there is no matching key\n     * }\n     * ```\n     */\n    async getKeyByAltName(keyAltName) {\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);\n        return this._keyVaultClient\n            .db(dbName)\n            .collection(collectionName)\n            .findOne({ keyAltNames: keyAltName }, { readConcern: { level: 'majority' } });\n    }\n    /**\n     * Adds a keyAltName to a key identified by the provided _id.\n     *\n     * This method resolves to/returns the *old* key value (prior to adding the new altKeyName).\n     *\n     * @param _id - The id of the document to update.\n     * @param keyAltName - a keyAltName to search for a key\n     * @returns Returns a promise that either resolves to a {@link DataKey} if a document matches the key or null if no documents\n     * match the id.  The promise rejects with an error if an error is thrown.\n     * @example\n     * ```ts\n     * // adding an keyAltName to a data key\n     * const id = new Binary();  // id is a bson binary subtype 4 object\n     * const keyAltName = 'keyAltName';\n     * const oldKey = await clientEncryption.addKeyAltName(id, keyAltName);\n     * if (!oldKey) {\n     *  // null is returned if there is no matching document with an id matching the supplied id\n     * }\n     * ```\n     */\n    async addKeyAltName(_id, keyAltName) {\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);\n        const value = await this._keyVaultClient\n            .db(dbName)\n            .collection(collectionName)\n            .findOneAndUpdate({ _id }, { $addToSet: { keyAltNames: keyAltName } }, { writeConcern: { w: 'majority' }, returnDocument: 'before' });\n        return value;\n    }\n    /**\n     * Adds a keyAltName to a key identified by the provided _id.\n     *\n     * This method resolves to/returns the *old* key value (prior to removing the new altKeyName).\n     *\n     * If the removed keyAltName is the last keyAltName for that key, the `altKeyNames` property is unset from the document.\n     *\n     * @param _id - The id of the document to update.\n     * @param keyAltName - a keyAltName to search for a key\n     * @returns Returns a promise that either resolves to a {@link DataKey} if a document matches the key or null if no documents\n     * match the id.  The promise rejects with an error if an error is thrown.\n     * @example\n     * ```ts\n     * // removing a key alt name from a data key\n     * const id = new Binary();  // id is a bson binary subtype 4 object\n     * const keyAltName = 'keyAltName';\n     * const oldKey = await clientEncryption.removeKeyAltName(id, keyAltName);\n     *\n     * if (!oldKey) {\n     *  // null is returned if there is no matching document with an id matching the supplied id\n     * }\n     * ```\n     */\n    async removeKeyAltName(_id, keyAltName) {\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);\n        const pipeline = [\n            {\n                $set: {\n                    keyAltNames: {\n                        $cond: [\n                            {\n                                $eq: ['$keyAltNames', [keyAltName]]\n                            },\n                            '$$REMOVE',\n                            {\n                                $filter: {\n                                    input: '$keyAltNames',\n                                    cond: {\n                                        $ne: ['$$this', keyAltName]\n                                    }\n                                }\n                            }\n                        ]\n                    }\n                }\n            }\n        ];\n        const value = await this._keyVaultClient\n            .db(dbName)\n            .collection(collectionName)\n            .findOneAndUpdate({ _id }, pipeline, {\n            writeConcern: { w: 'majority' },\n            returnDocument: 'before'\n        });\n        return value;\n    }\n    /**\n     * A convenience method for creating an encrypted collection.\n     * This method will create data keys for any encryptedFields that do not have a `keyId` defined\n     * and then create a new collection with the full set of encryptedFields.\n     *\n     * @param db - A Node.js driver Db object with which to create the collection\n     * @param name - The name of the collection to be created\n     * @param options - Options for createDataKey and for createCollection\n     * @returns created collection and generated encryptedFields\n     * @throws MongoCryptCreateDataKeyError - If part way through the process a createDataKey invocation fails, an error will be rejected that has the partial `encryptedFields` that were created.\n     * @throws MongoCryptCreateEncryptedCollectionError - If creating the collection fails, an error will be rejected that has the entire `encryptedFields` that were created.\n     */\n    async createEncryptedCollection(db, name, options) {\n        const { provider, masterKey, createCollectionOptions: { encryptedFields: { ...encryptedFields }, ...createCollectionOptions } } = options;\n        if (Array.isArray(encryptedFields.fields)) {\n            const createDataKeyPromises = encryptedFields.fields.map(async (field) => field == null || typeof field !== 'object' || field.keyId != null\n                ? field\n                : {\n                    ...field,\n                    keyId: await this.createDataKey(provider, { masterKey })\n                });\n            const createDataKeyResolutions = await Promise.allSettled(createDataKeyPromises);\n            encryptedFields.fields = createDataKeyResolutions.map((resolution, index) => resolution.status === 'fulfilled' ? resolution.value : encryptedFields.fields[index]);\n            const rejection = createDataKeyResolutions.find((result) => result.status === 'rejected');\n            if (rejection != null) {\n                throw new errors_1.MongoCryptCreateDataKeyError(encryptedFields, { cause: rejection.reason });\n            }\n        }\n        try {\n            const collection = await db.createCollection(name, {\n                ...createCollectionOptions,\n                encryptedFields\n            });\n            return { collection, encryptedFields };\n        }\n        catch (cause) {\n            throw new errors_1.MongoCryptCreateEncryptedCollectionError(encryptedFields, { cause });\n        }\n    }\n    /**\n     * Explicitly encrypt a provided value. Note that either `options.keyId` or `options.keyAltName` must\n     * be specified. Specifying both `options.keyId` and `options.keyAltName` is considered an error.\n     *\n     * @param value - The value that you wish to serialize. Must be of a type that can be serialized into BSON\n     * @param options -\n     * @returns a Promise that either resolves with the encrypted value, or rejects with an error.\n     *\n     * @example\n     * ```ts\n     * // Encryption with async/await api\n     * async function encryptMyData(value) {\n     *   const keyId = await clientEncryption.createDataKey('local');\n     *   return clientEncryption.encrypt(value, { keyId, algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic' });\n     * }\n     * ```\n     *\n     * @example\n     * ```ts\n     * // Encryption using a keyAltName\n     * async function encryptMyData(value) {\n     *   await clientEncryption.createDataKey('local', { keyAltNames: 'mySpecialKey' });\n     *   return clientEncryption.encrypt(value, { keyAltName: 'mySpecialKey', algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic' });\n     * }\n     * ```\n     */\n    async encrypt(value, options) {\n        return this._encrypt(value, false, options);\n    }\n    /**\n     * Encrypts a Match Expression or Aggregate Expression to query a range index.\n     *\n     * Only supported when queryType is \"rangePreview\" and algorithm is \"RangePreview\".\n     *\n     * @experimental The Range algorithm is experimental only. It is not intended for production use. It is subject to breaking changes.\n     *\n     * @param expression - a BSON document of one of the following forms:\n     *  1. A Match Expression of this form:\n     *      `{$and: [{<field>: {$gt: <value1>}}, {<field>: {$lt: <value2> }}]}`\n     *  2. An Aggregate Expression of this form:\n     *      `{$and: [{$gt: [<fieldpath>, <value1>]}, {$lt: [<fieldpath>, <value2>]}]}`\n     *\n     *    `$gt` may also be `$gte`. `$lt` may also be `$lte`.\n     *\n     * @param options -\n     * @returns Returns a Promise that either resolves with the encrypted value or rejects with an error.\n     */\n    async encryptExpression(expression, options) {\n        return this._encrypt(expression, true, options);\n    }\n    /**\n     * Explicitly decrypt a provided encrypted value\n     *\n     * @param value - An encrypted value\n     * @returns a Promise that either resolves with the decrypted value, or rejects with an error\n     *\n     * @example\n     * ```ts\n     * // Decrypting value with async/await API\n     * async function decryptMyValue(value) {\n     *   return clientEncryption.decrypt(value);\n     * }\n     * ```\n     */\n    async decrypt(value) {\n        const valueBuffer = (0, bson_1.serialize)({ v: value });\n        const context = this._mongoCrypt.makeExplicitDecryptionContext(valueBuffer);\n        const stateMachine = new state_machine_1.StateMachine({\n            proxyOptions: this._proxyOptions,\n            tlsOptions: this._tlsOptions\n        });\n        const { v } = await stateMachine.execute(this, context);\n        return v;\n    }\n    /**\n     * @internal\n     * Ask the user for KMS credentials.\n     *\n     * This returns anything that looks like the kmsProviders original input\n     * option. It can be empty, and any provider specified here will override\n     * the original ones.\n     */\n    async askForKMSCredentials() {\n        return (0, index_1.refreshKMSCredentials)(this._kmsProviders);\n    }\n    static get libmongocryptVersion() {\n        return ClientEncryption.getMongoCrypt().libmongocryptVersion;\n    }\n    /**\n     * @internal\n     * A helper that perform explicit encryption of values and expressions.\n     * Explicitly encrypt a provided value. Note that either `options.keyId` or `options.keyAltName` must\n     * be specified. Specifying both `options.keyId` and `options.keyAltName` is considered an error.\n     *\n     * @param value - The value that you wish to encrypt. Must be of a type that can be serialized into BSON\n     * @param expressionMode - a boolean that indicates whether or not to encrypt the value as an expression\n     * @param options - options to pass to encrypt\n     * @returns the raw result of the call to stateMachine.execute().  When expressionMode is set to true, the return\n     *          value will be a bson document.  When false, the value will be a BSON Binary.\n     *\n     */\n    async _encrypt(value, expressionMode, options) {\n        const { algorithm, keyId, keyAltName, contentionFactor, queryType, rangeOptions } = options;\n        const contextOptions = {\n            expressionMode,\n            algorithm\n        };\n        if (keyId) {\n            contextOptions.keyId = keyId.buffer;\n        }\n        if (keyAltName) {\n            if (keyId) {\n                throw new errors_1.MongoCryptInvalidArgumentError(`\"options\" cannot contain both \"keyId\" and \"keyAltName\"`);\n            }\n            if (typeof keyAltName !== 'string') {\n                throw new errors_1.MongoCryptInvalidArgumentError(`\"options.keyAltName\" must be of type string, but was of type ${typeof keyAltName}`);\n            }\n            contextOptions.keyAltName = (0, bson_1.serialize)({ keyAltName });\n        }\n        if (typeof contentionFactor === 'number' || typeof contentionFactor === 'bigint') {\n            contextOptions.contentionFactor = contentionFactor;\n        }\n        if (typeof queryType === 'string') {\n            contextOptions.queryType = queryType;\n        }\n        if (typeof rangeOptions === 'object') {\n            contextOptions.rangeOptions = (0, bson_1.serialize)(rangeOptions);\n        }\n        const valueBuffer = (0, bson_1.serialize)({ v: value });\n        const stateMachine = new state_machine_1.StateMachine({\n            proxyOptions: this._proxyOptions,\n            tlsOptions: this._tlsOptions\n        });\n        const context = this._mongoCrypt.makeExplicitEncryptionContext(valueBuffer, contextOptions);\n        const result = await stateMachine.execute(this, context);\n        return result.v;\n    }\n}\nexports.ClientEncryption = ClientEncryption;\n//# sourceMappingURL=client_encryption.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/client-side-encryption/client_encryption.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/crypto_callbacks.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/crypto_callbacks.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.hmacSha256Hook = exports.hmacSha512Hook = exports.aes256CtrDecryptHook = exports.aes256CtrEncryptHook = exports.aes256CbcDecryptHook = exports.aes256CbcEncryptHook = exports.signRsaSha256Hook = exports.makeHmacHook = exports.sha256Hook = exports.randomHook = exports.makeAES256Hook = void 0;\nconst crypto = __webpack_require__(/*! crypto */ \"crypto\");\nfunction makeAES256Hook(method, mode) {\n    return function (key, iv, input, output) {\n        let result;\n        try {\n            const cipher = crypto[method](mode, key, iv);\n            cipher.setAutoPadding(false);\n            result = cipher.update(input);\n            const final = cipher.final();\n            if (final.length > 0) {\n                result = Buffer.concat([result, final]);\n            }\n        }\n        catch (e) {\n            return e;\n        }\n        result.copy(output);\n        return result.length;\n    };\n}\nexports.makeAES256Hook = makeAES256Hook;\nfunction randomHook(buffer, count) {\n    try {\n        crypto.randomFillSync(buffer, 0, count);\n    }\n    catch (e) {\n        return e;\n    }\n    return count;\n}\nexports.randomHook = randomHook;\nfunction sha256Hook(input, output) {\n    let result;\n    try {\n        result = crypto.createHash('sha256').update(input).digest();\n    }\n    catch (e) {\n        return e;\n    }\n    result.copy(output);\n    return result.length;\n}\nexports.sha256Hook = sha256Hook;\nfunction makeHmacHook(algorithm) {\n    return (key, input, output) => {\n        let result;\n        try {\n            result = crypto.createHmac(algorithm, key).update(input).digest();\n        }\n        catch (e) {\n            return e;\n        }\n        result.copy(output);\n        return result.length;\n    };\n}\nexports.makeHmacHook = makeHmacHook;\nfunction signRsaSha256Hook(key, input, output) {\n    let result;\n    try {\n        const signer = crypto.createSign('sha256WithRSAEncryption');\n        const privateKey = Buffer.from(`-----BEGIN PRIVATE KEY-----\\n${key.toString('base64')}\\n-----END PRIVATE KEY-----\\n`);\n        result = signer.update(input).end().sign(privateKey);\n    }\n    catch (e) {\n        return e;\n    }\n    result.copy(output);\n    return result.length;\n}\nexports.signRsaSha256Hook = signRsaSha256Hook;\nexports.aes256CbcEncryptHook = makeAES256Hook('createCipheriv', 'aes-256-cbc');\nexports.aes256CbcDecryptHook = makeAES256Hook('createDecipheriv', 'aes-256-cbc');\nexports.aes256CtrEncryptHook = makeAES256Hook('createCipheriv', 'aes-256-ctr');\nexports.aes256CtrDecryptHook = makeAES256Hook('createDecipheriv', 'aes-256-ctr');\nexports.hmacSha512Hook = makeHmacHook('sha512');\nexports.hmacSha256Hook = makeHmacHook('sha256');\n//# sourceMappingURL=crypto_callbacks.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/client-side-encryption/crypto_callbacks.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/errors.js":
/*!*******************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/errors.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoCryptKMSRequestNetworkTimeoutError = exports.MongoCryptAzureKMSRequestError = exports.MongoCryptCreateEncryptedCollectionError = exports.MongoCryptCreateDataKeyError = exports.MongoCryptInvalidArgumentError = exports.MongoCryptError = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\n/**\n * @public\n * An error indicating that something went wrong specifically with MongoDB Client Encryption\n */\nclass MongoCryptError extends error_1.MongoError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options = {}) {\n        super(message, options);\n    }\n    get name() {\n        return 'MongoCryptError';\n    }\n}\nexports.MongoCryptError = MongoCryptError;\n/**\n * @public\n *\n * An error indicating an invalid argument was provided to an encryption API.\n */\nclass MongoCryptInvalidArgumentError extends MongoCryptError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoCryptInvalidArgumentError';\n    }\n}\nexports.MongoCryptInvalidArgumentError = MongoCryptInvalidArgumentError;\n/**\n * @public\n * An error indicating that `ClientEncryption.createEncryptedCollection()` failed to create data keys\n */\nclass MongoCryptCreateDataKeyError extends MongoCryptError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(encryptedFields, { cause }) {\n        super(`Unable to complete creating data keys: ${cause.message}`, { cause });\n        this.encryptedFields = encryptedFields;\n    }\n    get name() {\n        return 'MongoCryptCreateDataKeyError';\n    }\n}\nexports.MongoCryptCreateDataKeyError = MongoCryptCreateDataKeyError;\n/**\n * @public\n * An error indicating that `ClientEncryption.createEncryptedCollection()` failed to create a collection\n */\nclass MongoCryptCreateEncryptedCollectionError extends MongoCryptError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(encryptedFields, { cause }) {\n        super(`Unable to create collection: ${cause.message}`, { cause });\n        this.encryptedFields = encryptedFields;\n    }\n    get name() {\n        return 'MongoCryptCreateEncryptedCollectionError';\n    }\n}\nexports.MongoCryptCreateEncryptedCollectionError = MongoCryptCreateEncryptedCollectionError;\n/**\n * @public\n * An error indicating that mongodb-client-encryption failed to auto-refresh Azure KMS credentials.\n */\nclass MongoCryptAzureKMSRequestError extends MongoCryptError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, body) {\n        super(message);\n        this.body = body;\n    }\n    get name() {\n        return 'MongoCryptAzureKMSRequestError';\n    }\n}\nexports.MongoCryptAzureKMSRequestError = MongoCryptAzureKMSRequestError;\n/** @public */\nclass MongoCryptKMSRequestNetworkTimeoutError extends MongoCryptError {\n    get name() {\n        return 'MongoCryptKMSRequestNetworkTimeoutError';\n    }\n}\nexports.MongoCryptKMSRequestNetworkTimeoutError = MongoCryptKMSRequestNetworkTimeoutError;\n//# sourceMappingURL=errors.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/client-side-encryption/errors.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/mongocryptd_manager.js":
/*!********************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/mongocryptd_manager.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongocryptdManager = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\n/**\n * @internal\n * An internal class that handles spawning a mongocryptd.\n */\nclass MongocryptdManager {\n    constructor(extraOptions = {}) {\n        this.uri =\n            typeof extraOptions.mongocryptdURI === 'string' && extraOptions.mongocryptdURI.length > 0\n                ? extraOptions.mongocryptdURI\n                : MongocryptdManager.DEFAULT_MONGOCRYPTD_URI;\n        this.bypassSpawn = !!extraOptions.mongocryptdBypassSpawn;\n        this.spawnPath = extraOptions.mongocryptdSpawnPath || '';\n        this.spawnArgs = [];\n        if (Array.isArray(extraOptions.mongocryptdSpawnArgs)) {\n            this.spawnArgs = this.spawnArgs.concat(extraOptions.mongocryptdSpawnArgs);\n        }\n        if (this.spawnArgs\n            .filter(arg => typeof arg === 'string')\n            .every(arg => arg.indexOf('--idleShutdownTimeoutSecs') < 0)) {\n            this.spawnArgs.push('--idleShutdownTimeoutSecs', '60');\n        }\n    }\n    /**\n     * Will check to see if a mongocryptd is up. If it is not up, it will attempt\n     * to spawn a mongocryptd in a detached process, and then wait for it to be up.\n     */\n    async spawn() {\n        const cmdName = this.spawnPath || 'mongocryptd';\n        // eslint-disable-next-line @typescript-eslint/no-var-requires\n        const { spawn } = __webpack_require__(/*! child_process */ \"child_process\");\n        // Spawned with stdio: ignore and detached: true\n        // to ensure child can outlive parent.\n        this._child = spawn(cmdName, this.spawnArgs, {\n            stdio: 'ignore',\n            detached: true\n        });\n        this._child.on('error', () => {\n            // From the FLE spec:\n            // \"The stdout and stderr of the spawned process MUST not be exposed in the driver\n            // (e.g. redirect to /dev/null). Users can pass the argument --logpath to\n            // extraOptions.mongocryptdSpawnArgs if they need to inspect mongocryptd logs.\n            // If spawning is necessary, the driver MUST spawn mongocryptd whenever server\n            // selection on the MongoClient to mongocryptd fails. If the MongoClient fails to\n            // connect after spawning, the server selection error is propagated to the user.\"\n            // The AutoEncrypter and MongoCryptdManager should work together to spawn\n            // mongocryptd whenever necessary.  Additionally, the `mongocryptd` intentionally\n            // shuts down after 60s and gets respawned when necessary.  We rely on server\n            // selection timeouts when connecting to the `mongocryptd` to inform users that something\n            // has been configured incorrectly.  For those reasons, we suppress stderr from\n            // the `mongocryptd` process and immediately unref the process.\n        });\n        // unref child to remove handle from event loop\n        this._child.unref();\n    }\n    /**\n     * @returns the result of `fn` or rejects with an error.\n     */\n    async withRespawn(fn) {\n        try {\n            const result = await fn();\n            return result;\n        }\n        catch (err) {\n            // If we are not bypassing spawning, then we should retry once on a MongoTimeoutError (server selection error)\n            const shouldSpawn = err instanceof error_1.MongoNetworkTimeoutError && !this.bypassSpawn;\n            if (!shouldSpawn) {\n                throw err;\n            }\n        }\n        await this.spawn();\n        const result = await fn();\n        return result;\n    }\n}\nMongocryptdManager.DEFAULT_MONGOCRYPTD_URI = 'mongodb://localhost:27020';\nexports.MongocryptdManager = MongocryptdManager;\n//# sourceMappingURL=mongocryptd_manager.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/client-side-encryption/mongocryptd_manager.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/providers/aws.js":
/*!**************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/providers/aws.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.loadAWSCredentials = void 0;\nconst deps_1 = __webpack_require__(/*! ../../deps */ \"./node_modules/mongodb/lib/deps.js\");\n/**\n * @internal\n */\nasync function loadAWSCredentials(kmsProviders) {\n    const credentialProvider = (0, deps_1.getAwsCredentialProvider)();\n    if ('kModuleError' in credentialProvider) {\n        return kmsProviders;\n    }\n    const { fromNodeProviderChain } = credentialProvider;\n    const provider = fromNodeProviderChain();\n    // The state machine is the only place calling this so it will\n    // catch if there is a rejection here.\n    const aws = await provider();\n    return { ...kmsProviders, aws };\n}\nexports.loadAWSCredentials = loadAWSCredentials;\n//# sourceMappingURL=aws.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/client-side-encryption/providers/aws.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/providers/azure.js":
/*!****************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/providers/azure.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.loadAzureCredentials = exports.fetchAzureKMSToken = exports.prepareRequest = exports.tokenCache = exports.AzureCredentialCache = void 0;\nconst errors_1 = __webpack_require__(/*! ../errors */ \"./node_modules/mongodb/lib/client-side-encryption/errors.js\");\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/mongodb/lib/client-side-encryption/providers/utils.js\");\nconst MINIMUM_TOKEN_REFRESH_IN_MILLISECONDS = 6000;\n/**\n * @internal\n */\nclass AzureCredentialCache {\n    constructor() {\n        this.cachedToken = null;\n    }\n    async getToken() {\n        if (this.cachedToken == null || this.needsRefresh(this.cachedToken)) {\n            this.cachedToken = await this._getToken();\n        }\n        return { accessToken: this.cachedToken.accessToken };\n    }\n    needsRefresh(token) {\n        const timeUntilExpirationMS = token.expiresOnTimestamp - Date.now();\n        return timeUntilExpirationMS <= MINIMUM_TOKEN_REFRESH_IN_MILLISECONDS;\n    }\n    /**\n     * exposed for testing\n     */\n    resetCache() {\n        this.cachedToken = null;\n    }\n    /**\n     * exposed for testing\n     */\n    _getToken() {\n        return fetchAzureKMSToken();\n    }\n}\nexports.AzureCredentialCache = AzureCredentialCache;\n/** @internal */\nexports.tokenCache = new AzureCredentialCache();\n/** @internal */\nasync function parseResponse(response) {\n    const { status, body: rawBody } = response;\n    const body = (() => {\n        try {\n            return JSON.parse(rawBody);\n        }\n        catch {\n            throw new errors_1.MongoCryptAzureKMSRequestError('Malformed JSON body in GET request.');\n        }\n    })();\n    if (status !== 200) {\n        throw new errors_1.MongoCryptAzureKMSRequestError('Unable to complete request.', body);\n    }\n    if (!body.access_token) {\n        throw new errors_1.MongoCryptAzureKMSRequestError('Malformed response body - missing field `access_token`.');\n    }\n    if (!body.expires_in) {\n        throw new errors_1.MongoCryptAzureKMSRequestError('Malformed response body - missing field `expires_in`.');\n    }\n    const expiresInMS = Number(body.expires_in) * 1000;\n    if (Number.isNaN(expiresInMS)) {\n        throw new errors_1.MongoCryptAzureKMSRequestError('Malformed response body - unable to parse int from `expires_in` field.');\n    }\n    return {\n        accessToken: body.access_token,\n        expiresOnTimestamp: Date.now() + expiresInMS\n    };\n}\n/**\n * @internal\n *\n * parses any options provided by prose tests to `fetchAzureKMSToken` and merges them with\n * the default values for headers and the request url.\n */\nfunction prepareRequest(options) {\n    const url = new URL(options.url?.toString() ?? 'http://169.254.169.254/metadata/identity/oauth2/token');\n    url.searchParams.append('api-version', '2018-02-01');\n    url.searchParams.append('resource', 'https://vault.azure.net');\n    const headers = { ...options.headers, 'Content-Type': 'application/json', Metadata: true };\n    return { headers, url };\n}\nexports.prepareRequest = prepareRequest;\n/**\n * @internal\n *\n * `AzureKMSRequestOptions` allows prose tests to modify the http request sent to the idms\n * servers.  This is required to simulate different server conditions.  No options are expected to\n * be set outside of tests.\n *\n * exposed for CSFLE\n * [prose test 18](https://github.com/mongodb/specifications/tree/master/source/client-side-encryption/tests#azure-imds-credentials)\n */\nasync function fetchAzureKMSToken(options = {}) {\n    const { headers, url } = prepareRequest(options);\n    const response = await (0, utils_1.get)(url, { headers }).catch(error => {\n        if (error instanceof errors_1.MongoCryptKMSRequestNetworkTimeoutError) {\n            throw new errors_1.MongoCryptAzureKMSRequestError(`[Azure KMS] ${error.message}`);\n        }\n        throw error;\n    });\n    return parseResponse(response);\n}\nexports.fetchAzureKMSToken = fetchAzureKMSToken;\n/**\n * @internal\n *\n * @throws Will reject with a `MongoCryptError` if the http request fails or the http response is malformed.\n */\nasync function loadAzureCredentials(kmsProviders) {\n    const azure = await exports.tokenCache.getToken();\n    return { ...kmsProviders, azure };\n}\nexports.loadAzureCredentials = loadAzureCredentials;\n//# sourceMappingURL=azure.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/client-side-encryption/providers/azure.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/providers/gcp.js":
/*!**************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/providers/gcp.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.loadGCPCredentials = void 0;\nconst deps_1 = __webpack_require__(/*! ../../deps */ \"./node_modules/mongodb/lib/deps.js\");\n/** @internal */\nasync function loadGCPCredentials(kmsProviders) {\n    const gcpMetadata = (0, deps_1.getGcpMetadata)();\n    if ('kModuleError' in gcpMetadata) {\n        return kmsProviders;\n    }\n    const { access_token: accessToken } = await gcpMetadata.instance({\n        property: 'service-accounts/default/token'\n    });\n    return { ...kmsProviders, gcp: { accessToken } };\n}\nexports.loadGCPCredentials = loadGCPCredentials;\n//# sourceMappingURL=gcp.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/client-side-encryption/providers/gcp.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/providers/index.js":
/*!****************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/providers/index.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.refreshKMSCredentials = exports.isEmptyCredentials = void 0;\nconst aws_1 = __webpack_require__(/*! ./aws */ \"./node_modules/mongodb/lib/client-side-encryption/providers/aws.js\");\nconst azure_1 = __webpack_require__(/*! ./azure */ \"./node_modules/mongodb/lib/client-side-encryption/providers/azure.js\");\nconst gcp_1 = __webpack_require__(/*! ./gcp */ \"./node_modules/mongodb/lib/client-side-encryption/providers/gcp.js\");\n/**\n * Auto credential fetching should only occur when the provider is defined on the kmsProviders map\n * and the settings are an empty object.\n *\n * This is distinct from a nullish provider key.\n *\n * @internal - exposed for testing purposes only\n */\nfunction isEmptyCredentials(providerName, kmsProviders) {\n    const provider = kmsProviders[providerName];\n    if (provider == null) {\n        return false;\n    }\n    return typeof provider === 'object' && Object.keys(provider).length === 0;\n}\nexports.isEmptyCredentials = isEmptyCredentials;\n/**\n * Load cloud provider credentials for the user provided KMS providers.\n * Credentials will only attempt to get loaded if they do not exist\n * and no existing credentials will get overwritten.\n *\n * @internal\n */\nasync function refreshKMSCredentials(kmsProviders) {\n    let finalKMSProviders = kmsProviders;\n    if (isEmptyCredentials('aws', kmsProviders)) {\n        finalKMSProviders = await (0, aws_1.loadAWSCredentials)(finalKMSProviders);\n    }\n    if (isEmptyCredentials('gcp', kmsProviders)) {\n        finalKMSProviders = await (0, gcp_1.loadGCPCredentials)(finalKMSProviders);\n    }\n    if (isEmptyCredentials('azure', kmsProviders)) {\n        finalKMSProviders = await (0, azure_1.loadAzureCredentials)(finalKMSProviders);\n    }\n    return finalKMSProviders;\n}\nexports.refreshKMSCredentials = refreshKMSCredentials;\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/client-side-encryption/providers/index.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/providers/utils.js":
/*!****************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/providers/utils.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.get = void 0;\nconst http = __webpack_require__(/*! http */ \"http\");\nconst timers_1 = __webpack_require__(/*! timers */ \"timers\");\nconst errors_1 = __webpack_require__(/*! ../errors */ \"./node_modules/mongodb/lib/client-side-encryption/errors.js\");\n/**\n * @internal\n */\nfunction get(url, options = {}) {\n    return new Promise((resolve, reject) => {\n        /* eslint-disable prefer-const */\n        let timeoutId;\n        const request = http\n            .get(url, options, response => {\n            response.setEncoding('utf8');\n            let body = '';\n            response.on('data', chunk => (body += chunk));\n            response.on('end', () => {\n                (0, timers_1.clearTimeout)(timeoutId);\n                resolve({ status: response.statusCode, body });\n            });\n        })\n            .on('error', error => {\n            (0, timers_1.clearTimeout)(timeoutId);\n            reject(error);\n        })\n            .end();\n        timeoutId = (0, timers_1.setTimeout)(() => {\n            request.destroy(new errors_1.MongoCryptKMSRequestNetworkTimeoutError(`request timed out after 10 seconds`));\n        }, 10000);\n    });\n}\nexports.get = get;\n//# sourceMappingURL=utils.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/client-side-encryption/providers/utils.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/state_machine.js":
/*!**************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/state_machine.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.StateMachine = void 0;\nconst fs = __webpack_require__(/*! fs/promises */ \"fs/promises\");\nconst net = __webpack_require__(/*! net */ \"net\");\nconst tls = __webpack_require__(/*! tls */ \"tls\");\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst deps_1 = __webpack_require__(/*! ../deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst errors_1 = __webpack_require__(/*! ./errors */ \"./node_modules/mongodb/lib/client-side-encryption/errors.js\");\nlet socks = null;\nfunction loadSocks() {\n    if (socks == null) {\n        const socksImport = (0, deps_1.getSocks)();\n        if ('kModuleError' in socksImport) {\n            throw socksImport.kModuleError;\n        }\n        socks = socksImport;\n    }\n    return socks;\n}\n// libmongocrypt states\nconst MONGOCRYPT_CTX_ERROR = 0;\nconst MONGOCRYPT_CTX_NEED_MONGO_COLLINFO = 1;\nconst MONGOCRYPT_CTX_NEED_MONGO_MARKINGS = 2;\nconst MONGOCRYPT_CTX_NEED_MONGO_KEYS = 3;\nconst MONGOCRYPT_CTX_NEED_KMS_CREDENTIALS = 7;\nconst MONGOCRYPT_CTX_NEED_KMS = 4;\nconst MONGOCRYPT_CTX_READY = 5;\nconst MONGOCRYPT_CTX_DONE = 6;\nconst HTTPS_PORT = 443;\nconst stateToString = new Map([\n    [MONGOCRYPT_CTX_ERROR, 'MONGOCRYPT_CTX_ERROR'],\n    [MONGOCRYPT_CTX_NEED_MONGO_COLLINFO, 'MONGOCRYPT_CTX_NEED_MONGO_COLLINFO'],\n    [MONGOCRYPT_CTX_NEED_MONGO_MARKINGS, 'MONGOCRYPT_CTX_NEED_MONGO_MARKINGS'],\n    [MONGOCRYPT_CTX_NEED_MONGO_KEYS, 'MONGOCRYPT_CTX_NEED_MONGO_KEYS'],\n    [MONGOCRYPT_CTX_NEED_KMS_CREDENTIALS, 'MONGOCRYPT_CTX_NEED_KMS_CREDENTIALS'],\n    [MONGOCRYPT_CTX_NEED_KMS, 'MONGOCRYPT_CTX_NEED_KMS'],\n    [MONGOCRYPT_CTX_READY, 'MONGOCRYPT_CTX_READY'],\n    [MONGOCRYPT_CTX_DONE, 'MONGOCRYPT_CTX_DONE']\n]);\nconst INSECURE_TLS_OPTIONS = [\n    'tlsInsecure',\n    'tlsAllowInvalidCertificates',\n    'tlsAllowInvalidHostnames',\n    // These options are disallowed by the spec, so we explicitly filter them out if provided, even\n    // though the StateMachine does not declare support for these options.\n    'tlsDisableOCSPEndpointCheck',\n    'tlsDisableCertificateRevocationCheck'\n];\n/**\n * Helper function for logging. Enabled by setting the environment flag MONGODB_CRYPT_DEBUG.\n * @param msg - Anything you want to be logged.\n */\nfunction debug(msg) {\n    if (process.env.MONGODB_CRYPT_DEBUG) {\n        // eslint-disable-next-line no-console\n        console.error(msg);\n    }\n}\n/**\n * @internal\n * An internal class that executes across a MongoCryptContext until either\n * a finishing state or an error is reached. Do not instantiate directly.\n */\nclass StateMachine {\n    constructor(options, bsonOptions = (0, bson_1.pluckBSONSerializeOptions)(options)) {\n        this.options = options;\n        this.bsonOptions = bsonOptions;\n    }\n    /**\n     * Executes the state machine according to the specification\n     */\n    async execute(executor, context) {\n        const keyVaultNamespace = executor._keyVaultNamespace;\n        const keyVaultClient = executor._keyVaultClient;\n        const metaDataClient = executor._metaDataClient;\n        const mongocryptdClient = executor._mongocryptdClient;\n        const mongocryptdManager = executor._mongocryptdManager;\n        let result = null;\n        while (context.state !== MONGOCRYPT_CTX_DONE && context.state !== MONGOCRYPT_CTX_ERROR) {\n            debug(`[context#${context.id}] ${stateToString.get(context.state) || context.state}`);\n            switch (context.state) {\n                case MONGOCRYPT_CTX_NEED_MONGO_COLLINFO: {\n                    const filter = (0, bson_1.deserialize)(context.nextMongoOperation());\n                    if (!metaDataClient) {\n                        throw new errors_1.MongoCryptError('unreachable state machine state: entered MONGOCRYPT_CTX_NEED_MONGO_COLLINFO but metadata client is undefined');\n                    }\n                    const collInfo = await this.fetchCollectionInfo(metaDataClient, context.ns, filter);\n                    if (collInfo) {\n                        context.addMongoOperationResponse(collInfo);\n                    }\n                    context.finishMongoOperation();\n                    break;\n                }\n                case MONGOCRYPT_CTX_NEED_MONGO_MARKINGS: {\n                    const command = context.nextMongoOperation();\n                    if (!mongocryptdClient) {\n                        throw new errors_1.MongoCryptError('unreachable state machine state: entered MONGOCRYPT_CTX_NEED_MONGO_MARKINGS but mongocryptdClient is undefined');\n                    }\n                    // When we are using the shared library, we don't have a mongocryptd manager.\n                    const markedCommand = mongocryptdManager\n                        ? await mongocryptdManager.withRespawn(this.markCommand.bind(this, mongocryptdClient, context.ns, command))\n                        : await this.markCommand(mongocryptdClient, context.ns, command);\n                    context.addMongoOperationResponse(markedCommand);\n                    context.finishMongoOperation();\n                    break;\n                }\n                case MONGOCRYPT_CTX_NEED_MONGO_KEYS: {\n                    const filter = context.nextMongoOperation();\n                    const keys = await this.fetchKeys(keyVaultClient, keyVaultNamespace, filter);\n                    if (keys.length === 0) {\n                        // This is kind of a hack.  For `rewrapManyDataKey`, we have tests that\n                        // guarantee that when there are no matching keys, `rewrapManyDataKey` returns\n                        // nothing.  We also have tests for auto encryption that guarantee for `encrypt`\n                        // we return an error when there are no matching keys.  This error is generated in\n                        // subsequent iterations of the state machine.\n                        // Some apis (`encrypt`) throw if there are no filter matches and others (`rewrapManyDataKey`)\n                        // do not.  We set the result manually here, and let the state machine continue.  `libmongocrypt`\n                        // will inform us if we need to error by setting the state to `MONGOCRYPT_CTX_ERROR` but\n                        // otherwise we'll return `{ v: [] }`.\n                        result = { v: [] };\n                    }\n                    for await (const key of keys) {\n                        context.addMongoOperationResponse((0, bson_1.serialize)(key));\n                    }\n                    context.finishMongoOperation();\n                    break;\n                }\n                case MONGOCRYPT_CTX_NEED_KMS_CREDENTIALS: {\n                    const kmsProviders = await executor.askForKMSCredentials();\n                    context.provideKMSProviders((0, bson_1.serialize)(kmsProviders));\n                    break;\n                }\n                case MONGOCRYPT_CTX_NEED_KMS: {\n                    const requests = Array.from(this.requests(context));\n                    await Promise.all(requests);\n                    context.finishKMSRequests();\n                    break;\n                }\n                case MONGOCRYPT_CTX_READY: {\n                    const finalizedContext = context.finalize();\n                    // @ts-expect-error finalize can change the state, check for error\n                    if (context.state === MONGOCRYPT_CTX_ERROR) {\n                        const message = context.status.message || 'Finalization error';\n                        throw new errors_1.MongoCryptError(message);\n                    }\n                    result = (0, bson_1.deserialize)(finalizedContext, this.options);\n                    break;\n                }\n                default:\n                    throw new errors_1.MongoCryptError(`Unknown state: ${context.state}`);\n            }\n        }\n        if (context.state === MONGOCRYPT_CTX_ERROR || result == null) {\n            const message = context.status.message;\n            if (!message) {\n                debug(`unidentifiable error in MongoCrypt - received an error status from \\`libmongocrypt\\` but received no error message.`);\n            }\n            throw new errors_1.MongoCryptError(message ??\n                'unidentifiable error in MongoCrypt - received an error status from `libmongocrypt` but received no error message.');\n        }\n        return result;\n    }\n    /**\n     * Handles the request to the KMS service. Exposed for testing purposes. Do not directly invoke.\n     * @param kmsContext - A C++ KMS context returned from the bindings\n     * @returns A promise that resolves when the KMS reply has be fully parsed\n     */\n    kmsRequest(request) {\n        const parsedUrl = request.endpoint.split(':');\n        const port = parsedUrl[1] != null ? Number.parseInt(parsedUrl[1], 10) : HTTPS_PORT;\n        const options = {\n            host: parsedUrl[0],\n            servername: parsedUrl[0],\n            port\n        };\n        const message = request.message;\n        // TODO(NODE-3959): We can adopt `for-await on(socket, 'data')` with logic to control abort\n        // eslint-disable-next-line @typescript-eslint/no-misused-promises, no-async-promise-executor\n        return new Promise(async (resolve, reject) => {\n            const buffer = new utils_1.BufferPool();\n            // eslint-disable-next-line prefer-const\n            let socket;\n            let rawSocket;\n            function destroySockets() {\n                for (const sock of [socket, rawSocket]) {\n                    if (sock) {\n                        sock.removeAllListeners();\n                        sock.destroy();\n                    }\n                }\n            }\n            function ontimeout() {\n                destroySockets();\n                reject(new errors_1.MongoCryptError('KMS request timed out'));\n            }\n            function onerror(err) {\n                destroySockets();\n                const mcError = new errors_1.MongoCryptError('KMS request failed', { cause: err });\n                reject(mcError);\n            }\n            if (this.options.proxyOptions && this.options.proxyOptions.proxyHost) {\n                rawSocket = net.connect({\n                    host: this.options.proxyOptions.proxyHost,\n                    port: this.options.proxyOptions.proxyPort || 1080\n                });\n                rawSocket.on('timeout', ontimeout);\n                rawSocket.on('error', onerror);\n                try {\n                    // eslint-disable-next-line @typescript-eslint/no-var-requires\n                    const events = __webpack_require__(/*! events */ \"events\");\n                    await events.once(rawSocket, 'connect');\n                    socks ??= loadSocks();\n                    options.socket = (await socks.SocksClient.createConnection({\n                        existing_socket: rawSocket,\n                        command: 'connect',\n                        destination: { host: options.host, port: options.port },\n                        proxy: {\n                            // host and port are ignored because we pass existing_socket\n                            host: 'iLoveJavaScript',\n                            port: 0,\n                            type: 5,\n                            userId: this.options.proxyOptions.proxyUsername,\n                            password: this.options.proxyOptions.proxyPassword\n                        }\n                    })).socket;\n                }\n                catch (err) {\n                    return onerror(err);\n                }\n            }\n            const tlsOptions = this.options.tlsOptions;\n            if (tlsOptions) {\n                const kmsProvider = request.kmsProvider;\n                const providerTlsOptions = tlsOptions[kmsProvider];\n                if (providerTlsOptions) {\n                    const error = this.validateTlsOptions(kmsProvider, providerTlsOptions);\n                    if (error)\n                        reject(error);\n                    try {\n                        await this.setTlsOptions(providerTlsOptions, options);\n                    }\n                    catch (error) {\n                        return onerror(error);\n                    }\n                }\n            }\n            socket = tls.connect(options, () => {\n                socket.write(message);\n            });\n            socket.once('timeout', ontimeout);\n            socket.once('error', onerror);\n            socket.on('data', data => {\n                buffer.append(data);\n                while (request.bytesNeeded > 0 && buffer.length) {\n                    const bytesNeeded = Math.min(request.bytesNeeded, buffer.length);\n                    request.addResponse(buffer.read(bytesNeeded));\n                }\n                if (request.bytesNeeded <= 0) {\n                    // There's no need for any more activity on this socket at this point.\n                    destroySockets();\n                    resolve();\n                }\n            });\n        });\n    }\n    *requests(context) {\n        for (let request = context.nextKMSRequest(); request != null; request = context.nextKMSRequest()) {\n            yield this.kmsRequest(request);\n        }\n    }\n    /**\n     * Validates the provided TLS options are secure.\n     *\n     * @param kmsProvider - The KMS provider name.\n     * @param tlsOptions - The client TLS options for the provider.\n     *\n     * @returns An error if any option is invalid.\n     */\n    validateTlsOptions(kmsProvider, tlsOptions) {\n        const tlsOptionNames = Object.keys(tlsOptions);\n        for (const option of INSECURE_TLS_OPTIONS) {\n            if (tlsOptionNames.includes(option)) {\n                return new errors_1.MongoCryptError(`Insecure TLS options prohibited for ${kmsProvider}: ${option}`);\n            }\n        }\n    }\n    /**\n     * Sets only the valid secure TLS options.\n     *\n     * @param tlsOptions - The client TLS options for the provider.\n     * @param options - The existing connection options.\n     */\n    async setTlsOptions(tlsOptions, options) {\n        if (tlsOptions.tlsCertificateKeyFile) {\n            const cert = await fs.readFile(tlsOptions.tlsCertificateKeyFile);\n            options.cert = options.key = cert;\n        }\n        if (tlsOptions.tlsCAFile) {\n            options.ca = await fs.readFile(tlsOptions.tlsCAFile);\n        }\n        if (tlsOptions.tlsCertificateKeyFilePassword) {\n            options.passphrase = tlsOptions.tlsCertificateKeyFilePassword;\n        }\n    }\n    /**\n     * Fetches collection info for a provided namespace, when libmongocrypt\n     * enters the `MONGOCRYPT_CTX_NEED_MONGO_COLLINFO` state. The result is\n     * used to inform libmongocrypt of the schema associated with this\n     * namespace. Exposed for testing purposes. Do not directly invoke.\n     *\n     * @param client - A MongoClient connected to the topology\n     * @param ns - The namespace to list collections from\n     * @param filter - A filter for the listCollections command\n     * @param callback - Invoked with the info of the requested collection, or with an error\n     */\n    async fetchCollectionInfo(client, ns, filter) {\n        const { db } = utils_1.MongoDBCollectionNamespace.fromString(ns);\n        const collections = await client\n            .db(db)\n            .listCollections(filter, {\n            promoteLongs: false,\n            promoteValues: false\n        })\n            .toArray();\n        const info = collections.length > 0 ? (0, bson_1.serialize)(collections[0]) : null;\n        return info;\n    }\n    /**\n     * Calls to the mongocryptd to provide markings for a command.\n     * Exposed for testing purposes. Do not directly invoke.\n     * @param client - A MongoClient connected to a mongocryptd\n     * @param ns - The namespace (database.collection) the command is being executed on\n     * @param command - The command to execute.\n     * @param callback - Invoked with the serialized and marked bson command, or with an error\n     */\n    async markCommand(client, ns, command) {\n        const options = { promoteLongs: false, promoteValues: false };\n        const { db } = utils_1.MongoDBCollectionNamespace.fromString(ns);\n        const rawCommand = (0, bson_1.deserialize)(command, options);\n        const response = await client.db(db).command(rawCommand, options);\n        return (0, bson_1.serialize)(response, this.bsonOptions);\n    }\n    /**\n     * Requests keys from the keyVault collection on the topology.\n     * Exposed for testing purposes. Do not directly invoke.\n     * @param client - A MongoClient connected to the topology\n     * @param keyVaultNamespace - The namespace (database.collection) of the keyVault Collection\n     * @param filter - The filter for the find query against the keyVault Collection\n     * @param callback - Invoked with the found keys, or with an error\n     */\n    fetchKeys(client, keyVaultNamespace, filter) {\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(keyVaultNamespace);\n        return client\n            .db(dbName)\n            .collection(collectionName, { readConcern: { level: 'majority' } })\n            .find((0, bson_1.deserialize)(filter))\n            .toArray();\n    }\n}\nexports.StateMachine = StateMachine;\n//# sourceMappingURL=state_machine.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/client-side-encryption/state_machine.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/auth_provider.js":
/*!*************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/auth_provider.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AuthProvider = exports.AuthContext = void 0;\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\n/**\n * Context used during authentication\n * @internal\n */\nclass AuthContext {\n    constructor(connection, credentials, options) {\n        /** If the context is for reauthentication. */\n        this.reauthenticating = false;\n        this.connection = connection;\n        this.credentials = credentials;\n        this.options = options;\n    }\n}\nexports.AuthContext = AuthContext;\nclass AuthProvider {\n    /**\n     * Prepare the handshake document before the initial handshake.\n     *\n     * @param handshakeDoc - The document used for the initial handshake on a connection\n     * @param authContext - Context for authentication flow\n     */\n    async prepare(handshakeDoc, _authContext) {\n        return handshakeDoc;\n    }\n    /**\n     * Reauthenticate.\n     * @param context - The shared auth context.\n     */\n    async reauth(context) {\n        if (context.reauthenticating) {\n            throw new error_1.MongoRuntimeError('Reauthentication already in progress.');\n        }\n        try {\n            context.reauthenticating = true;\n            await this.auth(context);\n        }\n        finally {\n            context.reauthenticating = false;\n        }\n    }\n}\nexports.AuthProvider = AuthProvider;\n//# sourceMappingURL=auth_provider.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/auth/auth_provider.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/gssapi.js":
/*!******************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/gssapi.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.resolveCname = exports.performGSSAPICanonicalizeHostName = exports.GSSAPI = exports.GSSAPICanonicalizationValue = void 0;\nconst dns = __webpack_require__(/*! dns */ \"dns\");\nconst deps_1 = __webpack_require__(/*! ../../deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst auth_provider_1 = __webpack_require__(/*! ./auth_provider */ \"./node_modules/mongodb/lib/cmap/auth/auth_provider.js\");\n/** @public */\nexports.GSSAPICanonicalizationValue = Object.freeze({\n    on: true,\n    off: false,\n    none: 'none',\n    forward: 'forward',\n    forwardAndReverse: 'forwardAndReverse'\n});\nasync function externalCommand(connection, command) {\n    return connection.commandAsync((0, utils_1.ns)('$external.$cmd'), command, undefined);\n}\nlet krb;\nclass GSSAPI extends auth_provider_1.AuthProvider {\n    async auth(authContext) {\n        const { connection, credentials } = authContext;\n        if (credentials == null) {\n            throw new error_1.MongoMissingCredentialsError('Credentials required for GSSAPI authentication');\n        }\n        const { username } = credentials;\n        const client = await makeKerberosClient(authContext);\n        const payload = await client.step('');\n        const saslStartResponse = await externalCommand(connection, saslStart(payload));\n        const negotiatedPayload = await negotiate(client, 10, saslStartResponse.payload);\n        const saslContinueResponse = await externalCommand(connection, saslContinue(negotiatedPayload, saslStartResponse.conversationId));\n        const finalizePayload = await finalize(client, username, saslContinueResponse.payload);\n        await externalCommand(connection, {\n            saslContinue: 1,\n            conversationId: saslContinueResponse.conversationId,\n            payload: finalizePayload\n        });\n    }\n}\nexports.GSSAPI = GSSAPI;\nasync function makeKerberosClient(authContext) {\n    const { hostAddress } = authContext.options;\n    const { credentials } = authContext;\n    if (!hostAddress || typeof hostAddress.host !== 'string' || !credentials) {\n        throw new error_1.MongoInvalidArgumentError('Connection must have host and port and credentials defined.');\n    }\n    loadKrb();\n    if ('kModuleError' in krb) {\n        throw krb['kModuleError'];\n    }\n    const { initializeClient } = krb;\n    const { username, password } = credentials;\n    const mechanismProperties = credentials.mechanismProperties;\n    const serviceName = mechanismProperties.SERVICE_NAME ?? 'mongodb';\n    const host = await performGSSAPICanonicalizeHostName(hostAddress.host, mechanismProperties);\n    const initOptions = {};\n    if (password != null) {\n        // TODO(NODE-5139): These do not match the typescript options in initializeClient\n        Object.assign(initOptions, { user: username, password: password });\n    }\n    const spnHost = mechanismProperties.SERVICE_HOST ?? host;\n    let spn = `${serviceName}${process.platform === 'win32' ? '/' : '@'}${spnHost}`;\n    if ('SERVICE_REALM' in mechanismProperties) {\n        spn = `${spn}@${mechanismProperties.SERVICE_REALM}`;\n    }\n    return initializeClient(spn, initOptions);\n}\nfunction saslStart(payload) {\n    return {\n        saslStart: 1,\n        mechanism: 'GSSAPI',\n        payload,\n        autoAuthorize: 1\n    };\n}\nfunction saslContinue(payload, conversationId) {\n    return {\n        saslContinue: 1,\n        conversationId,\n        payload\n    };\n}\nasync function negotiate(client, retries, payload) {\n    try {\n        const response = await client.step(payload);\n        return response || '';\n    }\n    catch (error) {\n        if (retries === 0) {\n            // Retries exhausted, raise error\n            throw error;\n        }\n        // Adjust number of retries and call step again\n        return negotiate(client, retries - 1, payload);\n    }\n}\nasync function finalize(client, user, payload) {\n    // GSS Client Unwrap\n    const response = await client.unwrap(payload);\n    return client.wrap(response || '', { user });\n}\nasync function performGSSAPICanonicalizeHostName(host, mechanismProperties) {\n    const mode = mechanismProperties.CANONICALIZE_HOST_NAME;\n    if (!mode || mode === exports.GSSAPICanonicalizationValue.none) {\n        return host;\n    }\n    // If forward and reverse or true\n    if (mode === exports.GSSAPICanonicalizationValue.on ||\n        mode === exports.GSSAPICanonicalizationValue.forwardAndReverse) {\n        // Perform the lookup of the ip address.\n        const { address } = await dns.promises.lookup(host);\n        try {\n            // Perform a reverse ptr lookup on the ip address.\n            const results = await dns.promises.resolvePtr(address);\n            // If the ptr did not error but had no results, return the host.\n            return results.length > 0 ? results[0] : host;\n        }\n        catch (error) {\n            // This can error as ptr records may not exist for all ips. In this case\n            // fallback to a cname lookup as dns.lookup() does not return the\n            // cname.\n            return resolveCname(host);\n        }\n    }\n    else {\n        // The case for forward is just to resolve the cname as dns.lookup()\n        // will not return it.\n        return resolveCname(host);\n    }\n}\nexports.performGSSAPICanonicalizeHostName = performGSSAPICanonicalizeHostName;\nasync function resolveCname(host) {\n    // Attempt to resolve the host name\n    try {\n        const results = await dns.promises.resolveCname(host);\n        // Get the first resolved host id\n        return results.length > 0 ? results[0] : host;\n    }\n    catch {\n        return host;\n    }\n}\nexports.resolveCname = resolveCname;\n/**\n * Load the Kerberos library.\n */\nfunction loadKrb() {\n    if (!krb) {\n        krb = (0, deps_1.getKerberos)();\n    }\n}\n//# sourceMappingURL=gssapi.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/auth/gssapi.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongo_credentials.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongo_credentials.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoCredentials = exports.DEFAULT_ALLOWED_HOSTS = void 0;\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst gssapi_1 = __webpack_require__(/*! ./gssapi */ \"./node_modules/mongodb/lib/cmap/auth/gssapi.js\");\nconst providers_1 = __webpack_require__(/*! ./providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\n// https://github.com/mongodb/specifications/blob/master/source/auth/auth.rst\nfunction getDefaultAuthMechanism(hello) {\n    if (hello) {\n        // If hello contains saslSupportedMechs, use scram-sha-256\n        // if it is available, else scram-sha-1\n        if (Array.isArray(hello.saslSupportedMechs)) {\n            return hello.saslSupportedMechs.includes(providers_1.AuthMechanism.MONGODB_SCRAM_SHA256)\n                ? providers_1.AuthMechanism.MONGODB_SCRAM_SHA256\n                : providers_1.AuthMechanism.MONGODB_SCRAM_SHA1;\n        }\n        // Fallback to legacy selection method. If wire version >= 3, use scram-sha-1\n        if (hello.maxWireVersion >= 3) {\n            return providers_1.AuthMechanism.MONGODB_SCRAM_SHA1;\n        }\n    }\n    // Default for wireprotocol < 3\n    return providers_1.AuthMechanism.MONGODB_CR;\n}\nconst ALLOWED_PROVIDER_NAMES = ['aws', 'azure'];\nconst ALLOWED_HOSTS_ERROR = 'Auth mechanism property ALLOWED_HOSTS must be an array of strings.';\n/** @internal */\nexports.DEFAULT_ALLOWED_HOSTS = [\n    '*.mongodb.net',\n    '*.mongodb-dev.net',\n    '*.mongodbgov.net',\n    'localhost',\n    '127.0.0.1',\n    '::1'\n];\n/** Error for when the token audience is missing in the environment. */\nconst TOKEN_AUDIENCE_MISSING_ERROR = 'TOKEN_AUDIENCE must be set in the auth mechanism properties when PROVIDER_NAME is azure.';\n/**\n * A representation of the credentials used by MongoDB\n * @public\n */\nclass MongoCredentials {\n    constructor(options) {\n        this.username = options.username ?? '';\n        this.password = options.password;\n        this.source = options.source;\n        if (!this.source && options.db) {\n            this.source = options.db;\n        }\n        this.mechanism = options.mechanism || providers_1.AuthMechanism.MONGODB_DEFAULT;\n        this.mechanismProperties = options.mechanismProperties || {};\n        if (this.mechanism.match(/MONGODB-AWS/i)) {\n            if (!this.username && process.env.AWS_ACCESS_KEY_ID) {\n                this.username = process.env.AWS_ACCESS_KEY_ID;\n            }\n            if (!this.password && process.env.AWS_SECRET_ACCESS_KEY) {\n                this.password = process.env.AWS_SECRET_ACCESS_KEY;\n            }\n            if (this.mechanismProperties.AWS_SESSION_TOKEN == null &&\n                process.env.AWS_SESSION_TOKEN != null) {\n                this.mechanismProperties = {\n                    ...this.mechanismProperties,\n                    AWS_SESSION_TOKEN: process.env.AWS_SESSION_TOKEN\n                };\n            }\n        }\n        if (this.mechanism === providers_1.AuthMechanism.MONGODB_OIDC && !this.mechanismProperties.ALLOWED_HOSTS) {\n            this.mechanismProperties = {\n                ...this.mechanismProperties,\n                ALLOWED_HOSTS: exports.DEFAULT_ALLOWED_HOSTS\n            };\n        }\n        Object.freeze(this.mechanismProperties);\n        Object.freeze(this);\n    }\n    /** Determines if two MongoCredentials objects are equivalent */\n    equals(other) {\n        return (this.mechanism === other.mechanism &&\n            this.username === other.username &&\n            this.password === other.password &&\n            this.source === other.source);\n    }\n    /**\n     * If the authentication mechanism is set to \"default\", resolves the authMechanism\n     * based on the server version and server supported sasl mechanisms.\n     *\n     * @param hello - A hello response from the server\n     */\n    resolveAuthMechanism(hello) {\n        // If the mechanism is not \"default\", then it does not need to be resolved\n        if (this.mechanism.match(/DEFAULT/i)) {\n            return new MongoCredentials({\n                username: this.username,\n                password: this.password,\n                source: this.source,\n                mechanism: getDefaultAuthMechanism(hello),\n                mechanismProperties: this.mechanismProperties\n            });\n        }\n        return this;\n    }\n    validate() {\n        if ((this.mechanism === providers_1.AuthMechanism.MONGODB_GSSAPI ||\n            this.mechanism === providers_1.AuthMechanism.MONGODB_CR ||\n            this.mechanism === providers_1.AuthMechanism.MONGODB_PLAIN ||\n            this.mechanism === providers_1.AuthMechanism.MONGODB_SCRAM_SHA1 ||\n            this.mechanism === providers_1.AuthMechanism.MONGODB_SCRAM_SHA256) &&\n            !this.username) {\n            throw new error_1.MongoMissingCredentialsError(`Username required for mechanism '${this.mechanism}'`);\n        }\n        if (this.mechanism === providers_1.AuthMechanism.MONGODB_OIDC) {\n            if (this.username && this.mechanismProperties.PROVIDER_NAME) {\n                throw new error_1.MongoInvalidArgumentError(`username and PROVIDER_NAME may not be used together for mechanism '${this.mechanism}'.`);\n            }\n            if (this.mechanismProperties.PROVIDER_NAME === 'azure' &&\n                !this.mechanismProperties.TOKEN_AUDIENCE) {\n                throw new error_1.MongoAzureError(TOKEN_AUDIENCE_MISSING_ERROR);\n            }\n            if (this.mechanismProperties.PROVIDER_NAME &&\n                !ALLOWED_PROVIDER_NAMES.includes(this.mechanismProperties.PROVIDER_NAME)) {\n                throw new error_1.MongoInvalidArgumentError(`Currently only a PROVIDER_NAME in ${ALLOWED_PROVIDER_NAMES.join(',')} is supported for mechanism '${this.mechanism}'.`);\n            }\n            if (this.mechanismProperties.REFRESH_TOKEN_CALLBACK &&\n                !this.mechanismProperties.REQUEST_TOKEN_CALLBACK) {\n                throw new error_1.MongoInvalidArgumentError(`A REQUEST_TOKEN_CALLBACK must be provided when using a REFRESH_TOKEN_CALLBACK for mechanism '${this.mechanism}'`);\n            }\n            if (!this.mechanismProperties.PROVIDER_NAME &&\n                !this.mechanismProperties.REQUEST_TOKEN_CALLBACK) {\n                throw new error_1.MongoInvalidArgumentError(`Either a PROVIDER_NAME or a REQUEST_TOKEN_CALLBACK must be specified for mechanism '${this.mechanism}'.`);\n            }\n            if (this.mechanismProperties.ALLOWED_HOSTS) {\n                const hosts = this.mechanismProperties.ALLOWED_HOSTS;\n                if (!Array.isArray(hosts)) {\n                    throw new error_1.MongoInvalidArgumentError(ALLOWED_HOSTS_ERROR);\n                }\n                for (const host of hosts) {\n                    if (typeof host !== 'string') {\n                        throw new error_1.MongoInvalidArgumentError(ALLOWED_HOSTS_ERROR);\n                    }\n                }\n            }\n        }\n        if (providers_1.AUTH_MECHS_AUTH_SRC_EXTERNAL.has(this.mechanism)) {\n            if (this.source != null && this.source !== '$external') {\n                // TODO(NODE-3485): Replace this with a MongoAuthValidationError\n                throw new error_1.MongoAPIError(`Invalid source '${this.source}' for mechanism '${this.mechanism}' specified.`);\n            }\n        }\n        if (this.mechanism === providers_1.AuthMechanism.MONGODB_PLAIN && this.source == null) {\n            // TODO(NODE-3485): Replace this with a MongoAuthValidationError\n            throw new error_1.MongoAPIError('PLAIN Authentication Mechanism needs an auth source');\n        }\n        if (this.mechanism === providers_1.AuthMechanism.MONGODB_X509 && this.password != null) {\n            if (this.password === '') {\n                Reflect.set(this, 'password', undefined);\n                return;\n            }\n            // TODO(NODE-3485): Replace this with a MongoAuthValidationError\n            throw new error_1.MongoAPIError(`Password not allowed for mechanism MONGODB-X509`);\n        }\n        const canonicalization = this.mechanismProperties.CANONICALIZE_HOST_NAME ?? false;\n        if (!Object.values(gssapi_1.GSSAPICanonicalizationValue).includes(canonicalization)) {\n            throw new error_1.MongoAPIError(`Invalid CANONICALIZE_HOST_NAME value: ${canonicalization}`);\n        }\n    }\n    static merge(creds, options) {\n        return new MongoCredentials({\n            username: options.username ?? creds?.username ?? '',\n            password: options.password ?? creds?.password ?? '',\n            mechanism: options.mechanism ?? creds?.mechanism ?? providers_1.AuthMechanism.MONGODB_DEFAULT,\n            mechanismProperties: options.mechanismProperties ?? creds?.mechanismProperties ?? {},\n            source: options.source ?? options.db ?? creds?.source ?? 'admin'\n        });\n    }\n}\nexports.MongoCredentials = MongoCredentials;\n//# sourceMappingURL=mongo_credentials.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/auth/mongo_credentials.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongocr.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongocr.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoCR = void 0;\nconst crypto = __webpack_require__(/*! crypto */ \"crypto\");\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst auth_provider_1 = __webpack_require__(/*! ./auth_provider */ \"./node_modules/mongodb/lib/cmap/auth/auth_provider.js\");\nclass MongoCR extends auth_provider_1.AuthProvider {\n    async auth(authContext) {\n        const { connection, credentials } = authContext;\n        if (!credentials) {\n            throw new error_1.MongoMissingCredentialsError('AuthContext must provide credentials.');\n        }\n        const { username, password, source } = credentials;\n        const { nonce } = await connection.commandAsync((0, utils_1.ns)(`${source}.$cmd`), { getnonce: 1 }, undefined);\n        const hashPassword = crypto\n            .createHash('md5')\n            .update(`${username}:mongo:${password}`, 'utf8')\n            .digest('hex');\n        // Final key\n        const key = crypto\n            .createHash('md5')\n            .update(`${nonce}${username}${hashPassword}`, 'utf8')\n            .digest('hex');\n        const authenticateCommand = {\n            authenticate: 1,\n            user: username,\n            nonce,\n            key\n        };\n        await connection.commandAsync((0, utils_1.ns)(`${source}.$cmd`), authenticateCommand, undefined);\n    }\n}\nexports.MongoCR = MongoCR;\n//# sourceMappingURL=mongocr.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/auth/mongocr.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_aws.js":
/*!***********************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_aws.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoDBAWS = void 0;\nconst crypto = __webpack_require__(/*! crypto */ \"crypto\");\nconst process = __webpack_require__(/*! process */ \"process\");\nconst util_1 = __webpack_require__(/*! util */ \"util\");\nconst BSON = __webpack_require__(/*! ../../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst deps_1 = __webpack_require__(/*! ../../deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst auth_provider_1 = __webpack_require__(/*! ./auth_provider */ \"./node_modules/mongodb/lib/cmap/auth/auth_provider.js\");\nconst mongo_credentials_1 = __webpack_require__(/*! ./mongo_credentials */ \"./node_modules/mongodb/lib/cmap/auth/mongo_credentials.js\");\nconst providers_1 = __webpack_require__(/*! ./providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\n/**\n * The following regions use the global AWS STS endpoint, sts.amazonaws.com, by default\n * https://docs.aws.amazon.com/sdkref/latest/guide/feature-sts-regionalized-endpoints.html\n */\nconst LEGACY_REGIONS = new Set([\n    'ap-northeast-1',\n    'ap-south-1',\n    'ap-southeast-1',\n    'ap-southeast-2',\n    'aws-global',\n    'ca-central-1',\n    'eu-central-1',\n    'eu-north-1',\n    'eu-west-1',\n    'eu-west-2',\n    'eu-west-3',\n    'sa-east-1',\n    'us-east-1',\n    'us-east-2',\n    'us-west-1',\n    'us-west-2'\n]);\nconst ASCII_N = 110;\nconst AWS_RELATIVE_URI = 'http://169.254.170.2';\nconst AWS_EC2_URI = 'http://169.254.169.254';\nconst AWS_EC2_PATH = '/latest/meta-data/iam/security-credentials';\nconst bsonOptions = {\n    useBigInt64: false,\n    promoteLongs: true,\n    promoteValues: true,\n    promoteBuffers: false,\n    bsonRegExp: false\n};\nclass MongoDBAWS extends auth_provider_1.AuthProvider {\n    constructor() {\n        super();\n        this.randomBytesAsync = (0, util_1.promisify)(crypto.randomBytes);\n    }\n    async auth(authContext) {\n        const { connection } = authContext;\n        if (!authContext.credentials) {\n            throw new error_1.MongoMissingCredentialsError('AuthContext must provide credentials.');\n        }\n        if ('kModuleError' in deps_1.aws4) {\n            throw deps_1.aws4['kModuleError'];\n        }\n        const { sign } = deps_1.aws4;\n        if ((0, utils_1.maxWireVersion)(connection) < 9) {\n            throw new error_1.MongoCompatibilityError('MONGODB-AWS authentication requires MongoDB version 4.4 or later');\n        }\n        if (!authContext.credentials.username) {\n            authContext.credentials = await makeTempCredentials(authContext.credentials);\n        }\n        const { credentials } = authContext;\n        const accessKeyId = credentials.username;\n        const secretAccessKey = credentials.password;\n        const sessionToken = credentials.mechanismProperties.AWS_SESSION_TOKEN;\n        // If all three defined, include sessionToken, else include username and pass, else no credentials\n        const awsCredentials = accessKeyId && secretAccessKey && sessionToken\n            ? { accessKeyId, secretAccessKey, sessionToken }\n            : accessKeyId && secretAccessKey\n                ? { accessKeyId, secretAccessKey }\n                : undefined;\n        const db = credentials.source;\n        const nonce = await this.randomBytesAsync(32);\n        const saslStart = {\n            saslStart: 1,\n            mechanism: 'MONGODB-AWS',\n            payload: BSON.serialize({ r: nonce, p: ASCII_N }, bsonOptions)\n        };\n        const saslStartResponse = await connection.commandAsync((0, utils_1.ns)(`${db}.$cmd`), saslStart, undefined);\n        const serverResponse = BSON.deserialize(saslStartResponse.payload.buffer, bsonOptions);\n        const host = serverResponse.h;\n        const serverNonce = serverResponse.s.buffer;\n        if (serverNonce.length !== 64) {\n            // TODO(NODE-3483)\n            throw new error_1.MongoRuntimeError(`Invalid server nonce length ${serverNonce.length}, expected 64`);\n        }\n        if (!utils_1.ByteUtils.equals(serverNonce.subarray(0, nonce.byteLength), nonce)) {\n            // throw because the serverNonce's leading 32 bytes must equal the client nonce's 32 bytes\n            // https://github.com/mongodb/specifications/blob/875446db44aade414011731840831f38a6c668df/source/auth/auth.rst#id11\n            // TODO(NODE-3483)\n            throw new error_1.MongoRuntimeError('Server nonce does not begin with client nonce');\n        }\n        if (host.length < 1 || host.length > 255 || host.indexOf('..') !== -1) {\n            // TODO(NODE-3483)\n            throw new error_1.MongoRuntimeError(`Server returned an invalid host: \"${host}\"`);\n        }\n        const body = 'Action=GetCallerIdentity&Version=2011-06-15';\n        const options = sign({\n            method: 'POST',\n            host,\n            region: deriveRegion(serverResponse.h),\n            service: 'sts',\n            headers: {\n                'Content-Type': 'application/x-www-form-urlencoded',\n                'Content-Length': body.length,\n                'X-MongoDB-Server-Nonce': utils_1.ByteUtils.toBase64(serverNonce),\n                'X-MongoDB-GS2-CB-Flag': 'n'\n            },\n            path: '/',\n            body\n        }, awsCredentials);\n        const payload = {\n            a: options.headers.Authorization,\n            d: options.headers['X-Amz-Date']\n        };\n        if (sessionToken) {\n            payload.t = sessionToken;\n        }\n        const saslContinue = {\n            saslContinue: 1,\n            conversationId: 1,\n            payload: BSON.serialize(payload, bsonOptions)\n        };\n        await connection.commandAsync((0, utils_1.ns)(`${db}.$cmd`), saslContinue, undefined);\n    }\n}\nMongoDBAWS.credentialProvider = null;\nexports.MongoDBAWS = MongoDBAWS;\nasync function makeTempCredentials(credentials) {\n    function makeMongoCredentialsFromAWSTemp(creds) {\n        if (!creds.AccessKeyId || !creds.SecretAccessKey || !creds.Token) {\n            throw new error_1.MongoMissingCredentialsError('Could not obtain temporary MONGODB-AWS credentials');\n        }\n        return new mongo_credentials_1.MongoCredentials({\n            username: creds.AccessKeyId,\n            password: creds.SecretAccessKey,\n            source: credentials.source,\n            mechanism: providers_1.AuthMechanism.MONGODB_AWS,\n            mechanismProperties: {\n                AWS_SESSION_TOKEN: creds.Token\n            }\n        });\n    }\n    MongoDBAWS.credentialProvider ??= (0, deps_1.getAwsCredentialProvider)();\n    // Check if the AWS credential provider from the SDK is present. If not,\n    // use the old method.\n    if ('kModuleError' in MongoDBAWS.credentialProvider) {\n        // If the environment variable AWS_CONTAINER_CREDENTIALS_RELATIVE_URI\n        // is set then drivers MUST assume that it was set by an AWS ECS agent\n        if (process.env.AWS_CONTAINER_CREDENTIALS_RELATIVE_URI) {\n            return makeMongoCredentialsFromAWSTemp(await (0, utils_1.request)(`${AWS_RELATIVE_URI}${process.env.AWS_CONTAINER_CREDENTIALS_RELATIVE_URI}`));\n        }\n        // Otherwise assume we are on an EC2 instance\n        // get a token\n        const token = await (0, utils_1.request)(`${AWS_EC2_URI}/latest/api/token`, {\n            method: 'PUT',\n            json: false,\n            headers: { 'X-aws-ec2-metadata-token-ttl-seconds': 30 }\n        });\n        // get role name\n        const roleName = await (0, utils_1.request)(`${AWS_EC2_URI}/${AWS_EC2_PATH}`, {\n            json: false,\n            headers: { 'X-aws-ec2-metadata-token': token }\n        });\n        // get temp credentials\n        const creds = await (0, utils_1.request)(`${AWS_EC2_URI}/${AWS_EC2_PATH}/${roleName}`, {\n            headers: { 'X-aws-ec2-metadata-token': token }\n        });\n        return makeMongoCredentialsFromAWSTemp(creds);\n    }\n    else {\n        let { AWS_STS_REGIONAL_ENDPOINTS = '', AWS_REGION = '' } = process.env;\n        AWS_STS_REGIONAL_ENDPOINTS = AWS_STS_REGIONAL_ENDPOINTS.toLowerCase();\n        AWS_REGION = AWS_REGION.toLowerCase();\n        /** The option setting should work only for users who have explicit settings in their environment, the driver should not encode \"defaults\" */\n        const awsRegionSettingsExist = AWS_REGION.length !== 0 && AWS_STS_REGIONAL_ENDPOINTS.length !== 0;\n        /**\n         * If AWS_STS_REGIONAL_ENDPOINTS is set to regional, users are opting into the new behavior of respecting the region settings\n         *\n         * If AWS_STS_REGIONAL_ENDPOINTS is set to legacy, then \"old\" regions need to keep using the global setting.\n         * Technically the SDK gets this wrong, it reaches out to 'sts.us-east-1.amazonaws.com' when it should be 'sts.amazonaws.com'.\n         * That is not our bug to fix here. We leave that up to the SDK.\n         */\n        const useRegionalSts = AWS_STS_REGIONAL_ENDPOINTS === 'regional' ||\n            (AWS_STS_REGIONAL_ENDPOINTS === 'legacy' && !LEGACY_REGIONS.has(AWS_REGION));\n        const provider = awsRegionSettingsExist && useRegionalSts\n            ? MongoDBAWS.credentialProvider.fromNodeProviderChain({\n                clientConfig: { region: AWS_REGION }\n            })\n            : MongoDBAWS.credentialProvider.fromNodeProviderChain();\n        /*\n         * Creates a credential provider that will attempt to find credentials from the\n         * following sources (listed in order of precedence):\n         *\n         * - Environment variables exposed via process.env\n         * - SSO credentials from token cache\n         * - Web identity token credentials\n         * - Shared credentials and config ini files\n         * - The EC2/ECS Instance Metadata Service\n         */\n        try {\n            const creds = await provider();\n            return makeMongoCredentialsFromAWSTemp({\n                AccessKeyId: creds.accessKeyId,\n                SecretAccessKey: creds.secretAccessKey,\n                Token: creds.sessionToken,\n                Expiration: creds.expiration\n            });\n        }\n        catch (error) {\n            throw new error_1.MongoAWSError(error.message);\n        }\n    }\n}\nfunction deriveRegion(host) {\n    const parts = host.split('.');\n    if (parts.length === 1 || parts[1] === 'amazonaws') {\n        return 'us-east-1';\n    }\n    return parts[1];\n}\n//# sourceMappingURL=mongodb_aws.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/auth/mongodb_aws.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc.js":
/*!************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoDBOIDC = exports.OIDC_WORKFLOWS = void 0;\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst auth_provider_1 = __webpack_require__(/*! ./auth_provider */ \"./node_modules/mongodb/lib/cmap/auth/auth_provider.js\");\nconst aws_service_workflow_1 = __webpack_require__(/*! ./mongodb_oidc/aws_service_workflow */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/aws_service_workflow.js\");\nconst azure_service_workflow_1 = __webpack_require__(/*! ./mongodb_oidc/azure_service_workflow */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/azure_service_workflow.js\");\nconst callback_workflow_1 = __webpack_require__(/*! ./mongodb_oidc/callback_workflow */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/callback_workflow.js\");\n/** Error when credentials are missing. */\nconst MISSING_CREDENTIALS_ERROR = 'AuthContext must provide credentials.';\n/** @internal */\nexports.OIDC_WORKFLOWS = new Map();\nexports.OIDC_WORKFLOWS.set('callback', new callback_workflow_1.CallbackWorkflow());\nexports.OIDC_WORKFLOWS.set('aws', new aws_service_workflow_1.AwsServiceWorkflow());\nexports.OIDC_WORKFLOWS.set('azure', new azure_service_workflow_1.AzureServiceWorkflow());\n/**\n * OIDC auth provider.\n * @experimental\n */\nclass MongoDBOIDC extends auth_provider_1.AuthProvider {\n    /**\n     * Instantiate the auth provider.\n     */\n    constructor() {\n        super();\n    }\n    /**\n     * Authenticate using OIDC\n     */\n    async auth(authContext) {\n        const { connection, reauthenticating, response } = authContext;\n        const credentials = getCredentials(authContext);\n        const workflow = getWorkflow(credentials);\n        await workflow.execute(connection, credentials, reauthenticating, response);\n    }\n    /**\n     * Add the speculative auth for the initial handshake.\n     */\n    async prepare(handshakeDoc, authContext) {\n        const credentials = getCredentials(authContext);\n        const workflow = getWorkflow(credentials);\n        const result = await workflow.speculativeAuth(credentials);\n        return { ...handshakeDoc, ...result };\n    }\n}\nexports.MongoDBOIDC = MongoDBOIDC;\n/**\n * Get credentials from the auth context, throwing if they do not exist.\n */\nfunction getCredentials(authContext) {\n    const { credentials } = authContext;\n    if (!credentials) {\n        throw new error_1.MongoMissingCredentialsError(MISSING_CREDENTIALS_ERROR);\n    }\n    return credentials;\n}\n/**\n * Gets either a device workflow or callback workflow.\n */\nfunction getWorkflow(credentials) {\n    const providerName = credentials.mechanismProperties.PROVIDER_NAME;\n    const workflow = exports.OIDC_WORKFLOWS.get(providerName || 'callback');\n    if (!workflow) {\n        throw new error_1.MongoInvalidArgumentError(`Could not load workflow for provider ${credentials.mechanismProperties.PROVIDER_NAME}`);\n    }\n    return workflow;\n}\n//# sourceMappingURL=mongodb_oidc.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/aws_service_workflow.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/aws_service_workflow.js ***!
  \*********************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AwsServiceWorkflow = void 0;\nconst fs = __webpack_require__(/*! fs */ \"fs\");\nconst error_1 = __webpack_require__(/*! ../../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst service_workflow_1 = __webpack_require__(/*! ./service_workflow */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/service_workflow.js\");\n/** Error for when the token is missing in the environment. */\nconst TOKEN_MISSING_ERROR = 'AWS_WEB_IDENTITY_TOKEN_FILE must be set in the environment.';\n/**\n * Device workflow implementation for AWS.\n *\n * @internal\n */\nclass AwsServiceWorkflow extends service_workflow_1.ServiceWorkflow {\n    constructor() {\n        super();\n    }\n    /**\n     * Get the token from the environment.\n     */\n    async getToken() {\n        const tokenFile = process.env.AWS_WEB_IDENTITY_TOKEN_FILE;\n        if (!tokenFile) {\n            throw new error_1.MongoAWSError(TOKEN_MISSING_ERROR);\n        }\n        return fs.promises.readFile(tokenFile, 'utf8');\n    }\n}\nexports.AwsServiceWorkflow = AwsServiceWorkflow;\n//# sourceMappingURL=aws_service_workflow.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/aws_service_workflow.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/azure_service_workflow.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/azure_service_workflow.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AzureServiceWorkflow = void 0;\nconst error_1 = __webpack_require__(/*! ../../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst azure_token_cache_1 = __webpack_require__(/*! ./azure_token_cache */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/azure_token_cache.js\");\nconst service_workflow_1 = __webpack_require__(/*! ./service_workflow */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/service_workflow.js\");\n/** Base URL for getting Azure tokens. */\nconst AZURE_BASE_URL = 'http://169.254.169.254/metadata/identity/oauth2/token?api-version=2018-02-01';\n/** Azure request headers. */\nconst AZURE_HEADERS = Object.freeze({ Metadata: 'true', Accept: 'application/json' });\n/** Invalid endpoint result error. */\nconst ENDPOINT_RESULT_ERROR = 'Azure endpoint did not return a value with only access_token and expires_in properties';\n/** Error for when the token audience is missing in the environment. */\nconst TOKEN_AUDIENCE_MISSING_ERROR = 'TOKEN_AUDIENCE must be set in the auth mechanism properties when PROVIDER_NAME is azure.';\n/**\n * Device workflow implementation for Azure.\n *\n * @internal\n */\nclass AzureServiceWorkflow extends service_workflow_1.ServiceWorkflow {\n    constructor() {\n        super(...arguments);\n        this.cache = new azure_token_cache_1.AzureTokenCache();\n    }\n    /**\n     * Get the token from the environment.\n     */\n    async getToken(credentials) {\n        const tokenAudience = credentials?.mechanismProperties.TOKEN_AUDIENCE;\n        if (!tokenAudience) {\n            throw new error_1.MongoAzureError(TOKEN_AUDIENCE_MISSING_ERROR);\n        }\n        let token;\n        const entry = this.cache.getEntry(tokenAudience);\n        if (entry?.isValid()) {\n            token = entry.token;\n        }\n        else {\n            this.cache.deleteEntry(tokenAudience);\n            const response = await getAzureTokenData(tokenAudience);\n            if (!isEndpointResultValid(response)) {\n                throw new error_1.MongoAzureError(ENDPOINT_RESULT_ERROR);\n            }\n            this.cache.addEntry(tokenAudience, response);\n            token = response.access_token;\n        }\n        return token;\n    }\n}\nexports.AzureServiceWorkflow = AzureServiceWorkflow;\n/**\n * Hit the Azure endpoint to get the token data.\n */\nasync function getAzureTokenData(tokenAudience) {\n    const url = `${AZURE_BASE_URL}&resource=${tokenAudience}`;\n    const data = await (0, utils_1.request)(url, {\n        json: true,\n        headers: AZURE_HEADERS\n    });\n    return data;\n}\n/**\n * Determines if a result returned from the endpoint is valid.\n * This means the result is not nullish, contains the access_token required field\n * and the expires_in required field.\n */\nfunction isEndpointResultValid(token) {\n    if (token == null || typeof token !== 'object')\n        return false;\n    return 'access_token' in token && 'expires_in' in token;\n}\n//# sourceMappingURL=azure_service_workflow.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/azure_service_workflow.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/azure_token_cache.js":
/*!******************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/azure_token_cache.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AzureTokenCache = exports.AzureTokenEntry = void 0;\nconst cache_1 = __webpack_require__(/*! ./cache */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/cache.js\");\n/** @internal */\nclass AzureTokenEntry extends cache_1.ExpiringCacheEntry {\n    /**\n     * Instantiate the entry.\n     */\n    constructor(token, expiration) {\n        super(expiration);\n        this.token = token;\n    }\n}\nexports.AzureTokenEntry = AzureTokenEntry;\n/**\n * A cache of access tokens from Azure.\n * @internal\n */\nclass AzureTokenCache extends cache_1.Cache {\n    /**\n     * Add an entry to the cache.\n     */\n    addEntry(tokenAudience, token) {\n        const entry = new AzureTokenEntry(token.access_token, token.expires_in);\n        this.entries.set(tokenAudience, entry);\n        return entry;\n    }\n    /**\n     * Create a cache key.\n     */\n    cacheKey(tokenAudience) {\n        return tokenAudience;\n    }\n    /**\n     * Delete an entry from the cache.\n     */\n    deleteEntry(tokenAudience) {\n        this.entries.delete(tokenAudience);\n    }\n    /**\n     * Get an Azure token entry from the cache.\n     */\n    getEntry(tokenAudience) {\n        return this.entries.get(tokenAudience);\n    }\n}\nexports.AzureTokenCache = AzureTokenCache;\n//# sourceMappingURL=azure_token_cache.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/azure_token_cache.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/cache.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/cache.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Cache = exports.ExpiringCacheEntry = void 0;\n/* 5 minutes in milliseconds */\nconst EXPIRATION_BUFFER_MS = 300000;\n/**\n * An entry in a cache that can expire in a certain amount of time.\n */\nclass ExpiringCacheEntry {\n    /**\n     * Create a new expiring token entry.\n     */\n    constructor(expiration) {\n        this.expiration = this.expirationTime(expiration);\n    }\n    /**\n     * The entry is still valid if the expiration is more than\n     * 5 minutes from the expiration time.\n     */\n    isValid() {\n        return this.expiration - Date.now() > EXPIRATION_BUFFER_MS;\n    }\n    /**\n     * Get an expiration time in milliseconds past epoch.\n     */\n    expirationTime(expiresInSeconds) {\n        return Date.now() + expiresInSeconds * 1000;\n    }\n}\nexports.ExpiringCacheEntry = ExpiringCacheEntry;\n/**\n * Base class for OIDC caches.\n */\nclass Cache {\n    /**\n     * Create a new cache.\n     */\n    constructor() {\n        this.entries = new Map();\n    }\n    /**\n     * Clear the cache.\n     */\n    clear() {\n        this.entries.clear();\n    }\n    /**\n     * Create a cache key from the address and username.\n     */\n    hashedCacheKey(address, username, callbackHash) {\n        return JSON.stringify([address, username, callbackHash]);\n    }\n}\nexports.Cache = Cache;\n//# sourceMappingURL=cache.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/cache.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/callback_lock_cache.js":
/*!********************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/callback_lock_cache.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CallbackLockCache = void 0;\nconst error_1 = __webpack_require__(/*! ../../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst cache_1 = __webpack_require__(/*! ./cache */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/cache.js\");\n/** Error message for when request callback is missing. */\nconst REQUEST_CALLBACK_REQUIRED_ERROR = 'Auth mechanism property REQUEST_TOKEN_CALLBACK is required.';\n/* Counter for function \"hashes\".*/\nlet FN_HASH_COUNTER = 0;\n/* No function present function */\nconst NO_FUNCTION = async () => ({ accessToken: 'test' });\n/* The map of function hashes */\nconst FN_HASHES = new WeakMap();\n/* Put the no function hash in the map. */\nFN_HASHES.set(NO_FUNCTION, FN_HASH_COUNTER);\n/**\n * A cache of request and refresh callbacks per server/user.\n */\nclass CallbackLockCache extends cache_1.Cache {\n    /**\n     * Get the callbacks for the connection and credentials. If an entry does not\n     * exist a new one will get set.\n     */\n    getEntry(connection, credentials) {\n        const requestCallback = credentials.mechanismProperties.REQUEST_TOKEN_CALLBACK;\n        const refreshCallback = credentials.mechanismProperties.REFRESH_TOKEN_CALLBACK;\n        if (!requestCallback) {\n            throw new error_1.MongoInvalidArgumentError(REQUEST_CALLBACK_REQUIRED_ERROR);\n        }\n        const callbackHash = hashFunctions(requestCallback, refreshCallback);\n        const key = this.cacheKey(connection.address, credentials.username, callbackHash);\n        const entry = this.entries.get(key);\n        if (entry) {\n            return entry;\n        }\n        return this.addEntry(key, callbackHash, requestCallback, refreshCallback);\n    }\n    /**\n     * Set locked callbacks on for connection and credentials.\n     */\n    addEntry(key, callbackHash, requestCallback, refreshCallback) {\n        const entry = {\n            requestCallback: withLock(requestCallback),\n            refreshCallback: refreshCallback ? withLock(refreshCallback) : undefined,\n            callbackHash: callbackHash\n        };\n        this.entries.set(key, entry);\n        return entry;\n    }\n    /**\n     * Create a cache key from the address and username.\n     */\n    cacheKey(address, username, callbackHash) {\n        return this.hashedCacheKey(address, username, callbackHash);\n    }\n}\nexports.CallbackLockCache = CallbackLockCache;\n/**\n * Ensure the callback is only executed one at a time.\n */\nfunction withLock(callback) {\n    let lock = Promise.resolve();\n    return async (info, context) => {\n        await lock;\n        lock = lock.then(() => callback(info, context));\n        return lock;\n    };\n}\n/**\n * Get the hash string for the request and refresh functions.\n */\nfunction hashFunctions(requestFn, refreshFn) {\n    let requestHash = FN_HASHES.get(requestFn);\n    let refreshHash = FN_HASHES.get(refreshFn ?? NO_FUNCTION);\n    if (requestHash == null) {\n        // Create a new one for the function and put it in the map.\n        FN_HASH_COUNTER++;\n        requestHash = FN_HASH_COUNTER;\n        FN_HASHES.set(requestFn, FN_HASH_COUNTER);\n    }\n    if (refreshHash == null && refreshFn) {\n        // Create a new one for the function and put it in the map.\n        FN_HASH_COUNTER++;\n        refreshHash = FN_HASH_COUNTER;\n        FN_HASHES.set(refreshFn, FN_HASH_COUNTER);\n    }\n    return `${requestHash}-${refreshHash}`;\n}\n//# sourceMappingURL=callback_lock_cache.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/callback_lock_cache.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/callback_workflow.js":
/*!******************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/callback_workflow.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CallbackWorkflow = void 0;\nconst bson_1 = __webpack_require__(/*! bson */ \"./node_modules/bson/lib/bson.cjs\");\nconst error_1 = __webpack_require__(/*! ../../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst providers_1 = __webpack_require__(/*! ../providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\nconst callback_lock_cache_1 = __webpack_require__(/*! ./callback_lock_cache */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/callback_lock_cache.js\");\nconst token_entry_cache_1 = __webpack_require__(/*! ./token_entry_cache */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/token_entry_cache.js\");\n/** The current version of OIDC implementation. */\nconst OIDC_VERSION = 0;\n/** 5 minutes in seconds */\nconst TIMEOUT_S = 300;\n/** Properties allowed on results of callbacks. */\nconst RESULT_PROPERTIES = ['accessToken', 'expiresInSeconds', 'refreshToken'];\n/** Error message when the callback result is invalid. */\nconst CALLBACK_RESULT_ERROR = 'User provided OIDC callbacks must return a valid object with an accessToken.';\n/**\n * OIDC implementation of a callback based workflow.\n * @internal\n */\nclass CallbackWorkflow {\n    /**\n     * Instantiate the workflow\n     */\n    constructor() {\n        this.cache = new token_entry_cache_1.TokenEntryCache();\n        this.callbackCache = new callback_lock_cache_1.CallbackLockCache();\n    }\n    /**\n     * Get the document to add for speculative authentication. This also needs\n     * to add a db field from the credentials source.\n     */\n    async speculativeAuth(credentials) {\n        const document = startCommandDocument(credentials);\n        document.db = credentials.source;\n        return { speculativeAuthenticate: document };\n    }\n    /**\n     * Execute the OIDC callback workflow.\n     */\n    async execute(connection, credentials, reauthenticating, response) {\n        // Get the callbacks with locks from the callback lock cache.\n        const { requestCallback, refreshCallback, callbackHash } = this.callbackCache.getEntry(connection, credentials);\n        // Look for an existing entry in the cache.\n        const entry = this.cache.getEntry(connection.address, credentials.username, callbackHash);\n        let result;\n        if (entry) {\n            // Reauthentication cannot use a token from the cache since the server has\n            // stated it is invalid by the request for reauthentication.\n            if (entry.isValid() && !reauthenticating) {\n                // Presence of a valid cache entry means we can skip to the finishing step.\n                result = await this.finishAuthentication(connection, credentials, entry.tokenResult, response?.speculativeAuthenticate?.conversationId);\n            }\n            else {\n                // Presence of an expired cache entry means we must fetch a new one and\n                // then execute the final step.\n                const tokenResult = await this.fetchAccessToken(connection, credentials, entry.serverInfo, reauthenticating, callbackHash, requestCallback, refreshCallback);\n                try {\n                    result = await this.finishAuthentication(connection, credentials, tokenResult, reauthenticating ? undefined : response?.speculativeAuthenticate?.conversationId);\n                }\n                catch (error) {\n                    // If we are reauthenticating and this errors with reauthentication\n                    // required, we need to do the entire process over again and clear\n                    // the cache entry.\n                    if (reauthenticating &&\n                        error instanceof error_1.MongoError &&\n                        error.code === error_1.MONGODB_ERROR_CODES.Reauthenticate) {\n                        this.cache.deleteEntry(connection.address, credentials.username, callbackHash);\n                        result = await this.execute(connection, credentials, reauthenticating);\n                    }\n                    else {\n                        throw error;\n                    }\n                }\n            }\n        }\n        else {\n            // No entry in the cache requires us to do all authentication steps\n            // from start to finish, including getting a fresh token for the cache.\n            const startDocument = await this.startAuthentication(connection, credentials, reauthenticating, response);\n            const conversationId = startDocument.conversationId;\n            const serverResult = bson_1.BSON.deserialize(startDocument.payload.buffer);\n            const tokenResult = await this.fetchAccessToken(connection, credentials, serverResult, reauthenticating, callbackHash, requestCallback, refreshCallback);\n            result = await this.finishAuthentication(connection, credentials, tokenResult, conversationId);\n        }\n        return result;\n    }\n    /**\n     * Starts the callback authentication process. If there is a speculative\n     * authentication document from the initial handshake, then we will use that\n     * value to get the issuer, otherwise we will send the saslStart command.\n     */\n    async startAuthentication(connection, credentials, reauthenticating, response) {\n        let result;\n        if (!reauthenticating && response?.speculativeAuthenticate) {\n            result = response.speculativeAuthenticate;\n        }\n        else {\n            result = await connection.commandAsync((0, utils_1.ns)(credentials.source), startCommandDocument(credentials), undefined);\n        }\n        return result;\n    }\n    /**\n     * Finishes the callback authentication process.\n     */\n    async finishAuthentication(connection, credentials, tokenResult, conversationId) {\n        const result = await connection.commandAsync((0, utils_1.ns)(credentials.source), finishCommandDocument(tokenResult.accessToken, conversationId), undefined);\n        return result;\n    }\n    /**\n     * Fetches an access token using either the request or refresh callbacks and\n     * puts it in the cache.\n     */\n    async fetchAccessToken(connection, credentials, serverInfo, reauthenticating, callbackHash, requestCallback, refreshCallback) {\n        // Get the token from the cache.\n        const entry = this.cache.getEntry(connection.address, credentials.username, callbackHash);\n        let result;\n        const context = { timeoutSeconds: TIMEOUT_S, version: OIDC_VERSION };\n        // Check if there's a token in the cache.\n        if (entry) {\n            // If the cache entry is valid, return the token result.\n            if (entry.isValid() && !reauthenticating) {\n                return entry.tokenResult;\n            }\n            // If the cache entry is not valid, remove it from the cache and first attempt\n            // to use the refresh callback to get a new token. If no refresh callback\n            // exists, then fallback to the request callback.\n            if (refreshCallback) {\n                context.refreshToken = entry.tokenResult.refreshToken;\n                result = await refreshCallback(serverInfo, context);\n            }\n            else {\n                result = await requestCallback(serverInfo, context);\n            }\n        }\n        else {\n            // With no token in the cache we use the request callback.\n            result = await requestCallback(serverInfo, context);\n        }\n        // Validate that the result returned by the callback is acceptable. If it is not\n        // we must clear the token result from the cache.\n        if (isCallbackResultInvalid(result)) {\n            this.cache.deleteEntry(connection.address, credentials.username, callbackHash);\n            throw new error_1.MongoMissingCredentialsError(CALLBACK_RESULT_ERROR);\n        }\n        // Cleanup the cache.\n        this.cache.deleteExpiredEntries();\n        // Put the new entry into the cache.\n        this.cache.addEntry(connection.address, credentials.username || '', callbackHash, result, serverInfo);\n        return result;\n    }\n}\nexports.CallbackWorkflow = CallbackWorkflow;\n/**\n * Generate the finishing command document for authentication. Will be a\n * saslStart or saslContinue depending on the presence of a conversation id.\n */\nfunction finishCommandDocument(token, conversationId) {\n    if (conversationId != null && typeof conversationId === 'number') {\n        return {\n            saslContinue: 1,\n            conversationId: conversationId,\n            payload: new bson_1.Binary(bson_1.BSON.serialize({ jwt: token }))\n        };\n    }\n    // saslContinue requires a conversationId in the command to be valid so in this\n    // case the server allows \"step two\" to actually be a saslStart with the token\n    // as the jwt since the use of the cached value has no correlating conversating\n    // on the particular connection.\n    return {\n        saslStart: 1,\n        mechanism: providers_1.AuthMechanism.MONGODB_OIDC,\n        payload: new bson_1.Binary(bson_1.BSON.serialize({ jwt: token }))\n    };\n}\n/**\n * Determines if a result returned from a request or refresh callback\n * function is invalid. This means the result is nullish, doesn't contain\n * the accessToken required field, and does not contain extra fields.\n */\nfunction isCallbackResultInvalid(tokenResult) {\n    if (tokenResult == null || typeof tokenResult !== 'object')\n        return true;\n    if (!('accessToken' in tokenResult))\n        return true;\n    return !Object.getOwnPropertyNames(tokenResult).every(prop => RESULT_PROPERTIES.includes(prop));\n}\n/**\n * Generate the saslStart command document.\n */\nfunction startCommandDocument(credentials) {\n    const payload = {};\n    if (credentials.username) {\n        payload.n = credentials.username;\n    }\n    return {\n        saslStart: 1,\n        autoAuthorize: 1,\n        mechanism: providers_1.AuthMechanism.MONGODB_OIDC,\n        payload: new bson_1.Binary(bson_1.BSON.serialize(payload))\n    };\n}\n//# sourceMappingURL=callback_workflow.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/callback_workflow.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/service_workflow.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/service_workflow.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.commandDocument = exports.ServiceWorkflow = void 0;\nconst bson_1 = __webpack_require__(/*! bson */ \"./node_modules/bson/lib/bson.cjs\");\nconst utils_1 = __webpack_require__(/*! ../../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst providers_1 = __webpack_require__(/*! ../providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\n/**\n * Common behaviour for OIDC device workflows.\n * @internal\n */\nclass ServiceWorkflow {\n    /**\n     * Execute the workflow. Looks for AWS_WEB_IDENTITY_TOKEN_FILE in the environment\n     * and then attempts to read the token from that path.\n     */\n    async execute(connection, credentials) {\n        const token = await this.getToken(credentials);\n        const command = commandDocument(token);\n        return connection.commandAsync((0, utils_1.ns)(credentials.source), command, undefined);\n    }\n    /**\n     * Get the document to add for speculative authentication.\n     */\n    async speculativeAuth(credentials) {\n        const token = await this.getToken(credentials);\n        const document = commandDocument(token);\n        document.db = credentials.source;\n        return { speculativeAuthenticate: document };\n    }\n}\nexports.ServiceWorkflow = ServiceWorkflow;\n/**\n * Create the saslStart command document.\n */\nfunction commandDocument(token) {\n    return {\n        saslStart: 1,\n        mechanism: providers_1.AuthMechanism.MONGODB_OIDC,\n        payload: bson_1.BSON.serialize({ jwt: token })\n    };\n}\nexports.commandDocument = commandDocument;\n//# sourceMappingURL=service_workflow.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/service_workflow.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/token_entry_cache.js":
/*!******************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/token_entry_cache.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TokenEntryCache = exports.TokenEntry = void 0;\nconst cache_1 = __webpack_require__(/*! ./cache */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/cache.js\");\n/* Default expiration is now for when no expiration provided */\nconst DEFAULT_EXPIRATION_SECS = 0;\n/** @internal */\nclass TokenEntry extends cache_1.ExpiringCacheEntry {\n    /**\n     * Instantiate the entry.\n     */\n    constructor(tokenResult, serverInfo, expiration) {\n        super(expiration);\n        this.tokenResult = tokenResult;\n        this.serverInfo = serverInfo;\n    }\n}\nexports.TokenEntry = TokenEntry;\n/**\n * Cache of OIDC token entries.\n * @internal\n */\nclass TokenEntryCache extends cache_1.Cache {\n    /**\n     * Set an entry in the token cache.\n     */\n    addEntry(address, username, callbackHash, tokenResult, serverInfo) {\n        const entry = new TokenEntry(tokenResult, serverInfo, tokenResult.expiresInSeconds ?? DEFAULT_EXPIRATION_SECS);\n        this.entries.set(this.cacheKey(address, username, callbackHash), entry);\n        return entry;\n    }\n    /**\n     * Delete an entry from the cache.\n     */\n    deleteEntry(address, username, callbackHash) {\n        this.entries.delete(this.cacheKey(address, username, callbackHash));\n    }\n    /**\n     * Get an entry from the cache.\n     */\n    getEntry(address, username, callbackHash) {\n        return this.entries.get(this.cacheKey(address, username, callbackHash));\n    }\n    /**\n     * Delete all expired entries from the cache.\n     */\n    deleteExpiredEntries() {\n        for (const [key, entry] of this.entries) {\n            if (!entry.isValid()) {\n                this.entries.delete(key);\n            }\n        }\n    }\n    /**\n     * Create a cache key from the address and username.\n     */\n    cacheKey(address, username, callbackHash) {\n        return this.hashedCacheKey(address, username, callbackHash);\n    }\n}\nexports.TokenEntryCache = TokenEntryCache;\n//# sourceMappingURL=token_entry_cache.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/token_entry_cache.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/plain.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/plain.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Plain = void 0;\nconst bson_1 = __webpack_require__(/*! ../../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst auth_provider_1 = __webpack_require__(/*! ./auth_provider */ \"./node_modules/mongodb/lib/cmap/auth/auth_provider.js\");\nclass Plain extends auth_provider_1.AuthProvider {\n    async auth(authContext) {\n        const { connection, credentials } = authContext;\n        if (!credentials) {\n            throw new error_1.MongoMissingCredentialsError('AuthContext must provide credentials.');\n        }\n        const { username, password } = credentials;\n        const payload = new bson_1.Binary(Buffer.from(`\\x00${username}\\x00${password}`));\n        const command = {\n            saslStart: 1,\n            mechanism: 'PLAIN',\n            payload: payload,\n            autoAuthorize: 1\n        };\n        await connection.commandAsync((0, utils_1.ns)('$external.$cmd'), command, undefined);\n    }\n}\nexports.Plain = Plain;\n//# sourceMappingURL=plain.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/auth/plain.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/providers.js":
/*!*********************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/providers.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AUTH_MECHS_AUTH_SRC_EXTERNAL = exports.AuthMechanism = void 0;\n/** @public */\nexports.AuthMechanism = Object.freeze({\n    MONGODB_AWS: 'MONGODB-AWS',\n    MONGODB_CR: 'MONGODB-CR',\n    MONGODB_DEFAULT: 'DEFAULT',\n    MONGODB_GSSAPI: 'GSSAPI',\n    MONGODB_PLAIN: 'PLAIN',\n    MONGODB_SCRAM_SHA1: 'SCRAM-SHA-1',\n    MONGODB_SCRAM_SHA256: 'SCRAM-SHA-256',\n    MONGODB_X509: 'MONGODB-X509',\n    /** @experimental */\n    MONGODB_OIDC: 'MONGODB-OIDC'\n});\n/** @internal */\nexports.AUTH_MECHS_AUTH_SRC_EXTERNAL = new Set([\n    exports.AuthMechanism.MONGODB_GSSAPI,\n    exports.AuthMechanism.MONGODB_AWS,\n    exports.AuthMechanism.MONGODB_OIDC,\n    exports.AuthMechanism.MONGODB_X509\n]);\n//# sourceMappingURL=providers.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/auth/providers.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/scram.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/scram.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ScramSHA256 = exports.ScramSHA1 = void 0;\nconst saslprep_1 = __webpack_require__(/*! @mongodb-js/saslprep */ \"./node_modules/@mongodb-js/saslprep/dist/index.js\");\nconst crypto = __webpack_require__(/*! crypto */ \"crypto\");\nconst util_1 = __webpack_require__(/*! util */ \"util\");\nconst bson_1 = __webpack_require__(/*! ../../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst auth_provider_1 = __webpack_require__(/*! ./auth_provider */ \"./node_modules/mongodb/lib/cmap/auth/auth_provider.js\");\nconst providers_1 = __webpack_require__(/*! ./providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\nclass ScramSHA extends auth_provider_1.AuthProvider {\n    constructor(cryptoMethod) {\n        super();\n        this.cryptoMethod = cryptoMethod || 'sha1';\n        this.randomBytesAsync = (0, util_1.promisify)(crypto.randomBytes);\n    }\n    async prepare(handshakeDoc, authContext) {\n        const cryptoMethod = this.cryptoMethod;\n        const credentials = authContext.credentials;\n        if (!credentials) {\n            throw new error_1.MongoMissingCredentialsError('AuthContext must provide credentials.');\n        }\n        const nonce = await this.randomBytesAsync(24);\n        // store the nonce for later use\n        authContext.nonce = nonce;\n        const request = {\n            ...handshakeDoc,\n            speculativeAuthenticate: {\n                ...makeFirstMessage(cryptoMethod, credentials, nonce),\n                db: credentials.source\n            }\n        };\n        return request;\n    }\n    async auth(authContext) {\n        const { reauthenticating, response } = authContext;\n        if (response?.speculativeAuthenticate && !reauthenticating) {\n            return continueScramConversation(this.cryptoMethod, response.speculativeAuthenticate, authContext);\n        }\n        return executeScram(this.cryptoMethod, authContext);\n    }\n}\nfunction cleanUsername(username) {\n    return username.replace('=', '=3D').replace(',', '=2C');\n}\nfunction clientFirstMessageBare(username, nonce) {\n    // NOTE: This is done b/c Javascript uses UTF-16, but the server is hashing in UTF-8.\n    // Since the username is not sasl-prep-d, we need to do this here.\n    return Buffer.concat([\n        Buffer.from('n=', 'utf8'),\n        Buffer.from(username, 'utf8'),\n        Buffer.from(',r=', 'utf8'),\n        Buffer.from(nonce.toString('base64'), 'utf8')\n    ]);\n}\nfunction makeFirstMessage(cryptoMethod, credentials, nonce) {\n    const username = cleanUsername(credentials.username);\n    const mechanism = cryptoMethod === 'sha1' ? providers_1.AuthMechanism.MONGODB_SCRAM_SHA1 : providers_1.AuthMechanism.MONGODB_SCRAM_SHA256;\n    // NOTE: This is done b/c Javascript uses UTF-16, but the server is hashing in UTF-8.\n    // Since the username is not sasl-prep-d, we need to do this here.\n    return {\n        saslStart: 1,\n        mechanism,\n        payload: new bson_1.Binary(Buffer.concat([Buffer.from('n,,', 'utf8'), clientFirstMessageBare(username, nonce)])),\n        autoAuthorize: 1,\n        options: { skipEmptyExchange: true }\n    };\n}\nasync function executeScram(cryptoMethod, authContext) {\n    const { connection, credentials } = authContext;\n    if (!credentials) {\n        throw new error_1.MongoMissingCredentialsError('AuthContext must provide credentials.');\n    }\n    if (!authContext.nonce) {\n        throw new error_1.MongoInvalidArgumentError('AuthContext must contain a valid nonce property');\n    }\n    const nonce = authContext.nonce;\n    const db = credentials.source;\n    const saslStartCmd = makeFirstMessage(cryptoMethod, credentials, nonce);\n    const response = await connection.commandAsync((0, utils_1.ns)(`${db}.$cmd`), saslStartCmd, undefined);\n    await continueScramConversation(cryptoMethod, response, authContext);\n}\nasync function continueScramConversation(cryptoMethod, response, authContext) {\n    const connection = authContext.connection;\n    const credentials = authContext.credentials;\n    if (!credentials) {\n        throw new error_1.MongoMissingCredentialsError('AuthContext must provide credentials.');\n    }\n    if (!authContext.nonce) {\n        throw new error_1.MongoInvalidArgumentError('Unable to continue SCRAM without valid nonce');\n    }\n    const nonce = authContext.nonce;\n    const db = credentials.source;\n    const username = cleanUsername(credentials.username);\n    const password = credentials.password;\n    const processedPassword = cryptoMethod === 'sha256' ? (0, saslprep_1.saslprep)(password) : passwordDigest(username, password);\n    const payload = Buffer.isBuffer(response.payload)\n        ? new bson_1.Binary(response.payload)\n        : response.payload;\n    const dict = parsePayload(payload);\n    const iterations = parseInt(dict.i, 10);\n    if (iterations && iterations < 4096) {\n        // TODO(NODE-3483)\n        throw new error_1.MongoRuntimeError(`Server returned an invalid iteration count ${iterations}`);\n    }\n    const salt = dict.s;\n    const rnonce = dict.r;\n    if (rnonce.startsWith('nonce')) {\n        // TODO(NODE-3483)\n        throw new error_1.MongoRuntimeError(`Server returned an invalid nonce: ${rnonce}`);\n    }\n    // Set up start of proof\n    const withoutProof = `c=biws,r=${rnonce}`;\n    const saltedPassword = HI(processedPassword, Buffer.from(salt, 'base64'), iterations, cryptoMethod);\n    const clientKey = HMAC(cryptoMethod, saltedPassword, 'Client Key');\n    const serverKey = HMAC(cryptoMethod, saltedPassword, 'Server Key');\n    const storedKey = H(cryptoMethod, clientKey);\n    const authMessage = [\n        clientFirstMessageBare(username, nonce),\n        payload.toString('utf8'),\n        withoutProof\n    ].join(',');\n    const clientSignature = HMAC(cryptoMethod, storedKey, authMessage);\n    const clientProof = `p=${xor(clientKey, clientSignature)}`;\n    const clientFinal = [withoutProof, clientProof].join(',');\n    const serverSignature = HMAC(cryptoMethod, serverKey, authMessage);\n    const saslContinueCmd = {\n        saslContinue: 1,\n        conversationId: response.conversationId,\n        payload: new bson_1.Binary(Buffer.from(clientFinal))\n    };\n    const r = await connection.commandAsync((0, utils_1.ns)(`${db}.$cmd`), saslContinueCmd, undefined);\n    const parsedResponse = parsePayload(r.payload);\n    if (!compareDigest(Buffer.from(parsedResponse.v, 'base64'), serverSignature)) {\n        throw new error_1.MongoRuntimeError('Server returned an invalid signature');\n    }\n    if (r.done !== false) {\n        // If the server sends r.done === true we can save one RTT\n        return;\n    }\n    const retrySaslContinueCmd = {\n        saslContinue: 1,\n        conversationId: r.conversationId,\n        payload: Buffer.alloc(0)\n    };\n    await connection.commandAsync((0, utils_1.ns)(`${db}.$cmd`), retrySaslContinueCmd, undefined);\n}\nfunction parsePayload(payload) {\n    const payloadStr = payload.toString('utf8');\n    const dict = {};\n    const parts = payloadStr.split(',');\n    for (let i = 0; i < parts.length; i++) {\n        const valueParts = parts[i].split('=');\n        dict[valueParts[0]] = valueParts[1];\n    }\n    return dict;\n}\nfunction passwordDigest(username, password) {\n    if (typeof username !== 'string') {\n        throw new error_1.MongoInvalidArgumentError('Username must be a string');\n    }\n    if (typeof password !== 'string') {\n        throw new error_1.MongoInvalidArgumentError('Password must be a string');\n    }\n    if (password.length === 0) {\n        throw new error_1.MongoInvalidArgumentError('Password cannot be empty');\n    }\n    let md5;\n    try {\n        md5 = crypto.createHash('md5');\n    }\n    catch (err) {\n        if (crypto.getFips()) {\n            // This error is (slightly) more helpful than what comes from OpenSSL directly, e.g.\n            // 'Error: error:060800C8:digital envelope routines:EVP_DigestInit_ex:disabled for FIPS'\n            throw new Error('Auth mechanism SCRAM-SHA-1 is not supported in FIPS mode');\n        }\n        throw err;\n    }\n    md5.update(`${username}:mongo:${password}`, 'utf8');\n    return md5.digest('hex');\n}\n// XOR two buffers\nfunction xor(a, b) {\n    if (!Buffer.isBuffer(a)) {\n        a = Buffer.from(a);\n    }\n    if (!Buffer.isBuffer(b)) {\n        b = Buffer.from(b);\n    }\n    const length = Math.max(a.length, b.length);\n    const res = [];\n    for (let i = 0; i < length; i += 1) {\n        res.push(a[i] ^ b[i]);\n    }\n    return Buffer.from(res).toString('base64');\n}\nfunction H(method, text) {\n    return crypto.createHash(method).update(text).digest();\n}\nfunction HMAC(method, key, text) {\n    return crypto.createHmac(method, key).update(text).digest();\n}\nlet _hiCache = {};\nlet _hiCacheCount = 0;\nfunction _hiCachePurge() {\n    _hiCache = {};\n    _hiCacheCount = 0;\n}\nconst hiLengthMap = {\n    sha256: 32,\n    sha1: 20\n};\nfunction HI(data, salt, iterations, cryptoMethod) {\n    // omit the work if already generated\n    const key = [data, salt.toString('base64'), iterations].join('_');\n    if (_hiCache[key] != null) {\n        return _hiCache[key];\n    }\n    // generate the salt\n    const saltedData = crypto.pbkdf2Sync(data, salt, iterations, hiLengthMap[cryptoMethod], cryptoMethod);\n    // cache a copy to speed up the next lookup, but prevent unbounded cache growth\n    if (_hiCacheCount >= 200) {\n        _hiCachePurge();\n    }\n    _hiCache[key] = saltedData;\n    _hiCacheCount += 1;\n    return saltedData;\n}\nfunction compareDigest(lhs, rhs) {\n    if (lhs.length !== rhs.length) {\n        return false;\n    }\n    if (typeof crypto.timingSafeEqual === 'function') {\n        return crypto.timingSafeEqual(lhs, rhs);\n    }\n    let result = 0;\n    for (let i = 0; i < lhs.length; i++) {\n        result |= lhs[i] ^ rhs[i];\n    }\n    return result === 0;\n}\nclass ScramSHA1 extends ScramSHA {\n    constructor() {\n        super('sha1');\n    }\n}\nexports.ScramSHA1 = ScramSHA1;\nclass ScramSHA256 extends ScramSHA {\n    constructor() {\n        super('sha256');\n    }\n}\nexports.ScramSHA256 = ScramSHA256;\n//# sourceMappingURL=scram.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/auth/scram.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/x509.js":
/*!****************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/x509.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.X509 = void 0;\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst auth_provider_1 = __webpack_require__(/*! ./auth_provider */ \"./node_modules/mongodb/lib/cmap/auth/auth_provider.js\");\nclass X509 extends auth_provider_1.AuthProvider {\n    async prepare(handshakeDoc, authContext) {\n        const { credentials } = authContext;\n        if (!credentials) {\n            throw new error_1.MongoMissingCredentialsError('AuthContext must provide credentials.');\n        }\n        return { ...handshakeDoc, speculativeAuthenticate: x509AuthenticateCommand(credentials) };\n    }\n    async auth(authContext) {\n        const connection = authContext.connection;\n        const credentials = authContext.credentials;\n        if (!credentials) {\n            throw new error_1.MongoMissingCredentialsError('AuthContext must provide credentials.');\n        }\n        const response = authContext.response;\n        if (response?.speculativeAuthenticate) {\n            return;\n        }\n        await connection.commandAsync((0, utils_1.ns)('$external.$cmd'), x509AuthenticateCommand(credentials), undefined);\n    }\n}\nexports.X509 = X509;\nfunction x509AuthenticateCommand(credentials) {\n    const command = { authenticate: 1, mechanism: 'MONGODB-X509' };\n    if (credentials.username) {\n        command.user = credentials.username;\n    }\n    return command;\n}\n//# sourceMappingURL=x509.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/auth/x509.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/command_monitoring_events.js":
/*!********************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/command_monitoring_events.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SENSITIVE_COMMANDS = exports.CommandFailedEvent = exports.CommandSucceededEvent = exports.CommandStartedEvent = void 0;\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst commands_1 = __webpack_require__(/*! ./commands */ \"./node_modules/mongodb/lib/cmap/commands.js\");\n/**\n * An event indicating the start of a given command\n * @public\n * @category Event\n */\nclass CommandStartedEvent {\n    /**\n     * Create a started event\n     *\n     * @internal\n     * @param pool - the pool that originated the command\n     * @param command - the command\n     */\n    constructor(connection, command) {\n        /** @internal */\n        this.name = constants_1.COMMAND_STARTED;\n        const cmd = extractCommand(command);\n        const commandName = extractCommandName(cmd);\n        const { address, connectionId, serviceId } = extractConnectionDetails(connection);\n        // TODO: remove in major revision, this is not spec behavior\n        if (exports.SENSITIVE_COMMANDS.has(commandName)) {\n            this.commandObj = {};\n            this.commandObj[commandName] = true;\n        }\n        this.address = address;\n        this.connectionId = connectionId;\n        this.serviceId = serviceId;\n        this.requestId = command.requestId;\n        this.databaseName = command.databaseName;\n        this.commandName = commandName;\n        this.command = maybeRedact(commandName, cmd, cmd);\n    }\n    /* @internal */\n    get hasServiceId() {\n        return !!this.serviceId;\n    }\n}\nexports.CommandStartedEvent = CommandStartedEvent;\n/**\n * An event indicating the success of a given command\n * @public\n * @category Event\n */\nclass CommandSucceededEvent {\n    /**\n     * Create a succeeded event\n     *\n     * @internal\n     * @param pool - the pool that originated the command\n     * @param command - the command\n     * @param reply - the reply for this command from the server\n     * @param started - a high resolution tuple timestamp of when the command was first sent, to calculate duration\n     */\n    constructor(connection, command, reply, started) {\n        /** @internal */\n        this.name = constants_1.COMMAND_SUCCEEDED;\n        const cmd = extractCommand(command);\n        const commandName = extractCommandName(cmd);\n        const { address, connectionId, serviceId } = extractConnectionDetails(connection);\n        this.address = address;\n        this.connectionId = connectionId;\n        this.serviceId = serviceId;\n        this.requestId = command.requestId;\n        this.commandName = commandName;\n        this.duration = (0, utils_1.calculateDurationInMs)(started);\n        this.reply = maybeRedact(commandName, cmd, extractReply(command, reply));\n    }\n    /* @internal */\n    get hasServiceId() {\n        return !!this.serviceId;\n    }\n}\nexports.CommandSucceededEvent = CommandSucceededEvent;\n/**\n * An event indicating the failure of a given command\n * @public\n * @category Event\n */\nclass CommandFailedEvent {\n    /**\n     * Create a failure event\n     *\n     * @internal\n     * @param pool - the pool that originated the command\n     * @param command - the command\n     * @param error - the generated error or a server error response\n     * @param started - a high resolution tuple timestamp of when the command was first sent, to calculate duration\n     */\n    constructor(connection, command, error, started) {\n        /** @internal */\n        this.name = constants_1.COMMAND_FAILED;\n        const cmd = extractCommand(command);\n        const commandName = extractCommandName(cmd);\n        const { address, connectionId, serviceId } = extractConnectionDetails(connection);\n        this.address = address;\n        this.connectionId = connectionId;\n        this.serviceId = serviceId;\n        this.requestId = command.requestId;\n        this.commandName = commandName;\n        this.duration = (0, utils_1.calculateDurationInMs)(started);\n        this.failure = maybeRedact(commandName, cmd, error);\n    }\n    /* @internal */\n    get hasServiceId() {\n        return !!this.serviceId;\n    }\n}\nexports.CommandFailedEvent = CommandFailedEvent;\n/**\n * Commands that we want to redact because of the sensitive nature of their contents\n * @internal\n */\nexports.SENSITIVE_COMMANDS = new Set([\n    'authenticate',\n    'saslStart',\n    'saslContinue',\n    'getnonce',\n    'createUser',\n    'updateUser',\n    'copydbgetnonce',\n    'copydbsaslstart',\n    'copydb'\n]);\nconst HELLO_COMMANDS = new Set(['hello', constants_1.LEGACY_HELLO_COMMAND, constants_1.LEGACY_HELLO_COMMAND_CAMEL_CASE]);\n// helper methods\nconst extractCommandName = (commandDoc) => Object.keys(commandDoc)[0];\nconst namespace = (command) => command.ns;\nconst collectionName = (command) => command.ns.split('.')[1];\nconst maybeRedact = (commandName, commandDoc, result) => exports.SENSITIVE_COMMANDS.has(commandName) ||\n    (HELLO_COMMANDS.has(commandName) && commandDoc.speculativeAuthenticate)\n    ? {}\n    : result;\nconst LEGACY_FIND_QUERY_MAP = {\n    $query: 'filter',\n    $orderby: 'sort',\n    $hint: 'hint',\n    $comment: 'comment',\n    $maxScan: 'maxScan',\n    $max: 'max',\n    $min: 'min',\n    $returnKey: 'returnKey',\n    $showDiskLoc: 'showRecordId',\n    $maxTimeMS: 'maxTimeMS',\n    $snapshot: 'snapshot'\n};\nconst LEGACY_FIND_OPTIONS_MAP = {\n    numberToSkip: 'skip',\n    numberToReturn: 'batchSize',\n    returnFieldSelector: 'projection'\n};\nconst OP_QUERY_KEYS = [\n    'tailable',\n    'oplogReplay',\n    'noCursorTimeout',\n    'awaitData',\n    'partial',\n    'exhaust'\n];\n/** Extract the actual command from the query, possibly up-converting if it's a legacy format */\nfunction extractCommand(command) {\n    if (command instanceof commands_1.OpMsgRequest) {\n        return (0, utils_1.deepCopy)(command.command);\n    }\n    if (command.query?.$query) {\n        let result;\n        if (command.ns === 'admin.$cmd') {\n            // up-convert legacy command\n            result = Object.assign({}, command.query.$query);\n        }\n        else {\n            // up-convert legacy find command\n            result = { find: collectionName(command) };\n            Object.keys(LEGACY_FIND_QUERY_MAP).forEach(key => {\n                if (command.query[key] != null) {\n                    result[LEGACY_FIND_QUERY_MAP[key]] = (0, utils_1.deepCopy)(command.query[key]);\n                }\n            });\n        }\n        Object.keys(LEGACY_FIND_OPTIONS_MAP).forEach(key => {\n            const legacyKey = key;\n            if (command[legacyKey] != null) {\n                result[LEGACY_FIND_OPTIONS_MAP[legacyKey]] = (0, utils_1.deepCopy)(command[legacyKey]);\n            }\n        });\n        OP_QUERY_KEYS.forEach(key => {\n            if (command[key]) {\n                result[key] = command[key];\n            }\n        });\n        if (command.pre32Limit != null) {\n            result.limit = command.pre32Limit;\n        }\n        if (command.query.$explain) {\n            return { explain: result };\n        }\n        return result;\n    }\n    const clonedQuery = {};\n    const clonedCommand = {};\n    if (command.query) {\n        for (const k in command.query) {\n            clonedQuery[k] = (0, utils_1.deepCopy)(command.query[k]);\n        }\n        clonedCommand.query = clonedQuery;\n    }\n    for (const k in command) {\n        if (k === 'query')\n            continue;\n        clonedCommand[k] = (0, utils_1.deepCopy)(command[k]);\n    }\n    return command.query ? clonedQuery : clonedCommand;\n}\nfunction extractReply(command, reply) {\n    if (!reply) {\n        return reply;\n    }\n    if (command instanceof commands_1.OpMsgRequest) {\n        return (0, utils_1.deepCopy)(reply.result ? reply.result : reply);\n    }\n    // is this a legacy find command?\n    if (command.query && command.query.$query != null) {\n        return {\n            ok: 1,\n            cursor: {\n                id: (0, utils_1.deepCopy)(reply.cursorId),\n                ns: namespace(command),\n                firstBatch: (0, utils_1.deepCopy)(reply.documents)\n            }\n        };\n    }\n    return (0, utils_1.deepCopy)(reply.result ? reply.result : reply);\n}\nfunction extractConnectionDetails(connection) {\n    let connectionId;\n    if ('id' in connection) {\n        connectionId = connection.id;\n    }\n    return {\n        address: connection.address,\n        serviceId: connection.serviceId,\n        connectionId\n    };\n}\n//# sourceMappingURL=command_monitoring_events.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/command_monitoring_events.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/commands.js":
/*!***************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/commands.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.OpCompressedRequest = exports.OpMsgResponse = exports.OpMsgRequest = exports.OpQueryResponse = exports.OpQueryRequest = void 0;\nconst BSON = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_preference_1 = __webpack_require__(/*! ../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst compression_1 = __webpack_require__(/*! ./wire_protocol/compression */ \"./node_modules/mongodb/lib/cmap/wire_protocol/compression.js\");\nconst constants_1 = __webpack_require__(/*! ./wire_protocol/constants */ \"./node_modules/mongodb/lib/cmap/wire_protocol/constants.js\");\n// Incrementing request id\nlet _requestId = 0;\n// Query flags\nconst OPTS_TAILABLE_CURSOR = 2;\nconst OPTS_SECONDARY = 4;\nconst OPTS_OPLOG_REPLAY = 8;\nconst OPTS_NO_CURSOR_TIMEOUT = 16;\nconst OPTS_AWAIT_DATA = 32;\nconst OPTS_EXHAUST = 64;\nconst OPTS_PARTIAL = 128;\n// Response flags\nconst CURSOR_NOT_FOUND = 1;\nconst QUERY_FAILURE = 2;\nconst SHARD_CONFIG_STALE = 4;\nconst AWAIT_CAPABLE = 8;\n/**************************************************************\n * QUERY\n **************************************************************/\n/** @internal */\nclass OpQueryRequest {\n    constructor(databaseName, query, options) {\n        this.databaseName = databaseName;\n        this.query = query;\n        // Basic options needed to be passed in\n        // TODO(NODE-3483): Replace with MongoCommandError\n        const ns = `${databaseName}.$cmd`;\n        if (typeof databaseName !== 'string') {\n            throw new error_1.MongoRuntimeError('Database name must be a string for a query');\n        }\n        // TODO(NODE-3483): Replace with MongoCommandError\n        if (query == null)\n            throw new error_1.MongoRuntimeError('A query document must be specified for query');\n        // Validate that we are not passing 0x00 in the collection name\n        if (ns.indexOf('\\x00') !== -1) {\n            // TODO(NODE-3483): Use MongoNamespace static method\n            throw new error_1.MongoRuntimeError('Namespace cannot contain a null character');\n        }\n        // Basic options\n        this.ns = ns;\n        // Additional options\n        this.numberToSkip = options.numberToSkip || 0;\n        this.numberToReturn = options.numberToReturn || 0;\n        this.returnFieldSelector = options.returnFieldSelector || undefined;\n        this.requestId = options.requestId ?? OpQueryRequest.getRequestId();\n        // special case for pre-3.2 find commands, delete ASAP\n        this.pre32Limit = options.pre32Limit;\n        // Serialization option\n        this.serializeFunctions =\n            typeof options.serializeFunctions === 'boolean' ? options.serializeFunctions : false;\n        this.ignoreUndefined =\n            typeof options.ignoreUndefined === 'boolean' ? options.ignoreUndefined : false;\n        this.maxBsonSize = options.maxBsonSize || 1024 * 1024 * 16;\n        this.checkKeys = typeof options.checkKeys === 'boolean' ? options.checkKeys : false;\n        this.batchSize = this.numberToReturn;\n        // Flags\n        this.tailable = false;\n        this.secondaryOk = typeof options.secondaryOk === 'boolean' ? options.secondaryOk : false;\n        this.oplogReplay = false;\n        this.noCursorTimeout = false;\n        this.awaitData = false;\n        this.exhaust = false;\n        this.partial = false;\n    }\n    /** Assign next request Id. */\n    incRequestId() {\n        this.requestId = _requestId++;\n    }\n    /** Peek next request Id. */\n    nextRequestId() {\n        return _requestId + 1;\n    }\n    /** Increment then return next request Id. */\n    static getRequestId() {\n        return ++_requestId;\n    }\n    // Uses a single allocated buffer for the process, avoiding multiple memory allocations\n    toBin() {\n        const buffers = [];\n        let projection = null;\n        // Set up the flags\n        let flags = 0;\n        if (this.tailable) {\n            flags |= OPTS_TAILABLE_CURSOR;\n        }\n        if (this.secondaryOk) {\n            flags |= OPTS_SECONDARY;\n        }\n        if (this.oplogReplay) {\n            flags |= OPTS_OPLOG_REPLAY;\n        }\n        if (this.noCursorTimeout) {\n            flags |= OPTS_NO_CURSOR_TIMEOUT;\n        }\n        if (this.awaitData) {\n            flags |= OPTS_AWAIT_DATA;\n        }\n        if (this.exhaust) {\n            flags |= OPTS_EXHAUST;\n        }\n        if (this.partial) {\n            flags |= OPTS_PARTIAL;\n        }\n        // If batchSize is different to this.numberToReturn\n        if (this.batchSize !== this.numberToReturn)\n            this.numberToReturn = this.batchSize;\n        // Allocate write protocol header buffer\n        const header = Buffer.alloc(4 * 4 + // Header\n            4 + // Flags\n            Buffer.byteLength(this.ns) +\n            1 + // namespace\n            4 + // numberToSkip\n            4 // numberToReturn\n        );\n        // Add header to buffers\n        buffers.push(header);\n        // Serialize the query\n        const query = BSON.serialize(this.query, {\n            checkKeys: this.checkKeys,\n            serializeFunctions: this.serializeFunctions,\n            ignoreUndefined: this.ignoreUndefined\n        });\n        // Add query document\n        buffers.push(query);\n        if (this.returnFieldSelector && Object.keys(this.returnFieldSelector).length > 0) {\n            // Serialize the projection document\n            projection = BSON.serialize(this.returnFieldSelector, {\n                checkKeys: this.checkKeys,\n                serializeFunctions: this.serializeFunctions,\n                ignoreUndefined: this.ignoreUndefined\n            });\n            // Add projection document\n            buffers.push(projection);\n        }\n        // Total message size\n        const totalLength = header.length + query.length + (projection ? projection.length : 0);\n        // Set up the index\n        let index = 4;\n        // Write total document length\n        header[3] = (totalLength >> 24) & 0xff;\n        header[2] = (totalLength >> 16) & 0xff;\n        header[1] = (totalLength >> 8) & 0xff;\n        header[0] = totalLength & 0xff;\n        // Write header information requestId\n        header[index + 3] = (this.requestId >> 24) & 0xff;\n        header[index + 2] = (this.requestId >> 16) & 0xff;\n        header[index + 1] = (this.requestId >> 8) & 0xff;\n        header[index] = this.requestId & 0xff;\n        index = index + 4;\n        // Write header information responseTo\n        header[index + 3] = (0 >> 24) & 0xff;\n        header[index + 2] = (0 >> 16) & 0xff;\n        header[index + 1] = (0 >> 8) & 0xff;\n        header[index] = 0 & 0xff;\n        index = index + 4;\n        // Write header information OP_QUERY\n        header[index + 3] = (constants_1.OP_QUERY >> 24) & 0xff;\n        header[index + 2] = (constants_1.OP_QUERY >> 16) & 0xff;\n        header[index + 1] = (constants_1.OP_QUERY >> 8) & 0xff;\n        header[index] = constants_1.OP_QUERY & 0xff;\n        index = index + 4;\n        // Write header information flags\n        header[index + 3] = (flags >> 24) & 0xff;\n        header[index + 2] = (flags >> 16) & 0xff;\n        header[index + 1] = (flags >> 8) & 0xff;\n        header[index] = flags & 0xff;\n        index = index + 4;\n        // Write collection name\n        index = index + header.write(this.ns, index, 'utf8') + 1;\n        header[index - 1] = 0;\n        // Write header information flags numberToSkip\n        header[index + 3] = (this.numberToSkip >> 24) & 0xff;\n        header[index + 2] = (this.numberToSkip >> 16) & 0xff;\n        header[index + 1] = (this.numberToSkip >> 8) & 0xff;\n        header[index] = this.numberToSkip & 0xff;\n        index = index + 4;\n        // Write header information flags numberToReturn\n        header[index + 3] = (this.numberToReturn >> 24) & 0xff;\n        header[index + 2] = (this.numberToReturn >> 16) & 0xff;\n        header[index + 1] = (this.numberToReturn >> 8) & 0xff;\n        header[index] = this.numberToReturn & 0xff;\n        index = index + 4;\n        // Return the buffers\n        return buffers;\n    }\n}\nexports.OpQueryRequest = OpQueryRequest;\n/** @internal */\nclass OpQueryResponse {\n    constructor(message, msgHeader, msgBody, opts) {\n        this.documents = new Array(0);\n        this.parsed = false;\n        this.raw = message;\n        this.data = msgBody;\n        this.opts = opts ?? {\n            useBigInt64: false,\n            promoteLongs: true,\n            promoteValues: true,\n            promoteBuffers: false,\n            bsonRegExp: false\n        };\n        // Read the message header\n        this.length = msgHeader.length;\n        this.requestId = msgHeader.requestId;\n        this.responseTo = msgHeader.responseTo;\n        this.opCode = msgHeader.opCode;\n        this.fromCompressed = msgHeader.fromCompressed;\n        // Flag values\n        this.useBigInt64 = typeof this.opts.useBigInt64 === 'boolean' ? this.opts.useBigInt64 : false;\n        this.promoteLongs = typeof this.opts.promoteLongs === 'boolean' ? this.opts.promoteLongs : true;\n        this.promoteValues =\n            typeof this.opts.promoteValues === 'boolean' ? this.opts.promoteValues : true;\n        this.promoteBuffers =\n            typeof this.opts.promoteBuffers === 'boolean' ? this.opts.promoteBuffers : false;\n        this.bsonRegExp = typeof this.opts.bsonRegExp === 'boolean' ? this.opts.bsonRegExp : false;\n    }\n    isParsed() {\n        return this.parsed;\n    }\n    parse(options) {\n        // Don't parse again if not needed\n        if (this.parsed)\n            return;\n        options = options ?? {};\n        // Allow the return of raw documents instead of parsing\n        const raw = options.raw || false;\n        const documentsReturnedIn = options.documentsReturnedIn || null;\n        const useBigInt64 = options.useBigInt64 ?? this.opts.useBigInt64;\n        const promoteLongs = options.promoteLongs ?? this.opts.promoteLongs;\n        const promoteValues = options.promoteValues ?? this.opts.promoteValues;\n        const promoteBuffers = options.promoteBuffers ?? this.opts.promoteBuffers;\n        const bsonRegExp = options.bsonRegExp ?? this.opts.bsonRegExp;\n        let bsonSize;\n        // Set up the options\n        const _options = {\n            useBigInt64,\n            promoteLongs,\n            promoteValues,\n            promoteBuffers,\n            bsonRegExp\n        };\n        // Position within OP_REPLY at which documents start\n        // (See https://www.mongodb.com/docs/manual/reference/mongodb-wire-protocol/#wire-op-reply)\n        this.index = 20;\n        // Read the message body\n        this.responseFlags = this.data.readInt32LE(0);\n        this.cursorId = new BSON.Long(this.data.readInt32LE(4), this.data.readInt32LE(8));\n        this.startingFrom = this.data.readInt32LE(12);\n        this.numberReturned = this.data.readInt32LE(16);\n        // Preallocate document array\n        this.documents = new Array(this.numberReturned);\n        this.cursorNotFound = (this.responseFlags & CURSOR_NOT_FOUND) !== 0;\n        this.queryFailure = (this.responseFlags & QUERY_FAILURE) !== 0;\n        this.shardConfigStale = (this.responseFlags & SHARD_CONFIG_STALE) !== 0;\n        this.awaitCapable = (this.responseFlags & AWAIT_CAPABLE) !== 0;\n        // Parse Body\n        for (let i = 0; i < this.numberReturned; i++) {\n            bsonSize =\n                this.data[this.index] |\n                    (this.data[this.index + 1] << 8) |\n                    (this.data[this.index + 2] << 16) |\n                    (this.data[this.index + 3] << 24);\n            // If we have raw results specified slice the return document\n            if (raw) {\n                this.documents[i] = this.data.slice(this.index, this.index + bsonSize);\n            }\n            else {\n                this.documents[i] = BSON.deserialize(this.data.slice(this.index, this.index + bsonSize), _options);\n            }\n            // Adjust the index\n            this.index = this.index + bsonSize;\n        }\n        if (this.documents.length === 1 && documentsReturnedIn != null && raw) {\n            const fieldsAsRaw = {};\n            fieldsAsRaw[documentsReturnedIn] = true;\n            _options.fieldsAsRaw = fieldsAsRaw;\n            const doc = BSON.deserialize(this.documents[0], _options);\n            this.documents = [doc];\n        }\n        // Set parsed\n        this.parsed = true;\n    }\n}\nexports.OpQueryResponse = OpQueryResponse;\n// Implementation of OP_MSG spec:\n// https://github.com/mongodb/specifications/blob/master/source/message/OP_MSG.rst\n//\n// struct Section {\n//   uint8 payloadType;\n//   union payload {\n//       document  document; // payloadType == 0\n//       struct sequence { // payloadType == 1\n//           int32      size;\n//           cstring    identifier;\n//           document*  documents;\n//       };\n//   };\n// };\n// struct OP_MSG {\n//   struct MsgHeader {\n//       int32  messageLength;\n//       int32  requestID;\n//       int32  responseTo;\n//       int32  opCode = 2013;\n//   };\n//   uint32      flagBits;\n//   Section+    sections;\n//   [uint32     checksum;]\n// };\n// Msg Flags\nconst OPTS_CHECKSUM_PRESENT = 1;\nconst OPTS_MORE_TO_COME = 2;\nconst OPTS_EXHAUST_ALLOWED = 1 << 16;\n/** @internal */\nclass OpMsgRequest {\n    constructor(databaseName, command, options) {\n        this.databaseName = databaseName;\n        this.command = command;\n        this.options = options;\n        // Basic options needed to be passed in\n        if (command == null)\n            throw new error_1.MongoInvalidArgumentError('Query document must be specified for query');\n        // Basic options\n        this.command.$db = databaseName;\n        if (options.readPreference && options.readPreference.mode !== read_preference_1.ReadPreference.PRIMARY) {\n            this.command.$readPreference = options.readPreference.toJSON();\n        }\n        // Ensure empty options\n        this.options = options ?? {};\n        // Additional options\n        this.requestId = options.requestId ? options.requestId : OpMsgRequest.getRequestId();\n        // Serialization option\n        this.serializeFunctions =\n            typeof options.serializeFunctions === 'boolean' ? options.serializeFunctions : false;\n        this.ignoreUndefined =\n            typeof options.ignoreUndefined === 'boolean' ? options.ignoreUndefined : false;\n        this.checkKeys = typeof options.checkKeys === 'boolean' ? options.checkKeys : false;\n        this.maxBsonSize = options.maxBsonSize || 1024 * 1024 * 16;\n        // flags\n        this.checksumPresent = false;\n        this.moreToCome = options.moreToCome || false;\n        this.exhaustAllowed =\n            typeof options.exhaustAllowed === 'boolean' ? options.exhaustAllowed : false;\n    }\n    toBin() {\n        const buffers = [];\n        let flags = 0;\n        if (this.checksumPresent) {\n            flags |= OPTS_CHECKSUM_PRESENT;\n        }\n        if (this.moreToCome) {\n            flags |= OPTS_MORE_TO_COME;\n        }\n        if (this.exhaustAllowed) {\n            flags |= OPTS_EXHAUST_ALLOWED;\n        }\n        const header = Buffer.alloc(4 * 4 + // Header\n            4 // Flags\n        );\n        buffers.push(header);\n        let totalLength = header.length;\n        const command = this.command;\n        totalLength += this.makeDocumentSegment(buffers, command);\n        header.writeInt32LE(totalLength, 0); // messageLength\n        header.writeInt32LE(this.requestId, 4); // requestID\n        header.writeInt32LE(0, 8); // responseTo\n        header.writeInt32LE(constants_1.OP_MSG, 12); // opCode\n        header.writeUInt32LE(flags, 16); // flags\n        return buffers;\n    }\n    makeDocumentSegment(buffers, document) {\n        const payloadTypeBuffer = Buffer.alloc(1);\n        payloadTypeBuffer[0] = 0;\n        const documentBuffer = this.serializeBson(document);\n        buffers.push(payloadTypeBuffer);\n        buffers.push(documentBuffer);\n        return payloadTypeBuffer.length + documentBuffer.length;\n    }\n    serializeBson(document) {\n        return BSON.serialize(document, {\n            checkKeys: this.checkKeys,\n            serializeFunctions: this.serializeFunctions,\n            ignoreUndefined: this.ignoreUndefined\n        });\n    }\n    static getRequestId() {\n        _requestId = (_requestId + 1) & 0x7fffffff;\n        return _requestId;\n    }\n}\nexports.OpMsgRequest = OpMsgRequest;\n/** @internal */\nclass OpMsgResponse {\n    constructor(message, msgHeader, msgBody, opts) {\n        this.parsed = false;\n        this.raw = message;\n        this.data = msgBody;\n        this.opts = opts ?? {\n            useBigInt64: false,\n            promoteLongs: true,\n            promoteValues: true,\n            promoteBuffers: false,\n            bsonRegExp: false\n        };\n        // Read the message header\n        this.length = msgHeader.length;\n        this.requestId = msgHeader.requestId;\n        this.responseTo = msgHeader.responseTo;\n        this.opCode = msgHeader.opCode;\n        this.fromCompressed = msgHeader.fromCompressed;\n        // Read response flags\n        this.responseFlags = msgBody.readInt32LE(0);\n        this.checksumPresent = (this.responseFlags & OPTS_CHECKSUM_PRESENT) !== 0;\n        this.moreToCome = (this.responseFlags & OPTS_MORE_TO_COME) !== 0;\n        this.exhaustAllowed = (this.responseFlags & OPTS_EXHAUST_ALLOWED) !== 0;\n        this.useBigInt64 = typeof this.opts.useBigInt64 === 'boolean' ? this.opts.useBigInt64 : false;\n        this.promoteLongs = typeof this.opts.promoteLongs === 'boolean' ? this.opts.promoteLongs : true;\n        this.promoteValues =\n            typeof this.opts.promoteValues === 'boolean' ? this.opts.promoteValues : true;\n        this.promoteBuffers =\n            typeof this.opts.promoteBuffers === 'boolean' ? this.opts.promoteBuffers : false;\n        this.bsonRegExp = typeof this.opts.bsonRegExp === 'boolean' ? this.opts.bsonRegExp : false;\n        this.documents = [];\n    }\n    isParsed() {\n        return this.parsed;\n    }\n    parse(options) {\n        // Don't parse again if not needed\n        if (this.parsed)\n            return;\n        options = options ?? {};\n        this.index = 4;\n        // Allow the return of raw documents instead of parsing\n        const raw = options.raw || false;\n        const documentsReturnedIn = options.documentsReturnedIn || null;\n        const useBigInt64 = options.useBigInt64 ?? this.opts.useBigInt64;\n        const promoteLongs = options.promoteLongs ?? this.opts.promoteLongs;\n        const promoteValues = options.promoteValues ?? this.opts.promoteValues;\n        const promoteBuffers = options.promoteBuffers ?? this.opts.promoteBuffers;\n        const bsonRegExp = options.bsonRegExp ?? this.opts.bsonRegExp;\n        const validation = this.parseBsonSerializationOptions(options);\n        // Set up the options\n        const bsonOptions = {\n            useBigInt64,\n            promoteLongs,\n            promoteValues,\n            promoteBuffers,\n            bsonRegExp,\n            validation\n            // Due to the strictness of the BSON libraries validation option we need this cast\n        };\n        while (this.index < this.data.length) {\n            const payloadType = this.data.readUInt8(this.index++);\n            if (payloadType === 0) {\n                const bsonSize = this.data.readUInt32LE(this.index);\n                const bin = this.data.slice(this.index, this.index + bsonSize);\n                this.documents.push(raw ? bin : BSON.deserialize(bin, bsonOptions));\n                this.index += bsonSize;\n            }\n            else if (payloadType === 1) {\n                // It was decided that no driver makes use of payload type 1\n                // TODO(NODE-3483): Replace with MongoDeprecationError\n                throw new error_1.MongoRuntimeError('OP_MSG Payload Type 1 detected unsupported protocol');\n            }\n        }\n        if (this.documents.length === 1 && documentsReturnedIn != null && raw) {\n            const fieldsAsRaw = {};\n            fieldsAsRaw[documentsReturnedIn] = true;\n            bsonOptions.fieldsAsRaw = fieldsAsRaw;\n            const doc = BSON.deserialize(this.documents[0], bsonOptions);\n            this.documents = [doc];\n        }\n        this.parsed = true;\n    }\n    parseBsonSerializationOptions({ enableUtf8Validation }) {\n        if (enableUtf8Validation === false) {\n            return { utf8: false };\n        }\n        return { utf8: { writeErrors: false } };\n    }\n}\nexports.OpMsgResponse = OpMsgResponse;\nconst MESSAGE_HEADER_SIZE = 16;\nconst COMPRESSION_DETAILS_SIZE = 9; // originalOpcode + uncompressedSize, compressorID\n/**\n * @internal\n *\n * An OP_COMPRESSED request wraps either an OP_QUERY or OP_MSG message.\n */\nclass OpCompressedRequest {\n    constructor(command, options) {\n        this.command = command;\n        this.options = options;\n    }\n    // Return whether a command contains an uncompressible command term\n    // Will return true if command contains no uncompressible command terms\n    static canCompress(command) {\n        const commandDoc = command instanceof OpMsgRequest ? command.command : command.query;\n        const commandName = Object.keys(commandDoc)[0];\n        return !compression_1.uncompressibleCommands.has(commandName);\n    }\n    async toBin() {\n        const concatenatedOriginalCommandBuffer = Buffer.concat(this.command.toBin());\n        // otherwise, compress the message\n        const messageToBeCompressed = concatenatedOriginalCommandBuffer.slice(MESSAGE_HEADER_SIZE);\n        // Extract information needed for OP_COMPRESSED from the uncompressed message\n        const originalCommandOpCode = concatenatedOriginalCommandBuffer.readInt32LE(12);\n        // Compress the message body\n        const compressedMessage = await (0, compression_1.compress)(this.options, messageToBeCompressed);\n        // Create the msgHeader of OP_COMPRESSED\n        const msgHeader = Buffer.alloc(MESSAGE_HEADER_SIZE);\n        msgHeader.writeInt32LE(MESSAGE_HEADER_SIZE + COMPRESSION_DETAILS_SIZE + compressedMessage.length, 0); // messageLength\n        msgHeader.writeInt32LE(this.command.requestId, 4); // requestID\n        msgHeader.writeInt32LE(0, 8); // responseTo (zero)\n        msgHeader.writeInt32LE(constants_1.OP_COMPRESSED, 12); // opCode\n        // Create the compression details of OP_COMPRESSED\n        const compressionDetails = Buffer.alloc(COMPRESSION_DETAILS_SIZE);\n        compressionDetails.writeInt32LE(originalCommandOpCode, 0); // originalOpcode\n        compressionDetails.writeInt32LE(messageToBeCompressed.length, 4); // Size of the uncompressed compressedMessage, excluding the MsgHeader\n        compressionDetails.writeUInt8(compression_1.Compressor[this.options.agreedCompressor], 8); // compressorID\n        return [msgHeader, compressionDetails, compressedMessage];\n    }\n}\nexports.OpCompressedRequest = OpCompressedRequest;\n//# sourceMappingURL=commands.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/commands.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/connect.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/connect.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.LEGAL_TCP_SOCKET_OPTIONS = exports.LEGAL_TLS_SOCKET_OPTIONS = exports.prepareHandshakeDocument = exports.connect = exports.AUTH_PROVIDERS = void 0;\nconst net = __webpack_require__(/*! net */ \"net\");\nconst tls = __webpack_require__(/*! tls */ \"tls\");\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst deps_1 = __webpack_require__(/*! ../deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst auth_provider_1 = __webpack_require__(/*! ./auth/auth_provider */ \"./node_modules/mongodb/lib/cmap/auth/auth_provider.js\");\nconst gssapi_1 = __webpack_require__(/*! ./auth/gssapi */ \"./node_modules/mongodb/lib/cmap/auth/gssapi.js\");\nconst mongocr_1 = __webpack_require__(/*! ./auth/mongocr */ \"./node_modules/mongodb/lib/cmap/auth/mongocr.js\");\nconst mongodb_aws_1 = __webpack_require__(/*! ./auth/mongodb_aws */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_aws.js\");\nconst mongodb_oidc_1 = __webpack_require__(/*! ./auth/mongodb_oidc */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc.js\");\nconst plain_1 = __webpack_require__(/*! ./auth/plain */ \"./node_modules/mongodb/lib/cmap/auth/plain.js\");\nconst providers_1 = __webpack_require__(/*! ./auth/providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\nconst scram_1 = __webpack_require__(/*! ./auth/scram */ \"./node_modules/mongodb/lib/cmap/auth/scram.js\");\nconst x509_1 = __webpack_require__(/*! ./auth/x509 */ \"./node_modules/mongodb/lib/cmap/auth/x509.js\");\nconst connection_1 = __webpack_require__(/*! ./connection */ \"./node_modules/mongodb/lib/cmap/connection.js\");\nconst constants_2 = __webpack_require__(/*! ./wire_protocol/constants */ \"./node_modules/mongodb/lib/cmap/wire_protocol/constants.js\");\n/** @internal */\nexports.AUTH_PROVIDERS = new Map([\n    [providers_1.AuthMechanism.MONGODB_AWS, new mongodb_aws_1.MongoDBAWS()],\n    [providers_1.AuthMechanism.MONGODB_CR, new mongocr_1.MongoCR()],\n    [providers_1.AuthMechanism.MONGODB_GSSAPI, new gssapi_1.GSSAPI()],\n    [providers_1.AuthMechanism.MONGODB_OIDC, new mongodb_oidc_1.MongoDBOIDC()],\n    [providers_1.AuthMechanism.MONGODB_PLAIN, new plain_1.Plain()],\n    [providers_1.AuthMechanism.MONGODB_SCRAM_SHA1, new scram_1.ScramSHA1()],\n    [providers_1.AuthMechanism.MONGODB_SCRAM_SHA256, new scram_1.ScramSHA256()],\n    [providers_1.AuthMechanism.MONGODB_X509, new x509_1.X509()]\n]);\nfunction connect(options, callback) {\n    makeConnection({ ...options, existingSocket: undefined }, (err, socket) => {\n        if (err || !socket) {\n            return callback(err);\n        }\n        let ConnectionType = options.connectionType ?? connection_1.Connection;\n        if (options.autoEncrypter) {\n            ConnectionType = connection_1.CryptoConnection;\n        }\n        const connection = new ConnectionType(socket, options);\n        performInitialHandshake(connection, options).then(() => callback(undefined, connection), error => {\n            connection.destroy({ force: false });\n            callback(error);\n        });\n    });\n}\nexports.connect = connect;\nfunction checkSupportedServer(hello, options) {\n    const maxWireVersion = Number(hello.maxWireVersion);\n    const minWireVersion = Number(hello.minWireVersion);\n    const serverVersionHighEnough = !Number.isNaN(maxWireVersion) && maxWireVersion >= constants_2.MIN_SUPPORTED_WIRE_VERSION;\n    const serverVersionLowEnough = !Number.isNaN(minWireVersion) && minWireVersion <= constants_2.MAX_SUPPORTED_WIRE_VERSION;\n    if (serverVersionHighEnough) {\n        if (serverVersionLowEnough) {\n            return null;\n        }\n        const message = `Server at ${options.hostAddress} reports minimum wire version ${JSON.stringify(hello.minWireVersion)}, but this version of the Node.js Driver requires at most ${constants_2.MAX_SUPPORTED_WIRE_VERSION} (MongoDB ${constants_2.MAX_SUPPORTED_SERVER_VERSION})`;\n        return new error_1.MongoCompatibilityError(message);\n    }\n    const message = `Server at ${options.hostAddress} reports maximum wire version ${JSON.stringify(hello.maxWireVersion) ?? 0}, but this version of the Node.js Driver requires at least ${constants_2.MIN_SUPPORTED_WIRE_VERSION} (MongoDB ${constants_2.MIN_SUPPORTED_SERVER_VERSION})`;\n    return new error_1.MongoCompatibilityError(message);\n}\nasync function performInitialHandshake(conn, options) {\n    const credentials = options.credentials;\n    if (credentials) {\n        if (!(credentials.mechanism === providers_1.AuthMechanism.MONGODB_DEFAULT) &&\n            !exports.AUTH_PROVIDERS.get(credentials.mechanism)) {\n            throw new error_1.MongoInvalidArgumentError(`AuthMechanism '${credentials.mechanism}' not supported`);\n        }\n    }\n    const authContext = new auth_provider_1.AuthContext(conn, credentials, options);\n    conn.authContext = authContext;\n    const handshakeDoc = await prepareHandshakeDocument(authContext);\n    // @ts-expect-error: TODO(NODE-5141): The options need to be filtered properly, Connection options differ from Command options\n    const handshakeOptions = { ...options };\n    if (typeof options.connectTimeoutMS === 'number') {\n        // The handshake technically is a monitoring check, so its socket timeout should be connectTimeoutMS\n        handshakeOptions.socketTimeoutMS = options.connectTimeoutMS;\n    }\n    const start = new Date().getTime();\n    const response = await conn.commandAsync((0, utils_1.ns)('admin.$cmd'), handshakeDoc, handshakeOptions);\n    if (!('isWritablePrimary' in response)) {\n        // Provide hello-style response document.\n        response.isWritablePrimary = response[constants_1.LEGACY_HELLO_COMMAND];\n    }\n    if (response.helloOk) {\n        conn.helloOk = true;\n    }\n    const supportedServerErr = checkSupportedServer(response, options);\n    if (supportedServerErr) {\n        throw supportedServerErr;\n    }\n    if (options.loadBalanced) {\n        if (!response.serviceId) {\n            throw new error_1.MongoCompatibilityError('Driver attempted to initialize in load balancing mode, ' +\n                'but the server does not support this mode.');\n        }\n    }\n    // NOTE: This is metadata attached to the connection while porting away from\n    //       handshake being done in the `Server` class. Likely, it should be\n    //       relocated, or at very least restructured.\n    conn.hello = response;\n    conn.lastHelloMS = new Date().getTime() - start;\n    if (!response.arbiterOnly && credentials) {\n        // store the response on auth context\n        authContext.response = response;\n        const resolvedCredentials = credentials.resolveAuthMechanism(response);\n        const provider = exports.AUTH_PROVIDERS.get(resolvedCredentials.mechanism);\n        if (!provider) {\n            throw new error_1.MongoInvalidArgumentError(`No AuthProvider for ${resolvedCredentials.mechanism} defined.`);\n        }\n        try {\n            await provider.auth(authContext);\n        }\n        catch (error) {\n            if (error instanceof error_1.MongoError) {\n                error.addErrorLabel(error_1.MongoErrorLabel.HandshakeError);\n                if ((0, error_1.needsRetryableWriteLabel)(error, response.maxWireVersion)) {\n                    error.addErrorLabel(error_1.MongoErrorLabel.RetryableWriteError);\n                }\n            }\n            throw error;\n        }\n    }\n}\n/**\n * @internal\n *\n * This function is only exposed for testing purposes.\n */\nasync function prepareHandshakeDocument(authContext) {\n    const options = authContext.options;\n    const compressors = options.compressors ? options.compressors : [];\n    const { serverApi } = authContext.connection;\n    const handshakeDoc = {\n        [serverApi?.version || options.loadBalanced === true ? 'hello' : constants_1.LEGACY_HELLO_COMMAND]: 1,\n        helloOk: true,\n        client: options.metadata,\n        compression: compressors\n    };\n    if (options.loadBalanced === true) {\n        handshakeDoc.loadBalanced = true;\n    }\n    const credentials = authContext.credentials;\n    if (credentials) {\n        if (credentials.mechanism === providers_1.AuthMechanism.MONGODB_DEFAULT && credentials.username) {\n            handshakeDoc.saslSupportedMechs = `${credentials.source}.${credentials.username}`;\n            const provider = exports.AUTH_PROVIDERS.get(providers_1.AuthMechanism.MONGODB_SCRAM_SHA256);\n            if (!provider) {\n                // This auth mechanism is always present.\n                throw new error_1.MongoInvalidArgumentError(`No AuthProvider for ${providers_1.AuthMechanism.MONGODB_SCRAM_SHA256} defined.`);\n            }\n            return provider.prepare(handshakeDoc, authContext);\n        }\n        const provider = exports.AUTH_PROVIDERS.get(credentials.mechanism);\n        if (!provider) {\n            throw new error_1.MongoInvalidArgumentError(`No AuthProvider for ${credentials.mechanism} defined.`);\n        }\n        return provider.prepare(handshakeDoc, authContext);\n    }\n    return handshakeDoc;\n}\nexports.prepareHandshakeDocument = prepareHandshakeDocument;\n/** @public */\nexports.LEGAL_TLS_SOCKET_OPTIONS = [\n    'ALPNProtocols',\n    'ca',\n    'cert',\n    'checkServerIdentity',\n    'ciphers',\n    'crl',\n    'ecdhCurve',\n    'key',\n    'minDHSize',\n    'passphrase',\n    'pfx',\n    'rejectUnauthorized',\n    'secureContext',\n    'secureProtocol',\n    'servername',\n    'session'\n];\n/** @public */\nexports.LEGAL_TCP_SOCKET_OPTIONS = [\n    'family',\n    'hints',\n    'localAddress',\n    'localPort',\n    'lookup'\n];\nfunction parseConnectOptions(options) {\n    const hostAddress = options.hostAddress;\n    if (!hostAddress)\n        throw new error_1.MongoInvalidArgumentError('Option \"hostAddress\" is required');\n    const result = {};\n    for (const name of exports.LEGAL_TCP_SOCKET_OPTIONS) {\n        if (options[name] != null) {\n            result[name] = options[name];\n        }\n    }\n    if (typeof hostAddress.socketPath === 'string') {\n        result.path = hostAddress.socketPath;\n        return result;\n    }\n    else if (typeof hostAddress.host === 'string') {\n        result.host = hostAddress.host;\n        result.port = hostAddress.port;\n        return result;\n    }\n    else {\n        // This should never happen since we set up HostAddresses\n        // But if we don't throw here the socket could hang until timeout\n        // TODO(NODE-3483)\n        throw new error_1.MongoRuntimeError(`Unexpected HostAddress ${JSON.stringify(hostAddress)}`);\n    }\n}\nfunction parseSslOptions(options) {\n    const result = parseConnectOptions(options);\n    // Merge in valid SSL options\n    for (const name of exports.LEGAL_TLS_SOCKET_OPTIONS) {\n        if (options[name] != null) {\n            result[name] = options[name];\n        }\n    }\n    if (options.existingSocket) {\n        result.socket = options.existingSocket;\n    }\n    // Set default sni servername to be the same as host\n    if (result.servername == null && result.host && !net.isIP(result.host)) {\n        result.servername = result.host;\n    }\n    return result;\n}\nconst SOCKET_ERROR_EVENT_LIST = ['error', 'close', 'timeout', 'parseError'];\nconst SOCKET_ERROR_EVENTS = new Set(SOCKET_ERROR_EVENT_LIST);\nfunction makeConnection(options, _callback) {\n    const useTLS = options.tls ?? false;\n    const noDelay = options.noDelay ?? true;\n    const connectTimeoutMS = options.connectTimeoutMS ?? 30000;\n    const rejectUnauthorized = options.rejectUnauthorized ?? true;\n    const existingSocket = options.existingSocket;\n    let socket;\n    const callback = function (err, ret) {\n        if (err && socket) {\n            socket.destroy();\n        }\n        _callback(err, ret);\n    };\n    if (options.proxyHost != null) {\n        // Currently, only Socks5 is supported.\n        return makeSocks5Connection({\n            ...options,\n            connectTimeoutMS // Should always be present for Socks5\n        }, callback);\n    }\n    if (useTLS) {\n        const tlsSocket = tls.connect(parseSslOptions(options));\n        if (typeof tlsSocket.disableRenegotiation === 'function') {\n            tlsSocket.disableRenegotiation();\n        }\n        socket = tlsSocket;\n    }\n    else if (existingSocket) {\n        // In the TLS case, parseSslOptions() sets options.socket to existingSocket,\n        // so we only need to handle the non-TLS case here (where existingSocket\n        // gives us all we need out of the box).\n        socket = existingSocket;\n    }\n    else {\n        socket = net.createConnection(parseConnectOptions(options));\n    }\n    socket.setKeepAlive(true, 300000);\n    socket.setTimeout(connectTimeoutMS);\n    socket.setNoDelay(noDelay);\n    const connectEvent = useTLS ? 'secureConnect' : 'connect';\n    let cancellationHandler;\n    function errorHandler(eventName) {\n        return (err) => {\n            SOCKET_ERROR_EVENTS.forEach(event => socket.removeAllListeners(event));\n            if (cancellationHandler && options.cancellationToken) {\n                options.cancellationToken.removeListener('cancel', cancellationHandler);\n            }\n            socket.removeListener(connectEvent, connectHandler);\n            callback(connectionFailureError(eventName, err));\n        };\n    }\n    function connectHandler() {\n        SOCKET_ERROR_EVENTS.forEach(event => socket.removeAllListeners(event));\n        if (cancellationHandler && options.cancellationToken) {\n            options.cancellationToken.removeListener('cancel', cancellationHandler);\n        }\n        if ('authorizationError' in socket) {\n            if (socket.authorizationError && rejectUnauthorized) {\n                // TODO(NODE-5192): wrap this with a MongoError subclass\n                return callback(socket.authorizationError);\n            }\n        }\n        socket.setTimeout(0);\n        callback(undefined, socket);\n    }\n    SOCKET_ERROR_EVENTS.forEach(event => socket.once(event, errorHandler(event)));\n    if (options.cancellationToken) {\n        cancellationHandler = errorHandler('cancel');\n        options.cancellationToken.once('cancel', cancellationHandler);\n    }\n    if (existingSocket) {\n        process.nextTick(connectHandler);\n    }\n    else {\n        socket.once(connectEvent, connectHandler);\n    }\n}\nlet socks = null;\nfunction loadSocks() {\n    if (socks == null) {\n        const socksImport = (0, deps_1.getSocks)();\n        if ('kModuleError' in socksImport) {\n            throw socksImport.kModuleError;\n        }\n        socks = socksImport;\n    }\n    return socks;\n}\nfunction makeSocks5Connection(options, callback) {\n    const hostAddress = utils_1.HostAddress.fromHostPort(options.proxyHost ?? '', // proxyHost is guaranteed to set here\n    options.proxyPort ?? 1080);\n    // First, connect to the proxy server itself:\n    makeConnection({\n        ...options,\n        hostAddress,\n        tls: false,\n        proxyHost: undefined\n    }, (err, rawSocket) => {\n        if (err || !rawSocket) {\n            return callback(err);\n        }\n        const destination = parseConnectOptions(options);\n        if (typeof destination.host !== 'string' || typeof destination.port !== 'number') {\n            return callback(new error_1.MongoInvalidArgumentError('Can only make Socks5 connections to TCP hosts'));\n        }\n        try {\n            socks ??= loadSocks();\n        }\n        catch (error) {\n            return callback(error);\n        }\n        // Then, establish the Socks5 proxy connection:\n        socks.SocksClient.createConnection({\n            existing_socket: rawSocket,\n            timeout: options.connectTimeoutMS,\n            command: 'connect',\n            destination: {\n                host: destination.host,\n                port: destination.port\n            },\n            proxy: {\n                // host and port are ignored because we pass existing_socket\n                host: 'iLoveJavaScript',\n                port: 0,\n                type: 5,\n                userId: options.proxyUsername || undefined,\n                password: options.proxyPassword || undefined\n            }\n        }).then(({ socket }) => {\n            // Finally, now treat the resulting duplex stream as the\n            // socket over which we send and receive wire protocol messages:\n            makeConnection({\n                ...options,\n                existingSocket: socket,\n                proxyHost: undefined\n            }, callback);\n        }, error => callback(connectionFailureError('error', error)));\n    });\n}\nfunction connectionFailureError(type, err) {\n    switch (type) {\n        case 'error':\n            return new error_1.MongoNetworkError(error_1.MongoError.buildErrorMessage(err), { cause: err });\n        case 'timeout':\n            return new error_1.MongoNetworkTimeoutError('connection timed out');\n        case 'close':\n            return new error_1.MongoNetworkError('connection closed');\n        case 'cancel':\n            return new error_1.MongoNetworkError('connection establishment was cancelled');\n        default:\n            return new error_1.MongoNetworkError('unknown network error');\n    }\n}\n//# sourceMappingURL=connect.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/connect.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/connection.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/connection.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.read = exports.readMany = exports.writeCommand = exports.readWireProtocolMessages = exports.ModernConnection = exports.hasSessionSupport = exports.CryptoConnection = exports.Connection = void 0;\nconst events_1 = __webpack_require__(/*! events */ \"events\");\nconst stream_1 = __webpack_require__(/*! stream */ \"stream\");\nconst timers_1 = __webpack_require__(/*! timers */ \"timers\");\nconst util_1 = __webpack_require__(/*! util */ \"util\");\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_types_1 = __webpack_require__(/*! ../mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst sessions_1 = __webpack_require__(/*! ../sessions */ \"./node_modules/mongodb/lib/sessions.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_monitoring_events_1 = __webpack_require__(/*! ./command_monitoring_events */ \"./node_modules/mongodb/lib/cmap/command_monitoring_events.js\");\nconst commands_1 = __webpack_require__(/*! ./commands */ \"./node_modules/mongodb/lib/cmap/commands.js\");\nconst message_stream_1 = __webpack_require__(/*! ./message_stream */ \"./node_modules/mongodb/lib/cmap/message_stream.js\");\nconst stream_description_1 = __webpack_require__(/*! ./stream_description */ \"./node_modules/mongodb/lib/cmap/stream_description.js\");\nconst compression_1 = __webpack_require__(/*! ./wire_protocol/compression */ \"./node_modules/mongodb/lib/cmap/wire_protocol/compression.js\");\nconst shared_1 = __webpack_require__(/*! ./wire_protocol/shared */ \"./node_modules/mongodb/lib/cmap/wire_protocol/shared.js\");\n/** @internal */\nconst kStream = Symbol('stream');\n/** @internal */\nconst kQueue = Symbol('queue');\n/** @internal */\nconst kMessageStream = Symbol('messageStream');\n/** @internal */\nconst kGeneration = Symbol('generation');\n/** @internal */\nconst kLastUseTime = Symbol('lastUseTime');\n/** @internal */\nconst kClusterTime = Symbol('clusterTime');\n/** @internal */\nconst kDescription = Symbol('description');\n/** @internal */\nconst kHello = Symbol('hello');\n/** @internal */\nconst kAutoEncrypter = Symbol('autoEncrypter');\n/** @internal */\nconst kDelayedTimeoutId = Symbol('delayedTimeoutId');\nconst INVALID_QUEUE_SIZE = 'Connection internal queue contains more than 1 operation description';\n/** @internal */\nclass Connection extends mongo_types_1.TypedEventEmitter {\n    constructor(stream, options) {\n        super();\n        this.commandAsync = (0, util_1.promisify)((ns, cmd, options, callback) => this.command(ns, cmd, options, callback));\n        this.id = options.id;\n        this.address = streamIdentifier(stream, options);\n        this.socketTimeoutMS = options.socketTimeoutMS ?? 0;\n        this.monitorCommands = options.monitorCommands;\n        this.serverApi = options.serverApi;\n        this.closed = false;\n        this[kHello] = null;\n        this[kClusterTime] = null;\n        this[kDescription] = new stream_description_1.StreamDescription(this.address, options);\n        this[kGeneration] = options.generation;\n        this[kLastUseTime] = (0, utils_1.now)();\n        // setup parser stream and message handling\n        this[kQueue] = new Map();\n        this[kMessageStream] = new message_stream_1.MessageStream({\n            ...options,\n            maxBsonMessageSize: this.hello?.maxBsonMessageSize\n        });\n        this[kStream] = stream;\n        this[kDelayedTimeoutId] = null;\n        this[kMessageStream].on('message', message => this.onMessage(message));\n        this[kMessageStream].on('error', error => this.onError(error));\n        this[kStream].on('close', () => this.onClose());\n        this[kStream].on('timeout', () => this.onTimeout());\n        this[kStream].on('error', () => {\n            /* ignore errors, listen to `close` instead */\n        });\n        // hook the message stream up to the passed in stream\n        this[kStream].pipe(this[kMessageStream]);\n        this[kMessageStream].pipe(this[kStream]);\n    }\n    get description() {\n        return this[kDescription];\n    }\n    get hello() {\n        return this[kHello];\n    }\n    // the `connect` method stores the result of the handshake hello on the connection\n    set hello(response) {\n        this[kDescription].receiveResponse(response);\n        this[kDescription] = Object.freeze(this[kDescription]);\n        // TODO: remove this, and only use the `StreamDescription` in the future\n        this[kHello] = response;\n    }\n    // Set the whether the message stream is for a monitoring connection.\n    set isMonitoringConnection(value) {\n        this[kMessageStream].isMonitoringConnection = value;\n    }\n    get isMonitoringConnection() {\n        return this[kMessageStream].isMonitoringConnection;\n    }\n    get serviceId() {\n        return this.hello?.serviceId;\n    }\n    get loadBalanced() {\n        return this.description.loadBalanced;\n    }\n    get generation() {\n        return this[kGeneration] || 0;\n    }\n    set generation(generation) {\n        this[kGeneration] = generation;\n    }\n    get idleTime() {\n        return (0, utils_1.calculateDurationInMs)(this[kLastUseTime]);\n    }\n    get clusterTime() {\n        return this[kClusterTime];\n    }\n    get stream() {\n        return this[kStream];\n    }\n    markAvailable() {\n        this[kLastUseTime] = (0, utils_1.now)();\n    }\n    onError(error) {\n        this.cleanup(true, error);\n    }\n    onClose() {\n        const message = `connection ${this.id} to ${this.address} closed`;\n        this.cleanup(true, new error_1.MongoNetworkError(message));\n    }\n    onTimeout() {\n        this[kDelayedTimeoutId] = (0, timers_1.setTimeout)(() => {\n            const message = `connection ${this.id} to ${this.address} timed out`;\n            const beforeHandshake = this.hello == null;\n            this.cleanup(true, new error_1.MongoNetworkTimeoutError(message, { beforeHandshake }));\n        }, 1).unref(); // No need for this timer to hold the event loop open\n    }\n    onMessage(message) {\n        const delayedTimeoutId = this[kDelayedTimeoutId];\n        if (delayedTimeoutId != null) {\n            (0, timers_1.clearTimeout)(delayedTimeoutId);\n            this[kDelayedTimeoutId] = null;\n        }\n        const socketTimeoutMS = this[kStream].timeout ?? 0;\n        this[kStream].setTimeout(0);\n        // always emit the message, in case we are streaming\n        this.emit('message', message);\n        let operationDescription = this[kQueue].get(message.responseTo);\n        if (!operationDescription && this.isMonitoringConnection) {\n            // This is how we recover when the initial hello's requestId is not\n            // the responseTo when hello responses have been skipped:\n            // First check if the map is of invalid size\n            if (this[kQueue].size > 1) {\n                this.cleanup(true, new error_1.MongoRuntimeError(INVALID_QUEUE_SIZE));\n            }\n            else {\n                // Get the first orphaned operation description.\n                const entry = this[kQueue].entries().next();\n                if (entry.value != null) {\n                    const [requestId, orphaned] = entry.value;\n                    // If the orphaned operation description exists then set it.\n                    operationDescription = orphaned;\n                    // Remove the entry with the bad request id from the queue.\n                    this[kQueue].delete(requestId);\n                }\n            }\n        }\n        if (!operationDescription) {\n            return;\n        }\n        const callback = operationDescription.cb;\n        // SERVER-45775: For exhaust responses we should be able to use the same requestId to\n        // track response, however the server currently synthetically produces remote requests\n        // making the `responseTo` change on each response\n        this[kQueue].delete(message.responseTo);\n        if ('moreToCome' in message && message.moreToCome) {\n            // If the operation description check above does find an orphaned\n            // description and sets the operationDescription then this line will put one\n            // back in the queue with the correct requestId and will resolve not being able\n            // to find the next one via the responseTo of the next streaming hello.\n            this[kQueue].set(message.requestId, operationDescription);\n            this[kStream].setTimeout(socketTimeoutMS);\n        }\n        try {\n            // Pass in the entire description because it has BSON parsing options\n            message.parse(operationDescription);\n        }\n        catch (err) {\n            // If this error is generated by our own code, it will already have the correct class applied\n            // if it is not, then it is coming from a catastrophic data parse failure or the BSON library\n            // in either case, it should not be wrapped\n            callback(err);\n            return;\n        }\n        if (message.documents[0]) {\n            const document = message.documents[0];\n            const session = operationDescription.session;\n            if (session) {\n                (0, sessions_1.updateSessionFromResponse)(session, document);\n            }\n            if (document.$clusterTime) {\n                this[kClusterTime] = document.$clusterTime;\n                this.emit(Connection.CLUSTER_TIME_RECEIVED, document.$clusterTime);\n            }\n            if (document.writeConcernError) {\n                callback(new error_1.MongoWriteConcernError(document.writeConcernError, document), document);\n                return;\n            }\n            if (document.ok === 0 || document.$err || document.errmsg || document.code) {\n                callback(new error_1.MongoServerError(document));\n                return;\n            }\n        }\n        callback(undefined, message.documents[0]);\n    }\n    destroy(options, callback) {\n        if (this.closed) {\n            process.nextTick(() => callback?.());\n            return;\n        }\n        if (typeof callback === 'function') {\n            this.once('close', () => process.nextTick(() => callback()));\n        }\n        // load balanced mode requires that these listeners remain on the connection\n        // after cleanup on timeouts, errors or close so we remove them before calling\n        // cleanup.\n        this.removeAllListeners(Connection.PINNED);\n        this.removeAllListeners(Connection.UNPINNED);\n        const message = `connection ${this.id} to ${this.address} closed`;\n        this.cleanup(options.force, new error_1.MongoNetworkError(message));\n    }\n    /**\n     * A method that cleans up the connection.  When `force` is true, this method\n     * forcibly destroys the socket.\n     *\n     * If an error is provided, any in-flight operations will be closed with the error.\n     *\n     * This method does nothing if the connection is already closed.\n     */\n    cleanup(force, error) {\n        if (this.closed) {\n            return;\n        }\n        this.closed = true;\n        const completeCleanup = () => {\n            for (const op of this[kQueue].values()) {\n                op.cb(error);\n            }\n            this[kQueue].clear();\n            this.emit(Connection.CLOSE);\n        };\n        this[kStream].removeAllListeners();\n        this[kMessageStream].removeAllListeners();\n        this[kMessageStream].destroy();\n        if (force) {\n            this[kStream].destroy();\n            completeCleanup();\n            return;\n        }\n        if (!this[kStream].writableEnded) {\n            this[kStream].end(() => {\n                this[kStream].destroy();\n                completeCleanup();\n            });\n        }\n        else {\n            completeCleanup();\n        }\n    }\n    command(ns, command, options, callback) {\n        let cmd = { ...command };\n        const readPreference = (0, shared_1.getReadPreference)(options);\n        const shouldUseOpMsg = supportsOpMsg(this);\n        const session = options?.session;\n        let clusterTime = this.clusterTime;\n        if (this.serverApi) {\n            const { version, strict, deprecationErrors } = this.serverApi;\n            cmd.apiVersion = version;\n            if (strict != null)\n                cmd.apiStrict = strict;\n            if (deprecationErrors != null)\n                cmd.apiDeprecationErrors = deprecationErrors;\n        }\n        if (hasSessionSupport(this) && session) {\n            if (session.clusterTime &&\n                clusterTime &&\n                session.clusterTime.clusterTime.greaterThan(clusterTime.clusterTime)) {\n                clusterTime = session.clusterTime;\n            }\n            const err = (0, sessions_1.applySession)(session, cmd, options);\n            if (err) {\n                return callback(err);\n            }\n        }\n        else if (session?.explicit) {\n            return callback(new error_1.MongoCompatibilityError('Current topology does not support sessions'));\n        }\n        // if we have a known cluster time, gossip it\n        if (clusterTime) {\n            cmd.$clusterTime = clusterTime;\n        }\n        if ((0, shared_1.isSharded)(this) && !shouldUseOpMsg && readPreference && readPreference.mode !== 'primary') {\n            cmd = {\n                $query: cmd,\n                $readPreference: readPreference.toJSON()\n            };\n        }\n        const commandOptions = Object.assign({\n            numberToSkip: 0,\n            numberToReturn: -1,\n            checkKeys: false,\n            // This value is not overridable\n            secondaryOk: readPreference.secondaryOk()\n        }, options);\n        const message = shouldUseOpMsg\n            ? new commands_1.OpMsgRequest(ns.db, cmd, commandOptions)\n            : new commands_1.OpQueryRequest(ns.db, cmd, commandOptions);\n        try {\n            write(this, message, commandOptions, callback);\n        }\n        catch (err) {\n            callback(err);\n        }\n    }\n}\n/** @event */\nConnection.COMMAND_STARTED = constants_1.COMMAND_STARTED;\n/** @event */\nConnection.COMMAND_SUCCEEDED = constants_1.COMMAND_SUCCEEDED;\n/** @event */\nConnection.COMMAND_FAILED = constants_1.COMMAND_FAILED;\n/** @event */\nConnection.CLUSTER_TIME_RECEIVED = constants_1.CLUSTER_TIME_RECEIVED;\n/** @event */\nConnection.CLOSE = constants_1.CLOSE;\n/** @event */\nConnection.MESSAGE = constants_1.MESSAGE;\n/** @event */\nConnection.PINNED = constants_1.PINNED;\n/** @event */\nConnection.UNPINNED = constants_1.UNPINNED;\nexports.Connection = Connection;\n/** @internal */\nclass CryptoConnection extends Connection {\n    constructor(stream, options) {\n        super(stream, options);\n        this[kAutoEncrypter] = options.autoEncrypter;\n    }\n    /** @internal @override */\n    command(ns, cmd, options, callback) {\n        const autoEncrypter = this[kAutoEncrypter];\n        if (!autoEncrypter) {\n            return callback(new error_1.MongoMissingDependencyError('No AutoEncrypter available for encryption'));\n        }\n        const serverWireVersion = (0, utils_1.maxWireVersion)(this);\n        if (serverWireVersion === 0) {\n            // This means the initial handshake hasn't happened yet\n            return super.command(ns, cmd, options, callback);\n        }\n        if (serverWireVersion < 8) {\n            callback(new error_1.MongoCompatibilityError('Auto-encryption requires a minimum MongoDB version of 4.2'));\n            return;\n        }\n        // Save sort or indexKeys based on the command being run\n        // the encrypt API serializes our JS objects to BSON to pass to the native code layer\n        // and then deserializes the encrypted result, the protocol level components\n        // of the command (ex. sort) are then converted to JS objects potentially losing\n        // import key order information. These fields are never encrypted so we can save the values\n        // from before the encryption and replace them after encryption has been performed\n        const sort = cmd.find || cmd.findAndModify ? cmd.sort : null;\n        const indexKeys = cmd.createIndexes\n            ? cmd.indexes.map((index) => index.key)\n            : null;\n        autoEncrypter.encrypt(ns.toString(), cmd, options).then(encrypted => {\n            // Replace the saved values\n            if (sort != null && (cmd.find || cmd.findAndModify)) {\n                encrypted.sort = sort;\n            }\n            if (indexKeys != null && cmd.createIndexes) {\n                for (const [offset, index] of indexKeys.entries()) {\n                    // @ts-expect-error `encrypted` is a generic \"command\", but we've narrowed for only `createIndexes` commands here\n                    encrypted.indexes[offset].key = index;\n                }\n            }\n            super.command(ns, encrypted, options, (err, response) => {\n                if (err || response == null) {\n                    callback(err, response);\n                    return;\n                }\n                autoEncrypter.decrypt(response, options).then(res => callback(undefined, res), err => callback(err));\n            });\n        }, err => {\n            if (err) {\n                callback(err, null);\n            }\n        });\n    }\n}\nexports.CryptoConnection = CryptoConnection;\n/** @internal */\nfunction hasSessionSupport(conn) {\n    const description = conn.description;\n    return description.logicalSessionTimeoutMinutes != null;\n}\nexports.hasSessionSupport = hasSessionSupport;\nfunction supportsOpMsg(conn) {\n    const description = conn.description;\n    if (description == null) {\n        return false;\n    }\n    return (0, utils_1.maxWireVersion)(conn) >= 6 && !description.__nodejs_mock_server__;\n}\nfunction streamIdentifier(stream, options) {\n    if (options.proxyHost) {\n        // If proxy options are specified, the properties of `stream` itself\n        // will not accurately reflect what endpoint this is connected to.\n        return options.hostAddress.toString();\n    }\n    const { remoteAddress, remotePort } = stream;\n    if (typeof remoteAddress === 'string' && typeof remotePort === 'number') {\n        return utils_1.HostAddress.fromHostPort(remoteAddress, remotePort).toString();\n    }\n    return (0, utils_1.uuidV4)().toString('hex');\n}\nfunction write(conn, command, options, callback) {\n    options = options ?? {};\n    const operationDescription = {\n        requestId: command.requestId,\n        cb: callback,\n        session: options.session,\n        noResponse: typeof options.noResponse === 'boolean' ? options.noResponse : false,\n        documentsReturnedIn: options.documentsReturnedIn,\n        // for BSON parsing\n        useBigInt64: typeof options.useBigInt64 === 'boolean' ? options.useBigInt64 : false,\n        promoteLongs: typeof options.promoteLongs === 'boolean' ? options.promoteLongs : true,\n        promoteValues: typeof options.promoteValues === 'boolean' ? options.promoteValues : true,\n        promoteBuffers: typeof options.promoteBuffers === 'boolean' ? options.promoteBuffers : false,\n        bsonRegExp: typeof options.bsonRegExp === 'boolean' ? options.bsonRegExp : false,\n        enableUtf8Validation: typeof options.enableUtf8Validation === 'boolean' ? options.enableUtf8Validation : true,\n        raw: typeof options.raw === 'boolean' ? options.raw : false,\n        started: 0\n    };\n    if (conn[kDescription] && conn[kDescription].compressor) {\n        operationDescription.agreedCompressor = conn[kDescription].compressor;\n        if (conn[kDescription].zlibCompressionLevel) {\n            operationDescription.zlibCompressionLevel = conn[kDescription].zlibCompressionLevel;\n        }\n    }\n    if (typeof options.socketTimeoutMS === 'number') {\n        conn[kStream].setTimeout(options.socketTimeoutMS);\n    }\n    else if (conn.socketTimeoutMS !== 0) {\n        conn[kStream].setTimeout(conn.socketTimeoutMS);\n    }\n    // if command monitoring is enabled we need to modify the callback here\n    if (conn.monitorCommands) {\n        conn.emit(Connection.COMMAND_STARTED, new command_monitoring_events_1.CommandStartedEvent(conn, command));\n        operationDescription.started = (0, utils_1.now)();\n        operationDescription.cb = (err, reply) => {\n            // Command monitoring spec states that if ok is 1, then we must always emit\n            // a command succeeded event, even if there's an error. Write concern errors\n            // will have an ok: 1 in their reply.\n            if (err && reply?.ok !== 1) {\n                conn.emit(Connection.COMMAND_FAILED, new command_monitoring_events_1.CommandFailedEvent(conn, command, err, operationDescription.started));\n            }\n            else {\n                if (reply && (reply.ok === 0 || reply.$err)) {\n                    conn.emit(Connection.COMMAND_FAILED, new command_monitoring_events_1.CommandFailedEvent(conn, command, reply, operationDescription.started));\n                }\n                else {\n                    conn.emit(Connection.COMMAND_SUCCEEDED, new command_monitoring_events_1.CommandSucceededEvent(conn, command, reply, operationDescription.started));\n                }\n            }\n            if (typeof callback === 'function') {\n                // Since we're passing through the reply with the write concern error now, we\n                // need it not to be provided to the original callback in this case so\n                // retryability does not get tricked into thinking the command actually\n                // succeeded.\n                callback(err, err instanceof error_1.MongoWriteConcernError ? undefined : reply);\n            }\n        };\n    }\n    if (!operationDescription.noResponse) {\n        conn[kQueue].set(operationDescription.requestId, operationDescription);\n    }\n    try {\n        conn[kMessageStream].writeCommand(command, operationDescription);\n    }\n    catch (e) {\n        if (!operationDescription.noResponse) {\n            conn[kQueue].delete(operationDescription.requestId);\n            operationDescription.cb(e);\n            return;\n        }\n    }\n    if (operationDescription.noResponse) {\n        operationDescription.cb();\n    }\n}\n/** in-progress connection layer */\n/** @internal */\nclass ModernConnection extends mongo_types_1.TypedEventEmitter {\n    constructor(stream, options) {\n        super();\n        this.commandAsync = (0, util_1.promisify)((ns, cmd, options, callback) => this.command(ns, cmd, options, callback));\n        this.id = options.id;\n        this.address = streamIdentifier(stream, options);\n        this.socketTimeoutMS = options.socketTimeoutMS ?? 0;\n        this.monitorCommands = options.monitorCommands;\n        this.serverApi = options.serverApi;\n        this.closed = false;\n        this[kHello] = null;\n        this[kClusterTime] = null;\n        this[kDescription] = new stream_description_1.StreamDescription(this.address, options);\n        this[kGeneration] = options.generation;\n        this[kLastUseTime] = (0, utils_1.now)();\n        // setup parser stream and message handling\n        this[kQueue] = new Map();\n        this[kMessageStream] = new message_stream_1.MessageStream({\n            ...options,\n            maxBsonMessageSize: this.hello?.maxBsonMessageSize\n        });\n        this.socket = stream;\n        this[kDelayedTimeoutId] = null;\n        this[kMessageStream].on('message', message => this.onMessage(message));\n        this[kMessageStream].on('error', error => this.onError(error));\n        this.socket.on('close', () => this.onClose());\n        this.socket.on('timeout', () => this.onTimeout());\n        this.socket.on('error', () => {\n            /* ignore errors, listen to `close` instead */\n        });\n        // hook the message stream up to the passed in stream\n        this.socket.pipe(this[kMessageStream]);\n        this[kMessageStream].pipe(this.socket);\n    }\n    get description() {\n        return this[kDescription];\n    }\n    get hello() {\n        return this[kHello];\n    }\n    // the `connect` method stores the result of the handshake hello on the connection\n    set hello(response) {\n        this[kDescription].receiveResponse(response);\n        this[kDescription] = Object.freeze(this[kDescription]);\n        // TODO: remove this, and only use the `StreamDescription` in the future\n        this[kHello] = response;\n    }\n    // Set the whether the message stream is for a monitoring connection.\n    set isMonitoringConnection(value) {\n        this[kMessageStream].isMonitoringConnection = value;\n    }\n    get isMonitoringConnection() {\n        return this[kMessageStream].isMonitoringConnection;\n    }\n    get serviceId() {\n        return this.hello?.serviceId;\n    }\n    get loadBalanced() {\n        return this.description.loadBalanced;\n    }\n    get generation() {\n        return this[kGeneration] || 0;\n    }\n    set generation(generation) {\n        this[kGeneration] = generation;\n    }\n    get idleTime() {\n        return (0, utils_1.calculateDurationInMs)(this[kLastUseTime]);\n    }\n    get clusterTime() {\n        return this[kClusterTime];\n    }\n    get stream() {\n        return this.socket;\n    }\n    get hasSessionSupport() {\n        return this.description.logicalSessionTimeoutMinutes != null;\n    }\n    get supportsOpMsg() {\n        return (this.description != null &&\n            (0, utils_1.maxWireVersion)(this) >= 6 &&\n            !this.description.__nodejs_mock_server__);\n    }\n    markAvailable() {\n        this[kLastUseTime] = (0, utils_1.now)();\n    }\n    onError(error) {\n        this.cleanup(true, error);\n    }\n    onClose() {\n        const message = `connection ${this.id} to ${this.address} closed`;\n        this.cleanup(true, new error_1.MongoNetworkError(message));\n    }\n    onTimeout() {\n        this[kDelayedTimeoutId] = (0, timers_1.setTimeout)(() => {\n            const message = `connection ${this.id} to ${this.address} timed out`;\n            const beforeHandshake = this.hello == null;\n            this.cleanup(true, new error_1.MongoNetworkTimeoutError(message, { beforeHandshake }));\n        }, 1).unref(); // No need for this timer to hold the event loop open\n    }\n    onMessage(message) {\n        const delayedTimeoutId = this[kDelayedTimeoutId];\n        if (delayedTimeoutId != null) {\n            (0, timers_1.clearTimeout)(delayedTimeoutId);\n            this[kDelayedTimeoutId] = null;\n        }\n        const socketTimeoutMS = this.socket.timeout ?? 0;\n        this.socket.setTimeout(0);\n        // always emit the message, in case we are streaming\n        this.emit('message', message);\n        let operationDescription = this[kQueue].get(message.responseTo);\n        if (!operationDescription && this.isMonitoringConnection) {\n            // This is how we recover when the initial hello's requestId is not\n            // the responseTo when hello responses have been skipped:\n            // First check if the map is of invalid size\n            if (this[kQueue].size > 1) {\n                this.cleanup(true, new error_1.MongoRuntimeError(INVALID_QUEUE_SIZE));\n            }\n            else {\n                // Get the first orphaned operation description.\n                const entry = this[kQueue].entries().next();\n                if (entry.value != null) {\n                    const [requestId, orphaned] = entry.value;\n                    // If the orphaned operation description exists then set it.\n                    operationDescription = orphaned;\n                    // Remove the entry with the bad request id from the queue.\n                    this[kQueue].delete(requestId);\n                }\n            }\n        }\n        if (!operationDescription) {\n            return;\n        }\n        const callback = operationDescription.cb;\n        // SERVER-45775: For exhaust responses we should be able to use the same requestId to\n        // track response, however the server currently synthetically produces remote requests\n        // making the `responseTo` change on each response\n        this[kQueue].delete(message.responseTo);\n        if ('moreToCome' in message && message.moreToCome) {\n            // If the operation description check above does find an orphaned\n            // description and sets the operationDescription then this line will put one\n            // back in the queue with the correct requestId and will resolve not being able\n            // to find the next one via the responseTo of the next streaming hello.\n            this[kQueue].set(message.requestId, operationDescription);\n            this.socket.setTimeout(socketTimeoutMS);\n        }\n        try {\n            // Pass in the entire description because it has BSON parsing options\n            message.parse(operationDescription);\n        }\n        catch (err) {\n            // If this error is generated by our own code, it will already have the correct class applied\n            // if it is not, then it is coming from a catastrophic data parse failure or the BSON library\n            // in either case, it should not be wrapped\n            callback(err);\n            return;\n        }\n        if (message.documents[0]) {\n            const document = message.documents[0];\n            const session = operationDescription.session;\n            if (session) {\n                (0, sessions_1.updateSessionFromResponse)(session, document);\n            }\n            if (document.$clusterTime) {\n                this[kClusterTime] = document.$clusterTime;\n                this.emit(Connection.CLUSTER_TIME_RECEIVED, document.$clusterTime);\n            }\n            if (document.writeConcernError) {\n                callback(new error_1.MongoWriteConcernError(document.writeConcernError, document), document);\n                return;\n            }\n            if (document.ok === 0 || document.$err || document.errmsg || document.code) {\n                callback(new error_1.MongoServerError(document));\n                return;\n            }\n        }\n        callback(undefined, message.documents[0]);\n    }\n    destroy(options, callback) {\n        if (this.closed) {\n            process.nextTick(() => callback?.());\n            return;\n        }\n        if (typeof callback === 'function') {\n            this.once('close', () => process.nextTick(() => callback()));\n        }\n        // load balanced mode requires that these listeners remain on the connection\n        // after cleanup on timeouts, errors or close so we remove them before calling\n        // cleanup.\n        this.removeAllListeners(Connection.PINNED);\n        this.removeAllListeners(Connection.UNPINNED);\n        const message = `connection ${this.id} to ${this.address} closed`;\n        this.cleanup(options.force, new error_1.MongoNetworkError(message));\n    }\n    /**\n     * A method that cleans up the connection.  When `force` is true, this method\n     * forcibly destroys the socket.\n     *\n     * If an error is provided, any in-flight operations will be closed with the error.\n     *\n     * This method does nothing if the connection is already closed.\n     */\n    cleanup(force, error) {\n        if (this.closed) {\n            return;\n        }\n        this.closed = true;\n        const completeCleanup = () => {\n            for (const op of this[kQueue].values()) {\n                op.cb(error);\n            }\n            this[kQueue].clear();\n            this.emit(Connection.CLOSE);\n        };\n        this.socket.removeAllListeners();\n        this[kMessageStream].removeAllListeners();\n        this[kMessageStream].destroy();\n        if (force) {\n            this.socket.destroy();\n            completeCleanup();\n            return;\n        }\n        if (!this.socket.writableEnded) {\n            this.socket.end(() => {\n                this.socket.destroy();\n                completeCleanup();\n            });\n        }\n        else {\n            completeCleanup();\n        }\n    }\n    command(ns, command, options, callback) {\n        let cmd = { ...command };\n        const readPreference = (0, shared_1.getReadPreference)(options);\n        const session = options?.session;\n        let clusterTime = this.clusterTime;\n        if (this.serverApi) {\n            const { version, strict, deprecationErrors } = this.serverApi;\n            cmd.apiVersion = version;\n            if (strict != null)\n                cmd.apiStrict = strict;\n            if (deprecationErrors != null)\n                cmd.apiDeprecationErrors = deprecationErrors;\n        }\n        if (this.hasSessionSupport && session) {\n            if (session.clusterTime &&\n                clusterTime &&\n                session.clusterTime.clusterTime.greaterThan(clusterTime.clusterTime)) {\n                clusterTime = session.clusterTime;\n            }\n            const err = (0, sessions_1.applySession)(session, cmd, options);\n            if (err) {\n                return callback(err);\n            }\n        }\n        else if (session?.explicit) {\n            return callback(new error_1.MongoCompatibilityError('Current topology does not support sessions'));\n        }\n        // if we have a known cluster time, gossip it\n        if (clusterTime) {\n            cmd.$clusterTime = clusterTime;\n        }\n        if (\n        // @ts-expect-error ModernConnections cannot be passed as connections\n        (0, shared_1.isSharded)(this) &&\n            !this.supportsOpMsg &&\n            readPreference &&\n            readPreference.mode !== 'primary') {\n            cmd = {\n                $query: cmd,\n                $readPreference: readPreference.toJSON()\n            };\n        }\n        const commandOptions = Object.assign({\n            numberToSkip: 0,\n            numberToReturn: -1,\n            checkKeys: false,\n            // This value is not overridable\n            secondaryOk: readPreference.secondaryOk()\n        }, options);\n        const message = this.supportsOpMsg\n            ? new commands_1.OpMsgRequest(ns.db, cmd, commandOptions)\n            : new commands_1.OpQueryRequest(ns.db, cmd, commandOptions);\n        try {\n            write(this, message, commandOptions, callback);\n        }\n        catch (err) {\n            callback(err);\n        }\n    }\n}\n/** @event */\nModernConnection.COMMAND_STARTED = constants_1.COMMAND_STARTED;\n/** @event */\nModernConnection.COMMAND_SUCCEEDED = constants_1.COMMAND_SUCCEEDED;\n/** @event */\nModernConnection.COMMAND_FAILED = constants_1.COMMAND_FAILED;\n/** @event */\nModernConnection.CLUSTER_TIME_RECEIVED = constants_1.CLUSTER_TIME_RECEIVED;\n/** @event */\nModernConnection.CLOSE = constants_1.CLOSE;\n/** @event */\nModernConnection.MESSAGE = constants_1.MESSAGE;\n/** @event */\nModernConnection.PINNED = constants_1.PINNED;\n/** @event */\nModernConnection.UNPINNED = constants_1.UNPINNED;\nexports.ModernConnection = ModernConnection;\nconst kDefaultMaxBsonMessageSize = 1024 * 1024 * 16 * 4;\n/**\n * @internal\n *\n * This helper reads chucks of data out of a socket and buffers them until it has received a\n * full wire protocol message.\n *\n * By itself, produces an infinite async generator of wire protocol messages and consumers must end\n * the stream by calling `return` on the generator.\n *\n * Note that `for-await` loops call `return` automatically when the loop is exited.\n */\nasync function* readWireProtocolMessages(connection) {\n    const bufferPool = new utils_1.BufferPool();\n    const maxBsonMessageSize = connection.hello?.maxBsonMessageSize ?? kDefaultMaxBsonMessageSize;\n    for await (const [chunk] of (0, stream_1.on)(connection.socket, 'data')) {\n        bufferPool.append(chunk);\n        const sizeOfMessage = bufferPool.getInt32();\n        if (sizeOfMessage == null) {\n            continue;\n        }\n        if (sizeOfMessage < 0) {\n            throw new error_1.MongoParseError(`Invalid message size: ${sizeOfMessage}`);\n        }\n        if (sizeOfMessage > maxBsonMessageSize) {\n            throw new error_1.MongoParseError(`Invalid message size: ${sizeOfMessage}, max allowed: ${maxBsonMessageSize}`);\n        }\n        if (sizeOfMessage > bufferPool.length) {\n            continue;\n        }\n        yield bufferPool.read(sizeOfMessage);\n    }\n}\nexports.readWireProtocolMessages = readWireProtocolMessages;\n/**\n * @internal\n *\n * Writes an OP_MSG or OP_QUERY request to the socket, optionally compressing the command. This method\n * waits until the socket's buffer has emptied (the Nodejs socket `drain` event has fired).\n */\nasync function writeCommand(connection, command, options) {\n    const drained = (0, events_1.once)(connection.socket, 'drain');\n    const finalCommand = options.agreedCompressor === 'none' || !commands_1.OpCompressedRequest.canCompress(command)\n        ? command\n        : new commands_1.OpCompressedRequest(command, {\n            agreedCompressor: options.agreedCompressor ?? 'none',\n            zlibCompressionLevel: options.zlibCompressionLevel ?? 0\n        });\n    const buffer = Buffer.concat(await finalCommand.toBin());\n    connection.socket.push(buffer);\n    await drained;\n}\nexports.writeCommand = writeCommand;\n/**\n * @internal\n *\n * Returns an async generator that yields full wire protocol messages from the underlying socket.  This function\n * yields messages until `moreToCome` is false or not present in a response, or the caller cancels the request\n * by calling `return` on the generator.\n *\n * Note that `for-await` loops call `return` automatically when the loop is exited.\n */\nasync function* readMany(connection) {\n    for await (const message of readWireProtocolMessages(connection)) {\n        const response = await (0, compression_1.decompressResponse)(message);\n        yield response;\n        if (!('moreToCome' in response) || !response.moreToCome) {\n            return;\n        }\n    }\n}\nexports.readMany = readMany;\n/**\n * @internal\n *\n * Reads a single wire protocol message out of a connection.\n */\nasync function read(connection) {\n    for await (const value of readMany(connection)) {\n        return value;\n    }\n    throw new error_1.MongoRuntimeError('unable to read message off of connection');\n}\nexports.read = read;\n//# sourceMappingURL=connection.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/connection.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/connection_pool.js":
/*!**********************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/connection_pool.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConnectionPool = exports.PoolState = void 0;\nconst timers_1 = __webpack_require__(/*! timers */ \"timers\");\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_types_1 = __webpack_require__(/*! ../mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst connect_1 = __webpack_require__(/*! ./connect */ \"./node_modules/mongodb/lib/cmap/connect.js\");\nconst connection_1 = __webpack_require__(/*! ./connection */ \"./node_modules/mongodb/lib/cmap/connection.js\");\nconst connection_pool_events_1 = __webpack_require__(/*! ./connection_pool_events */ \"./node_modules/mongodb/lib/cmap/connection_pool_events.js\");\nconst errors_1 = __webpack_require__(/*! ./errors */ \"./node_modules/mongodb/lib/cmap/errors.js\");\nconst metrics_1 = __webpack_require__(/*! ./metrics */ \"./node_modules/mongodb/lib/cmap/metrics.js\");\n/** @internal */\nconst kServer = Symbol('server');\n/** @internal */\nconst kConnections = Symbol('connections');\n/** @internal */\nconst kPending = Symbol('pending');\n/** @internal */\nconst kCheckedOut = Symbol('checkedOut');\n/** @internal */\nconst kMinPoolSizeTimer = Symbol('minPoolSizeTimer');\n/** @internal */\nconst kGeneration = Symbol('generation');\n/** @internal */\nconst kServiceGenerations = Symbol('serviceGenerations');\n/** @internal */\nconst kConnectionCounter = Symbol('connectionCounter');\n/** @internal */\nconst kCancellationToken = Symbol('cancellationToken');\n/** @internal */\nconst kWaitQueue = Symbol('waitQueue');\n/** @internal */\nconst kCancelled = Symbol('cancelled');\n/** @internal */\nconst kMetrics = Symbol('metrics');\n/** @internal */\nconst kProcessingWaitQueue = Symbol('processingWaitQueue');\n/** @internal */\nconst kPoolState = Symbol('poolState');\n/** @internal */\nexports.PoolState = Object.freeze({\n    paused: 'paused',\n    ready: 'ready',\n    closed: 'closed'\n});\n/**\n * A pool of connections which dynamically resizes, and emit events related to pool activity\n * @internal\n */\nclass ConnectionPool extends mongo_types_1.TypedEventEmitter {\n    constructor(server, options) {\n        super();\n        this.options = Object.freeze({\n            ...options,\n            connectionType: connection_1.Connection,\n            maxPoolSize: options.maxPoolSize ?? 100,\n            minPoolSize: options.minPoolSize ?? 0,\n            maxConnecting: options.maxConnecting ?? 2,\n            maxIdleTimeMS: options.maxIdleTimeMS ?? 0,\n            waitQueueTimeoutMS: options.waitQueueTimeoutMS ?? 0,\n            minPoolSizeCheckFrequencyMS: options.minPoolSizeCheckFrequencyMS ?? 100,\n            autoEncrypter: options.autoEncrypter,\n            metadata: options.metadata\n        });\n        if (this.options.minPoolSize > this.options.maxPoolSize) {\n            throw new error_1.MongoInvalidArgumentError('Connection pool minimum size must not be greater than maximum pool size');\n        }\n        this[kPoolState] = exports.PoolState.paused;\n        this[kServer] = server;\n        this[kConnections] = new utils_1.List();\n        this[kPending] = 0;\n        this[kCheckedOut] = new Set();\n        this[kMinPoolSizeTimer] = undefined;\n        this[kGeneration] = 0;\n        this[kServiceGenerations] = new Map();\n        this[kConnectionCounter] = (0, utils_1.makeCounter)(1);\n        this[kCancellationToken] = new mongo_types_1.CancellationToken();\n        this[kCancellationToken].setMaxListeners(Infinity);\n        this[kWaitQueue] = new utils_1.List();\n        this[kMetrics] = new metrics_1.ConnectionPoolMetrics();\n        this[kProcessingWaitQueue] = false;\n        this.mongoLogger = this[kServer].topology.client.mongoLogger;\n        this.component = 'connection';\n        process.nextTick(() => {\n            this.emitAndLog(ConnectionPool.CONNECTION_POOL_CREATED, new connection_pool_events_1.ConnectionPoolCreatedEvent(this));\n        });\n    }\n    /** The address of the endpoint the pool is connected to */\n    get address() {\n        return this.options.hostAddress.toString();\n    }\n    /**\n     * Check if the pool has been closed\n     *\n     * TODO(NODE-3263): We can remove this property once shell no longer needs it\n     */\n    get closed() {\n        return this[kPoolState] === exports.PoolState.closed;\n    }\n    /** An integer representing the SDAM generation of the pool */\n    get generation() {\n        return this[kGeneration];\n    }\n    /** An integer expressing how many total connections (available + pending + in use) the pool currently has */\n    get totalConnectionCount() {\n        return (this.availableConnectionCount + this.pendingConnectionCount + this.currentCheckedOutCount);\n    }\n    /** An integer expressing how many connections are currently available in the pool. */\n    get availableConnectionCount() {\n        return this[kConnections].length;\n    }\n    get pendingConnectionCount() {\n        return this[kPending];\n    }\n    get currentCheckedOutCount() {\n        return this[kCheckedOut].size;\n    }\n    get waitQueueSize() {\n        return this[kWaitQueue].length;\n    }\n    get loadBalanced() {\n        return this.options.loadBalanced;\n    }\n    get serviceGenerations() {\n        return this[kServiceGenerations];\n    }\n    get serverError() {\n        return this[kServer].description.error;\n    }\n    /**\n     * This is exposed ONLY for use in mongosh, to enable\n     * killing all connections if a user quits the shell with\n     * operations in progress.\n     *\n     * This property may be removed as a part of NODE-3263.\n     */\n    get checkedOutConnections() {\n        return this[kCheckedOut];\n    }\n    /**\n     * Get the metrics information for the pool when a wait queue timeout occurs.\n     */\n    waitQueueErrorMetrics() {\n        return this[kMetrics].info(this.options.maxPoolSize);\n    }\n    /**\n     * Set the pool state to \"ready\"\n     */\n    ready() {\n        if (this[kPoolState] !== exports.PoolState.paused) {\n            return;\n        }\n        this[kPoolState] = exports.PoolState.ready;\n        this.emitAndLog(ConnectionPool.CONNECTION_POOL_READY, new connection_pool_events_1.ConnectionPoolReadyEvent(this));\n        (0, timers_1.clearTimeout)(this[kMinPoolSizeTimer]);\n        this.ensureMinPoolSize();\n    }\n    /**\n     * Check a connection out of this pool. The connection will continue to be tracked, but no reference to it\n     * will be held by the pool. This means that if a connection is checked out it MUST be checked back in or\n     * explicitly destroyed by the new owner.\n     */\n    checkOut(callback) {\n        this.emitAndLog(ConnectionPool.CONNECTION_CHECK_OUT_STARTED, new connection_pool_events_1.ConnectionCheckOutStartedEvent(this));\n        const waitQueueTimeoutMS = this.options.waitQueueTimeoutMS;\n        const waitQueueMember = {\n            callback,\n            timeoutController: new utils_1.TimeoutController(waitQueueTimeoutMS)\n        };\n        waitQueueMember.timeoutController.signal.addEventListener('abort', () => {\n            waitQueueMember[kCancelled] = true;\n            waitQueueMember.timeoutController.clear();\n            this.emitAndLog(ConnectionPool.CONNECTION_CHECK_OUT_FAILED, new connection_pool_events_1.ConnectionCheckOutFailedEvent(this, 'timeout'));\n            waitQueueMember.callback(new errors_1.WaitQueueTimeoutError(this.loadBalanced\n                ? this.waitQueueErrorMetrics()\n                : 'Timed out while checking out a connection from connection pool', this.address));\n        });\n        this[kWaitQueue].push(waitQueueMember);\n        process.nextTick(() => this.processWaitQueue());\n    }\n    /**\n     * Check a connection into the pool.\n     *\n     * @param connection - The connection to check in\n     */\n    checkIn(connection) {\n        if (!this[kCheckedOut].has(connection)) {\n            return;\n        }\n        const poolClosed = this.closed;\n        const stale = this.connectionIsStale(connection);\n        const willDestroy = !!(poolClosed || stale || connection.closed);\n        if (!willDestroy) {\n            connection.markAvailable();\n            this[kConnections].unshift(connection);\n        }\n        this[kCheckedOut].delete(connection);\n        this.emitAndLog(ConnectionPool.CONNECTION_CHECKED_IN, new connection_pool_events_1.ConnectionCheckedInEvent(this, connection));\n        if (willDestroy) {\n            const reason = connection.closed ? 'error' : poolClosed ? 'poolClosed' : 'stale';\n            this.destroyConnection(connection, reason);\n        }\n        process.nextTick(() => this.processWaitQueue());\n    }\n    /**\n     * Clear the pool\n     *\n     * Pool reset is handled by incrementing the pool's generation count. Any existing connection of a\n     * previous generation will eventually be pruned during subsequent checkouts.\n     */\n    clear(options = {}) {\n        if (this.closed) {\n            return;\n        }\n        // handle load balanced case\n        if (this.loadBalanced) {\n            const { serviceId } = options;\n            if (!serviceId) {\n                throw new error_1.MongoRuntimeError('ConnectionPool.clear() called in load balanced mode with no serviceId.');\n            }\n            const sid = serviceId.toHexString();\n            const generation = this.serviceGenerations.get(sid);\n            // Only need to worry if the generation exists, since it should\n            // always be there but typescript needs the check.\n            if (generation == null) {\n                throw new error_1.MongoRuntimeError('Service generations are required in load balancer mode.');\n            }\n            else {\n                // Increment the generation for the service id.\n                this.serviceGenerations.set(sid, generation + 1);\n            }\n            this.emitAndLog(ConnectionPool.CONNECTION_POOL_CLEARED, new connection_pool_events_1.ConnectionPoolClearedEvent(this, { serviceId }));\n            return;\n        }\n        // handle non load-balanced case\n        const interruptInUseConnections = options.interruptInUseConnections ?? false;\n        const oldGeneration = this[kGeneration];\n        this[kGeneration] += 1;\n        const alreadyPaused = this[kPoolState] === exports.PoolState.paused;\n        this[kPoolState] = exports.PoolState.paused;\n        this.clearMinPoolSizeTimer();\n        if (!alreadyPaused) {\n            this.emitAndLog(ConnectionPool.CONNECTION_POOL_CLEARED, new connection_pool_events_1.ConnectionPoolClearedEvent(this, {\n                interruptInUseConnections\n            }));\n        }\n        if (interruptInUseConnections) {\n            process.nextTick(() => this.interruptInUseConnections(oldGeneration));\n        }\n        this.processWaitQueue();\n    }\n    /**\n     * Closes all stale in-use connections in the pool with a resumable PoolClearedOnNetworkError.\n     *\n     * Only connections where `connection.generation <= minGeneration` are killed.\n     */\n    interruptInUseConnections(minGeneration) {\n        for (const connection of this[kCheckedOut]) {\n            if (connection.generation <= minGeneration) {\n                this.checkIn(connection);\n                connection.onError(new errors_1.PoolClearedOnNetworkError(this));\n            }\n        }\n    }\n    close(_options, _cb) {\n        let options = _options;\n        const callback = (_cb ?? _options);\n        if (typeof options === 'function') {\n            options = {};\n        }\n        options = Object.assign({ force: false }, options);\n        if (this.closed) {\n            return callback();\n        }\n        // immediately cancel any in-flight connections\n        this[kCancellationToken].emit('cancel');\n        // end the connection counter\n        if (typeof this[kConnectionCounter].return === 'function') {\n            this[kConnectionCounter].return(undefined);\n        }\n        this[kPoolState] = exports.PoolState.closed;\n        this.clearMinPoolSizeTimer();\n        this.processWaitQueue();\n        (0, utils_1.eachAsync)(this[kConnections].toArray(), (conn, cb) => {\n            this.emitAndLog(ConnectionPool.CONNECTION_CLOSED, new connection_pool_events_1.ConnectionClosedEvent(this, conn, 'poolClosed'));\n            conn.destroy({ force: !!options.force }, cb);\n        }, err => {\n            this[kConnections].clear();\n            this.emitAndLog(ConnectionPool.CONNECTION_POOL_CLOSED, new connection_pool_events_1.ConnectionPoolClosedEvent(this));\n            callback(err);\n        });\n    }\n    /**\n     * Runs a lambda with an implicitly checked out connection, checking that connection back in when the lambda\n     * has completed by calling back.\n     *\n     * NOTE: please note the required signature of `fn`\n     *\n     * @remarks When in load balancer mode, connections can be pinned to cursors or transactions.\n     *   In these cases we pass the connection in to this method to ensure it is used and a new\n     *   connection is not checked out.\n     *\n     * @param conn - A pinned connection for use in load balancing mode.\n     * @param fn - A function which operates on a managed connection\n     * @param callback - The original callback\n     */\n    withConnection(conn, fn, callback) {\n        if (conn) {\n            // use the provided connection, and do _not_ check it in after execution\n            fn(undefined, conn, (fnErr, result) => {\n                if (fnErr) {\n                    return this.withReauthentication(fnErr, conn, fn, callback);\n                }\n                callback(undefined, result);\n            });\n            return;\n        }\n        this.checkOut((err, conn) => {\n            // don't callback with `err` here, we might want to act upon it inside `fn`\n            fn(err, conn, (fnErr, result) => {\n                if (fnErr) {\n                    if (conn) {\n                        this.withReauthentication(fnErr, conn, fn, callback);\n                    }\n                    else {\n                        callback(fnErr);\n                    }\n                }\n                else {\n                    callback(undefined, result);\n                }\n                if (conn) {\n                    this.checkIn(conn);\n                }\n            });\n        });\n    }\n    withReauthentication(fnErr, conn, fn, callback) {\n        if (fnErr instanceof error_1.MongoError && fnErr.code === error_1.MONGODB_ERROR_CODES.Reauthenticate) {\n            this.reauthenticate(conn, fn, (error, res) => {\n                if (error) {\n                    return callback(error);\n                }\n                callback(undefined, res);\n            });\n        }\n        else {\n            callback(fnErr);\n        }\n    }\n    /**\n     * Reauthenticate on the same connection and then retry the operation.\n     */\n    reauthenticate(connection, fn, callback) {\n        const authContext = connection.authContext;\n        if (!authContext) {\n            return callback(new error_1.MongoRuntimeError('No auth context found on connection.'));\n        }\n        const credentials = authContext.credentials;\n        if (!credentials) {\n            return callback(new error_1.MongoMissingCredentialsError('Connection is missing credentials when asked to reauthenticate'));\n        }\n        const resolvedCredentials = credentials.resolveAuthMechanism(connection.hello || undefined);\n        const provider = connect_1.AUTH_PROVIDERS.get(resolvedCredentials.mechanism);\n        if (!provider) {\n            return callback(new error_1.MongoMissingCredentialsError(`Reauthenticate failed due to no auth provider for ${credentials.mechanism}`));\n        }\n        provider.reauth(authContext).then(() => {\n            fn(undefined, connection, (fnErr, fnResult) => {\n                if (fnErr) {\n                    return callback(fnErr);\n                }\n                callback(undefined, fnResult);\n            });\n        }, error => callback(error));\n    }\n    /** Clear the min pool size timer */\n    clearMinPoolSizeTimer() {\n        const minPoolSizeTimer = this[kMinPoolSizeTimer];\n        if (minPoolSizeTimer) {\n            (0, timers_1.clearTimeout)(minPoolSizeTimer);\n        }\n    }\n    destroyConnection(connection, reason) {\n        this.emitAndLog(ConnectionPool.CONNECTION_CLOSED, new connection_pool_events_1.ConnectionClosedEvent(this, connection, reason));\n        // destroy the connection\n        process.nextTick(() => connection.destroy({ force: false }));\n    }\n    connectionIsStale(connection) {\n        const serviceId = connection.serviceId;\n        if (this.loadBalanced && serviceId) {\n            const sid = serviceId.toHexString();\n            const generation = this.serviceGenerations.get(sid);\n            return connection.generation !== generation;\n        }\n        return connection.generation !== this[kGeneration];\n    }\n    connectionIsIdle(connection) {\n        return !!(this.options.maxIdleTimeMS && connection.idleTime > this.options.maxIdleTimeMS);\n    }\n    /**\n     * Destroys a connection if the connection is perished.\n     *\n     * @returns `true` if the connection was destroyed, `false` otherwise.\n     */\n    destroyConnectionIfPerished(connection) {\n        const isStale = this.connectionIsStale(connection);\n        const isIdle = this.connectionIsIdle(connection);\n        if (!isStale && !isIdle && !connection.closed) {\n            return false;\n        }\n        const reason = connection.closed ? 'error' : isStale ? 'stale' : 'idle';\n        this.destroyConnection(connection, reason);\n        return true;\n    }\n    createConnection(callback) {\n        const connectOptions = {\n            ...this.options,\n            id: this[kConnectionCounter].next().value,\n            generation: this[kGeneration],\n            cancellationToken: this[kCancellationToken]\n        };\n        this[kPending]++;\n        // This is our version of a \"virtual\" no-I/O connection as the spec requires\n        this.emitAndLog(ConnectionPool.CONNECTION_CREATED, new connection_pool_events_1.ConnectionCreatedEvent(this, { id: connectOptions.id }));\n        (0, connect_1.connect)(connectOptions, (err, connection) => {\n            if (err || !connection) {\n                this[kPending]--;\n                this.emitAndLog(ConnectionPool.CONNECTION_CLOSED, new connection_pool_events_1.ConnectionClosedEvent(this, { id: connectOptions.id, serviceId: undefined }, 'error', \n                // TODO(NODE-5192): Remove this cast\n                err));\n                if (err instanceof error_1.MongoNetworkError || err instanceof error_1.MongoServerError) {\n                    err.connectionGeneration = connectOptions.generation;\n                }\n                callback(err ?? new error_1.MongoRuntimeError('Connection creation failed without error'));\n                return;\n            }\n            // The pool might have closed since we started trying to create a connection\n            if (this[kPoolState] !== exports.PoolState.ready) {\n                this[kPending]--;\n                connection.destroy({ force: true });\n                callback(this.closed ? new errors_1.PoolClosedError(this) : new errors_1.PoolClearedError(this));\n                return;\n            }\n            // forward all events from the connection to the pool\n            for (const event of [...constants_1.APM_EVENTS, connection_1.Connection.CLUSTER_TIME_RECEIVED]) {\n                connection.on(event, (e) => this.emit(event, e));\n            }\n            if (this.loadBalanced) {\n                connection.on(connection_1.Connection.PINNED, pinType => this[kMetrics].markPinned(pinType));\n                connection.on(connection_1.Connection.UNPINNED, pinType => this[kMetrics].markUnpinned(pinType));\n                const serviceId = connection.serviceId;\n                if (serviceId) {\n                    let generation;\n                    const sid = serviceId.toHexString();\n                    if ((generation = this.serviceGenerations.get(sid))) {\n                        connection.generation = generation;\n                    }\n                    else {\n                        this.serviceGenerations.set(sid, 0);\n                        connection.generation = 0;\n                    }\n                }\n            }\n            connection.markAvailable();\n            this.emitAndLog(ConnectionPool.CONNECTION_READY, new connection_pool_events_1.ConnectionReadyEvent(this, connection));\n            this[kPending]--;\n            callback(undefined, connection);\n            return;\n        });\n    }\n    ensureMinPoolSize() {\n        const minPoolSize = this.options.minPoolSize;\n        if (this[kPoolState] !== exports.PoolState.ready || minPoolSize === 0) {\n            return;\n        }\n        this[kConnections].prune(connection => this.destroyConnectionIfPerished(connection));\n        if (this.totalConnectionCount < minPoolSize &&\n            this.pendingConnectionCount < this.options.maxConnecting) {\n            // NOTE: ensureMinPoolSize should not try to get all the pending\n            // connection permits because that potentially delays the availability of\n            // the connection to a checkout request\n            this.createConnection((err, connection) => {\n                if (err) {\n                    this[kServer].handleError(err);\n                }\n                if (!err && connection) {\n                    this[kConnections].push(connection);\n                    process.nextTick(() => this.processWaitQueue());\n                }\n                if (this[kPoolState] === exports.PoolState.ready) {\n                    (0, timers_1.clearTimeout)(this[kMinPoolSizeTimer]);\n                    this[kMinPoolSizeTimer] = (0, timers_1.setTimeout)(() => this.ensureMinPoolSize(), this.options.minPoolSizeCheckFrequencyMS);\n                }\n            });\n        }\n        else {\n            (0, timers_1.clearTimeout)(this[kMinPoolSizeTimer]);\n            this[kMinPoolSizeTimer] = (0, timers_1.setTimeout)(() => this.ensureMinPoolSize(), this.options.minPoolSizeCheckFrequencyMS);\n        }\n    }\n    processWaitQueue() {\n        if (this[kProcessingWaitQueue]) {\n            return;\n        }\n        this[kProcessingWaitQueue] = true;\n        while (this.waitQueueSize) {\n            const waitQueueMember = this[kWaitQueue].first();\n            if (!waitQueueMember) {\n                this[kWaitQueue].shift();\n                continue;\n            }\n            if (waitQueueMember[kCancelled]) {\n                this[kWaitQueue].shift();\n                continue;\n            }\n            if (this[kPoolState] !== exports.PoolState.ready) {\n                const reason = this.closed ? 'poolClosed' : 'connectionError';\n                const error = this.closed ? new errors_1.PoolClosedError(this) : new errors_1.PoolClearedError(this);\n                this.emitAndLog(ConnectionPool.CONNECTION_CHECK_OUT_FAILED, new connection_pool_events_1.ConnectionCheckOutFailedEvent(this, reason, error));\n                waitQueueMember.timeoutController.clear();\n                this[kWaitQueue].shift();\n                waitQueueMember.callback(error);\n                continue;\n            }\n            if (!this.availableConnectionCount) {\n                break;\n            }\n            const connection = this[kConnections].shift();\n            if (!connection) {\n                break;\n            }\n            if (!this.destroyConnectionIfPerished(connection)) {\n                this[kCheckedOut].add(connection);\n                this.emitAndLog(ConnectionPool.CONNECTION_CHECKED_OUT, new connection_pool_events_1.ConnectionCheckedOutEvent(this, connection));\n                waitQueueMember.timeoutController.clear();\n                this[kWaitQueue].shift();\n                waitQueueMember.callback(undefined, connection);\n            }\n        }\n        const { maxPoolSize, maxConnecting } = this.options;\n        while (this.waitQueueSize > 0 &&\n            this.pendingConnectionCount < maxConnecting &&\n            (maxPoolSize === 0 || this.totalConnectionCount < maxPoolSize)) {\n            const waitQueueMember = this[kWaitQueue].shift();\n            if (!waitQueueMember || waitQueueMember[kCancelled]) {\n                continue;\n            }\n            this.createConnection((err, connection) => {\n                if (waitQueueMember[kCancelled]) {\n                    if (!err && connection) {\n                        this[kConnections].push(connection);\n                    }\n                }\n                else {\n                    if (err) {\n                        this.emitAndLog(ConnectionPool.CONNECTION_CHECK_OUT_FAILED, \n                        // TODO(NODE-5192): Remove this cast\n                        new connection_pool_events_1.ConnectionCheckOutFailedEvent(this, 'connectionError', err));\n                    }\n                    else if (connection) {\n                        this[kCheckedOut].add(connection);\n                        this.emitAndLog(ConnectionPool.CONNECTION_CHECKED_OUT, new connection_pool_events_1.ConnectionCheckedOutEvent(this, connection));\n                    }\n                    waitQueueMember.timeoutController.clear();\n                    waitQueueMember.callback(err, connection);\n                }\n                process.nextTick(() => this.processWaitQueue());\n            });\n        }\n        this[kProcessingWaitQueue] = false;\n    }\n}\n/**\n * Emitted when the connection pool is created.\n * @event\n */\nConnectionPool.CONNECTION_POOL_CREATED = constants_1.CONNECTION_POOL_CREATED;\n/**\n * Emitted once when the connection pool is closed\n * @event\n */\nConnectionPool.CONNECTION_POOL_CLOSED = constants_1.CONNECTION_POOL_CLOSED;\n/**\n * Emitted each time the connection pool is cleared and it's generation incremented\n * @event\n */\nConnectionPool.CONNECTION_POOL_CLEARED = constants_1.CONNECTION_POOL_CLEARED;\n/**\n * Emitted each time the connection pool is marked ready\n * @event\n */\nConnectionPool.CONNECTION_POOL_READY = constants_1.CONNECTION_POOL_READY;\n/**\n * Emitted when a connection is created.\n * @event\n */\nConnectionPool.CONNECTION_CREATED = constants_1.CONNECTION_CREATED;\n/**\n * Emitted when a connection becomes established, and is ready to use\n * @event\n */\nConnectionPool.CONNECTION_READY = constants_1.CONNECTION_READY;\n/**\n * Emitted when a connection is closed\n * @event\n */\nConnectionPool.CONNECTION_CLOSED = constants_1.CONNECTION_CLOSED;\n/**\n * Emitted when an attempt to check out a connection begins\n * @event\n */\nConnectionPool.CONNECTION_CHECK_OUT_STARTED = constants_1.CONNECTION_CHECK_OUT_STARTED;\n/**\n * Emitted when an attempt to check out a connection fails\n * @event\n */\nConnectionPool.CONNECTION_CHECK_OUT_FAILED = constants_1.CONNECTION_CHECK_OUT_FAILED;\n/**\n * Emitted each time a connection is successfully checked out of the connection pool\n * @event\n */\nConnectionPool.CONNECTION_CHECKED_OUT = constants_1.CONNECTION_CHECKED_OUT;\n/**\n * Emitted each time a connection is successfully checked into the connection pool\n * @event\n */\nConnectionPool.CONNECTION_CHECKED_IN = constants_1.CONNECTION_CHECKED_IN;\nexports.ConnectionPool = ConnectionPool;\n//# sourceMappingURL=connection_pool.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/connection_pool.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/connection_pool_events.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/connection_pool_events.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConnectionPoolClearedEvent = exports.ConnectionCheckedInEvent = exports.ConnectionCheckedOutEvent = exports.ConnectionCheckOutFailedEvent = exports.ConnectionCheckOutStartedEvent = exports.ConnectionClosedEvent = exports.ConnectionReadyEvent = exports.ConnectionCreatedEvent = exports.ConnectionPoolClosedEvent = exports.ConnectionPoolReadyEvent = exports.ConnectionPoolCreatedEvent = exports.ConnectionPoolMonitoringEvent = void 0;\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\n/**\n * The base export class for all monitoring events published from the connection pool\n * @public\n * @category Event\n */\nclass ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool) {\n        this.time = new Date();\n        this.address = pool.address;\n    }\n}\nexports.ConnectionPoolMonitoringEvent = ConnectionPoolMonitoringEvent;\n/**\n * An event published when a connection pool is created\n * @public\n * @category Event\n */\nclass ConnectionPoolCreatedEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_POOL_CREATED;\n        const { maxConnecting, maxPoolSize, minPoolSize, maxIdleTimeMS, waitQueueTimeoutMS } = pool.options;\n        this.options = { maxConnecting, maxPoolSize, minPoolSize, maxIdleTimeMS, waitQueueTimeoutMS };\n    }\n}\nexports.ConnectionPoolCreatedEvent = ConnectionPoolCreatedEvent;\n/**\n * An event published when a connection pool is ready\n * @public\n * @category Event\n */\nclass ConnectionPoolReadyEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_POOL_READY;\n    }\n}\nexports.ConnectionPoolReadyEvent = ConnectionPoolReadyEvent;\n/**\n * An event published when a connection pool is closed\n * @public\n * @category Event\n */\nclass ConnectionPoolClosedEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_POOL_CLOSED;\n    }\n}\nexports.ConnectionPoolClosedEvent = ConnectionPoolClosedEvent;\n/**\n * An event published when a connection pool creates a new connection\n * @public\n * @category Event\n */\nclass ConnectionCreatedEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool, connection) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_CREATED;\n        this.connectionId = connection.id;\n    }\n}\nexports.ConnectionCreatedEvent = ConnectionCreatedEvent;\n/**\n * An event published when a connection is ready for use\n * @public\n * @category Event\n */\nclass ConnectionReadyEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool, connection) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_READY;\n        this.connectionId = connection.id;\n    }\n}\nexports.ConnectionReadyEvent = ConnectionReadyEvent;\n/**\n * An event published when a connection is closed\n * @public\n * @category Event\n */\nclass ConnectionClosedEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool, connection, reason, error) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_CLOSED;\n        this.connectionId = connection.id;\n        this.reason = reason;\n        this.serviceId = connection.serviceId;\n        this.error = error ?? null;\n    }\n}\nexports.ConnectionClosedEvent = ConnectionClosedEvent;\n/**\n * An event published when a request to check a connection out begins\n * @public\n * @category Event\n */\nclass ConnectionCheckOutStartedEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_CHECK_OUT_STARTED;\n    }\n}\nexports.ConnectionCheckOutStartedEvent = ConnectionCheckOutStartedEvent;\n/**\n * An event published when a request to check a connection out fails\n * @public\n * @category Event\n */\nclass ConnectionCheckOutFailedEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool, reason, error) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_CHECK_OUT_FAILED;\n        this.reason = reason;\n        this.error = error;\n    }\n}\nexports.ConnectionCheckOutFailedEvent = ConnectionCheckOutFailedEvent;\n/**\n * An event published when a connection is checked out of the connection pool\n * @public\n * @category Event\n */\nclass ConnectionCheckedOutEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool, connection) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_CHECKED_OUT;\n        this.connectionId = connection.id;\n    }\n}\nexports.ConnectionCheckedOutEvent = ConnectionCheckedOutEvent;\n/**\n * An event published when a connection is checked into the connection pool\n * @public\n * @category Event\n */\nclass ConnectionCheckedInEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool, connection) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_CHECKED_IN;\n        this.connectionId = connection.id;\n    }\n}\nexports.ConnectionCheckedInEvent = ConnectionCheckedInEvent;\n/**\n * An event published when a connection pool is cleared\n * @public\n * @category Event\n */\nclass ConnectionPoolClearedEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool, options = {}) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_POOL_CLEARED;\n        this.serviceId = options.serviceId;\n        this.interruptInUseConnections = options.interruptInUseConnections;\n    }\n}\nexports.ConnectionPoolClearedEvent = ConnectionPoolClearedEvent;\n//# sourceMappingURL=connection_pool_events.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/connection_pool_events.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/errors.js":
/*!*************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/errors.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.WaitQueueTimeoutError = exports.PoolClearedOnNetworkError = exports.PoolClearedError = exports.PoolClosedError = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\n/**\n * An error indicating a connection pool is closed\n * @category Error\n */\nclass PoolClosedError extends error_1.MongoDriverError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(pool) {\n        super('Attempted to check out a connection from closed connection pool');\n        this.address = pool.address;\n    }\n    get name() {\n        return 'MongoPoolClosedError';\n    }\n}\nexports.PoolClosedError = PoolClosedError;\n/**\n * An error indicating a connection pool is currently paused\n * @category Error\n */\nclass PoolClearedError extends error_1.MongoNetworkError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(pool, message) {\n        const errorMessage = message\n            ? message\n            : `Connection pool for ${pool.address} was cleared because another operation failed with: \"${pool.serverError?.message}\"`;\n        super(errorMessage, pool.serverError ? { cause: pool.serverError } : undefined);\n        this.address = pool.address;\n        this.addErrorLabel(error_1.MongoErrorLabel.PoolRequstedRetry);\n    }\n    get name() {\n        return 'MongoPoolClearedError';\n    }\n}\nexports.PoolClearedError = PoolClearedError;\n/**\n * An error indicating that a connection pool has been cleared after the monitor for that server timed out.\n * @category Error\n */\nclass PoolClearedOnNetworkError extends PoolClearedError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(pool) {\n        super(pool, `Connection to ${pool.address} interrupted due to server monitor timeout`);\n    }\n    get name() {\n        return 'PoolClearedOnNetworkError';\n    }\n}\nexports.PoolClearedOnNetworkError = PoolClearedOnNetworkError;\n/**\n * An error thrown when a request to check out a connection times out\n * @category Error\n */\nclass WaitQueueTimeoutError extends error_1.MongoDriverError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, address) {\n        super(message);\n        this.address = address;\n    }\n    get name() {\n        return 'MongoWaitQueueTimeoutError';\n    }\n}\nexports.WaitQueueTimeoutError = WaitQueueTimeoutError;\n//# sourceMappingURL=errors.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/errors.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/handshake/client_metadata.js":
/*!********************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/handshake/client_metadata.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.getFAASEnv = exports.makeClientMetadata = exports.LimitedSizeDocument = void 0;\nconst os = __webpack_require__(/*! os */ \"os\");\nconst process = __webpack_require__(/*! process */ \"process\");\nconst bson_1 = __webpack_require__(/*! ../../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\n// eslint-disable-next-line @typescript-eslint/no-var-requires\nconst NODE_DRIVER_VERSION = (__webpack_require__(/*! ../../../package.json */ \"./node_modules/mongodb/package.json\").version);\n/** @internal */\nclass LimitedSizeDocument {\n    constructor(maxSize) {\n        this.maxSize = maxSize;\n        this.document = new Map();\n        /** BSON overhead: Int32 + Null byte */\n        this.documentSize = 5;\n    }\n    /** Only adds key/value if the bsonByteLength is less than MAX_SIZE */\n    ifItFitsItSits(key, value) {\n        // The BSON byteLength of the new element is the same as serializing it to its own document\n        // subtracting the document size int32 and the null terminator.\n        const newElementSize = bson_1.BSON.serialize(new Map().set(key, value)).byteLength - 5;\n        if (newElementSize + this.documentSize > this.maxSize) {\n            return false;\n        }\n        this.documentSize += newElementSize;\n        this.document.set(key, value);\n        return true;\n    }\n    toObject() {\n        return bson_1.BSON.deserialize(bson_1.BSON.serialize(this.document), {\n            promoteLongs: false,\n            promoteBuffers: false,\n            promoteValues: false,\n            useBigInt64: false\n        });\n    }\n}\nexports.LimitedSizeDocument = LimitedSizeDocument;\n/**\n * From the specs:\n * Implementors SHOULD cumulatively update fields in the following order until the document is under the size limit:\n * 1. Omit fields from `env` except `env.name`.\n * 2. Omit fields from `os` except `os.type`.\n * 3. Omit the `env` document entirely.\n * 4. Truncate `platform`. -- special we do not truncate this field\n */\nfunction makeClientMetadata(options) {\n    const metadataDocument = new LimitedSizeDocument(512);\n    const { appName = '' } = options;\n    // Add app name first, it must be sent\n    if (appName.length > 0) {\n        const name = Buffer.byteLength(appName, 'utf8') <= 128\n            ? options.appName\n            : Buffer.from(appName, 'utf8').subarray(0, 128).toString('utf8');\n        metadataDocument.ifItFitsItSits('application', { name });\n    }\n    const { name = '', version = '', platform = '' } = options.driverInfo;\n    const driverInfo = {\n        name: name.length > 0 ? `nodejs|${name}` : 'nodejs',\n        version: version.length > 0 ? `${NODE_DRIVER_VERSION}|${version}` : NODE_DRIVER_VERSION\n    };\n    if (!metadataDocument.ifItFitsItSits('driver', driverInfo)) {\n        throw new error_1.MongoInvalidArgumentError('Unable to include driverInfo name and version, metadata cannot exceed 512 bytes');\n    }\n    let runtimeInfo = getRuntimeInfo();\n    if (platform.length > 0) {\n        runtimeInfo = `${runtimeInfo}|${platform}`;\n    }\n    if (!metadataDocument.ifItFitsItSits('platform', runtimeInfo)) {\n        throw new error_1.MongoInvalidArgumentError('Unable to include driverInfo platform, metadata cannot exceed 512 bytes');\n    }\n    // Note: order matters, os.type is last so it will be removed last if we're at maxSize\n    const osInfo = new Map()\n        .set('name', process.platform)\n        .set('architecture', process.arch)\n        .set('version', os.release())\n        .set('type', os.type());\n    if (!metadataDocument.ifItFitsItSits('os', osInfo)) {\n        for (const key of osInfo.keys()) {\n            osInfo.delete(key);\n            if (osInfo.size === 0)\n                break;\n            if (metadataDocument.ifItFitsItSits('os', osInfo))\n                break;\n        }\n    }\n    const faasEnv = getFAASEnv();\n    if (faasEnv != null) {\n        if (!metadataDocument.ifItFitsItSits('env', faasEnv)) {\n            for (const key of faasEnv.keys()) {\n                faasEnv.delete(key);\n                if (faasEnv.size === 0)\n                    break;\n                if (metadataDocument.ifItFitsItSits('env', faasEnv))\n                    break;\n            }\n        }\n    }\n    return metadataDocument.toObject();\n}\nexports.makeClientMetadata = makeClientMetadata;\n/**\n * Collects FaaS metadata.\n * - `name` MUST be the last key in the Map returned.\n */\nfunction getFAASEnv() {\n    const { AWS_EXECUTION_ENV = '', AWS_LAMBDA_RUNTIME_API = '', FUNCTIONS_WORKER_RUNTIME = '', K_SERVICE = '', FUNCTION_NAME = '', VERCEL = '', AWS_LAMBDA_FUNCTION_MEMORY_SIZE = '', AWS_REGION = '', FUNCTION_MEMORY_MB = '', FUNCTION_REGION = '', FUNCTION_TIMEOUT_SEC = '', VERCEL_REGION = '' } = process.env;\n    const isAWSFaaS = AWS_EXECUTION_ENV.startsWith('AWS_Lambda_') || AWS_LAMBDA_RUNTIME_API.length > 0;\n    const isAzureFaaS = FUNCTIONS_WORKER_RUNTIME.length > 0;\n    const isGCPFaaS = K_SERVICE.length > 0 || FUNCTION_NAME.length > 0;\n    const isVercelFaaS = VERCEL.length > 0;\n    // Note: order matters, name must always be the last key\n    const faasEnv = new Map();\n    // When isVercelFaaS is true so is isAWSFaaS; Vercel inherits the AWS env\n    if (isVercelFaaS && !(isAzureFaaS || isGCPFaaS)) {\n        if (VERCEL_REGION.length > 0) {\n            faasEnv.set('region', VERCEL_REGION);\n        }\n        faasEnv.set('name', 'vercel');\n        return faasEnv;\n    }\n    if (isAWSFaaS && !(isAzureFaaS || isGCPFaaS || isVercelFaaS)) {\n        if (AWS_REGION.length > 0) {\n            faasEnv.set('region', AWS_REGION);\n        }\n        if (AWS_LAMBDA_FUNCTION_MEMORY_SIZE.length > 0 &&\n            Number.isInteger(+AWS_LAMBDA_FUNCTION_MEMORY_SIZE)) {\n            faasEnv.set('memory_mb', new bson_1.Int32(AWS_LAMBDA_FUNCTION_MEMORY_SIZE));\n        }\n        faasEnv.set('name', 'aws.lambda');\n        return faasEnv;\n    }\n    if (isAzureFaaS && !(isGCPFaaS || isAWSFaaS || isVercelFaaS)) {\n        faasEnv.set('name', 'azure.func');\n        return faasEnv;\n    }\n    if (isGCPFaaS && !(isAzureFaaS || isAWSFaaS || isVercelFaaS)) {\n        if (FUNCTION_REGION.length > 0) {\n            faasEnv.set('region', FUNCTION_REGION);\n        }\n        if (FUNCTION_MEMORY_MB.length > 0 && Number.isInteger(+FUNCTION_MEMORY_MB)) {\n            faasEnv.set('memory_mb', new bson_1.Int32(FUNCTION_MEMORY_MB));\n        }\n        if (FUNCTION_TIMEOUT_SEC.length > 0 && Number.isInteger(+FUNCTION_TIMEOUT_SEC)) {\n            faasEnv.set('timeout_sec', new bson_1.Int32(FUNCTION_TIMEOUT_SEC));\n        }\n        faasEnv.set('name', 'gcp.func');\n        return faasEnv;\n    }\n    return null;\n}\nexports.getFAASEnv = getFAASEnv;\n/**\n * @internal\n * Get current JavaScript runtime platform\n *\n * NOTE: The version information fetching is intentionally written defensively\n * to avoid having a released driver version that becomes incompatible\n * with a future change to these global objects.\n */\nfunction getRuntimeInfo() {\n    if ('Deno' in globalThis) {\n        const version = typeof Deno?.version?.deno === 'string' ? Deno?.version?.deno : '0.0.0-unknown';\n        return `Deno v${version}, ${os.endianness()}`;\n    }\n    if ('Bun' in globalThis) {\n        const version = typeof Bun?.version === 'string' ? Bun?.version : '0.0.0-unknown';\n        return `Bun v${version}, ${os.endianness()}`;\n    }\n    return `Node.js ${process.version}, ${os.endianness()}`;\n}\n//# sourceMappingURL=client_metadata.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/handshake/client_metadata.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/message_stream.js":
/*!*********************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/message_stream.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MessageStream = void 0;\nconst stream_1 = __webpack_require__(/*! stream */ \"stream\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst commands_1 = __webpack_require__(/*! ./commands */ \"./node_modules/mongodb/lib/cmap/commands.js\");\nconst compression_1 = __webpack_require__(/*! ./wire_protocol/compression */ \"./node_modules/mongodb/lib/cmap/wire_protocol/compression.js\");\nconst constants_1 = __webpack_require__(/*! ./wire_protocol/constants */ \"./node_modules/mongodb/lib/cmap/wire_protocol/constants.js\");\nconst MESSAGE_HEADER_SIZE = 16;\nconst COMPRESSION_DETAILS_SIZE = 9; // originalOpcode + uncompressedSize, compressorID\nconst kDefaultMaxBsonMessageSize = 1024 * 1024 * 16 * 4;\n/** @internal */\nconst kBuffer = Symbol('buffer');\n/**\n * A duplex stream that is capable of reading and writing raw wire protocol messages, with\n * support for optional compression\n * @internal\n */\nclass MessageStream extends stream_1.Duplex {\n    constructor(options = {}) {\n        super(options);\n        /** @internal */\n        this.isMonitoringConnection = false;\n        this.maxBsonMessageSize = options.maxBsonMessageSize || kDefaultMaxBsonMessageSize;\n        this[kBuffer] = new utils_1.BufferPool();\n    }\n    get buffer() {\n        return this[kBuffer];\n    }\n    _write(chunk, _, callback) {\n        this[kBuffer].append(chunk);\n        processIncomingData(this, callback);\n    }\n    _read( /* size */) {\n        // NOTE: This implementation is empty because we explicitly push data to be read\n        //       when `writeMessage` is called.\n        return;\n    }\n    writeCommand(command, operationDescription) {\n        const agreedCompressor = operationDescription.agreedCompressor ?? 'none';\n        if (agreedCompressor === 'none' || !commands_1.OpCompressedRequest.canCompress(command)) {\n            const data = command.toBin();\n            this.push(Array.isArray(data) ? Buffer.concat(data) : data);\n            return;\n        }\n        // otherwise, compress the message\n        const concatenatedOriginalCommandBuffer = Buffer.concat(command.toBin());\n        const messageToBeCompressed = concatenatedOriginalCommandBuffer.slice(MESSAGE_HEADER_SIZE);\n        // Extract information needed for OP_COMPRESSED from the uncompressed message\n        const originalCommandOpCode = concatenatedOriginalCommandBuffer.readInt32LE(12);\n        const options = {\n            agreedCompressor,\n            zlibCompressionLevel: operationDescription.zlibCompressionLevel ?? 0\n        };\n        // Compress the message body\n        (0, compression_1.compress)(options, messageToBeCompressed).then(compressedMessage => {\n            // Create the msgHeader of OP_COMPRESSED\n            const msgHeader = Buffer.alloc(MESSAGE_HEADER_SIZE);\n            msgHeader.writeInt32LE(MESSAGE_HEADER_SIZE + COMPRESSION_DETAILS_SIZE + compressedMessage.length, 0); // messageLength\n            msgHeader.writeInt32LE(command.requestId, 4); // requestID\n            msgHeader.writeInt32LE(0, 8); // responseTo (zero)\n            msgHeader.writeInt32LE(constants_1.OP_COMPRESSED, 12); // opCode\n            // Create the compression details of OP_COMPRESSED\n            const compressionDetails = Buffer.alloc(COMPRESSION_DETAILS_SIZE);\n            compressionDetails.writeInt32LE(originalCommandOpCode, 0); // originalOpcode\n            compressionDetails.writeInt32LE(messageToBeCompressed.length, 4); // Size of the uncompressed compressedMessage, excluding the MsgHeader\n            compressionDetails.writeUInt8(compression_1.Compressor[agreedCompressor], 8); // compressorID\n            this.push(Buffer.concat([msgHeader, compressionDetails, compressedMessage]));\n        }, error => {\n            operationDescription.cb(error);\n        });\n    }\n}\nexports.MessageStream = MessageStream;\nfunction processIncomingData(stream, callback) {\n    const buffer = stream[kBuffer];\n    const sizeOfMessage = buffer.getInt32();\n    if (sizeOfMessage == null) {\n        return callback();\n    }\n    if (sizeOfMessage < 0) {\n        return callback(new error_1.MongoParseError(`Invalid message size: ${sizeOfMessage}`));\n    }\n    if (sizeOfMessage > stream.maxBsonMessageSize) {\n        return callback(new error_1.MongoParseError(`Invalid message size: ${sizeOfMessage}, max allowed: ${stream.maxBsonMessageSize}`));\n    }\n    if (sizeOfMessage > buffer.length) {\n        return callback();\n    }\n    const message = buffer.read(sizeOfMessage);\n    const messageHeader = {\n        length: message.readInt32LE(0),\n        requestId: message.readInt32LE(4),\n        responseTo: message.readInt32LE(8),\n        opCode: message.readInt32LE(12)\n    };\n    const monitorHasAnotherHello = () => {\n        if (stream.isMonitoringConnection) {\n            // Can we read the next message size?\n            const sizeOfMessage = buffer.getInt32();\n            if (sizeOfMessage != null && sizeOfMessage <= buffer.length) {\n                return true;\n            }\n        }\n        return false;\n    };\n    let ResponseType = messageHeader.opCode === constants_1.OP_MSG ? commands_1.OpMsgResponse : commands_1.OpQueryResponse;\n    if (messageHeader.opCode !== constants_1.OP_COMPRESSED) {\n        const messageBody = message.subarray(MESSAGE_HEADER_SIZE);\n        // If we are a monitoring connection message stream and\n        // there is more in the buffer that can be read, skip processing since we\n        // want the last hello command response that is in the buffer.\n        if (monitorHasAnotherHello()) {\n            return processIncomingData(stream, callback);\n        }\n        stream.emit('message', new ResponseType(message, messageHeader, messageBody));\n        if (buffer.length >= 4) {\n            return processIncomingData(stream, callback);\n        }\n        return callback();\n    }\n    messageHeader.fromCompressed = true;\n    messageHeader.opCode = message.readInt32LE(MESSAGE_HEADER_SIZE);\n    messageHeader.length = message.readInt32LE(MESSAGE_HEADER_SIZE + 4);\n    const compressorID = message[MESSAGE_HEADER_SIZE + 8];\n    const compressedBuffer = message.slice(MESSAGE_HEADER_SIZE + 9);\n    // recalculate based on wrapped opcode\n    ResponseType = messageHeader.opCode === constants_1.OP_MSG ? commands_1.OpMsgResponse : commands_1.OpQueryResponse;\n    (0, compression_1.decompress)(compressorID, compressedBuffer).then(messageBody => {\n        if (messageBody.length !== messageHeader.length) {\n            return callback(new error_1.MongoDecompressionError('Message body and message header must be the same length'));\n        }\n        // If we are a monitoring connection message stream and\n        // there is more in the buffer that can be read, skip processing since we\n        // want the last hello command response that is in the buffer.\n        if (monitorHasAnotherHello()) {\n            return processIncomingData(stream, callback);\n        }\n        stream.emit('message', new ResponseType(message, messageHeader, messageBody));\n        if (buffer.length >= 4) {\n            return processIncomingData(stream, callback);\n        }\n        return callback();\n    }, error => {\n        return callback(error);\n    });\n}\n//# sourceMappingURL=message_stream.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/message_stream.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/metrics.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/metrics.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConnectionPoolMetrics = void 0;\n/** @internal */\nclass ConnectionPoolMetrics {\n    constructor() {\n        this.txnConnections = 0;\n        this.cursorConnections = 0;\n        this.otherConnections = 0;\n    }\n    /**\n     * Mark a connection as pinned for a specific operation.\n     */\n    markPinned(pinType) {\n        if (pinType === ConnectionPoolMetrics.TXN) {\n            this.txnConnections += 1;\n        }\n        else if (pinType === ConnectionPoolMetrics.CURSOR) {\n            this.cursorConnections += 1;\n        }\n        else {\n            this.otherConnections += 1;\n        }\n    }\n    /**\n     * Unmark a connection as pinned for an operation.\n     */\n    markUnpinned(pinType) {\n        if (pinType === ConnectionPoolMetrics.TXN) {\n            this.txnConnections -= 1;\n        }\n        else if (pinType === ConnectionPoolMetrics.CURSOR) {\n            this.cursorConnections -= 1;\n        }\n        else {\n            this.otherConnections -= 1;\n        }\n    }\n    /**\n     * Return information about the cmap metrics as a string.\n     */\n    info(maxPoolSize) {\n        return ('Timed out while checking out a connection from connection pool: ' +\n            `maxPoolSize: ${maxPoolSize}, ` +\n            `connections in use by cursors: ${this.cursorConnections}, ` +\n            `connections in use by transactions: ${this.txnConnections}, ` +\n            `connections in use by other operations: ${this.otherConnections}`);\n    }\n    /**\n     * Reset the metrics to the initial values.\n     */\n    reset() {\n        this.txnConnections = 0;\n        this.cursorConnections = 0;\n        this.otherConnections = 0;\n    }\n}\nConnectionPoolMetrics.TXN = 'txn';\nConnectionPoolMetrics.CURSOR = 'cursor';\nConnectionPoolMetrics.OTHER = 'other';\nexports.ConnectionPoolMetrics = ConnectionPoolMetrics;\n//# sourceMappingURL=metrics.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/metrics.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/stream_description.js":
/*!*************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/stream_description.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.StreamDescription = void 0;\nconst common_1 = __webpack_require__(/*! ../sdam/common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst server_description_1 = __webpack_require__(/*! ../sdam/server_description */ \"./node_modules/mongodb/lib/sdam/server_description.js\");\nconst RESPONSE_FIELDS = [\n    'minWireVersion',\n    'maxWireVersion',\n    'maxBsonObjectSize',\n    'maxMessageSizeBytes',\n    'maxWriteBatchSize',\n    'logicalSessionTimeoutMinutes'\n];\n/** @public */\nclass StreamDescription {\n    constructor(address, options) {\n        this.address = address;\n        this.type = common_1.ServerType.Unknown;\n        this.minWireVersion = undefined;\n        this.maxWireVersion = undefined;\n        this.maxBsonObjectSize = 16777216;\n        this.maxMessageSizeBytes = 48000000;\n        this.maxWriteBatchSize = 100000;\n        this.logicalSessionTimeoutMinutes = options?.logicalSessionTimeoutMinutes;\n        this.loadBalanced = !!options?.loadBalanced;\n        this.compressors =\n            options && options.compressors && Array.isArray(options.compressors)\n                ? options.compressors\n                : [];\n    }\n    receiveResponse(response) {\n        if (response == null) {\n            return;\n        }\n        this.type = (0, server_description_1.parseServerType)(response);\n        for (const field of RESPONSE_FIELDS) {\n            if (response[field] != null) {\n                this[field] = response[field];\n            }\n            // testing case\n            if ('__nodejs_mock_server__' in response) {\n                this.__nodejs_mock_server__ = response['__nodejs_mock_server__'];\n            }\n        }\n        if (response.compression) {\n            this.compressor = this.compressors.filter(c => response.compression?.includes(c))[0];\n        }\n    }\n}\nexports.StreamDescription = StreamDescription;\n//# sourceMappingURL=stream_description.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/stream_description.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/wire_protocol/compression.js":
/*!********************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/wire_protocol/compression.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.decompressResponse = exports.compressCommand = exports.decompress = exports.compress = exports.uncompressibleCommands = exports.Compressor = void 0;\nconst util_1 = __webpack_require__(/*! util */ \"util\");\nconst zlib = __webpack_require__(/*! zlib */ \"zlib\");\nconst constants_1 = __webpack_require__(/*! ../../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst deps_1 = __webpack_require__(/*! ../../deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst commands_1 = __webpack_require__(/*! ../commands */ \"./node_modules/mongodb/lib/cmap/commands.js\");\nconst constants_2 = __webpack_require__(/*! ./constants */ \"./node_modules/mongodb/lib/cmap/wire_protocol/constants.js\");\n/** @public */\nexports.Compressor = Object.freeze({\n    none: 0,\n    snappy: 1,\n    zlib: 2,\n    zstd: 3\n});\nexports.uncompressibleCommands = new Set([\n    constants_1.LEGACY_HELLO_COMMAND,\n    'saslStart',\n    'saslContinue',\n    'getnonce',\n    'authenticate',\n    'createUser',\n    'updateUser',\n    'copydbSaslStart',\n    'copydbgetnonce',\n    'copydb'\n]);\nconst ZSTD_COMPRESSION_LEVEL = 3;\nconst zlibInflate = (0, util_1.promisify)(zlib.inflate.bind(zlib));\nconst zlibDeflate = (0, util_1.promisify)(zlib.deflate.bind(zlib));\nlet zstd;\nlet Snappy = null;\nfunction loadSnappy() {\n    if (Snappy == null) {\n        const snappyImport = (0, deps_1.getSnappy)();\n        if ('kModuleError' in snappyImport) {\n            throw snappyImport.kModuleError;\n        }\n        Snappy = snappyImport;\n    }\n    return Snappy;\n}\n// Facilitate compressing a message using an agreed compressor\nasync function compress(options, dataToBeCompressed) {\n    const zlibOptions = {};\n    switch (options.agreedCompressor) {\n        case 'snappy': {\n            Snappy ??= loadSnappy();\n            return Snappy.compress(dataToBeCompressed);\n        }\n        case 'zstd': {\n            loadZstd();\n            if ('kModuleError' in zstd) {\n                throw zstd['kModuleError'];\n            }\n            return zstd.compress(dataToBeCompressed, ZSTD_COMPRESSION_LEVEL);\n        }\n        case 'zlib': {\n            if (options.zlibCompressionLevel) {\n                zlibOptions.level = options.zlibCompressionLevel;\n            }\n            return zlibDeflate(dataToBeCompressed, zlibOptions);\n        }\n        default: {\n            throw new error_1.MongoInvalidArgumentError(`Unknown compressor ${options.agreedCompressor} failed to compress`);\n        }\n    }\n}\nexports.compress = compress;\n// Decompress a message using the given compressor\nasync function decompress(compressorID, compressedData) {\n    if (compressorID !== exports.Compressor.snappy &&\n        compressorID !== exports.Compressor.zstd &&\n        compressorID !== exports.Compressor.zlib &&\n        compressorID !== exports.Compressor.none) {\n        throw new error_1.MongoDecompressionError(`Server sent message compressed using an unsupported compressor. (Received compressor ID ${compressorID})`);\n    }\n    switch (compressorID) {\n        case exports.Compressor.snappy: {\n            Snappy ??= loadSnappy();\n            return Snappy.uncompress(compressedData, { asBuffer: true });\n        }\n        case exports.Compressor.zstd: {\n            loadZstd();\n            if ('kModuleError' in zstd) {\n                throw zstd['kModuleError'];\n            }\n            return zstd.decompress(compressedData);\n        }\n        case exports.Compressor.zlib: {\n            return zlibInflate(compressedData);\n        }\n        default: {\n            return compressedData;\n        }\n    }\n}\nexports.decompress = decompress;\n/**\n * Load ZStandard if it is not already set.\n */\nfunction loadZstd() {\n    if (!zstd) {\n        zstd = (0, deps_1.getZstdLibrary)();\n    }\n}\nconst MESSAGE_HEADER_SIZE = 16;\n/**\n * @internal\n *\n * Compresses an OP_MSG or OP_QUERY message, if compression is configured.  This method\n * also serializes the command to BSON.\n */\nasync function compressCommand(command, description) {\n    const finalCommand = description.agreedCompressor === 'none' || !commands_1.OpCompressedRequest.canCompress(command)\n        ? command\n        : new commands_1.OpCompressedRequest(command, {\n            agreedCompressor: description.agreedCompressor ?? 'none',\n            zlibCompressionLevel: description.zlibCompressionLevel ?? 0\n        });\n    const data = await finalCommand.toBin();\n    return Buffer.concat(data);\n}\nexports.compressCommand = compressCommand;\n/**\n * @internal\n *\n * Decompresses an OP_MSG or OP_QUERY response from the server, if compression is configured.\n *\n * This method does not parse the response's BSON.\n */\nasync function decompressResponse(message) {\n    const messageHeader = {\n        length: message.readInt32LE(0),\n        requestId: message.readInt32LE(4),\n        responseTo: message.readInt32LE(8),\n        opCode: message.readInt32LE(12)\n    };\n    if (messageHeader.opCode !== constants_2.OP_COMPRESSED) {\n        const ResponseType = messageHeader.opCode === constants_2.OP_MSG ? commands_1.OpMsgResponse : commands_1.OpQueryResponse;\n        const messageBody = message.subarray(MESSAGE_HEADER_SIZE);\n        return new ResponseType(message, messageHeader, messageBody);\n    }\n    const header = {\n        ...messageHeader,\n        fromCompressed: true,\n        opCode: message.readInt32LE(MESSAGE_HEADER_SIZE),\n        length: message.readInt32LE(MESSAGE_HEADER_SIZE + 4)\n    };\n    const compressorID = message[MESSAGE_HEADER_SIZE + 8];\n    const compressedBuffer = message.slice(MESSAGE_HEADER_SIZE + 9);\n    // recalculate based on wrapped opcode\n    const ResponseType = header.opCode === constants_2.OP_MSG ? commands_1.OpMsgResponse : commands_1.OpQueryResponse;\n    const messageBody = await decompress(compressorID, compressedBuffer);\n    if (messageBody.length !== header.length) {\n        throw new error_1.MongoDecompressionError('Message body and message header must be the same length');\n    }\n    return new ResponseType(message, header, messageBody);\n}\nexports.decompressResponse = decompressResponse;\n//# sourceMappingURL=compression.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/wire_protocol/compression.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/wire_protocol/constants.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/wire_protocol/constants.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.OP_MSG = exports.OP_COMPRESSED = exports.OP_DELETE = exports.OP_QUERY = exports.OP_INSERT = exports.OP_UPDATE = exports.OP_REPLY = exports.MIN_SUPPORTED_QE_SERVER_VERSION = exports.MIN_SUPPORTED_QE_WIRE_VERSION = exports.MAX_SUPPORTED_WIRE_VERSION = exports.MIN_SUPPORTED_WIRE_VERSION = exports.MAX_SUPPORTED_SERVER_VERSION = exports.MIN_SUPPORTED_SERVER_VERSION = void 0;\nexports.MIN_SUPPORTED_SERVER_VERSION = '3.6';\nexports.MAX_SUPPORTED_SERVER_VERSION = '7.0';\nexports.MIN_SUPPORTED_WIRE_VERSION = 6;\nexports.MAX_SUPPORTED_WIRE_VERSION = 21;\nexports.MIN_SUPPORTED_QE_WIRE_VERSION = 21;\nexports.MIN_SUPPORTED_QE_SERVER_VERSION = '7.0';\nexports.OP_REPLY = 1;\nexports.OP_UPDATE = 2001;\nexports.OP_INSERT = 2002;\nexports.OP_QUERY = 2004;\nexports.OP_DELETE = 2006;\nexports.OP_COMPRESSED = 2012;\nexports.OP_MSG = 2013;\n//# sourceMappingURL=constants.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/wire_protocol/constants.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/wire_protocol/shared.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/wire_protocol/shared.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.isSharded = exports.getReadPreference = void 0;\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_preference_1 = __webpack_require__(/*! ../../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst common_1 = __webpack_require__(/*! ../../sdam/common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst topology_description_1 = __webpack_require__(/*! ../../sdam/topology_description */ \"./node_modules/mongodb/lib/sdam/topology_description.js\");\nfunction getReadPreference(options) {\n    // Default to command version of the readPreference\n    let readPreference = options?.readPreference ?? read_preference_1.ReadPreference.primary;\n    // If we have an option readPreference override the command one\n    if (options?.readPreference) {\n        readPreference = options.readPreference;\n    }\n    if (typeof readPreference === 'string') {\n        readPreference = read_preference_1.ReadPreference.fromString(readPreference);\n    }\n    if (!(readPreference instanceof read_preference_1.ReadPreference)) {\n        throw new error_1.MongoInvalidArgumentError('Option \"readPreference\" must be a ReadPreference instance');\n    }\n    return readPreference;\n}\nexports.getReadPreference = getReadPreference;\nfunction isSharded(topologyOrServer) {\n    if (topologyOrServer == null) {\n        return false;\n    }\n    if (topologyOrServer.description && topologyOrServer.description.type === common_1.ServerType.Mongos) {\n        return true;\n    }\n    // NOTE: This is incredibly inefficient, and should be removed once command construction\n    //       happens based on `Server` not `Topology`.\n    if (topologyOrServer.description && topologyOrServer.description instanceof topology_description_1.TopologyDescription) {\n        const servers = Array.from(topologyOrServer.description.servers.values());\n        return servers.some((server) => server.type === common_1.ServerType.Mongos);\n    }\n    return false;\n}\nexports.isSharded = isSharded;\n//# sourceMappingURL=shared.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cmap/wire_protocol/shared.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/collection.js":
/*!************************************************!*\
  !*** ./node_modules/mongodb/lib/collection.js ***!
  \************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Collection = void 0;\nconst bson_1 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst ordered_1 = __webpack_require__(/*! ./bulk/ordered */ \"./node_modules/mongodb/lib/bulk/ordered.js\");\nconst unordered_1 = __webpack_require__(/*! ./bulk/unordered */ \"./node_modules/mongodb/lib/bulk/unordered.js\");\nconst change_stream_1 = __webpack_require__(/*! ./change_stream */ \"./node_modules/mongodb/lib/change_stream.js\");\nconst aggregation_cursor_1 = __webpack_require__(/*! ./cursor/aggregation_cursor */ \"./node_modules/mongodb/lib/cursor/aggregation_cursor.js\");\nconst find_cursor_1 = __webpack_require__(/*! ./cursor/find_cursor */ \"./node_modules/mongodb/lib/cursor/find_cursor.js\");\nconst list_indexes_cursor_1 = __webpack_require__(/*! ./cursor/list_indexes_cursor */ \"./node_modules/mongodb/lib/cursor/list_indexes_cursor.js\");\nconst list_search_indexes_cursor_1 = __webpack_require__(/*! ./cursor/list_search_indexes_cursor */ \"./node_modules/mongodb/lib/cursor/list_search_indexes_cursor.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst bulk_write_1 = __webpack_require__(/*! ./operations/bulk_write */ \"./node_modules/mongodb/lib/operations/bulk_write.js\");\nconst count_1 = __webpack_require__(/*! ./operations/count */ \"./node_modules/mongodb/lib/operations/count.js\");\nconst count_documents_1 = __webpack_require__(/*! ./operations/count_documents */ \"./node_modules/mongodb/lib/operations/count_documents.js\");\nconst delete_1 = __webpack_require__(/*! ./operations/delete */ \"./node_modules/mongodb/lib/operations/delete.js\");\nconst distinct_1 = __webpack_require__(/*! ./operations/distinct */ \"./node_modules/mongodb/lib/operations/distinct.js\");\nconst drop_1 = __webpack_require__(/*! ./operations/drop */ \"./node_modules/mongodb/lib/operations/drop.js\");\nconst estimated_document_count_1 = __webpack_require__(/*! ./operations/estimated_document_count */ \"./node_modules/mongodb/lib/operations/estimated_document_count.js\");\nconst execute_operation_1 = __webpack_require__(/*! ./operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst find_and_modify_1 = __webpack_require__(/*! ./operations/find_and_modify */ \"./node_modules/mongodb/lib/operations/find_and_modify.js\");\nconst indexes_1 = __webpack_require__(/*! ./operations/indexes */ \"./node_modules/mongodb/lib/operations/indexes.js\");\nconst insert_1 = __webpack_require__(/*! ./operations/insert */ \"./node_modules/mongodb/lib/operations/insert.js\");\nconst is_capped_1 = __webpack_require__(/*! ./operations/is_capped */ \"./node_modules/mongodb/lib/operations/is_capped.js\");\nconst options_operation_1 = __webpack_require__(/*! ./operations/options_operation */ \"./node_modules/mongodb/lib/operations/options_operation.js\");\nconst rename_1 = __webpack_require__(/*! ./operations/rename */ \"./node_modules/mongodb/lib/operations/rename.js\");\nconst create_1 = __webpack_require__(/*! ./operations/search_indexes/create */ \"./node_modules/mongodb/lib/operations/search_indexes/create.js\");\nconst drop_2 = __webpack_require__(/*! ./operations/search_indexes/drop */ \"./node_modules/mongodb/lib/operations/search_indexes/drop.js\");\nconst update_1 = __webpack_require__(/*! ./operations/search_indexes/update */ \"./node_modules/mongodb/lib/operations/search_indexes/update.js\");\nconst update_2 = __webpack_require__(/*! ./operations/update */ \"./node_modules/mongodb/lib/operations/update.js\");\nconst read_concern_1 = __webpack_require__(/*! ./read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst read_preference_1 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst write_concern_1 = __webpack_require__(/*! ./write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\n/**\n * The **Collection** class is an internal class that embodies a MongoDB collection\n * allowing for insert/find/update/delete and other command operation on that MongoDB collection.\n *\n * **COLLECTION Cannot directly be instantiated**\n * @public\n *\n * @example\n * ```ts\n * import { MongoClient } from 'mongodb';\n *\n * interface Pet {\n *   name: string;\n *   kind: 'dog' | 'cat' | 'fish';\n * }\n *\n * const client = new MongoClient('mongodb://localhost:27017');\n * const pets = client.db().collection<Pet>('pets');\n *\n * const petCursor = pets.find();\n *\n * for await (const pet of petCursor) {\n *   console.log(`${pet.name} is a ${pet.kind}!`);\n * }\n * ```\n */\nclass Collection {\n    /**\n     * Create a new Collection instance\n     * @internal\n     */\n    constructor(db, name, options) {\n        // Internal state\n        this.s = {\n            db,\n            options,\n            namespace: new utils_1.MongoDBCollectionNamespace(db.databaseName, name),\n            pkFactory: db.options?.pkFactory ?? utils_1.DEFAULT_PK_FACTORY,\n            readPreference: read_preference_1.ReadPreference.fromOptions(options),\n            bsonOptions: (0, bson_1.resolveBSONOptions)(options, db),\n            readConcern: read_concern_1.ReadConcern.fromOptions(options),\n            writeConcern: write_concern_1.WriteConcern.fromOptions(options)\n        };\n        this.client = db.client;\n    }\n    /**\n     * The name of the database this collection belongs to\n     */\n    get dbName() {\n        return this.s.namespace.db;\n    }\n    /**\n     * The name of this collection\n     */\n    get collectionName() {\n        return this.s.namespace.collection;\n    }\n    /**\n     * The namespace of this collection, in the format `${this.dbName}.${this.collectionName}`\n     */\n    get namespace() {\n        return this.fullNamespace.toString();\n    }\n    /**\n     *  @internal\n     *\n     * The `MongoDBNamespace` for the collection.\n     */\n    get fullNamespace() {\n        return this.s.namespace;\n    }\n    /**\n     * The current readConcern of the collection. If not explicitly defined for\n     * this collection, will be inherited from the parent DB\n     */\n    get readConcern() {\n        if (this.s.readConcern == null) {\n            return this.s.db.readConcern;\n        }\n        return this.s.readConcern;\n    }\n    /**\n     * The current readPreference of the collection. If not explicitly defined for\n     * this collection, will be inherited from the parent DB\n     */\n    get readPreference() {\n        if (this.s.readPreference == null) {\n            return this.s.db.readPreference;\n        }\n        return this.s.readPreference;\n    }\n    get bsonOptions() {\n        return this.s.bsonOptions;\n    }\n    /**\n     * The current writeConcern of the collection. If not explicitly defined for\n     * this collection, will be inherited from the parent DB\n     */\n    get writeConcern() {\n        if (this.s.writeConcern == null) {\n            return this.s.db.writeConcern;\n        }\n        return this.s.writeConcern;\n    }\n    /** The current index hint for the collection */\n    get hint() {\n        return this.s.collectionHint;\n    }\n    set hint(v) {\n        this.s.collectionHint = (0, utils_1.normalizeHintField)(v);\n    }\n    /**\n     * Inserts a single document into MongoDB. If documents passed in do not contain the **_id** field,\n     * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n     * can be overridden by setting the **forceServerObjectId** flag.\n     *\n     * @param doc - The document to insert\n     * @param options - Optional settings for the command\n     */\n    async insertOne(doc, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new insert_1.InsertOneOperation(this, doc, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Inserts an array of documents into MongoDB. If documents passed in do not contain the **_id** field,\n     * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n     * can be overridden by setting the **forceServerObjectId** flag.\n     *\n     * @param docs - The documents to insert\n     * @param options - Optional settings for the command\n     */\n    async insertMany(docs, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new insert_1.InsertManyOperation(this, docs, (0, utils_1.resolveOptions)(this, options ?? { ordered: true })));\n    }\n    /**\n     * Perform a bulkWrite operation without a fluent API\n     *\n     * Legal operation types are\n     * - `insertOne`\n     * - `replaceOne`\n     * - `updateOne`\n     * - `updateMany`\n     * - `deleteOne`\n     * - `deleteMany`\n     *\n     * If documents passed in do not contain the **_id** field,\n     * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n     * can be overridden by setting the **forceServerObjectId** flag.\n     *\n     * @param operations - Bulk operations to perform\n     * @param options - Optional settings for the command\n     * @throws MongoDriverError if operations is not an array\n     */\n    async bulkWrite(operations, options) {\n        if (!Array.isArray(operations)) {\n            throw new error_1.MongoInvalidArgumentError('Argument \"operations\" must be an array of documents');\n        }\n        return (0, execute_operation_1.executeOperation)(this.client, new bulk_write_1.BulkWriteOperation(this, operations, (0, utils_1.resolveOptions)(this, options ?? { ordered: true })));\n    }\n    /**\n     * Update a single document in a collection\n     *\n     * @param filter - The filter used to select the document to update\n     * @param update - The update operations to be applied to the document\n     * @param options - Optional settings for the command\n     */\n    async updateOne(filter, update, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new update_2.UpdateOneOperation(this, filter, update, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Replace a document in a collection with another document\n     *\n     * @param filter - The filter used to select the document to replace\n     * @param replacement - The Document that replaces the matching document\n     * @param options - Optional settings for the command\n     */\n    async replaceOne(filter, replacement, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new update_2.ReplaceOneOperation(this, filter, replacement, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Update multiple documents in a collection\n     *\n     * @param filter - The filter used to select the documents to update\n     * @param update - The update operations to be applied to the documents\n     * @param options - Optional settings for the command\n     */\n    async updateMany(filter, update, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new update_2.UpdateManyOperation(this, filter, update, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Delete a document from a collection\n     *\n     * @param filter - The filter used to select the document to remove\n     * @param options - Optional settings for the command\n     */\n    async deleteOne(filter = {}, options = {}) {\n        return (0, execute_operation_1.executeOperation)(this.client, new delete_1.DeleteOneOperation(this, filter, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Delete multiple documents from a collection\n     *\n     * @param filter - The filter used to select the documents to remove\n     * @param options - Optional settings for the command\n     */\n    async deleteMany(filter = {}, options = {}) {\n        return (0, execute_operation_1.executeOperation)(this.client, new delete_1.DeleteManyOperation(this, filter, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Rename the collection.\n     *\n     * @remarks\n     * This operation does not inherit options from the Db or MongoClient.\n     *\n     * @param newName - New name of of the collection.\n     * @param options - Optional settings for the command\n     */\n    async rename(newName, options) {\n        // Intentionally, we do not inherit options from parent for this operation.\n        return (0, execute_operation_1.executeOperation)(this.client, new rename_1.RenameOperation(this, newName, {\n            ...options,\n            readPreference: read_preference_1.ReadPreference.PRIMARY\n        }));\n    }\n    /**\n     * Drop the collection from the database, removing it permanently. New accesses will create a new collection.\n     *\n     * @param options - Optional settings for the command\n     */\n    async drop(options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new drop_1.DropCollectionOperation(this.s.db, this.collectionName, options));\n    }\n    async findOne(filter = {}, options = {}) {\n        const cursor = this.find(filter, options).limit(-1).batchSize(1);\n        const res = await cursor.next();\n        await cursor.close();\n        return res;\n    }\n    find(filter = {}, options = {}) {\n        return new find_cursor_1.FindCursor(this.client, this.s.namespace, filter, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * Returns the options of the collection.\n     *\n     * @param options - Optional settings for the command\n     */\n    async options(options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new options_operation_1.OptionsOperation(this, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Returns if the collection is a capped collection\n     *\n     * @param options - Optional settings for the command\n     */\n    async isCapped(options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new is_capped_1.IsCappedOperation(this, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Creates an index on the db and collection collection.\n     *\n     * @param indexSpec - The field name or index specification to create an index for\n     * @param options - Optional settings for the command\n     *\n     * @example\n     * ```ts\n     * const collection = client.db('foo').collection('bar');\n     *\n     * await collection.createIndex({ a: 1, b: -1 });\n     *\n     * // Alternate syntax for { c: 1, d: -1 } that ensures order of indexes\n     * await collection.createIndex([ [c, 1], [d, -1] ]);\n     *\n     * // Equivalent to { e: 1 }\n     * await collection.createIndex('e');\n     *\n     * // Equivalent to { f: 1, g: 1 }\n     * await collection.createIndex(['f', 'g'])\n     *\n     * // Equivalent to { h: 1, i: -1 }\n     * await collection.createIndex([ { h: 1 }, { i: -1 } ]);\n     *\n     * // Equivalent to { j: 1, k: -1, l: 2d }\n     * await collection.createIndex(['j', ['k', -1], { l: '2d' }])\n     * ```\n     */\n    async createIndex(indexSpec, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new indexes_1.CreateIndexOperation(this, this.collectionName, indexSpec, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Creates multiple indexes in the collection, this method is only supported for\n     * MongoDB 2.6 or higher. Earlier version of MongoDB will throw a command not supported\n     * error.\n     *\n     * **Note**: Unlike {@link Collection#createIndex| createIndex}, this function takes in raw index specifications.\n     * Index specifications are defined {@link https://www.mongodb.com/docs/manual/reference/command/createIndexes/| here}.\n     *\n     * @param indexSpecs - An array of index specifications to be created\n     * @param options - Optional settings for the command\n     *\n     * @example\n     * ```ts\n     * const collection = client.db('foo').collection('bar');\n     * await collection.createIndexes([\n     *   // Simple index on field fizz\n     *   {\n     *     key: { fizz: 1 },\n     *   }\n     *   // wildcard index\n     *   {\n     *     key: { '$**': 1 }\n     *   },\n     *   // named index on darmok and jalad\n     *   {\n     *     key: { darmok: 1, jalad: -1 }\n     *     name: 'tanagra'\n     *   }\n     * ]);\n     * ```\n     */\n    async createIndexes(indexSpecs, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new indexes_1.CreateIndexesOperation(this, this.collectionName, indexSpecs, (0, utils_1.resolveOptions)(this, { ...options, maxTimeMS: undefined })));\n    }\n    /**\n     * Drops an index from this collection.\n     *\n     * @param indexName - Name of the index to drop.\n     * @param options - Optional settings for the command\n     */\n    async dropIndex(indexName, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new indexes_1.DropIndexOperation(this, indexName, {\n            ...(0, utils_1.resolveOptions)(this, options),\n            readPreference: read_preference_1.ReadPreference.primary\n        }));\n    }\n    /**\n     * Drops all indexes from this collection.\n     *\n     * @param options - Optional settings for the command\n     */\n    async dropIndexes(options) {\n        try {\n            await (0, execute_operation_1.executeOperation)(this.client, new indexes_1.DropIndexOperation(this, '*', (0, utils_1.resolveOptions)(this, options)));\n            return true;\n        }\n        catch {\n            return false;\n        }\n    }\n    /**\n     * Get the list of all indexes information for the collection.\n     *\n     * @param options - Optional settings for the command\n     */\n    listIndexes(options) {\n        return new list_indexes_cursor_1.ListIndexesCursor(this, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * Checks if one or more indexes exist on the collection, fails on first non-existing index\n     *\n     * @param indexes - One or more index names to check.\n     * @param options - Optional settings for the command\n     */\n    async indexExists(indexes, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new indexes_1.IndexExistsOperation(this, indexes, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Retrieves this collections index info.\n     *\n     * @param options - Optional settings for the command\n     */\n    async indexInformation(options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new indexes_1.IndexInformationOperation(this.s.db, this.collectionName, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Gets an estimate of the count of documents in a collection using collection metadata.\n     * This will always run a count command on all server versions.\n     *\n     * due to an oversight in versions 5.0.0-5.0.8 of MongoDB, the count command,\n     * which estimatedDocumentCount uses in its implementation, was not included in v1 of\n     * the Stable API, and so users of the Stable API with estimatedDocumentCount are\n     * recommended to upgrade their server version to 5.0.9+ or set apiStrict: false to avoid\n     * encountering errors.\n     *\n     * @see {@link https://www.mongodb.com/docs/manual/reference/command/count/#behavior|Count: Behavior}\n     * @param options - Optional settings for the command\n     */\n    async estimatedDocumentCount(options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new estimated_document_count_1.EstimatedDocumentCountOperation(this, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Gets the number of documents matching the filter.\n     * For a fast count of the total documents in a collection see {@link Collection#estimatedDocumentCount| estimatedDocumentCount}.\n     * **Note**: When migrating from {@link Collection#count| count} to {@link Collection#countDocuments| countDocuments}\n     * the following query operators must be replaced:\n     *\n     * | Operator | Replacement |\n     * | -------- | ----------- |\n     * | `$where`   | [`$expr`][1] |\n     * | `$near`    | [`$geoWithin`][2] with [`$center`][3] |\n     * | `$nearSphere` | [`$geoWithin`][2] with [`$centerSphere`][4] |\n     *\n     * [1]: https://www.mongodb.com/docs/manual/reference/operator/query/expr/\n     * [2]: https://www.mongodb.com/docs/manual/reference/operator/query/geoWithin/\n     * [3]: https://www.mongodb.com/docs/manual/reference/operator/query/center/#op._S_center\n     * [4]: https://www.mongodb.com/docs/manual/reference/operator/query/centerSphere/#op._S_centerSphere\n     *\n     * @param filter - The filter for the count\n     * @param options - Optional settings for the command\n     *\n     * @see https://www.mongodb.com/docs/manual/reference/operator/query/expr/\n     * @see https://www.mongodb.com/docs/manual/reference/operator/query/geoWithin/\n     * @see https://www.mongodb.com/docs/manual/reference/operator/query/center/#op._S_center\n     * @see https://www.mongodb.com/docs/manual/reference/operator/query/centerSphere/#op._S_centerSphere\n     */\n    async countDocuments(filter = {}, options = {}) {\n        return (0, execute_operation_1.executeOperation)(this.client, new count_documents_1.CountDocumentsOperation(this, filter, (0, utils_1.resolveOptions)(this, options)));\n    }\n    async distinct(key, filter = {}, options = {}) {\n        return (0, execute_operation_1.executeOperation)(this.client, new distinct_1.DistinctOperation(this, key, filter, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Retrieve all the indexes on the collection.\n     *\n     * @param options - Optional settings for the command\n     */\n    async indexes(options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new indexes_1.IndexesOperation(this, (0, utils_1.resolveOptions)(this, options)));\n    }\n    async findOneAndDelete(filter, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new find_and_modify_1.FindOneAndDeleteOperation(this, filter, (0, utils_1.resolveOptions)(this, options)));\n    }\n    async findOneAndReplace(filter, replacement, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new find_and_modify_1.FindOneAndReplaceOperation(this, filter, replacement, (0, utils_1.resolveOptions)(this, options)));\n    }\n    async findOneAndUpdate(filter, update, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new find_and_modify_1.FindOneAndUpdateOperation(this, filter, update, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Execute an aggregation framework pipeline against the collection, needs MongoDB \\>= 2.2\n     *\n     * @param pipeline - An array of aggregation pipelines to execute\n     * @param options - Optional settings for the command\n     */\n    aggregate(pipeline = [], options) {\n        if (!Array.isArray(pipeline)) {\n            throw new error_1.MongoInvalidArgumentError('Argument \"pipeline\" must be an array of aggregation stages');\n        }\n        return new aggregation_cursor_1.AggregationCursor(this.client, this.s.namespace, pipeline, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * Create a new Change Stream, watching for new changes (insertions, updates, replacements, deletions, and invalidations) in this collection.\n     *\n     * @remarks\n     * watch() accepts two generic arguments for distinct use cases:\n     * - The first is to override the schema that may be defined for this specific collection\n     * - The second is to override the shape of the change stream document entirely, if it is not provided the type will default to ChangeStreamDocument of the first argument\n     * @example\n     * By just providing the first argument I can type the change to be `ChangeStreamDocument<{ _id: number }>`\n     * ```ts\n     * collection.watch<{ _id: number }>()\n     *   .on('change', change => console.log(change._id.toFixed(4)));\n     * ```\n     *\n     * @example\n     * Passing a second argument provides a way to reflect the type changes caused by an advanced pipeline.\n     * Here, we are using a pipeline to have MongoDB filter for insert changes only and add a comment.\n     * No need start from scratch on the ChangeStreamInsertDocument type!\n     * By using an intersection we can save time and ensure defaults remain the same type!\n     * ```ts\n     * collection\n     *   .watch<Schema, ChangeStreamInsertDocument<Schema> & { comment: string }>([\n     *     { $addFields: { comment: 'big changes' } },\n     *     { $match: { operationType: 'insert' } }\n     *   ])\n     *   .on('change', change => {\n     *     change.comment.startsWith('big');\n     *     change.operationType === 'insert';\n     *     // No need to narrow in code because the generics did that for us!\n     *     expectType<Schema>(change.fullDocument);\n     *   });\n     * ```\n     *\n     * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents. This allows for filtering (using $match) and manipulating the change stream documents.\n     * @param options - Optional settings for the command\n     * @typeParam TLocal - Type of the data being detected by the change stream\n     * @typeParam TChange - Type of the whole change stream document emitted\n     */\n    watch(pipeline = [], options = {}) {\n        // Allow optionally not specifying a pipeline\n        if (!Array.isArray(pipeline)) {\n            options = pipeline;\n            pipeline = [];\n        }\n        return new change_stream_1.ChangeStream(this, pipeline, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * Initiate an Out of order batch write operation. All operations will be buffered into insert/update/remove commands executed out of order.\n     *\n     * @throws MongoNotConnectedError\n     * @remarks\n     * **NOTE:** MongoClient must be connected prior to calling this method due to a known limitation in this legacy implementation.\n     * However, `collection.bulkWrite()` provides an equivalent API that does not require prior connecting.\n     */\n    initializeUnorderedBulkOp(options) {\n        return new unordered_1.UnorderedBulkOperation(this, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * Initiate an In order bulk write operation. Operations will be serially executed in the order they are added, creating a new operation for each switch in types.\n     *\n     * @throws MongoNotConnectedError\n     * @remarks\n     * **NOTE:** MongoClient must be connected prior to calling this method due to a known limitation in this legacy implementation.\n     * However, `collection.bulkWrite()` provides an equivalent API that does not require prior connecting.\n     */\n    initializeOrderedBulkOp(options) {\n        return new ordered_1.OrderedBulkOperation(this, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * An estimated count of matching documents in the db to a filter.\n     *\n     * **NOTE:** This method has been deprecated, since it does not provide an accurate count of the documents\n     * in a collection. To obtain an accurate count of documents in the collection, use {@link Collection#countDocuments| countDocuments}.\n     * To obtain an estimated count of all documents in the collection, use {@link Collection#estimatedDocumentCount| estimatedDocumentCount}.\n     *\n     * @deprecated use {@link Collection#countDocuments| countDocuments} or {@link Collection#estimatedDocumentCount| estimatedDocumentCount} instead\n     *\n     * @param filter - The filter for the count.\n     * @param options - Optional settings for the command\n     */\n    async count(filter = {}, options = {}) {\n        return (0, execute_operation_1.executeOperation)(this.client, new count_1.CountOperation(this.fullNamespace, filter, (0, utils_1.resolveOptions)(this, options)));\n    }\n    listSearchIndexes(indexNameOrOptions, options) {\n        options =\n            typeof indexNameOrOptions === 'object' ? indexNameOrOptions : options == null ? {} : options;\n        const indexName = indexNameOrOptions == null\n            ? null\n            : typeof indexNameOrOptions === 'object'\n                ? null\n                : indexNameOrOptions;\n        return new list_search_indexes_cursor_1.ListSearchIndexesCursor(this, indexName, options);\n    }\n    /**\n     * Creates a single search index for the collection.\n     *\n     * @param description - The index description for the new search index.\n     * @returns A promise that resolves to the name of the new search index.\n     *\n     * @remarks Only available when used against a 7.0+ Atlas cluster.\n     */\n    async createSearchIndex(description) {\n        const [index] = await this.createSearchIndexes([description]);\n        return index;\n    }\n    /**\n     * Creates multiple search indexes for the current collection.\n     *\n     * @param descriptions - An array of `SearchIndexDescription`s for the new search indexes.\n     * @returns A promise that resolves to an array of the newly created search index names.\n     *\n     * @remarks Only available when used against a 7.0+ Atlas cluster.\n     * @returns\n     */\n    async createSearchIndexes(descriptions) {\n        return (0, execute_operation_1.executeOperation)(this.client, new create_1.CreateSearchIndexesOperation(this, descriptions));\n    }\n    /**\n     * Deletes a search index by index name.\n     *\n     * @param name - The name of the search index to be deleted.\n     *\n     * @remarks Only available when used against a 7.0+ Atlas cluster.\n     */\n    async dropSearchIndex(name) {\n        return (0, execute_operation_1.executeOperation)(this.client, new drop_2.DropSearchIndexOperation(this, name));\n    }\n    /**\n     * Updates a search index by replacing the existing index definition with the provided definition.\n     *\n     * @param name - The name of the search index to update.\n     * @param definition - The new search index definition.\n     *\n     * @remarks Only available when used against a 7.0+ Atlas cluster.\n     */\n    async updateSearchIndex(name, definition) {\n        return (0, execute_operation_1.executeOperation)(this.client, new update_1.UpdateSearchIndexOperation(this, name, definition));\n    }\n}\nexports.Collection = Collection;\n//# sourceMappingURL=collection.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/collection.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/connection_string.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongodb/lib/connection_string.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.FEATURE_FLAGS = exports.DEFAULT_OPTIONS = exports.OPTIONS = exports.parseOptions = exports.resolveSRVRecord = void 0;\nconst dns = __webpack_require__(/*! dns */ \"dns\");\nconst mongodb_connection_string_url_1 = __webpack_require__(/*! mongodb-connection-string-url */ \"./node_modules/mongodb-connection-string-url/lib/index.js\");\nconst url_1 = __webpack_require__(/*! url */ \"url\");\nconst mongo_credentials_1 = __webpack_require__(/*! ./cmap/auth/mongo_credentials */ \"./node_modules/mongodb/lib/cmap/auth/mongo_credentials.js\");\nconst providers_1 = __webpack_require__(/*! ./cmap/auth/providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\nconst client_metadata_1 = __webpack_require__(/*! ./cmap/handshake/client_metadata */ \"./node_modules/mongodb/lib/cmap/handshake/client_metadata.js\");\nconst compression_1 = __webpack_require__(/*! ./cmap/wire_protocol/compression */ \"./node_modules/mongodb/lib/cmap/wire_protocol/compression.js\");\nconst encrypter_1 = __webpack_require__(/*! ./encrypter */ \"./node_modules/mongodb/lib/encrypter.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_client_1 = __webpack_require__(/*! ./mongo_client */ \"./node_modules/mongodb/lib/mongo_client.js\");\nconst mongo_logger_1 = __webpack_require__(/*! ./mongo_logger */ \"./node_modules/mongodb/lib/mongo_logger.js\");\nconst read_concern_1 = __webpack_require__(/*! ./read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst read_preference_1 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst monitor_1 = __webpack_require__(/*! ./sdam/monitor */ \"./node_modules/mongodb/lib/sdam/monitor.js\");\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst write_concern_1 = __webpack_require__(/*! ./write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\nconst VALID_TXT_RECORDS = ['authSource', 'replicaSet', 'loadBalanced'];\nconst LB_SINGLE_HOST_ERROR = 'loadBalanced option only supported with a single host in the URI';\nconst LB_REPLICA_SET_ERROR = 'loadBalanced option not supported with a replicaSet option';\nconst LB_DIRECT_CONNECTION_ERROR = 'loadBalanced option not supported when directConnection is provided';\n/**\n * Lookup a `mongodb+srv` connection string, combine the parts and reparse it as a normal\n * connection string.\n *\n * @param uri - The connection string to parse\n * @param options - Optional user provided connection string options\n */\nasync function resolveSRVRecord(options) {\n    if (typeof options.srvHost !== 'string') {\n        throw new error_1.MongoAPIError('Option \"srvHost\" must not be empty');\n    }\n    if (options.srvHost.split('.').length < 3) {\n        // TODO(NODE-3484): Replace with MongoConnectionStringError\n        throw new error_1.MongoAPIError('URI must include hostname, domain name, and tld');\n    }\n    // Resolve the SRV record and use the result as the list of hosts to connect to.\n    const lookupAddress = options.srvHost;\n    const addresses = await dns.promises.resolveSrv(`_${options.srvServiceName}._tcp.${lookupAddress}`);\n    if (addresses.length === 0) {\n        throw new error_1.MongoAPIError('No addresses found at host');\n    }\n    for (const { name } of addresses) {\n        if (!(0, utils_1.matchesParentDomain)(name, lookupAddress)) {\n            throw new error_1.MongoAPIError('Server record does not share hostname with parent URI');\n        }\n    }\n    const hostAddresses = addresses.map(r => utils_1.HostAddress.fromString(`${r.name}:${r.port ?? 27017}`));\n    validateLoadBalancedOptions(hostAddresses, options, true);\n    // Resolve TXT record and add options from there if they exist.\n    let record;\n    try {\n        record = await dns.promises.resolveTxt(lookupAddress);\n    }\n    catch (error) {\n        if (error.code !== 'ENODATA' && error.code !== 'ENOTFOUND') {\n            throw error;\n        }\n        return hostAddresses;\n    }\n    if (record.length > 1) {\n        throw new error_1.MongoParseError('Multiple text records not allowed');\n    }\n    const txtRecordOptions = new url_1.URLSearchParams(record[0].join(''));\n    const txtRecordOptionKeys = [...txtRecordOptions.keys()];\n    if (txtRecordOptionKeys.some(key => !VALID_TXT_RECORDS.includes(key))) {\n        throw new error_1.MongoParseError(`Text record may only set any of: ${VALID_TXT_RECORDS.join(', ')}`);\n    }\n    if (VALID_TXT_RECORDS.some(option => txtRecordOptions.get(option) === '')) {\n        throw new error_1.MongoParseError('Cannot have empty URI params in DNS TXT Record');\n    }\n    const source = txtRecordOptions.get('authSource') ?? undefined;\n    const replicaSet = txtRecordOptions.get('replicaSet') ?? undefined;\n    const loadBalanced = txtRecordOptions.get('loadBalanced') ?? undefined;\n    if (!options.userSpecifiedAuthSource &&\n        source &&\n        options.credentials &&\n        !providers_1.AUTH_MECHS_AUTH_SRC_EXTERNAL.has(options.credentials.mechanism)) {\n        options.credentials = mongo_credentials_1.MongoCredentials.merge(options.credentials, { source });\n    }\n    if (!options.userSpecifiedReplicaSet && replicaSet) {\n        options.replicaSet = replicaSet;\n    }\n    if (loadBalanced === 'true') {\n        options.loadBalanced = true;\n    }\n    if (options.replicaSet && options.srvMaxHosts > 0) {\n        throw new error_1.MongoParseError('Cannot combine replicaSet option with srvMaxHosts');\n    }\n    validateLoadBalancedOptions(hostAddresses, options, true);\n    return hostAddresses;\n}\nexports.resolveSRVRecord = resolveSRVRecord;\n/**\n * Checks if TLS options are valid\n *\n * @param allOptions - All options provided by user or included in default options map\n * @throws MongoAPIError if TLS options are invalid\n */\nfunction checkTLSOptions(allOptions) {\n    if (!allOptions)\n        return;\n    const check = (a, b) => {\n        if (allOptions.has(a) && allOptions.has(b)) {\n            throw new error_1.MongoAPIError(`The '${a}' option cannot be used with the '${b}' option`);\n        }\n    };\n    check('tlsInsecure', 'tlsAllowInvalidCertificates');\n    check('tlsInsecure', 'tlsAllowInvalidHostnames');\n    check('tlsInsecure', 'tlsDisableCertificateRevocationCheck');\n    check('tlsInsecure', 'tlsDisableOCSPEndpointCheck');\n    check('tlsAllowInvalidCertificates', 'tlsDisableCertificateRevocationCheck');\n    check('tlsAllowInvalidCertificates', 'tlsDisableOCSPEndpointCheck');\n    check('tlsDisableCertificateRevocationCheck', 'tlsDisableOCSPEndpointCheck');\n}\nfunction getBoolean(name, value) {\n    if (typeof value === 'boolean')\n        return value;\n    switch (value) {\n        case 'true':\n            return true;\n        case 'false':\n            return false;\n        default:\n            throw new error_1.MongoParseError(`${name} must be either \"true\" or \"false\"`);\n    }\n}\nfunction getIntFromOptions(name, value) {\n    const parsedInt = (0, utils_1.parseInteger)(value);\n    if (parsedInt != null) {\n        return parsedInt;\n    }\n    throw new error_1.MongoParseError(`Expected ${name} to be stringified int value, got: ${value}`);\n}\nfunction getUIntFromOptions(name, value) {\n    const parsedValue = getIntFromOptions(name, value);\n    if (parsedValue < 0) {\n        throw new error_1.MongoParseError(`${name} can only be a positive int value, got: ${value}`);\n    }\n    return parsedValue;\n}\nfunction* entriesFromString(value) {\n    if (value === '') {\n        return;\n    }\n    const keyValuePairs = value.split(',');\n    for (const keyValue of keyValuePairs) {\n        const [key, value] = keyValue.split(/:(.*)/);\n        if (value == null) {\n            throw new error_1.MongoParseError('Cannot have undefined values in key value pairs');\n        }\n        yield [key, value];\n    }\n}\nclass CaseInsensitiveMap extends Map {\n    constructor(entries = []) {\n        super(entries.map(([k, v]) => [k.toLowerCase(), v]));\n    }\n    has(k) {\n        return super.has(k.toLowerCase());\n    }\n    get(k) {\n        return super.get(k.toLowerCase());\n    }\n    set(k, v) {\n        return super.set(k.toLowerCase(), v);\n    }\n    delete(k) {\n        return super.delete(k.toLowerCase());\n    }\n}\nfunction parseOptions(uri, mongoClient = undefined, options = {}) {\n    if (mongoClient != null && !(mongoClient instanceof mongo_client_1.MongoClient)) {\n        options = mongoClient;\n        mongoClient = undefined;\n    }\n    // validate BSONOptions\n    if (options.useBigInt64 && typeof options.promoteLongs === 'boolean' && !options.promoteLongs) {\n        throw new error_1.MongoAPIError('Must request either bigint or Long for int64 deserialization');\n    }\n    if (options.useBigInt64 && typeof options.promoteValues === 'boolean' && !options.promoteValues) {\n        throw new error_1.MongoAPIError('Must request either bigint or Long for int64 deserialization');\n    }\n    const url = new mongodb_connection_string_url_1.default(uri);\n    const { hosts, isSRV } = url;\n    const mongoOptions = Object.create(null);\n    // Feature flags\n    for (const flag of Object.getOwnPropertySymbols(options)) {\n        if (exports.FEATURE_FLAGS.has(flag)) {\n            mongoOptions[flag] = options[flag];\n        }\n    }\n    mongoOptions.hosts = isSRV ? [] : hosts.map(utils_1.HostAddress.fromString);\n    const urlOptions = new CaseInsensitiveMap();\n    if (url.pathname !== '/' && url.pathname !== '') {\n        const dbName = decodeURIComponent(url.pathname[0] === '/' ? url.pathname.slice(1) : url.pathname);\n        if (dbName) {\n            urlOptions.set('dbName', [dbName]);\n        }\n    }\n    if (url.username !== '') {\n        const auth = {\n            username: decodeURIComponent(url.username)\n        };\n        if (typeof url.password === 'string') {\n            auth.password = decodeURIComponent(url.password);\n        }\n        urlOptions.set('auth', [auth]);\n    }\n    for (const key of url.searchParams.keys()) {\n        const values = url.searchParams.getAll(key);\n        const isReadPreferenceTags = /readPreferenceTags/i.test(key);\n        if (!isReadPreferenceTags && values.length > 1) {\n            throw new error_1.MongoInvalidArgumentError(`URI option \"${key}\" cannot appear more than once in the connection string`);\n        }\n        if (!isReadPreferenceTags && values.includes('')) {\n            throw new error_1.MongoAPIError(`URI option \"${key}\" cannot be specified with no value`);\n        }\n        if (!urlOptions.has(key)) {\n            urlOptions.set(key, values);\n        }\n    }\n    const objectOptions = new CaseInsensitiveMap(Object.entries(options).filter(([, v]) => v != null));\n    // Validate options that can only be provided by one of uri or object\n    if (urlOptions.has('serverApi')) {\n        throw new error_1.MongoParseError('URI cannot contain `serverApi`, it can only be passed to the client');\n    }\n    const uriMechanismProperties = urlOptions.get('authMechanismProperties');\n    if (uriMechanismProperties) {\n        for (const property of uriMechanismProperties) {\n            if (/(^|,)ALLOWED_HOSTS:/.test(property)) {\n                throw new error_1.MongoParseError('Auth mechanism property ALLOWED_HOSTS is not allowed in the connection string.');\n            }\n        }\n    }\n    if (objectOptions.has('loadBalanced')) {\n        throw new error_1.MongoParseError('loadBalanced is only a valid option in the URI');\n    }\n    // All option collection\n    const allProvidedOptions = new CaseInsensitiveMap();\n    const allProvidedKeys = new Set([...urlOptions.keys(), ...objectOptions.keys()]);\n    for (const key of allProvidedKeys) {\n        const values = [];\n        const objectOptionValue = objectOptions.get(key);\n        if (objectOptionValue != null) {\n            values.push(objectOptionValue);\n        }\n        const urlValues = urlOptions.get(key) ?? [];\n        values.push(...urlValues);\n        allProvidedOptions.set(key, values);\n    }\n    if (allProvidedOptions.has('tls') || allProvidedOptions.has('ssl')) {\n        const tlsAndSslOpts = (allProvidedOptions.get('tls') || [])\n            .concat(allProvidedOptions.get('ssl') || [])\n            .map(getBoolean.bind(null, 'tls/ssl'));\n        if (new Set(tlsAndSslOpts).size !== 1) {\n            throw new error_1.MongoParseError('All values of tls/ssl must be the same.');\n        }\n    }\n    checkTLSOptions(allProvidedOptions);\n    const unsupportedOptions = (0, utils_1.setDifference)(allProvidedKeys, Array.from(Object.keys(exports.OPTIONS)).map(s => s.toLowerCase()));\n    if (unsupportedOptions.size !== 0) {\n        const optionWord = unsupportedOptions.size > 1 ? 'options' : 'option';\n        const isOrAre = unsupportedOptions.size > 1 ? 'are' : 'is';\n        throw new error_1.MongoParseError(`${optionWord} ${Array.from(unsupportedOptions).join(', ')} ${isOrAre} not supported`);\n    }\n    // Option parsing and setting\n    for (const [key, descriptor] of Object.entries(exports.OPTIONS)) {\n        const values = allProvidedOptions.get(key);\n        if (!values || values.length === 0) {\n            if (exports.DEFAULT_OPTIONS.has(key)) {\n                setOption(mongoOptions, key, descriptor, [exports.DEFAULT_OPTIONS.get(key)]);\n            }\n        }\n        else {\n            const { deprecated } = descriptor;\n            if (deprecated) {\n                const deprecatedMsg = typeof deprecated === 'string' ? `: ${deprecated}` : '';\n                (0, utils_1.emitWarning)(`${key} is a deprecated option${deprecatedMsg}`);\n            }\n            setOption(mongoOptions, key, descriptor, values);\n        }\n    }\n    if (mongoOptions.credentials) {\n        const isGssapi = mongoOptions.credentials.mechanism === providers_1.AuthMechanism.MONGODB_GSSAPI;\n        const isX509 = mongoOptions.credentials.mechanism === providers_1.AuthMechanism.MONGODB_X509;\n        const isAws = mongoOptions.credentials.mechanism === providers_1.AuthMechanism.MONGODB_AWS;\n        const isOidc = mongoOptions.credentials.mechanism === providers_1.AuthMechanism.MONGODB_OIDC;\n        if ((isGssapi || isX509) &&\n            allProvidedOptions.has('authSource') &&\n            mongoOptions.credentials.source !== '$external') {\n            // If authSource was explicitly given and its incorrect, we error\n            throw new error_1.MongoParseError(`authMechanism ${mongoOptions.credentials.mechanism} requires an authSource of '$external'`);\n        }\n        if (!(isGssapi || isX509 || isAws || isOidc) &&\n            mongoOptions.dbName &&\n            !allProvidedOptions.has('authSource')) {\n            // inherit the dbName unless GSSAPI or X509, then silently ignore dbName\n            // and there was no specific authSource given\n            mongoOptions.credentials = mongo_credentials_1.MongoCredentials.merge(mongoOptions.credentials, {\n                source: mongoOptions.dbName\n            });\n        }\n        if (isAws && mongoOptions.credentials.username && !mongoOptions.credentials.password) {\n            throw new error_1.MongoMissingCredentialsError(`When using ${mongoOptions.credentials.mechanism} password must be set when a username is specified`);\n        }\n        mongoOptions.credentials.validate();\n        // Check if the only auth related option provided was authSource, if so we can remove credentials\n        if (mongoOptions.credentials.password === '' &&\n            mongoOptions.credentials.username === '' &&\n            mongoOptions.credentials.mechanism === providers_1.AuthMechanism.MONGODB_DEFAULT &&\n            Object.keys(mongoOptions.credentials.mechanismProperties).length === 0) {\n            delete mongoOptions.credentials;\n        }\n    }\n    if (!mongoOptions.dbName) {\n        // dbName default is applied here because of the credential validation above\n        mongoOptions.dbName = 'test';\n    }\n    validateLoadBalancedOptions(hosts, mongoOptions, isSRV);\n    if (mongoClient && mongoOptions.autoEncryption) {\n        encrypter_1.Encrypter.checkForMongoCrypt();\n        mongoOptions.encrypter = new encrypter_1.Encrypter(mongoClient, uri, options);\n        mongoOptions.autoEncrypter = mongoOptions.encrypter.autoEncrypter;\n    }\n    // Potential SRV Overrides and SRV connection string validations\n    mongoOptions.userSpecifiedAuthSource =\n        objectOptions.has('authSource') || urlOptions.has('authSource');\n    mongoOptions.userSpecifiedReplicaSet =\n        objectOptions.has('replicaSet') || urlOptions.has('replicaSet');\n    if (isSRV) {\n        // SRV Record is resolved upon connecting\n        mongoOptions.srvHost = hosts[0];\n        if (mongoOptions.directConnection) {\n            throw new error_1.MongoAPIError('SRV URI does not support directConnection');\n        }\n        if (mongoOptions.srvMaxHosts > 0 && typeof mongoOptions.replicaSet === 'string') {\n            throw new error_1.MongoParseError('Cannot use srvMaxHosts option with replicaSet');\n        }\n        // SRV turns on TLS by default, but users can override and turn it off\n        const noUserSpecifiedTLS = !objectOptions.has('tls') && !urlOptions.has('tls');\n        const noUserSpecifiedSSL = !objectOptions.has('ssl') && !urlOptions.has('ssl');\n        if (noUserSpecifiedTLS && noUserSpecifiedSSL) {\n            mongoOptions.tls = true;\n        }\n    }\n    else {\n        const userSpecifiedSrvOptions = urlOptions.has('srvMaxHosts') ||\n            objectOptions.has('srvMaxHosts') ||\n            urlOptions.has('srvServiceName') ||\n            objectOptions.has('srvServiceName');\n        if (userSpecifiedSrvOptions) {\n            throw new error_1.MongoParseError('Cannot use srvMaxHosts or srvServiceName with a non-srv connection string');\n        }\n    }\n    if (mongoOptions.directConnection && mongoOptions.hosts.length !== 1) {\n        throw new error_1.MongoParseError('directConnection option requires exactly one host');\n    }\n    if (!mongoOptions.proxyHost &&\n        (mongoOptions.proxyPort || mongoOptions.proxyUsername || mongoOptions.proxyPassword)) {\n        throw new error_1.MongoParseError('Must specify proxyHost if other proxy options are passed');\n    }\n    if ((mongoOptions.proxyUsername && !mongoOptions.proxyPassword) ||\n        (!mongoOptions.proxyUsername && mongoOptions.proxyPassword)) {\n        throw new error_1.MongoParseError('Can only specify both of proxy username/password or neither');\n    }\n    const proxyOptions = ['proxyHost', 'proxyPort', 'proxyUsername', 'proxyPassword'].map(key => urlOptions.get(key) ?? []);\n    if (proxyOptions.some(options => options.length > 1)) {\n        throw new error_1.MongoParseError('Proxy options cannot be specified multiple times in the connection string');\n    }\n    const loggerFeatureFlag = Symbol.for('@@mdb.enableMongoLogger');\n    mongoOptions[loggerFeatureFlag] = mongoOptions[loggerFeatureFlag] ?? false;\n    let loggerEnvOptions = {};\n    let loggerClientOptions = {};\n    if (mongoOptions[loggerFeatureFlag]) {\n        loggerEnvOptions = {\n            MONGODB_LOG_COMMAND: process.env.MONGODB_LOG_COMMAND,\n            MONGODB_LOG_TOPOLOGY: process.env.MONGODB_LOG_TOPOLOGY,\n            MONGODB_LOG_SERVER_SELECTION: process.env.MONGODB_LOG_SERVER_SELECTION,\n            MONGODB_LOG_CONNECTION: process.env.MONGODB_LOG_CONNECTION,\n            MONGODB_LOG_CLIENT: process.env.MONGODB_LOG_CLIENT,\n            MONGODB_LOG_ALL: process.env.MONGODB_LOG_ALL,\n            MONGODB_LOG_MAX_DOCUMENT_LENGTH: process.env.MONGODB_LOG_MAX_DOCUMENT_LENGTH,\n            MONGODB_LOG_PATH: process.env.MONGODB_LOG_PATH,\n            ...mongoOptions[Symbol.for('@@mdb.internalLoggerConfig')]\n        };\n        loggerClientOptions = {\n            mongodbLogPath: mongoOptions.mongodbLogPath,\n            mongodbLogComponentSeverities: mongoOptions.mongodbLogComponentSeverities,\n            mongodbLogMaxDocumentLength: mongoOptions.mongodbLogMaxDocumentLength\n        };\n    }\n    mongoOptions.mongoLoggerOptions = mongo_logger_1.MongoLogger.resolveOptions(loggerEnvOptions, loggerClientOptions);\n    mongoOptions.metadata = (0, client_metadata_1.makeClientMetadata)(mongoOptions);\n    return mongoOptions;\n}\nexports.parseOptions = parseOptions;\n/**\n * #### Throws if LB mode is true:\n * - hosts contains more than one host\n * - there is a replicaSet name set\n * - directConnection is set\n * - if srvMaxHosts is used when an srv connection string is passed in\n *\n * @throws MongoParseError\n */\nfunction validateLoadBalancedOptions(hosts, mongoOptions, isSrv) {\n    if (mongoOptions.loadBalanced) {\n        if (hosts.length > 1) {\n            throw new error_1.MongoParseError(LB_SINGLE_HOST_ERROR);\n        }\n        if (mongoOptions.replicaSet) {\n            throw new error_1.MongoParseError(LB_REPLICA_SET_ERROR);\n        }\n        if (mongoOptions.directConnection) {\n            throw new error_1.MongoParseError(LB_DIRECT_CONNECTION_ERROR);\n        }\n        if (isSrv && mongoOptions.srvMaxHosts > 0) {\n            throw new error_1.MongoParseError('Cannot limit srv hosts with loadBalanced enabled');\n        }\n    }\n    return;\n}\nfunction setOption(mongoOptions, key, descriptor, values) {\n    const { target, type, transform } = descriptor;\n    const name = target ?? key;\n    switch (type) {\n        case 'boolean':\n            mongoOptions[name] = getBoolean(name, values[0]);\n            break;\n        case 'int':\n            mongoOptions[name] = getIntFromOptions(name, values[0]);\n            break;\n        case 'uint':\n            mongoOptions[name] = getUIntFromOptions(name, values[0]);\n            break;\n        case 'string':\n            if (values[0] == null) {\n                break;\n            }\n            mongoOptions[name] = String(values[0]);\n            break;\n        case 'record':\n            if (!(0, utils_1.isRecord)(values[0])) {\n                throw new error_1.MongoParseError(`${name} must be an object`);\n            }\n            mongoOptions[name] = values[0];\n            break;\n        case 'any':\n            mongoOptions[name] = values[0];\n            break;\n        default: {\n            if (!transform) {\n                throw new error_1.MongoParseError('Descriptors missing a type must define a transform');\n            }\n            const transformValue = transform({ name, options: mongoOptions, values });\n            mongoOptions[name] = transformValue;\n            break;\n        }\n    }\n}\nexports.OPTIONS = {\n    appName: {\n        type: 'string'\n    },\n    auth: {\n        target: 'credentials',\n        transform({ name, options, values: [value] }) {\n            if (!(0, utils_1.isRecord)(value, ['username', 'password'])) {\n                throw new error_1.MongoParseError(`${name} must be an object with 'username' and 'password' properties`);\n            }\n            return mongo_credentials_1.MongoCredentials.merge(options.credentials, {\n                username: value.username,\n                password: value.password\n            });\n        }\n    },\n    authMechanism: {\n        target: 'credentials',\n        transform({ options, values: [value] }) {\n            const mechanisms = Object.values(providers_1.AuthMechanism);\n            const [mechanism] = mechanisms.filter(m => m.match(RegExp(String.raw `\\b${value}\\b`, 'i')));\n            if (!mechanism) {\n                throw new error_1.MongoParseError(`authMechanism one of ${mechanisms}, got ${value}`);\n            }\n            let source = options.credentials?.source;\n            if (mechanism === providers_1.AuthMechanism.MONGODB_PLAIN ||\n                providers_1.AUTH_MECHS_AUTH_SRC_EXTERNAL.has(mechanism)) {\n                // some mechanisms have '$external' as the Auth Source\n                source = '$external';\n            }\n            let password = options.credentials?.password;\n            if (mechanism === providers_1.AuthMechanism.MONGODB_X509 && password === '') {\n                password = undefined;\n            }\n            return mongo_credentials_1.MongoCredentials.merge(options.credentials, {\n                mechanism,\n                source,\n                password\n            });\n        }\n    },\n    authMechanismProperties: {\n        target: 'credentials',\n        transform({ options, values }) {\n            // We can have a combination of options passed in the URI and options passed\n            // as an object to the MongoClient. So we must transform the string options\n            // as well as merge them together with a potentially provided object.\n            let mechanismProperties = Object.create(null);\n            for (const optionValue of values) {\n                if (typeof optionValue === 'string') {\n                    for (const [key, value] of entriesFromString(optionValue)) {\n                        try {\n                            mechanismProperties[key] = getBoolean(key, value);\n                        }\n                        catch {\n                            mechanismProperties[key] = value;\n                        }\n                    }\n                }\n                else {\n                    if (!(0, utils_1.isRecord)(optionValue)) {\n                        throw new error_1.MongoParseError('AuthMechanismProperties must be an object');\n                    }\n                    mechanismProperties = { ...optionValue };\n                }\n            }\n            return mongo_credentials_1.MongoCredentials.merge(options.credentials, {\n                mechanismProperties\n            });\n        }\n    },\n    authSource: {\n        target: 'credentials',\n        transform({ options, values: [value] }) {\n            const source = String(value);\n            return mongo_credentials_1.MongoCredentials.merge(options.credentials, { source });\n        }\n    },\n    autoEncryption: {\n        type: 'record'\n    },\n    bsonRegExp: {\n        type: 'boolean'\n    },\n    serverApi: {\n        target: 'serverApi',\n        transform({ values: [version] }) {\n            const serverApiToValidate = typeof version === 'string' ? { version } : version;\n            const versionToValidate = serverApiToValidate && serverApiToValidate.version;\n            if (!versionToValidate) {\n                throw new error_1.MongoParseError(`Invalid \\`serverApi\\` property; must specify a version from the following enum: [\"${Object.values(mongo_client_1.ServerApiVersion).join('\", \"')}\"]`);\n            }\n            if (!Object.values(mongo_client_1.ServerApiVersion).some(v => v === versionToValidate)) {\n                throw new error_1.MongoParseError(`Invalid server API version=${versionToValidate}; must be in the following enum: [\"${Object.values(mongo_client_1.ServerApiVersion).join('\", \"')}\"]`);\n            }\n            return serverApiToValidate;\n        }\n    },\n    checkKeys: {\n        type: 'boolean'\n    },\n    compressors: {\n        default: 'none',\n        target: 'compressors',\n        transform({ values }) {\n            const compressionList = new Set();\n            for (const compVal of values) {\n                const compValArray = typeof compVal === 'string' ? compVal.split(',') : compVal;\n                if (!Array.isArray(compValArray)) {\n                    throw new error_1.MongoInvalidArgumentError('compressors must be an array or a comma-delimited list of strings');\n                }\n                for (const c of compValArray) {\n                    if (Object.keys(compression_1.Compressor).includes(String(c))) {\n                        compressionList.add(String(c));\n                    }\n                    else {\n                        throw new error_1.MongoInvalidArgumentError(`${c} is not a valid compression mechanism. Must be one of: ${Object.keys(compression_1.Compressor)}.`);\n                    }\n                }\n            }\n            return [...compressionList];\n        }\n    },\n    connectTimeoutMS: {\n        default: 30000,\n        type: 'uint'\n    },\n    dbName: {\n        type: 'string'\n    },\n    directConnection: {\n        default: false,\n        type: 'boolean'\n    },\n    driverInfo: {\n        default: {},\n        type: 'record'\n    },\n    enableUtf8Validation: { type: 'boolean', default: true },\n    family: {\n        transform({ name, values: [value] }) {\n            const transformValue = getIntFromOptions(name, value);\n            if (transformValue === 4 || transformValue === 6) {\n                return transformValue;\n            }\n            throw new error_1.MongoParseError(`Option 'family' must be 4 or 6 got ${transformValue}.`);\n        }\n    },\n    fieldsAsRaw: {\n        type: 'record'\n    },\n    forceServerObjectId: {\n        default: false,\n        type: 'boolean'\n    },\n    fsync: {\n        deprecated: 'Please use journal instead',\n        target: 'writeConcern',\n        transform({ name, options, values: [value] }) {\n            const wc = write_concern_1.WriteConcern.fromOptions({\n                writeConcern: {\n                    ...options.writeConcern,\n                    fsync: getBoolean(name, value)\n                }\n            });\n            if (!wc)\n                throw new error_1.MongoParseError(`Unable to make a writeConcern from fsync=${value}`);\n            return wc;\n        }\n    },\n    heartbeatFrequencyMS: {\n        default: 10000,\n        type: 'uint'\n    },\n    ignoreUndefined: {\n        type: 'boolean'\n    },\n    j: {\n        deprecated: 'Please use journal instead',\n        target: 'writeConcern',\n        transform({ name, options, values: [value] }) {\n            const wc = write_concern_1.WriteConcern.fromOptions({\n                writeConcern: {\n                    ...options.writeConcern,\n                    journal: getBoolean(name, value)\n                }\n            });\n            if (!wc)\n                throw new error_1.MongoParseError(`Unable to make a writeConcern from journal=${value}`);\n            return wc;\n        }\n    },\n    journal: {\n        target: 'writeConcern',\n        transform({ name, options, values: [value] }) {\n            const wc = write_concern_1.WriteConcern.fromOptions({\n                writeConcern: {\n                    ...options.writeConcern,\n                    journal: getBoolean(name, value)\n                }\n            });\n            if (!wc)\n                throw new error_1.MongoParseError(`Unable to make a writeConcern from journal=${value}`);\n            return wc;\n        }\n    },\n    loadBalanced: {\n        default: false,\n        type: 'boolean'\n    },\n    localThresholdMS: {\n        default: 15,\n        type: 'uint'\n    },\n    maxConnecting: {\n        default: 2,\n        transform({ name, values: [value] }) {\n            const maxConnecting = getUIntFromOptions(name, value);\n            if (maxConnecting === 0) {\n                throw new error_1.MongoInvalidArgumentError('maxConnecting must be > 0 if specified');\n            }\n            return maxConnecting;\n        }\n    },\n    maxIdleTimeMS: {\n        default: 0,\n        type: 'uint'\n    },\n    maxPoolSize: {\n        default: 100,\n        type: 'uint'\n    },\n    maxStalenessSeconds: {\n        target: 'readPreference',\n        transform({ name, options, values: [value] }) {\n            const maxStalenessSeconds = getUIntFromOptions(name, value);\n            if (options.readPreference) {\n                return read_preference_1.ReadPreference.fromOptions({\n                    readPreference: { ...options.readPreference, maxStalenessSeconds }\n                });\n            }\n            else {\n                return new read_preference_1.ReadPreference('secondary', undefined, { maxStalenessSeconds });\n            }\n        }\n    },\n    minInternalBufferSize: {\n        type: 'uint'\n    },\n    minPoolSize: {\n        default: 0,\n        type: 'uint'\n    },\n    minHeartbeatFrequencyMS: {\n        default: 500,\n        type: 'uint'\n    },\n    monitorCommands: {\n        default: false,\n        type: 'boolean'\n    },\n    name: {\n        target: 'driverInfo',\n        transform({ values: [value], options }) {\n            return { ...options.driverInfo, name: String(value) };\n        }\n    },\n    noDelay: {\n        default: true,\n        type: 'boolean'\n    },\n    pkFactory: {\n        default: utils_1.DEFAULT_PK_FACTORY,\n        transform({ values: [value] }) {\n            if ((0, utils_1.isRecord)(value, ['createPk']) && typeof value.createPk === 'function') {\n                return value;\n            }\n            throw new error_1.MongoParseError(`Option pkFactory must be an object with a createPk function, got ${value}`);\n        }\n    },\n    promoteBuffers: {\n        type: 'boolean'\n    },\n    promoteLongs: {\n        type: 'boolean'\n    },\n    promoteValues: {\n        type: 'boolean'\n    },\n    useBigInt64: {\n        type: 'boolean'\n    },\n    proxyHost: {\n        type: 'string'\n    },\n    proxyPassword: {\n        type: 'string'\n    },\n    proxyPort: {\n        type: 'uint'\n    },\n    proxyUsername: {\n        type: 'string'\n    },\n    raw: {\n        default: false,\n        type: 'boolean'\n    },\n    readConcern: {\n        transform({ values: [value], options }) {\n            if (value instanceof read_concern_1.ReadConcern || (0, utils_1.isRecord)(value, ['level'])) {\n                return read_concern_1.ReadConcern.fromOptions({ ...options.readConcern, ...value });\n            }\n            throw new error_1.MongoParseError(`ReadConcern must be an object, got ${JSON.stringify(value)}`);\n        }\n    },\n    readConcernLevel: {\n        target: 'readConcern',\n        transform({ values: [level], options }) {\n            return read_concern_1.ReadConcern.fromOptions({\n                ...options.readConcern,\n                level: level\n            });\n        }\n    },\n    readPreference: {\n        default: read_preference_1.ReadPreference.primary,\n        transform({ values: [value], options }) {\n            if (value instanceof read_preference_1.ReadPreference) {\n                return read_preference_1.ReadPreference.fromOptions({\n                    readPreference: { ...options.readPreference, ...value },\n                    ...value\n                });\n            }\n            if ((0, utils_1.isRecord)(value, ['mode'])) {\n                const rp = read_preference_1.ReadPreference.fromOptions({\n                    readPreference: { ...options.readPreference, ...value },\n                    ...value\n                });\n                if (rp)\n                    return rp;\n                else\n                    throw new error_1.MongoParseError(`Cannot make read preference from ${JSON.stringify(value)}`);\n            }\n            if (typeof value === 'string') {\n                const rpOpts = {\n                    hedge: options.readPreference?.hedge,\n                    maxStalenessSeconds: options.readPreference?.maxStalenessSeconds\n                };\n                return new read_preference_1.ReadPreference(value, options.readPreference?.tags, rpOpts);\n            }\n            throw new error_1.MongoParseError(`Unknown ReadPreference value: ${value}`);\n        }\n    },\n    readPreferenceTags: {\n        target: 'readPreference',\n        transform({ values, options }) {\n            const tags = Array.isArray(values[0])\n                ? values[0]\n                : values;\n            const readPreferenceTags = [];\n            for (const tag of tags) {\n                const readPreferenceTag = Object.create(null);\n                if (typeof tag === 'string') {\n                    for (const [k, v] of entriesFromString(tag)) {\n                        readPreferenceTag[k] = v;\n                    }\n                }\n                if ((0, utils_1.isRecord)(tag)) {\n                    for (const [k, v] of Object.entries(tag)) {\n                        readPreferenceTag[k] = v;\n                    }\n                }\n                readPreferenceTags.push(readPreferenceTag);\n            }\n            return read_preference_1.ReadPreference.fromOptions({\n                readPreference: options.readPreference,\n                readPreferenceTags\n            });\n        }\n    },\n    replicaSet: {\n        type: 'string'\n    },\n    retryReads: {\n        default: true,\n        type: 'boolean'\n    },\n    retryWrites: {\n        default: true,\n        type: 'boolean'\n    },\n    serializeFunctions: {\n        type: 'boolean'\n    },\n    serverMonitoringMode: {\n        default: 'auto',\n        transform({ values: [value] }) {\n            if (!Object.values(monitor_1.ServerMonitoringMode).includes(value)) {\n                throw new error_1.MongoParseError('serverMonitoringMode must be one of `auto`, `poll`, or `stream`');\n            }\n            return value;\n        }\n    },\n    serverSelectionTimeoutMS: {\n        default: 30000,\n        type: 'uint'\n    },\n    servername: {\n        type: 'string'\n    },\n    socketTimeoutMS: {\n        default: 0,\n        type: 'uint'\n    },\n    srvMaxHosts: {\n        type: 'uint',\n        default: 0\n    },\n    srvServiceName: {\n        type: 'string',\n        default: 'mongodb'\n    },\n    ssl: {\n        target: 'tls',\n        type: 'boolean'\n    },\n    tls: {\n        type: 'boolean'\n    },\n    tlsAllowInvalidCertificates: {\n        target: 'rejectUnauthorized',\n        transform({ name, values: [value] }) {\n            // allowInvalidCertificates is the inverse of rejectUnauthorized\n            return !getBoolean(name, value);\n        }\n    },\n    tlsAllowInvalidHostnames: {\n        target: 'checkServerIdentity',\n        transform({ name, values: [value] }) {\n            // tlsAllowInvalidHostnames means setting the checkServerIdentity function to a noop\n            return getBoolean(name, value) ? () => undefined : undefined;\n        }\n    },\n    tlsCAFile: {\n        type: 'string'\n    },\n    tlsCRLFile: {\n        type: 'string'\n    },\n    tlsCertificateKeyFile: {\n        type: 'string'\n    },\n    tlsCertificateKeyFilePassword: {\n        target: 'passphrase',\n        type: 'any'\n    },\n    tlsInsecure: {\n        transform({ name, options, values: [value] }) {\n            const tlsInsecure = getBoolean(name, value);\n            if (tlsInsecure) {\n                options.checkServerIdentity = () => undefined;\n                options.rejectUnauthorized = false;\n            }\n            else {\n                options.checkServerIdentity = options.tlsAllowInvalidHostnames\n                    ? () => undefined\n                    : undefined;\n                options.rejectUnauthorized = options.tlsAllowInvalidCertificates ? false : true;\n            }\n            return tlsInsecure;\n        }\n    },\n    w: {\n        target: 'writeConcern',\n        transform({ values: [value], options }) {\n            return write_concern_1.WriteConcern.fromOptions({ writeConcern: { ...options.writeConcern, w: value } });\n        }\n    },\n    waitQueueTimeoutMS: {\n        default: 0,\n        type: 'uint'\n    },\n    writeConcern: {\n        target: 'writeConcern',\n        transform({ values: [value], options }) {\n            if ((0, utils_1.isRecord)(value) || value instanceof write_concern_1.WriteConcern) {\n                return write_concern_1.WriteConcern.fromOptions({\n                    writeConcern: {\n                        ...options.writeConcern,\n                        ...value\n                    }\n                });\n            }\n            else if (value === 'majority' || typeof value === 'number') {\n                return write_concern_1.WriteConcern.fromOptions({\n                    writeConcern: {\n                        ...options.writeConcern,\n                        w: value\n                    }\n                });\n            }\n            throw new error_1.MongoParseError(`Invalid WriteConcern cannot parse: ${JSON.stringify(value)}`);\n        }\n    },\n    wtimeout: {\n        deprecated: 'Please use wtimeoutMS instead',\n        target: 'writeConcern',\n        transform({ values: [value], options }) {\n            const wc = write_concern_1.WriteConcern.fromOptions({\n                writeConcern: {\n                    ...options.writeConcern,\n                    wtimeout: getUIntFromOptions('wtimeout', value)\n                }\n            });\n            if (wc)\n                return wc;\n            throw new error_1.MongoParseError(`Cannot make WriteConcern from wtimeout`);\n        }\n    },\n    wtimeoutMS: {\n        target: 'writeConcern',\n        transform({ values: [value], options }) {\n            const wc = write_concern_1.WriteConcern.fromOptions({\n                writeConcern: {\n                    ...options.writeConcern,\n                    wtimeoutMS: getUIntFromOptions('wtimeoutMS', value)\n                }\n            });\n            if (wc)\n                return wc;\n            throw new error_1.MongoParseError(`Cannot make WriteConcern from wtimeout`);\n        }\n    },\n    zlibCompressionLevel: {\n        default: 0,\n        type: 'int'\n    },\n    // Custom types for modifying core behavior\n    connectionType: { type: 'any' },\n    srvPoller: { type: 'any' },\n    // Accepted NodeJS Options\n    minDHSize: { type: 'any' },\n    pskCallback: { type: 'any' },\n    secureContext: { type: 'any' },\n    enableTrace: { type: 'any' },\n    requestCert: { type: 'any' },\n    rejectUnauthorized: { type: 'any' },\n    checkServerIdentity: { type: 'any' },\n    ALPNProtocols: { type: 'any' },\n    SNICallback: { type: 'any' },\n    session: { type: 'any' },\n    requestOCSP: { type: 'any' },\n    localAddress: { type: 'any' },\n    localPort: { type: 'any' },\n    hints: { type: 'any' },\n    lookup: { type: 'any' },\n    ca: { type: 'any' },\n    cert: { type: 'any' },\n    ciphers: { type: 'any' },\n    crl: { type: 'any' },\n    ecdhCurve: { type: 'any' },\n    key: { type: 'any' },\n    passphrase: { type: 'any' },\n    pfx: { type: 'any' },\n    secureProtocol: { type: 'any' },\n    index: { type: 'any' },\n    // Legacy options from v3 era\n    useNewUrlParser: {\n        type: 'boolean',\n        deprecated: 'useNewUrlParser has no effect since Node.js Driver version 4.0.0 and will be removed in the next major version'\n    },\n    useUnifiedTopology: {\n        type: 'boolean',\n        deprecated: 'useUnifiedTopology has no effect since Node.js Driver version 4.0.0 and will be removed in the next major version'\n    },\n    // MongoLogger\n    /**\n     * @internal\n     * TODO: NODE-5671 - remove internal flag\n     */\n    mongodbLogPath: { type: 'any' },\n    /**\n     * @internal\n     * TODO: NODE-5671 - remove internal flag\n     */\n    mongodbLogComponentSeverities: { type: 'any' },\n    /**\n     * @internal\n     * TODO: NODE-5671 - remove internal flag\n     */\n    mongodbLogMaxDocumentLength: { type: 'uint' }\n};\nexports.DEFAULT_OPTIONS = new CaseInsensitiveMap(Object.entries(exports.OPTIONS)\n    .filter(([, descriptor]) => descriptor.default != null)\n    .map(([k, d]) => [k, d.default]));\n/**\n * Set of permitted feature flags\n * @internal\n */\nexports.FEATURE_FLAGS = new Set([\n    Symbol.for('@@mdb.skipPingOnConnect'),\n    Symbol.for('@@mdb.enableMongoLogger'),\n    Symbol.for('@@mdb.internalLoggerConfig')\n]);\n//# sourceMappingURL=connection_string.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/connection_string.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/constants.js":
/*!***********************************************!*\
  !*** ./node_modules/mongodb/lib/constants.js ***!
  \***********************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TOPOLOGY_EVENTS = exports.CMAP_EVENTS = exports.HEARTBEAT_EVENTS = exports.RESUME_TOKEN_CHANGED = exports.END = exports.CHANGE = exports.INIT = exports.MORE = exports.RESPONSE = exports.SERVER_HEARTBEAT_FAILED = exports.SERVER_HEARTBEAT_SUCCEEDED = exports.SERVER_HEARTBEAT_STARTED = exports.COMMAND_FAILED = exports.COMMAND_SUCCEEDED = exports.COMMAND_STARTED = exports.CLUSTER_TIME_RECEIVED = exports.CONNECTION_CHECKED_IN = exports.CONNECTION_CHECKED_OUT = exports.CONNECTION_CHECK_OUT_FAILED = exports.CONNECTION_CHECK_OUT_STARTED = exports.CONNECTION_CLOSED = exports.CONNECTION_READY = exports.CONNECTION_CREATED = exports.CONNECTION_POOL_READY = exports.CONNECTION_POOL_CLEARED = exports.CONNECTION_POOL_CLOSED = exports.CONNECTION_POOL_CREATED = exports.TOPOLOGY_DESCRIPTION_CHANGED = exports.TOPOLOGY_CLOSED = exports.TOPOLOGY_OPENING = exports.SERVER_DESCRIPTION_CHANGED = exports.SERVER_CLOSED = exports.SERVER_OPENING = exports.DESCRIPTION_RECEIVED = exports.UNPINNED = exports.PINNED = exports.MESSAGE = exports.ENDED = exports.CLOSED = exports.CONNECT = exports.OPEN = exports.CLOSE = exports.TIMEOUT = exports.ERROR = exports.SYSTEM_JS_COLLECTION = exports.SYSTEM_COMMAND_COLLECTION = exports.SYSTEM_USER_COLLECTION = exports.SYSTEM_PROFILE_COLLECTION = exports.SYSTEM_INDEX_COLLECTION = exports.SYSTEM_NAMESPACE_COLLECTION = void 0;\nexports.LEGACY_HELLO_COMMAND_CAMEL_CASE = exports.LEGACY_HELLO_COMMAND = exports.MONGO_CLIENT_EVENTS = exports.LOCAL_SERVER_EVENTS = exports.SERVER_RELAY_EVENTS = exports.APM_EVENTS = void 0;\nexports.SYSTEM_NAMESPACE_COLLECTION = 'system.namespaces';\nexports.SYSTEM_INDEX_COLLECTION = 'system.indexes';\nexports.SYSTEM_PROFILE_COLLECTION = 'system.profile';\nexports.SYSTEM_USER_COLLECTION = 'system.users';\nexports.SYSTEM_COMMAND_COLLECTION = '$cmd';\nexports.SYSTEM_JS_COLLECTION = 'system.js';\n// events\nexports.ERROR = 'error';\nexports.TIMEOUT = 'timeout';\nexports.CLOSE = 'close';\nexports.OPEN = 'open';\nexports.CONNECT = 'connect';\nexports.CLOSED = 'closed';\nexports.ENDED = 'ended';\nexports.MESSAGE = 'message';\nexports.PINNED = 'pinned';\nexports.UNPINNED = 'unpinned';\nexports.DESCRIPTION_RECEIVED = 'descriptionReceived';\nexports.SERVER_OPENING = 'serverOpening';\nexports.SERVER_CLOSED = 'serverClosed';\nexports.SERVER_DESCRIPTION_CHANGED = 'serverDescriptionChanged';\nexports.TOPOLOGY_OPENING = 'topologyOpening';\nexports.TOPOLOGY_CLOSED = 'topologyClosed';\nexports.TOPOLOGY_DESCRIPTION_CHANGED = 'topologyDescriptionChanged';\n/** @internal */\nexports.CONNECTION_POOL_CREATED = 'connectionPoolCreated';\n/** @internal */\nexports.CONNECTION_POOL_CLOSED = 'connectionPoolClosed';\n/** @internal */\nexports.CONNECTION_POOL_CLEARED = 'connectionPoolCleared';\n/** @internal */\nexports.CONNECTION_POOL_READY = 'connectionPoolReady';\n/** @internal */\nexports.CONNECTION_CREATED = 'connectionCreated';\n/** @internal */\nexports.CONNECTION_READY = 'connectionReady';\n/** @internal */\nexports.CONNECTION_CLOSED = 'connectionClosed';\n/** @internal */\nexports.CONNECTION_CHECK_OUT_STARTED = 'connectionCheckOutStarted';\n/** @internal */\nexports.CONNECTION_CHECK_OUT_FAILED = 'connectionCheckOutFailed';\n/** @internal */\nexports.CONNECTION_CHECKED_OUT = 'connectionCheckedOut';\n/** @internal */\nexports.CONNECTION_CHECKED_IN = 'connectionCheckedIn';\nexports.CLUSTER_TIME_RECEIVED = 'clusterTimeReceived';\nexports.COMMAND_STARTED = 'commandStarted';\nexports.COMMAND_SUCCEEDED = 'commandSucceeded';\nexports.COMMAND_FAILED = 'commandFailed';\nexports.SERVER_HEARTBEAT_STARTED = 'serverHeartbeatStarted';\nexports.SERVER_HEARTBEAT_SUCCEEDED = 'serverHeartbeatSucceeded';\nexports.SERVER_HEARTBEAT_FAILED = 'serverHeartbeatFailed';\nexports.RESPONSE = 'response';\nexports.MORE = 'more';\nexports.INIT = 'init';\nexports.CHANGE = 'change';\nexports.END = 'end';\nexports.RESUME_TOKEN_CHANGED = 'resumeTokenChanged';\n/** @public */\nexports.HEARTBEAT_EVENTS = Object.freeze([\n    exports.SERVER_HEARTBEAT_STARTED,\n    exports.SERVER_HEARTBEAT_SUCCEEDED,\n    exports.SERVER_HEARTBEAT_FAILED\n]);\n/** @public */\nexports.CMAP_EVENTS = Object.freeze([\n    exports.CONNECTION_POOL_CREATED,\n    exports.CONNECTION_POOL_READY,\n    exports.CONNECTION_POOL_CLEARED,\n    exports.CONNECTION_POOL_CLOSED,\n    exports.CONNECTION_CREATED,\n    exports.CONNECTION_READY,\n    exports.CONNECTION_CLOSED,\n    exports.CONNECTION_CHECK_OUT_STARTED,\n    exports.CONNECTION_CHECK_OUT_FAILED,\n    exports.CONNECTION_CHECKED_OUT,\n    exports.CONNECTION_CHECKED_IN\n]);\n/** @public */\nexports.TOPOLOGY_EVENTS = Object.freeze([\n    exports.SERVER_OPENING,\n    exports.SERVER_CLOSED,\n    exports.SERVER_DESCRIPTION_CHANGED,\n    exports.TOPOLOGY_OPENING,\n    exports.TOPOLOGY_CLOSED,\n    exports.TOPOLOGY_DESCRIPTION_CHANGED,\n    exports.ERROR,\n    exports.TIMEOUT,\n    exports.CLOSE\n]);\n/** @public */\nexports.APM_EVENTS = Object.freeze([\n    exports.COMMAND_STARTED,\n    exports.COMMAND_SUCCEEDED,\n    exports.COMMAND_FAILED\n]);\n/**\n * All events that we relay to the `Topology`\n * @internal\n */\nexports.SERVER_RELAY_EVENTS = Object.freeze([\n    exports.SERVER_HEARTBEAT_STARTED,\n    exports.SERVER_HEARTBEAT_SUCCEEDED,\n    exports.SERVER_HEARTBEAT_FAILED,\n    exports.COMMAND_STARTED,\n    exports.COMMAND_SUCCEEDED,\n    exports.COMMAND_FAILED,\n    ...exports.CMAP_EVENTS\n]);\n/**\n * All events we listen to from `Server` instances, but do not forward to the client\n * @internal\n */\nexports.LOCAL_SERVER_EVENTS = Object.freeze([\n    exports.CONNECT,\n    exports.DESCRIPTION_RECEIVED,\n    exports.CLOSED,\n    exports.ENDED\n]);\n/** @public */\nexports.MONGO_CLIENT_EVENTS = Object.freeze([\n    ...exports.CMAP_EVENTS,\n    ...exports.APM_EVENTS,\n    ...exports.TOPOLOGY_EVENTS,\n    ...exports.HEARTBEAT_EVENTS\n]);\n/**\n * @internal\n * The legacy hello command that was deprecated in MongoDB 5.0.\n */\nexports.LEGACY_HELLO_COMMAND = 'ismaster';\n/**\n * @internal\n * The legacy hello command that was deprecated in MongoDB 5.0.\n */\nexports.LEGACY_HELLO_COMMAND_CAMEL_CASE = 'isMaster';\n//# sourceMappingURL=constants.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/constants.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cursor/abstract_cursor.js":
/*!************************************************************!*\
  !*** ./node_modules/mongodb/lib/cursor/abstract_cursor.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.assertUninitialized = exports.AbstractCursor = exports.CURSOR_FLAGS = void 0;\nconst stream_1 = __webpack_require__(/*! stream */ \"stream\");\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_types_1 = __webpack_require__(/*! ../mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst execute_operation_1 = __webpack_require__(/*! ../operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst get_more_1 = __webpack_require__(/*! ../operations/get_more */ \"./node_modules/mongodb/lib/operations/get_more.js\");\nconst kill_cursors_1 = __webpack_require__(/*! ../operations/kill_cursors */ \"./node_modules/mongodb/lib/operations/kill_cursors.js\");\nconst read_concern_1 = __webpack_require__(/*! ../read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst read_preference_1 = __webpack_require__(/*! ../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst sessions_1 = __webpack_require__(/*! ../sessions */ \"./node_modules/mongodb/lib/sessions.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\n/** @internal */\nconst kId = Symbol('id');\n/** @internal */\nconst kDocuments = Symbol('documents');\n/** @internal */\nconst kServer = Symbol('server');\n/** @internal */\nconst kNamespace = Symbol('namespace');\n/** @internal */\nconst kClient = Symbol('client');\n/** @internal */\nconst kSession = Symbol('session');\n/** @internal */\nconst kOptions = Symbol('options');\n/** @internal */\nconst kTransform = Symbol('transform');\n/** @internal */\nconst kInitialized = Symbol('initialized');\n/** @internal */\nconst kClosed = Symbol('closed');\n/** @internal */\nconst kKilled = Symbol('killed');\n/** @internal */\nconst kInit = Symbol('kInit');\n/** @public */\nexports.CURSOR_FLAGS = [\n    'tailable',\n    'oplogReplay',\n    'noCursorTimeout',\n    'awaitData',\n    'exhaust',\n    'partial'\n];\n/** @public */\nclass AbstractCursor extends mongo_types_1.TypedEventEmitter {\n    /** @internal */\n    constructor(client, namespace, options = {}) {\n        super();\n        if (!client.s.isMongoClient) {\n            throw new error_1.MongoRuntimeError('Cursor must be constructed with MongoClient');\n        }\n        this[kClient] = client;\n        this[kNamespace] = namespace;\n        this[kId] = null;\n        this[kDocuments] = new utils_1.List();\n        this[kInitialized] = false;\n        this[kClosed] = false;\n        this[kKilled] = false;\n        this[kOptions] = {\n            readPreference: options.readPreference && options.readPreference instanceof read_preference_1.ReadPreference\n                ? options.readPreference\n                : read_preference_1.ReadPreference.primary,\n            ...(0, bson_1.pluckBSONSerializeOptions)(options)\n        };\n        const readConcern = read_concern_1.ReadConcern.fromOptions(options);\n        if (readConcern) {\n            this[kOptions].readConcern = readConcern;\n        }\n        if (typeof options.batchSize === 'number') {\n            this[kOptions].batchSize = options.batchSize;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (options.comment !== undefined) {\n            this[kOptions].comment = options.comment;\n        }\n        if (typeof options.maxTimeMS === 'number') {\n            this[kOptions].maxTimeMS = options.maxTimeMS;\n        }\n        if (typeof options.maxAwaitTimeMS === 'number') {\n            this[kOptions].maxAwaitTimeMS = options.maxAwaitTimeMS;\n        }\n        if (options.session instanceof sessions_1.ClientSession) {\n            this[kSession] = options.session;\n        }\n        else {\n            this[kSession] = this[kClient].startSession({ owner: this, explicit: false });\n        }\n    }\n    get id() {\n        return this[kId] ?? undefined;\n    }\n    /** @internal */\n    get isDead() {\n        return (this[kId]?.isZero() ?? false) || this[kClosed] || this[kKilled];\n    }\n    /** @internal */\n    get client() {\n        return this[kClient];\n    }\n    /** @internal */\n    get server() {\n        return this[kServer];\n    }\n    get namespace() {\n        return this[kNamespace];\n    }\n    get readPreference() {\n        return this[kOptions].readPreference;\n    }\n    get readConcern() {\n        return this[kOptions].readConcern;\n    }\n    /** @internal */\n    get session() {\n        return this[kSession];\n    }\n    set session(clientSession) {\n        this[kSession] = clientSession;\n    }\n    /** @internal */\n    get cursorOptions() {\n        return this[kOptions];\n    }\n    get closed() {\n        return this[kClosed];\n    }\n    get killed() {\n        return this[kKilled];\n    }\n    get loadBalanced() {\n        return !!this[kClient].topology?.loadBalanced;\n    }\n    /** Returns current buffered documents length */\n    bufferedCount() {\n        return this[kDocuments].length;\n    }\n    /** Returns current buffered documents */\n    readBufferedDocuments(number) {\n        const bufferedDocs = [];\n        const documentsToRead = Math.min(number ?? this[kDocuments].length, this[kDocuments].length);\n        for (let count = 0; count < documentsToRead; count++) {\n            const document = this[kDocuments].shift();\n            if (document != null) {\n                bufferedDocs.push(document);\n            }\n        }\n        return bufferedDocs;\n    }\n    async *[Symbol.asyncIterator]() {\n        if (this.closed) {\n            return;\n        }\n        try {\n            while (true) {\n                const document = await this.next();\n                // Intentional strict null check, because users can map cursors to falsey values.\n                // We allow mapping to all values except for null.\n                // eslint-disable-next-line no-restricted-syntax\n                if (document === null) {\n                    if (!this.closed) {\n                        const message = 'Cursor returned a `null` document, but the cursor is not exhausted.  Mapping documents to `null` is not supported in the cursor transform.';\n                        await cleanupCursor(this, { needsToEmitClosed: true }).catch(() => null);\n                        throw new error_1.MongoAPIError(message);\n                    }\n                    break;\n                }\n                yield document;\n                if (this[kId] === bson_1.Long.ZERO) {\n                    // Cursor exhausted\n                    break;\n                }\n            }\n        }\n        finally {\n            // Only close the cursor if it has not already been closed. This finally clause handles\n            // the case when a user would break out of a for await of loop early.\n            if (!this.closed) {\n                await this.close().catch(() => null);\n            }\n        }\n    }\n    stream(options) {\n        if (options?.transform) {\n            const transform = options.transform;\n            const readable = new ReadableCursorStream(this);\n            return readable.pipe(new stream_1.Transform({\n                objectMode: true,\n                highWaterMark: 1,\n                transform(chunk, _, callback) {\n                    try {\n                        const transformed = transform(chunk);\n                        callback(undefined, transformed);\n                    }\n                    catch (err) {\n                        callback(err);\n                    }\n                }\n            }));\n        }\n        return new ReadableCursorStream(this);\n    }\n    async hasNext() {\n        if (this[kId] === bson_1.Long.ZERO) {\n            return false;\n        }\n        if (this[kDocuments].length !== 0) {\n            return true;\n        }\n        const doc = await next(this, { blocking: true, transform: false });\n        if (doc) {\n            this[kDocuments].unshift(doc);\n            return true;\n        }\n        return false;\n    }\n    /** Get the next available document from the cursor, returns null if no more documents are available. */\n    async next() {\n        if (this[kId] === bson_1.Long.ZERO) {\n            throw new error_1.MongoCursorExhaustedError();\n        }\n        return next(this, { blocking: true, transform: true });\n    }\n    /**\n     * Try to get the next available document from the cursor or `null` if an empty batch is returned\n     */\n    async tryNext() {\n        if (this[kId] === bson_1.Long.ZERO) {\n            throw new error_1.MongoCursorExhaustedError();\n        }\n        return next(this, { blocking: false, transform: true });\n    }\n    /**\n     * Iterates over all the documents for this cursor using the iterator, callback pattern.\n     *\n     * If the iterator returns `false`, iteration will stop.\n     *\n     * @param iterator - The iteration callback.\n     * @deprecated - Will be removed in a future release. Use for await...of instead.\n     */\n    async forEach(iterator) {\n        if (typeof iterator !== 'function') {\n            throw new error_1.MongoInvalidArgumentError('Argument \"iterator\" must be a function');\n        }\n        for await (const document of this) {\n            const result = iterator(document);\n            if (result === false) {\n                break;\n            }\n        }\n    }\n    async close() {\n        const needsToEmitClosed = !this[kClosed];\n        this[kClosed] = true;\n        await cleanupCursor(this, { needsToEmitClosed });\n    }\n    /**\n     * Returns an array of documents. The caller is responsible for making sure that there\n     * is enough memory to store the results. Note that the array only contains partial\n     * results when this cursor had been previously accessed. In that case,\n     * cursor.rewind() can be used to reset the cursor.\n     */\n    async toArray() {\n        const array = [];\n        for await (const document of this) {\n            array.push(document);\n        }\n        return array;\n    }\n    /**\n     * Add a cursor flag to the cursor\n     *\n     * @param flag - The flag to set, must be one of following ['tailable', 'oplogReplay', 'noCursorTimeout', 'awaitData', 'partial' -.\n     * @param value - The flag boolean value.\n     */\n    addCursorFlag(flag, value) {\n        assertUninitialized(this);\n        if (!exports.CURSOR_FLAGS.includes(flag)) {\n            throw new error_1.MongoInvalidArgumentError(`Flag ${flag} is not one of ${exports.CURSOR_FLAGS}`);\n        }\n        if (typeof value !== 'boolean') {\n            throw new error_1.MongoInvalidArgumentError(`Flag ${flag} must be a boolean value`);\n        }\n        this[kOptions][flag] = value;\n        return this;\n    }\n    /**\n     * Map all documents using the provided function\n     * If there is a transform set on the cursor, that will be called first and the result passed to\n     * this function's transform.\n     *\n     * @remarks\n     *\n     * **Note** Cursors use `null` internally to indicate that there are no more documents in the cursor. Providing a mapping\n     * function that maps values to `null` will result in the cursor closing itself before it has finished iterating\n     * all documents.  This will **not** result in a memory leak, just surprising behavior.  For example:\n     *\n     * ```typescript\n     * const cursor = collection.find({});\n     * cursor.map(() => null);\n     *\n     * const documents = await cursor.toArray();\n     * // documents is always [], regardless of how many documents are in the collection.\n     * ```\n     *\n     * Other falsey values are allowed:\n     *\n     * ```typescript\n     * const cursor = collection.find({});\n     * cursor.map(() => '');\n     *\n     * const documents = await cursor.toArray();\n     * // documents is now an array of empty strings\n     * ```\n     *\n     * **Note for Typescript Users:** adding a transform changes the return type of the iteration of this cursor,\n     * it **does not** return a new instance of a cursor. This means when calling map,\n     * you should always assign the result to a new variable in order to get a correctly typed cursor variable.\n     * Take note of the following example:\n     *\n     * @example\n     * ```typescript\n     * const cursor: FindCursor<Document> = coll.find();\n     * const mappedCursor: FindCursor<number> = cursor.map(doc => Object.keys(doc).length);\n     * const keyCounts: number[] = await mappedCursor.toArray(); // cursor.toArray() still returns Document[]\n     * ```\n     * @param transform - The mapping transformation method.\n     */\n    map(transform) {\n        assertUninitialized(this);\n        const oldTransform = this[kTransform]; // TODO(NODE-3283): Improve transform typing\n        if (oldTransform) {\n            this[kTransform] = doc => {\n                return transform(oldTransform(doc));\n            };\n        }\n        else {\n            this[kTransform] = transform;\n        }\n        return this;\n    }\n    /**\n     * Set the ReadPreference for the cursor.\n     *\n     * @param readPreference - The new read preference for the cursor.\n     */\n    withReadPreference(readPreference) {\n        assertUninitialized(this);\n        if (readPreference instanceof read_preference_1.ReadPreference) {\n            this[kOptions].readPreference = readPreference;\n        }\n        else if (typeof readPreference === 'string') {\n            this[kOptions].readPreference = read_preference_1.ReadPreference.fromString(readPreference);\n        }\n        else {\n            throw new error_1.MongoInvalidArgumentError(`Invalid read preference: ${readPreference}`);\n        }\n        return this;\n    }\n    /**\n     * Set the ReadPreference for the cursor.\n     *\n     * @param readPreference - The new read preference for the cursor.\n     */\n    withReadConcern(readConcern) {\n        assertUninitialized(this);\n        const resolvedReadConcern = read_concern_1.ReadConcern.fromOptions({ readConcern });\n        if (resolvedReadConcern) {\n            this[kOptions].readConcern = resolvedReadConcern;\n        }\n        return this;\n    }\n    /**\n     * Set a maxTimeMS on the cursor query, allowing for hard timeout limits on queries (Only supported on MongoDB 2.6 or higher)\n     *\n     * @param value - Number of milliseconds to wait before aborting the query.\n     */\n    maxTimeMS(value) {\n        assertUninitialized(this);\n        if (typeof value !== 'number') {\n            throw new error_1.MongoInvalidArgumentError('Argument for maxTimeMS must be a number');\n        }\n        this[kOptions].maxTimeMS = value;\n        return this;\n    }\n    /**\n     * Set the batch size for the cursor.\n     *\n     * @param value - The number of documents to return per batch. See {@link https://www.mongodb.com/docs/manual/reference/command/find/|find command documentation}.\n     */\n    batchSize(value) {\n        assertUninitialized(this);\n        if (this[kOptions].tailable) {\n            throw new error_1.MongoTailableCursorError('Tailable cursor does not support batchSize');\n        }\n        if (typeof value !== 'number') {\n            throw new error_1.MongoInvalidArgumentError('Operation \"batchSize\" requires an integer');\n        }\n        this[kOptions].batchSize = value;\n        return this;\n    }\n    /**\n     * Rewind this cursor to its uninitialized state. Any options that are present on the cursor will\n     * remain in effect. Iterating this cursor will cause new queries to be sent to the server, even\n     * if the resultant data has already been retrieved by this cursor.\n     */\n    rewind() {\n        if (!this[kInitialized]) {\n            return;\n        }\n        this[kId] = null;\n        this[kDocuments].clear();\n        this[kClosed] = false;\n        this[kKilled] = false;\n        this[kInitialized] = false;\n        const session = this[kSession];\n        if (session) {\n            // We only want to end this session if we created it, and it hasn't ended yet\n            if (session.explicit === false) {\n                if (!session.hasEnded) {\n                    session.endSession().catch(() => null);\n                }\n                this[kSession] = this.client.startSession({ owner: this, explicit: false });\n            }\n        }\n    }\n    /** @internal */\n    async getMore(batchSize) {\n        // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n        const getMoreOperation = new get_more_1.GetMoreOperation(this[kNamespace], this[kId], this[kServer], {\n            ...this[kOptions],\n            session: this[kSession],\n            batchSize\n        });\n        return (0, execute_operation_1.executeOperation)(this[kClient], getMoreOperation);\n    }\n    /**\n     * @internal\n     *\n     * This function is exposed for the unified test runner's createChangeStream\n     * operation.  We cannot refactor to use the abstract _initialize method without\n     * a significant refactor.\n     */\n    async [kInit]() {\n        try {\n            const state = await this._initialize(this[kSession]);\n            const response = state.response;\n            this[kServer] = state.server;\n            if (response.cursor) {\n                // TODO(NODE-2674): Preserve int64 sent from MongoDB\n                this[kId] =\n                    typeof response.cursor.id === 'number'\n                        ? bson_1.Long.fromNumber(response.cursor.id)\n                        : typeof response.cursor.id === 'bigint'\n                            ? bson_1.Long.fromBigInt(response.cursor.id)\n                            : response.cursor.id;\n                if (response.cursor.ns) {\n                    this[kNamespace] = (0, utils_1.ns)(response.cursor.ns);\n                }\n                this[kDocuments].pushMany(response.cursor.firstBatch);\n            }\n            // When server responses return without a cursor document, we close this cursor\n            // and return the raw server response. This is often the case for explain commands\n            // for example\n            if (this[kId] == null) {\n                this[kId] = bson_1.Long.ZERO;\n                // TODO(NODE-3286): ExecutionResult needs to accept a generic parameter\n                this[kDocuments].push(state.response);\n            }\n            // the cursor is now initialized, even if it is dead\n            this[kInitialized] = true;\n        }\n        catch (error) {\n            // the cursor is now initialized, even if an error occurred\n            this[kInitialized] = true;\n            await cleanupCursor(this, { error });\n            throw error;\n        }\n        if (this.isDead) {\n            await cleanupCursor(this, undefined);\n        }\n        return;\n    }\n}\n/** @event */\nAbstractCursor.CLOSE = 'close';\nexports.AbstractCursor = AbstractCursor;\n/**\n * @param cursor - the cursor on which to call `next`\n * @param blocking - a boolean indicating whether or not the cursor should `block` until data\n *     is available.  Generally, this flag is set to `false` because if the getMore returns no documents,\n *     the cursor has been exhausted.  In certain scenarios (ChangeStreams, tailable await cursors and\n *     `tryNext`, for example) blocking is necessary because a getMore returning no documents does\n *     not indicate the end of the cursor.\n * @param transform - if true, the cursor's transform function is applied to the result document (if the transform exists)\n * @returns the next document in the cursor, or `null`.  When `blocking` is `true`, a `null` document means\n * the cursor has been exhausted.  Otherwise, it means that there is no document available in the cursor's buffer.\n */\nasync function next(cursor, { blocking, transform }) {\n    if (cursor.closed) {\n        return null;\n    }\n    do {\n        if (cursor[kId] == null) {\n            // All cursors must operate within a session, one must be made implicitly if not explicitly provided\n            await cursor[kInit]();\n        }\n        if (cursor[kDocuments].length !== 0) {\n            const doc = cursor[kDocuments].shift();\n            if (doc != null && transform && cursor[kTransform]) {\n                try {\n                    return cursor[kTransform](doc);\n                }\n                catch (error) {\n                    // `cleanupCursorAsync` should never throw, but if it does we want to throw the original\n                    // error instead.\n                    await cleanupCursor(cursor, { error, needsToEmitClosed: true }).catch(() => null);\n                    throw error;\n                }\n            }\n            return doc;\n        }\n        if (cursor.isDead) {\n            // if the cursor is dead, we clean it up\n            // cleanupCursorAsync should never throw, but if it does it indicates a bug in the driver\n            // and we should surface the error\n            await cleanupCursor(cursor, {});\n            return null;\n        }\n        // otherwise need to call getMore\n        const batchSize = cursor[kOptions].batchSize || 1000;\n        try {\n            const response = await cursor.getMore(batchSize);\n            if (response) {\n                const cursorId = typeof response.cursor.id === 'number'\n                    ? bson_1.Long.fromNumber(response.cursor.id)\n                    : typeof response.cursor.id === 'bigint'\n                        ? bson_1.Long.fromBigInt(response.cursor.id)\n                        : response.cursor.id;\n                cursor[kDocuments].pushMany(response.cursor.nextBatch);\n                cursor[kId] = cursorId;\n            }\n        }\n        catch (error) {\n            // `cleanupCursorAsync` should never throw, but if it does we want to throw the original\n            // error instead.\n            await cleanupCursor(cursor, { error }).catch(() => null);\n            throw error;\n        }\n        if (cursor.isDead) {\n            // If we successfully received a response from a cursor BUT the cursor indicates that it is exhausted,\n            // we intentionally clean up the cursor to release its session back into the pool before the cursor\n            // is iterated.  This prevents a cursor that is exhausted on the server from holding\n            // onto a session indefinitely until the AbstractCursor is iterated.\n            //\n            // cleanupCursorAsync should never throw, but if it does it indicates a bug in the driver\n            // and we should surface the error\n            await cleanupCursor(cursor, {});\n        }\n        if (cursor[kDocuments].length === 0 && blocking === false) {\n            return null;\n        }\n    } while (!cursor.isDead || cursor[kDocuments].length !== 0);\n    return null;\n}\nasync function cleanupCursor(cursor, options) {\n    const cursorId = cursor[kId];\n    const cursorNs = cursor[kNamespace];\n    const server = cursor[kServer];\n    const session = cursor[kSession];\n    const error = options?.error;\n    // Cursors only emit closed events once the client-side cursor has been exhausted fully or there\n    // was an error.  Notably, when the server returns a cursor id of 0 and a non-empty batch, we\n    // cleanup the cursor but don't emit a `close` event.\n    const needsToEmitClosed = options?.needsToEmitClosed ?? cursor[kDocuments].length === 0;\n    if (error) {\n        if (cursor.loadBalanced && error instanceof error_1.MongoNetworkError) {\n            return completeCleanup();\n        }\n    }\n    if (cursorId == null || server == null || cursorId.isZero() || cursorNs == null) {\n        if (needsToEmitClosed) {\n            cursor[kClosed] = true;\n            cursor[kId] = bson_1.Long.ZERO;\n            cursor.emit(AbstractCursor.CLOSE);\n        }\n        if (session) {\n            if (session.owner === cursor) {\n                await session.endSession({ error });\n                return;\n            }\n            if (!session.inTransaction()) {\n                (0, sessions_1.maybeClearPinnedConnection)(session, { error });\n            }\n        }\n        return;\n    }\n    async function completeCleanup() {\n        if (session) {\n            if (session.owner === cursor) {\n                try {\n                    await session.endSession({ error });\n                }\n                finally {\n                    cursor.emit(AbstractCursor.CLOSE);\n                }\n                return;\n            }\n            if (!session.inTransaction()) {\n                (0, sessions_1.maybeClearPinnedConnection)(session, { error });\n            }\n        }\n        cursor.emit(AbstractCursor.CLOSE);\n        return;\n    }\n    cursor[kKilled] = true;\n    if (session.hasEnded) {\n        return completeCleanup();\n    }\n    try {\n        await (0, execute_operation_1.executeOperation)(cursor[kClient], new kill_cursors_1.KillCursorsOperation(cursorId, cursorNs, server, { session })).catch(() => null);\n    }\n    finally {\n        await completeCleanup();\n    }\n}\n/** @internal */\nfunction assertUninitialized(cursor) {\n    if (cursor[kInitialized]) {\n        throw new error_1.MongoCursorInUseError();\n    }\n}\nexports.assertUninitialized = assertUninitialized;\nclass ReadableCursorStream extends stream_1.Readable {\n    constructor(cursor) {\n        super({\n            objectMode: true,\n            autoDestroy: false,\n            highWaterMark: 1\n        });\n        this._readInProgress = false;\n        this._cursor = cursor;\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    _read(size) {\n        if (!this._readInProgress) {\n            this._readInProgress = true;\n            this._readNext();\n        }\n    }\n    _destroy(error, callback) {\n        this._cursor.close().then(() => callback(error), closeError => callback(closeError));\n    }\n    _readNext() {\n        next(this._cursor, { blocking: true, transform: true }).then(result => {\n            if (result == null) {\n                this.push(null);\n            }\n            else if (this.destroyed) {\n                this._cursor.close().catch(() => null);\n            }\n            else {\n                if (this.push(result)) {\n                    return this._readNext();\n                }\n                this._readInProgress = false;\n            }\n        }, err => {\n            // NOTE: This is questionable, but we have a test backing the behavior. It seems the\n            //       desired behavior is that a stream ends cleanly when a user explicitly closes\n            //       a client during iteration. Alternatively, we could do the \"right\" thing and\n            //       propagate the error message by removing this special case.\n            if (err.message.match(/server is closed/)) {\n                this._cursor.close().catch(() => null);\n                return this.push(null);\n            }\n            // NOTE: This is also perhaps questionable. The rationale here is that these errors tend\n            //       to be \"operation was interrupted\", where a cursor has been closed but there is an\n            //       active getMore in-flight. This used to check if the cursor was killed but once\n            //       that changed to happen in cleanup legitimate errors would not destroy the\n            //       stream. There are change streams test specifically test these cases.\n            if (err.message.match(/operation was interrupted/)) {\n                return this.push(null);\n            }\n            // NOTE: The two above checks on the message of the error will cause a null to be pushed\n            //       to the stream, thus closing the stream before the destroy call happens. This means\n            //       that either of those error messages on a change stream will not get a proper\n            //       'error' event to be emitted (the error passed to destroy). Change stream resumability\n            //       relies on that error event to be emitted to create its new cursor and thus was not\n            //       working on 4.4 servers because the error emitted on failover was \"interrupted at\n            //       shutdown\" while on 5.0+ it is \"The server is in quiesce mode and will shut down\".\n            //       See NODE-4475.\n            return this.destroy(err);\n        });\n    }\n}\n//# sourceMappingURL=abstract_cursor.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cursor/abstract_cursor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cursor/aggregation_cursor.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongodb/lib/cursor/aggregation_cursor.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AggregationCursor = void 0;\nconst aggregate_1 = __webpack_require__(/*! ../operations/aggregate */ \"./node_modules/mongodb/lib/operations/aggregate.js\");\nconst execute_operation_1 = __webpack_require__(/*! ../operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst abstract_cursor_1 = __webpack_require__(/*! ./abstract_cursor */ \"./node_modules/mongodb/lib/cursor/abstract_cursor.js\");\n/** @internal */\nconst kPipeline = Symbol('pipeline');\n/** @internal */\nconst kOptions = Symbol('options');\n/**\n * The **AggregationCursor** class is an internal class that embodies an aggregation cursor on MongoDB\n * allowing for iteration over the results returned from the underlying query. It supports\n * one by one document iteration, conversion to an array or can be iterated as a Node 4.X\n * or higher stream\n * @public\n */\nclass AggregationCursor extends abstract_cursor_1.AbstractCursor {\n    /** @internal */\n    constructor(client, namespace, pipeline = [], options = {}) {\n        super(client, namespace, options);\n        this[kPipeline] = pipeline;\n        this[kOptions] = options;\n    }\n    get pipeline() {\n        return this[kPipeline];\n    }\n    clone() {\n        const clonedOptions = (0, utils_1.mergeOptions)({}, this[kOptions]);\n        delete clonedOptions.session;\n        return new AggregationCursor(this.client, this.namespace, this[kPipeline], {\n            ...clonedOptions\n        });\n    }\n    map(transform) {\n        return super.map(transform);\n    }\n    /** @internal */\n    async _initialize(session) {\n        const aggregateOperation = new aggregate_1.AggregateOperation(this.namespace, this[kPipeline], {\n            ...this[kOptions],\n            ...this.cursorOptions,\n            session\n        });\n        const response = await (0, execute_operation_1.executeOperation)(this.client, aggregateOperation);\n        // TODO: NODE-2882\n        return { server: aggregateOperation.server, session, response };\n    }\n    /** Execute the explain for the cursor */\n    async explain(verbosity) {\n        return (0, execute_operation_1.executeOperation)(this.client, new aggregate_1.AggregateOperation(this.namespace, this[kPipeline], {\n            ...this[kOptions],\n            ...this.cursorOptions,\n            explain: verbosity ?? true\n        }));\n    }\n    group($group) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kPipeline].push({ $group });\n        return this;\n    }\n    /** Add a limit stage to the aggregation pipeline */\n    limit($limit) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kPipeline].push({ $limit });\n        return this;\n    }\n    /** Add a match stage to the aggregation pipeline */\n    match($match) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kPipeline].push({ $match });\n        return this;\n    }\n    /** Add an out stage to the aggregation pipeline */\n    out($out) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kPipeline].push({ $out });\n        return this;\n    }\n    /**\n     * Add a project stage to the aggregation pipeline\n     *\n     * @remarks\n     * In order to strictly type this function you must provide an interface\n     * that represents the effect of your projection on the result documents.\n     *\n     * By default chaining a projection to your cursor changes the returned type to the generic {@link Document} type.\n     * You should specify a parameterized type to have assertions on your final results.\n     *\n     * @example\n     * ```typescript\n     * // Best way\n     * const docs: AggregationCursor<{ a: number }> = cursor.project<{ a: number }>({ _id: 0, a: true });\n     * // Flexible way\n     * const docs: AggregationCursor<Document> = cursor.project({ _id: 0, a: true });\n     * ```\n     *\n     * @remarks\n     * In order to strictly type this function you must provide an interface\n     * that represents the effect of your projection on the result documents.\n     *\n     * **Note for Typescript Users:** adding a transform changes the return type of the iteration of this cursor,\n     * it **does not** return a new instance of a cursor. This means when calling project,\n     * you should always assign the result to a new variable in order to get a correctly typed cursor variable.\n     * Take note of the following example:\n     *\n     * @example\n     * ```typescript\n     * const cursor: AggregationCursor<{ a: number; b: string }> = coll.aggregate([]);\n     * const projectCursor = cursor.project<{ a: number }>({ _id: 0, a: true });\n     * const aPropOnlyArray: {a: number}[] = await projectCursor.toArray();\n     *\n     * // or always use chaining and save the final cursor\n     *\n     * const cursor = coll.aggregate().project<{ a: string }>({\n     *   _id: 0,\n     *   a: { $convert: { input: '$a', to: 'string' }\n     * }});\n     * ```\n     */\n    project($project) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kPipeline].push({ $project });\n        return this;\n    }\n    /** Add a lookup stage to the aggregation pipeline */\n    lookup($lookup) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kPipeline].push({ $lookup });\n        return this;\n    }\n    /** Add a redact stage to the aggregation pipeline */\n    redact($redact) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kPipeline].push({ $redact });\n        return this;\n    }\n    /** Add a skip stage to the aggregation pipeline */\n    skip($skip) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kPipeline].push({ $skip });\n        return this;\n    }\n    /** Add a sort stage to the aggregation pipeline */\n    sort($sort) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kPipeline].push({ $sort });\n        return this;\n    }\n    /** Add a unwind stage to the aggregation pipeline */\n    unwind($unwind) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kPipeline].push({ $unwind });\n        return this;\n    }\n    /** Add a geoNear stage to the aggregation pipeline */\n    geoNear($geoNear) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kPipeline].push({ $geoNear });\n        return this;\n    }\n}\nexports.AggregationCursor = AggregationCursor;\n//# sourceMappingURL=aggregation_cursor.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cursor/aggregation_cursor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cursor/change_stream_cursor.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mongodb/lib/cursor/change_stream_cursor.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ChangeStreamCursor = void 0;\nconst change_stream_1 = __webpack_require__(/*! ../change_stream */ \"./node_modules/mongodb/lib/change_stream.js\");\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst aggregate_1 = __webpack_require__(/*! ../operations/aggregate */ \"./node_modules/mongodb/lib/operations/aggregate.js\");\nconst execute_operation_1 = __webpack_require__(/*! ../operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst abstract_cursor_1 = __webpack_require__(/*! ./abstract_cursor */ \"./node_modules/mongodb/lib/cursor/abstract_cursor.js\");\n/** @internal */\nclass ChangeStreamCursor extends abstract_cursor_1.AbstractCursor {\n    constructor(client, namespace, pipeline = [], options = {}) {\n        super(client, namespace, options);\n        this.pipeline = pipeline;\n        this.options = options;\n        this._resumeToken = null;\n        this.startAtOperationTime = options.startAtOperationTime;\n        if (options.startAfter) {\n            this.resumeToken = options.startAfter;\n        }\n        else if (options.resumeAfter) {\n            this.resumeToken = options.resumeAfter;\n        }\n    }\n    set resumeToken(token) {\n        this._resumeToken = token;\n        this.emit(change_stream_1.ChangeStream.RESUME_TOKEN_CHANGED, token);\n    }\n    get resumeToken() {\n        return this._resumeToken;\n    }\n    get resumeOptions() {\n        const options = {\n            ...this.options\n        };\n        for (const key of ['resumeAfter', 'startAfter', 'startAtOperationTime']) {\n            delete options[key];\n        }\n        if (this.resumeToken != null) {\n            if (this.options.startAfter && !this.hasReceived) {\n                options.startAfter = this.resumeToken;\n            }\n            else {\n                options.resumeAfter = this.resumeToken;\n            }\n        }\n        else if (this.startAtOperationTime != null && (0, utils_1.maxWireVersion)(this.server) >= 7) {\n            options.startAtOperationTime = this.startAtOperationTime;\n        }\n        return options;\n    }\n    cacheResumeToken(resumeToken) {\n        if (this.bufferedCount() === 0 && this.postBatchResumeToken) {\n            this.resumeToken = this.postBatchResumeToken;\n        }\n        else {\n            this.resumeToken = resumeToken;\n        }\n        this.hasReceived = true;\n    }\n    _processBatch(response) {\n        const cursor = response.cursor;\n        if (cursor.postBatchResumeToken) {\n            this.postBatchResumeToken = response.cursor.postBatchResumeToken;\n            const batch = 'firstBatch' in response.cursor ? response.cursor.firstBatch : response.cursor.nextBatch;\n            if (batch.length === 0) {\n                this.resumeToken = cursor.postBatchResumeToken;\n            }\n        }\n    }\n    clone() {\n        return new ChangeStreamCursor(this.client, this.namespace, this.pipeline, {\n            ...this.cursorOptions\n        });\n    }\n    async _initialize(session) {\n        const aggregateOperation = new aggregate_1.AggregateOperation(this.namespace, this.pipeline, {\n            ...this.cursorOptions,\n            ...this.options,\n            session\n        });\n        const response = await (0, execute_operation_1.executeOperation)(session.client, aggregateOperation);\n        const server = aggregateOperation.server;\n        this.maxWireVersion = (0, utils_1.maxWireVersion)(server);\n        if (this.startAtOperationTime == null &&\n            this.resumeAfter == null &&\n            this.startAfter == null &&\n            this.maxWireVersion >= 7) {\n            this.startAtOperationTime = response.operationTime;\n        }\n        this._processBatch(response);\n        this.emit(constants_1.INIT, response);\n        this.emit(constants_1.RESPONSE);\n        // TODO: NODE-2882\n        return { server, session, response };\n    }\n    async getMore(batchSize) {\n        const response = await super.getMore(batchSize);\n        this.maxWireVersion = (0, utils_1.maxWireVersion)(this.server);\n        this._processBatch(response);\n        this.emit(change_stream_1.ChangeStream.MORE, response);\n        this.emit(change_stream_1.ChangeStream.RESPONSE);\n        return response;\n    }\n}\nexports.ChangeStreamCursor = ChangeStreamCursor;\n//# sourceMappingURL=change_stream_cursor.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cursor/change_stream_cursor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cursor/find_cursor.js":
/*!********************************************************!*\
  !*** ./node_modules/mongodb/lib/cursor/find_cursor.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.FindCursor = exports.FLAGS = void 0;\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst count_1 = __webpack_require__(/*! ../operations/count */ \"./node_modules/mongodb/lib/operations/count.js\");\nconst execute_operation_1 = __webpack_require__(/*! ../operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst find_1 = __webpack_require__(/*! ../operations/find */ \"./node_modules/mongodb/lib/operations/find.js\");\nconst sort_1 = __webpack_require__(/*! ../sort */ \"./node_modules/mongodb/lib/sort.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst abstract_cursor_1 = __webpack_require__(/*! ./abstract_cursor */ \"./node_modules/mongodb/lib/cursor/abstract_cursor.js\");\n/** @internal */\nconst kFilter = Symbol('filter');\n/** @internal */\nconst kNumReturned = Symbol('numReturned');\n/** @internal */\nconst kBuiltOptions = Symbol('builtOptions');\n/** @public Flags allowed for cursor */\nexports.FLAGS = [\n    'tailable',\n    'oplogReplay',\n    'noCursorTimeout',\n    'awaitData',\n    'exhaust',\n    'partial'\n];\n/** @public */\nclass FindCursor extends abstract_cursor_1.AbstractCursor {\n    /** @internal */\n    constructor(client, namespace, filter = {}, options = {}) {\n        super(client, namespace, options);\n        this[kFilter] = filter;\n        this[kBuiltOptions] = options;\n        if (options.sort != null) {\n            this[kBuiltOptions].sort = (0, sort_1.formatSort)(options.sort);\n        }\n    }\n    clone() {\n        const clonedOptions = (0, utils_1.mergeOptions)({}, this[kBuiltOptions]);\n        delete clonedOptions.session;\n        return new FindCursor(this.client, this.namespace, this[kFilter], {\n            ...clonedOptions\n        });\n    }\n    map(transform) {\n        return super.map(transform);\n    }\n    /** @internal */\n    async _initialize(session) {\n        const findOperation = new find_1.FindOperation(undefined, this.namespace, this[kFilter], {\n            ...this[kBuiltOptions],\n            ...this.cursorOptions,\n            session\n        });\n        const response = await (0, execute_operation_1.executeOperation)(this.client, findOperation);\n        // the response is not a cursor when `explain` is enabled\n        this[kNumReturned] = response.cursor?.firstBatch?.length;\n        // TODO: NODE-2882\n        return { server: findOperation.server, session, response };\n    }\n    /** @internal */\n    async getMore(batchSize) {\n        const numReturned = this[kNumReturned];\n        if (numReturned) {\n            // TODO(DRIVERS-1448): Remove logic to enforce `limit` in the driver\n            const limit = this[kBuiltOptions].limit;\n            batchSize =\n                limit && limit > 0 && numReturned + batchSize > limit ? limit - numReturned : batchSize;\n            if (batchSize <= 0) {\n                // this is an optimization for the special case of a limit for a find command to avoid an\n                // extra getMore when the limit has been reached and the limit is a multiple of the batchSize.\n                // This is a consequence of the new query engine in 5.0 having no knowledge of the limit as it\n                // produces results for the find command.  Once a batch is filled up, it is returned and only\n                // on the subsequent getMore will the query framework consider the limit, determine the cursor\n                // is exhausted and return a cursorId of zero.\n                // instead, if we determine there are no more documents to request from the server, we preemptively\n                // close the cursor\n                await this.close().catch(() => null);\n                return { cursor: { id: bson_1.Long.ZERO, nextBatch: [] } };\n            }\n        }\n        const response = await super.getMore(batchSize);\n        // TODO: wrap this in some logic to prevent it from happening if we don't need this support\n        if (response) {\n            this[kNumReturned] = this[kNumReturned] + response.cursor.nextBatch.length;\n        }\n        return response;\n    }\n    /**\n     * Get the count of documents for this cursor\n     * @deprecated Use `collection.estimatedDocumentCount` or `collection.countDocuments` instead\n     */\n    async count(options) {\n        (0, utils_1.emitWarningOnce)('cursor.count is deprecated and will be removed in the next major version, please use `collection.estimatedDocumentCount` or `collection.countDocuments` instead ');\n        if (typeof options === 'boolean') {\n            throw new error_1.MongoInvalidArgumentError('Invalid first parameter to count');\n        }\n        return (0, execute_operation_1.executeOperation)(this.client, new count_1.CountOperation(this.namespace, this[kFilter], {\n            ...this[kBuiltOptions],\n            ...this.cursorOptions,\n            ...options\n        }));\n    }\n    /** Execute the explain for the cursor */\n    async explain(verbosity) {\n        return (0, execute_operation_1.executeOperation)(this.client, new find_1.FindOperation(undefined, this.namespace, this[kFilter], {\n            ...this[kBuiltOptions],\n            ...this.cursorOptions,\n            explain: verbosity ?? true\n        }));\n    }\n    /** Set the cursor query */\n    filter(filter) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kFilter] = filter;\n        return this;\n    }\n    /**\n     * Set the cursor hint\n     *\n     * @param hint - If specified, then the query system will only consider plans using the hinted index.\n     */\n    hint(hint) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kBuiltOptions].hint = hint;\n        return this;\n    }\n    /**\n     * Set the cursor min\n     *\n     * @param min - Specify a $min value to specify the inclusive lower bound for a specific index in order to constrain the results of find(). The $min specifies the lower bound for all keys of a specific index in order.\n     */\n    min(min) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kBuiltOptions].min = min;\n        return this;\n    }\n    /**\n     * Set the cursor max\n     *\n     * @param max - Specify a $max value to specify the exclusive upper bound for a specific index in order to constrain the results of find(). The $max specifies the upper bound for all keys of a specific index in order.\n     */\n    max(max) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kBuiltOptions].max = max;\n        return this;\n    }\n    /**\n     * Set the cursor returnKey.\n     * If set to true, modifies the cursor to only return the index field or fields for the results of the query, rather than documents.\n     * If set to true and the query does not use an index to perform the read operation, the returned documents will not contain any fields.\n     *\n     * @param value - the returnKey value.\n     */\n    returnKey(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kBuiltOptions].returnKey = value;\n        return this;\n    }\n    /**\n     * Modifies the output of a query by adding a field $recordId to matching documents. $recordId is the internal key which uniquely identifies a document in a collection.\n     *\n     * @param value - The $showDiskLoc option has now been deprecated and replaced with the showRecordId field. $showDiskLoc will still be accepted for OP_QUERY stye find.\n     */\n    showRecordId(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kBuiltOptions].showRecordId = value;\n        return this;\n    }\n    /**\n     * Add a query modifier to the cursor query\n     *\n     * @param name - The query modifier (must start with $, such as $orderby etc)\n     * @param value - The modifier value.\n     */\n    addQueryModifier(name, value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        if (name[0] !== '$') {\n            throw new error_1.MongoInvalidArgumentError(`${name} is not a valid query modifier`);\n        }\n        // Strip of the $\n        const field = name.substr(1);\n        // NOTE: consider some TS magic for this\n        switch (field) {\n            case 'comment':\n                this[kBuiltOptions].comment = value;\n                break;\n            case 'explain':\n                this[kBuiltOptions].explain = value;\n                break;\n            case 'hint':\n                this[kBuiltOptions].hint = value;\n                break;\n            case 'max':\n                this[kBuiltOptions].max = value;\n                break;\n            case 'maxTimeMS':\n                this[kBuiltOptions].maxTimeMS = value;\n                break;\n            case 'min':\n                this[kBuiltOptions].min = value;\n                break;\n            case 'orderby':\n                this[kBuiltOptions].sort = (0, sort_1.formatSort)(value);\n                break;\n            case 'query':\n                this[kFilter] = value;\n                break;\n            case 'returnKey':\n                this[kBuiltOptions].returnKey = value;\n                break;\n            case 'showDiskLoc':\n                this[kBuiltOptions].showRecordId = value;\n                break;\n            default:\n                throw new error_1.MongoInvalidArgumentError(`Invalid query modifier: ${name}`);\n        }\n        return this;\n    }\n    /**\n     * Add a comment to the cursor query allowing for tracking the comment in the log.\n     *\n     * @param value - The comment attached to this query.\n     */\n    comment(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kBuiltOptions].comment = value;\n        return this;\n    }\n    /**\n     * Set a maxAwaitTimeMS on a tailing cursor query to allow to customize the timeout value for the option awaitData (Only supported on MongoDB 3.2 or higher, ignored otherwise)\n     *\n     * @param value - Number of milliseconds to wait before aborting the tailed query.\n     */\n    maxAwaitTimeMS(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        if (typeof value !== 'number') {\n            throw new error_1.MongoInvalidArgumentError('Argument for maxAwaitTimeMS must be a number');\n        }\n        this[kBuiltOptions].maxAwaitTimeMS = value;\n        return this;\n    }\n    /**\n     * Set a maxTimeMS on the cursor query, allowing for hard timeout limits on queries (Only supported on MongoDB 2.6 or higher)\n     *\n     * @param value - Number of milliseconds to wait before aborting the query.\n     */\n    maxTimeMS(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        if (typeof value !== 'number') {\n            throw new error_1.MongoInvalidArgumentError('Argument for maxTimeMS must be a number');\n        }\n        this[kBuiltOptions].maxTimeMS = value;\n        return this;\n    }\n    /**\n     * Add a project stage to the aggregation pipeline\n     *\n     * @remarks\n     * In order to strictly type this function you must provide an interface\n     * that represents the effect of your projection on the result documents.\n     *\n     * By default chaining a projection to your cursor changes the returned type to the generic\n     * {@link Document} type.\n     * You should specify a parameterized type to have assertions on your final results.\n     *\n     * @example\n     * ```typescript\n     * // Best way\n     * const docs: FindCursor<{ a: number }> = cursor.project<{ a: number }>({ _id: 0, a: true });\n     * // Flexible way\n     * const docs: FindCursor<Document> = cursor.project({ _id: 0, a: true });\n     * ```\n     *\n     * @remarks\n     *\n     * **Note for Typescript Users:** adding a transform changes the return type of the iteration of this cursor,\n     * it **does not** return a new instance of a cursor. This means when calling project,\n     * you should always assign the result to a new variable in order to get a correctly typed cursor variable.\n     * Take note of the following example:\n     *\n     * @example\n     * ```typescript\n     * const cursor: FindCursor<{ a: number; b: string }> = coll.find();\n     * const projectCursor = cursor.project<{ a: number }>({ _id: 0, a: true });\n     * const aPropOnlyArray: {a: number}[] = await projectCursor.toArray();\n     *\n     * // or always use chaining and save the final cursor\n     *\n     * const cursor = coll.find().project<{ a: string }>({\n     *   _id: 0,\n     *   a: { $convert: { input: '$a', to: 'string' }\n     * }});\n     * ```\n     */\n    project(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kBuiltOptions].projection = value;\n        return this;\n    }\n    /**\n     * Sets the sort order of the cursor query.\n     *\n     * @param sort - The key or keys set for the sort.\n     * @param direction - The direction of the sorting (1 or -1).\n     */\n    sort(sort, direction) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        if (this[kBuiltOptions].tailable) {\n            throw new error_1.MongoTailableCursorError('Tailable cursor does not support sorting');\n        }\n        this[kBuiltOptions].sort = (0, sort_1.formatSort)(sort, direction);\n        return this;\n    }\n    /**\n     * Allows disk use for blocking sort operations exceeding 100MB memory. (MongoDB 3.2 or higher)\n     *\n     * @remarks\n     * {@link https://www.mongodb.com/docs/manual/reference/command/find/#find-cmd-allowdiskuse | find command allowDiskUse documentation}\n     */\n    allowDiskUse(allow = true) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        if (!this[kBuiltOptions].sort) {\n            throw new error_1.MongoInvalidArgumentError('Option \"allowDiskUse\" requires a sort specification');\n        }\n        // As of 6.0 the default is true. This allows users to get back to the old behavior.\n        if (!allow) {\n            this[kBuiltOptions].allowDiskUse = false;\n            return this;\n        }\n        this[kBuiltOptions].allowDiskUse = true;\n        return this;\n    }\n    /**\n     * Set the collation options for the cursor.\n     *\n     * @param value - The cursor collation options (MongoDB 3.4 or higher) settings for update operation (see 3.4 documentation for available fields).\n     */\n    collation(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kBuiltOptions].collation = value;\n        return this;\n    }\n    /**\n     * Set the limit for the cursor.\n     *\n     * @param value - The limit for the cursor query.\n     */\n    limit(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        if (this[kBuiltOptions].tailable) {\n            throw new error_1.MongoTailableCursorError('Tailable cursor does not support limit');\n        }\n        if (typeof value !== 'number') {\n            throw new error_1.MongoInvalidArgumentError('Operation \"limit\" requires an integer');\n        }\n        this[kBuiltOptions].limit = value;\n        return this;\n    }\n    /**\n     * Set the skip for the cursor.\n     *\n     * @param value - The skip for the cursor query.\n     */\n    skip(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        if (this[kBuiltOptions].tailable) {\n            throw new error_1.MongoTailableCursorError('Tailable cursor does not support skip');\n        }\n        if (typeof value !== 'number') {\n            throw new error_1.MongoInvalidArgumentError('Operation \"skip\" requires an integer');\n        }\n        this[kBuiltOptions].skip = value;\n        return this;\n    }\n}\nexports.FindCursor = FindCursor;\n//# sourceMappingURL=find_cursor.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cursor/find_cursor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cursor/list_collections_cursor.js":
/*!********************************************************************!*\
  !*** ./node_modules/mongodb/lib/cursor/list_collections_cursor.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ListCollectionsCursor = void 0;\nconst execute_operation_1 = __webpack_require__(/*! ../operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst list_collections_1 = __webpack_require__(/*! ../operations/list_collections */ \"./node_modules/mongodb/lib/operations/list_collections.js\");\nconst abstract_cursor_1 = __webpack_require__(/*! ./abstract_cursor */ \"./node_modules/mongodb/lib/cursor/abstract_cursor.js\");\n/** @public */\nclass ListCollectionsCursor extends abstract_cursor_1.AbstractCursor {\n    constructor(db, filter, options) {\n        super(db.client, db.s.namespace, options);\n        this.parent = db;\n        this.filter = filter;\n        this.options = options;\n    }\n    clone() {\n        return new ListCollectionsCursor(this.parent, this.filter, {\n            ...this.options,\n            ...this.cursorOptions\n        });\n    }\n    /** @internal */\n    async _initialize(session) {\n        const operation = new list_collections_1.ListCollectionsOperation(this.parent, this.filter, {\n            ...this.cursorOptions,\n            ...this.options,\n            session\n        });\n        const response = await (0, execute_operation_1.executeOperation)(this.parent.client, operation);\n        // TODO: NODE-2882\n        return { server: operation.server, session, response };\n    }\n}\nexports.ListCollectionsCursor = ListCollectionsCursor;\n//# sourceMappingURL=list_collections_cursor.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cursor/list_collections_cursor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cursor/list_indexes_cursor.js":
/*!****************************************************************!*\
  !*** ./node_modules/mongodb/lib/cursor/list_indexes_cursor.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ListIndexesCursor = void 0;\nconst execute_operation_1 = __webpack_require__(/*! ../operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst indexes_1 = __webpack_require__(/*! ../operations/indexes */ \"./node_modules/mongodb/lib/operations/indexes.js\");\nconst abstract_cursor_1 = __webpack_require__(/*! ./abstract_cursor */ \"./node_modules/mongodb/lib/cursor/abstract_cursor.js\");\n/** @public */\nclass ListIndexesCursor extends abstract_cursor_1.AbstractCursor {\n    constructor(collection, options) {\n        super(collection.client, collection.s.namespace, options);\n        this.parent = collection;\n        this.options = options;\n    }\n    clone() {\n        return new ListIndexesCursor(this.parent, {\n            ...this.options,\n            ...this.cursorOptions\n        });\n    }\n    /** @internal */\n    async _initialize(session) {\n        const operation = new indexes_1.ListIndexesOperation(this.parent, {\n            ...this.cursorOptions,\n            ...this.options,\n            session\n        });\n        const response = await (0, execute_operation_1.executeOperation)(this.parent.client, operation);\n        // TODO: NODE-2882\n        return { server: operation.server, session, response };\n    }\n}\nexports.ListIndexesCursor = ListIndexesCursor;\n//# sourceMappingURL=list_indexes_cursor.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cursor/list_indexes_cursor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cursor/list_search_indexes_cursor.js":
/*!***********************************************************************!*\
  !*** ./node_modules/mongodb/lib/cursor/list_search_indexes_cursor.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ListSearchIndexesCursor = void 0;\nconst aggregation_cursor_1 = __webpack_require__(/*! ./aggregation_cursor */ \"./node_modules/mongodb/lib/cursor/aggregation_cursor.js\");\n/** @public */\nclass ListSearchIndexesCursor extends aggregation_cursor_1.AggregationCursor {\n    /** @internal */\n    constructor({ fullNamespace: ns, client }, name, options = {}) {\n        const pipeline = name == null ? [{ $listSearchIndexes: {} }] : [{ $listSearchIndexes: { name } }];\n        super(client, ns, pipeline, options);\n    }\n}\nexports.ListSearchIndexesCursor = ListSearchIndexesCursor;\n//# sourceMappingURL=list_search_indexes_cursor.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cursor/list_search_indexes_cursor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cursor/run_command_cursor.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongodb/lib/cursor/run_command_cursor.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RunCommandCursor = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst execute_operation_1 = __webpack_require__(/*! ../operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst get_more_1 = __webpack_require__(/*! ../operations/get_more */ \"./node_modules/mongodb/lib/operations/get_more.js\");\nconst run_command_1 = __webpack_require__(/*! ../operations/run_command */ \"./node_modules/mongodb/lib/operations/run_command.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst abstract_cursor_1 = __webpack_require__(/*! ./abstract_cursor */ \"./node_modules/mongodb/lib/cursor/abstract_cursor.js\");\n/** @public */\nclass RunCommandCursor extends abstract_cursor_1.AbstractCursor {\n    /**\n     * Controls the `getMore.comment` field\n     * @param comment - any BSON value\n     */\n    setComment(comment) {\n        this.getMoreOptions.comment = comment;\n        return this;\n    }\n    /**\n     * Controls the `getMore.maxTimeMS` field. Only valid when cursor is tailable await\n     * @param maxTimeMS - the number of milliseconds to wait for new data\n     */\n    setMaxTimeMS(maxTimeMS) {\n        this.getMoreOptions.maxAwaitTimeMS = maxTimeMS;\n        return this;\n    }\n    /**\n     * Controls the `getMore.batchSize` field\n     * @param maxTimeMS - the number documents to return in the `nextBatch`\n     */\n    setBatchSize(batchSize) {\n        this.getMoreOptions.batchSize = batchSize;\n        return this;\n    }\n    /** Unsupported for RunCommandCursor */\n    clone() {\n        throw new error_1.MongoAPIError('Clone not supported, create a new cursor with db.runCursorCommand');\n    }\n    /** Unsupported for RunCommandCursor: readConcern must be configured directly on command document */\n    withReadConcern(_) {\n        throw new error_1.MongoAPIError('RunCommandCursor does not support readConcern it must be attached to the command being run');\n    }\n    /** Unsupported for RunCommandCursor: various cursor flags must be configured directly on command document */\n    addCursorFlag(_, __) {\n        throw new error_1.MongoAPIError('RunCommandCursor does not support cursor flags, they must be attached to the command being run');\n    }\n    /** Unsupported for RunCommandCursor: maxTimeMS must be configured directly on command document */\n    maxTimeMS(_) {\n        throw new error_1.MongoAPIError('maxTimeMS must be configured on the command document directly, to configure getMore.maxTimeMS use cursor.setMaxTimeMS()');\n    }\n    /** Unsupported for RunCommandCursor: batchSize must be configured directly on command document */\n    batchSize(_) {\n        throw new error_1.MongoAPIError('batchSize must be configured on the command document directly, to configure getMore.batchSize use cursor.setBatchSize()');\n    }\n    /** @internal */\n    constructor(db, command, options = {}) {\n        super(db.client, (0, utils_1.ns)(db.namespace), options);\n        this.getMoreOptions = {};\n        this.db = db;\n        this.command = Object.freeze({ ...command });\n    }\n    /** @internal */\n    async _initialize(session) {\n        const operation = new run_command_1.RunCommandOperation(this.db, this.command, {\n            ...this.cursorOptions,\n            session: session,\n            readPreference: this.cursorOptions.readPreference\n        });\n        const response = await (0, execute_operation_1.executeOperation)(this.client, operation);\n        if (response.cursor == null) {\n            throw new error_1.MongoUnexpectedServerResponseError('Expected server to respond with cursor');\n        }\n        return {\n            server: operation.server,\n            session,\n            response\n        };\n    }\n    /** @internal */\n    async getMore(_batchSize) {\n        // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n        const getMoreOperation = new get_more_1.GetMoreOperation(this.namespace, this.id, this.server, {\n            ...this.cursorOptions,\n            session: this.session,\n            ...this.getMoreOptions\n        });\n        return (0, execute_operation_1.executeOperation)(this.client, getMoreOperation);\n    }\n}\nexports.RunCommandCursor = RunCommandCursor;\n//# sourceMappingURL=run_command_cursor.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/cursor/run_command_cursor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/db.js":
/*!****************************************!*\
  !*** ./node_modules/mongodb/lib/db.js ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Db = void 0;\nconst admin_1 = __webpack_require__(/*! ./admin */ \"./node_modules/mongodb/lib/admin.js\");\nconst bson_1 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst change_stream_1 = __webpack_require__(/*! ./change_stream */ \"./node_modules/mongodb/lib/change_stream.js\");\nconst collection_1 = __webpack_require__(/*! ./collection */ \"./node_modules/mongodb/lib/collection.js\");\nconst CONSTANTS = __webpack_require__(/*! ./constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst aggregation_cursor_1 = __webpack_require__(/*! ./cursor/aggregation_cursor */ \"./node_modules/mongodb/lib/cursor/aggregation_cursor.js\");\nconst list_collections_cursor_1 = __webpack_require__(/*! ./cursor/list_collections_cursor */ \"./node_modules/mongodb/lib/cursor/list_collections_cursor.js\");\nconst run_command_cursor_1 = __webpack_require__(/*! ./cursor/run_command_cursor */ \"./node_modules/mongodb/lib/cursor/run_command_cursor.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst collections_1 = __webpack_require__(/*! ./operations/collections */ \"./node_modules/mongodb/lib/operations/collections.js\");\nconst create_collection_1 = __webpack_require__(/*! ./operations/create_collection */ \"./node_modules/mongodb/lib/operations/create_collection.js\");\nconst drop_1 = __webpack_require__(/*! ./operations/drop */ \"./node_modules/mongodb/lib/operations/drop.js\");\nconst execute_operation_1 = __webpack_require__(/*! ./operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst indexes_1 = __webpack_require__(/*! ./operations/indexes */ \"./node_modules/mongodb/lib/operations/indexes.js\");\nconst profiling_level_1 = __webpack_require__(/*! ./operations/profiling_level */ \"./node_modules/mongodb/lib/operations/profiling_level.js\");\nconst remove_user_1 = __webpack_require__(/*! ./operations/remove_user */ \"./node_modules/mongodb/lib/operations/remove_user.js\");\nconst rename_1 = __webpack_require__(/*! ./operations/rename */ \"./node_modules/mongodb/lib/operations/rename.js\");\nconst run_command_1 = __webpack_require__(/*! ./operations/run_command */ \"./node_modules/mongodb/lib/operations/run_command.js\");\nconst set_profiling_level_1 = __webpack_require__(/*! ./operations/set_profiling_level */ \"./node_modules/mongodb/lib/operations/set_profiling_level.js\");\nconst stats_1 = __webpack_require__(/*! ./operations/stats */ \"./node_modules/mongodb/lib/operations/stats.js\");\nconst read_concern_1 = __webpack_require__(/*! ./read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst read_preference_1 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst write_concern_1 = __webpack_require__(/*! ./write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\n// Allowed parameters\nconst DB_OPTIONS_ALLOW_LIST = [\n    'writeConcern',\n    'readPreference',\n    'readPreferenceTags',\n    'native_parser',\n    'forceServerObjectId',\n    'pkFactory',\n    'serializeFunctions',\n    'raw',\n    'authSource',\n    'ignoreUndefined',\n    'readConcern',\n    'retryMiliSeconds',\n    'numberOfRetries',\n    'useBigInt64',\n    'promoteBuffers',\n    'promoteLongs',\n    'bsonRegExp',\n    'enableUtf8Validation',\n    'promoteValues',\n    'compression',\n    'retryWrites'\n];\n/**\n * The **Db** class is a class that represents a MongoDB Database.\n * @public\n *\n * @example\n * ```ts\n * import { MongoClient } from 'mongodb';\n *\n * interface Pet {\n *   name: string;\n *   kind: 'dog' | 'cat' | 'fish';\n * }\n *\n * const client = new MongoClient('mongodb://localhost:27017');\n * const db = client.db();\n *\n * // Create a collection that validates our union\n * await db.createCollection<Pet>('pets', {\n *   validator: { $expr: { $in: ['$kind', ['dog', 'cat', 'fish']] } }\n * })\n * ```\n */\nclass Db {\n    /**\n     * Creates a new Db instance.\n     *\n     * Db name cannot contain a dot, the server may apply more restrictions when an operation is run.\n     *\n     * @param client - The MongoClient for the database.\n     * @param databaseName - The name of the database this instance represents.\n     * @param options - Optional settings for Db construction.\n     */\n    constructor(client, databaseName, options) {\n        options = options ?? {};\n        // Filter the options\n        options = (0, utils_1.filterOptions)(options, DB_OPTIONS_ALLOW_LIST);\n        // Ensure there are no dots in database name\n        if (typeof databaseName === 'string' && databaseName.includes('.')) {\n            throw new error_1.MongoInvalidArgumentError(`Database names cannot contain the character '.'`);\n        }\n        // Internal state of the db object\n        this.s = {\n            // Options\n            options,\n            // Unpack read preference\n            readPreference: read_preference_1.ReadPreference.fromOptions(options),\n            // Merge bson options\n            bsonOptions: (0, bson_1.resolveBSONOptions)(options, client),\n            // Set up the primary key factory or fallback to ObjectId\n            pkFactory: options?.pkFactory ?? utils_1.DEFAULT_PK_FACTORY,\n            // ReadConcern\n            readConcern: read_concern_1.ReadConcern.fromOptions(options),\n            writeConcern: write_concern_1.WriteConcern.fromOptions(options),\n            // Namespace\n            namespace: new utils_1.MongoDBNamespace(databaseName)\n        };\n        this.client = client;\n    }\n    get databaseName() {\n        return this.s.namespace.db;\n    }\n    // Options\n    get options() {\n        return this.s.options;\n    }\n    /**\n     * Check if a secondary can be used (because the read preference is *not* set to primary)\n     */\n    get secondaryOk() {\n        return this.s.readPreference?.preference !== 'primary' || false;\n    }\n    get readConcern() {\n        return this.s.readConcern;\n    }\n    /**\n     * The current readPreference of the Db. If not explicitly defined for\n     * this Db, will be inherited from the parent MongoClient\n     */\n    get readPreference() {\n        if (this.s.readPreference == null) {\n            return this.client.readPreference;\n        }\n        return this.s.readPreference;\n    }\n    get bsonOptions() {\n        return this.s.bsonOptions;\n    }\n    // get the write Concern\n    get writeConcern() {\n        return this.s.writeConcern;\n    }\n    get namespace() {\n        return this.s.namespace.toString();\n    }\n    /**\n     * Create a new collection on a server with the specified options. Use this to create capped collections.\n     * More information about command options available at https://www.mongodb.com/docs/manual/reference/command/create/\n     *\n     * Collection namespace validation is performed server-side.\n     *\n     * @param name - The name of the collection to create\n     * @param options - Optional settings for the command\n     */\n    async createCollection(name, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new create_collection_1.CreateCollectionOperation(this, name, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Execute a command\n     *\n     * @remarks\n     * This command does not inherit options from the MongoClient.\n     *\n     * The driver will ensure the following fields are attached to the command sent to the server:\n     * - `lsid` - sourced from an implicit session or options.session\n     * - `$readPreference` - defaults to primary or can be configured by options.readPreference\n     * - `$db` - sourced from the name of this database\n     *\n     * If the client has a serverApi setting:\n     * - `apiVersion`\n     * - `apiStrict`\n     * - `apiDeprecationErrors`\n     *\n     * When in a transaction:\n     * - `readConcern` - sourced from readConcern set on the TransactionOptions\n     * - `writeConcern` - sourced from writeConcern set on the TransactionOptions\n     *\n     * Attaching any of the above fields to the command will have no effect as the driver will overwrite the value.\n     *\n     * @param command - The command to run\n     * @param options - Optional settings for the command\n     */\n    async command(command, options) {\n        // Intentionally, we do not inherit options from parent for this operation.\n        return (0, execute_operation_1.executeOperation)(this.client, new run_command_1.RunCommandOperation(this, command, {\n            ...(0, bson_1.resolveBSONOptions)(options),\n            session: options?.session,\n            readPreference: options?.readPreference\n        }));\n    }\n    /**\n     * Execute an aggregation framework pipeline against the database, needs MongoDB \\>= 3.6\n     *\n     * @param pipeline - An array of aggregation stages to be executed\n     * @param options - Optional settings for the command\n     */\n    aggregate(pipeline = [], options) {\n        return new aggregation_cursor_1.AggregationCursor(this.client, this.s.namespace, pipeline, (0, utils_1.resolveOptions)(this, options));\n    }\n    /** Return the Admin db instance */\n    admin() {\n        return new admin_1.Admin(this);\n    }\n    /**\n     * Returns a reference to a MongoDB Collection. If it does not exist it will be created implicitly.\n     *\n     * Collection namespace validation is performed server-side.\n     *\n     * @param name - the collection name we wish to access.\n     * @returns return the new Collection instance\n     */\n    collection(name, options = {}) {\n        if (typeof options === 'function') {\n            throw new error_1.MongoInvalidArgumentError('The callback form of this helper has been removed.');\n        }\n        return new collection_1.Collection(this, name, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * Get all the db statistics.\n     *\n     * @param options - Optional settings for the command\n     */\n    async stats(options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new stats_1.DbStatsOperation(this, (0, utils_1.resolveOptions)(this, options)));\n    }\n    listCollections(filter = {}, options = {}) {\n        return new list_collections_cursor_1.ListCollectionsCursor(this, filter, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * Rename a collection.\n     *\n     * @remarks\n     * This operation does not inherit options from the MongoClient.\n     *\n     * @param fromCollection - Name of current collection to rename\n     * @param toCollection - New name of of the collection\n     * @param options - Optional settings for the command\n     */\n    async renameCollection(fromCollection, toCollection, options) {\n        // Intentionally, we do not inherit options from parent for this operation.\n        return (0, execute_operation_1.executeOperation)(this.client, new rename_1.RenameOperation(this.collection(fromCollection), toCollection, { ...options, new_collection: true, readPreference: read_preference_1.ReadPreference.primary }));\n    }\n    /**\n     * Drop a collection from the database, removing it permanently. New accesses will create a new collection.\n     *\n     * @param name - Name of collection to drop\n     * @param options - Optional settings for the command\n     */\n    async dropCollection(name, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new drop_1.DropCollectionOperation(this, name, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Drop a database, removing it permanently from the server.\n     *\n     * @param options - Optional settings for the command\n     */\n    async dropDatabase(options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new drop_1.DropDatabaseOperation(this, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Fetch all collections for the current db.\n     *\n     * @param options - Optional settings for the command\n     */\n    async collections(options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new collections_1.CollectionsOperation(this, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Creates an index on the db and collection.\n     *\n     * @param name - Name of the collection to create the index on.\n     * @param indexSpec - Specify the field to index, or an index specification\n     * @param options - Optional settings for the command\n     */\n    async createIndex(name, indexSpec, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new indexes_1.CreateIndexOperation(this, name, indexSpec, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Remove a user from a database\n     *\n     * @param username - The username to remove\n     * @param options - Optional settings for the command\n     */\n    async removeUser(username, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new remove_user_1.RemoveUserOperation(this, username, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Set the current profiling level of MongoDB\n     *\n     * @param level - The new profiling level (off, slow_only, all).\n     * @param options - Optional settings for the command\n     */\n    async setProfilingLevel(level, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new set_profiling_level_1.SetProfilingLevelOperation(this, level, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Retrieve the current profiling Level for MongoDB\n     *\n     * @param options - Optional settings for the command\n     */\n    async profilingLevel(options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new profiling_level_1.ProfilingLevelOperation(this, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Retrieves this collections index info.\n     *\n     * @param name - The name of the collection.\n     * @param options - Optional settings for the command\n     */\n    async indexInformation(name, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new indexes_1.IndexInformationOperation(this, name, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Create a new Change Stream, watching for new changes (insertions, updates,\n     * replacements, deletions, and invalidations) in this database. Will ignore all\n     * changes to system collections.\n     *\n     * @remarks\n     * watch() accepts two generic arguments for distinct use cases:\n     * - The first is to provide the schema that may be defined for all the collections within this database\n     * - The second is to override the shape of the change stream document entirely, if it is not provided the type will default to ChangeStreamDocument of the first argument\n     *\n     * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents. This allows for filtering (using $match) and manipulating the change stream documents.\n     * @param options - Optional settings for the command\n     * @typeParam TSchema - Type of the data being detected by the change stream\n     * @typeParam TChange - Type of the whole change stream document emitted\n     */\n    watch(pipeline = [], options = {}) {\n        // Allow optionally not specifying a pipeline\n        if (!Array.isArray(pipeline)) {\n            options = pipeline;\n            pipeline = [];\n        }\n        return new change_stream_1.ChangeStream(this, pipeline, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * A low level cursor API providing basic driver functionality:\n     * - ClientSession management\n     * - ReadPreference for server selection\n     * - Running getMores automatically when a local batch is exhausted\n     *\n     * @param command - The command that will start a cursor on the server.\n     * @param options - Configurations for running the command, bson options will apply to getMores\n     */\n    runCursorCommand(command, options) {\n        return new run_command_cursor_1.RunCommandCursor(this, command, options);\n    }\n}\nDb.SYSTEM_NAMESPACE_COLLECTION = CONSTANTS.SYSTEM_NAMESPACE_COLLECTION;\nDb.SYSTEM_INDEX_COLLECTION = CONSTANTS.SYSTEM_INDEX_COLLECTION;\nDb.SYSTEM_PROFILE_COLLECTION = CONSTANTS.SYSTEM_PROFILE_COLLECTION;\nDb.SYSTEM_USER_COLLECTION = CONSTANTS.SYSTEM_USER_COLLECTION;\nDb.SYSTEM_COMMAND_COLLECTION = CONSTANTS.SYSTEM_COMMAND_COLLECTION;\nDb.SYSTEM_JS_COLLECTION = CONSTANTS.SYSTEM_JS_COLLECTION;\nexports.Db = Db;\n//# sourceMappingURL=db.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/db.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/deps.js":
/*!******************************************!*\
  !*** ./node_modules/mongodb/lib/deps.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.getMongoDBClientEncryption = exports.aws4 = exports.getSocks = exports.getSnappy = exports.getGcpMetadata = exports.getAwsCredentialProvider = exports.getZstdLibrary = exports.ZStandard = exports.getKerberos = exports.Kerberos = void 0;\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nfunction makeErrorModule(error) {\n    const props = error ? { kModuleError: error } : {};\n    return new Proxy(props, {\n        get: (_, key) => {\n            if (key === 'kModuleError') {\n                return error;\n            }\n            throw error;\n        },\n        set: () => {\n            throw error;\n        }\n    });\n}\nexports.Kerberos = makeErrorModule(new error_1.MongoMissingDependencyError('Optional module `kerberos` not found. Please install it to enable kerberos authentication'));\nfunction getKerberos() {\n    try {\n        // Ensure you always wrap an optional require in the try block NODE-3199\n        exports.Kerberos = Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'kerberos'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }());\n        return exports.Kerberos;\n    }\n    catch {\n        return exports.Kerberos;\n    }\n}\nexports.getKerberos = getKerberos;\nexports.ZStandard = makeErrorModule(new error_1.MongoMissingDependencyError('Optional module `@mongodb-js/zstd` not found. Please install it to enable zstd compression'));\nfunction getZstdLibrary() {\n    try {\n        exports.ZStandard = Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@mongodb-js/zstd'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }());\n        return exports.ZStandard;\n    }\n    catch {\n        return exports.ZStandard;\n    }\n}\nexports.getZstdLibrary = getZstdLibrary;\nfunction getAwsCredentialProvider() {\n    try {\n        // Ensure you always wrap an optional require in the try block NODE-3199\n        const credentialProvider = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@aws-sdk/credential-providers'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n        return credentialProvider;\n    }\n    catch {\n        return makeErrorModule(new error_1.MongoMissingDependencyError('Optional module `@aws-sdk/credential-providers` not found.' +\n            ' Please install it to enable getting aws credentials via the official sdk.'));\n    }\n}\nexports.getAwsCredentialProvider = getAwsCredentialProvider;\nfunction getGcpMetadata() {\n    try {\n        // Ensure you always wrap an optional require in the try block NODE-3199\n        const credentialProvider = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'gcp-metadata'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n        return credentialProvider;\n    }\n    catch {\n        return makeErrorModule(new error_1.MongoMissingDependencyError('Optional module `gcp-metadata` not found.' +\n            ' Please install it to enable getting gcp credentials via the official sdk.'));\n    }\n}\nexports.getGcpMetadata = getGcpMetadata;\nfunction getSnappy() {\n    try {\n        // Ensure you always wrap an optional require in the try block NODE-3199\n        const value = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'snappy'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n        return value;\n    }\n    catch (cause) {\n        const kModuleError = new error_1.MongoMissingDependencyError('Optional module `snappy` not found. Please install it to enable snappy compression', { cause });\n        return { kModuleError };\n    }\n}\nexports.getSnappy = getSnappy;\nfunction getSocks() {\n    try {\n        // Ensure you always wrap an optional require in the try block NODE-3199\n        const value = __webpack_require__(/*! socks */ \"./node_modules/socks/build/index.js\");\n        return value;\n    }\n    catch (cause) {\n        const kModuleError = new error_1.MongoMissingDependencyError('Optional module `socks` not found. Please install it to connections over a SOCKS5 proxy', { cause });\n        return { kModuleError };\n    }\n}\nexports.getSocks = getSocks;\nexports.aws4 = makeErrorModule(new error_1.MongoMissingDependencyError('Optional module `aws4` not found. Please install it to enable AWS authentication'));\ntry {\n    // Ensure you always wrap an optional require in the try block NODE-3199\n    exports.aws4 = Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'aws4'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }());\n}\ncatch { } // eslint-disable-line\n/** A utility function to get the instance of mongodb-client-encryption, if it exists. */\nfunction getMongoDBClientEncryption() {\n    let mongodbClientEncryption = null;\n    try {\n        // NOTE(NODE-3199): Ensure you always wrap an optional require literally in the try block\n        // Cannot be moved to helper utility function, bundlers search and replace the actual require call\n        // in a way that makes this line throw at bundle time, not runtime, catching here will make bundling succeed\n        mongodbClientEncryption = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'mongodb-client-encryption'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n    }\n    catch (cause) {\n        const kModuleError = new error_1.MongoMissingDependencyError('Optional module `mongodb-client-encryption` not found. Please install it to use auto encryption or ClientEncryption.', { cause });\n        return { kModuleError };\n    }\n    return mongodbClientEncryption;\n}\nexports.getMongoDBClientEncryption = getMongoDBClientEncryption;\n//# sourceMappingURL=deps.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/deps.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/encrypter.js":
/*!***********************************************!*\
  !*** ./node_modules/mongodb/lib/encrypter.js ***!
  \***********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Encrypter = void 0;\nconst util_1 = __webpack_require__(/*! util */ \"util\");\nconst auto_encrypter_1 = __webpack_require__(/*! ./client-side-encryption/auto_encrypter */ \"./node_modules/mongodb/lib/client-side-encryption/auto_encrypter.js\");\nconst constants_1 = __webpack_require__(/*! ./constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst deps_1 = __webpack_require__(/*! ./deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_client_1 = __webpack_require__(/*! ./mongo_client */ \"./node_modules/mongodb/lib/mongo_client.js\");\n/** @internal */\nconst kInternalClient = Symbol('internalClient');\n/** @internal */\nclass Encrypter {\n    constructor(client, uri, options) {\n        if (typeof options.autoEncryption !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('Option \"autoEncryption\" must be specified');\n        }\n        // initialize to null, if we call getInternalClient, we may set this it is important to not overwrite those function calls.\n        this[kInternalClient] = null;\n        this.bypassAutoEncryption = !!options.autoEncryption.bypassAutoEncryption;\n        this.needsConnecting = false;\n        if (options.maxPoolSize === 0 && options.autoEncryption.keyVaultClient == null) {\n            options.autoEncryption.keyVaultClient = client;\n        }\n        else if (options.autoEncryption.keyVaultClient == null) {\n            options.autoEncryption.keyVaultClient = this.getInternalClient(client, uri, options);\n        }\n        if (this.bypassAutoEncryption) {\n            options.autoEncryption.metadataClient = undefined;\n        }\n        else if (options.maxPoolSize === 0) {\n            options.autoEncryption.metadataClient = client;\n        }\n        else {\n            options.autoEncryption.metadataClient = this.getInternalClient(client, uri, options);\n        }\n        if (options.proxyHost) {\n            options.autoEncryption.proxyOptions = {\n                proxyHost: options.proxyHost,\n                proxyPort: options.proxyPort,\n                proxyUsername: options.proxyUsername,\n                proxyPassword: options.proxyPassword\n            };\n        }\n        this.autoEncrypter = new auto_encrypter_1.AutoEncrypter(client, options.autoEncryption);\n    }\n    getInternalClient(client, uri, options) {\n        // TODO(NODE-4144): Remove new variable for type narrowing\n        let internalClient = this[kInternalClient];\n        if (internalClient == null) {\n            const clonedOptions = {};\n            for (const key of [\n                ...Object.getOwnPropertyNames(options),\n                ...Object.getOwnPropertySymbols(options)\n            ]) {\n                if (['autoEncryption', 'minPoolSize', 'servers', 'caseTranslate', 'dbName'].includes(key))\n                    continue;\n                Reflect.set(clonedOptions, key, Reflect.get(options, key));\n            }\n            clonedOptions.minPoolSize = 0;\n            internalClient = new mongo_client_1.MongoClient(uri, clonedOptions);\n            this[kInternalClient] = internalClient;\n            for (const eventName of constants_1.MONGO_CLIENT_EVENTS) {\n                for (const listener of client.listeners(eventName)) {\n                    internalClient.on(eventName, listener);\n                }\n            }\n            client.on('newListener', (eventName, listener) => {\n                internalClient?.on(eventName, listener);\n            });\n            this.needsConnecting = true;\n        }\n        return internalClient;\n    }\n    async connectInternalClient() {\n        // TODO(NODE-4144): Remove new variable for type narrowing\n        const internalClient = this[kInternalClient];\n        if (this.needsConnecting && internalClient != null) {\n            this.needsConnecting = false;\n            await internalClient.connect();\n        }\n    }\n    closeCallback(client, force, callback) {\n        (0, util_1.callbackify)(this.close.bind(this))(client, force, callback);\n    }\n    async close(client, force) {\n        const maybeError = await this.autoEncrypter.teardown(!!force).catch(e => e);\n        const internalClient = this[kInternalClient];\n        if (internalClient != null && client !== internalClient) {\n            return internalClient.close(force);\n        }\n        if (maybeError) {\n            throw maybeError;\n        }\n    }\n    static checkForMongoCrypt() {\n        const mongodbClientEncryption = (0, deps_1.getMongoDBClientEncryption)();\n        if ('kModuleError' in mongodbClientEncryption) {\n            throw new error_1.MongoMissingDependencyError('Auto-encryption requested, but the module is not installed. ' +\n                'Please add `mongodb-client-encryption` as a dependency of your project');\n        }\n    }\n}\nexports.Encrypter = Encrypter;\n//# sourceMappingURL=encrypter.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/encrypter.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/error.js":
/*!*******************************************!*\
  !*** ./node_modules/mongodb/lib/error.js ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.isResumableError = exports.isNetworkTimeoutError = exports.isSDAMUnrecoverableError = exports.isNodeShuttingDownError = exports.isRetryableReadError = exports.isRetryableWriteError = exports.needsRetryableWriteLabel = exports.MongoWriteConcernError = exports.MongoServerSelectionError = exports.MongoSystemError = exports.MongoMissingDependencyError = exports.MongoMissingCredentialsError = exports.MongoCompatibilityError = exports.MongoInvalidArgumentError = exports.MongoParseError = exports.MongoNetworkTimeoutError = exports.MongoNetworkError = exports.isNetworkErrorBeforeHandshake = exports.MongoTopologyClosedError = exports.MongoCursorExhaustedError = exports.MongoServerClosedError = exports.MongoCursorInUseError = exports.MongoUnexpectedServerResponseError = exports.MongoGridFSChunkError = exports.MongoGridFSStreamError = exports.MongoTailableCursorError = exports.MongoChangeStreamError = exports.MongoAzureError = exports.MongoAWSError = exports.MongoKerberosError = exports.MongoExpiredSessionError = exports.MongoTransactionError = exports.MongoNotConnectedError = exports.MongoDecompressionError = exports.MongoBatchReExecutionError = exports.MongoRuntimeError = exports.MongoAPIError = exports.MongoDriverError = exports.MongoServerError = exports.MongoError = exports.MongoErrorLabel = exports.GET_MORE_RESUMABLE_CODES = exports.MONGODB_ERROR_CODES = exports.NODE_IS_RECOVERING_ERROR_MESSAGE = exports.LEGACY_NOT_PRIMARY_OR_SECONDARY_ERROR_MESSAGE = exports.LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE = void 0;\n/** @internal */\nconst kErrorLabels = Symbol('errorLabels');\n/**\n * @internal\n * The legacy error message from the server that indicates the node is not a writable primary\n * https://github.com/mongodb/specifications/blob/b07c26dc40d04ac20349f989db531c9845fdd755/source/server-discovery-and-monitoring/server-discovery-and-monitoring.rst#not-writable-primary-and-node-is-recovering\n */\nexports.LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE = new RegExp('not master', 'i');\n/**\n * @internal\n * The legacy error message from the server that indicates the node is not a primary or secondary\n * https://github.com/mongodb/specifications/blob/b07c26dc40d04ac20349f989db531c9845fdd755/source/server-discovery-and-monitoring/server-discovery-and-monitoring.rst#not-writable-primary-and-node-is-recovering\n */\nexports.LEGACY_NOT_PRIMARY_OR_SECONDARY_ERROR_MESSAGE = new RegExp('not master or secondary', 'i');\n/**\n * @internal\n * The error message from the server that indicates the node is recovering\n * https://github.com/mongodb/specifications/blob/b07c26dc40d04ac20349f989db531c9845fdd755/source/server-discovery-and-monitoring/server-discovery-and-monitoring.rst#not-writable-primary-and-node-is-recovering\n */\nexports.NODE_IS_RECOVERING_ERROR_MESSAGE = new RegExp('node is recovering', 'i');\n/** @internal MongoDB Error Codes */\nexports.MONGODB_ERROR_CODES = Object.freeze({\n    HostUnreachable: 6,\n    HostNotFound: 7,\n    NetworkTimeout: 89,\n    ShutdownInProgress: 91,\n    PrimarySteppedDown: 189,\n    ExceededTimeLimit: 262,\n    SocketException: 9001,\n    NotWritablePrimary: 10107,\n    InterruptedAtShutdown: 11600,\n    InterruptedDueToReplStateChange: 11602,\n    NotPrimaryNoSecondaryOk: 13435,\n    NotPrimaryOrSecondary: 13436,\n    StaleShardVersion: 63,\n    StaleEpoch: 150,\n    StaleConfig: 13388,\n    RetryChangeStream: 234,\n    FailedToSatisfyReadPreference: 133,\n    CursorNotFound: 43,\n    LegacyNotPrimary: 10058,\n    WriteConcernFailed: 64,\n    NamespaceNotFound: 26,\n    IllegalOperation: 20,\n    MaxTimeMSExpired: 50,\n    UnknownReplWriteConcern: 79,\n    UnsatisfiableWriteConcern: 100,\n    Reauthenticate: 391\n});\n// From spec@https://github.com/mongodb/specifications/blob/f93d78191f3db2898a59013a7ed5650352ef6da8/source/change-streams/change-streams.rst#resumable-error\nexports.GET_MORE_RESUMABLE_CODES = new Set([\n    exports.MONGODB_ERROR_CODES.HostUnreachable,\n    exports.MONGODB_ERROR_CODES.HostNotFound,\n    exports.MONGODB_ERROR_CODES.NetworkTimeout,\n    exports.MONGODB_ERROR_CODES.ShutdownInProgress,\n    exports.MONGODB_ERROR_CODES.PrimarySteppedDown,\n    exports.MONGODB_ERROR_CODES.ExceededTimeLimit,\n    exports.MONGODB_ERROR_CODES.SocketException,\n    exports.MONGODB_ERROR_CODES.NotWritablePrimary,\n    exports.MONGODB_ERROR_CODES.InterruptedAtShutdown,\n    exports.MONGODB_ERROR_CODES.InterruptedDueToReplStateChange,\n    exports.MONGODB_ERROR_CODES.NotPrimaryNoSecondaryOk,\n    exports.MONGODB_ERROR_CODES.NotPrimaryOrSecondary,\n    exports.MONGODB_ERROR_CODES.StaleShardVersion,\n    exports.MONGODB_ERROR_CODES.StaleEpoch,\n    exports.MONGODB_ERROR_CODES.StaleConfig,\n    exports.MONGODB_ERROR_CODES.RetryChangeStream,\n    exports.MONGODB_ERROR_CODES.FailedToSatisfyReadPreference,\n    exports.MONGODB_ERROR_CODES.CursorNotFound\n]);\n/** @public */\nexports.MongoErrorLabel = Object.freeze({\n    RetryableWriteError: 'RetryableWriteError',\n    TransientTransactionError: 'TransientTransactionError',\n    UnknownTransactionCommitResult: 'UnknownTransactionCommitResult',\n    ResumableChangeStreamError: 'ResumableChangeStreamError',\n    HandshakeError: 'HandshakeError',\n    ResetPool: 'ResetPool',\n    PoolRequstedRetry: 'PoolRequstedRetry',\n    InterruptInUseConnections: 'InterruptInUseConnections',\n    NoWritesPerformed: 'NoWritesPerformed'\n});\nfunction isAggregateError(e) {\n    return 'errors' in e && Array.isArray(e.errors);\n}\n/**\n * @public\n * @category Error\n *\n * @privateRemarks\n * mongodb-client-encryption has a dependency on this error, it uses the constructor with a string argument\n */\nclass MongoError extends Error {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options) {\n        super(message, options);\n        this[kErrorLabels] = new Set();\n    }\n    /** @internal */\n    static buildErrorMessage(e) {\n        if (typeof e === 'string') {\n            return e;\n        }\n        if (isAggregateError(e) && e.message.length === 0) {\n            return e.errors.length === 0\n                ? 'AggregateError has an empty errors array. Please check the `cause` property for more information.'\n                : e.errors.map(({ message }) => message).join(', ');\n        }\n        return e.message;\n    }\n    get name() {\n        return 'MongoError';\n    }\n    /** Legacy name for server error responses */\n    get errmsg() {\n        return this.message;\n    }\n    /**\n     * Checks the error to see if it has an error label\n     *\n     * @param label - The error label to check for\n     * @returns returns true if the error has the provided error label\n     */\n    hasErrorLabel(label) {\n        return this[kErrorLabels].has(label);\n    }\n    addErrorLabel(label) {\n        this[kErrorLabels].add(label);\n    }\n    get errorLabels() {\n        return Array.from(this[kErrorLabels]);\n    }\n}\nexports.MongoError = MongoError;\n/**\n * An error coming from the mongo server\n *\n * @public\n * @category Error\n */\nclass MongoServerError extends MongoError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message.message || message.errmsg || message.$err || 'n/a');\n        if (message.errorLabels) {\n            this[kErrorLabels] = new Set(message.errorLabels);\n        }\n        for (const name in message) {\n            if (name !== 'errorLabels' && name !== 'errmsg' && name !== 'message')\n                this[name] = message[name];\n        }\n    }\n    get name() {\n        return 'MongoServerError';\n    }\n}\nexports.MongoServerError = MongoServerError;\n/**\n * An error generated by the driver\n *\n * @public\n * @category Error\n */\nclass MongoDriverError extends MongoError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options) {\n        super(message, options);\n    }\n    get name() {\n        return 'MongoDriverError';\n    }\n}\nexports.MongoDriverError = MongoDriverError;\n/**\n * An error generated when the driver API is used incorrectly\n *\n * @privateRemarks\n * Should **never** be directly instantiated\n *\n * @public\n * @category Error\n */\nclass MongoAPIError extends MongoDriverError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options) {\n        super(message, options);\n    }\n    get name() {\n        return 'MongoAPIError';\n    }\n}\nexports.MongoAPIError = MongoAPIError;\n/**\n * An error generated when the driver encounters unexpected input\n * or reaches an unexpected/invalid internal state\n *\n * @privateRemarks\n * Should **never** be directly instantiated.\n *\n * @public\n * @category Error\n */\nclass MongoRuntimeError extends MongoDriverError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options) {\n        super(message, options);\n    }\n    get name() {\n        return 'MongoRuntimeError';\n    }\n}\nexports.MongoRuntimeError = MongoRuntimeError;\n/**\n * An error generated when a batch command is re-executed after one of the commands in the batch\n * has failed\n *\n * @public\n * @category Error\n */\nclass MongoBatchReExecutionError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message = 'This batch has already been executed, create new batch to execute') {\n        super(message);\n    }\n    get name() {\n        return 'MongoBatchReExecutionError';\n    }\n}\nexports.MongoBatchReExecutionError = MongoBatchReExecutionError;\n/**\n * An error generated when the driver fails to decompress\n * data received from the server.\n *\n * @public\n * @category Error\n */\nclass MongoDecompressionError extends MongoRuntimeError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoDecompressionError';\n    }\n}\nexports.MongoDecompressionError = MongoDecompressionError;\n/**\n * An error thrown when the user attempts to operate on a database or collection through a MongoClient\n * that has not yet successfully called the \"connect\" method\n *\n * @public\n * @category Error\n */\nclass MongoNotConnectedError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoNotConnectedError';\n    }\n}\nexports.MongoNotConnectedError = MongoNotConnectedError;\n/**\n * An error generated when the user makes a mistake in the usage of transactions.\n * (e.g. attempting to commit a transaction with a readPreference other than primary)\n *\n * @public\n * @category Error\n */\nclass MongoTransactionError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoTransactionError';\n    }\n}\nexports.MongoTransactionError = MongoTransactionError;\n/**\n * An error generated when the user attempts to operate\n * on a session that has expired or has been closed.\n *\n * @public\n * @category Error\n */\nclass MongoExpiredSessionError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message = 'Cannot use a session that has ended') {\n        super(message);\n    }\n    get name() {\n        return 'MongoExpiredSessionError';\n    }\n}\nexports.MongoExpiredSessionError = MongoExpiredSessionError;\n/**\n * A error generated when the user attempts to authenticate\n * via Kerberos, but fails to connect to the Kerberos client.\n *\n * @public\n * @category Error\n */\nclass MongoKerberosError extends MongoRuntimeError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoKerberosError';\n    }\n}\nexports.MongoKerberosError = MongoKerberosError;\n/**\n * A error generated when the user attempts to authenticate\n * via AWS, but fails\n *\n * @public\n * @category Error\n */\nclass MongoAWSError extends MongoRuntimeError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoAWSError';\n    }\n}\nexports.MongoAWSError = MongoAWSError;\n/**\n * A error generated when the user attempts to authenticate\n * via Azure, but fails.\n *\n * @public\n * @category Error\n */\nclass MongoAzureError extends MongoRuntimeError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoAzureError';\n    }\n}\nexports.MongoAzureError = MongoAzureError;\n/**\n * An error generated when a ChangeStream operation fails to execute.\n *\n * @public\n * @category Error\n */\nclass MongoChangeStreamError extends MongoRuntimeError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoChangeStreamError';\n    }\n}\nexports.MongoChangeStreamError = MongoChangeStreamError;\n/**\n * An error thrown when the user calls a function or method not supported on a tailable cursor\n *\n * @public\n * @category Error\n */\nclass MongoTailableCursorError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message = 'Tailable cursor does not support this operation') {\n        super(message);\n    }\n    get name() {\n        return 'MongoTailableCursorError';\n    }\n}\nexports.MongoTailableCursorError = MongoTailableCursorError;\n/** An error generated when a GridFSStream operation fails to execute.\n *\n * @public\n * @category Error\n */\nclass MongoGridFSStreamError extends MongoRuntimeError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoGridFSStreamError';\n    }\n}\nexports.MongoGridFSStreamError = MongoGridFSStreamError;\n/**\n * An error generated when a malformed or invalid chunk is\n * encountered when reading from a GridFSStream.\n *\n * @public\n * @category Error\n */\nclass MongoGridFSChunkError extends MongoRuntimeError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoGridFSChunkError';\n    }\n}\nexports.MongoGridFSChunkError = MongoGridFSChunkError;\n/**\n * An error generated when a **parsable** unexpected response comes from the server.\n * This is generally an error where the driver in a state expecting a certain behavior to occur in\n * the next message from MongoDB but it receives something else.\n * This error **does not** represent an issue with wire message formatting.\n *\n * #### Example\n * When an operation fails, it is the driver's job to retry it. It must perform serverSelection\n * again to make sure that it attempts the operation against a server in a good state. If server\n * selection returns a server that does not support retryable operations, this error is used.\n * This scenario is unlikely as retryable support would also have been determined on the first attempt\n * but it is possible the state change could report a selectable server that does not support retries.\n *\n * @public\n * @category Error\n */\nclass MongoUnexpectedServerResponseError extends MongoRuntimeError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoUnexpectedServerResponseError';\n    }\n}\nexports.MongoUnexpectedServerResponseError = MongoUnexpectedServerResponseError;\n/**\n * An error thrown when the user attempts to add options to a cursor that has already been\n * initialized\n *\n * @public\n * @category Error\n */\nclass MongoCursorInUseError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message = 'Cursor is already initialized') {\n        super(message);\n    }\n    get name() {\n        return 'MongoCursorInUseError';\n    }\n}\nexports.MongoCursorInUseError = MongoCursorInUseError;\n/**\n * An error generated when an attempt is made to operate\n * on a closed/closing server.\n *\n * @public\n * @category Error\n */\nclass MongoServerClosedError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message = 'Server is closed') {\n        super(message);\n    }\n    get name() {\n        return 'MongoServerClosedError';\n    }\n}\nexports.MongoServerClosedError = MongoServerClosedError;\n/**\n * An error thrown when an attempt is made to read from a cursor that has been exhausted\n *\n * @public\n * @category Error\n */\nclass MongoCursorExhaustedError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message || 'Cursor is exhausted');\n    }\n    get name() {\n        return 'MongoCursorExhaustedError';\n    }\n}\nexports.MongoCursorExhaustedError = MongoCursorExhaustedError;\n/**\n * An error generated when an attempt is made to operate on a\n * dropped, or otherwise unavailable, database.\n *\n * @public\n * @category Error\n */\nclass MongoTopologyClosedError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message = 'Topology is closed') {\n        super(message);\n    }\n    get name() {\n        return 'MongoTopologyClosedError';\n    }\n}\nexports.MongoTopologyClosedError = MongoTopologyClosedError;\n/** @internal */\nconst kBeforeHandshake = Symbol('beforeHandshake');\nfunction isNetworkErrorBeforeHandshake(err) {\n    return err[kBeforeHandshake] === true;\n}\nexports.isNetworkErrorBeforeHandshake = isNetworkErrorBeforeHandshake;\n/**\n * An error indicating an issue with the network, including TCP errors and timeouts.\n * @public\n * @category Error\n */\nclass MongoNetworkError extends MongoError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options) {\n        super(message, { cause: options?.cause });\n        if (options && typeof options.beforeHandshake === 'boolean') {\n            this[kBeforeHandshake] = options.beforeHandshake;\n        }\n    }\n    get name() {\n        return 'MongoNetworkError';\n    }\n}\nexports.MongoNetworkError = MongoNetworkError;\n/**\n * An error indicating a network timeout occurred\n * @public\n * @category Error\n *\n * @privateRemarks\n * mongodb-client-encryption has a dependency on this error with an instanceof check\n */\nclass MongoNetworkTimeoutError extends MongoNetworkError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options) {\n        super(message, options);\n    }\n    get name() {\n        return 'MongoNetworkTimeoutError';\n    }\n}\nexports.MongoNetworkTimeoutError = MongoNetworkTimeoutError;\n/**\n * An error used when attempting to parse a value (like a connection string)\n * @public\n * @category Error\n */\nclass MongoParseError extends MongoDriverError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoParseError';\n    }\n}\nexports.MongoParseError = MongoParseError;\n/**\n * An error generated when the user supplies malformed or unexpected arguments\n * or when a required argument or field is not provided.\n *\n *\n * @public\n * @category Error\n */\nclass MongoInvalidArgumentError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoInvalidArgumentError';\n    }\n}\nexports.MongoInvalidArgumentError = MongoInvalidArgumentError;\n/**\n * An error generated when a feature that is not enabled or allowed for the current server\n * configuration is used\n *\n *\n * @public\n * @category Error\n */\nclass MongoCompatibilityError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoCompatibilityError';\n    }\n}\nexports.MongoCompatibilityError = MongoCompatibilityError;\n/**\n * An error generated when the user fails to provide authentication credentials before attempting\n * to connect to a mongo server instance.\n *\n *\n * @public\n * @category Error\n */\nclass MongoMissingCredentialsError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoMissingCredentialsError';\n    }\n}\nexports.MongoMissingCredentialsError = MongoMissingCredentialsError;\n/**\n * An error generated when a required module or dependency is not present in the local environment\n *\n * @public\n * @category Error\n */\nclass MongoMissingDependencyError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options = {}) {\n        super(message, options);\n    }\n    get name() {\n        return 'MongoMissingDependencyError';\n    }\n}\nexports.MongoMissingDependencyError = MongoMissingDependencyError;\n/**\n * An error signifying a general system issue\n * @public\n * @category Error\n */\nclass MongoSystemError extends MongoError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, reason) {\n        if (reason && reason.error) {\n            super(MongoError.buildErrorMessage(reason.error.message || reason.error), {\n                cause: reason.error\n            });\n        }\n        else {\n            super(message);\n        }\n        if (reason) {\n            this.reason = reason;\n        }\n        this.code = reason.error?.code;\n    }\n    get name() {\n        return 'MongoSystemError';\n    }\n}\nexports.MongoSystemError = MongoSystemError;\n/**\n * An error signifying a client-side server selection error\n * @public\n * @category Error\n */\nclass MongoServerSelectionError extends MongoSystemError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, reason) {\n        super(message, reason);\n    }\n    get name() {\n        return 'MongoServerSelectionError';\n    }\n}\nexports.MongoServerSelectionError = MongoServerSelectionError;\nfunction makeWriteConcernResultObject(input) {\n    const output = Object.assign({}, input);\n    if (output.ok === 0) {\n        output.ok = 1;\n        delete output.errmsg;\n        delete output.code;\n        delete output.codeName;\n    }\n    return output;\n}\n/**\n * An error thrown when the server reports a writeConcernError\n * @public\n * @category Error\n */\nclass MongoWriteConcernError extends MongoServerError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, result) {\n        if (result && Array.isArray(result.errorLabels)) {\n            message.errorLabels = result.errorLabels;\n        }\n        super(message);\n        this.errInfo = message.errInfo;\n        if (result != null) {\n            this.result = makeWriteConcernResultObject(result);\n        }\n    }\n    get name() {\n        return 'MongoWriteConcernError';\n    }\n}\nexports.MongoWriteConcernError = MongoWriteConcernError;\n// https://github.com/mongodb/specifications/blob/master/source/retryable-reads/retryable-reads.rst#retryable-error\nconst RETRYABLE_READ_ERROR_CODES = new Set([\n    exports.MONGODB_ERROR_CODES.HostUnreachable,\n    exports.MONGODB_ERROR_CODES.HostNotFound,\n    exports.MONGODB_ERROR_CODES.NetworkTimeout,\n    exports.MONGODB_ERROR_CODES.ShutdownInProgress,\n    exports.MONGODB_ERROR_CODES.PrimarySteppedDown,\n    exports.MONGODB_ERROR_CODES.SocketException,\n    exports.MONGODB_ERROR_CODES.NotWritablePrimary,\n    exports.MONGODB_ERROR_CODES.InterruptedAtShutdown,\n    exports.MONGODB_ERROR_CODES.InterruptedDueToReplStateChange,\n    exports.MONGODB_ERROR_CODES.NotPrimaryNoSecondaryOk,\n    exports.MONGODB_ERROR_CODES.NotPrimaryOrSecondary\n]);\n// see: https://github.com/mongodb/specifications/blob/master/source/retryable-writes/retryable-writes.rst#terms\nconst RETRYABLE_WRITE_ERROR_CODES = new Set([\n    ...RETRYABLE_READ_ERROR_CODES,\n    exports.MONGODB_ERROR_CODES.ExceededTimeLimit\n]);\nfunction needsRetryableWriteLabel(error, maxWireVersion) {\n    // pre-4.4 server, then the driver adds an error label for every valid case\n    // execute operation will only inspect the label, code/message logic is handled here\n    if (error instanceof MongoNetworkError) {\n        return true;\n    }\n    if (error instanceof MongoError) {\n        if ((maxWireVersion >= 9 || isRetryableWriteError(error)) &&\n            !error.hasErrorLabel(exports.MongoErrorLabel.HandshakeError)) {\n            // If we already have the error label no need to add it again. 4.4+ servers add the label.\n            // In the case where we have a handshake error, need to fall down to the logic checking\n            // the codes.\n            return false;\n        }\n    }\n    if (error instanceof MongoWriteConcernError) {\n        return RETRYABLE_WRITE_ERROR_CODES.has(error.result?.code ?? error.code ?? 0);\n    }\n    if (error instanceof MongoError && typeof error.code === 'number') {\n        return RETRYABLE_WRITE_ERROR_CODES.has(error.code);\n    }\n    const isNotWritablePrimaryError = exports.LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE.test(error.message);\n    if (isNotWritablePrimaryError) {\n        return true;\n    }\n    const isNodeIsRecoveringError = exports.NODE_IS_RECOVERING_ERROR_MESSAGE.test(error.message);\n    if (isNodeIsRecoveringError) {\n        return true;\n    }\n    return false;\n}\nexports.needsRetryableWriteLabel = needsRetryableWriteLabel;\nfunction isRetryableWriteError(error) {\n    return (error.hasErrorLabel(exports.MongoErrorLabel.RetryableWriteError) ||\n        error.hasErrorLabel(exports.MongoErrorLabel.PoolRequstedRetry));\n}\nexports.isRetryableWriteError = isRetryableWriteError;\n/** Determines whether an error is something the driver should attempt to retry */\nfunction isRetryableReadError(error) {\n    const hasRetryableErrorCode = typeof error.code === 'number' ? RETRYABLE_READ_ERROR_CODES.has(error.code) : false;\n    if (hasRetryableErrorCode) {\n        return true;\n    }\n    if (error instanceof MongoNetworkError) {\n        return true;\n    }\n    const isNotWritablePrimaryError = exports.LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE.test(error.message);\n    if (isNotWritablePrimaryError) {\n        return true;\n    }\n    const isNodeIsRecoveringError = exports.NODE_IS_RECOVERING_ERROR_MESSAGE.test(error.message);\n    if (isNodeIsRecoveringError) {\n        return true;\n    }\n    return false;\n}\nexports.isRetryableReadError = isRetryableReadError;\nconst SDAM_RECOVERING_CODES = new Set([\n    exports.MONGODB_ERROR_CODES.ShutdownInProgress,\n    exports.MONGODB_ERROR_CODES.PrimarySteppedDown,\n    exports.MONGODB_ERROR_CODES.InterruptedAtShutdown,\n    exports.MONGODB_ERROR_CODES.InterruptedDueToReplStateChange,\n    exports.MONGODB_ERROR_CODES.NotPrimaryOrSecondary\n]);\nconst SDAM_NOT_PRIMARY_CODES = new Set([\n    exports.MONGODB_ERROR_CODES.NotWritablePrimary,\n    exports.MONGODB_ERROR_CODES.NotPrimaryNoSecondaryOk,\n    exports.MONGODB_ERROR_CODES.LegacyNotPrimary\n]);\nconst SDAM_NODE_SHUTTING_DOWN_ERROR_CODES = new Set([\n    exports.MONGODB_ERROR_CODES.InterruptedAtShutdown,\n    exports.MONGODB_ERROR_CODES.ShutdownInProgress\n]);\nfunction isRecoveringError(err) {\n    if (typeof err.code === 'number') {\n        // If any error code exists, we ignore the error.message\n        return SDAM_RECOVERING_CODES.has(err.code);\n    }\n    return (exports.LEGACY_NOT_PRIMARY_OR_SECONDARY_ERROR_MESSAGE.test(err.message) ||\n        exports.NODE_IS_RECOVERING_ERROR_MESSAGE.test(err.message));\n}\nfunction isNotWritablePrimaryError(err) {\n    if (typeof err.code === 'number') {\n        // If any error code exists, we ignore the error.message\n        return SDAM_NOT_PRIMARY_CODES.has(err.code);\n    }\n    if (isRecoveringError(err)) {\n        return false;\n    }\n    return exports.LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE.test(err.message);\n}\nfunction isNodeShuttingDownError(err) {\n    return !!(typeof err.code === 'number' && SDAM_NODE_SHUTTING_DOWN_ERROR_CODES.has(err.code));\n}\nexports.isNodeShuttingDownError = isNodeShuttingDownError;\n/**\n * Determines whether SDAM can recover from a given error. If it cannot\n * then the pool will be cleared, and server state will completely reset\n * locally.\n *\n * @see https://github.com/mongodb/specifications/blob/master/source/server-discovery-and-monitoring/server-discovery-and-monitoring.rst#not-master-and-node-is-recovering\n */\nfunction isSDAMUnrecoverableError(error) {\n    // NOTE: null check is here for a strictly pre-CMAP world, a timeout or\n    //       close event are considered unrecoverable\n    if (error instanceof MongoParseError || error == null) {\n        return true;\n    }\n    return isRecoveringError(error) || isNotWritablePrimaryError(error);\n}\nexports.isSDAMUnrecoverableError = isSDAMUnrecoverableError;\nfunction isNetworkTimeoutError(err) {\n    return !!(err instanceof MongoNetworkError && err.message.match(/timed out/));\n}\nexports.isNetworkTimeoutError = isNetworkTimeoutError;\nfunction isResumableError(error, wireVersion) {\n    if (error == null || !(error instanceof MongoError)) {\n        return false;\n    }\n    if (error instanceof MongoNetworkError) {\n        return true;\n    }\n    if (wireVersion != null && wireVersion >= 9) {\n        // DRIVERS-1308: For 4.4 drivers running against 4.4 servers, drivers will add a special case to treat the CursorNotFound error code as resumable\n        if (error.code === exports.MONGODB_ERROR_CODES.CursorNotFound) {\n            return true;\n        }\n        return error.hasErrorLabel(exports.MongoErrorLabel.ResumableChangeStreamError);\n    }\n    if (typeof error.code === 'number') {\n        return exports.GET_MORE_RESUMABLE_CODES.has(error.code);\n    }\n    return false;\n}\nexports.isResumableError = isResumableError;\n//# sourceMappingURL=error.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/error.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/explain.js":
/*!*********************************************!*\
  !*** ./node_modules/mongodb/lib/explain.js ***!
  \*********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Explain = exports.ExplainVerbosity = void 0;\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\n/** @public */\nexports.ExplainVerbosity = Object.freeze({\n    queryPlanner: 'queryPlanner',\n    queryPlannerExtended: 'queryPlannerExtended',\n    executionStats: 'executionStats',\n    allPlansExecution: 'allPlansExecution'\n});\n/** @internal */\nclass Explain {\n    constructor(verbosity) {\n        if (typeof verbosity === 'boolean') {\n            this.verbosity = verbosity\n                ? exports.ExplainVerbosity.allPlansExecution\n                : exports.ExplainVerbosity.queryPlanner;\n        }\n        else {\n            this.verbosity = verbosity;\n        }\n    }\n    static fromOptions(options) {\n        if (options?.explain == null)\n            return;\n        const explain = options.explain;\n        if (typeof explain === 'boolean' || typeof explain === 'string') {\n            return new Explain(explain);\n        }\n        throw new error_1.MongoInvalidArgumentError('Field \"explain\" must be a string or a boolean');\n    }\n}\nexports.Explain = Explain;\n//# sourceMappingURL=explain.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/explain.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/gridfs/download.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongodb/lib/gridfs/download.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.GridFSBucketReadStream = void 0;\nconst stream_1 = __webpack_require__(/*! stream */ \"stream\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\n/**\n * A readable stream that enables you to read buffers from GridFS.\n *\n * Do not instantiate this class directly. Use `openDownloadStream()` instead.\n * @public\n */\nclass GridFSBucketReadStream extends stream_1.Readable {\n    /**\n     * @param chunks - Handle for chunks collection\n     * @param files - Handle for files collection\n     * @param readPreference - The read preference to use\n     * @param filter - The filter to use to find the file document\n     * @internal\n     */\n    constructor(chunks, files, readPreference, filter, options) {\n        super({ emitClose: true });\n        this.s = {\n            bytesToTrim: 0,\n            bytesToSkip: 0,\n            bytesRead: 0,\n            chunks,\n            expected: 0,\n            files,\n            filter,\n            init: false,\n            expectedEnd: 0,\n            options: {\n                start: 0,\n                end: 0,\n                ...options\n            },\n            readPreference\n        };\n    }\n    /**\n     * Reads from the cursor and pushes to the stream.\n     * Private Impl, do not call directly\n     * @internal\n     */\n    _read() {\n        if (this.destroyed)\n            return;\n        waitForFile(this, () => doRead(this));\n    }\n    /**\n     * Sets the 0-based offset in bytes to start streaming from. Throws\n     * an error if this stream has entered flowing mode\n     * (e.g. if you've already called `on('data')`)\n     *\n     * @param start - 0-based offset in bytes to start streaming from\n     */\n    start(start = 0) {\n        throwIfInitialized(this);\n        this.s.options.start = start;\n        return this;\n    }\n    /**\n     * Sets the 0-based offset in bytes to start streaming from. Throws\n     * an error if this stream has entered flowing mode\n     * (e.g. if you've already called `on('data')`)\n     *\n     * @param end - Offset in bytes to stop reading at\n     */\n    end(end = 0) {\n        throwIfInitialized(this);\n        this.s.options.end = end;\n        return this;\n    }\n    /**\n     * Marks this stream as aborted (will never push another `data` event)\n     * and kills the underlying cursor. Will emit the 'end' event, and then\n     * the 'close' event once the cursor is successfully killed.\n     */\n    async abort() {\n        this.push(null);\n        this.destroy();\n        await this.s.cursor?.close();\n    }\n}\n/**\n * Fires when the stream loaded the file document corresponding to the provided id.\n * @event\n */\nGridFSBucketReadStream.FILE = 'file';\nexports.GridFSBucketReadStream = GridFSBucketReadStream;\nfunction throwIfInitialized(stream) {\n    if (stream.s.init) {\n        throw new error_1.MongoGridFSStreamError('Options cannot be changed after the stream is initialized');\n    }\n}\nfunction doRead(stream) {\n    if (stream.destroyed)\n        return;\n    if (!stream.s.cursor)\n        return;\n    if (!stream.s.file)\n        return;\n    const handleReadResult = ({ error, doc }) => {\n        if (stream.destroyed) {\n            return;\n        }\n        if (error) {\n            stream.destroy(error);\n            return;\n        }\n        if (!doc) {\n            stream.push(null);\n            stream.s.cursor?.close().then(() => null, error => stream.destroy(error));\n            return;\n        }\n        if (!stream.s.file)\n            return;\n        const bytesRemaining = stream.s.file.length - stream.s.bytesRead;\n        const expectedN = stream.s.expected++;\n        const expectedLength = Math.min(stream.s.file.chunkSize, bytesRemaining);\n        if (doc.n > expectedN) {\n            return stream.destroy(new error_1.MongoGridFSChunkError(`ChunkIsMissing: Got unexpected n: ${doc.n}, expected: ${expectedN}`));\n        }\n        if (doc.n < expectedN) {\n            return stream.destroy(new error_1.MongoGridFSChunkError(`ExtraChunk: Got unexpected n: ${doc.n}, expected: ${expectedN}`));\n        }\n        let buf = Buffer.isBuffer(doc.data) ? doc.data : doc.data.buffer;\n        if (buf.byteLength !== expectedLength) {\n            if (bytesRemaining <= 0) {\n                return stream.destroy(new error_1.MongoGridFSChunkError(`ExtraChunk: Got unexpected n: ${doc.n}, expected file length ${stream.s.file.length} bytes but already read ${stream.s.bytesRead} bytes`));\n            }\n            return stream.destroy(new error_1.MongoGridFSChunkError(`ChunkIsWrongSize: Got unexpected length: ${buf.byteLength}, expected: ${expectedLength}`));\n        }\n        stream.s.bytesRead += buf.byteLength;\n        if (buf.byteLength === 0) {\n            return stream.push(null);\n        }\n        let sliceStart = null;\n        let sliceEnd = null;\n        if (stream.s.bytesToSkip != null) {\n            sliceStart = stream.s.bytesToSkip;\n            stream.s.bytesToSkip = 0;\n        }\n        const atEndOfStream = expectedN === stream.s.expectedEnd - 1;\n        const bytesLeftToRead = stream.s.options.end - stream.s.bytesToSkip;\n        if (atEndOfStream && stream.s.bytesToTrim != null) {\n            sliceEnd = stream.s.file.chunkSize - stream.s.bytesToTrim;\n        }\n        else if (stream.s.options.end && bytesLeftToRead < doc.data.byteLength) {\n            sliceEnd = bytesLeftToRead;\n        }\n        if (sliceStart != null || sliceEnd != null) {\n            buf = buf.slice(sliceStart || 0, sliceEnd || buf.byteLength);\n        }\n        stream.push(buf);\n        return;\n    };\n    stream.s.cursor.next().then(doc => handleReadResult({ error: null, doc }), error => handleReadResult({ error, doc: null }));\n}\nfunction init(stream) {\n    const findOneOptions = {};\n    if (stream.s.readPreference) {\n        findOneOptions.readPreference = stream.s.readPreference;\n    }\n    if (stream.s.options && stream.s.options.sort) {\n        findOneOptions.sort = stream.s.options.sort;\n    }\n    if (stream.s.options && stream.s.options.skip) {\n        findOneOptions.skip = stream.s.options.skip;\n    }\n    const handleReadResult = ({ error, doc }) => {\n        if (error) {\n            return stream.destroy(error);\n        }\n        if (!doc) {\n            const identifier = stream.s.filter._id\n                ? stream.s.filter._id.toString()\n                : stream.s.filter.filename;\n            const errmsg = `FileNotFound: file ${identifier} was not found`;\n            // TODO(NODE-3483)\n            const err = new error_1.MongoRuntimeError(errmsg);\n            err.code = 'ENOENT'; // TODO: NODE-3338 set property as part of constructor\n            return stream.destroy(err);\n        }\n        // If document is empty, kill the stream immediately and don't\n        // execute any reads\n        if (doc.length <= 0) {\n            stream.push(null);\n            return;\n        }\n        if (stream.destroyed) {\n            // If user destroys the stream before we have a cursor, wait\n            // until the query is done to say we're 'closed' because we can't\n            // cancel a query.\n            stream.destroy();\n            return;\n        }\n        try {\n            stream.s.bytesToSkip = handleStartOption(stream, doc, stream.s.options);\n        }\n        catch (error) {\n            return stream.destroy(error);\n        }\n        const filter = { files_id: doc._id };\n        // Currently (MongoDB 3.4.4) skip function does not support the index,\n        // it needs to retrieve all the documents first and then skip them. (CS-25811)\n        // As work around we use $gte on the \"n\" field.\n        if (stream.s.options && stream.s.options.start != null) {\n            const skip = Math.floor(stream.s.options.start / doc.chunkSize);\n            if (skip > 0) {\n                filter['n'] = { $gte: skip };\n            }\n        }\n        stream.s.cursor = stream.s.chunks.find(filter).sort({ n: 1 });\n        if (stream.s.readPreference) {\n            stream.s.cursor.withReadPreference(stream.s.readPreference);\n        }\n        stream.s.expectedEnd = Math.ceil(doc.length / doc.chunkSize);\n        stream.s.file = doc;\n        try {\n            stream.s.bytesToTrim = handleEndOption(stream, doc, stream.s.cursor, stream.s.options);\n        }\n        catch (error) {\n            return stream.destroy(error);\n        }\n        stream.emit(GridFSBucketReadStream.FILE, doc);\n        return;\n    };\n    stream.s.files.findOne(stream.s.filter, findOneOptions).then(doc => handleReadResult({ error: null, doc }), error => handleReadResult({ error, doc: null }));\n}\nfunction waitForFile(stream, callback) {\n    if (stream.s.file) {\n        return callback();\n    }\n    if (!stream.s.init) {\n        init(stream);\n        stream.s.init = true;\n    }\n    stream.once('file', () => {\n        callback();\n    });\n}\nfunction handleStartOption(stream, doc, options) {\n    if (options && options.start != null) {\n        if (options.start > doc.length) {\n            throw new error_1.MongoInvalidArgumentError(`Stream start (${options.start}) must not be more than the length of the file (${doc.length})`);\n        }\n        if (options.start < 0) {\n            throw new error_1.MongoInvalidArgumentError(`Stream start (${options.start}) must not be negative`);\n        }\n        if (options.end != null && options.end < options.start) {\n            throw new error_1.MongoInvalidArgumentError(`Stream start (${options.start}) must not be greater than stream end (${options.end})`);\n        }\n        stream.s.bytesRead = Math.floor(options.start / doc.chunkSize) * doc.chunkSize;\n        stream.s.expected = Math.floor(options.start / doc.chunkSize);\n        return options.start - stream.s.bytesRead;\n    }\n    throw new error_1.MongoInvalidArgumentError('Start option must be defined');\n}\nfunction handleEndOption(stream, doc, cursor, options) {\n    if (options && options.end != null) {\n        if (options.end > doc.length) {\n            throw new error_1.MongoInvalidArgumentError(`Stream end (${options.end}) must not be more than the length of the file (${doc.length})`);\n        }\n        if (options.start == null || options.start < 0) {\n            throw new error_1.MongoInvalidArgumentError(`Stream end (${options.end}) must not be negative`);\n        }\n        const start = options.start != null ? Math.floor(options.start / doc.chunkSize) : 0;\n        cursor.limit(Math.ceil(options.end / doc.chunkSize) - start);\n        stream.s.expectedEnd = Math.ceil(options.end / doc.chunkSize);\n        return Math.ceil(options.end / doc.chunkSize) * doc.chunkSize - options.end;\n    }\n    throw new error_1.MongoInvalidArgumentError('End option must be defined');\n}\n//# sourceMappingURL=download.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/gridfs/download.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/gridfs/index.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/gridfs/index.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.GridFSBucket = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_types_1 = __webpack_require__(/*! ../mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst write_concern_1 = __webpack_require__(/*! ../write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\nconst download_1 = __webpack_require__(/*! ./download */ \"./node_modules/mongodb/lib/gridfs/download.js\");\nconst upload_1 = __webpack_require__(/*! ./upload */ \"./node_modules/mongodb/lib/gridfs/upload.js\");\nconst DEFAULT_GRIDFS_BUCKET_OPTIONS = {\n    bucketName: 'fs',\n    chunkSizeBytes: 255 * 1024\n};\n/**\n * Constructor for a streaming GridFS interface\n * @public\n */\nclass GridFSBucket extends mongo_types_1.TypedEventEmitter {\n    constructor(db, options) {\n        super();\n        this.setMaxListeners(0);\n        const privateOptions = {\n            ...DEFAULT_GRIDFS_BUCKET_OPTIONS,\n            ...options,\n            writeConcern: write_concern_1.WriteConcern.fromOptions(options)\n        };\n        this.s = {\n            db,\n            options: privateOptions,\n            _chunksCollection: db.collection(privateOptions.bucketName + '.chunks'),\n            _filesCollection: db.collection(privateOptions.bucketName + '.files'),\n            checkedIndexes: false,\n            calledOpenUploadStream: false\n        };\n    }\n    /**\n     * Returns a writable stream (GridFSBucketWriteStream) for writing\n     * buffers to GridFS. The stream's 'id' property contains the resulting\n     * file's id.\n     *\n     * @param filename - The value of the 'filename' key in the files doc\n     * @param options - Optional settings.\n     */\n    openUploadStream(filename, options) {\n        return new upload_1.GridFSBucketWriteStream(this, filename, options);\n    }\n    /**\n     * Returns a writable stream (GridFSBucketWriteStream) for writing\n     * buffers to GridFS for a custom file id. The stream's 'id' property contains the resulting\n     * file's id.\n     */\n    openUploadStreamWithId(id, filename, options) {\n        return new upload_1.GridFSBucketWriteStream(this, filename, { ...options, id });\n    }\n    /** Returns a readable stream (GridFSBucketReadStream) for streaming file data from GridFS. */\n    openDownloadStream(id, options) {\n        return new download_1.GridFSBucketReadStream(this.s._chunksCollection, this.s._filesCollection, this.s.options.readPreference, { _id: id }, options);\n    }\n    /**\n     * Deletes a file with the given id\n     *\n     * @param id - The id of the file doc\n     */\n    async delete(id) {\n        const { deletedCount } = await this.s._filesCollection.deleteOne({ _id: id });\n        // Delete orphaned chunks before returning FileNotFound\n        await this.s._chunksCollection.deleteMany({ files_id: id });\n        if (deletedCount === 0) {\n            // TODO(NODE-3483): Replace with more appropriate error\n            // Consider creating new error MongoGridFSFileNotFoundError\n            throw new error_1.MongoRuntimeError(`File not found for id ${id}`);\n        }\n    }\n    /** Convenience wrapper around find on the files collection */\n    find(filter = {}, options = {}) {\n        return this.s._filesCollection.find(filter, options);\n    }\n    /**\n     * Returns a readable stream (GridFSBucketReadStream) for streaming the\n     * file with the given name from GridFS. If there are multiple files with\n     * the same name, this will stream the most recent file with the given name\n     * (as determined by the `uploadDate` field). You can set the `revision`\n     * option to change this behavior.\n     */\n    openDownloadStreamByName(filename, options) {\n        let sort = { uploadDate: -1 };\n        let skip = undefined;\n        if (options && options.revision != null) {\n            if (options.revision >= 0) {\n                sort = { uploadDate: 1 };\n                skip = options.revision;\n            }\n            else {\n                skip = -options.revision - 1;\n            }\n        }\n        return new download_1.GridFSBucketReadStream(this.s._chunksCollection, this.s._filesCollection, this.s.options.readPreference, { filename }, { ...options, sort, skip });\n    }\n    /**\n     * Renames the file with the given _id to the given string\n     *\n     * @param id - the id of the file to rename\n     * @param filename - new name for the file\n     */\n    async rename(id, filename) {\n        const filter = { _id: id };\n        const update = { $set: { filename } };\n        const { matchedCount } = await this.s._filesCollection.updateOne(filter, update);\n        if (matchedCount === 0) {\n            throw new error_1.MongoRuntimeError(`File with id ${id} not found`);\n        }\n    }\n    /** Removes this bucket's files collection, followed by its chunks collection. */\n    async drop() {\n        await this.s._filesCollection.drop();\n        await this.s._chunksCollection.drop();\n    }\n}\n/**\n * When the first call to openUploadStream is made, the upload stream will\n * check to see if it needs to create the proper indexes on the chunks and\n * files collections. This event is fired either when 1) it determines that\n * no index creation is necessary, 2) when it successfully creates the\n * necessary indexes.\n * @event\n */\nGridFSBucket.INDEX = 'index';\nexports.GridFSBucket = GridFSBucket;\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/gridfs/index.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/gridfs/upload.js":
/*!***************************************************!*\
  !*** ./node_modules/mongodb/lib/gridfs/upload.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.GridFSBucketWriteStream = void 0;\nconst stream_1 = __webpack_require__(/*! stream */ \"stream\");\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst write_concern_1 = __webpack_require__(/*! ./../write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\n/**\n * A writable stream that enables you to write buffers to GridFS.\n *\n * Do not instantiate this class directly. Use `openUploadStream()` instead.\n * @public\n */\nclass GridFSBucketWriteStream extends stream_1.Writable {\n    /**\n     * @param bucket - Handle for this stream's corresponding bucket\n     * @param filename - The value of the 'filename' key in the files doc\n     * @param options - Optional settings.\n     * @internal\n     */\n    constructor(bucket, filename, options) {\n        super();\n        /**\n         * The document containing information about the inserted file.\n         * This property is defined _after_ the finish event has been emitted.\n         * It will remain `null` if an error occurs.\n         *\n         * @example\n         * ```ts\n         * fs.createReadStream('file.txt')\n         *   .pipe(bucket.openUploadStream('file.txt'))\n         *   .on('finish', function () {\n         *     console.log(this.gridFSFile)\n         *   })\n         * ```\n         */\n        this.gridFSFile = null;\n        options = options ?? {};\n        this.bucket = bucket;\n        this.chunks = bucket.s._chunksCollection;\n        this.filename = filename;\n        this.files = bucket.s._filesCollection;\n        this.options = options;\n        this.writeConcern = write_concern_1.WriteConcern.fromOptions(options) || bucket.s.options.writeConcern;\n        // Signals the write is all done\n        this.done = false;\n        this.id = options.id ? options.id : new bson_1.ObjectId();\n        // properly inherit the default chunksize from parent\n        this.chunkSizeBytes = options.chunkSizeBytes || this.bucket.s.options.chunkSizeBytes;\n        this.bufToStore = Buffer.alloc(this.chunkSizeBytes);\n        this.length = 0;\n        this.n = 0;\n        this.pos = 0;\n        this.state = {\n            streamEnd: false,\n            outstandingRequests: 0,\n            errored: false,\n            aborted: false\n        };\n        if (!this.bucket.s.calledOpenUploadStream) {\n            this.bucket.s.calledOpenUploadStream = true;\n            checkIndexes(this).then(() => {\n                this.bucket.s.checkedIndexes = true;\n                this.bucket.emit('index');\n            }, () => null);\n        }\n    }\n    /**\n     * @internal\n     *\n     * The stream is considered constructed when the indexes are done being created\n     */\n    _construct(callback) {\n        if (this.bucket.s.checkedIndexes) {\n            return process.nextTick(callback);\n        }\n        this.bucket.once('index', callback);\n    }\n    /**\n     * @internal\n     * Write a buffer to the stream.\n     *\n     * @param chunk - Buffer to write\n     * @param encoding - Optional encoding for the buffer\n     * @param callback - Function to call when the chunk was added to the buffer, or if the entire chunk was persisted to MongoDB if this chunk caused a flush.\n     */\n    _write(chunk, encoding, callback) {\n        doWrite(this, chunk, encoding, callback);\n    }\n    /** @internal */\n    _final(callback) {\n        if (this.state.streamEnd) {\n            return process.nextTick(callback);\n        }\n        this.state.streamEnd = true;\n        writeRemnant(this, callback);\n    }\n    /**\n     * Places this write stream into an aborted state (all future writes fail)\n     * and deletes all chunks that have already been written.\n     */\n    async abort() {\n        if (this.state.streamEnd) {\n            // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n            throw new error_1.MongoAPIError('Cannot abort a stream that has already completed');\n        }\n        if (this.state.aborted) {\n            // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n            throw new error_1.MongoAPIError('Cannot call abort() on a stream twice');\n        }\n        this.state.aborted = true;\n        await this.chunks.deleteMany({ files_id: this.id });\n    }\n}\nexports.GridFSBucketWriteStream = GridFSBucketWriteStream;\nfunction handleError(stream, error, callback) {\n    if (stream.state.errored) {\n        process.nextTick(callback);\n        return;\n    }\n    stream.state.errored = true;\n    process.nextTick(callback, error);\n}\nfunction createChunkDoc(filesId, n, data) {\n    return {\n        _id: new bson_1.ObjectId(),\n        files_id: filesId,\n        n,\n        data\n    };\n}\nasync function checkChunksIndex(stream) {\n    const index = { files_id: 1, n: 1 };\n    let indexes;\n    try {\n        indexes = await stream.chunks.listIndexes().toArray();\n    }\n    catch (error) {\n        if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n            indexes = [];\n        }\n        else {\n            throw error;\n        }\n    }\n    const hasChunksIndex = !!indexes.find(index => {\n        const keys = Object.keys(index.key);\n        if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {\n            return true;\n        }\n        return false;\n    });\n    if (!hasChunksIndex) {\n        await stream.chunks.createIndex(index, {\n            ...stream.writeConcern,\n            background: true,\n            unique: true\n        });\n    }\n}\nfunction checkDone(stream, callback) {\n    if (stream.done) {\n        return process.nextTick(callback);\n    }\n    if (stream.state.streamEnd && stream.state.outstandingRequests === 0 && !stream.state.errored) {\n        // Set done so we do not trigger duplicate createFilesDoc\n        stream.done = true;\n        // Create a new files doc\n        const gridFSFile = createFilesDoc(stream.id, stream.length, stream.chunkSizeBytes, stream.filename, stream.options.contentType, stream.options.aliases, stream.options.metadata);\n        if (isAborted(stream, callback)) {\n            return;\n        }\n        stream.files.insertOne(gridFSFile, { writeConcern: stream.writeConcern }).then(() => {\n            stream.gridFSFile = gridFSFile;\n            callback();\n        }, error => handleError(stream, error, callback));\n        return;\n    }\n    process.nextTick(callback);\n}\nasync function checkIndexes(stream) {\n    const doc = await stream.files.findOne({}, { projection: { _id: 1 } });\n    if (doc != null) {\n        // If at least one document exists assume the collection has the required index\n        return;\n    }\n    const index = { filename: 1, uploadDate: 1 };\n    let indexes;\n    try {\n        indexes = await stream.files.listIndexes().toArray();\n    }\n    catch (error) {\n        if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n            indexes = [];\n        }\n        else {\n            throw error;\n        }\n    }\n    const hasFileIndex = !!indexes.find(index => {\n        const keys = Object.keys(index.key);\n        if (keys.length === 2 && index.key.filename === 1 && index.key.uploadDate === 1) {\n            return true;\n        }\n        return false;\n    });\n    if (!hasFileIndex) {\n        await stream.files.createIndex(index, { background: false });\n    }\n    await checkChunksIndex(stream);\n}\nfunction createFilesDoc(_id, length, chunkSize, filename, contentType, aliases, metadata) {\n    const ret = {\n        _id,\n        length,\n        chunkSize,\n        uploadDate: new Date(),\n        filename\n    };\n    if (contentType) {\n        ret.contentType = contentType;\n    }\n    if (aliases) {\n        ret.aliases = aliases;\n    }\n    if (metadata) {\n        ret.metadata = metadata;\n    }\n    return ret;\n}\nfunction doWrite(stream, chunk, encoding, callback) {\n    if (isAborted(stream, callback)) {\n        return;\n    }\n    const inputBuf = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);\n    stream.length += inputBuf.length;\n    // Input is small enough to fit in our buffer\n    if (stream.pos + inputBuf.length < stream.chunkSizeBytes) {\n        inputBuf.copy(stream.bufToStore, stream.pos);\n        stream.pos += inputBuf.length;\n        process.nextTick(callback);\n        return;\n    }\n    // Otherwise, buffer is too big for current chunk, so we need to flush\n    // to MongoDB.\n    let inputBufRemaining = inputBuf.length;\n    let spaceRemaining = stream.chunkSizeBytes - stream.pos;\n    let numToCopy = Math.min(spaceRemaining, inputBuf.length);\n    let outstandingRequests = 0;\n    while (inputBufRemaining > 0) {\n        const inputBufPos = inputBuf.length - inputBufRemaining;\n        inputBuf.copy(stream.bufToStore, stream.pos, inputBufPos, inputBufPos + numToCopy);\n        stream.pos += numToCopy;\n        spaceRemaining -= numToCopy;\n        let doc;\n        if (spaceRemaining === 0) {\n            doc = createChunkDoc(stream.id, stream.n, Buffer.from(stream.bufToStore));\n            ++stream.state.outstandingRequests;\n            ++outstandingRequests;\n            if (isAborted(stream, callback)) {\n                return;\n            }\n            stream.chunks.insertOne(doc, { writeConcern: stream.writeConcern }).then(() => {\n                --stream.state.outstandingRequests;\n                --outstandingRequests;\n                if (!outstandingRequests) {\n                    checkDone(stream, callback);\n                }\n            }, error => handleError(stream, error, callback));\n            spaceRemaining = stream.chunkSizeBytes;\n            stream.pos = 0;\n            ++stream.n;\n        }\n        inputBufRemaining -= numToCopy;\n        numToCopy = Math.min(spaceRemaining, inputBufRemaining);\n    }\n}\nfunction writeRemnant(stream, callback) {\n    // Buffer is empty, so don't bother to insert\n    if (stream.pos === 0) {\n        return checkDone(stream, callback);\n    }\n    ++stream.state.outstandingRequests;\n    // Create a new buffer to make sure the buffer isn't bigger than it needs\n    // to be.\n    const remnant = Buffer.alloc(stream.pos);\n    stream.bufToStore.copy(remnant, 0, 0, stream.pos);\n    const doc = createChunkDoc(stream.id, stream.n, remnant);\n    // If the stream was aborted, do not write remnant\n    if (isAborted(stream, callback)) {\n        return;\n    }\n    stream.chunks.insertOne(doc, { writeConcern: stream.writeConcern }).then(() => {\n        --stream.state.outstandingRequests;\n        checkDone(stream, callback);\n    }, error => handleError(stream, error, callback));\n}\nfunction isAborted(stream, callback) {\n    if (stream.state.aborted) {\n        process.nextTick(callback, new error_1.MongoAPIError('Stream has been aborted'));\n        return true;\n    }\n    return false;\n}\n//# sourceMappingURL=upload.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/gridfs/upload.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/index.js":
/*!*******************************************!*\
  !*** ./node_modules/mongodb/lib/index.js ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoUnexpectedServerResponseError = exports.MongoTransactionError = exports.MongoTopologyClosedError = exports.MongoTailableCursorError = exports.MongoSystemError = exports.MongoServerSelectionError = exports.MongoServerError = exports.MongoServerClosedError = exports.MongoRuntimeError = exports.MongoParseError = exports.MongoNotConnectedError = exports.MongoNetworkTimeoutError = exports.MongoNetworkError = exports.MongoMissingDependencyError = exports.MongoMissingCredentialsError = exports.MongoKerberosError = exports.MongoInvalidArgumentError = exports.MongoGridFSStreamError = exports.MongoGridFSChunkError = exports.MongoExpiredSessionError = exports.MongoError = exports.MongoDriverError = exports.MongoDecompressionError = exports.MongoCursorInUseError = exports.MongoCursorExhaustedError = exports.MongoCompatibilityError = exports.MongoChangeStreamError = exports.MongoBatchReExecutionError = exports.MongoAzureError = exports.MongoAWSError = exports.MongoAPIError = exports.ChangeStreamCursor = exports.ClientEncryption = exports.MongoBulkWriteError = exports.UUID = exports.Timestamp = exports.ObjectId = exports.MinKey = exports.MaxKey = exports.Long = exports.Int32 = exports.Double = exports.Decimal128 = exports.DBRef = exports.Code = exports.BSONType = exports.BSONSymbol = exports.BSONRegExp = exports.Binary = exports.BSON = void 0;\nexports.ConnectionPoolReadyEvent = exports.ConnectionPoolMonitoringEvent = exports.ConnectionPoolCreatedEvent = exports.ConnectionPoolClosedEvent = exports.ConnectionPoolClearedEvent = exports.ConnectionCreatedEvent = exports.ConnectionClosedEvent = exports.ConnectionCheckOutStartedEvent = exports.ConnectionCheckOutFailedEvent = exports.ConnectionCheckedOutEvent = exports.ConnectionCheckedInEvent = exports.CommandSucceededEvent = exports.CommandStartedEvent = exports.CommandFailedEvent = exports.WriteConcern = exports.ReadPreference = exports.ReadConcern = exports.TopologyType = exports.ServerType = exports.ReadPreferenceMode = exports.ReadConcernLevel = exports.ProfilingLevel = exports.ReturnDocument = exports.ServerApiVersion = exports.ExplainVerbosity = exports.MongoErrorLabel = exports.CURSOR_FLAGS = exports.Compressor = exports.AuthMechanism = exports.GSSAPICanonicalizationValue = exports.AutoEncryptionLoggerLevel = exports.BatchType = exports.UnorderedBulkOperation = exports.OrderedBulkOperation = exports.MongoClient = exports.ListIndexesCursor = exports.ListCollectionsCursor = exports.GridFSBucketWriteStream = exports.GridFSBucketReadStream = exports.GridFSBucket = exports.FindCursor = exports.Db = exports.Collection = exports.ClientSession = exports.ChangeStream = exports.CancellationToken = exports.AggregationCursor = exports.Admin = exports.AbstractCursor = exports.MongoWriteConcernError = void 0;\nexports.MongoCryptKMSRequestNetworkTimeoutError = exports.MongoCryptInvalidArgumentError = exports.MongoCryptError = exports.MongoCryptCreateEncryptedCollectionError = exports.MongoCryptCreateDataKeyError = exports.MongoCryptAzureKMSRequestError = exports.SrvPollingEvent = exports.TopologyOpeningEvent = exports.TopologyDescriptionChangedEvent = exports.TopologyClosedEvent = exports.ServerOpeningEvent = exports.ServerHeartbeatSucceededEvent = exports.ServerHeartbeatStartedEvent = exports.ServerHeartbeatFailedEvent = exports.ServerDescriptionChangedEvent = exports.ServerClosedEvent = exports.ConnectionReadyEvent = void 0;\nconst admin_1 = __webpack_require__(/*! ./admin */ \"./node_modules/mongodb/lib/admin.js\");\nObject.defineProperty(exports, \"Admin\", ({ enumerable: true, get: function () { return admin_1.Admin; } }));\nconst ordered_1 = __webpack_require__(/*! ./bulk/ordered */ \"./node_modules/mongodb/lib/bulk/ordered.js\");\nObject.defineProperty(exports, \"OrderedBulkOperation\", ({ enumerable: true, get: function () { return ordered_1.OrderedBulkOperation; } }));\nconst unordered_1 = __webpack_require__(/*! ./bulk/unordered */ \"./node_modules/mongodb/lib/bulk/unordered.js\");\nObject.defineProperty(exports, \"UnorderedBulkOperation\", ({ enumerable: true, get: function () { return unordered_1.UnorderedBulkOperation; } }));\nconst change_stream_1 = __webpack_require__(/*! ./change_stream */ \"./node_modules/mongodb/lib/change_stream.js\");\nObject.defineProperty(exports, \"ChangeStream\", ({ enumerable: true, get: function () { return change_stream_1.ChangeStream; } }));\nconst collection_1 = __webpack_require__(/*! ./collection */ \"./node_modules/mongodb/lib/collection.js\");\nObject.defineProperty(exports, \"Collection\", ({ enumerable: true, get: function () { return collection_1.Collection; } }));\nconst abstract_cursor_1 = __webpack_require__(/*! ./cursor/abstract_cursor */ \"./node_modules/mongodb/lib/cursor/abstract_cursor.js\");\nObject.defineProperty(exports, \"AbstractCursor\", ({ enumerable: true, get: function () { return abstract_cursor_1.AbstractCursor; } }));\nconst aggregation_cursor_1 = __webpack_require__(/*! ./cursor/aggregation_cursor */ \"./node_modules/mongodb/lib/cursor/aggregation_cursor.js\");\nObject.defineProperty(exports, \"AggregationCursor\", ({ enumerable: true, get: function () { return aggregation_cursor_1.AggregationCursor; } }));\nconst find_cursor_1 = __webpack_require__(/*! ./cursor/find_cursor */ \"./node_modules/mongodb/lib/cursor/find_cursor.js\");\nObject.defineProperty(exports, \"FindCursor\", ({ enumerable: true, get: function () { return find_cursor_1.FindCursor; } }));\nconst list_collections_cursor_1 = __webpack_require__(/*! ./cursor/list_collections_cursor */ \"./node_modules/mongodb/lib/cursor/list_collections_cursor.js\");\nObject.defineProperty(exports, \"ListCollectionsCursor\", ({ enumerable: true, get: function () { return list_collections_cursor_1.ListCollectionsCursor; } }));\nconst list_indexes_cursor_1 = __webpack_require__(/*! ./cursor/list_indexes_cursor */ \"./node_modules/mongodb/lib/cursor/list_indexes_cursor.js\");\nObject.defineProperty(exports, \"ListIndexesCursor\", ({ enumerable: true, get: function () { return list_indexes_cursor_1.ListIndexesCursor; } }));\nconst db_1 = __webpack_require__(/*! ./db */ \"./node_modules/mongodb/lib/db.js\");\nObject.defineProperty(exports, \"Db\", ({ enumerable: true, get: function () { return db_1.Db; } }));\nconst gridfs_1 = __webpack_require__(/*! ./gridfs */ \"./node_modules/mongodb/lib/gridfs/index.js\");\nObject.defineProperty(exports, \"GridFSBucket\", ({ enumerable: true, get: function () { return gridfs_1.GridFSBucket; } }));\nconst download_1 = __webpack_require__(/*! ./gridfs/download */ \"./node_modules/mongodb/lib/gridfs/download.js\");\nObject.defineProperty(exports, \"GridFSBucketReadStream\", ({ enumerable: true, get: function () { return download_1.GridFSBucketReadStream; } }));\nconst upload_1 = __webpack_require__(/*! ./gridfs/upload */ \"./node_modules/mongodb/lib/gridfs/upload.js\");\nObject.defineProperty(exports, \"GridFSBucketWriteStream\", ({ enumerable: true, get: function () { return upload_1.GridFSBucketWriteStream; } }));\nconst mongo_client_1 = __webpack_require__(/*! ./mongo_client */ \"./node_modules/mongodb/lib/mongo_client.js\");\nObject.defineProperty(exports, \"MongoClient\", ({ enumerable: true, get: function () { return mongo_client_1.MongoClient; } }));\nconst mongo_types_1 = __webpack_require__(/*! ./mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nObject.defineProperty(exports, \"CancellationToken\", ({ enumerable: true, get: function () { return mongo_types_1.CancellationToken; } }));\nconst sessions_1 = __webpack_require__(/*! ./sessions */ \"./node_modules/mongodb/lib/sessions.js\");\nObject.defineProperty(exports, \"ClientSession\", ({ enumerable: true, get: function () { return sessions_1.ClientSession; } }));\n/** @public */\nvar bson_1 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nObject.defineProperty(exports, \"BSON\", ({ enumerable: true, get: function () { return bson_1.BSON; } }));\nvar bson_2 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nObject.defineProperty(exports, \"Binary\", ({ enumerable: true, get: function () { return bson_2.Binary; } }));\nObject.defineProperty(exports, \"BSONRegExp\", ({ enumerable: true, get: function () { return bson_2.BSONRegExp; } }));\nObject.defineProperty(exports, \"BSONSymbol\", ({ enumerable: true, get: function () { return bson_2.BSONSymbol; } }));\nObject.defineProperty(exports, \"BSONType\", ({ enumerable: true, get: function () { return bson_2.BSONType; } }));\nObject.defineProperty(exports, \"Code\", ({ enumerable: true, get: function () { return bson_2.Code; } }));\nObject.defineProperty(exports, \"DBRef\", ({ enumerable: true, get: function () { return bson_2.DBRef; } }));\nObject.defineProperty(exports, \"Decimal128\", ({ enumerable: true, get: function () { return bson_2.Decimal128; } }));\nObject.defineProperty(exports, \"Double\", ({ enumerable: true, get: function () { return bson_2.Double; } }));\nObject.defineProperty(exports, \"Int32\", ({ enumerable: true, get: function () { return bson_2.Int32; } }));\nObject.defineProperty(exports, \"Long\", ({ enumerable: true, get: function () { return bson_2.Long; } }));\nObject.defineProperty(exports, \"MaxKey\", ({ enumerable: true, get: function () { return bson_2.MaxKey; } }));\nObject.defineProperty(exports, \"MinKey\", ({ enumerable: true, get: function () { return bson_2.MinKey; } }));\nObject.defineProperty(exports, \"ObjectId\", ({ enumerable: true, get: function () { return bson_2.ObjectId; } }));\nObject.defineProperty(exports, \"Timestamp\", ({ enumerable: true, get: function () { return bson_2.Timestamp; } }));\nObject.defineProperty(exports, \"UUID\", ({ enumerable: true, get: function () { return bson_2.UUID; } }));\nvar common_1 = __webpack_require__(/*! ./bulk/common */ \"./node_modules/mongodb/lib/bulk/common.js\");\nObject.defineProperty(exports, \"MongoBulkWriteError\", ({ enumerable: true, get: function () { return common_1.MongoBulkWriteError; } }));\nvar client_encryption_1 = __webpack_require__(/*! ./client-side-encryption/client_encryption */ \"./node_modules/mongodb/lib/client-side-encryption/client_encryption.js\");\nObject.defineProperty(exports, \"ClientEncryption\", ({ enumerable: true, get: function () { return client_encryption_1.ClientEncryption; } }));\nvar change_stream_cursor_1 = __webpack_require__(/*! ./cursor/change_stream_cursor */ \"./node_modules/mongodb/lib/cursor/change_stream_cursor.js\");\nObject.defineProperty(exports, \"ChangeStreamCursor\", ({ enumerable: true, get: function () { return change_stream_cursor_1.ChangeStreamCursor; } }));\nvar error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nObject.defineProperty(exports, \"MongoAPIError\", ({ enumerable: true, get: function () { return error_1.MongoAPIError; } }));\nObject.defineProperty(exports, \"MongoAWSError\", ({ enumerable: true, get: function () { return error_1.MongoAWSError; } }));\nObject.defineProperty(exports, \"MongoAzureError\", ({ enumerable: true, get: function () { return error_1.MongoAzureError; } }));\nObject.defineProperty(exports, \"MongoBatchReExecutionError\", ({ enumerable: true, get: function () { return error_1.MongoBatchReExecutionError; } }));\nObject.defineProperty(exports, \"MongoChangeStreamError\", ({ enumerable: true, get: function () { return error_1.MongoChangeStreamError; } }));\nObject.defineProperty(exports, \"MongoCompatibilityError\", ({ enumerable: true, get: function () { return error_1.MongoCompatibilityError; } }));\nObject.defineProperty(exports, \"MongoCursorExhaustedError\", ({ enumerable: true, get: function () { return error_1.MongoCursorExhaustedError; } }));\nObject.defineProperty(exports, \"MongoCursorInUseError\", ({ enumerable: true, get: function () { return error_1.MongoCursorInUseError; } }));\nObject.defineProperty(exports, \"MongoDecompressionError\", ({ enumerable: true, get: function () { return error_1.MongoDecompressionError; } }));\nObject.defineProperty(exports, \"MongoDriverError\", ({ enumerable: true, get: function () { return error_1.MongoDriverError; } }));\nObject.defineProperty(exports, \"MongoError\", ({ enumerable: true, get: function () { return error_1.MongoError; } }));\nObject.defineProperty(exports, \"MongoExpiredSessionError\", ({ enumerable: true, get: function () { return error_1.MongoExpiredSessionError; } }));\nObject.defineProperty(exports, \"MongoGridFSChunkError\", ({ enumerable: true, get: function () { return error_1.MongoGridFSChunkError; } }));\nObject.defineProperty(exports, \"MongoGridFSStreamError\", ({ enumerable: true, get: function () { return error_1.MongoGridFSStreamError; } }));\nObject.defineProperty(exports, \"MongoInvalidArgumentError\", ({ enumerable: true, get: function () { return error_1.MongoInvalidArgumentError; } }));\nObject.defineProperty(exports, \"MongoKerberosError\", ({ enumerable: true, get: function () { return error_1.MongoKerberosError; } }));\nObject.defineProperty(exports, \"MongoMissingCredentialsError\", ({ enumerable: true, get: function () { return error_1.MongoMissingCredentialsError; } }));\nObject.defineProperty(exports, \"MongoMissingDependencyError\", ({ enumerable: true, get: function () { return error_1.MongoMissingDependencyError; } }));\nObject.defineProperty(exports, \"MongoNetworkError\", ({ enumerable: true, get: function () { return error_1.MongoNetworkError; } }));\nObject.defineProperty(exports, \"MongoNetworkTimeoutError\", ({ enumerable: true, get: function () { return error_1.MongoNetworkTimeoutError; } }));\nObject.defineProperty(exports, \"MongoNotConnectedError\", ({ enumerable: true, get: function () { return error_1.MongoNotConnectedError; } }));\nObject.defineProperty(exports, \"MongoParseError\", ({ enumerable: true, get: function () { return error_1.MongoParseError; } }));\nObject.defineProperty(exports, \"MongoRuntimeError\", ({ enumerable: true, get: function () { return error_1.MongoRuntimeError; } }));\nObject.defineProperty(exports, \"MongoServerClosedError\", ({ enumerable: true, get: function () { return error_1.MongoServerClosedError; } }));\nObject.defineProperty(exports, \"MongoServerError\", ({ enumerable: true, get: function () { return error_1.MongoServerError; } }));\nObject.defineProperty(exports, \"MongoServerSelectionError\", ({ enumerable: true, get: function () { return error_1.MongoServerSelectionError; } }));\nObject.defineProperty(exports, \"MongoSystemError\", ({ enumerable: true, get: function () { return error_1.MongoSystemError; } }));\nObject.defineProperty(exports, \"MongoTailableCursorError\", ({ enumerable: true, get: function () { return error_1.MongoTailableCursorError; } }));\nObject.defineProperty(exports, \"MongoTopologyClosedError\", ({ enumerable: true, get: function () { return error_1.MongoTopologyClosedError; } }));\nObject.defineProperty(exports, \"MongoTransactionError\", ({ enumerable: true, get: function () { return error_1.MongoTransactionError; } }));\nObject.defineProperty(exports, \"MongoUnexpectedServerResponseError\", ({ enumerable: true, get: function () { return error_1.MongoUnexpectedServerResponseError; } }));\nObject.defineProperty(exports, \"MongoWriteConcernError\", ({ enumerable: true, get: function () { return error_1.MongoWriteConcernError; } }));\n// enums\nvar common_2 = __webpack_require__(/*! ./bulk/common */ \"./node_modules/mongodb/lib/bulk/common.js\");\nObject.defineProperty(exports, \"BatchType\", ({ enumerable: true, get: function () { return common_2.BatchType; } }));\nvar auto_encrypter_1 = __webpack_require__(/*! ./client-side-encryption/auto_encrypter */ \"./node_modules/mongodb/lib/client-side-encryption/auto_encrypter.js\");\nObject.defineProperty(exports, \"AutoEncryptionLoggerLevel\", ({ enumerable: true, get: function () { return auto_encrypter_1.AutoEncryptionLoggerLevel; } }));\nvar gssapi_1 = __webpack_require__(/*! ./cmap/auth/gssapi */ \"./node_modules/mongodb/lib/cmap/auth/gssapi.js\");\nObject.defineProperty(exports, \"GSSAPICanonicalizationValue\", ({ enumerable: true, get: function () { return gssapi_1.GSSAPICanonicalizationValue; } }));\nvar providers_1 = __webpack_require__(/*! ./cmap/auth/providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\nObject.defineProperty(exports, \"AuthMechanism\", ({ enumerable: true, get: function () { return providers_1.AuthMechanism; } }));\nvar compression_1 = __webpack_require__(/*! ./cmap/wire_protocol/compression */ \"./node_modules/mongodb/lib/cmap/wire_protocol/compression.js\");\nObject.defineProperty(exports, \"Compressor\", ({ enumerable: true, get: function () { return compression_1.Compressor; } }));\nvar abstract_cursor_2 = __webpack_require__(/*! ./cursor/abstract_cursor */ \"./node_modules/mongodb/lib/cursor/abstract_cursor.js\");\nObject.defineProperty(exports, \"CURSOR_FLAGS\", ({ enumerable: true, get: function () { return abstract_cursor_2.CURSOR_FLAGS; } }));\nvar error_2 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nObject.defineProperty(exports, \"MongoErrorLabel\", ({ enumerable: true, get: function () { return error_2.MongoErrorLabel; } }));\nvar explain_1 = __webpack_require__(/*! ./explain */ \"./node_modules/mongodb/lib/explain.js\");\nObject.defineProperty(exports, \"ExplainVerbosity\", ({ enumerable: true, get: function () { return explain_1.ExplainVerbosity; } }));\nvar mongo_client_2 = __webpack_require__(/*! ./mongo_client */ \"./node_modules/mongodb/lib/mongo_client.js\");\nObject.defineProperty(exports, \"ServerApiVersion\", ({ enumerable: true, get: function () { return mongo_client_2.ServerApiVersion; } }));\nvar find_and_modify_1 = __webpack_require__(/*! ./operations/find_and_modify */ \"./node_modules/mongodb/lib/operations/find_and_modify.js\");\nObject.defineProperty(exports, \"ReturnDocument\", ({ enumerable: true, get: function () { return find_and_modify_1.ReturnDocument; } }));\nvar set_profiling_level_1 = __webpack_require__(/*! ./operations/set_profiling_level */ \"./node_modules/mongodb/lib/operations/set_profiling_level.js\");\nObject.defineProperty(exports, \"ProfilingLevel\", ({ enumerable: true, get: function () { return set_profiling_level_1.ProfilingLevel; } }));\nvar read_concern_1 = __webpack_require__(/*! ./read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nObject.defineProperty(exports, \"ReadConcernLevel\", ({ enumerable: true, get: function () { return read_concern_1.ReadConcernLevel; } }));\nvar read_preference_1 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nObject.defineProperty(exports, \"ReadPreferenceMode\", ({ enumerable: true, get: function () { return read_preference_1.ReadPreferenceMode; } }));\nvar common_3 = __webpack_require__(/*! ./sdam/common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nObject.defineProperty(exports, \"ServerType\", ({ enumerable: true, get: function () { return common_3.ServerType; } }));\nObject.defineProperty(exports, \"TopologyType\", ({ enumerable: true, get: function () { return common_3.TopologyType; } }));\n// Helper classes\nvar read_concern_2 = __webpack_require__(/*! ./read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nObject.defineProperty(exports, \"ReadConcern\", ({ enumerable: true, get: function () { return read_concern_2.ReadConcern; } }));\nvar read_preference_2 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nObject.defineProperty(exports, \"ReadPreference\", ({ enumerable: true, get: function () { return read_preference_2.ReadPreference; } }));\nvar write_concern_1 = __webpack_require__(/*! ./write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\nObject.defineProperty(exports, \"WriteConcern\", ({ enumerable: true, get: function () { return write_concern_1.WriteConcern; } }));\n// events\nvar command_monitoring_events_1 = __webpack_require__(/*! ./cmap/command_monitoring_events */ \"./node_modules/mongodb/lib/cmap/command_monitoring_events.js\");\nObject.defineProperty(exports, \"CommandFailedEvent\", ({ enumerable: true, get: function () { return command_monitoring_events_1.CommandFailedEvent; } }));\nObject.defineProperty(exports, \"CommandStartedEvent\", ({ enumerable: true, get: function () { return command_monitoring_events_1.CommandStartedEvent; } }));\nObject.defineProperty(exports, \"CommandSucceededEvent\", ({ enumerable: true, get: function () { return command_monitoring_events_1.CommandSucceededEvent; } }));\nvar connection_pool_events_1 = __webpack_require__(/*! ./cmap/connection_pool_events */ \"./node_modules/mongodb/lib/cmap/connection_pool_events.js\");\nObject.defineProperty(exports, \"ConnectionCheckedInEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionCheckedInEvent; } }));\nObject.defineProperty(exports, \"ConnectionCheckedOutEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionCheckedOutEvent; } }));\nObject.defineProperty(exports, \"ConnectionCheckOutFailedEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionCheckOutFailedEvent; } }));\nObject.defineProperty(exports, \"ConnectionCheckOutStartedEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionCheckOutStartedEvent; } }));\nObject.defineProperty(exports, \"ConnectionClosedEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionClosedEvent; } }));\nObject.defineProperty(exports, \"ConnectionCreatedEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionCreatedEvent; } }));\nObject.defineProperty(exports, \"ConnectionPoolClearedEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionPoolClearedEvent; } }));\nObject.defineProperty(exports, \"ConnectionPoolClosedEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionPoolClosedEvent; } }));\nObject.defineProperty(exports, \"ConnectionPoolCreatedEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionPoolCreatedEvent; } }));\nObject.defineProperty(exports, \"ConnectionPoolMonitoringEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionPoolMonitoringEvent; } }));\nObject.defineProperty(exports, \"ConnectionPoolReadyEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionPoolReadyEvent; } }));\nObject.defineProperty(exports, \"ConnectionReadyEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionReadyEvent; } }));\nvar events_1 = __webpack_require__(/*! ./sdam/events */ \"./node_modules/mongodb/lib/sdam/events.js\");\nObject.defineProperty(exports, \"ServerClosedEvent\", ({ enumerable: true, get: function () { return events_1.ServerClosedEvent; } }));\nObject.defineProperty(exports, \"ServerDescriptionChangedEvent\", ({ enumerable: true, get: function () { return events_1.ServerDescriptionChangedEvent; } }));\nObject.defineProperty(exports, \"ServerHeartbeatFailedEvent\", ({ enumerable: true, get: function () { return events_1.ServerHeartbeatFailedEvent; } }));\nObject.defineProperty(exports, \"ServerHeartbeatStartedEvent\", ({ enumerable: true, get: function () { return events_1.ServerHeartbeatStartedEvent; } }));\nObject.defineProperty(exports, \"ServerHeartbeatSucceededEvent\", ({ enumerable: true, get: function () { return events_1.ServerHeartbeatSucceededEvent; } }));\nObject.defineProperty(exports, \"ServerOpeningEvent\", ({ enumerable: true, get: function () { return events_1.ServerOpeningEvent; } }));\nObject.defineProperty(exports, \"TopologyClosedEvent\", ({ enumerable: true, get: function () { return events_1.TopologyClosedEvent; } }));\nObject.defineProperty(exports, \"TopologyDescriptionChangedEvent\", ({ enumerable: true, get: function () { return events_1.TopologyDescriptionChangedEvent; } }));\nObject.defineProperty(exports, \"TopologyOpeningEvent\", ({ enumerable: true, get: function () { return events_1.TopologyOpeningEvent; } }));\nvar srv_polling_1 = __webpack_require__(/*! ./sdam/srv_polling */ \"./node_modules/mongodb/lib/sdam/srv_polling.js\");\nObject.defineProperty(exports, \"SrvPollingEvent\", ({ enumerable: true, get: function () { return srv_polling_1.SrvPollingEvent; } }));\nvar errors_1 = __webpack_require__(/*! ./client-side-encryption/errors */ \"./node_modules/mongodb/lib/client-side-encryption/errors.js\");\nObject.defineProperty(exports, \"MongoCryptAzureKMSRequestError\", ({ enumerable: true, get: function () { return errors_1.MongoCryptAzureKMSRequestError; } }));\nObject.defineProperty(exports, \"MongoCryptCreateDataKeyError\", ({ enumerable: true, get: function () { return errors_1.MongoCryptCreateDataKeyError; } }));\nObject.defineProperty(exports, \"MongoCryptCreateEncryptedCollectionError\", ({ enumerable: true, get: function () { return errors_1.MongoCryptCreateEncryptedCollectionError; } }));\nObject.defineProperty(exports, \"MongoCryptError\", ({ enumerable: true, get: function () { return errors_1.MongoCryptError; } }));\nObject.defineProperty(exports, \"MongoCryptInvalidArgumentError\", ({ enumerable: true, get: function () { return errors_1.MongoCryptInvalidArgumentError; } }));\nObject.defineProperty(exports, \"MongoCryptKMSRequestNetworkTimeoutError\", ({ enumerable: true, get: function () { return errors_1.MongoCryptKMSRequestNetworkTimeoutError; } }));\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/index.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/mongo_client.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/mongo_client.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoClient = exports.ServerApiVersion = void 0;\nconst fs_1 = __webpack_require__(/*! fs */ \"fs\");\nconst util_1 = __webpack_require__(/*! util */ \"util\");\nconst bson_1 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst change_stream_1 = __webpack_require__(/*! ./change_stream */ \"./node_modules/mongodb/lib/change_stream.js\");\nconst mongo_credentials_1 = __webpack_require__(/*! ./cmap/auth/mongo_credentials */ \"./node_modules/mongodb/lib/cmap/auth/mongo_credentials.js\");\nconst providers_1 = __webpack_require__(/*! ./cmap/auth/providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\nconst connection_string_1 = __webpack_require__(/*! ./connection_string */ \"./node_modules/mongodb/lib/connection_string.js\");\nconst constants_1 = __webpack_require__(/*! ./constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst db_1 = __webpack_require__(/*! ./db */ \"./node_modules/mongodb/lib/db.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_logger_1 = __webpack_require__(/*! ./mongo_logger */ \"./node_modules/mongodb/lib/mongo_logger.js\");\nconst mongo_types_1 = __webpack_require__(/*! ./mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst execute_operation_1 = __webpack_require__(/*! ./operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst run_command_1 = __webpack_require__(/*! ./operations/run_command */ \"./node_modules/mongodb/lib/operations/run_command.js\");\nconst read_preference_1 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst server_selection_1 = __webpack_require__(/*! ./sdam/server_selection */ \"./node_modules/mongodb/lib/sdam/server_selection.js\");\nconst topology_1 = __webpack_require__(/*! ./sdam/topology */ \"./node_modules/mongodb/lib/sdam/topology.js\");\nconst sessions_1 = __webpack_require__(/*! ./sessions */ \"./node_modules/mongodb/lib/sessions.js\");\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/mongodb/lib/utils.js\");\n/** @public */\nexports.ServerApiVersion = Object.freeze({\n    v1: '1'\n});\n/** @internal */\nconst kOptions = Symbol('options');\n/**\n * The **MongoClient** class is a class that allows for making Connections to MongoDB.\n * @public\n *\n * @remarks\n * The programmatically provided options take precedence over the URI options.\n *\n * @example\n * ```ts\n * import { MongoClient } from 'mongodb';\n *\n * // Enable command monitoring for debugging\n * const client = new MongoClient('mongodb://localhost:27017', { monitorCommands: true });\n *\n * client.on('commandStarted', started => console.log(started));\n * client.db().collection('pets');\n * await client.insertOne({ name: 'spot', kind: 'dog' });\n * ```\n */\nclass MongoClient extends mongo_types_1.TypedEventEmitter {\n    constructor(url, options) {\n        super();\n        this[kOptions] = (0, connection_string_1.parseOptions)(url, this, options);\n        this.mongoLogger = new mongo_logger_1.MongoLogger(this[kOptions].mongoLoggerOptions);\n        // eslint-disable-next-line @typescript-eslint/no-this-alias\n        const client = this;\n        // The internal state\n        this.s = {\n            url,\n            bsonOptions: (0, bson_1.resolveBSONOptions)(this[kOptions]),\n            namespace: (0, utils_1.ns)('admin'),\n            hasBeenClosed: false,\n            sessionPool: new sessions_1.ServerSessionPool(this),\n            activeSessions: new Set(),\n            get options() {\n                return client[kOptions];\n            },\n            get readConcern() {\n                return client[kOptions].readConcern;\n            },\n            get writeConcern() {\n                return client[kOptions].writeConcern;\n            },\n            get readPreference() {\n                return client[kOptions].readPreference;\n            },\n            get isMongoClient() {\n                return true;\n            }\n        };\n        this.checkForNonGenuineHosts();\n    }\n    /** @internal */\n    checkForNonGenuineHosts() {\n        const documentDBHostnames = this[kOptions].hosts.filter((hostAddress) => (0, utils_1.isHostMatch)(utils_1.DOCUMENT_DB_CHECK, hostAddress.host));\n        const srvHostIsDocumentDB = (0, utils_1.isHostMatch)(utils_1.DOCUMENT_DB_CHECK, this[kOptions].srvHost);\n        const cosmosDBHostnames = this[kOptions].hosts.filter((hostAddress) => (0, utils_1.isHostMatch)(utils_1.COSMOS_DB_CHECK, hostAddress.host));\n        const srvHostIsCosmosDB = (0, utils_1.isHostMatch)(utils_1.COSMOS_DB_CHECK, this[kOptions].srvHost);\n        if (documentDBHostnames.length !== 0 || srvHostIsDocumentDB) {\n            this.mongoLogger.info('client', utils_1.DOCUMENT_DB_MSG);\n        }\n        else if (cosmosDBHostnames.length !== 0 || srvHostIsCosmosDB) {\n            this.mongoLogger.info('client', utils_1.COSMOS_DB_MSG);\n        }\n    }\n    /** @see MongoOptions */\n    get options() {\n        return Object.freeze({ ...this[kOptions] });\n    }\n    get serverApi() {\n        return this[kOptions].serverApi && Object.freeze({ ...this[kOptions].serverApi });\n    }\n    /**\n     * Intended for APM use only\n     * @internal\n     */\n    get monitorCommands() {\n        return this[kOptions].monitorCommands;\n    }\n    set monitorCommands(value) {\n        this[kOptions].monitorCommands = value;\n    }\n    /** @internal */\n    get autoEncrypter() {\n        return this[kOptions].autoEncrypter;\n    }\n    get readConcern() {\n        return this.s.readConcern;\n    }\n    get writeConcern() {\n        return this.s.writeConcern;\n    }\n    get readPreference() {\n        return this.s.readPreference;\n    }\n    get bsonOptions() {\n        return this.s.bsonOptions;\n    }\n    /**\n     * Connect to MongoDB using a url\n     *\n     * @see docs.mongodb.org/manual/reference/connection-string/\n     */\n    async connect() {\n        if (this.connectionLock) {\n            return this.connectionLock;\n        }\n        try {\n            this.connectionLock = this._connect();\n            await this.connectionLock;\n        }\n        finally {\n            // release\n            this.connectionLock = undefined;\n        }\n        return this;\n    }\n    /**\n     * Create a topology to open the connection, must be locked to avoid topology leaks in concurrency scenario.\n     * Locking is enforced by the connect method.\n     *\n     * @internal\n     */\n    async _connect() {\n        if (this.topology && this.topology.isConnected()) {\n            return this;\n        }\n        const options = this[kOptions];\n        if (options.tls) {\n            if (typeof options.tlsCAFile === 'string') {\n                options.ca ??= await fs_1.promises.readFile(options.tlsCAFile);\n            }\n            if (typeof options.tlsCRLFile === 'string') {\n                options.crl ??= await fs_1.promises.readFile(options.tlsCRLFile);\n            }\n            if (typeof options.tlsCertificateKeyFile === 'string') {\n                if (!options.key || !options.cert) {\n                    const contents = await fs_1.promises.readFile(options.tlsCertificateKeyFile);\n                    options.key ??= contents;\n                    options.cert ??= contents;\n                }\n            }\n        }\n        if (typeof options.srvHost === 'string') {\n            const hosts = await (0, connection_string_1.resolveSRVRecord)(options);\n            for (const [index, host] of hosts.entries()) {\n                options.hosts[index] = host;\n            }\n        }\n        // It is important to perform validation of hosts AFTER SRV resolution, to check the real hostname,\n        // but BEFORE we even attempt connecting with a potentially not allowed hostname\n        if (options.credentials?.mechanism === providers_1.AuthMechanism.MONGODB_OIDC) {\n            const allowedHosts = options.credentials?.mechanismProperties?.ALLOWED_HOSTS || mongo_credentials_1.DEFAULT_ALLOWED_HOSTS;\n            const isServiceAuth = !!options.credentials?.mechanismProperties?.PROVIDER_NAME;\n            if (!isServiceAuth) {\n                for (const host of options.hosts) {\n                    if (!(0, utils_1.hostMatchesWildcards)(host.toHostPort().host, allowedHosts)) {\n                        throw new error_1.MongoInvalidArgumentError(`Host '${host}' is not valid for OIDC authentication with ALLOWED_HOSTS of '${allowedHosts.join(',')}'`);\n                    }\n                }\n            }\n        }\n        this.topology = new topology_1.Topology(this, options.hosts, options);\n        // Events can be emitted before initialization is complete so we have to\n        // save the reference to the topology on the client ASAP if the event handlers need to access it\n        this.topology.once(topology_1.Topology.OPEN, () => this.emit('open', this));\n        for (const event of constants_1.MONGO_CLIENT_EVENTS) {\n            this.topology.on(event, (...args) => this.emit(event, ...args));\n        }\n        const topologyConnect = async () => {\n            try {\n                await (0, util_1.promisify)(callback => this.topology?.connect(options, callback))();\n            }\n            catch (error) {\n                this.topology?.close({ force: true });\n                throw error;\n            }\n        };\n        if (this.autoEncrypter) {\n            await this.autoEncrypter?.init();\n            await topologyConnect();\n            await options.encrypter.connectInternalClient();\n        }\n        else {\n            await topologyConnect();\n        }\n        return this;\n    }\n    /**\n     * Close the client and its underlying connections\n     *\n     * @param force - Force close, emitting no events\n     */\n    async close(force = false) {\n        // There's no way to set hasBeenClosed back to false\n        Object.defineProperty(this.s, 'hasBeenClosed', {\n            value: true,\n            enumerable: true,\n            configurable: false,\n            writable: false\n        });\n        const activeSessionEnds = Array.from(this.s.activeSessions, session => session.endSession());\n        this.s.activeSessions.clear();\n        await Promise.all(activeSessionEnds);\n        if (this.topology == null) {\n            return;\n        }\n        // If we would attempt to select a server and get nothing back we short circuit\n        // to avoid the server selection timeout.\n        const selector = (0, server_selection_1.readPreferenceServerSelector)(read_preference_1.ReadPreference.primaryPreferred);\n        const topologyDescription = this.topology.description;\n        const serverDescriptions = Array.from(topologyDescription.servers.values());\n        const servers = selector(topologyDescription, serverDescriptions);\n        if (servers.length !== 0) {\n            const endSessions = Array.from(this.s.sessionPool.sessions, ({ id }) => id);\n            if (endSessions.length !== 0) {\n                await (0, execute_operation_1.executeOperation)(this, new run_command_1.RunAdminCommandOperation({ endSessions }, { readPreference: read_preference_1.ReadPreference.primaryPreferred, noResponse: true })).catch(() => null); // outcome does not matter;\n            }\n        }\n        // clear out references to old topology\n        const topology = this.topology;\n        this.topology = undefined;\n        await new Promise((resolve, reject) => {\n            topology.close({ force }, error => {\n                if (error)\n                    return reject(error);\n                const { encrypter } = this[kOptions];\n                if (encrypter) {\n                    return encrypter.closeCallback(this, force, error => {\n                        if (error)\n                            return reject(error);\n                        resolve();\n                    });\n                }\n                resolve();\n            });\n        });\n    }\n    /**\n     * Create a new Db instance sharing the current socket connections.\n     *\n     * @param dbName - The name of the database we want to use. If not provided, use database name from connection string.\n     * @param options - Optional settings for Db construction\n     */\n    db(dbName, options) {\n        options = options ?? {};\n        // Default to db from connection string if not provided\n        if (!dbName) {\n            dbName = this.options.dbName;\n        }\n        // Copy the options and add out internal override of the not shared flag\n        const finalOptions = Object.assign({}, this[kOptions], options);\n        // Return the db object\n        const db = new db_1.Db(this, dbName, finalOptions);\n        // Return the database\n        return db;\n    }\n    /**\n     * Connect to MongoDB using a url\n     *\n     * @remarks\n     * The programmatically provided options take precedence over the URI options.\n     *\n     * @see https://www.mongodb.com/docs/manual/reference/connection-string/\n     */\n    static async connect(url, options) {\n        const client = new this(url, options);\n        return client.connect();\n    }\n    /**\n     * Creates a new ClientSession. When using the returned session in an operation\n     * a corresponding ServerSession will be created.\n     *\n     * @remarks\n     * A ClientSession instance may only be passed to operations being performed on the same\n     * MongoClient it was started from.\n     */\n    startSession(options) {\n        const session = new sessions_1.ClientSession(this, this.s.sessionPool, { explicit: true, ...options }, this[kOptions]);\n        this.s.activeSessions.add(session);\n        session.once('ended', () => {\n            this.s.activeSessions.delete(session);\n        });\n        return session;\n    }\n    async withSession(optionsOrExecutor, executor) {\n        const options = {\n            // Always define an owner\n            owner: Symbol(),\n            // If it's an object inherit the options\n            ...(typeof optionsOrExecutor === 'object' ? optionsOrExecutor : {})\n        };\n        const withSessionCallback = typeof optionsOrExecutor === 'function' ? optionsOrExecutor : executor;\n        if (withSessionCallback == null) {\n            throw new error_1.MongoInvalidArgumentError('Missing required callback parameter');\n        }\n        const session = this.startSession(options);\n        try {\n            return await withSessionCallback(session);\n        }\n        finally {\n            try {\n                await session.endSession();\n            }\n            catch {\n                // We are not concerned with errors from endSession()\n            }\n        }\n    }\n    /**\n     * Create a new Change Stream, watching for new changes (insertions, updates,\n     * replacements, deletions, and invalidations) in this cluster. Will ignore all\n     * changes to system collections, as well as the local, admin, and config databases.\n     *\n     * @remarks\n     * watch() accepts two generic arguments for distinct use cases:\n     * - The first is to provide the schema that may be defined for all the data within the current cluster\n     * - The second is to override the shape of the change stream document entirely, if it is not provided the type will default to ChangeStreamDocument of the first argument\n     *\n     * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents. This allows for filtering (using $match) and manipulating the change stream documents.\n     * @param options - Optional settings for the command\n     * @typeParam TSchema - Type of the data being detected by the change stream\n     * @typeParam TChange - Type of the whole change stream document emitted\n     */\n    watch(pipeline = [], options = {}) {\n        // Allow optionally not specifying a pipeline\n        if (!Array.isArray(pipeline)) {\n            options = pipeline;\n            pipeline = [];\n        }\n        return new change_stream_1.ChangeStream(this, pipeline, (0, utils_1.resolveOptions)(this, options));\n    }\n}\nexports.MongoClient = MongoClient;\n//# sourceMappingURL=mongo_client.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/mongo_client.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/mongo_logger.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/mongo_logger.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoLogger = exports.stringifyWithMaxLen = exports.createStdioLogger = exports.MongoLoggableComponent = exports.SEVERITY_LEVEL_MAP = exports.DEFAULT_MAX_DOCUMENT_LENGTH = exports.SeverityLevel = void 0;\nconst bson_1 = __webpack_require__(/*! bson */ \"./node_modules/bson/lib/bson.cjs\");\nconst util_1 = __webpack_require__(/*! util */ \"util\");\nconst constants_1 = __webpack_require__(/*! ./constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/mongodb/lib/utils.js\");\n/** @internal */\nexports.SeverityLevel = Object.freeze({\n    EMERGENCY: 'emergency',\n    ALERT: 'alert',\n    CRITICAL: 'critical',\n    ERROR: 'error',\n    WARNING: 'warn',\n    NOTICE: 'notice',\n    INFORMATIONAL: 'info',\n    DEBUG: 'debug',\n    TRACE: 'trace',\n    OFF: 'off'\n});\n/** @internal */\nexports.DEFAULT_MAX_DOCUMENT_LENGTH = 1000;\n/** @internal */\nclass SeverityLevelMap extends Map {\n    constructor(entries) {\n        const newEntries = [];\n        for (const [level, value] of entries) {\n            newEntries.push([value, level]);\n        }\n        newEntries.push(...entries);\n        super(newEntries);\n    }\n    getNumericSeverityLevel(severity) {\n        return this.get(severity);\n    }\n    getSeverityLevelName(level) {\n        return this.get(level);\n    }\n}\n/** @internal */\nexports.SEVERITY_LEVEL_MAP = new SeverityLevelMap([\n    [exports.SeverityLevel.OFF, -Infinity],\n    [exports.SeverityLevel.EMERGENCY, 0],\n    [exports.SeverityLevel.ALERT, 1],\n    [exports.SeverityLevel.CRITICAL, 2],\n    [exports.SeverityLevel.ERROR, 3],\n    [exports.SeverityLevel.WARNING, 4],\n    [exports.SeverityLevel.NOTICE, 5],\n    [exports.SeverityLevel.INFORMATIONAL, 6],\n    [exports.SeverityLevel.DEBUG, 7],\n    [exports.SeverityLevel.TRACE, 8]\n]);\n/** @internal */\nexports.MongoLoggableComponent = Object.freeze({\n    COMMAND: 'command',\n    TOPOLOGY: 'topology',\n    SERVER_SELECTION: 'serverSelection',\n    CONNECTION: 'connection',\n    CLIENT: 'client'\n});\n/**\n * Parses a string as one of SeverityLevel\n *\n * @param s - the value to be parsed\n * @returns one of SeverityLevel if value can be parsed as such, otherwise null\n */\nfunction parseSeverityFromString(s) {\n    const validSeverities = Object.values(exports.SeverityLevel);\n    const lowerSeverity = s?.toLowerCase();\n    if (lowerSeverity != null && validSeverities.includes(lowerSeverity)) {\n        return lowerSeverity;\n    }\n    return null;\n}\n/** @internal */\nfunction createStdioLogger(stream) {\n    return {\n        write: (log) => {\n            stream.write((0, util_1.inspect)(log, { compact: true, breakLength: Infinity }), 'utf-8');\n            return;\n        }\n    };\n}\nexports.createStdioLogger = createStdioLogger;\n/**\n * resolves the MONGODB_LOG_PATH and mongodbLogPath options from the environment and the\n * mongo client options respectively. The mongodbLogPath can be either 'stdout', 'stderr', a NodeJS\n * Writable or an object which has a `write` method with the signature:\n * ```ts\n * write(log: Log): void\n * ```\n *\n * @returns the MongoDBLogWritable object to write logs to\n */\nfunction resolveLogPath({ MONGODB_LOG_PATH }, { mongodbLogPath }) {\n    if (typeof mongodbLogPath === 'string' && /^stderr$/i.test(mongodbLogPath)) {\n        return createStdioLogger(process.stderr);\n    }\n    if (typeof mongodbLogPath === 'string' && /^stdout$/i.test(mongodbLogPath)) {\n        return createStdioLogger(process.stdout);\n    }\n    if (typeof mongodbLogPath === 'object' && typeof mongodbLogPath?.write === 'function') {\n        return mongodbLogPath;\n    }\n    if (MONGODB_LOG_PATH && /^stderr$/i.test(MONGODB_LOG_PATH)) {\n        return createStdioLogger(process.stderr);\n    }\n    if (MONGODB_LOG_PATH && /^stdout$/i.test(MONGODB_LOG_PATH)) {\n        return createStdioLogger(process.stdout);\n    }\n    return createStdioLogger(process.stderr);\n}\nfunction resolveSeverityConfiguration(clientOption, environmentOption, defaultSeverity) {\n    return (parseSeverityFromString(clientOption) ??\n        parseSeverityFromString(environmentOption) ??\n        defaultSeverity);\n}\nfunction compareSeverity(s0, s1) {\n    const s0Num = exports.SEVERITY_LEVEL_MAP.getNumericSeverityLevel(s0);\n    const s1Num = exports.SEVERITY_LEVEL_MAP.getNumericSeverityLevel(s1);\n    return s0Num < s1Num ? -1 : s0Num > s1Num ? 1 : 0;\n}\n/** @internal */\nfunction stringifyWithMaxLen(value, maxDocumentLength) {\n    const ejson = bson_1.EJSON.stringify(value);\n    return maxDocumentLength !== 0 && ejson.length > maxDocumentLength\n        ? `${ejson.slice(0, maxDocumentLength)}...`\n        : ejson;\n}\nexports.stringifyWithMaxLen = stringifyWithMaxLen;\nfunction isLogConvertible(obj) {\n    const objAsLogConvertible = obj;\n    // eslint-disable-next-line no-restricted-syntax\n    return objAsLogConvertible.toLog !== undefined && typeof objAsLogConvertible.toLog === 'function';\n}\nfunction attachCommandFields(log, commandEvent) {\n    log.commandName = commandEvent.commandName;\n    log.requestId = commandEvent.requestId;\n    log.driverConnectionId = commandEvent?.connectionId;\n    const { host, port } = utils_1.HostAddress.fromString(commandEvent.address).toHostPort();\n    log.serverHost = host;\n    log.serverPort = port;\n    if (commandEvent?.serviceId) {\n        log.serviceId = commandEvent.serviceId.toHexString();\n    }\n    return log;\n}\nfunction attachConnectionFields(log, connectionPoolEvent) {\n    const { host, port } = utils_1.HostAddress.fromString(connectionPoolEvent.address).toHostPort();\n    log.serverHost = host;\n    log.serverPort = port;\n    return log;\n}\nfunction defaultLogTransform(logObject, maxDocumentLength = exports.DEFAULT_MAX_DOCUMENT_LENGTH) {\n    let log = Object.create(null);\n    switch (logObject.name) {\n        case constants_1.COMMAND_STARTED:\n            log = attachCommandFields(log, logObject);\n            log.message = 'Command started';\n            log.command = stringifyWithMaxLen(logObject.command, maxDocumentLength);\n            log.databaseName = logObject.databaseName;\n            return log;\n        case constants_1.COMMAND_SUCCEEDED:\n            log = attachCommandFields(log, logObject);\n            log.message = 'Command succeeded';\n            log.durationMS = logObject.duration;\n            log.reply = stringifyWithMaxLen(logObject.reply, maxDocumentLength);\n            return log;\n        case constants_1.COMMAND_FAILED:\n            log = attachCommandFields(log, logObject);\n            log.message = 'Command failed';\n            log.durationMS = logObject.duration;\n            log.failure = logObject.failure;\n            return log;\n        case constants_1.CONNECTION_POOL_CREATED:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection pool created';\n            if (logObject.options) {\n                const { maxIdleTimeMS, minPoolSize, maxPoolSize, maxConnecting, waitQueueTimeoutMS } = logObject.options;\n                log = {\n                    ...log,\n                    maxIdleTimeMS,\n                    minPoolSize,\n                    maxPoolSize,\n                    maxConnecting,\n                    waitQueueTimeoutMS\n                };\n            }\n            return log;\n        case constants_1.CONNECTION_POOL_READY:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection pool ready';\n            return log;\n        case constants_1.CONNECTION_POOL_CLEARED:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection pool cleared';\n            if (logObject.serviceId?._bsontype === 'ObjectId') {\n                log.serviceId = logObject.serviceId.toHexString();\n            }\n            return log;\n        case constants_1.CONNECTION_POOL_CLOSED:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection pool closed';\n            return log;\n        case constants_1.CONNECTION_CREATED:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection created';\n            log.driverConnectionId = logObject.connectionId;\n            return log;\n        case constants_1.CONNECTION_READY:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection ready';\n            log.driverConnectionId = logObject.connectionId;\n            return log;\n        case constants_1.CONNECTION_CLOSED:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection closed';\n            log.driverConnectionId = logObject.connectionId;\n            switch (logObject.reason) {\n                case 'stale':\n                    log.reason = 'Connection became stale because the pool was cleared';\n                    break;\n                case 'idle':\n                    log.reason =\n                        'Connection has been available but unused for longer than the configured max idle time';\n                    break;\n                case 'error':\n                    log.reason = 'An error occurred while using the connection';\n                    if (logObject.error) {\n                        log.error = logObject.error;\n                    }\n                    break;\n                case 'poolClosed':\n                    log.reason = 'Connection pool was closed';\n                    break;\n                default:\n                    log.reason = `Unknown close reason: ${logObject.reason}`;\n            }\n            return log;\n        case constants_1.CONNECTION_CHECK_OUT_STARTED:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection checkout started';\n            return log;\n        case constants_1.CONNECTION_CHECK_OUT_FAILED:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection checkout failed';\n            switch (logObject.reason) {\n                case 'poolClosed':\n                    log.reason = 'Connection pool was closed';\n                    break;\n                case 'timeout':\n                    log.reason = 'Wait queue timeout elapsed without a connection becoming available';\n                    break;\n                case 'connectionError':\n                    log.reason = 'An error occurred while trying to establish a new connection';\n                    if (logObject.error) {\n                        log.error = logObject.error;\n                    }\n                    break;\n                default:\n                    log.reason = `Unknown close reason: ${logObject.reason}`;\n            }\n            return log;\n        case constants_1.CONNECTION_CHECKED_OUT:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection checked out';\n            log.driverConnectionId = logObject.connectionId;\n            return log;\n        case constants_1.CONNECTION_CHECKED_IN:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection checked in';\n            log.driverConnectionId = logObject.connectionId;\n            return log;\n        default:\n            for (const [key, value] of Object.entries(logObject)) {\n                if (value != null)\n                    log[key] = value;\n            }\n    }\n    return log;\n}\n/** @internal */\nclass MongoLogger {\n    constructor(options) {\n        /**\n         * This method should be used when logging errors that do not have a public driver API for\n         * reporting errors.\n         */\n        this.error = this.log.bind(this, 'error');\n        /**\n         * This method should be used to log situations where undesirable application behaviour might\n         * occur. For example, failing to end sessions on `MongoClient.close`.\n         */\n        this.warn = this.log.bind(this, 'warn');\n        /**\n         * This method should be used to report high-level information about normal driver behaviour.\n         * For example, the creation of a `MongoClient`.\n         */\n        this.info = this.log.bind(this, 'info');\n        /**\n         * This method should be used to report information that would be helpful when debugging an\n         * application. For example, a command starting, succeeding or failing.\n         */\n        this.debug = this.log.bind(this, 'debug');\n        /**\n         * This method should be used to report fine-grained details related to logic flow. For example,\n         * entering and exiting a function body.\n         */\n        this.trace = this.log.bind(this, 'trace');\n        this.componentSeverities = options.componentSeverities;\n        this.maxDocumentLength = options.maxDocumentLength;\n        this.logDestination = options.logDestination;\n    }\n    log(severity, component, message) {\n        if (compareSeverity(severity, this.componentSeverities[component]) > 0)\n            return;\n        let logMessage = { t: new Date(), c: component, s: severity };\n        if (typeof message === 'string') {\n            logMessage.message = message;\n        }\n        else if (typeof message === 'object') {\n            if (isLogConvertible(message)) {\n                logMessage = { ...logMessage, ...message.toLog() };\n            }\n            else {\n                logMessage = { ...logMessage, ...defaultLogTransform(message, this.maxDocumentLength) };\n            }\n        }\n        this.logDestination.write(logMessage);\n    }\n    /**\n     * Merges options set through environment variables and the MongoClient, preferring environment\n     * variables when both are set, and substituting defaults for values not set. Options set in\n     * constructor take precedence over both environment variables and MongoClient options.\n     *\n     * @remarks\n     * When parsing component severity levels, invalid values are treated as unset and replaced with\n     * the default severity.\n     *\n     * @param envOptions - options set for the logger from the environment\n     * @param clientOptions - options set for the logger in the MongoClient options\n     * @returns a MongoLoggerOptions object to be used when instantiating a new MongoLogger\n     */\n    static resolveOptions(envOptions, clientOptions) {\n        // client options take precedence over env options\n        const combinedOptions = {\n            ...envOptions,\n            ...clientOptions,\n            mongodbLogPath: resolveLogPath(envOptions, clientOptions)\n        };\n        const defaultSeverity = resolveSeverityConfiguration(combinedOptions.mongodbLogComponentSeverities?.default, combinedOptions.MONGODB_LOG_ALL, exports.SeverityLevel.OFF);\n        return {\n            componentSeverities: {\n                command: resolveSeverityConfiguration(combinedOptions.mongodbLogComponentSeverities?.command, combinedOptions.MONGODB_LOG_COMMAND, defaultSeverity),\n                topology: resolveSeverityConfiguration(combinedOptions.mongodbLogComponentSeverities?.topology, combinedOptions.MONGODB_LOG_TOPOLOGY, defaultSeverity),\n                serverSelection: resolveSeverityConfiguration(combinedOptions.mongodbLogComponentSeverities?.serverSelection, combinedOptions.MONGODB_LOG_SERVER_SELECTION, defaultSeverity),\n                connection: resolveSeverityConfiguration(combinedOptions.mongodbLogComponentSeverities?.connection, combinedOptions.MONGODB_LOG_CONNECTION, defaultSeverity),\n                client: resolveSeverityConfiguration(combinedOptions.mongodbLogComponentSeverities?.client, combinedOptions.MONGODB_LOG_CLIENT, defaultSeverity),\n                default: defaultSeverity\n            },\n            maxDocumentLength: combinedOptions.mongodbLogMaxDocumentLength ??\n                (0, utils_1.parseUnsignedInteger)(combinedOptions.MONGODB_LOG_MAX_DOCUMENT_LENGTH) ??\n                1000,\n            logDestination: combinedOptions.mongodbLogPath\n        };\n    }\n}\nexports.MongoLogger = MongoLogger;\n//# sourceMappingURL=mongo_logger.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/mongo_logger.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/mongo_types.js":
/*!*************************************************!*\
  !*** ./node_modules/mongodb/lib/mongo_types.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CancellationToken = exports.TypedEventEmitter = void 0;\nconst events_1 = __webpack_require__(/*! events */ \"events\");\n/**\n * Typescript type safe event emitter\n * @public\n */\nclass TypedEventEmitter extends events_1.EventEmitter {\n    /** @internal */\n    emitAndLog(event, ...args) {\n        this.emit(event, ...args);\n        if (this.component)\n            this.mongoLogger?.debug(this.component, args[0]);\n    }\n}\nexports.TypedEventEmitter = TypedEventEmitter;\n/** @public */\nclass CancellationToken extends TypedEventEmitter {\n}\nexports.CancellationToken = CancellationToken;\n//# sourceMappingURL=mongo_types.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/mongo_types.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/aggregate.js":
/*!**********************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/aggregate.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AggregateOperation = exports.DB_AGGREGATE_COLLECTION = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst write_concern_1 = __webpack_require__(/*! ../write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nexports.DB_AGGREGATE_COLLECTION = 1;\nconst MIN_WIRE_VERSION_$OUT_READ_CONCERN_SUPPORT = 8;\n/** @internal */\nclass AggregateOperation extends command_1.CommandOperation {\n    constructor(ns, pipeline, options) {\n        super(undefined, { ...options, dbName: ns.db });\n        this.options = { ...options };\n        // Covers when ns.collection is null, undefined or the empty string, use DB_AGGREGATE_COLLECTION\n        this.target = ns.collection || exports.DB_AGGREGATE_COLLECTION;\n        this.pipeline = pipeline;\n        // determine if we have a write stage, override read preference if so\n        this.hasWriteStage = false;\n        if (typeof options?.out === 'string') {\n            this.pipeline = this.pipeline.concat({ $out: options.out });\n            this.hasWriteStage = true;\n        }\n        else if (pipeline.length > 0) {\n            const finalStage = pipeline[pipeline.length - 1];\n            if (finalStage.$out || finalStage.$merge) {\n                this.hasWriteStage = true;\n            }\n        }\n        if (this.hasWriteStage) {\n            this.trySecondaryWrite = true;\n        }\n        else {\n            delete this.options.writeConcern;\n        }\n        if (this.explain && this.writeConcern) {\n            throw new error_1.MongoInvalidArgumentError('Option \"explain\" cannot be used on an aggregate call with writeConcern');\n        }\n        if (options?.cursor != null && typeof options.cursor !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('Cursor options must be an object');\n        }\n    }\n    get canRetryRead() {\n        return !this.hasWriteStage;\n    }\n    addToPipeline(stage) {\n        this.pipeline.push(stage);\n    }\n    async execute(server, session) {\n        const options = this.options;\n        const serverWireVersion = (0, utils_1.maxWireVersion)(server);\n        const command = { aggregate: this.target, pipeline: this.pipeline };\n        if (this.hasWriteStage && serverWireVersion < MIN_WIRE_VERSION_$OUT_READ_CONCERN_SUPPORT) {\n            this.readConcern = undefined;\n        }\n        if (this.hasWriteStage && this.writeConcern) {\n            write_concern_1.WriteConcern.apply(command, this.writeConcern);\n        }\n        if (options.bypassDocumentValidation === true) {\n            command.bypassDocumentValidation = options.bypassDocumentValidation;\n        }\n        if (typeof options.allowDiskUse === 'boolean') {\n            command.allowDiskUse = options.allowDiskUse;\n        }\n        if (options.hint) {\n            command.hint = options.hint;\n        }\n        if (options.let) {\n            command.let = options.let;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (options.comment !== undefined) {\n            command.comment = options.comment;\n        }\n        command.cursor = options.cursor || {};\n        if (options.batchSize && !this.hasWriteStage) {\n            command.cursor.batchSize = options.batchSize;\n        }\n        return super.executeCommand(server, session, command);\n    }\n}\nexports.AggregateOperation = AggregateOperation;\n(0, operation_1.defineAspects)(AggregateOperation, [\n    operation_1.Aspect.READ_OPERATION,\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.EXPLAINABLE,\n    operation_1.Aspect.CURSOR_CREATING\n]);\n//# sourceMappingURL=aggregate.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/aggregate.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/bulk_write.js":
/*!***********************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/bulk_write.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.BulkWriteOperation = void 0;\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass BulkWriteOperation extends operation_1.AbstractOperation {\n    constructor(collection, operations, options) {\n        super(options);\n        this.options = options;\n        this.collection = collection;\n        this.operations = operations;\n    }\n    async execute(server, session) {\n        const coll = this.collection;\n        const operations = this.operations;\n        const options = { ...this.options, ...this.bsonOptions, readPreference: this.readPreference };\n        // Create the bulk operation\n        const bulk = options.ordered === false\n            ? coll.initializeUnorderedBulkOp(options)\n            : coll.initializeOrderedBulkOp(options);\n        // for each op go through and add to the bulk\n        for (let i = 0; i < operations.length; i++) {\n            bulk.raw(operations[i]);\n        }\n        // Execute the bulk\n        const result = await bulk.execute({ ...options, session });\n        return result;\n    }\n}\nexports.BulkWriteOperation = BulkWriteOperation;\n(0, operation_1.defineAspects)(BulkWriteOperation, [operation_1.Aspect.WRITE_OPERATION]);\n//# sourceMappingURL=bulk_write.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/bulk_write.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/collections.js":
/*!************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/collections.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CollectionsOperation = void 0;\nconst collection_1 = __webpack_require__(/*! ../collection */ \"./node_modules/mongodb/lib/collection.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass CollectionsOperation extends operation_1.AbstractOperation {\n    constructor(db, options) {\n        super(options);\n        this.options = options;\n        this.db = db;\n    }\n    async execute(server, session) {\n        // Let's get the collection names\n        const documents = await this.db\n            .listCollections({}, { ...this.options, nameOnly: true, readPreference: this.readPreference, session })\n            .toArray();\n        const collections = [];\n        for (const { name } of documents) {\n            if (!name.includes('$')) {\n                // Filter collections removing any illegal ones\n                collections.push(new collection_1.Collection(this.db, name, this.db.s.options));\n            }\n        }\n        // Return the collection objects\n        return collections;\n    }\n}\nexports.CollectionsOperation = CollectionsOperation;\n//# sourceMappingURL=collections.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/collections.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/command.js":
/*!********************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/command.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CommandOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst explain_1 = __webpack_require__(/*! ../explain */ \"./node_modules/mongodb/lib/explain.js\");\nconst read_concern_1 = __webpack_require__(/*! ../read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst server_selection_1 = __webpack_require__(/*! ../sdam/server_selection */ \"./node_modules/mongodb/lib/sdam/server_selection.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst write_concern_1 = __webpack_require__(/*! ../write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass CommandOperation extends operation_1.AbstractOperation {\n    constructor(parent, options) {\n        super(options);\n        this.options = options ?? {};\n        // NOTE: this was explicitly added for the add/remove user operations, it's likely\n        //       something we'd want to reconsider. Perhaps those commands can use `Admin`\n        //       as a parent?\n        const dbNameOverride = options?.dbName || options?.authdb;\n        if (dbNameOverride) {\n            this.ns = new utils_1.MongoDBNamespace(dbNameOverride, '$cmd');\n        }\n        else {\n            this.ns = parent\n                ? parent.s.namespace.withCollection('$cmd')\n                : new utils_1.MongoDBNamespace('admin', '$cmd');\n        }\n        this.readConcern = read_concern_1.ReadConcern.fromOptions(options);\n        this.writeConcern = write_concern_1.WriteConcern.fromOptions(options);\n        if (this.hasAspect(operation_1.Aspect.EXPLAINABLE)) {\n            this.explain = explain_1.Explain.fromOptions(options);\n        }\n        else if (options?.explain != null) {\n            throw new error_1.MongoInvalidArgumentError(`Option \"explain\" is not supported on this command`);\n        }\n    }\n    get canRetryWrite() {\n        if (this.hasAspect(operation_1.Aspect.EXPLAINABLE)) {\n            return this.explain == null;\n        }\n        return true;\n    }\n    async executeCommand(server, session, cmd) {\n        // TODO: consider making this a non-enumerable property\n        this.server = server;\n        const options = {\n            ...this.options,\n            ...this.bsonOptions,\n            readPreference: this.readPreference,\n            session\n        };\n        const serverWireVersion = (0, utils_1.maxWireVersion)(server);\n        const inTransaction = this.session && this.session.inTransaction();\n        if (this.readConcern && (0, utils_1.commandSupportsReadConcern)(cmd) && !inTransaction) {\n            Object.assign(cmd, { readConcern: this.readConcern });\n        }\n        if (this.trySecondaryWrite && serverWireVersion < server_selection_1.MIN_SECONDARY_WRITE_WIRE_VERSION) {\n            options.omitReadPreference = true;\n        }\n        if (this.writeConcern && this.hasAspect(operation_1.Aspect.WRITE_OPERATION) && !inTransaction) {\n            write_concern_1.WriteConcern.apply(cmd, this.writeConcern);\n        }\n        if (options.collation &&\n            typeof options.collation === 'object' &&\n            !this.hasAspect(operation_1.Aspect.SKIP_COLLATION)) {\n            Object.assign(cmd, { collation: options.collation });\n        }\n        if (typeof options.maxTimeMS === 'number') {\n            cmd.maxTimeMS = options.maxTimeMS;\n        }\n        if (this.hasAspect(operation_1.Aspect.EXPLAINABLE) && this.explain) {\n            cmd = (0, utils_1.decorateWithExplain)(cmd, this.explain);\n        }\n        return server.commandAsync(this.ns, cmd, options);\n    }\n}\nexports.CommandOperation = CommandOperation;\n//# sourceMappingURL=command.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/command.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/common_functions.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/common_functions.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.prepareDocs = exports.indexInformation = void 0;\nasync function indexInformation(db, name, options) {\n    if (options == null) {\n        options = {};\n    }\n    // If we specified full information\n    const full = options.full == null ? false : options.full;\n    // Get the list of indexes of the specified collection\n    const indexes = await db.collection(name).listIndexes(options).toArray();\n    if (full)\n        return indexes;\n    const info = {};\n    for (const index of indexes) {\n        info[index.name] = Object.entries(index.key);\n    }\n    return info;\n}\nexports.indexInformation = indexInformation;\nfunction prepareDocs(coll, docs, options) {\n    const forceServerObjectId = typeof options.forceServerObjectId === 'boolean'\n        ? options.forceServerObjectId\n        : coll.s.db.options?.forceServerObjectId;\n    // no need to modify the docs if server sets the ObjectId\n    if (forceServerObjectId === true) {\n        return docs;\n    }\n    return docs.map(doc => {\n        if (doc._id == null) {\n            doc._id = coll.s.pkFactory.createPk();\n        }\n        return doc;\n    });\n}\nexports.prepareDocs = prepareDocs;\n//# sourceMappingURL=common_functions.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/common_functions.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/count.js":
/*!******************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/count.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CountOperation = void 0;\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass CountOperation extends command_1.CommandOperation {\n    constructor(namespace, filter, options) {\n        super({ s: { namespace: namespace } }, options);\n        this.options = options;\n        this.collectionName = namespace.collection;\n        this.query = filter;\n    }\n    async execute(server, session) {\n        const options = this.options;\n        const cmd = {\n            count: this.collectionName,\n            query: this.query\n        };\n        if (typeof options.limit === 'number') {\n            cmd.limit = options.limit;\n        }\n        if (typeof options.skip === 'number') {\n            cmd.skip = options.skip;\n        }\n        if (options.hint != null) {\n            cmd.hint = options.hint;\n        }\n        if (typeof options.maxTimeMS === 'number') {\n            cmd.maxTimeMS = options.maxTimeMS;\n        }\n        const result = await super.executeCommand(server, session, cmd);\n        return result ? result.n : 0;\n    }\n}\nexports.CountOperation = CountOperation;\n(0, operation_1.defineAspects)(CountOperation, [operation_1.Aspect.READ_OPERATION, operation_1.Aspect.RETRYABLE]);\n//# sourceMappingURL=count.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/count.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/count_documents.js":
/*!****************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/count_documents.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CountDocumentsOperation = void 0;\nconst aggregate_1 = __webpack_require__(/*! ./aggregate */ \"./node_modules/mongodb/lib/operations/aggregate.js\");\n/** @internal */\nclass CountDocumentsOperation extends aggregate_1.AggregateOperation {\n    constructor(collection, query, options) {\n        const pipeline = [];\n        pipeline.push({ $match: query });\n        if (typeof options.skip === 'number') {\n            pipeline.push({ $skip: options.skip });\n        }\n        if (typeof options.limit === 'number') {\n            pipeline.push({ $limit: options.limit });\n        }\n        pipeline.push({ $group: { _id: 1, n: { $sum: 1 } } });\n        super(collection.s.namespace, pipeline, options);\n    }\n    async execute(server, session) {\n        const result = await super.execute(server, session);\n        // NOTE: We're avoiding creating a cursor here to reduce the callstack.\n        const response = result;\n        if (response.cursor == null || response.cursor.firstBatch == null) {\n            return 0;\n        }\n        const docs = response.cursor.firstBatch;\n        return docs.length ? docs[0].n : 0;\n    }\n}\nexports.CountDocumentsOperation = CountDocumentsOperation;\n//# sourceMappingURL=count_documents.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/count_documents.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/create_collection.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/create_collection.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CreateCollectionOperation = void 0;\nconst constants_1 = __webpack_require__(/*! ../cmap/wire_protocol/constants */ \"./node_modules/mongodb/lib/cmap/wire_protocol/constants.js\");\nconst collection_1 = __webpack_require__(/*! ../collection */ \"./node_modules/mongodb/lib/collection.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst indexes_1 = __webpack_require__(/*! ./indexes */ \"./node_modules/mongodb/lib/operations/indexes.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\nconst ILLEGAL_COMMAND_FIELDS = new Set([\n    'w',\n    'wtimeout',\n    'j',\n    'fsync',\n    'autoIndexId',\n    'pkFactory',\n    'raw',\n    'readPreference',\n    'session',\n    'readConcern',\n    'writeConcern',\n    'raw',\n    'fieldsAsRaw',\n    'useBigInt64',\n    'promoteLongs',\n    'promoteValues',\n    'promoteBuffers',\n    'bsonRegExp',\n    'serializeFunctions',\n    'ignoreUndefined',\n    'enableUtf8Validation'\n]);\n/* @internal */\nconst INVALID_QE_VERSION = 'Driver support of Queryable Encryption is incompatible with server. Upgrade server to use Queryable Encryption.';\n/** @internal */\nclass CreateCollectionOperation extends command_1.CommandOperation {\n    constructor(db, name, options = {}) {\n        super(db, options);\n        this.options = options;\n        this.db = db;\n        this.name = name;\n    }\n    async execute(server, session) {\n        const db = this.db;\n        const name = this.name;\n        const options = this.options;\n        const encryptedFields = options.encryptedFields ??\n            db.client.options.autoEncryption?.encryptedFieldsMap?.[`${db.databaseName}.${name}`];\n        if (encryptedFields) {\n            // Creating a QE collection required min server of 7.0.0\n            // TODO(NODE-5353): Get wire version information from connection.\n            if (!server.loadBalanced &&\n                server.description.maxWireVersion < constants_1.MIN_SUPPORTED_QE_WIRE_VERSION) {\n                throw new error_1.MongoCompatibilityError(`${INVALID_QE_VERSION} The minimum server version required is ${constants_1.MIN_SUPPORTED_QE_SERVER_VERSION}`);\n            }\n            // Create auxilliary collections for queryable encryption support.\n            const escCollection = encryptedFields.escCollection ?? `enxcol_.${name}.esc`;\n            const ecocCollection = encryptedFields.ecocCollection ?? `enxcol_.${name}.ecoc`;\n            for (const collectionName of [escCollection, ecocCollection]) {\n                const createOp = new CreateCollectionOperation(db, collectionName, {\n                    clusteredIndex: {\n                        key: { _id: 1 },\n                        unique: true\n                    }\n                });\n                await createOp.executeWithoutEncryptedFieldsCheck(server, session);\n            }\n            if (!options.encryptedFields) {\n                this.options = { ...this.options, encryptedFields };\n            }\n        }\n        const coll = await this.executeWithoutEncryptedFieldsCheck(server, session);\n        if (encryptedFields) {\n            // Create the required index for queryable encryption support.\n            const createIndexOp = new indexes_1.CreateIndexOperation(db, name, { __safeContent__: 1 }, {});\n            await createIndexOp.execute(server, session);\n        }\n        return coll;\n    }\n    async executeWithoutEncryptedFieldsCheck(server, session) {\n        const db = this.db;\n        const name = this.name;\n        const options = this.options;\n        const cmd = { create: name };\n        for (const n in options) {\n            if (options[n] != null &&\n                typeof options[n] !== 'function' &&\n                !ILLEGAL_COMMAND_FIELDS.has(n)) {\n                cmd[n] = options[n];\n            }\n        }\n        // otherwise just execute the command\n        await super.executeCommand(server, session, cmd);\n        return new collection_1.Collection(db, name, options);\n    }\n}\nexports.CreateCollectionOperation = CreateCollectionOperation;\n(0, operation_1.defineAspects)(CreateCollectionOperation, [operation_1.Aspect.WRITE_OPERATION]);\n//# sourceMappingURL=create_collection.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/create_collection.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/delete.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/delete.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.makeDeleteStatement = exports.DeleteManyOperation = exports.DeleteOneOperation = exports.DeleteOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass DeleteOperation extends command_1.CommandOperation {\n    constructor(ns, statements, options) {\n        super(undefined, options);\n        this.options = options;\n        this.ns = ns;\n        this.statements = statements;\n    }\n    get canRetryWrite() {\n        if (super.canRetryWrite === false) {\n            return false;\n        }\n        return this.statements.every(op => (op.limit != null ? op.limit > 0 : true));\n    }\n    async execute(server, session) {\n        const options = this.options ?? {};\n        const ordered = typeof options.ordered === 'boolean' ? options.ordered : true;\n        const command = {\n            delete: this.ns.collection,\n            deletes: this.statements,\n            ordered\n        };\n        if (options.let) {\n            command.let = options.let;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (options.comment !== undefined) {\n            command.comment = options.comment;\n        }\n        const unacknowledgedWrite = this.writeConcern && this.writeConcern.w === 0;\n        if (unacknowledgedWrite) {\n            if (this.statements.find((o) => o.hint)) {\n                // TODO(NODE-3541): fix error for hint with unacknowledged writes\n                throw new error_1.MongoCompatibilityError(`hint is not supported with unacknowledged writes`);\n            }\n        }\n        return super.executeCommand(server, session, command);\n    }\n}\nexports.DeleteOperation = DeleteOperation;\nclass DeleteOneOperation extends DeleteOperation {\n    constructor(collection, filter, options) {\n        super(collection.s.namespace, [makeDeleteStatement(filter, { ...options, limit: 1 })], options);\n    }\n    async execute(server, session) {\n        const res = (await super.execute(server, session));\n        if (this.explain)\n            return res;\n        if (res.code)\n            throw new error_1.MongoServerError(res);\n        if (res.writeErrors)\n            throw new error_1.MongoServerError(res.writeErrors[0]);\n        return {\n            acknowledged: this.writeConcern?.w !== 0,\n            deletedCount: res.n\n        };\n    }\n}\nexports.DeleteOneOperation = DeleteOneOperation;\nclass DeleteManyOperation extends DeleteOperation {\n    constructor(collection, filter, options) {\n        super(collection.s.namespace, [makeDeleteStatement(filter, options)], options);\n    }\n    async execute(server, session) {\n        const res = (await super.execute(server, session));\n        if (this.explain)\n            return res;\n        if (res.code)\n            throw new error_1.MongoServerError(res);\n        if (res.writeErrors)\n            throw new error_1.MongoServerError(res.writeErrors[0]);\n        return {\n            acknowledged: this.writeConcern?.w !== 0,\n            deletedCount: res.n\n        };\n    }\n}\nexports.DeleteManyOperation = DeleteManyOperation;\nfunction makeDeleteStatement(filter, options) {\n    const op = {\n        q: filter,\n        limit: typeof options.limit === 'number' ? options.limit : 0\n    };\n    if (options.collation) {\n        op.collation = options.collation;\n    }\n    if (options.hint) {\n        op.hint = options.hint;\n    }\n    return op;\n}\nexports.makeDeleteStatement = makeDeleteStatement;\n(0, operation_1.defineAspects)(DeleteOperation, [operation_1.Aspect.RETRYABLE, operation_1.Aspect.WRITE_OPERATION]);\n(0, operation_1.defineAspects)(DeleteOneOperation, [\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.WRITE_OPERATION,\n    operation_1.Aspect.EXPLAINABLE,\n    operation_1.Aspect.SKIP_COLLATION\n]);\n(0, operation_1.defineAspects)(DeleteManyOperation, [\n    operation_1.Aspect.WRITE_OPERATION,\n    operation_1.Aspect.EXPLAINABLE,\n    operation_1.Aspect.SKIP_COLLATION\n]);\n//# sourceMappingURL=delete.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/delete.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/distinct.js":
/*!*********************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/distinct.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DistinctOperation = void 0;\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/**\n * Return a list of distinct values for the given key across a collection.\n * @internal\n */\nclass DistinctOperation extends command_1.CommandOperation {\n    /**\n     * Construct a Distinct operation.\n     *\n     * @param collection - Collection instance.\n     * @param key - Field of the document to find distinct values for.\n     * @param query - The query for filtering the set of documents to which we apply the distinct filter.\n     * @param options - Optional settings. See Collection.prototype.distinct for a list of options.\n     */\n    constructor(collection, key, query, options) {\n        super(collection, options);\n        this.options = options ?? {};\n        this.collection = collection;\n        this.key = key;\n        this.query = query;\n    }\n    async execute(server, session) {\n        const coll = this.collection;\n        const key = this.key;\n        const query = this.query;\n        const options = this.options;\n        // Distinct command\n        const cmd = {\n            distinct: coll.collectionName,\n            key: key,\n            query: query\n        };\n        // Add maxTimeMS if defined\n        if (typeof options.maxTimeMS === 'number') {\n            cmd.maxTimeMS = options.maxTimeMS;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (typeof options.comment !== 'undefined') {\n            cmd.comment = options.comment;\n        }\n        // Do we have a readConcern specified\n        (0, utils_1.decorateWithReadConcern)(cmd, coll, options);\n        // Have we specified collation\n        (0, utils_1.decorateWithCollation)(cmd, coll, options);\n        const result = await super.executeCommand(server, session, cmd);\n        return this.explain ? result : result.values;\n    }\n}\nexports.DistinctOperation = DistinctOperation;\n(0, operation_1.defineAspects)(DistinctOperation, [operation_1.Aspect.READ_OPERATION, operation_1.Aspect.RETRYABLE, operation_1.Aspect.EXPLAINABLE]);\n//# sourceMappingURL=distinct.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/distinct.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/drop.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/drop.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DropDatabaseOperation = exports.DropCollectionOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass DropCollectionOperation extends command_1.CommandOperation {\n    constructor(db, name, options = {}) {\n        super(db, options);\n        this.db = db;\n        this.options = options;\n        this.name = name;\n    }\n    async execute(server, session) {\n        const db = this.db;\n        const options = this.options;\n        const name = this.name;\n        const encryptedFieldsMap = db.client.options.autoEncryption?.encryptedFieldsMap;\n        let encryptedFields = options.encryptedFields ?? encryptedFieldsMap?.[`${db.databaseName}.${name}`];\n        if (!encryptedFields && encryptedFieldsMap) {\n            // If the MongoClient was configured with an encryptedFieldsMap,\n            // and no encryptedFields config was available in it or explicitly\n            // passed as an argument, the spec tells us to look one up using\n            // listCollections().\n            const listCollectionsResult = await db\n                .listCollections({ name }, { nameOnly: false })\n                .toArray();\n            encryptedFields = listCollectionsResult?.[0]?.options?.encryptedFields;\n        }\n        if (encryptedFields) {\n            const escCollection = encryptedFields.escCollection || `enxcol_.${name}.esc`;\n            const ecocCollection = encryptedFields.ecocCollection || `enxcol_.${name}.ecoc`;\n            for (const collectionName of [escCollection, ecocCollection]) {\n                // Drop auxilliary collections, ignoring potential NamespaceNotFound errors.\n                const dropOp = new DropCollectionOperation(db, collectionName);\n                try {\n                    await dropOp.executeWithoutEncryptedFieldsCheck(server, session);\n                }\n                catch (err) {\n                    if (!(err instanceof error_1.MongoServerError) ||\n                        err.code !== error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n                        throw err;\n                    }\n                }\n            }\n        }\n        return this.executeWithoutEncryptedFieldsCheck(server, session);\n    }\n    async executeWithoutEncryptedFieldsCheck(server, session) {\n        await super.executeCommand(server, session, { drop: this.name });\n        return true;\n    }\n}\nexports.DropCollectionOperation = DropCollectionOperation;\n/** @internal */\nclass DropDatabaseOperation extends command_1.CommandOperation {\n    constructor(db, options) {\n        super(db, options);\n        this.options = options;\n    }\n    async execute(server, session) {\n        await super.executeCommand(server, session, { dropDatabase: 1 });\n        return true;\n    }\n}\nexports.DropDatabaseOperation = DropDatabaseOperation;\n(0, operation_1.defineAspects)(DropCollectionOperation, [operation_1.Aspect.WRITE_OPERATION]);\n(0, operation_1.defineAspects)(DropDatabaseOperation, [operation_1.Aspect.WRITE_OPERATION]);\n//# sourceMappingURL=drop.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/drop.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/estimated_document_count.js":
/*!*************************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/estimated_document_count.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.EstimatedDocumentCountOperation = void 0;\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass EstimatedDocumentCountOperation extends command_1.CommandOperation {\n    constructor(collection, options = {}) {\n        super(collection, options);\n        this.options = options;\n        this.collectionName = collection.collectionName;\n    }\n    async execute(server, session) {\n        const cmd = { count: this.collectionName };\n        if (typeof this.options.maxTimeMS === 'number') {\n            cmd.maxTimeMS = this.options.maxTimeMS;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (this.options.comment !== undefined) {\n            cmd.comment = this.options.comment;\n        }\n        const response = await super.executeCommand(server, session, cmd);\n        return response?.n || 0;\n    }\n}\nexports.EstimatedDocumentCountOperation = EstimatedDocumentCountOperation;\n(0, operation_1.defineAspects)(EstimatedDocumentCountOperation, [\n    operation_1.Aspect.READ_OPERATION,\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.CURSOR_CREATING\n]);\n//# sourceMappingURL=estimated_document_count.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/estimated_document_count.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/execute_operation.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/execute_operation.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.executeOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_preference_1 = __webpack_require__(/*! ../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst server_selection_1 = __webpack_require__(/*! ../sdam/server_selection */ \"./node_modules/mongodb/lib/sdam/server_selection.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\nconst MMAPv1_RETRY_WRITES_ERROR_CODE = error_1.MONGODB_ERROR_CODES.IllegalOperation;\nconst MMAPv1_RETRY_WRITES_ERROR_MESSAGE = 'This MongoDB deployment does not support retryable writes. Please add retryWrites=false to your connection string.';\nfunction executeOperation(client, operation, callback) {\n    return (0, utils_1.maybeCallback)(() => executeOperationAsync(client, operation), callback);\n}\nexports.executeOperation = executeOperation;\nasync function executeOperationAsync(client, operation) {\n    if (!(operation instanceof operation_1.AbstractOperation)) {\n        // TODO(NODE-3483): Extend MongoRuntimeError\n        throw new error_1.MongoRuntimeError('This method requires a valid operation instance');\n    }\n    if (client.topology == null) {\n        // Auto connect on operation\n        if (client.s.hasBeenClosed) {\n            throw new error_1.MongoNotConnectedError('Client must be connected before running operations');\n        }\n        client.s.options[Symbol.for('@@mdb.skipPingOnConnect')] = true;\n        try {\n            await client.connect();\n        }\n        finally {\n            delete client.s.options[Symbol.for('@@mdb.skipPingOnConnect')];\n        }\n    }\n    const { topology } = client;\n    if (topology == null) {\n        throw new error_1.MongoRuntimeError('client.connect did not create a topology but also did not throw');\n    }\n    // The driver sessions spec mandates that we implicitly create sessions for operations\n    // that are not explicitly provided with a session.\n    let session = operation.session;\n    let owner;\n    if (session == null) {\n        owner = Symbol();\n        session = client.startSession({ owner, explicit: false });\n    }\n    else if (session.hasEnded) {\n        throw new error_1.MongoExpiredSessionError('Use of expired sessions is not permitted');\n    }\n    else if (session.snapshotEnabled && !topology.capabilities.supportsSnapshotReads) {\n        throw new error_1.MongoCompatibilityError('Snapshot reads require MongoDB 5.0 or later');\n    }\n    else if (session.client !== client) {\n        throw new error_1.MongoInvalidArgumentError('ClientSession must be from the same MongoClient');\n    }\n    const readPreference = operation.readPreference ?? read_preference_1.ReadPreference.primary;\n    const inTransaction = !!session?.inTransaction();\n    if (inTransaction && !readPreference.equals(read_preference_1.ReadPreference.primary)) {\n        throw new error_1.MongoTransactionError(`Read preference in a transaction must be primary, not: ${readPreference.mode}`);\n    }\n    if (session?.isPinned && session.transaction.isCommitted && !operation.bypassPinningCheck) {\n        session.unpin();\n    }\n    let selector;\n    if (operation.hasAspect(operation_1.Aspect.MUST_SELECT_SAME_SERVER)) {\n        // GetMore and KillCursor operations must always select the same server, but run through\n        // server selection to potentially force monitor checks if the server is\n        // in an unknown state.\n        selector = (0, server_selection_1.sameServerSelector)(operation.server?.description);\n    }\n    else if (operation.trySecondaryWrite) {\n        // If operation should try to write to secondary use the custom server selector\n        // otherwise provide the read preference.\n        selector = (0, server_selection_1.secondaryWritableServerSelector)(topology.commonWireVersion, readPreference);\n    }\n    else {\n        selector = readPreference;\n    }\n    const server = await topology.selectServerAsync(selector, { session });\n    if (session == null) {\n        // No session also means it is not retryable, early exit\n        return operation.execute(server, undefined);\n    }\n    if (!operation.hasAspect(operation_1.Aspect.RETRYABLE)) {\n        // non-retryable operation, early exit\n        try {\n            return await operation.execute(server, session);\n        }\n        finally {\n            if (session?.owner != null && session.owner === owner) {\n                await session.endSession().catch(() => null);\n            }\n        }\n    }\n    const willRetryRead = topology.s.options.retryReads && !inTransaction && operation.canRetryRead;\n    const willRetryWrite = topology.s.options.retryWrites &&\n        !inTransaction &&\n        (0, utils_1.supportsRetryableWrites)(server) &&\n        operation.canRetryWrite;\n    const hasReadAspect = operation.hasAspect(operation_1.Aspect.READ_OPERATION);\n    const hasWriteAspect = operation.hasAspect(operation_1.Aspect.WRITE_OPERATION);\n    const willRetry = (hasReadAspect && willRetryRead) || (hasWriteAspect && willRetryWrite);\n    if (hasWriteAspect && willRetryWrite) {\n        operation.options.willRetryWrite = true;\n        session.incrementTransactionNumber();\n    }\n    try {\n        return await operation.execute(server, session);\n    }\n    catch (operationError) {\n        if (willRetry && operationError instanceof error_1.MongoError) {\n            return await retryOperation(operation, operationError, {\n                session,\n                topology,\n                selector\n            });\n        }\n        throw operationError;\n    }\n    finally {\n        if (session?.owner != null && session.owner === owner) {\n            await session.endSession().catch(() => null);\n        }\n    }\n}\nasync function retryOperation(operation, originalError, { session, topology, selector }) {\n    const isWriteOperation = operation.hasAspect(operation_1.Aspect.WRITE_OPERATION);\n    const isReadOperation = operation.hasAspect(operation_1.Aspect.READ_OPERATION);\n    if (isWriteOperation && originalError.code === MMAPv1_RETRY_WRITES_ERROR_CODE) {\n        throw new error_1.MongoServerError({\n            message: MMAPv1_RETRY_WRITES_ERROR_MESSAGE,\n            errmsg: MMAPv1_RETRY_WRITES_ERROR_MESSAGE,\n            originalError\n        });\n    }\n    if (isWriteOperation && !(0, error_1.isRetryableWriteError)(originalError)) {\n        throw originalError;\n    }\n    if (isReadOperation && !(0, error_1.isRetryableReadError)(originalError)) {\n        throw originalError;\n    }\n    if (originalError instanceof error_1.MongoNetworkError &&\n        session.isPinned &&\n        !session.inTransaction() &&\n        operation.hasAspect(operation_1.Aspect.CURSOR_CREATING)) {\n        // If we have a cursor and the initial command fails with a network error,\n        // we can retry it on another connection. So we need to check it back in, clear the\n        // pool for the service id, and retry again.\n        session.unpin({ force: true, forceClear: true });\n    }\n    // select a new server, and attempt to retry the operation\n    const server = await topology.selectServerAsync(selector, { session });\n    if (isWriteOperation && !(0, utils_1.supportsRetryableWrites)(server)) {\n        throw new error_1.MongoUnexpectedServerResponseError('Selected server does not support retryable writes');\n    }\n    try {\n        return await operation.execute(server, session);\n    }\n    catch (retryError) {\n        if (retryError instanceof error_1.MongoError &&\n            retryError.hasErrorLabel(error_1.MongoErrorLabel.NoWritesPerformed)) {\n            throw originalError;\n        }\n        throw retryError;\n    }\n}\n//# sourceMappingURL=execute_operation.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/execute_operation.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/find.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/find.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.FindOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_concern_1 = __webpack_require__(/*! ../read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst sort_1 = __webpack_require__(/*! ../sort */ \"./node_modules/mongodb/lib/sort.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass FindOperation extends command_1.CommandOperation {\n    constructor(collection, ns, filter = {}, options = {}) {\n        super(collection, options);\n        this.options = { ...options };\n        delete this.options.writeConcern;\n        this.ns = ns;\n        if (typeof filter !== 'object' || Array.isArray(filter)) {\n            throw new error_1.MongoInvalidArgumentError('Query filter must be a plain object or ObjectId');\n        }\n        // special case passing in an ObjectId as a filter\n        this.filter = filter != null && filter._bsontype === 'ObjectId' ? { _id: filter } : filter;\n    }\n    async execute(server, session) {\n        this.server = server;\n        const options = this.options;\n        let findCommand = makeFindCommand(this.ns, this.filter, options);\n        if (this.explain) {\n            findCommand = (0, utils_1.decorateWithExplain)(findCommand, this.explain);\n        }\n        return server.commandAsync(this.ns, findCommand, {\n            ...this.options,\n            ...this.bsonOptions,\n            documentsReturnedIn: 'firstBatch',\n            session\n        });\n    }\n}\nexports.FindOperation = FindOperation;\nfunction makeFindCommand(ns, filter, options) {\n    const findCommand = {\n        find: ns.collection,\n        filter\n    };\n    if (options.sort) {\n        findCommand.sort = (0, sort_1.formatSort)(options.sort);\n    }\n    if (options.projection) {\n        let projection = options.projection;\n        if (projection && Array.isArray(projection)) {\n            projection = projection.length\n                ? projection.reduce((result, field) => {\n                    result[field] = 1;\n                    return result;\n                }, {})\n                : { _id: 1 };\n        }\n        findCommand.projection = projection;\n    }\n    if (options.hint) {\n        findCommand.hint = (0, utils_1.normalizeHintField)(options.hint);\n    }\n    if (typeof options.skip === 'number') {\n        findCommand.skip = options.skip;\n    }\n    if (typeof options.limit === 'number') {\n        if (options.limit < 0) {\n            findCommand.limit = -options.limit;\n            findCommand.singleBatch = true;\n        }\n        else {\n            findCommand.limit = options.limit;\n        }\n    }\n    if (typeof options.batchSize === 'number') {\n        if (options.batchSize < 0) {\n            if (options.limit &&\n                options.limit !== 0 &&\n                Math.abs(options.batchSize) < Math.abs(options.limit)) {\n                findCommand.limit = -options.batchSize;\n            }\n            findCommand.singleBatch = true;\n        }\n        else {\n            findCommand.batchSize = options.batchSize;\n        }\n    }\n    if (typeof options.singleBatch === 'boolean') {\n        findCommand.singleBatch = options.singleBatch;\n    }\n    // we check for undefined specifically here to allow falsy values\n    // eslint-disable-next-line no-restricted-syntax\n    if (options.comment !== undefined) {\n        findCommand.comment = options.comment;\n    }\n    if (typeof options.maxTimeMS === 'number') {\n        findCommand.maxTimeMS = options.maxTimeMS;\n    }\n    const readConcern = read_concern_1.ReadConcern.fromOptions(options);\n    if (readConcern) {\n        findCommand.readConcern = readConcern.toJSON();\n    }\n    if (options.max) {\n        findCommand.max = options.max;\n    }\n    if (options.min) {\n        findCommand.min = options.min;\n    }\n    if (typeof options.returnKey === 'boolean') {\n        findCommand.returnKey = options.returnKey;\n    }\n    if (typeof options.showRecordId === 'boolean') {\n        findCommand.showRecordId = options.showRecordId;\n    }\n    if (typeof options.tailable === 'boolean') {\n        findCommand.tailable = options.tailable;\n    }\n    if (typeof options.oplogReplay === 'boolean') {\n        findCommand.oplogReplay = options.oplogReplay;\n    }\n    if (typeof options.timeout === 'boolean') {\n        findCommand.noCursorTimeout = !options.timeout;\n    }\n    else if (typeof options.noCursorTimeout === 'boolean') {\n        findCommand.noCursorTimeout = options.noCursorTimeout;\n    }\n    if (typeof options.awaitData === 'boolean') {\n        findCommand.awaitData = options.awaitData;\n    }\n    if (typeof options.allowPartialResults === 'boolean') {\n        findCommand.allowPartialResults = options.allowPartialResults;\n    }\n    if (options.collation) {\n        findCommand.collation = options.collation;\n    }\n    if (typeof options.allowDiskUse === 'boolean') {\n        findCommand.allowDiskUse = options.allowDiskUse;\n    }\n    if (options.let) {\n        findCommand.let = options.let;\n    }\n    return findCommand;\n}\n(0, operation_1.defineAspects)(FindOperation, [\n    operation_1.Aspect.READ_OPERATION,\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.EXPLAINABLE,\n    operation_1.Aspect.CURSOR_CREATING\n]);\n//# sourceMappingURL=find.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/find.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/find_and_modify.js":
/*!****************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/find_and_modify.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.FindOneAndUpdateOperation = exports.FindOneAndReplaceOperation = exports.FindOneAndDeleteOperation = exports.ReturnDocument = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_preference_1 = __webpack_require__(/*! ../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst sort_1 = __webpack_require__(/*! ../sort */ \"./node_modules/mongodb/lib/sort.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @public */\nexports.ReturnDocument = Object.freeze({\n    BEFORE: 'before',\n    AFTER: 'after'\n});\nfunction configureFindAndModifyCmdBaseUpdateOpts(cmdBase, options) {\n    cmdBase.new = options.returnDocument === exports.ReturnDocument.AFTER;\n    cmdBase.upsert = options.upsert === true;\n    if (options.bypassDocumentValidation === true) {\n        cmdBase.bypassDocumentValidation = options.bypassDocumentValidation;\n    }\n    return cmdBase;\n}\n/** @internal */\nclass FindAndModifyOperation extends command_1.CommandOperation {\n    constructor(collection, query, options) {\n        super(collection, options);\n        this.options = options ?? {};\n        this.cmdBase = {\n            remove: false,\n            new: false,\n            upsert: false\n        };\n        options.includeResultMetadata ??= false;\n        const sort = (0, sort_1.formatSort)(options.sort);\n        if (sort) {\n            this.cmdBase.sort = sort;\n        }\n        if (options.projection) {\n            this.cmdBase.fields = options.projection;\n        }\n        if (options.maxTimeMS) {\n            this.cmdBase.maxTimeMS = options.maxTimeMS;\n        }\n        // Decorate the findAndModify command with the write Concern\n        if (options.writeConcern) {\n            this.cmdBase.writeConcern = options.writeConcern;\n        }\n        if (options.let) {\n            this.cmdBase.let = options.let;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (options.comment !== undefined) {\n            this.cmdBase.comment = options.comment;\n        }\n        // force primary read preference\n        this.readPreference = read_preference_1.ReadPreference.primary;\n        this.collection = collection;\n        this.query = query;\n    }\n    async execute(server, session) {\n        const coll = this.collection;\n        const query = this.query;\n        const options = { ...this.options, ...this.bsonOptions };\n        // Create findAndModify command object\n        const cmd = {\n            findAndModify: coll.collectionName,\n            query: query,\n            ...this.cmdBase\n        };\n        // Have we specified collation\n        try {\n            (0, utils_1.decorateWithCollation)(cmd, coll, options);\n        }\n        catch (err) {\n            return err;\n        }\n        if (options.hint) {\n            // TODO: once this method becomes a CommandOperation we will have the server\n            // in place to check.\n            const unacknowledgedWrite = this.writeConcern?.w === 0;\n            if (unacknowledgedWrite || (0, utils_1.maxWireVersion)(server) < 8) {\n                throw new error_1.MongoCompatibilityError('The current topology does not support a hint on findAndModify commands');\n            }\n            cmd.hint = options.hint;\n        }\n        // Execute the command\n        const result = await super.executeCommand(server, session, cmd);\n        return options.includeResultMetadata ? result : result.value ?? null;\n    }\n}\n/** @internal */\nclass FindOneAndDeleteOperation extends FindAndModifyOperation {\n    constructor(collection, filter, options) {\n        // Basic validation\n        if (filter == null || typeof filter !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('Argument \"filter\" must be an object');\n        }\n        super(collection, filter, options);\n        this.cmdBase.remove = true;\n    }\n}\nexports.FindOneAndDeleteOperation = FindOneAndDeleteOperation;\n/** @internal */\nclass FindOneAndReplaceOperation extends FindAndModifyOperation {\n    constructor(collection, filter, replacement, options) {\n        if (filter == null || typeof filter !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('Argument \"filter\" must be an object');\n        }\n        if (replacement == null || typeof replacement !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('Argument \"replacement\" must be an object');\n        }\n        if ((0, utils_1.hasAtomicOperators)(replacement)) {\n            throw new error_1.MongoInvalidArgumentError('Replacement document must not contain atomic operators');\n        }\n        super(collection, filter, options);\n        this.cmdBase.update = replacement;\n        configureFindAndModifyCmdBaseUpdateOpts(this.cmdBase, options);\n    }\n}\nexports.FindOneAndReplaceOperation = FindOneAndReplaceOperation;\n/** @internal */\nclass FindOneAndUpdateOperation extends FindAndModifyOperation {\n    constructor(collection, filter, update, options) {\n        if (filter == null || typeof filter !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('Argument \"filter\" must be an object');\n        }\n        if (update == null || typeof update !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('Argument \"update\" must be an object');\n        }\n        if (!(0, utils_1.hasAtomicOperators)(update)) {\n            throw new error_1.MongoInvalidArgumentError('Update document requires atomic operators');\n        }\n        super(collection, filter, options);\n        this.cmdBase.update = update;\n        configureFindAndModifyCmdBaseUpdateOpts(this.cmdBase, options);\n        if (options.arrayFilters) {\n            this.cmdBase.arrayFilters = options.arrayFilters;\n        }\n    }\n}\nexports.FindOneAndUpdateOperation = FindOneAndUpdateOperation;\n(0, operation_1.defineAspects)(FindAndModifyOperation, [\n    operation_1.Aspect.WRITE_OPERATION,\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.EXPLAINABLE\n]);\n//# sourceMappingURL=find_and_modify.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/find_and_modify.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/get_more.js":
/*!*********************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/get_more.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.GetMoreOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass GetMoreOperation extends operation_1.AbstractOperation {\n    constructor(ns, cursorId, server, options) {\n        super(options);\n        this.options = options;\n        this.ns = ns;\n        this.cursorId = cursorId;\n        this.server = server;\n    }\n    /**\n     * Although there is a server already associated with the get more operation, the signature\n     * for execute passes a server so we will just use that one.\n     */\n    async execute(server, _session) {\n        if (server !== this.server) {\n            throw new error_1.MongoRuntimeError('Getmore must run on the same server operation began on');\n        }\n        if (this.cursorId == null || this.cursorId.isZero()) {\n            throw new error_1.MongoRuntimeError('Unable to iterate cursor with no id');\n        }\n        const collection = this.ns.collection;\n        if (collection == null) {\n            // Cursors should have adopted the namespace returned by MongoDB\n            // which should always defined a collection name (even a pseudo one, ex. db.aggregate())\n            throw new error_1.MongoRuntimeError('A collection name must be determined before getMore');\n        }\n        const getMoreCmd = {\n            getMore: this.cursorId,\n            collection\n        };\n        if (typeof this.options.batchSize === 'number') {\n            getMoreCmd.batchSize = Math.abs(this.options.batchSize);\n        }\n        if (typeof this.options.maxAwaitTimeMS === 'number') {\n            getMoreCmd.maxTimeMS = this.options.maxAwaitTimeMS;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (this.options.comment !== undefined && (0, utils_1.maxWireVersion)(server) >= 9) {\n            getMoreCmd.comment = this.options.comment;\n        }\n        const commandOptions = {\n            returnFieldSelector: null,\n            documentsReturnedIn: 'nextBatch',\n            ...this.options\n        };\n        return server.commandAsync(this.ns, getMoreCmd, commandOptions);\n    }\n}\nexports.GetMoreOperation = GetMoreOperation;\n(0, operation_1.defineAspects)(GetMoreOperation, [operation_1.Aspect.READ_OPERATION, operation_1.Aspect.MUST_SELECT_SAME_SERVER]);\n//# sourceMappingURL=get_more.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/get_more.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/indexes.js":
/*!********************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/indexes.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.IndexInformationOperation = exports.IndexExistsOperation = exports.ListIndexesOperation = exports.DropIndexOperation = exports.EnsureIndexOperation = exports.CreateIndexOperation = exports.CreateIndexesOperation = exports.IndexesOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_preference_1 = __webpack_require__(/*! ../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst common_functions_1 = __webpack_require__(/*! ./common_functions */ \"./node_modules/mongodb/lib/operations/common_functions.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\nconst VALID_INDEX_OPTIONS = new Set([\n    'background',\n    'unique',\n    'name',\n    'partialFilterExpression',\n    'sparse',\n    'hidden',\n    'expireAfterSeconds',\n    'storageEngine',\n    'collation',\n    'version',\n    // text indexes\n    'weights',\n    'default_language',\n    'language_override',\n    'textIndexVersion',\n    // 2d-sphere indexes\n    '2dsphereIndexVersion',\n    // 2d indexes\n    'bits',\n    'min',\n    'max',\n    // geoHaystack Indexes\n    'bucketSize',\n    // wildcard indexes\n    'wildcardProjection'\n]);\nfunction isIndexDirection(x) {\n    return (typeof x === 'number' || x === '2d' || x === '2dsphere' || x === 'text' || x === 'geoHaystack');\n}\nfunction isSingleIndexTuple(t) {\n    return Array.isArray(t) && t.length === 2 && isIndexDirection(t[1]);\n}\nfunction makeIndexSpec(indexSpec, options) {\n    const key = new Map();\n    const indexSpecs = !Array.isArray(indexSpec) || isSingleIndexTuple(indexSpec) ? [indexSpec] : indexSpec;\n    // Iterate through array and handle different types\n    for (const spec of indexSpecs) {\n        if (typeof spec === 'string') {\n            key.set(spec, 1);\n        }\n        else if (Array.isArray(spec)) {\n            key.set(spec[0], spec[1] ?? 1);\n        }\n        else if (spec instanceof Map) {\n            for (const [property, value] of spec) {\n                key.set(property, value);\n            }\n        }\n        else if ((0, utils_1.isObject)(spec)) {\n            for (const [property, value] of Object.entries(spec)) {\n                key.set(property, value);\n            }\n        }\n    }\n    return { ...options, key };\n}\n/** @internal */\nclass IndexesOperation extends operation_1.AbstractOperation {\n    constructor(collection, options) {\n        super(options);\n        this.options = options;\n        this.collection = collection;\n    }\n    async execute(_server, session) {\n        const coll = this.collection;\n        const options = this.options;\n        return (0, common_functions_1.indexInformation)(coll.s.db, coll.collectionName, {\n            full: true,\n            ...options,\n            readPreference: this.readPreference,\n            session\n        });\n    }\n}\nexports.IndexesOperation = IndexesOperation;\n/** @internal */\nclass CreateIndexesOperation extends command_1.CommandOperation {\n    constructor(parent, collectionName, indexes, options) {\n        super(parent, options);\n        this.options = options ?? {};\n        this.collectionName = collectionName;\n        this.indexes = indexes.map(userIndex => {\n            // Ensure the key is a Map to preserve index key ordering\n            const key = userIndex.key instanceof Map ? userIndex.key : new Map(Object.entries(userIndex.key));\n            const name = userIndex.name != null ? userIndex.name : Array.from(key).flat().join('_');\n            const validIndexOptions = Object.fromEntries(Object.entries({ ...userIndex }).filter(([optionName]) => VALID_INDEX_OPTIONS.has(optionName)));\n            return {\n                ...validIndexOptions,\n                name,\n                key\n            };\n        });\n    }\n    async execute(server, session) {\n        const options = this.options;\n        const indexes = this.indexes;\n        const serverWireVersion = (0, utils_1.maxWireVersion)(server);\n        const cmd = { createIndexes: this.collectionName, indexes };\n        if (options.commitQuorum != null) {\n            if (serverWireVersion < 9) {\n                throw new error_1.MongoCompatibilityError('Option `commitQuorum` for `createIndexes` not supported on servers < 4.4');\n            }\n            cmd.commitQuorum = options.commitQuorum;\n        }\n        // collation is set on each index, it should not be defined at the root\n        this.options.collation = undefined;\n        await super.executeCommand(server, session, cmd);\n        const indexNames = indexes.map(index => index.name || '');\n        return indexNames;\n    }\n}\nexports.CreateIndexesOperation = CreateIndexesOperation;\n/** @internal */\nclass CreateIndexOperation extends CreateIndexesOperation {\n    constructor(parent, collectionName, indexSpec, options) {\n        super(parent, collectionName, [makeIndexSpec(indexSpec, options)], options);\n    }\n    async execute(server, session) {\n        const indexNames = await super.execute(server, session);\n        return indexNames[0];\n    }\n}\nexports.CreateIndexOperation = CreateIndexOperation;\n/** @internal */\nclass EnsureIndexOperation extends CreateIndexOperation {\n    constructor(db, collectionName, indexSpec, options) {\n        super(db, collectionName, indexSpec, options);\n        this.readPreference = read_preference_1.ReadPreference.primary;\n        this.db = db;\n        this.collectionName = collectionName;\n    }\n    async execute(server, session) {\n        const indexName = this.indexes[0].name;\n        const indexes = await this.db\n            .collection(this.collectionName)\n            .listIndexes({ session })\n            .toArray()\n            .catch(error => {\n            if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound)\n                return [];\n            throw error;\n        });\n        if (indexName && indexes.some(index => index.name === indexName))\n            return indexName;\n        return super.execute(server, session);\n    }\n}\nexports.EnsureIndexOperation = EnsureIndexOperation;\n/** @internal */\nclass DropIndexOperation extends command_1.CommandOperation {\n    constructor(collection, indexName, options) {\n        super(collection, options);\n        this.options = options ?? {};\n        this.collection = collection;\n        this.indexName = indexName;\n    }\n    async execute(server, session) {\n        const cmd = { dropIndexes: this.collection.collectionName, index: this.indexName };\n        return super.executeCommand(server, session, cmd);\n    }\n}\nexports.DropIndexOperation = DropIndexOperation;\n/** @internal */\nclass ListIndexesOperation extends command_1.CommandOperation {\n    constructor(collection, options) {\n        super(collection, options);\n        this.options = { ...options };\n        delete this.options.writeConcern;\n        this.collectionNamespace = collection.s.namespace;\n    }\n    async execute(server, session) {\n        const serverWireVersion = (0, utils_1.maxWireVersion)(server);\n        const cursor = this.options.batchSize ? { batchSize: this.options.batchSize } : {};\n        const command = { listIndexes: this.collectionNamespace.collection, cursor };\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (serverWireVersion >= 9 && this.options.comment !== undefined) {\n            command.comment = this.options.comment;\n        }\n        return super.executeCommand(server, session, command);\n    }\n}\nexports.ListIndexesOperation = ListIndexesOperation;\n/** @internal */\nclass IndexExistsOperation extends operation_1.AbstractOperation {\n    constructor(collection, indexes, options) {\n        super(options);\n        this.options = options;\n        this.collection = collection;\n        this.indexes = indexes;\n    }\n    async execute(server, session) {\n        const coll = this.collection;\n        const indexes = this.indexes;\n        const info = await (0, common_functions_1.indexInformation)(coll.s.db, coll.collectionName, {\n            ...this.options,\n            readPreference: this.readPreference,\n            session\n        });\n        // Let's check for the index names\n        if (!Array.isArray(indexes))\n            return info[indexes] != null;\n        // All keys found return true\n        return indexes.every(indexName => info[indexName] != null);\n    }\n}\nexports.IndexExistsOperation = IndexExistsOperation;\n/** @internal */\nclass IndexInformationOperation extends operation_1.AbstractOperation {\n    constructor(db, name, options) {\n        super(options);\n        this.options = options ?? {};\n        this.db = db;\n        this.name = name;\n    }\n    async execute(server, session) {\n        const db = this.db;\n        const name = this.name;\n        return (0, common_functions_1.indexInformation)(db, name, {\n            ...this.options,\n            readPreference: this.readPreference,\n            session\n        });\n    }\n}\nexports.IndexInformationOperation = IndexInformationOperation;\n(0, operation_1.defineAspects)(ListIndexesOperation, [\n    operation_1.Aspect.READ_OPERATION,\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.CURSOR_CREATING\n]);\n(0, operation_1.defineAspects)(CreateIndexesOperation, [operation_1.Aspect.WRITE_OPERATION]);\n(0, operation_1.defineAspects)(CreateIndexOperation, [operation_1.Aspect.WRITE_OPERATION]);\n(0, operation_1.defineAspects)(EnsureIndexOperation, [operation_1.Aspect.WRITE_OPERATION]);\n(0, operation_1.defineAspects)(DropIndexOperation, [operation_1.Aspect.WRITE_OPERATION]);\n//# sourceMappingURL=indexes.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/indexes.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/insert.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/insert.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.InsertManyOperation = exports.InsertOneOperation = exports.InsertOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst write_concern_1 = __webpack_require__(/*! ../write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\nconst bulk_write_1 = __webpack_require__(/*! ./bulk_write */ \"./node_modules/mongodb/lib/operations/bulk_write.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst common_functions_1 = __webpack_require__(/*! ./common_functions */ \"./node_modules/mongodb/lib/operations/common_functions.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass InsertOperation extends command_1.CommandOperation {\n    constructor(ns, documents, options) {\n        super(undefined, options);\n        this.options = { ...options, checkKeys: options.checkKeys ?? false };\n        this.ns = ns;\n        this.documents = documents;\n    }\n    async execute(server, session) {\n        const options = this.options ?? {};\n        const ordered = typeof options.ordered === 'boolean' ? options.ordered : true;\n        const command = {\n            insert: this.ns.collection,\n            documents: this.documents,\n            ordered\n        };\n        if (typeof options.bypassDocumentValidation === 'boolean') {\n            command.bypassDocumentValidation = options.bypassDocumentValidation;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (options.comment !== undefined) {\n            command.comment = options.comment;\n        }\n        return super.executeCommand(server, session, command);\n    }\n}\nexports.InsertOperation = InsertOperation;\nclass InsertOneOperation extends InsertOperation {\n    constructor(collection, doc, options) {\n        super(collection.s.namespace, (0, common_functions_1.prepareDocs)(collection, [doc], options), options);\n    }\n    async execute(server, session) {\n        const res = await super.execute(server, session);\n        if (res.code)\n            throw new error_1.MongoServerError(res);\n        if (res.writeErrors) {\n            // This should be a WriteError but we can't change it now because of error hierarchy\n            throw new error_1.MongoServerError(res.writeErrors[0]);\n        }\n        return {\n            acknowledged: this.writeConcern?.w !== 0,\n            insertedId: this.documents[0]._id\n        };\n    }\n}\nexports.InsertOneOperation = InsertOneOperation;\n/** @internal */\nclass InsertManyOperation extends operation_1.AbstractOperation {\n    constructor(collection, docs, options) {\n        super(options);\n        if (!Array.isArray(docs)) {\n            throw new error_1.MongoInvalidArgumentError('Argument \"docs\" must be an array of documents');\n        }\n        this.options = options;\n        this.collection = collection;\n        this.docs = docs;\n    }\n    async execute(server, session) {\n        const coll = this.collection;\n        const options = { ...this.options, ...this.bsonOptions, readPreference: this.readPreference };\n        const writeConcern = write_concern_1.WriteConcern.fromOptions(options);\n        const bulkWriteOperation = new bulk_write_1.BulkWriteOperation(coll, (0, common_functions_1.prepareDocs)(coll, this.docs, options).map(document => ({ insertOne: { document } })), options);\n        try {\n            const res = await bulkWriteOperation.execute(server, session);\n            return {\n                acknowledged: writeConcern?.w !== 0,\n                insertedCount: res.insertedCount,\n                insertedIds: res.insertedIds\n            };\n        }\n        catch (err) {\n            if (err && err.message === 'Operation must be an object with an operation key') {\n                throw new error_1.MongoInvalidArgumentError('Collection.insertMany() cannot be called with an array that has null/undefined values');\n            }\n            throw err;\n        }\n    }\n}\nexports.InsertManyOperation = InsertManyOperation;\n(0, operation_1.defineAspects)(InsertOperation, [operation_1.Aspect.RETRYABLE, operation_1.Aspect.WRITE_OPERATION]);\n(0, operation_1.defineAspects)(InsertOneOperation, [operation_1.Aspect.RETRYABLE, operation_1.Aspect.WRITE_OPERATION]);\n(0, operation_1.defineAspects)(InsertManyOperation, [operation_1.Aspect.WRITE_OPERATION]);\n//# sourceMappingURL=insert.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/insert.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/is_capped.js":
/*!**********************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/is_capped.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.IsCappedOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass IsCappedOperation extends operation_1.AbstractOperation {\n    constructor(collection, options) {\n        super(options);\n        this.options = options;\n        this.collection = collection;\n    }\n    async execute(server, session) {\n        const coll = this.collection;\n        const [collection] = await coll.s.db\n            .listCollections({ name: coll.collectionName }, { ...this.options, nameOnly: false, readPreference: this.readPreference, session })\n            .toArray();\n        if (collection == null || collection.options == null) {\n            throw new error_1.MongoAPIError(`collection ${coll.namespace} not found`);\n        }\n        return !!collection.options?.capped;\n    }\n}\nexports.IsCappedOperation = IsCappedOperation;\n//# sourceMappingURL=is_capped.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/is_capped.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/kill_cursors.js":
/*!*************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/kill_cursors.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.KillCursorsOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\nclass KillCursorsOperation extends operation_1.AbstractOperation {\n    constructor(cursorId, ns, server, options) {\n        super(options);\n        this.ns = ns;\n        this.cursorId = cursorId;\n        this.server = server;\n    }\n    async execute(server, session) {\n        if (server !== this.server) {\n            throw new error_1.MongoRuntimeError('Killcursor must run on the same server operation began on');\n        }\n        const killCursors = this.ns.collection;\n        if (killCursors == null) {\n            // Cursors should have adopted the namespace returned by MongoDB\n            // which should always defined a collection name (even a pseudo one, ex. db.aggregate())\n            throw new error_1.MongoRuntimeError('A collection name must be determined before killCursors');\n        }\n        const killCursorsCommand = {\n            killCursors,\n            cursors: [this.cursorId]\n        };\n        try {\n            await server.commandAsync(this.ns, killCursorsCommand, { session });\n        }\n        catch {\n            // The driver should never emit errors from killCursors, this is spec-ed behavior\n        }\n    }\n}\nexports.KillCursorsOperation = KillCursorsOperation;\n(0, operation_1.defineAspects)(KillCursorsOperation, [operation_1.Aspect.MUST_SELECT_SAME_SERVER]);\n//# sourceMappingURL=kill_cursors.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/kill_cursors.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/list_collections.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/list_collections.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ListCollectionsOperation = void 0;\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass ListCollectionsOperation extends command_1.CommandOperation {\n    constructor(db, filter, options) {\n        super(db, options);\n        this.options = { ...options };\n        delete this.options.writeConcern;\n        this.db = db;\n        this.filter = filter;\n        this.nameOnly = !!this.options.nameOnly;\n        this.authorizedCollections = !!this.options.authorizedCollections;\n        if (typeof this.options.batchSize === 'number') {\n            this.batchSize = this.options.batchSize;\n        }\n    }\n    async execute(server, session) {\n        return super.executeCommand(server, session, this.generateCommand((0, utils_1.maxWireVersion)(server)));\n    }\n    /* This is here for the purpose of unit testing the final command that gets sent. */\n    generateCommand(wireVersion) {\n        const command = {\n            listCollections: 1,\n            filter: this.filter,\n            cursor: this.batchSize ? { batchSize: this.batchSize } : {},\n            nameOnly: this.nameOnly,\n            authorizedCollections: this.authorizedCollections\n        };\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (wireVersion >= 9 && this.options.comment !== undefined) {\n            command.comment = this.options.comment;\n        }\n        return command;\n    }\n}\nexports.ListCollectionsOperation = ListCollectionsOperation;\n(0, operation_1.defineAspects)(ListCollectionsOperation, [\n    operation_1.Aspect.READ_OPERATION,\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.CURSOR_CREATING\n]);\n//# sourceMappingURL=list_collections.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/list_collections.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/list_databases.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/list_databases.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ListDatabasesOperation = void 0;\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass ListDatabasesOperation extends command_1.CommandOperation {\n    constructor(db, options) {\n        super(db, options);\n        this.options = options ?? {};\n        this.ns = new utils_1.MongoDBNamespace('admin', '$cmd');\n    }\n    async execute(server, session) {\n        const cmd = { listDatabases: 1 };\n        if (typeof this.options.nameOnly === 'boolean') {\n            cmd.nameOnly = this.options.nameOnly;\n        }\n        if (this.options.filter) {\n            cmd.filter = this.options.filter;\n        }\n        if (typeof this.options.authorizedDatabases === 'boolean') {\n            cmd.authorizedDatabases = this.options.authorizedDatabases;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if ((0, utils_1.maxWireVersion)(server) >= 9 && this.options.comment !== undefined) {\n            cmd.comment = this.options.comment;\n        }\n        return super.executeCommand(server, session, cmd);\n    }\n}\nexports.ListDatabasesOperation = ListDatabasesOperation;\n(0, operation_1.defineAspects)(ListDatabasesOperation, [operation_1.Aspect.READ_OPERATION, operation_1.Aspect.RETRYABLE]);\n//# sourceMappingURL=list_databases.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/list_databases.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/operation.js":
/*!**********************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/operation.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.defineAspects = exports.AbstractOperation = exports.Aspect = void 0;\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst read_preference_1 = __webpack_require__(/*! ../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nexports.Aspect = {\n    READ_OPERATION: Symbol('READ_OPERATION'),\n    WRITE_OPERATION: Symbol('WRITE_OPERATION'),\n    RETRYABLE: Symbol('RETRYABLE'),\n    EXPLAINABLE: Symbol('EXPLAINABLE'),\n    SKIP_COLLATION: Symbol('SKIP_COLLATION'),\n    CURSOR_CREATING: Symbol('CURSOR_CREATING'),\n    MUST_SELECT_SAME_SERVER: Symbol('MUST_SELECT_SAME_SERVER')\n};\n/** @internal */\nconst kSession = Symbol('session');\n/**\n * This class acts as a parent class for any operation and is responsible for setting this.options,\n * as well as setting and getting a session.\n * Additionally, this class implements `hasAspect`, which determines whether an operation has\n * a specific aspect.\n * @internal\n */\nclass AbstractOperation {\n    constructor(options = {}) {\n        this.readPreference = this.hasAspect(exports.Aspect.WRITE_OPERATION)\n            ? read_preference_1.ReadPreference.primary\n            : read_preference_1.ReadPreference.fromOptions(options) ?? read_preference_1.ReadPreference.primary;\n        // Pull the BSON serialize options from the already-resolved options\n        this.bsonOptions = (0, bson_1.resolveBSONOptions)(options);\n        this[kSession] = options.session != null ? options.session : undefined;\n        this.options = options;\n        this.bypassPinningCheck = !!options.bypassPinningCheck;\n        this.trySecondaryWrite = false;\n    }\n    hasAspect(aspect) {\n        const ctor = this.constructor;\n        if (ctor.aspects == null) {\n            return false;\n        }\n        return ctor.aspects.has(aspect);\n    }\n    get session() {\n        return this[kSession];\n    }\n    clearSession() {\n        this[kSession] = undefined;\n    }\n    get canRetryRead() {\n        return true;\n    }\n    get canRetryWrite() {\n        return true;\n    }\n}\nexports.AbstractOperation = AbstractOperation;\nfunction defineAspects(operation, aspects) {\n    if (!Array.isArray(aspects) && !(aspects instanceof Set)) {\n        aspects = [aspects];\n    }\n    aspects = new Set(aspects);\n    Object.defineProperty(operation, 'aspects', {\n        value: aspects,\n        writable: false\n    });\n    return aspects;\n}\nexports.defineAspects = defineAspects;\n//# sourceMappingURL=operation.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/operation.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/options_operation.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/options_operation.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.OptionsOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass OptionsOperation extends operation_1.AbstractOperation {\n    constructor(collection, options) {\n        super(options);\n        this.options = options;\n        this.collection = collection;\n    }\n    async execute(server, session) {\n        const coll = this.collection;\n        const [collection] = await coll.s.db\n            .listCollections({ name: coll.collectionName }, { ...this.options, nameOnly: false, readPreference: this.readPreference, session })\n            .toArray();\n        if (collection == null || collection.options == null) {\n            throw new error_1.MongoAPIError(`collection ${coll.namespace} not found`);\n        }\n        return collection.options;\n    }\n}\nexports.OptionsOperation = OptionsOperation;\n//# sourceMappingURL=options_operation.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/options_operation.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/profiling_level.js":
/*!****************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/profiling_level.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ProfilingLevelOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\n/** @internal */\nclass ProfilingLevelOperation extends command_1.CommandOperation {\n    constructor(db, options) {\n        super(db, options);\n        this.options = options;\n    }\n    async execute(server, session) {\n        const doc = await super.executeCommand(server, session, { profile: -1 });\n        if (doc.ok === 1) {\n            const was = doc.was;\n            if (was === 0)\n                return 'off';\n            if (was === 1)\n                return 'slow_only';\n            if (was === 2)\n                return 'all';\n            throw new error_1.MongoUnexpectedServerResponseError(`Illegal profiling level value ${was}`);\n        }\n        else {\n            throw new error_1.MongoUnexpectedServerResponseError('Error with profile command');\n        }\n    }\n}\nexports.ProfilingLevelOperation = ProfilingLevelOperation;\n//# sourceMappingURL=profiling_level.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/profiling_level.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/remove_user.js":
/*!************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/remove_user.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RemoveUserOperation = void 0;\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass RemoveUserOperation extends command_1.CommandOperation {\n    constructor(db, username, options) {\n        super(db, options);\n        this.options = options;\n        this.username = username;\n    }\n    async execute(server, session) {\n        await super.executeCommand(server, session, { dropUser: this.username });\n        return true;\n    }\n}\nexports.RemoveUserOperation = RemoveUserOperation;\n(0, operation_1.defineAspects)(RemoveUserOperation, [operation_1.Aspect.WRITE_OPERATION]);\n//# sourceMappingURL=remove_user.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/remove_user.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/rename.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/rename.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RenameOperation = void 0;\nconst collection_1 = __webpack_require__(/*! ../collection */ \"./node_modules/mongodb/lib/collection.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass RenameOperation extends command_1.CommandOperation {\n    constructor(collection, newName, options) {\n        super(collection, options);\n        this.collection = collection;\n        this.newName = newName;\n        this.options = options;\n        this.ns = new utils_1.MongoDBNamespace('admin', '$cmd');\n    }\n    async execute(server, session) {\n        // Build the command\n        const renameCollection = this.collection.namespace;\n        const toCollection = this.collection.s.namespace.withCollection(this.newName).toString();\n        const dropTarget = typeof this.options.dropTarget === 'boolean' ? this.options.dropTarget : false;\n        const command = {\n            renameCollection: renameCollection,\n            to: toCollection,\n            dropTarget: dropTarget\n        };\n        await super.executeCommand(server, session, command);\n        return new collection_1.Collection(this.collection.s.db, this.newName, this.collection.s.options);\n    }\n}\nexports.RenameOperation = RenameOperation;\n(0, operation_1.defineAspects)(RenameOperation, [operation_1.Aspect.WRITE_OPERATION]);\n//# sourceMappingURL=rename.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/rename.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/run_command.js":
/*!************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/run_command.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RunAdminCommandOperation = exports.RunCommandOperation = void 0;\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass RunCommandOperation extends operation_1.AbstractOperation {\n    constructor(parent, command, options) {\n        super(options);\n        this.command = command;\n        this.options = options;\n        this.ns = parent.s.namespace.withCollection('$cmd');\n    }\n    async execute(server, session) {\n        this.server = server;\n        return server.commandAsync(this.ns, this.command, {\n            ...this.options,\n            readPreference: this.readPreference,\n            session\n        });\n    }\n}\nexports.RunCommandOperation = RunCommandOperation;\nclass RunAdminCommandOperation extends operation_1.AbstractOperation {\n    constructor(command, options) {\n        super(options);\n        this.command = command;\n        this.options = options;\n        this.ns = new utils_1.MongoDBNamespace('admin', '$cmd');\n    }\n    async execute(server, session) {\n        this.server = server;\n        return server.commandAsync(this.ns, this.command, {\n            ...this.options,\n            readPreference: this.readPreference,\n            session\n        });\n    }\n}\nexports.RunAdminCommandOperation = RunAdminCommandOperation;\n//# sourceMappingURL=run_command.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/run_command.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/search_indexes/create.js":
/*!**********************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/search_indexes/create.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CreateSearchIndexesOperation = void 0;\nconst operation_1 = __webpack_require__(/*! ../operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass CreateSearchIndexesOperation extends operation_1.AbstractOperation {\n    constructor(collection, descriptions) {\n        super();\n        this.collection = collection;\n        this.descriptions = descriptions;\n    }\n    async execute(server, session) {\n        const namespace = this.collection.fullNamespace;\n        const command = {\n            createSearchIndexes: namespace.collection,\n            indexes: this.descriptions\n        };\n        const res = await server.commandAsync(namespace, command, { session });\n        const indexesCreated = res?.indexesCreated ?? [];\n        return indexesCreated.map(({ name }) => name);\n    }\n}\nexports.CreateSearchIndexesOperation = CreateSearchIndexesOperation;\n//# sourceMappingURL=create.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/search_indexes/create.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/search_indexes/drop.js":
/*!********************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/search_indexes/drop.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DropSearchIndexOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst operation_1 = __webpack_require__(/*! ../operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass DropSearchIndexOperation extends operation_1.AbstractOperation {\n    constructor(collection, name) {\n        super();\n        this.collection = collection;\n        this.name = name;\n    }\n    async execute(server, session) {\n        const namespace = this.collection.fullNamespace;\n        const command = {\n            dropSearchIndex: namespace.collection\n        };\n        if (typeof this.name === 'string') {\n            command.name = this.name;\n        }\n        try {\n            await server.commandAsync(namespace, command, { session });\n        }\n        catch (error) {\n            const isNamespaceNotFoundError = error instanceof error_1.MongoServerError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound;\n            if (!isNamespaceNotFoundError) {\n                throw error;\n            }\n        }\n    }\n}\nexports.DropSearchIndexOperation = DropSearchIndexOperation;\n//# sourceMappingURL=drop.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/search_indexes/drop.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/search_indexes/update.js":
/*!**********************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/search_indexes/update.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.UpdateSearchIndexOperation = void 0;\nconst operation_1 = __webpack_require__(/*! ../operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass UpdateSearchIndexOperation extends operation_1.AbstractOperation {\n    constructor(collection, name, definition) {\n        super();\n        this.collection = collection;\n        this.name = name;\n        this.definition = definition;\n    }\n    async execute(server, session) {\n        const namespace = this.collection.fullNamespace;\n        const command = {\n            updateSearchIndex: namespace.collection,\n            name: this.name,\n            definition: this.definition\n        };\n        await server.commandAsync(namespace, command, { session });\n        return;\n    }\n}\nexports.UpdateSearchIndexOperation = UpdateSearchIndexOperation;\n//# sourceMappingURL=update.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/search_indexes/update.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/set_profiling_level.js":
/*!********************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/set_profiling_level.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SetProfilingLevelOperation = exports.ProfilingLevel = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst levelValues = new Set(['off', 'slow_only', 'all']);\n/** @public */\nexports.ProfilingLevel = Object.freeze({\n    off: 'off',\n    slowOnly: 'slow_only',\n    all: 'all'\n});\n/** @internal */\nclass SetProfilingLevelOperation extends command_1.CommandOperation {\n    constructor(db, level, options) {\n        super(db, options);\n        this.options = options;\n        switch (level) {\n            case exports.ProfilingLevel.off:\n                this.profile = 0;\n                break;\n            case exports.ProfilingLevel.slowOnly:\n                this.profile = 1;\n                break;\n            case exports.ProfilingLevel.all:\n                this.profile = 2;\n                break;\n            default:\n                this.profile = 0;\n                break;\n        }\n        this.level = level;\n    }\n    async execute(server, session) {\n        const level = this.level;\n        if (!levelValues.has(level)) {\n            throw new error_1.MongoInvalidArgumentError(`Profiling level must be one of \"${(0, utils_1.enumToString)(exports.ProfilingLevel)}\"`);\n        }\n        // TODO(NODE-3483): Determine error to put here\n        await super.executeCommand(server, session, { profile: this.profile });\n        return level;\n    }\n}\nexports.SetProfilingLevelOperation = SetProfilingLevelOperation;\n//# sourceMappingURL=set_profiling_level.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/set_profiling_level.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/stats.js":
/*!******************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/stats.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DbStatsOperation = void 0;\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass DbStatsOperation extends command_1.CommandOperation {\n    constructor(db, options) {\n        super(db, options);\n        this.options = options;\n    }\n    async execute(server, session) {\n        const command = { dbStats: true };\n        if (this.options.scale != null) {\n            command.scale = this.options.scale;\n        }\n        return super.executeCommand(server, session, command);\n    }\n}\nexports.DbStatsOperation = DbStatsOperation;\n(0, operation_1.defineAspects)(DbStatsOperation, [operation_1.Aspect.READ_OPERATION]);\n//# sourceMappingURL=stats.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/stats.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/update.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/update.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.makeUpdateStatement = exports.ReplaceOneOperation = exports.UpdateManyOperation = exports.UpdateOneOperation = exports.UpdateOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/**\n * @internal\n * UpdateOperation is used in bulk write, while UpdateOneOperation and UpdateManyOperation are only used in the collections API\n */\nclass UpdateOperation extends command_1.CommandOperation {\n    constructor(ns, statements, options) {\n        super(undefined, options);\n        this.options = options;\n        this.ns = ns;\n        this.statements = statements;\n    }\n    get canRetryWrite() {\n        if (super.canRetryWrite === false) {\n            return false;\n        }\n        return this.statements.every(op => op.multi == null || op.multi === false);\n    }\n    async execute(server, session) {\n        const options = this.options ?? {};\n        const ordered = typeof options.ordered === 'boolean' ? options.ordered : true;\n        const command = {\n            update: this.ns.collection,\n            updates: this.statements,\n            ordered\n        };\n        if (typeof options.bypassDocumentValidation === 'boolean') {\n            command.bypassDocumentValidation = options.bypassDocumentValidation;\n        }\n        if (options.let) {\n            command.let = options.let;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (options.comment !== undefined) {\n            command.comment = options.comment;\n        }\n        const unacknowledgedWrite = this.writeConcern && this.writeConcern.w === 0;\n        if (unacknowledgedWrite) {\n            if (this.statements.find((o) => o.hint)) {\n                // TODO(NODE-3541): fix error for hint with unacknowledged writes\n                throw new error_1.MongoCompatibilityError(`hint is not supported with unacknowledged writes`);\n            }\n        }\n        return super.executeCommand(server, session, command);\n    }\n}\nexports.UpdateOperation = UpdateOperation;\n/** @internal */\nclass UpdateOneOperation extends UpdateOperation {\n    constructor(collection, filter, update, options) {\n        super(collection.s.namespace, [makeUpdateStatement(filter, update, { ...options, multi: false })], options);\n        if (!(0, utils_1.hasAtomicOperators)(update)) {\n            throw new error_1.MongoInvalidArgumentError('Update document requires atomic operators');\n        }\n    }\n    async execute(server, session) {\n        const res = await super.execute(server, session);\n        if (this.explain != null)\n            return res;\n        if (res.code)\n            throw new error_1.MongoServerError(res);\n        if (res.writeErrors)\n            throw new error_1.MongoServerError(res.writeErrors[0]);\n        return {\n            acknowledged: this.writeConcern?.w !== 0,\n            modifiedCount: res.nModified ?? res.n,\n            upsertedId: Array.isArray(res.upserted) && res.upserted.length > 0 ? res.upserted[0]._id : null,\n            upsertedCount: Array.isArray(res.upserted) && res.upserted.length ? res.upserted.length : 0,\n            matchedCount: Array.isArray(res.upserted) && res.upserted.length > 0 ? 0 : res.n\n        };\n    }\n}\nexports.UpdateOneOperation = UpdateOneOperation;\n/** @internal */\nclass UpdateManyOperation extends UpdateOperation {\n    constructor(collection, filter, update, options) {\n        super(collection.s.namespace, [makeUpdateStatement(filter, update, { ...options, multi: true })], options);\n        if (!(0, utils_1.hasAtomicOperators)(update)) {\n            throw new error_1.MongoInvalidArgumentError('Update document requires atomic operators');\n        }\n    }\n    async execute(server, session) {\n        const res = await super.execute(server, session);\n        if (this.explain != null)\n            return res;\n        if (res.code)\n            throw new error_1.MongoServerError(res);\n        if (res.writeErrors)\n            throw new error_1.MongoServerError(res.writeErrors[0]);\n        return {\n            acknowledged: this.writeConcern?.w !== 0,\n            modifiedCount: res.nModified ?? res.n,\n            upsertedId: Array.isArray(res.upserted) && res.upserted.length > 0 ? res.upserted[0]._id : null,\n            upsertedCount: Array.isArray(res.upserted) && res.upserted.length ? res.upserted.length : 0,\n            matchedCount: Array.isArray(res.upserted) && res.upserted.length > 0 ? 0 : res.n\n        };\n    }\n}\nexports.UpdateManyOperation = UpdateManyOperation;\n/** @internal */\nclass ReplaceOneOperation extends UpdateOperation {\n    constructor(collection, filter, replacement, options) {\n        super(collection.s.namespace, [makeUpdateStatement(filter, replacement, { ...options, multi: false })], options);\n        if ((0, utils_1.hasAtomicOperators)(replacement)) {\n            throw new error_1.MongoInvalidArgumentError('Replacement document must not contain atomic operators');\n        }\n    }\n    async execute(server, session) {\n        const res = await super.execute(server, session);\n        if (this.explain != null)\n            return res;\n        if (res.code)\n            throw new error_1.MongoServerError(res);\n        if (res.writeErrors)\n            throw new error_1.MongoServerError(res.writeErrors[0]);\n        return {\n            acknowledged: this.writeConcern?.w !== 0,\n            modifiedCount: res.nModified ?? res.n,\n            upsertedId: Array.isArray(res.upserted) && res.upserted.length > 0 ? res.upserted[0]._id : null,\n            upsertedCount: Array.isArray(res.upserted) && res.upserted.length ? res.upserted.length : 0,\n            matchedCount: Array.isArray(res.upserted) && res.upserted.length > 0 ? 0 : res.n\n        };\n    }\n}\nexports.ReplaceOneOperation = ReplaceOneOperation;\nfunction makeUpdateStatement(filter, update, options) {\n    if (filter == null || typeof filter !== 'object') {\n        throw new error_1.MongoInvalidArgumentError('Selector must be a valid JavaScript object');\n    }\n    if (update == null || typeof update !== 'object') {\n        throw new error_1.MongoInvalidArgumentError('Document must be a valid JavaScript object');\n    }\n    const op = { q: filter, u: update };\n    if (typeof options.upsert === 'boolean') {\n        op.upsert = options.upsert;\n    }\n    if (options.multi) {\n        op.multi = options.multi;\n    }\n    if (options.hint) {\n        op.hint = options.hint;\n    }\n    if (options.arrayFilters) {\n        op.arrayFilters = options.arrayFilters;\n    }\n    if (options.collation) {\n        op.collation = options.collation;\n    }\n    return op;\n}\nexports.makeUpdateStatement = makeUpdateStatement;\n(0, operation_1.defineAspects)(UpdateOperation, [operation_1.Aspect.RETRYABLE, operation_1.Aspect.WRITE_OPERATION, operation_1.Aspect.SKIP_COLLATION]);\n(0, operation_1.defineAspects)(UpdateOneOperation, [\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.WRITE_OPERATION,\n    operation_1.Aspect.EXPLAINABLE,\n    operation_1.Aspect.SKIP_COLLATION\n]);\n(0, operation_1.defineAspects)(UpdateManyOperation, [\n    operation_1.Aspect.WRITE_OPERATION,\n    operation_1.Aspect.EXPLAINABLE,\n    operation_1.Aspect.SKIP_COLLATION\n]);\n(0, operation_1.defineAspects)(ReplaceOneOperation, [\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.WRITE_OPERATION,\n    operation_1.Aspect.SKIP_COLLATION\n]);\n//# sourceMappingURL=update.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/update.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/validate_collection.js":
/*!********************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/validate_collection.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ValidateCollectionOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\n/** @internal */\nclass ValidateCollectionOperation extends command_1.CommandOperation {\n    constructor(admin, collectionName, options) {\n        // Decorate command with extra options\n        const command = { validate: collectionName };\n        const keys = Object.keys(options);\n        for (let i = 0; i < keys.length; i++) {\n            if (Object.prototype.hasOwnProperty.call(options, keys[i]) && keys[i] !== 'session') {\n                command[keys[i]] = options[keys[i]];\n            }\n        }\n        super(admin.s.db, options);\n        this.options = options;\n        this.command = command;\n        this.collectionName = collectionName;\n    }\n    async execute(server, session) {\n        const collectionName = this.collectionName;\n        const doc = await super.executeCommand(server, session, this.command);\n        if (doc.result != null && typeof doc.result !== 'string')\n            throw new error_1.MongoUnexpectedServerResponseError('Error with validation data');\n        if (doc.result != null && doc.result.match(/exception|corrupt/) != null)\n            throw new error_1.MongoUnexpectedServerResponseError(`Invalid collection ${collectionName}`);\n        if (doc.valid != null && !doc.valid)\n            throw new error_1.MongoUnexpectedServerResponseError(`Invalid collection ${collectionName}`);\n        return doc;\n    }\n}\nexports.ValidateCollectionOperation = ValidateCollectionOperation;\n//# sourceMappingURL=validate_collection.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/operations/validate_collection.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/read_concern.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/read_concern.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ReadConcern = exports.ReadConcernLevel = void 0;\n/** @public */\nexports.ReadConcernLevel = Object.freeze({\n    local: 'local',\n    majority: 'majority',\n    linearizable: 'linearizable',\n    available: 'available',\n    snapshot: 'snapshot'\n});\n/**\n * The MongoDB ReadConcern, which allows for control of the consistency and isolation properties\n * of the data read from replica sets and replica set shards.\n * @public\n *\n * @see https://www.mongodb.com/docs/manual/reference/read-concern/index.html\n */\nclass ReadConcern {\n    /** Constructs a ReadConcern from the read concern level.*/\n    constructor(level) {\n        /**\n         * A spec test exists that allows level to be any string.\n         * \"invalid readConcern with out stage\"\n         * @see ./test/spec/crud/v2/aggregate-out-readConcern.json\n         * @see https://github.com/mongodb/specifications/blob/master/source/read-write-concern/read-write-concern.rst#unknown-levels-and-additional-options-for-string-based-readconcerns\n         */\n        this.level = exports.ReadConcernLevel[level] ?? level;\n    }\n    /**\n     * Construct a ReadConcern given an options object.\n     *\n     * @param options - The options object from which to extract the write concern.\n     */\n    static fromOptions(options) {\n        if (options == null) {\n            return;\n        }\n        if (options.readConcern) {\n            const { readConcern } = options;\n            if (readConcern instanceof ReadConcern) {\n                return readConcern;\n            }\n            else if (typeof readConcern === 'string') {\n                return new ReadConcern(readConcern);\n            }\n            else if ('level' in readConcern && readConcern.level) {\n                return new ReadConcern(readConcern.level);\n            }\n        }\n        if (options.level) {\n            return new ReadConcern(options.level);\n        }\n        return;\n    }\n    static get MAJORITY() {\n        return exports.ReadConcernLevel.majority;\n    }\n    static get AVAILABLE() {\n        return exports.ReadConcernLevel.available;\n    }\n    static get LINEARIZABLE() {\n        return exports.ReadConcernLevel.linearizable;\n    }\n    static get SNAPSHOT() {\n        return exports.ReadConcernLevel.snapshot;\n    }\n    toJSON() {\n        return { level: this.level };\n    }\n}\nexports.ReadConcern = ReadConcern;\n//# sourceMappingURL=read_concern.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/read_concern.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/read_preference.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongodb/lib/read_preference.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ReadPreference = exports.ReadPreferenceMode = void 0;\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\n/** @public */\nexports.ReadPreferenceMode = Object.freeze({\n    primary: 'primary',\n    primaryPreferred: 'primaryPreferred',\n    secondary: 'secondary',\n    secondaryPreferred: 'secondaryPreferred',\n    nearest: 'nearest'\n});\n/**\n * The **ReadPreference** class is a class that represents a MongoDB ReadPreference and is\n * used to construct connections.\n * @public\n *\n * @see https://www.mongodb.com/docs/manual/core/read-preference/\n */\nclass ReadPreference {\n    /**\n     * @param mode - A string describing the read preference mode (primary|primaryPreferred|secondary|secondaryPreferred|nearest)\n     * @param tags - A tag set used to target reads to members with the specified tag(s). tagSet is not available if using read preference mode primary.\n     * @param options - Additional read preference options\n     */\n    constructor(mode, tags, options) {\n        if (!ReadPreference.isValid(mode)) {\n            throw new error_1.MongoInvalidArgumentError(`Invalid read preference mode ${JSON.stringify(mode)}`);\n        }\n        if (options == null && typeof tags === 'object' && !Array.isArray(tags)) {\n            options = tags;\n            tags = undefined;\n        }\n        else if (tags && !Array.isArray(tags)) {\n            throw new error_1.MongoInvalidArgumentError('ReadPreference tags must be an array');\n        }\n        this.mode = mode;\n        this.tags = tags;\n        this.hedge = options?.hedge;\n        this.maxStalenessSeconds = undefined;\n        this.minWireVersion = undefined;\n        options = options ?? {};\n        if (options.maxStalenessSeconds != null) {\n            if (options.maxStalenessSeconds <= 0) {\n                throw new error_1.MongoInvalidArgumentError('maxStalenessSeconds must be a positive integer');\n            }\n            this.maxStalenessSeconds = options.maxStalenessSeconds;\n            // NOTE: The minimum required wire version is 5 for this read preference. If the existing\n            //       topology has a lower value then a MongoError will be thrown during server selection.\n            this.minWireVersion = 5;\n        }\n        if (this.mode === ReadPreference.PRIMARY) {\n            if (this.tags && Array.isArray(this.tags) && this.tags.length > 0) {\n                throw new error_1.MongoInvalidArgumentError('Primary read preference cannot be combined with tags');\n            }\n            if (this.maxStalenessSeconds) {\n                throw new error_1.MongoInvalidArgumentError('Primary read preference cannot be combined with maxStalenessSeconds');\n            }\n            if (this.hedge) {\n                throw new error_1.MongoInvalidArgumentError('Primary read preference cannot be combined with hedge');\n            }\n        }\n    }\n    // Support the deprecated `preference` property introduced in the porcelain layer\n    get preference() {\n        return this.mode;\n    }\n    static fromString(mode) {\n        return new ReadPreference(mode);\n    }\n    /**\n     * Construct a ReadPreference given an options object.\n     *\n     * @param options - The options object from which to extract the read preference.\n     */\n    static fromOptions(options) {\n        if (!options)\n            return;\n        const readPreference = options.readPreference ?? options.session?.transaction.options.readPreference;\n        const readPreferenceTags = options.readPreferenceTags;\n        if (readPreference == null) {\n            return;\n        }\n        if (typeof readPreference === 'string') {\n            return new ReadPreference(readPreference, readPreferenceTags, {\n                maxStalenessSeconds: options.maxStalenessSeconds,\n                hedge: options.hedge\n            });\n        }\n        else if (!(readPreference instanceof ReadPreference) && typeof readPreference === 'object') {\n            const mode = readPreference.mode || readPreference.preference;\n            if (mode && typeof mode === 'string') {\n                return new ReadPreference(mode, readPreference.tags ?? readPreferenceTags, {\n                    maxStalenessSeconds: readPreference.maxStalenessSeconds,\n                    hedge: options.hedge\n                });\n            }\n        }\n        if (readPreferenceTags) {\n            readPreference.tags = readPreferenceTags;\n        }\n        return readPreference;\n    }\n    /**\n     * Replaces options.readPreference with a ReadPreference instance\n     */\n    static translate(options) {\n        if (options.readPreference == null)\n            return options;\n        const r = options.readPreference;\n        if (typeof r === 'string') {\n            options.readPreference = new ReadPreference(r);\n        }\n        else if (r && !(r instanceof ReadPreference) && typeof r === 'object') {\n            const mode = r.mode || r.preference;\n            if (mode && typeof mode === 'string') {\n                options.readPreference = new ReadPreference(mode, r.tags, {\n                    maxStalenessSeconds: r.maxStalenessSeconds\n                });\n            }\n        }\n        else if (!(r instanceof ReadPreference)) {\n            throw new error_1.MongoInvalidArgumentError(`Invalid read preference: ${r}`);\n        }\n        return options;\n    }\n    /**\n     * Validate if a mode is legal\n     *\n     * @param mode - The string representing the read preference mode.\n     */\n    static isValid(mode) {\n        const VALID_MODES = new Set([\n            ReadPreference.PRIMARY,\n            ReadPreference.PRIMARY_PREFERRED,\n            ReadPreference.SECONDARY,\n            ReadPreference.SECONDARY_PREFERRED,\n            ReadPreference.NEAREST,\n            null\n        ]);\n        return VALID_MODES.has(mode);\n    }\n    /**\n     * Validate if a mode is legal\n     *\n     * @param mode - The string representing the read preference mode.\n     */\n    isValid(mode) {\n        return ReadPreference.isValid(typeof mode === 'string' ? mode : this.mode);\n    }\n    /**\n     * Indicates that this readPreference needs the \"SecondaryOk\" bit when sent over the wire\n     * @see https://www.mongodb.com/docs/manual/reference/mongodb-wire-protocol/#op-query\n     */\n    secondaryOk() {\n        const NEEDS_SECONDARYOK = new Set([\n            ReadPreference.PRIMARY_PREFERRED,\n            ReadPreference.SECONDARY,\n            ReadPreference.SECONDARY_PREFERRED,\n            ReadPreference.NEAREST\n        ]);\n        return NEEDS_SECONDARYOK.has(this.mode);\n    }\n    /**\n     * Check if the two ReadPreferences are equivalent\n     *\n     * @param readPreference - The read preference with which to check equality\n     */\n    equals(readPreference) {\n        return readPreference.mode === this.mode;\n    }\n    /** Return JSON representation */\n    toJSON() {\n        const readPreference = { mode: this.mode };\n        if (Array.isArray(this.tags))\n            readPreference.tags = this.tags;\n        if (this.maxStalenessSeconds)\n            readPreference.maxStalenessSeconds = this.maxStalenessSeconds;\n        if (this.hedge)\n            readPreference.hedge = this.hedge;\n        return readPreference;\n    }\n}\nReadPreference.PRIMARY = exports.ReadPreferenceMode.primary;\nReadPreference.PRIMARY_PREFERRED = exports.ReadPreferenceMode.primaryPreferred;\nReadPreference.SECONDARY = exports.ReadPreferenceMode.secondary;\nReadPreference.SECONDARY_PREFERRED = exports.ReadPreferenceMode.secondaryPreferred;\nReadPreference.NEAREST = exports.ReadPreferenceMode.nearest;\nReadPreference.primary = new ReadPreference(exports.ReadPreferenceMode.primary);\nReadPreference.primaryPreferred = new ReadPreference(exports.ReadPreferenceMode.primaryPreferred);\nReadPreference.secondary = new ReadPreference(exports.ReadPreferenceMode.secondary);\nReadPreference.secondaryPreferred = new ReadPreference(exports.ReadPreferenceMode.secondaryPreferred);\nReadPreference.nearest = new ReadPreference(exports.ReadPreferenceMode.nearest);\nexports.ReadPreference = ReadPreference;\n//# sourceMappingURL=read_preference.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/read_preference.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/common.js":
/*!*************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/common.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports._advanceClusterTime = exports.drainTimerQueue = exports.ServerType = exports.TopologyType = exports.STATE_CONNECTED = exports.STATE_CONNECTING = exports.STATE_CLOSED = exports.STATE_CLOSING = void 0;\nconst timers_1 = __webpack_require__(/*! timers */ \"timers\");\n// shared state names\nexports.STATE_CLOSING = 'closing';\nexports.STATE_CLOSED = 'closed';\nexports.STATE_CONNECTING = 'connecting';\nexports.STATE_CONNECTED = 'connected';\n/**\n * An enumeration of topology types we know about\n * @public\n */\nexports.TopologyType = Object.freeze({\n    Single: 'Single',\n    ReplicaSetNoPrimary: 'ReplicaSetNoPrimary',\n    ReplicaSetWithPrimary: 'ReplicaSetWithPrimary',\n    Sharded: 'Sharded',\n    Unknown: 'Unknown',\n    LoadBalanced: 'LoadBalanced'\n});\n/**\n * An enumeration of server types we know about\n * @public\n */\nexports.ServerType = Object.freeze({\n    Standalone: 'Standalone',\n    Mongos: 'Mongos',\n    PossiblePrimary: 'PossiblePrimary',\n    RSPrimary: 'RSPrimary',\n    RSSecondary: 'RSSecondary',\n    RSArbiter: 'RSArbiter',\n    RSOther: 'RSOther',\n    RSGhost: 'RSGhost',\n    Unknown: 'Unknown',\n    LoadBalancer: 'LoadBalancer'\n});\n/** @internal */\nfunction drainTimerQueue(queue) {\n    queue.forEach(timers_1.clearTimeout);\n    queue.clear();\n}\nexports.drainTimerQueue = drainTimerQueue;\n/** Shared function to determine clusterTime for a given topology or session */\nfunction _advanceClusterTime(entity, $clusterTime) {\n    if (entity.clusterTime == null) {\n        entity.clusterTime = $clusterTime;\n    }\n    else {\n        if ($clusterTime.clusterTime.greaterThan(entity.clusterTime.clusterTime)) {\n            entity.clusterTime = $clusterTime;\n        }\n    }\n}\nexports._advanceClusterTime = _advanceClusterTime;\n//# sourceMappingURL=common.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/sdam/common.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/events.js":
/*!*************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/events.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ServerHeartbeatFailedEvent = exports.ServerHeartbeatSucceededEvent = exports.ServerHeartbeatStartedEvent = exports.TopologyClosedEvent = exports.TopologyOpeningEvent = exports.TopologyDescriptionChangedEvent = exports.ServerClosedEvent = exports.ServerOpeningEvent = exports.ServerDescriptionChangedEvent = void 0;\n/**\n * Emitted when server description changes, but does NOT include changes to the RTT.\n * @public\n * @category Event\n */\nclass ServerDescriptionChangedEvent {\n    /** @internal */\n    constructor(topologyId, address, previousDescription, newDescription) {\n        this.topologyId = topologyId;\n        this.address = address;\n        this.previousDescription = previousDescription;\n        this.newDescription = newDescription;\n    }\n}\nexports.ServerDescriptionChangedEvent = ServerDescriptionChangedEvent;\n/**\n * Emitted when server is initialized.\n * @public\n * @category Event\n */\nclass ServerOpeningEvent {\n    /** @internal */\n    constructor(topologyId, address) {\n        this.topologyId = topologyId;\n        this.address = address;\n    }\n}\nexports.ServerOpeningEvent = ServerOpeningEvent;\n/**\n * Emitted when server is closed.\n * @public\n * @category Event\n */\nclass ServerClosedEvent {\n    /** @internal */\n    constructor(topologyId, address) {\n        this.topologyId = topologyId;\n        this.address = address;\n    }\n}\nexports.ServerClosedEvent = ServerClosedEvent;\n/**\n * Emitted when topology description changes.\n * @public\n * @category Event\n */\nclass TopologyDescriptionChangedEvent {\n    /** @internal */\n    constructor(topologyId, previousDescription, newDescription) {\n        this.topologyId = topologyId;\n        this.previousDescription = previousDescription;\n        this.newDescription = newDescription;\n    }\n}\nexports.TopologyDescriptionChangedEvent = TopologyDescriptionChangedEvent;\n/**\n * Emitted when topology is initialized.\n * @public\n * @category Event\n */\nclass TopologyOpeningEvent {\n    /** @internal */\n    constructor(topologyId) {\n        this.topologyId = topologyId;\n    }\n}\nexports.TopologyOpeningEvent = TopologyOpeningEvent;\n/**\n * Emitted when topology is closed.\n * @public\n * @category Event\n */\nclass TopologyClosedEvent {\n    /** @internal */\n    constructor(topologyId) {\n        this.topologyId = topologyId;\n    }\n}\nexports.TopologyClosedEvent = TopologyClosedEvent;\n/**\n * Emitted when the server monitors hello command is started - immediately before\n * the hello command is serialized into raw BSON and written to the socket.\n *\n * @public\n * @category Event\n */\nclass ServerHeartbeatStartedEvent {\n    /** @internal */\n    constructor(connectionId, awaited) {\n        this.connectionId = connectionId;\n        this.awaited = awaited;\n    }\n}\nexports.ServerHeartbeatStartedEvent = ServerHeartbeatStartedEvent;\n/**\n * Emitted when the server monitors hello succeeds.\n * @public\n * @category Event\n */\nclass ServerHeartbeatSucceededEvent {\n    /** @internal */\n    constructor(connectionId, duration, reply, awaited) {\n        this.connectionId = connectionId;\n        this.duration = duration;\n        this.reply = reply ?? {};\n        this.awaited = awaited;\n    }\n}\nexports.ServerHeartbeatSucceededEvent = ServerHeartbeatSucceededEvent;\n/**\n * Emitted when the server monitors hello fails, either with an ok: 0 or a socket exception.\n * @public\n * @category Event\n */\nclass ServerHeartbeatFailedEvent {\n    /** @internal */\n    constructor(connectionId, duration, failure, awaited) {\n        this.connectionId = connectionId;\n        this.duration = duration;\n        this.failure = failure;\n        this.awaited = awaited;\n    }\n}\nexports.ServerHeartbeatFailedEvent = ServerHeartbeatFailedEvent;\n//# sourceMappingURL=events.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/sdam/events.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/monitor.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/monitor.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MonitorInterval = exports.RTTPinger = exports.Monitor = exports.ServerMonitoringMode = void 0;\nconst timers_1 = __webpack_require__(/*! timers */ \"timers\");\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst connect_1 = __webpack_require__(/*! ../cmap/connect */ \"./node_modules/mongodb/lib/cmap/connect.js\");\nconst connection_1 = __webpack_require__(/*! ../cmap/connection */ \"./node_modules/mongodb/lib/cmap/connection.js\");\nconst client_metadata_1 = __webpack_require__(/*! ../cmap/handshake/client_metadata */ \"./node_modules/mongodb/lib/cmap/handshake/client_metadata.js\");\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_types_1 = __webpack_require__(/*! ../mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst common_1 = __webpack_require__(/*! ./common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst events_1 = __webpack_require__(/*! ./events */ \"./node_modules/mongodb/lib/sdam/events.js\");\nconst server_1 = __webpack_require__(/*! ./server */ \"./node_modules/mongodb/lib/sdam/server.js\");\n/** @internal */\nconst kServer = Symbol('server');\n/** @internal */\nconst kMonitorId = Symbol('monitorId');\n/** @internal */\nconst kConnection = Symbol('connection');\n/** @internal */\nconst kCancellationToken = Symbol('cancellationToken');\n/** @internal */\nconst kRoundTripTime = Symbol('roundTripTime');\nconst STATE_IDLE = 'idle';\nconst STATE_MONITORING = 'monitoring';\nconst stateTransition = (0, utils_1.makeStateMachine)({\n    [common_1.STATE_CLOSING]: [common_1.STATE_CLOSING, STATE_IDLE, common_1.STATE_CLOSED],\n    [common_1.STATE_CLOSED]: [common_1.STATE_CLOSED, STATE_MONITORING],\n    [STATE_IDLE]: [STATE_IDLE, STATE_MONITORING, common_1.STATE_CLOSING],\n    [STATE_MONITORING]: [STATE_MONITORING, STATE_IDLE, common_1.STATE_CLOSING]\n});\nconst INVALID_REQUEST_CHECK_STATES = new Set([common_1.STATE_CLOSING, common_1.STATE_CLOSED, STATE_MONITORING]);\nfunction isInCloseState(monitor) {\n    return monitor.s.state === common_1.STATE_CLOSED || monitor.s.state === common_1.STATE_CLOSING;\n}\n/** @public */\nexports.ServerMonitoringMode = Object.freeze({\n    auto: 'auto',\n    poll: 'poll',\n    stream: 'stream'\n});\n/** @internal */\nclass Monitor extends mongo_types_1.TypedEventEmitter {\n    get connection() {\n        return this[kConnection];\n    }\n    constructor(server, options) {\n        super();\n        this[kServer] = server;\n        this[kConnection] = undefined;\n        this[kCancellationToken] = new mongo_types_1.CancellationToken();\n        this[kCancellationToken].setMaxListeners(Infinity);\n        this[kMonitorId] = undefined;\n        this.s = {\n            state: common_1.STATE_CLOSED\n        };\n        this.address = server.description.address;\n        this.options = Object.freeze({\n            connectTimeoutMS: options.connectTimeoutMS ?? 10000,\n            heartbeatFrequencyMS: options.heartbeatFrequencyMS ?? 10000,\n            minHeartbeatFrequencyMS: options.minHeartbeatFrequencyMS ?? 500,\n            serverMonitoringMode: options.serverMonitoringMode\n        });\n        this.isRunningInFaasEnv = (0, client_metadata_1.getFAASEnv)() != null;\n        const cancellationToken = this[kCancellationToken];\n        // TODO: refactor this to pull it directly from the pool, requires new ConnectionPool integration\n        const connectOptions = Object.assign({\n            id: '<monitor>',\n            generation: server.pool.generation,\n            connectionType: connection_1.Connection,\n            cancellationToken,\n            hostAddress: server.description.hostAddress\n        }, options, \n        // force BSON serialization options\n        {\n            raw: false,\n            useBigInt64: false,\n            promoteLongs: true,\n            promoteValues: true,\n            promoteBuffers: true\n        });\n        // ensure no authentication is used for monitoring\n        delete connectOptions.credentials;\n        if (connectOptions.autoEncrypter) {\n            delete connectOptions.autoEncrypter;\n        }\n        this.connectOptions = Object.freeze(connectOptions);\n    }\n    connect() {\n        if (this.s.state !== common_1.STATE_CLOSED) {\n            return;\n        }\n        // start\n        const heartbeatFrequencyMS = this.options.heartbeatFrequencyMS;\n        const minHeartbeatFrequencyMS = this.options.minHeartbeatFrequencyMS;\n        this[kMonitorId] = new MonitorInterval(monitorServer(this), {\n            heartbeatFrequencyMS: heartbeatFrequencyMS,\n            minHeartbeatFrequencyMS: minHeartbeatFrequencyMS,\n            immediate: true\n        });\n    }\n    requestCheck() {\n        if (INVALID_REQUEST_CHECK_STATES.has(this.s.state)) {\n            return;\n        }\n        this[kMonitorId]?.wake();\n    }\n    reset() {\n        const topologyVersion = this[kServer].description.topologyVersion;\n        if (isInCloseState(this) || topologyVersion == null) {\n            return;\n        }\n        stateTransition(this, common_1.STATE_CLOSING);\n        resetMonitorState(this);\n        // restart monitor\n        stateTransition(this, STATE_IDLE);\n        // restart monitoring\n        const heartbeatFrequencyMS = this.options.heartbeatFrequencyMS;\n        const minHeartbeatFrequencyMS = this.options.minHeartbeatFrequencyMS;\n        this[kMonitorId] = new MonitorInterval(monitorServer(this), {\n            heartbeatFrequencyMS: heartbeatFrequencyMS,\n            minHeartbeatFrequencyMS: minHeartbeatFrequencyMS\n        });\n    }\n    close() {\n        if (isInCloseState(this)) {\n            return;\n        }\n        stateTransition(this, common_1.STATE_CLOSING);\n        resetMonitorState(this);\n        // close monitor\n        this.emit('close');\n        stateTransition(this, common_1.STATE_CLOSED);\n    }\n}\nexports.Monitor = Monitor;\nfunction resetMonitorState(monitor) {\n    monitor[kMonitorId]?.stop();\n    monitor[kMonitorId] = undefined;\n    monitor.rttPinger?.close();\n    monitor.rttPinger = undefined;\n    monitor[kCancellationToken].emit('cancel');\n    monitor[kConnection]?.destroy({ force: true });\n    monitor[kConnection] = undefined;\n}\nfunction useStreamingProtocol(monitor, topologyVersion) {\n    // If we have no topology version we always poll no matter\n    // what the user provided, since the server does not support\n    // the streaming protocol.\n    if (topologyVersion == null)\n        return false;\n    const serverMonitoringMode = monitor.options.serverMonitoringMode;\n    if (serverMonitoringMode === exports.ServerMonitoringMode.poll)\n        return false;\n    if (serverMonitoringMode === exports.ServerMonitoringMode.stream)\n        return true;\n    // If we are in auto mode, we need to figure out if we're in a FaaS\n    // environment or not and choose the appropriate mode.\n    if (monitor.isRunningInFaasEnv)\n        return false;\n    return true;\n}\nfunction checkServer(monitor, callback) {\n    let start = (0, utils_1.now)();\n    const topologyVersion = monitor[kServer].description.topologyVersion;\n    const isAwaitable = useStreamingProtocol(monitor, topologyVersion);\n    monitor.emit(server_1.Server.SERVER_HEARTBEAT_STARTED, new events_1.ServerHeartbeatStartedEvent(monitor.address, isAwaitable));\n    function failureHandler(err, awaited) {\n        monitor[kConnection]?.destroy({ force: true });\n        monitor[kConnection] = undefined;\n        monitor.emit(server_1.Server.SERVER_HEARTBEAT_FAILED, new events_1.ServerHeartbeatFailedEvent(monitor.address, (0, utils_1.calculateDurationInMs)(start), err, awaited));\n        const error = !(err instanceof error_1.MongoError)\n            ? new error_1.MongoError(error_1.MongoError.buildErrorMessage(err), { cause: err })\n            : err;\n        error.addErrorLabel(error_1.MongoErrorLabel.ResetPool);\n        if (error instanceof error_1.MongoNetworkTimeoutError) {\n            error.addErrorLabel(error_1.MongoErrorLabel.InterruptInUseConnections);\n        }\n        monitor.emit('resetServer', error);\n        callback(err);\n    }\n    const connection = monitor[kConnection];\n    if (connection && !connection.closed) {\n        const { serverApi, helloOk } = connection;\n        const connectTimeoutMS = monitor.options.connectTimeoutMS;\n        const maxAwaitTimeMS = monitor.options.heartbeatFrequencyMS;\n        const cmd = {\n            [serverApi?.version || helloOk ? 'hello' : constants_1.LEGACY_HELLO_COMMAND]: 1,\n            ...(isAwaitable && topologyVersion\n                ? { maxAwaitTimeMS, topologyVersion: makeTopologyVersion(topologyVersion) }\n                : {})\n        };\n        const options = isAwaitable\n            ? {\n                socketTimeoutMS: connectTimeoutMS ? connectTimeoutMS + maxAwaitTimeMS : 0,\n                exhaustAllowed: true\n            }\n            : { socketTimeoutMS: connectTimeoutMS };\n        if (isAwaitable && monitor.rttPinger == null) {\n            monitor.rttPinger = new RTTPinger(monitor[kCancellationToken], Object.assign({ heartbeatFrequencyMS: monitor.options.heartbeatFrequencyMS }, monitor.connectOptions));\n        }\n        connection.command((0, utils_1.ns)('admin.$cmd'), cmd, options, (err, hello) => {\n            if (err) {\n                return failureHandler(err, isAwaitable);\n            }\n            if (!('isWritablePrimary' in hello)) {\n                // Provide hello-style response document.\n                hello.isWritablePrimary = hello[constants_1.LEGACY_HELLO_COMMAND];\n            }\n            const duration = isAwaitable && monitor.rttPinger\n                ? monitor.rttPinger.roundTripTime\n                : (0, utils_1.calculateDurationInMs)(start);\n            monitor.emit(server_1.Server.SERVER_HEARTBEAT_SUCCEEDED, new events_1.ServerHeartbeatSucceededEvent(monitor.address, duration, hello, isAwaitable));\n            // If we are using the streaming protocol then we immediately issue another 'started'\n            // event, otherwise the \"check\" is complete and return to the main monitor loop.\n            if (isAwaitable) {\n                monitor.emit(server_1.Server.SERVER_HEARTBEAT_STARTED, new events_1.ServerHeartbeatStartedEvent(monitor.address, true));\n                start = (0, utils_1.now)();\n            }\n            else {\n                monitor.rttPinger?.close();\n                monitor.rttPinger = undefined;\n                callback(undefined, hello);\n            }\n        });\n        return;\n    }\n    // connecting does an implicit `hello`\n    (0, connect_1.connect)(monitor.connectOptions, (err, conn) => {\n        if (err) {\n            monitor[kConnection] = undefined;\n            failureHandler(err, false);\n            return;\n        }\n        if (conn) {\n            // Tell the connection that we are using the streaming protocol so that the\n            // connection's message stream will only read the last hello on the buffer.\n            conn.isMonitoringConnection = true;\n            if (isInCloseState(monitor)) {\n                conn.destroy({ force: true });\n                return;\n            }\n            monitor[kConnection] = conn;\n            monitor.emit(server_1.Server.SERVER_HEARTBEAT_SUCCEEDED, new events_1.ServerHeartbeatSucceededEvent(monitor.address, (0, utils_1.calculateDurationInMs)(start), conn.hello, useStreamingProtocol(monitor, conn.hello?.topologyVersion)));\n            callback(undefined, conn.hello);\n        }\n    });\n}\nfunction monitorServer(monitor) {\n    return (callback) => {\n        if (monitor.s.state === STATE_MONITORING) {\n            process.nextTick(callback);\n            return;\n        }\n        stateTransition(monitor, STATE_MONITORING);\n        function done() {\n            if (!isInCloseState(monitor)) {\n                stateTransition(monitor, STATE_IDLE);\n            }\n            callback();\n        }\n        checkServer(monitor, (err, hello) => {\n            if (err) {\n                // otherwise an error occurred on initial discovery, also bail\n                if (monitor[kServer].description.type === common_1.ServerType.Unknown) {\n                    return done();\n                }\n            }\n            // if the check indicates streaming is supported, immediately reschedule monitoring\n            if (useStreamingProtocol(monitor, hello?.topologyVersion)) {\n                (0, timers_1.setTimeout)(() => {\n                    if (!isInCloseState(monitor)) {\n                        monitor[kMonitorId]?.wake();\n                    }\n                }, 0);\n            }\n            done();\n        });\n    };\n}\nfunction makeTopologyVersion(tv) {\n    return {\n        processId: tv.processId,\n        // tests mock counter as just number, but in a real situation counter should always be a Long\n        // TODO(NODE-2674): Preserve int64 sent from MongoDB\n        counter: bson_1.Long.isLong(tv.counter) ? tv.counter : bson_1.Long.fromNumber(tv.counter)\n    };\n}\n/** @internal */\nclass RTTPinger {\n    constructor(cancellationToken, options) {\n        this.connection = undefined;\n        this[kCancellationToken] = cancellationToken;\n        this[kRoundTripTime] = 0;\n        this.closed = false;\n        const heartbeatFrequencyMS = options.heartbeatFrequencyMS;\n        this[kMonitorId] = (0, timers_1.setTimeout)(() => measureRoundTripTime(this, options), heartbeatFrequencyMS);\n    }\n    get roundTripTime() {\n        return this[kRoundTripTime];\n    }\n    close() {\n        this.closed = true;\n        (0, timers_1.clearTimeout)(this[kMonitorId]);\n        this.connection?.destroy({ force: true });\n        this.connection = undefined;\n    }\n}\nexports.RTTPinger = RTTPinger;\nfunction measureRoundTripTime(rttPinger, options) {\n    const start = (0, utils_1.now)();\n    options.cancellationToken = rttPinger[kCancellationToken];\n    const heartbeatFrequencyMS = options.heartbeatFrequencyMS;\n    if (rttPinger.closed) {\n        return;\n    }\n    function measureAndReschedule(conn) {\n        if (rttPinger.closed) {\n            conn?.destroy({ force: true });\n            return;\n        }\n        if (rttPinger.connection == null) {\n            rttPinger.connection = conn;\n        }\n        rttPinger[kRoundTripTime] = (0, utils_1.calculateDurationInMs)(start);\n        rttPinger[kMonitorId] = (0, timers_1.setTimeout)(() => measureRoundTripTime(rttPinger, options), heartbeatFrequencyMS);\n    }\n    const connection = rttPinger.connection;\n    if (connection == null) {\n        (0, connect_1.connect)(options, (err, conn) => {\n            if (err) {\n                rttPinger.connection = undefined;\n                rttPinger[kRoundTripTime] = 0;\n                return;\n            }\n            measureAndReschedule(conn);\n        });\n        return;\n    }\n    const commandName = connection.serverApi?.version || connection.helloOk ? 'hello' : constants_1.LEGACY_HELLO_COMMAND;\n    connection.commandAsync((0, utils_1.ns)('admin.$cmd'), { [commandName]: 1 }, undefined).then(() => measureAndReschedule(), () => {\n        rttPinger.connection?.destroy({ force: true });\n        rttPinger.connection = undefined;\n        rttPinger[kRoundTripTime] = 0;\n        return;\n    });\n}\n/**\n * @internal\n */\nclass MonitorInterval {\n    constructor(fn, options = {}) {\n        this.isExpeditedCallToFnScheduled = false;\n        this.stopped = false;\n        this.isExecutionInProgress = false;\n        this.hasExecutedOnce = false;\n        this._executeAndReschedule = () => {\n            if (this.stopped)\n                return;\n            if (this.timerId) {\n                (0, timers_1.clearTimeout)(this.timerId);\n            }\n            this.isExpeditedCallToFnScheduled = false;\n            this.isExecutionInProgress = true;\n            this.fn(() => {\n                this.lastExecutionEnded = (0, utils_1.now)();\n                this.isExecutionInProgress = false;\n                this._reschedule(this.heartbeatFrequencyMS);\n            });\n        };\n        this.fn = fn;\n        this.lastExecutionEnded = -Infinity;\n        this.heartbeatFrequencyMS = options.heartbeatFrequencyMS ?? 1000;\n        this.minHeartbeatFrequencyMS = options.minHeartbeatFrequencyMS ?? 500;\n        if (options.immediate) {\n            this._executeAndReschedule();\n        }\n        else {\n            this._reschedule(undefined);\n        }\n    }\n    wake() {\n        const currentTime = (0, utils_1.now)();\n        const timeSinceLastCall = currentTime - this.lastExecutionEnded;\n        // TODO(NODE-4674): Add error handling and logging to the monitor\n        if (timeSinceLastCall < 0) {\n            return this._executeAndReschedule();\n        }\n        if (this.isExecutionInProgress) {\n            return;\n        }\n        // debounce multiple calls to wake within the `minInterval`\n        if (this.isExpeditedCallToFnScheduled) {\n            return;\n        }\n        // reschedule a call as soon as possible, ensuring the call never happens\n        // faster than the `minInterval`\n        if (timeSinceLastCall < this.minHeartbeatFrequencyMS) {\n            this.isExpeditedCallToFnScheduled = true;\n            this._reschedule(this.minHeartbeatFrequencyMS - timeSinceLastCall);\n            return;\n        }\n        this._executeAndReschedule();\n    }\n    stop() {\n        this.stopped = true;\n        if (this.timerId) {\n            (0, timers_1.clearTimeout)(this.timerId);\n            this.timerId = undefined;\n        }\n        this.lastExecutionEnded = -Infinity;\n        this.isExpeditedCallToFnScheduled = false;\n    }\n    toString() {\n        return JSON.stringify(this);\n    }\n    toJSON() {\n        const currentTime = (0, utils_1.now)();\n        const timeSinceLastCall = currentTime - this.lastExecutionEnded;\n        return {\n            timerId: this.timerId != null ? 'set' : 'cleared',\n            lastCallTime: this.lastExecutionEnded,\n            isExpeditedCheckScheduled: this.isExpeditedCallToFnScheduled,\n            stopped: this.stopped,\n            heartbeatFrequencyMS: this.heartbeatFrequencyMS,\n            minHeartbeatFrequencyMS: this.minHeartbeatFrequencyMS,\n            currentTime,\n            timeSinceLastCall\n        };\n    }\n    _reschedule(ms) {\n        if (this.stopped)\n            return;\n        if (this.timerId) {\n            (0, timers_1.clearTimeout)(this.timerId);\n        }\n        this.timerId = (0, timers_1.setTimeout)(this._executeAndReschedule, ms || this.heartbeatFrequencyMS);\n    }\n}\nexports.MonitorInterval = MonitorInterval;\n//# sourceMappingURL=monitor.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/sdam/monitor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/server.js":
/*!*************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/server.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Server = void 0;\nconst util_1 = __webpack_require__(/*! util */ \"util\");\nconst connection_1 = __webpack_require__(/*! ../cmap/connection */ \"./node_modules/mongodb/lib/cmap/connection.js\");\nconst connection_pool_1 = __webpack_require__(/*! ../cmap/connection_pool */ \"./node_modules/mongodb/lib/cmap/connection_pool.js\");\nconst errors_1 = __webpack_require__(/*! ../cmap/errors */ \"./node_modules/mongodb/lib/cmap/errors.js\");\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_types_1 = __webpack_require__(/*! ../mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst transactions_1 = __webpack_require__(/*! ../transactions */ \"./node_modules/mongodb/lib/transactions.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst common_1 = __webpack_require__(/*! ./common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst monitor_1 = __webpack_require__(/*! ./monitor */ \"./node_modules/mongodb/lib/sdam/monitor.js\");\nconst server_description_1 = __webpack_require__(/*! ./server_description */ \"./node_modules/mongodb/lib/sdam/server_description.js\");\nconst stateTransition = (0, utils_1.makeStateMachine)({\n    [common_1.STATE_CLOSED]: [common_1.STATE_CLOSED, common_1.STATE_CONNECTING],\n    [common_1.STATE_CONNECTING]: [common_1.STATE_CONNECTING, common_1.STATE_CLOSING, common_1.STATE_CONNECTED, common_1.STATE_CLOSED],\n    [common_1.STATE_CONNECTED]: [common_1.STATE_CONNECTED, common_1.STATE_CLOSING, common_1.STATE_CLOSED],\n    [common_1.STATE_CLOSING]: [common_1.STATE_CLOSING, common_1.STATE_CLOSED]\n});\n/** @internal */\nclass Server extends mongo_types_1.TypedEventEmitter {\n    /**\n     * Create a server\n     */\n    constructor(topology, description, options) {\n        super();\n        this.commandAsync = (0, util_1.promisify)((ns, cmd, options, \n        // callback type defines Document result because result is never nullish when it succeeds, otherwise promise rejects\n        callback) => this.command(ns, cmd, options, callback));\n        this.serverApi = options.serverApi;\n        const poolOptions = { hostAddress: description.hostAddress, ...options };\n        this.topology = topology;\n        this.pool = new connection_pool_1.ConnectionPool(this, poolOptions);\n        this.s = {\n            description,\n            options,\n            state: common_1.STATE_CLOSED,\n            operationCount: 0\n        };\n        for (const event of [...constants_1.CMAP_EVENTS, ...constants_1.APM_EVENTS]) {\n            this.pool.on(event, (e) => this.emit(event, e));\n        }\n        this.pool.on(connection_1.Connection.CLUSTER_TIME_RECEIVED, (clusterTime) => {\n            this.clusterTime = clusterTime;\n        });\n        if (this.loadBalanced) {\n            this.monitor = null;\n            // monitoring is disabled in load balancing mode\n            return;\n        }\n        // create the monitor\n        this.monitor = new monitor_1.Monitor(this, this.s.options);\n        for (const event of constants_1.HEARTBEAT_EVENTS) {\n            this.monitor.on(event, (e) => this.emit(event, e));\n        }\n        this.monitor.on('resetServer', (error) => markServerUnknown(this, error));\n        this.monitor.on(Server.SERVER_HEARTBEAT_SUCCEEDED, (event) => {\n            this.emit(Server.DESCRIPTION_RECEIVED, new server_description_1.ServerDescription(this.description.hostAddress, event.reply, {\n                roundTripTime: calculateRoundTripTime(this.description.roundTripTime, event.duration)\n            }));\n            if (this.s.state === common_1.STATE_CONNECTING) {\n                stateTransition(this, common_1.STATE_CONNECTED);\n                this.emit(Server.CONNECT, this);\n            }\n        });\n    }\n    get clusterTime() {\n        return this.topology.clusterTime;\n    }\n    set clusterTime(clusterTime) {\n        this.topology.clusterTime = clusterTime;\n    }\n    get description() {\n        return this.s.description;\n    }\n    get name() {\n        return this.s.description.address;\n    }\n    get autoEncrypter() {\n        if (this.s.options && this.s.options.autoEncrypter) {\n            return this.s.options.autoEncrypter;\n        }\n        return;\n    }\n    get loadBalanced() {\n        return this.topology.description.type === common_1.TopologyType.LoadBalanced;\n    }\n    /**\n     * Initiate server connect\n     */\n    connect() {\n        if (this.s.state !== common_1.STATE_CLOSED) {\n            return;\n        }\n        stateTransition(this, common_1.STATE_CONNECTING);\n        // If in load balancer mode we automatically set the server to\n        // a load balancer. It never transitions out of this state and\n        // has no monitor.\n        if (!this.loadBalanced) {\n            this.monitor?.connect();\n        }\n        else {\n            stateTransition(this, common_1.STATE_CONNECTED);\n            this.emit(Server.CONNECT, this);\n        }\n    }\n    /** Destroy the server connection */\n    destroy(options, callback) {\n        if (typeof options === 'function') {\n            callback = options;\n            options = { force: false };\n        }\n        options = Object.assign({}, { force: false }, options);\n        if (this.s.state === common_1.STATE_CLOSED) {\n            if (typeof callback === 'function') {\n                callback();\n            }\n            return;\n        }\n        stateTransition(this, common_1.STATE_CLOSING);\n        if (!this.loadBalanced) {\n            this.monitor?.close();\n        }\n        this.pool.close(options, err => {\n            stateTransition(this, common_1.STATE_CLOSED);\n            this.emit('closed');\n            if (typeof callback === 'function') {\n                callback(err);\n            }\n        });\n    }\n    /**\n     * Immediately schedule monitoring of this server. If there already an attempt being made\n     * this will be a no-op.\n     */\n    requestCheck() {\n        if (!this.loadBalanced) {\n            this.monitor?.requestCheck();\n        }\n    }\n    /**\n     * Execute a command\n     * @internal\n     */\n    command(ns, cmd, options, callback) {\n        if (callback == null) {\n            throw new error_1.MongoInvalidArgumentError('Callback must be provided');\n        }\n        if (ns.db == null || typeof ns === 'string') {\n            throw new error_1.MongoInvalidArgumentError('Namespace must not be a string');\n        }\n        if (this.s.state === common_1.STATE_CLOSING || this.s.state === common_1.STATE_CLOSED) {\n            callback(new error_1.MongoServerClosedError());\n            return;\n        }\n        // Clone the options\n        const finalOptions = Object.assign({}, options, { wireProtocolCommand: false });\n        // There are cases where we need to flag the read preference not to get sent in\n        // the command, such as pre-5.0 servers attempting to perform an aggregate write\n        // with a non-primary read preference. In this case the effective read preference\n        // (primary) is not the same as the provided and must be removed completely.\n        if (finalOptions.omitReadPreference) {\n            delete finalOptions.readPreference;\n        }\n        const session = finalOptions.session;\n        const conn = session?.pinnedConnection;\n        // NOTE: This is a hack! We can't retrieve the connections used for executing an operation\n        //       (and prevent them from being checked back in) at the point of operation execution.\n        //       This should be considered as part of the work for NODE-2882\n        // NOTE:\n        //       When incrementing operation count, it's important that we increment it before we\n        //       attempt to check out a connection from the pool.  This ensures that operations that\n        //       are waiting for a connection are included in the operation count.  Load balanced\n        //       mode will only ever have a single server, so the operation count doesn't matter.\n        //       Incrementing the operation count above the logic to handle load balanced mode would\n        //       require special logic to decrement it again, or would double increment (the load\n        //       balanced code makes a recursive call).  Instead, we increment the count after this\n        //       check.\n        if (this.loadBalanced && session && conn == null && isPinnableCommand(cmd, session)) {\n            this.pool.checkOut((err, checkedOut) => {\n                if (err || checkedOut == null) {\n                    if (callback)\n                        return callback(err);\n                    return;\n                }\n                session.pin(checkedOut);\n                this.command(ns, cmd, finalOptions, callback);\n            });\n            return;\n        }\n        this.incrementOperationCount();\n        this.pool.withConnection(conn, (err, conn, cb) => {\n            if (err || !conn) {\n                this.decrementOperationCount();\n                if (!err) {\n                    return cb(new error_1.MongoRuntimeError('Failed to create connection without error'));\n                }\n                if (!(err instanceof errors_1.PoolClearedError)) {\n                    this.handleError(err);\n                }\n                return cb(err);\n            }\n            conn.command(ns, cmd, finalOptions, makeOperationHandler(this, conn, cmd, finalOptions, (error, response) => {\n                this.decrementOperationCount();\n                cb(error, response);\n            }));\n        }, callback);\n    }\n    /**\n     * Handle SDAM error\n     * @internal\n     */\n    handleError(error, connection) {\n        if (!(error instanceof error_1.MongoError)) {\n            return;\n        }\n        const isStaleError = error.connectionGeneration && error.connectionGeneration < this.pool.generation;\n        if (isStaleError) {\n            return;\n        }\n        const isNetworkNonTimeoutError = error instanceof error_1.MongoNetworkError && !(error instanceof error_1.MongoNetworkTimeoutError);\n        const isNetworkTimeoutBeforeHandshakeError = (0, error_1.isNetworkErrorBeforeHandshake)(error);\n        const isAuthHandshakeError = error.hasErrorLabel(error_1.MongoErrorLabel.HandshakeError);\n        if (isNetworkNonTimeoutError || isNetworkTimeoutBeforeHandshakeError || isAuthHandshakeError) {\n            // In load balanced mode we never mark the server as unknown and always\n            // clear for the specific service id.\n            if (!this.loadBalanced) {\n                error.addErrorLabel(error_1.MongoErrorLabel.ResetPool);\n                markServerUnknown(this, error);\n            }\n            else if (connection) {\n                this.pool.clear({ serviceId: connection.serviceId });\n            }\n        }\n        else {\n            if ((0, error_1.isSDAMUnrecoverableError)(error)) {\n                if (shouldHandleStateChangeError(this, error)) {\n                    const shouldClearPool = (0, utils_1.maxWireVersion)(this) <= 7 || (0, error_1.isNodeShuttingDownError)(error);\n                    if (this.loadBalanced && connection && shouldClearPool) {\n                        this.pool.clear({ serviceId: connection.serviceId });\n                    }\n                    if (!this.loadBalanced) {\n                        if (shouldClearPool) {\n                            error.addErrorLabel(error_1.MongoErrorLabel.ResetPool);\n                        }\n                        markServerUnknown(this, error);\n                        process.nextTick(() => this.requestCheck());\n                    }\n                }\n            }\n        }\n    }\n    /**\n     * Decrement the operation count, returning the new count.\n     */\n    decrementOperationCount() {\n        return (this.s.operationCount -= 1);\n    }\n    /**\n     * Increment the operation count, returning the new count.\n     */\n    incrementOperationCount() {\n        return (this.s.operationCount += 1);\n    }\n}\n/** @event */\nServer.SERVER_HEARTBEAT_STARTED = constants_1.SERVER_HEARTBEAT_STARTED;\n/** @event */\nServer.SERVER_HEARTBEAT_SUCCEEDED = constants_1.SERVER_HEARTBEAT_SUCCEEDED;\n/** @event */\nServer.SERVER_HEARTBEAT_FAILED = constants_1.SERVER_HEARTBEAT_FAILED;\n/** @event */\nServer.CONNECT = constants_1.CONNECT;\n/** @event */\nServer.DESCRIPTION_RECEIVED = constants_1.DESCRIPTION_RECEIVED;\n/** @event */\nServer.CLOSED = constants_1.CLOSED;\n/** @event */\nServer.ENDED = constants_1.ENDED;\nexports.Server = Server;\nfunction calculateRoundTripTime(oldRtt, duration) {\n    if (oldRtt === -1) {\n        return duration;\n    }\n    const alpha = 0.2;\n    return alpha * duration + (1 - alpha) * oldRtt;\n}\nfunction markServerUnknown(server, error) {\n    // Load balancer servers can never be marked unknown.\n    if (server.loadBalanced) {\n        return;\n    }\n    if (error instanceof error_1.MongoNetworkError && !(error instanceof error_1.MongoNetworkTimeoutError)) {\n        server.monitor?.reset();\n    }\n    server.emit(Server.DESCRIPTION_RECEIVED, new server_description_1.ServerDescription(server.description.hostAddress, undefined, { error }));\n}\nfunction isPinnableCommand(cmd, session) {\n    if (session) {\n        return (session.inTransaction() ||\n            'aggregate' in cmd ||\n            'find' in cmd ||\n            'getMore' in cmd ||\n            'listCollections' in cmd ||\n            'listIndexes' in cmd);\n    }\n    return false;\n}\nfunction connectionIsStale(pool, connection) {\n    if (connection.serviceId) {\n        return (connection.generation !== pool.serviceGenerations.get(connection.serviceId.toHexString()));\n    }\n    return connection.generation !== pool.generation;\n}\nfunction shouldHandleStateChangeError(server, err) {\n    const etv = err.topologyVersion;\n    const stv = server.description.topologyVersion;\n    return (0, server_description_1.compareTopologyVersion)(stv, etv) < 0;\n}\nfunction inActiveTransaction(session, cmd) {\n    return session && session.inTransaction() && !(0, transactions_1.isTransactionCommand)(cmd);\n}\n/** this checks the retryWrites option passed down from the client options, it\n * does not check if the server supports retryable writes */\nfunction isRetryableWritesEnabled(topology) {\n    return topology.s.options.retryWrites !== false;\n}\nfunction makeOperationHandler(server, connection, cmd, options, callback) {\n    const session = options?.session;\n    return function handleOperationResult(error, result) {\n        // We should not swallow an error if it is present.\n        if (error == null && result != null) {\n            return callback(undefined, result);\n        }\n        if (options != null && 'noResponse' in options && options.noResponse === true) {\n            return callback(undefined, null);\n        }\n        if (!error) {\n            return callback(new error_1.MongoUnexpectedServerResponseError('Empty response with no error'));\n        }\n        if (!(error instanceof error_1.MongoError)) {\n            // Node.js or some other error we have not special handling for\n            return callback(error);\n        }\n        if (connectionIsStale(server.pool, connection)) {\n            return callback(error);\n        }\n        if (error instanceof error_1.MongoNetworkError) {\n            if (session && !session.hasEnded && session.serverSession) {\n                session.serverSession.isDirty = true;\n            }\n            // inActiveTransaction check handles commit and abort.\n            if (inActiveTransaction(session, cmd) &&\n                !error.hasErrorLabel(error_1.MongoErrorLabel.TransientTransactionError)) {\n                error.addErrorLabel(error_1.MongoErrorLabel.TransientTransactionError);\n            }\n            if ((isRetryableWritesEnabled(server.topology) || (0, transactions_1.isTransactionCommand)(cmd)) &&\n                (0, utils_1.supportsRetryableWrites)(server) &&\n                !inActiveTransaction(session, cmd)) {\n                error.addErrorLabel(error_1.MongoErrorLabel.RetryableWriteError);\n            }\n        }\n        else {\n            if ((isRetryableWritesEnabled(server.topology) || (0, transactions_1.isTransactionCommand)(cmd)) &&\n                (0, error_1.needsRetryableWriteLabel)(error, (0, utils_1.maxWireVersion)(server)) &&\n                !inActiveTransaction(session, cmd)) {\n                error.addErrorLabel(error_1.MongoErrorLabel.RetryableWriteError);\n            }\n        }\n        if (session &&\n            session.isPinned &&\n            error.hasErrorLabel(error_1.MongoErrorLabel.TransientTransactionError)) {\n            session.unpin({ force: true });\n        }\n        server.handleError(error, connection);\n        return callback(error);\n    };\n}\n//# sourceMappingURL=server.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/sdam/server.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/server_description.js":
/*!*************************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/server_description.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.compareTopologyVersion = exports.parseServerType = exports.ServerDescription = void 0;\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst common_1 = __webpack_require__(/*! ./common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst WRITABLE_SERVER_TYPES = new Set([\n    common_1.ServerType.RSPrimary,\n    common_1.ServerType.Standalone,\n    common_1.ServerType.Mongos,\n    common_1.ServerType.LoadBalancer\n]);\nconst DATA_BEARING_SERVER_TYPES = new Set([\n    common_1.ServerType.RSPrimary,\n    common_1.ServerType.RSSecondary,\n    common_1.ServerType.Mongos,\n    common_1.ServerType.Standalone,\n    common_1.ServerType.LoadBalancer\n]);\n/**\n * The client's view of a single server, based on the most recent hello outcome.\n *\n * Internal type, not meant to be directly instantiated\n * @public\n */\nclass ServerDescription {\n    /**\n     * Create a ServerDescription\n     * @internal\n     *\n     * @param address - The address of the server\n     * @param hello - An optional hello response for this server\n     */\n    constructor(address, hello, options = {}) {\n        if (address == null || address === '') {\n            throw new error_1.MongoRuntimeError('ServerDescription must be provided with a non-empty address');\n        }\n        this.address =\n            typeof address === 'string'\n                ? utils_1.HostAddress.fromString(address).toString() // Use HostAddress to normalize\n                : address.toString();\n        this.type = parseServerType(hello, options);\n        this.hosts = hello?.hosts?.map((host) => host.toLowerCase()) ?? [];\n        this.passives = hello?.passives?.map((host) => host.toLowerCase()) ?? [];\n        this.arbiters = hello?.arbiters?.map((host) => host.toLowerCase()) ?? [];\n        this.tags = hello?.tags ?? {};\n        this.minWireVersion = hello?.minWireVersion ?? 0;\n        this.maxWireVersion = hello?.maxWireVersion ?? 0;\n        this.roundTripTime = options?.roundTripTime ?? -1;\n        this.lastUpdateTime = (0, utils_1.now)();\n        this.lastWriteDate = hello?.lastWrite?.lastWriteDate ?? 0;\n        this.error = options.error ?? null;\n        // TODO(NODE-2674): Preserve int64 sent from MongoDB\n        this.topologyVersion = this.error?.topologyVersion ?? hello?.topologyVersion ?? null;\n        this.setName = hello?.setName ?? null;\n        this.setVersion = hello?.setVersion ?? null;\n        this.electionId = hello?.electionId ?? null;\n        this.logicalSessionTimeoutMinutes = hello?.logicalSessionTimeoutMinutes ?? null;\n        this.primary = hello?.primary ?? null;\n        this.me = hello?.me?.toLowerCase() ?? null;\n        this.$clusterTime = hello?.$clusterTime ?? null;\n    }\n    get hostAddress() {\n        return utils_1.HostAddress.fromString(this.address);\n    }\n    get allHosts() {\n        return this.hosts.concat(this.arbiters).concat(this.passives);\n    }\n    /** Is this server available for reads*/\n    get isReadable() {\n        return this.type === common_1.ServerType.RSSecondary || this.isWritable;\n    }\n    /** Is this server data bearing */\n    get isDataBearing() {\n        return DATA_BEARING_SERVER_TYPES.has(this.type);\n    }\n    /** Is this server available for writes */\n    get isWritable() {\n        return WRITABLE_SERVER_TYPES.has(this.type);\n    }\n    get host() {\n        const chopLength = `:${this.port}`.length;\n        return this.address.slice(0, -chopLength);\n    }\n    get port() {\n        const port = this.address.split(':').pop();\n        return port ? Number.parseInt(port, 10) : 27017;\n    }\n    /**\n     * Determines if another `ServerDescription` is equal to this one per the rules defined\n     * in the {@link https://github.com/mongodb/specifications/blob/master/source/server-discovery-and-monitoring/server-discovery-and-monitoring.rst#serverdescription|SDAM spec}\n     */\n    equals(other) {\n        // Despite using the comparator that would determine a nullish topologyVersion as greater than\n        // for equality we should only always perform direct equality comparison\n        const topologyVersionsEqual = this.topologyVersion === other?.topologyVersion ||\n            compareTopologyVersion(this.topologyVersion, other?.topologyVersion) === 0;\n        const electionIdsEqual = this.electionId != null && other?.electionId != null\n            ? (0, utils_1.compareObjectId)(this.electionId, other.electionId) === 0\n            : this.electionId === other?.electionId;\n        return (other != null &&\n            (0, utils_1.errorStrictEqual)(this.error, other.error) &&\n            this.type === other.type &&\n            this.minWireVersion === other.minWireVersion &&\n            (0, utils_1.arrayStrictEqual)(this.hosts, other.hosts) &&\n            tagsStrictEqual(this.tags, other.tags) &&\n            this.setName === other.setName &&\n            this.setVersion === other.setVersion &&\n            electionIdsEqual &&\n            this.primary === other.primary &&\n            this.logicalSessionTimeoutMinutes === other.logicalSessionTimeoutMinutes &&\n            topologyVersionsEqual);\n    }\n}\nexports.ServerDescription = ServerDescription;\n// Parses a `hello` message and determines the server type\nfunction parseServerType(hello, options) {\n    if (options?.loadBalanced) {\n        return common_1.ServerType.LoadBalancer;\n    }\n    if (!hello || !hello.ok) {\n        return common_1.ServerType.Unknown;\n    }\n    if (hello.isreplicaset) {\n        return common_1.ServerType.RSGhost;\n    }\n    if (hello.msg && hello.msg === 'isdbgrid') {\n        return common_1.ServerType.Mongos;\n    }\n    if (hello.setName) {\n        if (hello.hidden) {\n            return common_1.ServerType.RSOther;\n        }\n        else if (hello.isWritablePrimary) {\n            return common_1.ServerType.RSPrimary;\n        }\n        else if (hello.secondary) {\n            return common_1.ServerType.RSSecondary;\n        }\n        else if (hello.arbiterOnly) {\n            return common_1.ServerType.RSArbiter;\n        }\n        else {\n            return common_1.ServerType.RSOther;\n        }\n    }\n    return common_1.ServerType.Standalone;\n}\nexports.parseServerType = parseServerType;\nfunction tagsStrictEqual(tags, tags2) {\n    const tagsKeys = Object.keys(tags);\n    const tags2Keys = Object.keys(tags2);\n    return (tagsKeys.length === tags2Keys.length &&\n        tagsKeys.every((key) => tags2[key] === tags[key]));\n}\n/**\n * Compares two topology versions.\n *\n * 1. If the response topologyVersion is unset or the ServerDescription's\n *    topologyVersion is null, the client MUST assume the response is more recent.\n * 1. If the response's topologyVersion.processId is not equal to the\n *    ServerDescription's, the client MUST assume the response is more recent.\n * 1. If the response's topologyVersion.processId is equal to the\n *    ServerDescription's, the client MUST use the counter field to determine\n *    which topologyVersion is more recent.\n *\n * ```ts\n * currentTv <   newTv === -1\n * currentTv === newTv === 0\n * currentTv >   newTv === 1\n * ```\n */\nfunction compareTopologyVersion(currentTv, newTv) {\n    if (currentTv == null || newTv == null) {\n        return -1;\n    }\n    if (!currentTv.processId.equals(newTv.processId)) {\n        return -1;\n    }\n    // TODO(NODE-2674): Preserve int64 sent from MongoDB\n    const currentCounter = bson_1.Long.isLong(currentTv.counter)\n        ? currentTv.counter\n        : bson_1.Long.fromNumber(currentTv.counter);\n    const newCounter = bson_1.Long.isLong(newTv.counter) ? newTv.counter : bson_1.Long.fromNumber(newTv.counter);\n    return currentCounter.compare(newCounter);\n}\nexports.compareTopologyVersion = compareTopologyVersion;\n//# sourceMappingURL=server_description.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/sdam/server_description.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/server_selection.js":
/*!***********************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/server_selection.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.readPreferenceServerSelector = exports.secondaryWritableServerSelector = exports.sameServerSelector = exports.writableServerSelector = exports.MIN_SECONDARY_WRITE_WIRE_VERSION = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_preference_1 = __webpack_require__(/*! ../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst common_1 = __webpack_require__(/*! ./common */ \"./node_modules/mongodb/lib/sdam/common.js\");\n// max staleness constants\nconst IDLE_WRITE_PERIOD = 10000;\nconst SMALLEST_MAX_STALENESS_SECONDS = 90;\n//  Minimum version to try writes on secondaries.\nexports.MIN_SECONDARY_WRITE_WIRE_VERSION = 13;\n/**\n * Returns a server selector that selects for writable servers\n */\nfunction writableServerSelector() {\n    return (topologyDescription, servers) => latencyWindowReducer(topologyDescription, servers.filter((s) => s.isWritable));\n}\nexports.writableServerSelector = writableServerSelector;\n/**\n * The purpose of this selector is to select the same server, only\n * if it is in a state that it can have commands sent to it.\n */\nfunction sameServerSelector(description) {\n    return (topologyDescription, servers) => {\n        if (!description)\n            return [];\n        // Filter the servers to match the provided description only if\n        // the type is not unknown.\n        return servers.filter(sd => {\n            return sd.address === description.address && sd.type !== common_1.ServerType.Unknown;\n        });\n    };\n}\nexports.sameServerSelector = sameServerSelector;\n/**\n * Returns a server selector that uses a read preference to select a\n * server potentially for a write on a secondary.\n */\nfunction secondaryWritableServerSelector(wireVersion, readPreference) {\n    // If server version < 5.0, read preference always primary.\n    // If server version >= 5.0...\n    // - If read preference is supplied, use that.\n    // - If no read preference is supplied, use primary.\n    if (!readPreference ||\n        !wireVersion ||\n        (wireVersion && wireVersion < exports.MIN_SECONDARY_WRITE_WIRE_VERSION)) {\n        return readPreferenceServerSelector(read_preference_1.ReadPreference.primary);\n    }\n    return readPreferenceServerSelector(readPreference);\n}\nexports.secondaryWritableServerSelector = secondaryWritableServerSelector;\n/**\n * Reduces the passed in array of servers by the rules of the \"Max Staleness\" specification\n * found here: https://github.com/mongodb/specifications/blob/master/source/max-staleness/max-staleness.rst\n *\n * @param readPreference - The read preference providing max staleness guidance\n * @param topologyDescription - The topology description\n * @param servers - The list of server descriptions to be reduced\n * @returns The list of servers that satisfy the requirements of max staleness\n */\nfunction maxStalenessReducer(readPreference, topologyDescription, servers) {\n    if (readPreference.maxStalenessSeconds == null || readPreference.maxStalenessSeconds < 0) {\n        return servers;\n    }\n    const maxStaleness = readPreference.maxStalenessSeconds;\n    const maxStalenessVariance = (topologyDescription.heartbeatFrequencyMS + IDLE_WRITE_PERIOD) / 1000;\n    if (maxStaleness < maxStalenessVariance) {\n        throw new error_1.MongoInvalidArgumentError(`Option \"maxStalenessSeconds\" must be at least ${maxStalenessVariance} seconds`);\n    }\n    if (maxStaleness < SMALLEST_MAX_STALENESS_SECONDS) {\n        throw new error_1.MongoInvalidArgumentError(`Option \"maxStalenessSeconds\" must be at least ${SMALLEST_MAX_STALENESS_SECONDS} seconds`);\n    }\n    if (topologyDescription.type === common_1.TopologyType.ReplicaSetWithPrimary) {\n        const primary = Array.from(topologyDescription.servers.values()).filter(primaryFilter)[0];\n        return servers.reduce((result, server) => {\n            const stalenessMS = server.lastUpdateTime -\n                server.lastWriteDate -\n                (primary.lastUpdateTime - primary.lastWriteDate) +\n                topologyDescription.heartbeatFrequencyMS;\n            const staleness = stalenessMS / 1000;\n            const maxStalenessSeconds = readPreference.maxStalenessSeconds ?? 0;\n            if (staleness <= maxStalenessSeconds) {\n                result.push(server);\n            }\n            return result;\n        }, []);\n    }\n    if (topologyDescription.type === common_1.TopologyType.ReplicaSetNoPrimary) {\n        if (servers.length === 0) {\n            return servers;\n        }\n        const sMax = servers.reduce((max, s) => s.lastWriteDate > max.lastWriteDate ? s : max);\n        return servers.reduce((result, server) => {\n            const stalenessMS = sMax.lastWriteDate - server.lastWriteDate + topologyDescription.heartbeatFrequencyMS;\n            const staleness = stalenessMS / 1000;\n            const maxStalenessSeconds = readPreference.maxStalenessSeconds ?? 0;\n            if (staleness <= maxStalenessSeconds) {\n                result.push(server);\n            }\n            return result;\n        }, []);\n    }\n    return servers;\n}\n/**\n * Determines whether a server's tags match a given set of tags\n *\n * @param tagSet - The requested tag set to match\n * @param serverTags - The server's tags\n */\nfunction tagSetMatch(tagSet, serverTags) {\n    const keys = Object.keys(tagSet);\n    const serverTagKeys = Object.keys(serverTags);\n    for (let i = 0; i < keys.length; ++i) {\n        const key = keys[i];\n        if (serverTagKeys.indexOf(key) === -1 || serverTags[key] !== tagSet[key]) {\n            return false;\n        }\n    }\n    return true;\n}\n/**\n * Reduces a set of server descriptions based on tags requested by the read preference\n *\n * @param readPreference - The read preference providing the requested tags\n * @param servers - The list of server descriptions to reduce\n * @returns The list of servers matching the requested tags\n */\nfunction tagSetReducer(readPreference, servers) {\n    if (readPreference.tags == null ||\n        (Array.isArray(readPreference.tags) && readPreference.tags.length === 0)) {\n        return servers;\n    }\n    for (let i = 0; i < readPreference.tags.length; ++i) {\n        const tagSet = readPreference.tags[i];\n        const serversMatchingTagset = servers.reduce((matched, server) => {\n            if (tagSetMatch(tagSet, server.tags))\n                matched.push(server);\n            return matched;\n        }, []);\n        if (serversMatchingTagset.length) {\n            return serversMatchingTagset;\n        }\n    }\n    return [];\n}\n/**\n * Reduces a list of servers to ensure they fall within an acceptable latency window. This is\n * further specified in the \"Server Selection\" specification, found here:\n * https://github.com/mongodb/specifications/blob/master/source/server-selection/server-selection.rst\n *\n * @param topologyDescription - The topology description\n * @param servers - The list of servers to reduce\n * @returns The servers which fall within an acceptable latency window\n */\nfunction latencyWindowReducer(topologyDescription, servers) {\n    const low = servers.reduce((min, server) => min === -1 ? server.roundTripTime : Math.min(server.roundTripTime, min), -1);\n    const high = low + topologyDescription.localThresholdMS;\n    return servers.reduce((result, server) => {\n        if (server.roundTripTime <= high && server.roundTripTime >= low)\n            result.push(server);\n        return result;\n    }, []);\n}\n// filters\nfunction primaryFilter(server) {\n    return server.type === common_1.ServerType.RSPrimary;\n}\nfunction secondaryFilter(server) {\n    return server.type === common_1.ServerType.RSSecondary;\n}\nfunction nearestFilter(server) {\n    return server.type === common_1.ServerType.RSSecondary || server.type === common_1.ServerType.RSPrimary;\n}\nfunction knownFilter(server) {\n    return server.type !== common_1.ServerType.Unknown;\n}\nfunction loadBalancerFilter(server) {\n    return server.type === common_1.ServerType.LoadBalancer;\n}\n/**\n * Returns a function which selects servers based on a provided read preference\n *\n * @param readPreference - The read preference to select with\n */\nfunction readPreferenceServerSelector(readPreference) {\n    if (!readPreference.isValid()) {\n        throw new error_1.MongoInvalidArgumentError('Invalid read preference specified');\n    }\n    return (topologyDescription, servers) => {\n        const commonWireVersion = topologyDescription.commonWireVersion;\n        if (commonWireVersion &&\n            readPreference.minWireVersion &&\n            readPreference.minWireVersion > commonWireVersion) {\n            throw new error_1.MongoCompatibilityError(`Minimum wire version '${readPreference.minWireVersion}' required, but found '${commonWireVersion}'`);\n        }\n        if (topologyDescription.type === common_1.TopologyType.LoadBalanced) {\n            return servers.filter(loadBalancerFilter);\n        }\n        if (topologyDescription.type === common_1.TopologyType.Unknown) {\n            return [];\n        }\n        if (topologyDescription.type === common_1.TopologyType.Single ||\n            topologyDescription.type === common_1.TopologyType.Sharded) {\n            return latencyWindowReducer(topologyDescription, servers.filter(knownFilter));\n        }\n        const mode = readPreference.mode;\n        if (mode === read_preference_1.ReadPreference.PRIMARY) {\n            return servers.filter(primaryFilter);\n        }\n        if (mode === read_preference_1.ReadPreference.PRIMARY_PREFERRED) {\n            const result = servers.filter(primaryFilter);\n            if (result.length) {\n                return result;\n            }\n        }\n        const filter = mode === read_preference_1.ReadPreference.NEAREST ? nearestFilter : secondaryFilter;\n        const selectedServers = latencyWindowReducer(topologyDescription, tagSetReducer(readPreference, maxStalenessReducer(readPreference, topologyDescription, servers.filter(filter))));\n        if (mode === read_preference_1.ReadPreference.SECONDARY_PREFERRED && selectedServers.length === 0) {\n            return servers.filter(primaryFilter);\n        }\n        return selectedServers;\n    };\n}\nexports.readPreferenceServerSelector = readPreferenceServerSelector;\n//# sourceMappingURL=server_selection.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/sdam/server_selection.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/srv_polling.js":
/*!******************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/srv_polling.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SrvPoller = exports.SrvPollingEvent = void 0;\nconst dns = __webpack_require__(/*! dns */ \"dns\");\nconst timers_1 = __webpack_require__(/*! timers */ \"timers\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_types_1 = __webpack_require__(/*! ../mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\n/**\n * @internal\n * @category Event\n */\nclass SrvPollingEvent {\n    constructor(srvRecords) {\n        this.srvRecords = srvRecords;\n    }\n    hostnames() {\n        return new Set(this.srvRecords.map(r => utils_1.HostAddress.fromSrvRecord(r).toString()));\n    }\n}\nexports.SrvPollingEvent = SrvPollingEvent;\n/** @internal */\nclass SrvPoller extends mongo_types_1.TypedEventEmitter {\n    constructor(options) {\n        super();\n        if (!options || !options.srvHost) {\n            throw new error_1.MongoRuntimeError('Options for SrvPoller must exist and include srvHost');\n        }\n        this.srvHost = options.srvHost;\n        this.srvMaxHosts = options.srvMaxHosts ?? 0;\n        this.srvServiceName = options.srvServiceName ?? 'mongodb';\n        this.rescanSrvIntervalMS = 60000;\n        this.heartbeatFrequencyMS = options.heartbeatFrequencyMS ?? 10000;\n        this.haMode = false;\n        this.generation = 0;\n        this._timeout = undefined;\n    }\n    get srvAddress() {\n        return `_${this.srvServiceName}._tcp.${this.srvHost}`;\n    }\n    get intervalMS() {\n        return this.haMode ? this.heartbeatFrequencyMS : this.rescanSrvIntervalMS;\n    }\n    start() {\n        if (!this._timeout) {\n            this.schedule();\n        }\n    }\n    stop() {\n        if (this._timeout) {\n            (0, timers_1.clearTimeout)(this._timeout);\n            this.generation += 1;\n            this._timeout = undefined;\n        }\n    }\n    // TODO(NODE-4994): implement new logging logic for SrvPoller failures\n    schedule() {\n        if (this._timeout) {\n            (0, timers_1.clearTimeout)(this._timeout);\n        }\n        this._timeout = (0, timers_1.setTimeout)(() => {\n            this._poll().catch(() => null);\n        }, this.intervalMS);\n    }\n    success(srvRecords) {\n        this.haMode = false;\n        this.schedule();\n        this.emit(SrvPoller.SRV_RECORD_DISCOVERY, new SrvPollingEvent(srvRecords));\n    }\n    failure() {\n        this.haMode = true;\n        this.schedule();\n    }\n    async _poll() {\n        const generation = this.generation;\n        let srvRecords;\n        try {\n            srvRecords = await dns.promises.resolveSrv(this.srvAddress);\n        }\n        catch (dnsError) {\n            this.failure();\n            return;\n        }\n        if (generation !== this.generation) {\n            return;\n        }\n        const finalAddresses = [];\n        for (const record of srvRecords) {\n            if ((0, utils_1.matchesParentDomain)(record.name, this.srvHost)) {\n                finalAddresses.push(record);\n            }\n        }\n        if (!finalAddresses.length) {\n            this.failure();\n            return;\n        }\n        this.success(finalAddresses);\n    }\n}\n/** @event */\nSrvPoller.SRV_RECORD_DISCOVERY = 'srvRecordDiscovery';\nexports.SrvPoller = SrvPoller;\n//# sourceMappingURL=srv_polling.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/sdam/srv_polling.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/topology.js":
/*!***************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/topology.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ServerCapabilities = exports.Topology = void 0;\nconst util_1 = __webpack_require__(/*! util */ \"util\");\nconst connection_string_1 = __webpack_require__(/*! ../connection_string */ \"./node_modules/mongodb/lib/connection_string.js\");\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_types_1 = __webpack_require__(/*! ../mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst read_preference_1 = __webpack_require__(/*! ../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst common_1 = __webpack_require__(/*! ./common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst events_1 = __webpack_require__(/*! ./events */ \"./node_modules/mongodb/lib/sdam/events.js\");\nconst server_1 = __webpack_require__(/*! ./server */ \"./node_modules/mongodb/lib/sdam/server.js\");\nconst server_description_1 = __webpack_require__(/*! ./server_description */ \"./node_modules/mongodb/lib/sdam/server_description.js\");\nconst server_selection_1 = __webpack_require__(/*! ./server_selection */ \"./node_modules/mongodb/lib/sdam/server_selection.js\");\nconst srv_polling_1 = __webpack_require__(/*! ./srv_polling */ \"./node_modules/mongodb/lib/sdam/srv_polling.js\");\nconst topology_description_1 = __webpack_require__(/*! ./topology_description */ \"./node_modules/mongodb/lib/sdam/topology_description.js\");\n// Global state\nlet globalTopologyCounter = 0;\nconst stateTransition = (0, utils_1.makeStateMachine)({\n    [common_1.STATE_CLOSED]: [common_1.STATE_CLOSED, common_1.STATE_CONNECTING],\n    [common_1.STATE_CONNECTING]: [common_1.STATE_CONNECTING, common_1.STATE_CLOSING, common_1.STATE_CONNECTED, common_1.STATE_CLOSED],\n    [common_1.STATE_CONNECTED]: [common_1.STATE_CONNECTED, common_1.STATE_CLOSING, common_1.STATE_CLOSED],\n    [common_1.STATE_CLOSING]: [common_1.STATE_CLOSING, common_1.STATE_CLOSED]\n});\n/** @internal */\nconst kCancelled = Symbol('cancelled');\n/** @internal */\nconst kWaitQueue = Symbol('waitQueue');\n/**\n * A container of server instances representing a connection to a MongoDB topology.\n * @internal\n */\nclass Topology extends mongo_types_1.TypedEventEmitter {\n    /**\n     * @param seedlist - a list of HostAddress instances to connect to\n     */\n    constructor(client, seeds, options) {\n        super();\n        this.client = client;\n        this.selectServerAsync = (0, util_1.promisify)((selector, options, callback) => this.selectServer(selector, options, callback));\n        // Options should only be undefined in tests, MongoClient will always have defined options\n        options = options ?? {\n            hosts: [utils_1.HostAddress.fromString('localhost:27017')],\n            ...Object.fromEntries(connection_string_1.DEFAULT_OPTIONS.entries()),\n            ...Object.fromEntries(connection_string_1.FEATURE_FLAGS.entries())\n        };\n        if (typeof seeds === 'string') {\n            seeds = [utils_1.HostAddress.fromString(seeds)];\n        }\n        else if (!Array.isArray(seeds)) {\n            seeds = [seeds];\n        }\n        const seedlist = [];\n        for (const seed of seeds) {\n            if (typeof seed === 'string') {\n                seedlist.push(utils_1.HostAddress.fromString(seed));\n            }\n            else if (seed instanceof utils_1.HostAddress) {\n                seedlist.push(seed);\n            }\n            else {\n                // FIXME(NODE-3483): May need to be a MongoParseError\n                throw new error_1.MongoRuntimeError(`Topology cannot be constructed from ${JSON.stringify(seed)}`);\n            }\n        }\n        const topologyType = topologyTypeFromOptions(options);\n        const topologyId = globalTopologyCounter++;\n        const selectedHosts = options.srvMaxHosts == null ||\n            options.srvMaxHosts === 0 ||\n            options.srvMaxHosts >= seedlist.length\n            ? seedlist\n            : (0, utils_1.shuffle)(seedlist, options.srvMaxHosts);\n        const serverDescriptions = new Map();\n        for (const hostAddress of selectedHosts) {\n            serverDescriptions.set(hostAddress.toString(), new server_description_1.ServerDescription(hostAddress));\n        }\n        this[kWaitQueue] = new utils_1.List();\n        this.s = {\n            // the id of this topology\n            id: topologyId,\n            // passed in options\n            options,\n            // initial seedlist of servers to connect to\n            seedlist,\n            // initial state\n            state: common_1.STATE_CLOSED,\n            // the topology description\n            description: new topology_description_1.TopologyDescription(topologyType, serverDescriptions, options.replicaSet, undefined, undefined, undefined, options),\n            serverSelectionTimeoutMS: options.serverSelectionTimeoutMS,\n            heartbeatFrequencyMS: options.heartbeatFrequencyMS,\n            minHeartbeatFrequencyMS: options.minHeartbeatFrequencyMS,\n            // a map of server instances to normalized addresses\n            servers: new Map(),\n            credentials: options?.credentials,\n            clusterTime: undefined,\n            // timer management\n            connectionTimers: new Set(),\n            detectShardedTopology: ev => this.detectShardedTopology(ev),\n            detectSrvRecords: ev => this.detectSrvRecords(ev)\n        };\n        if (options.srvHost && !options.loadBalanced) {\n            this.s.srvPoller =\n                options.srvPoller ??\n                    new srv_polling_1.SrvPoller({\n                        heartbeatFrequencyMS: this.s.heartbeatFrequencyMS,\n                        srvHost: options.srvHost,\n                        srvMaxHosts: options.srvMaxHosts,\n                        srvServiceName: options.srvServiceName\n                    });\n            this.on(Topology.TOPOLOGY_DESCRIPTION_CHANGED, this.s.detectShardedTopology);\n        }\n    }\n    detectShardedTopology(event) {\n        const previousType = event.previousDescription.type;\n        const newType = event.newDescription.type;\n        const transitionToSharded = previousType !== common_1.TopologyType.Sharded && newType === common_1.TopologyType.Sharded;\n        const srvListeners = this.s.srvPoller?.listeners(srv_polling_1.SrvPoller.SRV_RECORD_DISCOVERY);\n        const listeningToSrvPolling = !!srvListeners?.includes(this.s.detectSrvRecords);\n        if (transitionToSharded && !listeningToSrvPolling) {\n            this.s.srvPoller?.on(srv_polling_1.SrvPoller.SRV_RECORD_DISCOVERY, this.s.detectSrvRecords);\n            this.s.srvPoller?.start();\n        }\n    }\n    detectSrvRecords(ev) {\n        const previousTopologyDescription = this.s.description;\n        this.s.description = this.s.description.updateFromSrvPollingEvent(ev, this.s.options.srvMaxHosts);\n        if (this.s.description === previousTopologyDescription) {\n            // Nothing changed, so return\n            return;\n        }\n        updateServers(this);\n        this.emit(Topology.TOPOLOGY_DESCRIPTION_CHANGED, new events_1.TopologyDescriptionChangedEvent(this.s.id, previousTopologyDescription, this.s.description));\n    }\n    /**\n     * @returns A `TopologyDescription` for this topology\n     */\n    get description() {\n        return this.s.description;\n    }\n    get loadBalanced() {\n        return this.s.options.loadBalanced;\n    }\n    get capabilities() {\n        return new ServerCapabilities(this.lastHello());\n    }\n    connect(options, callback) {\n        if (typeof options === 'function')\n            (callback = options), (options = {});\n        options = options ?? {};\n        if (this.s.state === common_1.STATE_CONNECTED) {\n            if (typeof callback === 'function') {\n                callback();\n            }\n            return;\n        }\n        stateTransition(this, common_1.STATE_CONNECTING);\n        // emit SDAM monitoring events\n        this.emit(Topology.TOPOLOGY_OPENING, new events_1.TopologyOpeningEvent(this.s.id));\n        // emit an event for the topology change\n        this.emit(Topology.TOPOLOGY_DESCRIPTION_CHANGED, new events_1.TopologyDescriptionChangedEvent(this.s.id, new topology_description_1.TopologyDescription(common_1.TopologyType.Unknown), // initial is always Unknown\n        this.s.description));\n        // connect all known servers, then attempt server selection to connect\n        const serverDescriptions = Array.from(this.s.description.servers.values());\n        this.s.servers = new Map(serverDescriptions.map(serverDescription => [\n            serverDescription.address,\n            createAndConnectServer(this, serverDescription)\n        ]));\n        // In load balancer mode we need to fake a server description getting\n        // emitted from the monitor, since the monitor doesn't exist.\n        if (this.s.options.loadBalanced) {\n            for (const description of serverDescriptions) {\n                const newDescription = new server_description_1.ServerDescription(description.hostAddress, undefined, {\n                    loadBalanced: this.s.options.loadBalanced\n                });\n                this.serverUpdateHandler(newDescription);\n            }\n        }\n        const exitWithError = (error) => callback ? callback(error) : this.emit(Topology.ERROR, error);\n        const readPreference = options.readPreference ?? read_preference_1.ReadPreference.primary;\n        this.selectServer((0, server_selection_1.readPreferenceServerSelector)(readPreference), options, (err, server) => {\n            if (err) {\n                return this.close({ force: false }, () => exitWithError(err));\n            }\n            // TODO: NODE-2471\n            const skipPingOnConnect = this.s.options[Symbol.for('@@mdb.skipPingOnConnect')] === true;\n            if (!skipPingOnConnect && server && this.s.credentials) {\n                server.command((0, utils_1.ns)('admin.$cmd'), { ping: 1 }, {}, err => {\n                    if (err) {\n                        return exitWithError(err);\n                    }\n                    stateTransition(this, common_1.STATE_CONNECTED);\n                    this.emit(Topology.OPEN, this);\n                    this.emit(Topology.CONNECT, this);\n                    callback?.(undefined, this);\n                });\n                return;\n            }\n            stateTransition(this, common_1.STATE_CONNECTED);\n            this.emit(Topology.OPEN, this);\n            this.emit(Topology.CONNECT, this);\n            callback?.(undefined, this);\n        });\n    }\n    close(options, callback) {\n        options = options ?? { force: false };\n        if (this.s.state === common_1.STATE_CLOSED || this.s.state === common_1.STATE_CLOSING) {\n            return callback?.();\n        }\n        const destroyedServers = Array.from(this.s.servers.values(), server => {\n            return (0, util_1.promisify)(destroyServer)(server, this, { force: !!options?.force });\n        });\n        Promise.all(destroyedServers)\n            .then(() => {\n            this.s.servers.clear();\n            stateTransition(this, common_1.STATE_CLOSING);\n            drainWaitQueue(this[kWaitQueue], new error_1.MongoTopologyClosedError());\n            (0, common_1.drainTimerQueue)(this.s.connectionTimers);\n            if (this.s.srvPoller) {\n                this.s.srvPoller.stop();\n                this.s.srvPoller.removeListener(srv_polling_1.SrvPoller.SRV_RECORD_DISCOVERY, this.s.detectSrvRecords);\n            }\n            this.removeListener(Topology.TOPOLOGY_DESCRIPTION_CHANGED, this.s.detectShardedTopology);\n            stateTransition(this, common_1.STATE_CLOSED);\n            // emit an event for close\n            this.emit(Topology.TOPOLOGY_CLOSED, new events_1.TopologyClosedEvent(this.s.id));\n        })\n            .finally(() => callback?.());\n    }\n    /**\n     * Selects a server according to the selection predicate provided\n     *\n     * @param selector - An optional selector to select servers by, defaults to a random selection within a latency window\n     * @param options - Optional settings related to server selection\n     * @param callback - The callback used to indicate success or failure\n     * @returns An instance of a `Server` meeting the criteria of the predicate provided\n     */\n    selectServer(selector, options, callback) {\n        let serverSelector;\n        if (typeof selector !== 'function') {\n            if (typeof selector === 'string') {\n                serverSelector = (0, server_selection_1.readPreferenceServerSelector)(read_preference_1.ReadPreference.fromString(selector));\n            }\n            else {\n                let readPreference;\n                if (selector instanceof read_preference_1.ReadPreference) {\n                    readPreference = selector;\n                }\n                else {\n                    read_preference_1.ReadPreference.translate(options);\n                    readPreference = options.readPreference || read_preference_1.ReadPreference.primary;\n                }\n                serverSelector = (0, server_selection_1.readPreferenceServerSelector)(readPreference);\n            }\n        }\n        else {\n            serverSelector = selector;\n        }\n        options = Object.assign({}, { serverSelectionTimeoutMS: this.s.serverSelectionTimeoutMS }, options);\n        const isSharded = this.description.type === common_1.TopologyType.Sharded;\n        const session = options.session;\n        const transaction = session && session.transaction;\n        if (isSharded && transaction && transaction.server) {\n            callback(undefined, transaction.server);\n            return;\n        }\n        const waitQueueMember = {\n            serverSelector,\n            transaction,\n            callback,\n            timeoutController: new utils_1.TimeoutController(options.serverSelectionTimeoutMS)\n        };\n        waitQueueMember.timeoutController.signal.addEventListener('abort', () => {\n            waitQueueMember[kCancelled] = true;\n            waitQueueMember.timeoutController.clear();\n            const timeoutError = new error_1.MongoServerSelectionError(`Server selection timed out after ${options.serverSelectionTimeoutMS} ms`, this.description);\n            waitQueueMember.callback(timeoutError);\n        });\n        this[kWaitQueue].push(waitQueueMember);\n        processWaitQueue(this);\n    }\n    /**\n     * Update the internal TopologyDescription with a ServerDescription\n     *\n     * @param serverDescription - The server to update in the internal list of server descriptions\n     */\n    serverUpdateHandler(serverDescription) {\n        if (!this.s.description.hasServer(serverDescription.address)) {\n            return;\n        }\n        // ignore this server update if its from an outdated topologyVersion\n        if (isStaleServerDescription(this.s.description, serverDescription)) {\n            return;\n        }\n        // these will be used for monitoring events later\n        const previousTopologyDescription = this.s.description;\n        const previousServerDescription = this.s.description.servers.get(serverDescription.address);\n        if (!previousServerDescription) {\n            return;\n        }\n        // Driver Sessions Spec: \"Whenever a driver receives a cluster time from\n        // a server it MUST compare it to the current highest seen cluster time\n        // for the deployment. If the new cluster time is higher than the\n        // highest seen cluster time it MUST become the new highest seen cluster\n        // time. Two cluster times are compared using only the BsonTimestamp\n        // value of the clusterTime embedded field.\"\n        const clusterTime = serverDescription.$clusterTime;\n        if (clusterTime) {\n            (0, common_1._advanceClusterTime)(this, clusterTime);\n        }\n        // If we already know all the information contained in this updated description, then\n        // we don't need to emit SDAM events, but still need to update the description, in order\n        // to keep client-tracked attributes like last update time and round trip time up to date\n        const equalDescriptions = previousServerDescription && previousServerDescription.equals(serverDescription);\n        // first update the TopologyDescription\n        this.s.description = this.s.description.update(serverDescription);\n        if (this.s.description.compatibilityError) {\n            this.emit(Topology.ERROR, new error_1.MongoCompatibilityError(this.s.description.compatibilityError));\n            return;\n        }\n        // emit monitoring events for this change\n        if (!equalDescriptions) {\n            const newDescription = this.s.description.servers.get(serverDescription.address);\n            if (newDescription) {\n                this.emit(Topology.SERVER_DESCRIPTION_CHANGED, new events_1.ServerDescriptionChangedEvent(this.s.id, serverDescription.address, previousServerDescription, newDescription));\n            }\n        }\n        // update server list from updated descriptions\n        updateServers(this, serverDescription);\n        // attempt to resolve any outstanding server selection attempts\n        if (this[kWaitQueue].length > 0) {\n            processWaitQueue(this);\n        }\n        if (!equalDescriptions) {\n            this.emit(Topology.TOPOLOGY_DESCRIPTION_CHANGED, new events_1.TopologyDescriptionChangedEvent(this.s.id, previousTopologyDescription, this.s.description));\n        }\n    }\n    auth(credentials, callback) {\n        if (typeof credentials === 'function')\n            (callback = credentials), (credentials = undefined);\n        if (typeof callback === 'function')\n            callback(undefined, true);\n    }\n    get clientMetadata() {\n        return this.s.options.metadata;\n    }\n    isConnected() {\n        return this.s.state === common_1.STATE_CONNECTED;\n    }\n    isDestroyed() {\n        return this.s.state === common_1.STATE_CLOSED;\n    }\n    // NOTE: There are many places in code where we explicitly check the last hello\n    //       to do feature support detection. This should be done any other way, but for\n    //       now we will just return the first hello seen, which should suffice.\n    lastHello() {\n        const serverDescriptions = Array.from(this.description.servers.values());\n        if (serverDescriptions.length === 0)\n            return {};\n        const sd = serverDescriptions.filter((sd) => sd.type !== common_1.ServerType.Unknown)[0];\n        const result = sd || { maxWireVersion: this.description.commonWireVersion };\n        return result;\n    }\n    get commonWireVersion() {\n        return this.description.commonWireVersion;\n    }\n    get logicalSessionTimeoutMinutes() {\n        return this.description.logicalSessionTimeoutMinutes;\n    }\n    get clusterTime() {\n        return this.s.clusterTime;\n    }\n    set clusterTime(clusterTime) {\n        this.s.clusterTime = clusterTime;\n    }\n}\n/** @event */\nTopology.SERVER_OPENING = constants_1.SERVER_OPENING;\n/** @event */\nTopology.SERVER_CLOSED = constants_1.SERVER_CLOSED;\n/** @event */\nTopology.SERVER_DESCRIPTION_CHANGED = constants_1.SERVER_DESCRIPTION_CHANGED;\n/** @event */\nTopology.TOPOLOGY_OPENING = constants_1.TOPOLOGY_OPENING;\n/** @event */\nTopology.TOPOLOGY_CLOSED = constants_1.TOPOLOGY_CLOSED;\n/** @event */\nTopology.TOPOLOGY_DESCRIPTION_CHANGED = constants_1.TOPOLOGY_DESCRIPTION_CHANGED;\n/** @event */\nTopology.ERROR = constants_1.ERROR;\n/** @event */\nTopology.OPEN = constants_1.OPEN;\n/** @event */\nTopology.CONNECT = constants_1.CONNECT;\n/** @event */\nTopology.CLOSE = constants_1.CLOSE;\n/** @event */\nTopology.TIMEOUT = constants_1.TIMEOUT;\nexports.Topology = Topology;\n/** Destroys a server, and removes all event listeners from the instance */\nfunction destroyServer(server, topology, options, callback) {\n    options = options ?? { force: false };\n    for (const event of constants_1.LOCAL_SERVER_EVENTS) {\n        server.removeAllListeners(event);\n    }\n    server.destroy(options, () => {\n        topology.emit(Topology.SERVER_CLOSED, new events_1.ServerClosedEvent(topology.s.id, server.description.address));\n        for (const event of constants_1.SERVER_RELAY_EVENTS) {\n            server.removeAllListeners(event);\n        }\n        if (typeof callback === 'function') {\n            callback();\n        }\n    });\n}\n/** Predicts the TopologyType from options */\nfunction topologyTypeFromOptions(options) {\n    if (options?.directConnection) {\n        return common_1.TopologyType.Single;\n    }\n    if (options?.replicaSet) {\n        return common_1.TopologyType.ReplicaSetNoPrimary;\n    }\n    if (options?.loadBalanced) {\n        return common_1.TopologyType.LoadBalanced;\n    }\n    return common_1.TopologyType.Unknown;\n}\n/**\n * Creates new server instances and attempts to connect them\n *\n * @param topology - The topology that this server belongs to\n * @param serverDescription - The description for the server to initialize and connect to\n */\nfunction createAndConnectServer(topology, serverDescription) {\n    topology.emit(Topology.SERVER_OPENING, new events_1.ServerOpeningEvent(topology.s.id, serverDescription.address));\n    const server = new server_1.Server(topology, serverDescription, topology.s.options);\n    for (const event of constants_1.SERVER_RELAY_EVENTS) {\n        server.on(event, (e) => topology.emit(event, e));\n    }\n    server.on(server_1.Server.DESCRIPTION_RECEIVED, description => topology.serverUpdateHandler(description));\n    server.connect();\n    return server;\n}\n/**\n * @param topology - Topology to update.\n * @param incomingServerDescription - New server description.\n */\nfunction updateServers(topology, incomingServerDescription) {\n    // update the internal server's description\n    if (incomingServerDescription && topology.s.servers.has(incomingServerDescription.address)) {\n        const server = topology.s.servers.get(incomingServerDescription.address);\n        if (server) {\n            server.s.description = incomingServerDescription;\n            if (incomingServerDescription.error instanceof error_1.MongoError &&\n                incomingServerDescription.error.hasErrorLabel(error_1.MongoErrorLabel.ResetPool)) {\n                const interruptInUseConnections = incomingServerDescription.error.hasErrorLabel(error_1.MongoErrorLabel.InterruptInUseConnections);\n                server.pool.clear({ interruptInUseConnections });\n            }\n            else if (incomingServerDescription.error == null) {\n                const newTopologyType = topology.s.description.type;\n                const shouldMarkPoolReady = incomingServerDescription.isDataBearing ||\n                    (incomingServerDescription.type !== common_1.ServerType.Unknown &&\n                        newTopologyType === common_1.TopologyType.Single);\n                if (shouldMarkPoolReady) {\n                    server.pool.ready();\n                }\n            }\n        }\n    }\n    // add new servers for all descriptions we currently don't know about locally\n    for (const serverDescription of topology.description.servers.values()) {\n        if (!topology.s.servers.has(serverDescription.address)) {\n            const server = createAndConnectServer(topology, serverDescription);\n            topology.s.servers.set(serverDescription.address, server);\n        }\n    }\n    // for all servers no longer known, remove their descriptions and destroy their instances\n    for (const entry of topology.s.servers) {\n        const serverAddress = entry[0];\n        if (topology.description.hasServer(serverAddress)) {\n            continue;\n        }\n        if (!topology.s.servers.has(serverAddress)) {\n            continue;\n        }\n        const server = topology.s.servers.get(serverAddress);\n        topology.s.servers.delete(serverAddress);\n        // prepare server for garbage collection\n        if (server) {\n            destroyServer(server, topology);\n        }\n    }\n}\nfunction drainWaitQueue(queue, err) {\n    while (queue.length) {\n        const waitQueueMember = queue.shift();\n        if (!waitQueueMember) {\n            continue;\n        }\n        waitQueueMember.timeoutController.clear();\n        if (!waitQueueMember[kCancelled]) {\n            waitQueueMember.callback(err);\n        }\n    }\n}\nfunction processWaitQueue(topology) {\n    if (topology.s.state === common_1.STATE_CLOSED) {\n        drainWaitQueue(topology[kWaitQueue], new error_1.MongoTopologyClosedError());\n        return;\n    }\n    const isSharded = topology.description.type === common_1.TopologyType.Sharded;\n    const serverDescriptions = Array.from(topology.description.servers.values());\n    const membersToProcess = topology[kWaitQueue].length;\n    for (let i = 0; i < membersToProcess; ++i) {\n        const waitQueueMember = topology[kWaitQueue].shift();\n        if (!waitQueueMember) {\n            continue;\n        }\n        if (waitQueueMember[kCancelled]) {\n            continue;\n        }\n        let selectedDescriptions;\n        try {\n            const serverSelector = waitQueueMember.serverSelector;\n            selectedDescriptions = serverSelector\n                ? serverSelector(topology.description, serverDescriptions)\n                : serverDescriptions;\n        }\n        catch (e) {\n            waitQueueMember.timeoutController.clear();\n            waitQueueMember.callback(e);\n            continue;\n        }\n        let selectedServer;\n        if (selectedDescriptions.length === 0) {\n            topology[kWaitQueue].push(waitQueueMember);\n            continue;\n        }\n        else if (selectedDescriptions.length === 1) {\n            selectedServer = topology.s.servers.get(selectedDescriptions[0].address);\n        }\n        else {\n            const descriptions = (0, utils_1.shuffle)(selectedDescriptions, 2);\n            const server1 = topology.s.servers.get(descriptions[0].address);\n            const server2 = topology.s.servers.get(descriptions[1].address);\n            selectedServer =\n                server1 && server2 && server1.s.operationCount < server2.s.operationCount\n                    ? server1\n                    : server2;\n        }\n        if (!selectedServer) {\n            waitQueueMember.callback(new error_1.MongoServerSelectionError('server selection returned a server description but the server was not found in the topology', topology.description));\n            return;\n        }\n        const transaction = waitQueueMember.transaction;\n        if (isSharded && transaction && transaction.isActive && selectedServer) {\n            transaction.pinServer(selectedServer);\n        }\n        waitQueueMember.timeoutController.clear();\n        waitQueueMember.callback(undefined, selectedServer);\n    }\n    if (topology[kWaitQueue].length > 0) {\n        // ensure all server monitors attempt monitoring soon\n        for (const [, server] of topology.s.servers) {\n            process.nextTick(function scheduleServerCheck() {\n                return server.requestCheck();\n            });\n        }\n    }\n}\nfunction isStaleServerDescription(topologyDescription, incomingServerDescription) {\n    const currentServerDescription = topologyDescription.servers.get(incomingServerDescription.address);\n    const currentTopologyVersion = currentServerDescription?.topologyVersion;\n    return ((0, server_description_1.compareTopologyVersion)(currentTopologyVersion, incomingServerDescription.topologyVersion) > 0);\n}\n/** @public */\nclass ServerCapabilities {\n    constructor(hello) {\n        this.minWireVersion = hello.minWireVersion || 0;\n        this.maxWireVersion = hello.maxWireVersion || 0;\n    }\n    get hasAggregationCursor() {\n        return this.maxWireVersion >= 1;\n    }\n    get hasWriteCommands() {\n        return this.maxWireVersion >= 2;\n    }\n    get hasTextSearch() {\n        return this.minWireVersion >= 0;\n    }\n    get hasAuthCommands() {\n        return this.maxWireVersion >= 1;\n    }\n    get hasListCollectionsCommand() {\n        return this.maxWireVersion >= 3;\n    }\n    get hasListIndexesCommand() {\n        return this.maxWireVersion >= 3;\n    }\n    get supportsSnapshotReads() {\n        return this.maxWireVersion >= 13;\n    }\n    get commandsTakeWriteConcern() {\n        return this.maxWireVersion >= 5;\n    }\n    get commandsTakeCollation() {\n        return this.maxWireVersion >= 5;\n    }\n}\nexports.ServerCapabilities = ServerCapabilities;\n//# sourceMappingURL=topology.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/sdam/topology.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/topology_description.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/topology_description.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TopologyDescription = void 0;\nconst WIRE_CONSTANTS = __webpack_require__(/*! ../cmap/wire_protocol/constants */ \"./node_modules/mongodb/lib/cmap/wire_protocol/constants.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst common_1 = __webpack_require__(/*! ./common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst server_description_1 = __webpack_require__(/*! ./server_description */ \"./node_modules/mongodb/lib/sdam/server_description.js\");\n// constants related to compatibility checks\nconst MIN_SUPPORTED_SERVER_VERSION = WIRE_CONSTANTS.MIN_SUPPORTED_SERVER_VERSION;\nconst MAX_SUPPORTED_SERVER_VERSION = WIRE_CONSTANTS.MAX_SUPPORTED_SERVER_VERSION;\nconst MIN_SUPPORTED_WIRE_VERSION = WIRE_CONSTANTS.MIN_SUPPORTED_WIRE_VERSION;\nconst MAX_SUPPORTED_WIRE_VERSION = WIRE_CONSTANTS.MAX_SUPPORTED_WIRE_VERSION;\nconst MONGOS_OR_UNKNOWN = new Set([common_1.ServerType.Mongos, common_1.ServerType.Unknown]);\nconst MONGOS_OR_STANDALONE = new Set([common_1.ServerType.Mongos, common_1.ServerType.Standalone]);\nconst NON_PRIMARY_RS_MEMBERS = new Set([\n    common_1.ServerType.RSSecondary,\n    common_1.ServerType.RSArbiter,\n    common_1.ServerType.RSOther\n]);\n/**\n * Representation of a deployment of servers\n * @public\n */\nclass TopologyDescription {\n    /**\n     * Create a TopologyDescription\n     */\n    constructor(topologyType, serverDescriptions = null, setName = null, maxSetVersion = null, maxElectionId = null, commonWireVersion = null, options = null) {\n        options = options ?? {};\n        this.type = topologyType ?? common_1.TopologyType.Unknown;\n        this.servers = serverDescriptions ?? new Map();\n        this.stale = false;\n        this.compatible = true;\n        this.heartbeatFrequencyMS = options.heartbeatFrequencyMS ?? 0;\n        this.localThresholdMS = options.localThresholdMS ?? 15;\n        this.setName = setName ?? null;\n        this.maxElectionId = maxElectionId ?? null;\n        this.maxSetVersion = maxSetVersion ?? null;\n        this.commonWireVersion = commonWireVersion ?? 0;\n        // determine server compatibility\n        for (const serverDescription of this.servers.values()) {\n            // Load balancer mode is always compatible.\n            if (serverDescription.type === common_1.ServerType.Unknown ||\n                serverDescription.type === common_1.ServerType.LoadBalancer) {\n                continue;\n            }\n            if (serverDescription.minWireVersion > MAX_SUPPORTED_WIRE_VERSION) {\n                this.compatible = false;\n                this.compatibilityError = `Server at ${serverDescription.address} requires wire version ${serverDescription.minWireVersion}, but this version of the driver only supports up to ${MAX_SUPPORTED_WIRE_VERSION} (MongoDB ${MAX_SUPPORTED_SERVER_VERSION})`;\n            }\n            if (serverDescription.maxWireVersion < MIN_SUPPORTED_WIRE_VERSION) {\n                this.compatible = false;\n                this.compatibilityError = `Server at ${serverDescription.address} reports wire version ${serverDescription.maxWireVersion}, but this version of the driver requires at least ${MIN_SUPPORTED_WIRE_VERSION} (MongoDB ${MIN_SUPPORTED_SERVER_VERSION}).`;\n                break;\n            }\n        }\n        // Whenever a client updates the TopologyDescription from a hello response, it MUST set\n        // TopologyDescription.logicalSessionTimeoutMinutes to the smallest logicalSessionTimeoutMinutes\n        // value among ServerDescriptions of all data-bearing server types. If any have a null\n        // logicalSessionTimeoutMinutes, then TopologyDescription.logicalSessionTimeoutMinutes MUST be\n        // set to null.\n        this.logicalSessionTimeoutMinutes = null;\n        for (const [, server] of this.servers) {\n            if (server.isReadable) {\n                if (server.logicalSessionTimeoutMinutes == null) {\n                    // If any of the servers have a null logicalSessionsTimeout, then the whole topology does\n                    this.logicalSessionTimeoutMinutes = null;\n                    break;\n                }\n                if (this.logicalSessionTimeoutMinutes == null) {\n                    // First server with a non null logicalSessionsTimeout\n                    this.logicalSessionTimeoutMinutes = server.logicalSessionTimeoutMinutes;\n                    continue;\n                }\n                // Always select the smaller of the:\n                // current server logicalSessionsTimeout and the topologies logicalSessionsTimeout\n                this.logicalSessionTimeoutMinutes = Math.min(this.logicalSessionTimeoutMinutes, server.logicalSessionTimeoutMinutes);\n            }\n        }\n    }\n    /**\n     * Returns a new TopologyDescription based on the SrvPollingEvent\n     * @internal\n     */\n    updateFromSrvPollingEvent(ev, srvMaxHosts = 0) {\n        /** The SRV addresses defines the set of addresses we should be using */\n        const incomingHostnames = ev.hostnames();\n        const currentHostnames = new Set(this.servers.keys());\n        const hostnamesToAdd = new Set(incomingHostnames);\n        const hostnamesToRemove = new Set();\n        for (const hostname of currentHostnames) {\n            // filter hostnamesToAdd (made from incomingHostnames) down to what is *not* present in currentHostnames\n            hostnamesToAdd.delete(hostname);\n            if (!incomingHostnames.has(hostname)) {\n                // If the SRV Records no longer include this hostname\n                // we have to stop using it\n                hostnamesToRemove.add(hostname);\n            }\n        }\n        if (hostnamesToAdd.size === 0 && hostnamesToRemove.size === 0) {\n            // No new hosts to add and none to remove\n            return this;\n        }\n        const serverDescriptions = new Map(this.servers);\n        for (const removedHost of hostnamesToRemove) {\n            serverDescriptions.delete(removedHost);\n        }\n        if (hostnamesToAdd.size > 0) {\n            if (srvMaxHosts === 0) {\n                // Add all!\n                for (const hostToAdd of hostnamesToAdd) {\n                    serverDescriptions.set(hostToAdd, new server_description_1.ServerDescription(hostToAdd));\n                }\n            }\n            else if (serverDescriptions.size < srvMaxHosts) {\n                // Add only the amount needed to get us back to srvMaxHosts\n                const selectedHosts = (0, utils_1.shuffle)(hostnamesToAdd, srvMaxHosts - serverDescriptions.size);\n                for (const selectedHostToAdd of selectedHosts) {\n                    serverDescriptions.set(selectedHostToAdd, new server_description_1.ServerDescription(selectedHostToAdd));\n                }\n            }\n        }\n        return new TopologyDescription(this.type, serverDescriptions, this.setName, this.maxSetVersion, this.maxElectionId, this.commonWireVersion, { heartbeatFrequencyMS: this.heartbeatFrequencyMS, localThresholdMS: this.localThresholdMS });\n    }\n    /**\n     * Returns a copy of this description updated with a given ServerDescription\n     * @internal\n     */\n    update(serverDescription) {\n        const address = serverDescription.address;\n        // potentially mutated values\n        let { type: topologyType, setName, maxSetVersion, maxElectionId, commonWireVersion } = this;\n        const serverType = serverDescription.type;\n        const serverDescriptions = new Map(this.servers);\n        // update common wire version\n        if (serverDescription.maxWireVersion !== 0) {\n            if (commonWireVersion == null) {\n                commonWireVersion = serverDescription.maxWireVersion;\n            }\n            else {\n                commonWireVersion = Math.min(commonWireVersion, serverDescription.maxWireVersion);\n            }\n        }\n        if (typeof serverDescription.setName === 'string' &&\n            typeof setName === 'string' &&\n            serverDescription.setName !== setName) {\n            if (topologyType === common_1.TopologyType.Single) {\n                // \"Single\" Topology with setName mismatch is direct connection usage, mark unknown do not remove\n                serverDescription = new server_description_1.ServerDescription(address);\n            }\n            else {\n                serverDescriptions.delete(address);\n            }\n        }\n        // update the actual server description\n        serverDescriptions.set(address, serverDescription);\n        if (topologyType === common_1.TopologyType.Single) {\n            // once we are defined as single, that never changes\n            return new TopologyDescription(common_1.TopologyType.Single, serverDescriptions, setName, maxSetVersion, maxElectionId, commonWireVersion, { heartbeatFrequencyMS: this.heartbeatFrequencyMS, localThresholdMS: this.localThresholdMS });\n        }\n        if (topologyType === common_1.TopologyType.Unknown) {\n            if (serverType === common_1.ServerType.Standalone && this.servers.size !== 1) {\n                serverDescriptions.delete(address);\n            }\n            else {\n                topologyType = topologyTypeForServerType(serverType);\n            }\n        }\n        if (topologyType === common_1.TopologyType.Sharded) {\n            if (!MONGOS_OR_UNKNOWN.has(serverType)) {\n                serverDescriptions.delete(address);\n            }\n        }\n        if (topologyType === common_1.TopologyType.ReplicaSetNoPrimary) {\n            if (MONGOS_OR_STANDALONE.has(serverType)) {\n                serverDescriptions.delete(address);\n            }\n            if (serverType === common_1.ServerType.RSPrimary) {\n                const result = updateRsFromPrimary(serverDescriptions, serverDescription, setName, maxSetVersion, maxElectionId);\n                topologyType = result[0];\n                setName = result[1];\n                maxSetVersion = result[2];\n                maxElectionId = result[3];\n            }\n            else if (NON_PRIMARY_RS_MEMBERS.has(serverType)) {\n                const result = updateRsNoPrimaryFromMember(serverDescriptions, serverDescription, setName);\n                topologyType = result[0];\n                setName = result[1];\n            }\n        }\n        if (topologyType === common_1.TopologyType.ReplicaSetWithPrimary) {\n            if (MONGOS_OR_STANDALONE.has(serverType)) {\n                serverDescriptions.delete(address);\n                topologyType = checkHasPrimary(serverDescriptions);\n            }\n            else if (serverType === common_1.ServerType.RSPrimary) {\n                const result = updateRsFromPrimary(serverDescriptions, serverDescription, setName, maxSetVersion, maxElectionId);\n                topologyType = result[0];\n                setName = result[1];\n                maxSetVersion = result[2];\n                maxElectionId = result[3];\n            }\n            else if (NON_PRIMARY_RS_MEMBERS.has(serverType)) {\n                topologyType = updateRsWithPrimaryFromMember(serverDescriptions, serverDescription, setName);\n            }\n            else {\n                topologyType = checkHasPrimary(serverDescriptions);\n            }\n        }\n        return new TopologyDescription(topologyType, serverDescriptions, setName, maxSetVersion, maxElectionId, commonWireVersion, { heartbeatFrequencyMS: this.heartbeatFrequencyMS, localThresholdMS: this.localThresholdMS });\n    }\n    get error() {\n        const descriptionsWithError = Array.from(this.servers.values()).filter((sd) => sd.error);\n        if (descriptionsWithError.length > 0) {\n            return descriptionsWithError[0].error;\n        }\n        return null;\n    }\n    /**\n     * Determines if the topology description has any known servers\n     */\n    get hasKnownServers() {\n        return Array.from(this.servers.values()).some((sd) => sd.type !== common_1.ServerType.Unknown);\n    }\n    /**\n     * Determines if this topology description has a data-bearing server available.\n     */\n    get hasDataBearingServers() {\n        return Array.from(this.servers.values()).some((sd) => sd.isDataBearing);\n    }\n    /**\n     * Determines if the topology has a definition for the provided address\n     * @internal\n     */\n    hasServer(address) {\n        return this.servers.has(address);\n    }\n}\nexports.TopologyDescription = TopologyDescription;\nfunction topologyTypeForServerType(serverType) {\n    switch (serverType) {\n        case common_1.ServerType.Standalone:\n            return common_1.TopologyType.Single;\n        case common_1.ServerType.Mongos:\n            return common_1.TopologyType.Sharded;\n        case common_1.ServerType.RSPrimary:\n            return common_1.TopologyType.ReplicaSetWithPrimary;\n        case common_1.ServerType.RSOther:\n        case common_1.ServerType.RSSecondary:\n            return common_1.TopologyType.ReplicaSetNoPrimary;\n        default:\n            return common_1.TopologyType.Unknown;\n    }\n}\nfunction updateRsFromPrimary(serverDescriptions, serverDescription, setName = null, maxSetVersion = null, maxElectionId = null) {\n    setName = setName || serverDescription.setName;\n    if (setName !== serverDescription.setName) {\n        serverDescriptions.delete(serverDescription.address);\n        return [checkHasPrimary(serverDescriptions), setName, maxSetVersion, maxElectionId];\n    }\n    if (serverDescription.maxWireVersion >= 17) {\n        const electionIdComparison = (0, utils_1.compareObjectId)(maxElectionId, serverDescription.electionId);\n        const maxElectionIdIsEqual = electionIdComparison === 0;\n        const maxElectionIdIsLess = electionIdComparison === -1;\n        const maxSetVersionIsLessOrEqual = (maxSetVersion ?? -1) <= (serverDescription.setVersion ?? -1);\n        if (maxElectionIdIsLess || (maxElectionIdIsEqual && maxSetVersionIsLessOrEqual)) {\n            // The reported electionId was greater\n            // or the electionId was equal and reported setVersion was greater\n            // Always update both values, they are a tuple\n            maxElectionId = serverDescription.electionId;\n            maxSetVersion = serverDescription.setVersion;\n        }\n        else {\n            // Stale primary\n            // replace serverDescription with a default ServerDescription of type \"Unknown\"\n            serverDescriptions.set(serverDescription.address, new server_description_1.ServerDescription(serverDescription.address));\n            return [checkHasPrimary(serverDescriptions), setName, maxSetVersion, maxElectionId];\n        }\n    }\n    else {\n        const electionId = serverDescription.electionId ? serverDescription.electionId : null;\n        if (serverDescription.setVersion && electionId) {\n            if (maxSetVersion && maxElectionId) {\n                if (maxSetVersion > serverDescription.setVersion ||\n                    (0, utils_1.compareObjectId)(maxElectionId, electionId) > 0) {\n                    // this primary is stale, we must remove it\n                    serverDescriptions.set(serverDescription.address, new server_description_1.ServerDescription(serverDescription.address));\n                    return [checkHasPrimary(serverDescriptions), setName, maxSetVersion, maxElectionId];\n                }\n            }\n            maxElectionId = serverDescription.electionId;\n        }\n        if (serverDescription.setVersion != null &&\n            (maxSetVersion == null || serverDescription.setVersion > maxSetVersion)) {\n            maxSetVersion = serverDescription.setVersion;\n        }\n    }\n    // We've heard from the primary. Is it the same primary as before?\n    for (const [address, server] of serverDescriptions) {\n        if (server.type === common_1.ServerType.RSPrimary && server.address !== serverDescription.address) {\n            // Reset old primary's type to Unknown.\n            serverDescriptions.set(address, new server_description_1.ServerDescription(server.address));\n            // There can only be one primary\n            break;\n        }\n    }\n    // Discover new hosts from this primary's response.\n    serverDescription.allHosts.forEach((address) => {\n        if (!serverDescriptions.has(address)) {\n            serverDescriptions.set(address, new server_description_1.ServerDescription(address));\n        }\n    });\n    // Remove hosts not in the response.\n    const currentAddresses = Array.from(serverDescriptions.keys());\n    const responseAddresses = serverDescription.allHosts;\n    currentAddresses\n        .filter((addr) => responseAddresses.indexOf(addr) === -1)\n        .forEach((address) => {\n        serverDescriptions.delete(address);\n    });\n    return [checkHasPrimary(serverDescriptions), setName, maxSetVersion, maxElectionId];\n}\nfunction updateRsWithPrimaryFromMember(serverDescriptions, serverDescription, setName = null) {\n    if (setName == null) {\n        // TODO(NODE-3483): should be an appropriate runtime error\n        throw new error_1.MongoRuntimeError('Argument \"setName\" is required if connected to a replica set');\n    }\n    if (setName !== serverDescription.setName ||\n        (serverDescription.me && serverDescription.address !== serverDescription.me)) {\n        serverDescriptions.delete(serverDescription.address);\n    }\n    return checkHasPrimary(serverDescriptions);\n}\nfunction updateRsNoPrimaryFromMember(serverDescriptions, serverDescription, setName = null) {\n    const topologyType = common_1.TopologyType.ReplicaSetNoPrimary;\n    setName = setName ?? serverDescription.setName;\n    if (setName !== serverDescription.setName) {\n        serverDescriptions.delete(serverDescription.address);\n        return [topologyType, setName];\n    }\n    serverDescription.allHosts.forEach((address) => {\n        if (!serverDescriptions.has(address)) {\n            serverDescriptions.set(address, new server_description_1.ServerDescription(address));\n        }\n    });\n    if (serverDescription.me && serverDescription.address !== serverDescription.me) {\n        serverDescriptions.delete(serverDescription.address);\n    }\n    return [topologyType, setName];\n}\nfunction checkHasPrimary(serverDescriptions) {\n    for (const serverDescription of serverDescriptions.values()) {\n        if (serverDescription.type === common_1.ServerType.RSPrimary) {\n            return common_1.TopologyType.ReplicaSetWithPrimary;\n        }\n    }\n    return common_1.TopologyType.ReplicaSetNoPrimary;\n}\n//# sourceMappingURL=topology_description.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/sdam/topology_description.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sessions.js":
/*!**********************************************!*\
  !*** ./node_modules/mongodb/lib/sessions.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nvar _a;\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.updateSessionFromResponse = exports.applySession = exports.ServerSessionPool = exports.ServerSession = exports.maybeClearPinnedConnection = exports.ClientSession = void 0;\nconst util_1 = __webpack_require__(/*! util */ \"util\");\nconst bson_1 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst metrics_1 = __webpack_require__(/*! ./cmap/metrics */ \"./node_modules/mongodb/lib/cmap/metrics.js\");\nconst shared_1 = __webpack_require__(/*! ./cmap/wire_protocol/shared */ \"./node_modules/mongodb/lib/cmap/wire_protocol/shared.js\");\nconst constants_1 = __webpack_require__(/*! ./constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_types_1 = __webpack_require__(/*! ./mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst execute_operation_1 = __webpack_require__(/*! ./operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst run_command_1 = __webpack_require__(/*! ./operations/run_command */ \"./node_modules/mongodb/lib/operations/run_command.js\");\nconst read_concern_1 = __webpack_require__(/*! ./read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst read_preference_1 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst common_1 = __webpack_require__(/*! ./sdam/common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst transactions_1 = __webpack_require__(/*! ./transactions */ \"./node_modules/mongodb/lib/transactions.js\");\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst write_concern_1 = __webpack_require__(/*! ./write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\nconst minWireVersionForShardedTransactions = 8;\n/** @internal */\nconst kServerSession = Symbol('serverSession');\n/** @internal */\nconst kSnapshotTime = Symbol('snapshotTime');\n/** @internal */\nconst kSnapshotEnabled = Symbol('snapshotEnabled');\n/** @internal */\nconst kPinnedConnection = Symbol('pinnedConnection');\n/** @internal Accumulates total number of increments to add to txnNumber when applying session to command */\nconst kTxnNumberIncrement = Symbol('txnNumberIncrement');\n/**\n * A class representing a client session on the server\n *\n * NOTE: not meant to be instantiated directly.\n * @public\n */\nclass ClientSession extends mongo_types_1.TypedEventEmitter {\n    /**\n     * Create a client session.\n     * @internal\n     * @param client - The current client\n     * @param sessionPool - The server session pool (Internal Class)\n     * @param options - Optional settings\n     * @param clientOptions - Optional settings provided when creating a MongoClient\n     */\n    constructor(client, sessionPool, options, clientOptions) {\n        super();\n        /** @internal */\n        this[_a] = false;\n        if (client == null) {\n            // TODO(NODE-3483)\n            throw new error_1.MongoRuntimeError('ClientSession requires a MongoClient');\n        }\n        if (sessionPool == null || !(sessionPool instanceof ServerSessionPool)) {\n            // TODO(NODE-3483)\n            throw new error_1.MongoRuntimeError('ClientSession requires a ServerSessionPool');\n        }\n        options = options ?? {};\n        if (options.snapshot === true) {\n            this[kSnapshotEnabled] = true;\n            if (options.causalConsistency === true) {\n                throw new error_1.MongoInvalidArgumentError('Properties \"causalConsistency\" and \"snapshot\" are mutually exclusive');\n            }\n        }\n        this.client = client;\n        this.sessionPool = sessionPool;\n        this.hasEnded = false;\n        this.clientOptions = clientOptions;\n        this.explicit = !!options.explicit;\n        this[kServerSession] = this.explicit ? this.sessionPool.acquire() : null;\n        this[kTxnNumberIncrement] = 0;\n        const defaultCausalConsistencyValue = this.explicit && options.snapshot !== true;\n        this.supports = {\n            // if we can enable causal consistency, do so by default\n            causalConsistency: options.causalConsistency ?? defaultCausalConsistencyValue\n        };\n        this.clusterTime = options.initialClusterTime;\n        this.operationTime = undefined;\n        this.owner = options.owner;\n        this.defaultTransactionOptions = Object.assign({}, options.defaultTransactionOptions);\n        this.transaction = new transactions_1.Transaction();\n    }\n    /** The server id associated with this session */\n    get id() {\n        return this[kServerSession]?.id;\n    }\n    get serverSession() {\n        let serverSession = this[kServerSession];\n        if (serverSession == null) {\n            if (this.explicit) {\n                throw new error_1.MongoRuntimeError('Unexpected null serverSession for an explicit session');\n            }\n            if (this.hasEnded) {\n                throw new error_1.MongoRuntimeError('Unexpected null serverSession for an ended implicit session');\n            }\n            serverSession = this.sessionPool.acquire();\n            this[kServerSession] = serverSession;\n        }\n        return serverSession;\n    }\n    /** Whether or not this session is configured for snapshot reads */\n    get snapshotEnabled() {\n        return this[kSnapshotEnabled];\n    }\n    get loadBalanced() {\n        return this.client.topology?.description.type === common_1.TopologyType.LoadBalanced;\n    }\n    /** @internal */\n    get pinnedConnection() {\n        return this[kPinnedConnection];\n    }\n    /** @internal */\n    pin(conn) {\n        if (this[kPinnedConnection]) {\n            throw TypeError('Cannot pin multiple connections to the same session');\n        }\n        this[kPinnedConnection] = conn;\n        conn.emit(constants_1.PINNED, this.inTransaction() ? metrics_1.ConnectionPoolMetrics.TXN : metrics_1.ConnectionPoolMetrics.CURSOR);\n    }\n    /** @internal */\n    unpin(options) {\n        if (this.loadBalanced) {\n            return maybeClearPinnedConnection(this, options);\n        }\n        this.transaction.unpinServer();\n    }\n    get isPinned() {\n        return this.loadBalanced ? !!this[kPinnedConnection] : this.transaction.isPinned;\n    }\n    /**\n     * Ends this session on the server\n     *\n     * @param options - Optional settings. Currently reserved for future use\n     */\n    async endSession(options) {\n        try {\n            if (this.inTransaction()) {\n                await this.abortTransaction();\n            }\n            if (!this.hasEnded) {\n                const serverSession = this[kServerSession];\n                if (serverSession != null) {\n                    // release the server session back to the pool\n                    this.sessionPool.release(serverSession);\n                    // Make sure a new serverSession never makes it onto this ClientSession\n                    Object.defineProperty(this, kServerSession, {\n                        value: ServerSession.clone(serverSession),\n                        writable: false\n                    });\n                }\n                // mark the session as ended, and emit a signal\n                this.hasEnded = true;\n                this.emit('ended', this);\n            }\n        }\n        catch {\n            // spec indicates that we should ignore all errors for `endSessions`\n        }\n        finally {\n            maybeClearPinnedConnection(this, { force: true, ...options });\n        }\n    }\n    /**\n     * Advances the operationTime for a ClientSession.\n     *\n     * @param operationTime - the `BSON.Timestamp` of the operation type it is desired to advance to\n     */\n    advanceOperationTime(operationTime) {\n        if (this.operationTime == null) {\n            this.operationTime = operationTime;\n            return;\n        }\n        if (operationTime.greaterThan(this.operationTime)) {\n            this.operationTime = operationTime;\n        }\n    }\n    /**\n     * Advances the clusterTime for a ClientSession to the provided clusterTime of another ClientSession\n     *\n     * @param clusterTime - the $clusterTime returned by the server from another session in the form of a document containing the `BSON.Timestamp` clusterTime and signature\n     */\n    advanceClusterTime(clusterTime) {\n        if (!clusterTime || typeof clusterTime !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('input cluster time must be an object');\n        }\n        if (!clusterTime.clusterTime || clusterTime.clusterTime._bsontype !== 'Timestamp') {\n            throw new error_1.MongoInvalidArgumentError('input cluster time \"clusterTime\" property must be a valid BSON Timestamp');\n        }\n        if (!clusterTime.signature ||\n            clusterTime.signature.hash?._bsontype !== 'Binary' ||\n            (typeof clusterTime.signature.keyId !== 'bigint' &&\n                typeof clusterTime.signature.keyId !== 'number' &&\n                clusterTime.signature.keyId?._bsontype !== 'Long') // apparently we decode the key to number?\n        ) {\n            throw new error_1.MongoInvalidArgumentError('input cluster time must have a valid \"signature\" property with BSON Binary hash and BSON Long keyId');\n        }\n        (0, common_1._advanceClusterTime)(this, clusterTime);\n    }\n    /**\n     * Used to determine if this session equals another\n     *\n     * @param session - The session to compare to\n     */\n    equals(session) {\n        if (!(session instanceof ClientSession)) {\n            return false;\n        }\n        if (this.id == null || session.id == null) {\n            return false;\n        }\n        return utils_1.ByteUtils.equals(this.id.id.buffer, session.id.id.buffer);\n    }\n    /**\n     * Increment the transaction number on the internal ServerSession\n     *\n     * @privateRemarks\n     * This helper increments a value stored on the client session that will be\n     * added to the serverSession's txnNumber upon applying it to a command.\n     * This is because the serverSession is lazily acquired after a connection is obtained\n     */\n    incrementTransactionNumber() {\n        this[kTxnNumberIncrement] += 1;\n    }\n    /** @returns whether this session is currently in a transaction or not */\n    inTransaction() {\n        return this.transaction.isActive;\n    }\n    /**\n     * Starts a new transaction with the given options.\n     *\n     * @param options - Options for the transaction\n     */\n    startTransaction(options) {\n        if (this[kSnapshotEnabled]) {\n            throw new error_1.MongoCompatibilityError('Transactions are not supported in snapshot sessions');\n        }\n        if (this.inTransaction()) {\n            throw new error_1.MongoTransactionError('Transaction already in progress');\n        }\n        if (this.isPinned && this.transaction.isCommitted) {\n            this.unpin();\n        }\n        const topologyMaxWireVersion = (0, utils_1.maxWireVersion)(this.client.topology);\n        if ((0, shared_1.isSharded)(this.client.topology) &&\n            topologyMaxWireVersion != null &&\n            topologyMaxWireVersion < minWireVersionForShardedTransactions) {\n            throw new error_1.MongoCompatibilityError('Transactions are not supported on sharded clusters in MongoDB < 4.2.');\n        }\n        // increment txnNumber\n        this.incrementTransactionNumber();\n        // create transaction state\n        this.transaction = new transactions_1.Transaction({\n            readConcern: options?.readConcern ??\n                this.defaultTransactionOptions.readConcern ??\n                this.clientOptions?.readConcern,\n            writeConcern: options?.writeConcern ??\n                this.defaultTransactionOptions.writeConcern ??\n                this.clientOptions?.writeConcern,\n            readPreference: options?.readPreference ??\n                this.defaultTransactionOptions.readPreference ??\n                this.clientOptions?.readPreference,\n            maxCommitTimeMS: options?.maxCommitTimeMS ?? this.defaultTransactionOptions.maxCommitTimeMS\n        });\n        this.transaction.transition(transactions_1.TxnState.STARTING_TRANSACTION);\n    }\n    /**\n     * Commits the currently active transaction in this session.\n     */\n    async commitTransaction() {\n        return endTransactionAsync(this, 'commitTransaction');\n    }\n    /**\n     * Aborts the currently active transaction in this session.\n     */\n    async abortTransaction() {\n        return endTransactionAsync(this, 'abortTransaction');\n    }\n    /**\n     * This is here to ensure that ClientSession is never serialized to BSON.\n     */\n    toBSON() {\n        throw new error_1.MongoRuntimeError('ClientSession cannot be serialized to BSON.');\n    }\n    /**\n     * Starts a transaction and runs a provided function, ensuring the commitTransaction is always attempted when all operations run in the function have completed.\n     *\n     * **IMPORTANT:** This method requires the user to return a Promise, and `await` all operations.\n     *\n     * @remarks\n     * This function:\n     * - If all operations successfully complete and the `commitTransaction` operation is successful, then this function will return the result of the provided function.\n     * - If the transaction is unable to complete or an error is thrown from within the provided function, then this function will throw an error.\n     *   - If the transaction is manually aborted within the provided function it will not throw.\n     * - May be called multiple times if the driver needs to attempt to retry the operations.\n     *\n     * Checkout a descriptive example here:\n     * @see https://www.mongodb.com/blog/post/quick-start-nodejs--mongodb--how-to-implement-transactions\n     *\n     * @param fn - callback to run within a transaction\n     * @param options - optional settings for the transaction\n     * @returns A raw command response or undefined\n     */\n    async withTransaction(fn, options) {\n        const startTime = (0, utils_1.now)();\n        return attemptTransaction(this, startTime, fn, options);\n    }\n}\nexports.ClientSession = ClientSession;\n_a = kSnapshotEnabled;\nconst MAX_WITH_TRANSACTION_TIMEOUT = 120000;\nconst NON_DETERMINISTIC_WRITE_CONCERN_ERRORS = new Set([\n    'CannotSatisfyWriteConcern',\n    'UnknownReplWriteConcern',\n    'UnsatisfiableWriteConcern'\n]);\nfunction hasNotTimedOut(startTime, max) {\n    return (0, utils_1.calculateDurationInMs)(startTime) < max;\n}\nfunction isUnknownTransactionCommitResult(err) {\n    const isNonDeterministicWriteConcernError = err instanceof error_1.MongoServerError &&\n        err.codeName &&\n        NON_DETERMINISTIC_WRITE_CONCERN_ERRORS.has(err.codeName);\n    return (isMaxTimeMSExpiredError(err) ||\n        (!isNonDeterministicWriteConcernError &&\n            err.code !== error_1.MONGODB_ERROR_CODES.UnsatisfiableWriteConcern &&\n            err.code !== error_1.MONGODB_ERROR_CODES.UnknownReplWriteConcern));\n}\nfunction maybeClearPinnedConnection(session, options) {\n    // unpin a connection if it has been pinned\n    const conn = session[kPinnedConnection];\n    const error = options?.error;\n    if (session.inTransaction() &&\n        error &&\n        error instanceof error_1.MongoError &&\n        error.hasErrorLabel(error_1.MongoErrorLabel.TransientTransactionError)) {\n        return;\n    }\n    const topology = session.client.topology;\n    // NOTE: the spec talks about what to do on a network error only, but the tests seem to\n    //       to validate that we don't unpin on _all_ errors?\n    if (conn && topology != null) {\n        const servers = Array.from(topology.s.servers.values());\n        const loadBalancer = servers[0];\n        if (options?.error == null || options?.force) {\n            loadBalancer.pool.checkIn(conn);\n            conn.emit(constants_1.UNPINNED, session.transaction.state !== transactions_1.TxnState.NO_TRANSACTION\n                ? metrics_1.ConnectionPoolMetrics.TXN\n                : metrics_1.ConnectionPoolMetrics.CURSOR);\n            if (options?.forceClear) {\n                loadBalancer.pool.clear({ serviceId: conn.serviceId });\n            }\n        }\n        session[kPinnedConnection] = undefined;\n    }\n}\nexports.maybeClearPinnedConnection = maybeClearPinnedConnection;\nfunction isMaxTimeMSExpiredError(err) {\n    if (err == null || !(err instanceof error_1.MongoServerError)) {\n        return false;\n    }\n    return (err.code === error_1.MONGODB_ERROR_CODES.MaxTimeMSExpired ||\n        (err.writeConcernError && err.writeConcernError.code === error_1.MONGODB_ERROR_CODES.MaxTimeMSExpired));\n}\nfunction attemptTransactionCommit(session, startTime, fn, result, options) {\n    return session.commitTransaction().then(() => result, (err) => {\n        if (err instanceof error_1.MongoError &&\n            hasNotTimedOut(startTime, MAX_WITH_TRANSACTION_TIMEOUT) &&\n            !isMaxTimeMSExpiredError(err)) {\n            if (err.hasErrorLabel(error_1.MongoErrorLabel.UnknownTransactionCommitResult)) {\n                return attemptTransactionCommit(session, startTime, fn, result, options);\n            }\n            if (err.hasErrorLabel(error_1.MongoErrorLabel.TransientTransactionError)) {\n                return attemptTransaction(session, startTime, fn, options);\n            }\n        }\n        throw err;\n    });\n}\nconst USER_EXPLICIT_TXN_END_STATES = new Set([\n    transactions_1.TxnState.NO_TRANSACTION,\n    transactions_1.TxnState.TRANSACTION_COMMITTED,\n    transactions_1.TxnState.TRANSACTION_ABORTED\n]);\nfunction userExplicitlyEndedTransaction(session) {\n    return USER_EXPLICIT_TXN_END_STATES.has(session.transaction.state);\n}\nfunction attemptTransaction(session, startTime, fn, options = {}) {\n    session.startTransaction(options);\n    let promise;\n    try {\n        promise = fn(session);\n    }\n    catch (err) {\n        promise = Promise.reject(err);\n    }\n    if (!(0, utils_1.isPromiseLike)(promise)) {\n        session.abortTransaction().catch(() => null);\n        return Promise.reject(new error_1.MongoInvalidArgumentError('Function provided to `withTransaction` must return a Promise'));\n    }\n    return promise.then(result => {\n        if (userExplicitlyEndedTransaction(session)) {\n            return result;\n        }\n        return attemptTransactionCommit(session, startTime, fn, result, options);\n    }, err => {\n        function maybeRetryOrThrow(err) {\n            if (err instanceof error_1.MongoError &&\n                err.hasErrorLabel(error_1.MongoErrorLabel.TransientTransactionError) &&\n                hasNotTimedOut(startTime, MAX_WITH_TRANSACTION_TIMEOUT)) {\n                return attemptTransaction(session, startTime, fn, options);\n            }\n            if (isMaxTimeMSExpiredError(err)) {\n                err.addErrorLabel(error_1.MongoErrorLabel.UnknownTransactionCommitResult);\n            }\n            throw err;\n        }\n        if (session.inTransaction()) {\n            return session.abortTransaction().then(() => maybeRetryOrThrow(err));\n        }\n        return maybeRetryOrThrow(err);\n    });\n}\nconst endTransactionAsync = (0, util_1.promisify)(endTransaction);\nfunction endTransaction(session, commandName, callback) {\n    // handle any initial problematic cases\n    const txnState = session.transaction.state;\n    if (txnState === transactions_1.TxnState.NO_TRANSACTION) {\n        callback(new error_1.MongoTransactionError('No transaction started'));\n        return;\n    }\n    if (commandName === 'commitTransaction') {\n        if (txnState === transactions_1.TxnState.STARTING_TRANSACTION ||\n            txnState === transactions_1.TxnState.TRANSACTION_COMMITTED_EMPTY) {\n            // the transaction was never started, we can safely exit here\n            session.transaction.transition(transactions_1.TxnState.TRANSACTION_COMMITTED_EMPTY);\n            callback();\n            return;\n        }\n        if (txnState === transactions_1.TxnState.TRANSACTION_ABORTED) {\n            callback(new error_1.MongoTransactionError('Cannot call commitTransaction after calling abortTransaction'));\n            return;\n        }\n    }\n    else {\n        if (txnState === transactions_1.TxnState.STARTING_TRANSACTION) {\n            // the transaction was never started, we can safely exit here\n            session.transaction.transition(transactions_1.TxnState.TRANSACTION_ABORTED);\n            callback();\n            return;\n        }\n        if (txnState === transactions_1.TxnState.TRANSACTION_ABORTED) {\n            callback(new error_1.MongoTransactionError('Cannot call abortTransaction twice'));\n            return;\n        }\n        if (txnState === transactions_1.TxnState.TRANSACTION_COMMITTED ||\n            txnState === transactions_1.TxnState.TRANSACTION_COMMITTED_EMPTY) {\n            callback(new error_1.MongoTransactionError('Cannot call abortTransaction after calling commitTransaction'));\n            return;\n        }\n    }\n    // construct and send the command\n    const command = { [commandName]: 1 };\n    // apply a writeConcern if specified\n    let writeConcern;\n    if (session.transaction.options.writeConcern) {\n        writeConcern = Object.assign({}, session.transaction.options.writeConcern);\n    }\n    else if (session.clientOptions && session.clientOptions.writeConcern) {\n        writeConcern = { w: session.clientOptions.writeConcern.w };\n    }\n    if (txnState === transactions_1.TxnState.TRANSACTION_COMMITTED) {\n        writeConcern = Object.assign({ wtimeoutMS: 10000 }, writeConcern, { w: 'majority' });\n    }\n    if (writeConcern) {\n        write_concern_1.WriteConcern.apply(command, writeConcern);\n    }\n    if (commandName === 'commitTransaction' && session.transaction.options.maxTimeMS) {\n        Object.assign(command, { maxTimeMS: session.transaction.options.maxTimeMS });\n    }\n    function commandHandler(error) {\n        if (commandName !== 'commitTransaction') {\n            session.transaction.transition(transactions_1.TxnState.TRANSACTION_ABORTED);\n            if (session.loadBalanced) {\n                maybeClearPinnedConnection(session, { force: false });\n            }\n            // The spec indicates that we should ignore all errors on `abortTransaction`\n            return callback();\n        }\n        session.transaction.transition(transactions_1.TxnState.TRANSACTION_COMMITTED);\n        if (error instanceof error_1.MongoError) {\n            if ((0, error_1.isRetryableWriteError)(error) ||\n                error instanceof error_1.MongoWriteConcernError ||\n                isMaxTimeMSExpiredError(error)) {\n                if (isUnknownTransactionCommitResult(error)) {\n                    error.addErrorLabel(error_1.MongoErrorLabel.UnknownTransactionCommitResult);\n                    // per txns spec, must unpin session in this case\n                    session.unpin({ error });\n                }\n            }\n            else if (error.hasErrorLabel(error_1.MongoErrorLabel.TransientTransactionError)) {\n                session.unpin({ error });\n            }\n        }\n        callback(error);\n    }\n    if (session.transaction.recoveryToken) {\n        command.recoveryToken = session.transaction.recoveryToken;\n    }\n    // send the command\n    (0, execute_operation_1.executeOperation)(session.client, new run_command_1.RunAdminCommandOperation(command, {\n        session,\n        readPreference: read_preference_1.ReadPreference.primary,\n        bypassPinningCheck: true\n    }), error => {\n        if (command.abortTransaction) {\n            // always unpin on abort regardless of command outcome\n            session.unpin();\n        }\n        if (error instanceof error_1.MongoError && (0, error_1.isRetryableWriteError)(error)) {\n            // SPEC-1185: apply majority write concern when retrying commitTransaction\n            if (command.commitTransaction) {\n                // per txns spec, must unpin session in this case\n                session.unpin({ force: true });\n                command.writeConcern = Object.assign({ wtimeout: 10000 }, command.writeConcern, {\n                    w: 'majority'\n                });\n            }\n            return (0, execute_operation_1.executeOperation)(session.client, new run_command_1.RunAdminCommandOperation(command, {\n                session,\n                readPreference: read_preference_1.ReadPreference.primary,\n                bypassPinningCheck: true\n            }), commandHandler);\n        }\n        commandHandler(error);\n    });\n}\n/**\n * Reflects the existence of a session on the server. Can be reused by the session pool.\n * WARNING: not meant to be instantiated directly. For internal use only.\n * @public\n */\nclass ServerSession {\n    /** @internal */\n    constructor() {\n        this.id = { id: new bson_1.Binary((0, utils_1.uuidV4)(), bson_1.Binary.SUBTYPE_UUID) };\n        this.lastUse = (0, utils_1.now)();\n        this.txnNumber = 0;\n        this.isDirty = false;\n    }\n    /**\n     * Determines if the server session has timed out.\n     *\n     * @param sessionTimeoutMinutes - The server's \"logicalSessionTimeoutMinutes\"\n     */\n    hasTimedOut(sessionTimeoutMinutes) {\n        // Take the difference of the lastUse timestamp and now, which will result in a value in\n        // milliseconds, and then convert milliseconds to minutes to compare to `sessionTimeoutMinutes`\n        const idleTimeMinutes = Math.round((((0, utils_1.calculateDurationInMs)(this.lastUse) % 86400000) % 3600000) / 60000);\n        return idleTimeMinutes > sessionTimeoutMinutes - 1;\n    }\n    /**\n     * @internal\n     * Cloning meant to keep a readable reference to the server session data\n     * after ClientSession has ended\n     */\n    static clone(serverSession) {\n        const arrayBuffer = new ArrayBuffer(16);\n        const idBytes = Buffer.from(arrayBuffer);\n        idBytes.set(serverSession.id.id.buffer);\n        const id = new bson_1.Binary(idBytes, serverSession.id.id.sub_type);\n        // Manual prototype construction to avoid modifying the constructor of this class\n        return Object.setPrototypeOf({\n            id: { id },\n            lastUse: serverSession.lastUse,\n            txnNumber: serverSession.txnNumber,\n            isDirty: serverSession.isDirty\n        }, ServerSession.prototype);\n    }\n}\nexports.ServerSession = ServerSession;\n/**\n * Maintains a pool of Server Sessions.\n * For internal use only\n * @internal\n */\nclass ServerSessionPool {\n    constructor(client) {\n        if (client == null) {\n            throw new error_1.MongoRuntimeError('ServerSessionPool requires a MongoClient');\n        }\n        this.client = client;\n        this.sessions = new utils_1.List();\n    }\n    /**\n     * Acquire a Server Session from the pool.\n     * Iterates through each session in the pool, removing any stale sessions\n     * along the way. The first non-stale session found is removed from the\n     * pool and returned. If no non-stale session is found, a new ServerSession is created.\n     */\n    acquire() {\n        const sessionTimeoutMinutes = this.client.topology?.logicalSessionTimeoutMinutes ?? 10;\n        let session = null;\n        // Try to obtain from session pool\n        while (this.sessions.length > 0) {\n            const potentialSession = this.sessions.shift();\n            if (potentialSession != null &&\n                (!!this.client.topology?.loadBalanced ||\n                    !potentialSession.hasTimedOut(sessionTimeoutMinutes))) {\n                session = potentialSession;\n                break;\n            }\n        }\n        // If nothing valid came from the pool make a new one\n        if (session == null) {\n            session = new ServerSession();\n        }\n        return session;\n    }\n    /**\n     * Release a session to the session pool\n     * Adds the session back to the session pool if the session has not timed out yet.\n     * This method also removes any stale sessions from the pool.\n     *\n     * @param session - The session to release to the pool\n     */\n    release(session) {\n        const sessionTimeoutMinutes = this.client.topology?.logicalSessionTimeoutMinutes ?? 10;\n        if (this.client.topology?.loadBalanced && !sessionTimeoutMinutes) {\n            this.sessions.unshift(session);\n        }\n        if (!sessionTimeoutMinutes) {\n            return;\n        }\n        this.sessions.prune(session => session.hasTimedOut(sessionTimeoutMinutes));\n        if (!session.hasTimedOut(sessionTimeoutMinutes)) {\n            if (session.isDirty) {\n                return;\n            }\n            // otherwise, readd this session to the session pool\n            this.sessions.unshift(session);\n        }\n    }\n}\nexports.ServerSessionPool = ServerSessionPool;\n/**\n * Optionally decorate a command with sessions specific keys\n *\n * @param session - the session tracking transaction state\n * @param command - the command to decorate\n * @param options - Optional settings passed to calling operation\n *\n * @internal\n */\nfunction applySession(session, command, options) {\n    if (session.hasEnded) {\n        return new error_1.MongoExpiredSessionError();\n    }\n    // May acquire serverSession here\n    const serverSession = session.serverSession;\n    if (serverSession == null) {\n        return new error_1.MongoRuntimeError('Unable to acquire server session');\n    }\n    if (options.writeConcern?.w === 0) {\n        if (session && session.explicit) {\n            // Error if user provided an explicit session to an unacknowledged write (SPEC-1019)\n            return new error_1.MongoAPIError('Cannot have explicit session with unacknowledged writes');\n        }\n        return;\n    }\n    // mark the last use of this session, and apply the `lsid`\n    serverSession.lastUse = (0, utils_1.now)();\n    command.lsid = serverSession.id;\n    const inTxnOrTxnCommand = session.inTransaction() || (0, transactions_1.isTransactionCommand)(command);\n    const isRetryableWrite = !!options.willRetryWrite;\n    if (isRetryableWrite || inTxnOrTxnCommand) {\n        serverSession.txnNumber += session[kTxnNumberIncrement];\n        session[kTxnNumberIncrement] = 0;\n        // TODO(NODE-2674): Preserve int64 sent from MongoDB\n        command.txnNumber = bson_1.Long.fromNumber(serverSession.txnNumber);\n    }\n    if (!inTxnOrTxnCommand) {\n        if (session.transaction.state !== transactions_1.TxnState.NO_TRANSACTION) {\n            session.transaction.transition(transactions_1.TxnState.NO_TRANSACTION);\n        }\n        if (session.supports.causalConsistency &&\n            session.operationTime &&\n            (0, utils_1.commandSupportsReadConcern)(command)) {\n            command.readConcern = command.readConcern || {};\n            Object.assign(command.readConcern, { afterClusterTime: session.operationTime });\n        }\n        else if (session[kSnapshotEnabled]) {\n            command.readConcern = command.readConcern || { level: read_concern_1.ReadConcernLevel.snapshot };\n            if (session[kSnapshotTime] != null) {\n                Object.assign(command.readConcern, { atClusterTime: session[kSnapshotTime] });\n            }\n        }\n        return;\n    }\n    // now attempt to apply transaction-specific sessions data\n    // `autocommit` must always be false to differentiate from retryable writes\n    command.autocommit = false;\n    if (session.transaction.state === transactions_1.TxnState.STARTING_TRANSACTION) {\n        session.transaction.transition(transactions_1.TxnState.TRANSACTION_IN_PROGRESS);\n        command.startTransaction = true;\n        const readConcern = session.transaction.options.readConcern || session?.clientOptions?.readConcern;\n        if (readConcern) {\n            command.readConcern = readConcern;\n        }\n        if (session.supports.causalConsistency && session.operationTime) {\n            command.readConcern = command.readConcern || {};\n            Object.assign(command.readConcern, { afterClusterTime: session.operationTime });\n        }\n    }\n    return;\n}\nexports.applySession = applySession;\nfunction updateSessionFromResponse(session, document) {\n    if (document.$clusterTime) {\n        (0, common_1._advanceClusterTime)(session, document.$clusterTime);\n    }\n    if (document.operationTime && session && session.supports.causalConsistency) {\n        session.advanceOperationTime(document.operationTime);\n    }\n    if (document.recoveryToken && session && session.inTransaction()) {\n        session.transaction._recoveryToken = document.recoveryToken;\n    }\n    if (session?.[kSnapshotEnabled] && session[kSnapshotTime] == null) {\n        // find and aggregate commands return atClusterTime on the cursor\n        // distinct includes it in the response body\n        const atClusterTime = document.cursor?.atClusterTime || document.atClusterTime;\n        if (atClusterTime) {\n            session[kSnapshotTime] = atClusterTime;\n        }\n    }\n}\nexports.updateSessionFromResponse = updateSessionFromResponse;\n//# sourceMappingURL=sessions.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/sessions.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sort.js":
/*!******************************************!*\
  !*** ./node_modules/mongodb/lib/sort.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.formatSort = void 0;\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\n/** @internal */\nfunction prepareDirection(direction = 1) {\n    const value = `${direction}`.toLowerCase();\n    if (isMeta(direction))\n        return direction;\n    switch (value) {\n        case 'ascending':\n        case 'asc':\n        case '1':\n            return 1;\n        case 'descending':\n        case 'desc':\n        case '-1':\n            return -1;\n        default:\n            throw new error_1.MongoInvalidArgumentError(`Invalid sort direction: ${JSON.stringify(direction)}`);\n    }\n}\n/** @internal */\nfunction isMeta(t) {\n    return typeof t === 'object' && t != null && '$meta' in t && typeof t.$meta === 'string';\n}\n/** @internal */\nfunction isPair(t) {\n    if (Array.isArray(t) && t.length === 2) {\n        try {\n            prepareDirection(t[1]);\n            return true;\n        }\n        catch (e) {\n            return false;\n        }\n    }\n    return false;\n}\nfunction isDeep(t) {\n    return Array.isArray(t) && Array.isArray(t[0]);\n}\nfunction isMap(t) {\n    return t instanceof Map && t.size > 0;\n}\n/** @internal */\nfunction pairToMap(v) {\n    return new Map([[`${v[0]}`, prepareDirection([v[1]])]]);\n}\n/** @internal */\nfunction deepToMap(t) {\n    const sortEntries = t.map(([k, v]) => [`${k}`, prepareDirection(v)]);\n    return new Map(sortEntries);\n}\n/** @internal */\nfunction stringsToMap(t) {\n    const sortEntries = t.map(key => [`${key}`, 1]);\n    return new Map(sortEntries);\n}\n/** @internal */\nfunction objectToMap(t) {\n    const sortEntries = Object.entries(t).map(([k, v]) => [\n        `${k}`,\n        prepareDirection(v)\n    ]);\n    return new Map(sortEntries);\n}\n/** @internal */\nfunction mapToMap(t) {\n    const sortEntries = Array.from(t).map(([k, v]) => [\n        `${k}`,\n        prepareDirection(v)\n    ]);\n    return new Map(sortEntries);\n}\n/** converts a Sort type into a type that is valid for the server (SortForCmd) */\nfunction formatSort(sort, direction) {\n    if (sort == null)\n        return undefined;\n    if (typeof sort === 'string')\n        return new Map([[sort, prepareDirection(direction)]]);\n    if (typeof sort !== 'object') {\n        throw new error_1.MongoInvalidArgumentError(`Invalid sort format: ${JSON.stringify(sort)} Sort must be a valid object`);\n    }\n    if (!Array.isArray(sort)) {\n        return isMap(sort) ? mapToMap(sort) : Object.keys(sort).length ? objectToMap(sort) : undefined;\n    }\n    if (!sort.length)\n        return undefined;\n    if (isDeep(sort))\n        return deepToMap(sort);\n    if (isPair(sort))\n        return pairToMap(sort);\n    return stringsToMap(sort);\n}\nexports.formatSort = formatSort;\n//# sourceMappingURL=sort.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/sort.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/transactions.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/transactions.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.isTransactionCommand = exports.Transaction = exports.TxnState = void 0;\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_concern_1 = __webpack_require__(/*! ./read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst read_preference_1 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst write_concern_1 = __webpack_require__(/*! ./write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\n/** @internal */\nexports.TxnState = Object.freeze({\n    NO_TRANSACTION: 'NO_TRANSACTION',\n    STARTING_TRANSACTION: 'STARTING_TRANSACTION',\n    TRANSACTION_IN_PROGRESS: 'TRANSACTION_IN_PROGRESS',\n    TRANSACTION_COMMITTED: 'TRANSACTION_COMMITTED',\n    TRANSACTION_COMMITTED_EMPTY: 'TRANSACTION_COMMITTED_EMPTY',\n    TRANSACTION_ABORTED: 'TRANSACTION_ABORTED'\n});\nconst stateMachine = {\n    [exports.TxnState.NO_TRANSACTION]: [exports.TxnState.NO_TRANSACTION, exports.TxnState.STARTING_TRANSACTION],\n    [exports.TxnState.STARTING_TRANSACTION]: [\n        exports.TxnState.TRANSACTION_IN_PROGRESS,\n        exports.TxnState.TRANSACTION_COMMITTED,\n        exports.TxnState.TRANSACTION_COMMITTED_EMPTY,\n        exports.TxnState.TRANSACTION_ABORTED\n    ],\n    [exports.TxnState.TRANSACTION_IN_PROGRESS]: [\n        exports.TxnState.TRANSACTION_IN_PROGRESS,\n        exports.TxnState.TRANSACTION_COMMITTED,\n        exports.TxnState.TRANSACTION_ABORTED\n    ],\n    [exports.TxnState.TRANSACTION_COMMITTED]: [\n        exports.TxnState.TRANSACTION_COMMITTED,\n        exports.TxnState.TRANSACTION_COMMITTED_EMPTY,\n        exports.TxnState.STARTING_TRANSACTION,\n        exports.TxnState.NO_TRANSACTION\n    ],\n    [exports.TxnState.TRANSACTION_ABORTED]: [exports.TxnState.STARTING_TRANSACTION, exports.TxnState.NO_TRANSACTION],\n    [exports.TxnState.TRANSACTION_COMMITTED_EMPTY]: [\n        exports.TxnState.TRANSACTION_COMMITTED_EMPTY,\n        exports.TxnState.NO_TRANSACTION\n    ]\n};\nconst ACTIVE_STATES = new Set([\n    exports.TxnState.STARTING_TRANSACTION,\n    exports.TxnState.TRANSACTION_IN_PROGRESS\n]);\nconst COMMITTED_STATES = new Set([\n    exports.TxnState.TRANSACTION_COMMITTED,\n    exports.TxnState.TRANSACTION_COMMITTED_EMPTY,\n    exports.TxnState.TRANSACTION_ABORTED\n]);\n/**\n * @public\n * A class maintaining state related to a server transaction. Internal Only\n */\nclass Transaction {\n    /** Create a transaction @internal */\n    constructor(options) {\n        options = options ?? {};\n        this.state = exports.TxnState.NO_TRANSACTION;\n        this.options = {};\n        const writeConcern = write_concern_1.WriteConcern.fromOptions(options);\n        if (writeConcern) {\n            if (writeConcern.w === 0) {\n                throw new error_1.MongoTransactionError('Transactions do not support unacknowledged write concern');\n            }\n            this.options.writeConcern = writeConcern;\n        }\n        if (options.readConcern) {\n            this.options.readConcern = read_concern_1.ReadConcern.fromOptions(options);\n        }\n        if (options.readPreference) {\n            this.options.readPreference = read_preference_1.ReadPreference.fromOptions(options);\n        }\n        if (options.maxCommitTimeMS) {\n            this.options.maxTimeMS = options.maxCommitTimeMS;\n        }\n        // TODO: This isn't technically necessary\n        this._pinnedServer = undefined;\n        this._recoveryToken = undefined;\n    }\n    /** @internal */\n    get server() {\n        return this._pinnedServer;\n    }\n    get recoveryToken() {\n        return this._recoveryToken;\n    }\n    get isPinned() {\n        return !!this.server;\n    }\n    /** @returns Whether the transaction has started */\n    get isStarting() {\n        return this.state === exports.TxnState.STARTING_TRANSACTION;\n    }\n    /**\n     * @returns Whether this session is presently in a transaction\n     */\n    get isActive() {\n        return ACTIVE_STATES.has(this.state);\n    }\n    get isCommitted() {\n        return COMMITTED_STATES.has(this.state);\n    }\n    /**\n     * Transition the transaction in the state machine\n     * @internal\n     * @param nextState - The new state to transition to\n     */\n    transition(nextState) {\n        const nextStates = stateMachine[this.state];\n        if (nextStates && nextStates.includes(nextState)) {\n            this.state = nextState;\n            if (this.state === exports.TxnState.NO_TRANSACTION ||\n                this.state === exports.TxnState.STARTING_TRANSACTION ||\n                this.state === exports.TxnState.TRANSACTION_ABORTED) {\n                this.unpinServer();\n            }\n            return;\n        }\n        throw new error_1.MongoRuntimeError(`Attempted illegal state transition from [${this.state}] to [${nextState}]`);\n    }\n    /** @internal */\n    pinServer(server) {\n        if (this.isActive) {\n            this._pinnedServer = server;\n        }\n    }\n    /** @internal */\n    unpinServer() {\n        this._pinnedServer = undefined;\n    }\n}\nexports.Transaction = Transaction;\nfunction isTransactionCommand(command) {\n    return !!(command.commitTransaction || command.abortTransaction);\n}\nexports.isTransactionCommand = isTransactionCommand;\n//# sourceMappingURL=transactions.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/transactions.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/utils.js":
/*!*******************************************!*\
  !*** ./node_modules/mongodb/lib/utils.js ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DOCUMENT_DB_CHECK = exports.TimeoutController = exports.request = exports.matchesParentDomain = exports.parseUnsignedInteger = exports.parseInteger = exports.compareObjectId = exports.commandSupportsReadConcern = exports.shuffle = exports.supportsRetryableWrites = exports.enumToString = exports.emitWarningOnce = exports.emitWarning = exports.MONGODB_WARNING_CODE = exports.DEFAULT_PK_FACTORY = exports.HostAddress = exports.BufferPool = exports.List = exports.deepCopy = exports.isRecord = exports.setDifference = exports.isHello = exports.isSuperset = exports.resolveOptions = exports.hasAtomicOperators = exports.calculateDurationInMs = exports.now = exports.makeStateMachine = exports.errorStrictEqual = exports.arrayStrictEqual = exports.eachAsync = exports.maxWireVersion = exports.uuidV4 = exports.maybeCallback = exports.makeCounter = exports.MongoDBCollectionNamespace = exports.MongoDBNamespace = exports.ns = exports.getTopology = exports.decorateWithExplain = exports.decorateWithReadConcern = exports.decorateWithCollation = exports.isPromiseLike = exports.applyRetryableWrites = exports.filterOptions = exports.mergeOptions = exports.isObject = exports.normalizeHintField = exports.hostMatchesWildcards = exports.ByteUtils = void 0;\nexports.isHostMatch = exports.COSMOS_DB_MSG = exports.DOCUMENT_DB_MSG = exports.COSMOS_DB_CHECK = void 0;\nconst crypto = __webpack_require__(/*! crypto */ \"crypto\");\nconst http = __webpack_require__(/*! http */ \"http\");\nconst timers_1 = __webpack_require__(/*! timers */ \"timers\");\nconst url = __webpack_require__(/*! url */ \"url\");\nconst url_1 = __webpack_require__(/*! url */ \"url\");\nconst bson_1 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst constants_1 = __webpack_require__(/*! ./cmap/wire_protocol/constants */ \"./node_modules/mongodb/lib/cmap/wire_protocol/constants.js\");\nconst constants_2 = __webpack_require__(/*! ./constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_concern_1 = __webpack_require__(/*! ./read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst read_preference_1 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst common_1 = __webpack_require__(/*! ./sdam/common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst write_concern_1 = __webpack_require__(/*! ./write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\nexports.ByteUtils = {\n    toLocalBufferType(buffer) {\n        return Buffer.isBuffer(buffer)\n            ? buffer\n            : Buffer.from(buffer.buffer, buffer.byteOffset, buffer.byteLength);\n    },\n    equals(seqA, seqB) {\n        return exports.ByteUtils.toLocalBufferType(seqA).equals(seqB);\n    },\n    compare(seqA, seqB) {\n        return exports.ByteUtils.toLocalBufferType(seqA).compare(seqB);\n    },\n    toBase64(uint8array) {\n        return exports.ByteUtils.toLocalBufferType(uint8array).toString('base64');\n    }\n};\n/**\n * Determines if a connection's address matches a user provided list\n * of domain wildcards.\n */\nfunction hostMatchesWildcards(host, wildcards) {\n    for (const wildcard of wildcards) {\n        if (host === wildcard ||\n            (wildcard.startsWith('*.') && host?.endsWith(wildcard.substring(2, wildcard.length))) ||\n            (wildcard.startsWith('*/') && host?.endsWith(wildcard.substring(2, wildcard.length)))) {\n            return true;\n        }\n    }\n    return false;\n}\nexports.hostMatchesWildcards = hostMatchesWildcards;\n/**\n * Ensure Hint field is in a shape we expect:\n * - object of index names mapping to 1 or -1\n * - just an index name\n * @internal\n */\nfunction normalizeHintField(hint) {\n    let finalHint = undefined;\n    if (typeof hint === 'string') {\n        finalHint = hint;\n    }\n    else if (Array.isArray(hint)) {\n        finalHint = {};\n        hint.forEach(param => {\n            finalHint[param] = 1;\n        });\n    }\n    else if (hint != null && typeof hint === 'object') {\n        finalHint = {};\n        for (const name in hint) {\n            finalHint[name] = hint[name];\n        }\n    }\n    return finalHint;\n}\nexports.normalizeHintField = normalizeHintField;\nconst TO_STRING = (object) => Object.prototype.toString.call(object);\n/**\n * Checks if arg is an Object:\n * - **NOTE**: the check is based on the `[Symbol.toStringTag]() === 'Object'`\n * @internal\n */\nfunction isObject(arg) {\n    return '[object Object]' === TO_STRING(arg);\n}\nexports.isObject = isObject;\n/** @internal */\nfunction mergeOptions(target, source) {\n    return { ...target, ...source };\n}\nexports.mergeOptions = mergeOptions;\n/** @internal */\nfunction filterOptions(options, names) {\n    const filterOptions = {};\n    for (const name in options) {\n        if (names.includes(name)) {\n            filterOptions[name] = options[name];\n        }\n    }\n    // Filtered options\n    return filterOptions;\n}\nexports.filterOptions = filterOptions;\n/**\n * Applies retryWrites: true to a command if retryWrites is set on the command's database.\n * @internal\n *\n * @param target - The target command to which we will apply retryWrites.\n * @param db - The database from which we can inherit a retryWrites value.\n */\nfunction applyRetryableWrites(target, db) {\n    if (db && db.s.options?.retryWrites) {\n        target.retryWrites = true;\n    }\n    return target;\n}\nexports.applyRetryableWrites = applyRetryableWrites;\n/**\n * Applies a write concern to a command based on well defined inheritance rules, optionally\n * detecting support for the write concern in the first place.\n * @internal\n *\n * @param target - the target command we will be applying the write concern to\n * @param sources - sources where we can inherit default write concerns from\n * @param options - optional settings passed into a command for write concern overrides\n */\n/**\n * Checks if a given value is a Promise\n *\n * @typeParam T - The resolution type of the possible promise\n * @param value - An object that could be a promise\n * @returns true if the provided value is a Promise\n */\nfunction isPromiseLike(value) {\n    return !!value && typeof value.then === 'function';\n}\nexports.isPromiseLike = isPromiseLike;\n/**\n * Applies collation to a given command.\n * @internal\n *\n * @param command - the command on which to apply collation\n * @param target - target of command\n * @param options - options containing collation settings\n */\nfunction decorateWithCollation(command, target, options) {\n    const capabilities = getTopology(target).capabilities;\n    if (options.collation && typeof options.collation === 'object') {\n        if (capabilities && capabilities.commandsTakeCollation) {\n            command.collation = options.collation;\n        }\n        else {\n            throw new error_1.MongoCompatibilityError(`Current topology does not support collation`);\n        }\n    }\n}\nexports.decorateWithCollation = decorateWithCollation;\n/**\n * Applies a read concern to a given command.\n * @internal\n *\n * @param command - the command on which to apply the read concern\n * @param coll - the parent collection of the operation calling this method\n */\nfunction decorateWithReadConcern(command, coll, options) {\n    if (options && options.session && options.session.inTransaction()) {\n        return;\n    }\n    const readConcern = Object.assign({}, command.readConcern || {});\n    if (coll.s.readConcern) {\n        Object.assign(readConcern, coll.s.readConcern);\n    }\n    if (Object.keys(readConcern).length > 0) {\n        Object.assign(command, { readConcern: readConcern });\n    }\n}\nexports.decorateWithReadConcern = decorateWithReadConcern;\n/**\n * Applies an explain to a given command.\n * @internal\n *\n * @param command - the command on which to apply the explain\n * @param options - the options containing the explain verbosity\n */\nfunction decorateWithExplain(command, explain) {\n    if (command.explain) {\n        return command;\n    }\n    return { explain: command, verbosity: explain.verbosity };\n}\nexports.decorateWithExplain = decorateWithExplain;\n/**\n * A helper function to get the topology from a given provider. Throws\n * if the topology cannot be found.\n * @throws MongoNotConnectedError\n * @internal\n */\nfunction getTopology(provider) {\n    // MongoClient or ClientSession or AbstractCursor\n    if ('topology' in provider && provider.topology) {\n        return provider.topology;\n    }\n    else if ('client' in provider && provider.client.topology) {\n        return provider.client.topology;\n    }\n    throw new error_1.MongoNotConnectedError('MongoClient must be connected to perform this operation');\n}\nexports.getTopology = getTopology;\n/** @internal */\nfunction ns(ns) {\n    return MongoDBNamespace.fromString(ns);\n}\nexports.ns = ns;\n/** @public */\nclass MongoDBNamespace {\n    /**\n     * Create a namespace object\n     *\n     * @param db - database name\n     * @param collection - collection name\n     */\n    constructor(db, collection) {\n        this.db = db;\n        this.collection = collection;\n        this.collection = collection === '' ? undefined : collection;\n    }\n    toString() {\n        return this.collection ? `${this.db}.${this.collection}` : this.db;\n    }\n    withCollection(collection) {\n        return new MongoDBCollectionNamespace(this.db, collection);\n    }\n    static fromString(namespace) {\n        if (typeof namespace !== 'string' || namespace === '') {\n            // TODO(NODE-3483): Replace with MongoNamespaceError\n            throw new error_1.MongoRuntimeError(`Cannot parse namespace from \"${namespace}\"`);\n        }\n        const [db, ...collectionParts] = namespace.split('.');\n        const collection = collectionParts.join('.');\n        return new MongoDBNamespace(db, collection === '' ? undefined : collection);\n    }\n}\nexports.MongoDBNamespace = MongoDBNamespace;\n/**\n * @public\n *\n * A class representing a collection's namespace.  This class enforces (through Typescript) that\n * the `collection` portion of the namespace is defined and should only be\n * used in scenarios where this can be guaranteed.\n */\nclass MongoDBCollectionNamespace extends MongoDBNamespace {\n    constructor(db, collection) {\n        super(db, collection);\n        this.collection = collection;\n    }\n    static fromString(namespace) {\n        return super.fromString(namespace);\n    }\n}\nexports.MongoDBCollectionNamespace = MongoDBCollectionNamespace;\n/** @internal */\nfunction* makeCounter(seed = 0) {\n    let count = seed;\n    while (true) {\n        const newCount = count;\n        count += 1;\n        yield newCount;\n    }\n}\nexports.makeCounter = makeCounter;\nfunction maybeCallback(promiseFn, callback) {\n    const promise = promiseFn();\n    if (callback == null) {\n        return promise;\n    }\n    promise.then(result => callback(undefined, result), error => callback(error));\n    return;\n}\nexports.maybeCallback = maybeCallback;\n/**\n * Synchronously Generate a UUIDv4\n * @internal\n */\nfunction uuidV4() {\n    const result = crypto.randomBytes(16);\n    result[6] = (result[6] & 0x0f) | 0x40;\n    result[8] = (result[8] & 0x3f) | 0x80;\n    return result;\n}\nexports.uuidV4 = uuidV4;\n/**\n * A helper function for determining `maxWireVersion` between legacy and new topology instances\n * @internal\n */\nfunction maxWireVersion(topologyOrServer) {\n    if (topologyOrServer) {\n        if (topologyOrServer.loadBalanced) {\n            // Since we do not have a monitor, we assume the load balanced server is always\n            // pointed at the latest mongodb version. There is a risk that for on-prem\n            // deployments that don't upgrade immediately that this could alert to the\n            // application that a feature is available that is actually not.\n            return constants_1.MAX_SUPPORTED_WIRE_VERSION;\n        }\n        if (topologyOrServer.hello) {\n            return topologyOrServer.hello.maxWireVersion;\n        }\n        if ('lastHello' in topologyOrServer && typeof topologyOrServer.lastHello === 'function') {\n            const lastHello = topologyOrServer.lastHello();\n            if (lastHello) {\n                return lastHello.maxWireVersion;\n            }\n        }\n        if (topologyOrServer.description &&\n            'maxWireVersion' in topologyOrServer.description &&\n            topologyOrServer.description.maxWireVersion != null) {\n            return topologyOrServer.description.maxWireVersion;\n        }\n    }\n    return 0;\n}\nexports.maxWireVersion = maxWireVersion;\n/**\n * Applies the function `eachFn` to each item in `arr`, in parallel.\n * @internal\n *\n * @param arr - An array of items to asynchronously iterate over\n * @param eachFn - A function to call on each item of the array. The callback signature is `(item, callback)`, where the callback indicates iteration is complete.\n * @param callback - The callback called after every item has been iterated\n */\nfunction eachAsync(arr, eachFn, callback) {\n    arr = arr || [];\n    let idx = 0;\n    let awaiting = 0;\n    for (idx = 0; idx < arr.length; ++idx) {\n        awaiting++;\n        eachFn(arr[idx], eachCallback);\n    }\n    if (awaiting === 0) {\n        callback();\n        return;\n    }\n    function eachCallback(err) {\n        awaiting--;\n        if (err) {\n            callback(err);\n            return;\n        }\n        if (idx === arr.length && awaiting <= 0) {\n            callback();\n        }\n    }\n}\nexports.eachAsync = eachAsync;\n/** @internal */\nfunction arrayStrictEqual(arr, arr2) {\n    if (!Array.isArray(arr) || !Array.isArray(arr2)) {\n        return false;\n    }\n    return arr.length === arr2.length && arr.every((elt, idx) => elt === arr2[idx]);\n}\nexports.arrayStrictEqual = arrayStrictEqual;\n/** @internal */\nfunction errorStrictEqual(lhs, rhs) {\n    if (lhs === rhs) {\n        return true;\n    }\n    if (!lhs || !rhs) {\n        return lhs === rhs;\n    }\n    if ((lhs == null && rhs != null) || (lhs != null && rhs == null)) {\n        return false;\n    }\n    if (lhs.constructor.name !== rhs.constructor.name) {\n        return false;\n    }\n    if (lhs.message !== rhs.message) {\n        return false;\n    }\n    return true;\n}\nexports.errorStrictEqual = errorStrictEqual;\n/** @internal */\nfunction makeStateMachine(stateTable) {\n    return function stateTransition(target, newState) {\n        const legalStates = stateTable[target.s.state];\n        if (legalStates && legalStates.indexOf(newState) < 0) {\n            throw new error_1.MongoRuntimeError(`illegal state transition from [${target.s.state}] => [${newState}], allowed: [${legalStates}]`);\n        }\n        target.emit('stateChanged', target.s.state, newState);\n        target.s.state = newState;\n    };\n}\nexports.makeStateMachine = makeStateMachine;\n/** @internal */\nfunction now() {\n    const hrtime = process.hrtime();\n    return Math.floor(hrtime[0] * 1000 + hrtime[1] / 1000000);\n}\nexports.now = now;\n/** @internal */\nfunction calculateDurationInMs(started) {\n    if (typeof started !== 'number') {\n        throw new error_1.MongoInvalidArgumentError('Numeric value required to calculate duration');\n    }\n    const elapsed = now() - started;\n    return elapsed < 0 ? 0 : elapsed;\n}\nexports.calculateDurationInMs = calculateDurationInMs;\n/** @internal */\nfunction hasAtomicOperators(doc) {\n    if (Array.isArray(doc)) {\n        for (const document of doc) {\n            if (hasAtomicOperators(document)) {\n                return true;\n            }\n        }\n        return false;\n    }\n    const keys = Object.keys(doc);\n    return keys.length > 0 && keys[0][0] === '$';\n}\nexports.hasAtomicOperators = hasAtomicOperators;\n/**\n * Merge inherited properties from parent into options, prioritizing values from options,\n * then values from parent.\n * @internal\n */\nfunction resolveOptions(parent, options) {\n    const result = Object.assign({}, options, (0, bson_1.resolveBSONOptions)(options, parent));\n    // Users cannot pass a readConcern/writeConcern to operations in a transaction\n    const session = options?.session;\n    if (!session?.inTransaction()) {\n        const readConcern = read_concern_1.ReadConcern.fromOptions(options) ?? parent?.readConcern;\n        if (readConcern) {\n            result.readConcern = readConcern;\n        }\n        const writeConcern = write_concern_1.WriteConcern.fromOptions(options) ?? parent?.writeConcern;\n        if (writeConcern) {\n            result.writeConcern = writeConcern;\n        }\n    }\n    const readPreference = read_preference_1.ReadPreference.fromOptions(options) ?? parent?.readPreference;\n    if (readPreference) {\n        result.readPreference = readPreference;\n    }\n    return result;\n}\nexports.resolveOptions = resolveOptions;\nfunction isSuperset(set, subset) {\n    set = Array.isArray(set) ? new Set(set) : set;\n    subset = Array.isArray(subset) ? new Set(subset) : subset;\n    for (const elem of subset) {\n        if (!set.has(elem)) {\n            return false;\n        }\n    }\n    return true;\n}\nexports.isSuperset = isSuperset;\n/**\n * Checks if the document is a Hello request\n * @internal\n */\nfunction isHello(doc) {\n    return doc[constants_2.LEGACY_HELLO_COMMAND] || doc.hello ? true : false;\n}\nexports.isHello = isHello;\n/** Returns the items that are uniquely in setA */\nfunction setDifference(setA, setB) {\n    const difference = new Set(setA);\n    for (const elem of setB) {\n        difference.delete(elem);\n    }\n    return difference;\n}\nexports.setDifference = setDifference;\nconst HAS_OWN = (object, prop) => Object.prototype.hasOwnProperty.call(object, prop);\nfunction isRecord(value, requiredKeys = undefined) {\n    if (!isObject(value)) {\n        return false;\n    }\n    const ctor = value.constructor;\n    if (ctor && ctor.prototype) {\n        if (!isObject(ctor.prototype)) {\n            return false;\n        }\n        // Check to see if some method exists from the Object exists\n        if (!HAS_OWN(ctor.prototype, 'isPrototypeOf')) {\n            return false;\n        }\n    }\n    if (requiredKeys) {\n        const keys = Object.keys(value);\n        return isSuperset(keys, requiredKeys);\n    }\n    return true;\n}\nexports.isRecord = isRecord;\n/**\n * Make a deep copy of an object\n *\n * NOTE: This is not meant to be the perfect implementation of a deep copy,\n * but instead something that is good enough for the purposes of\n * command monitoring.\n */\nfunction deepCopy(value) {\n    if (value == null) {\n        return value;\n    }\n    else if (Array.isArray(value)) {\n        return value.map(item => deepCopy(item));\n    }\n    else if (isRecord(value)) {\n        const res = {};\n        for (const key in value) {\n            res[key] = deepCopy(value[key]);\n        }\n        return res;\n    }\n    const ctor = value.constructor;\n    if (ctor) {\n        switch (ctor.name.toLowerCase()) {\n            case 'date':\n                return new ctor(Number(value));\n            case 'map':\n                return new Map(value);\n            case 'set':\n                return new Set(value);\n            case 'buffer':\n                return Buffer.from(value);\n        }\n    }\n    return value;\n}\nexports.deepCopy = deepCopy;\n/**\n * A sequential list of items in a circularly linked list\n * @remarks\n * The head node is special, it is always defined and has a value of null.\n * It is never \"included\" in the list, in that, it is not returned by pop/shift or yielded by the iterator.\n * The circular linkage and always defined head node are to reduce checks for null next/prev references to zero.\n * New nodes are declared as object literals with keys always in the same order: next, prev, value.\n * @internal\n */\nclass List {\n    get length() {\n        return this.count;\n    }\n    get [Symbol.toStringTag]() {\n        return 'List';\n    }\n    constructor() {\n        this.count = 0;\n        // this is carefully crafted:\n        // declaring a complete and consistently key ordered\n        // object is beneficial to the runtime optimizations\n        this.head = {\n            next: null,\n            prev: null,\n            value: null\n        };\n        this.head.next = this.head;\n        this.head.prev = this.head;\n    }\n    toArray() {\n        return Array.from(this);\n    }\n    toString() {\n        return `head <=> ${this.toArray().join(' <=> ')} <=> head`;\n    }\n    *[Symbol.iterator]() {\n        for (const node of this.nodes()) {\n            yield node.value;\n        }\n    }\n    *nodes() {\n        let ptr = this.head.next;\n        while (ptr !== this.head) {\n            // Save next before yielding so that we make removing within iteration safe\n            const { next } = ptr;\n            yield ptr;\n            ptr = next;\n        }\n    }\n    /** Insert at end of list */\n    push(value) {\n        this.count += 1;\n        const newNode = {\n            next: this.head,\n            prev: this.head.prev,\n            value\n        };\n        this.head.prev.next = newNode;\n        this.head.prev = newNode;\n    }\n    /** Inserts every item inside an iterable instead of the iterable itself */\n    pushMany(iterable) {\n        for (const value of iterable) {\n            this.push(value);\n        }\n    }\n    /** Insert at front of list */\n    unshift(value) {\n        this.count += 1;\n        const newNode = {\n            next: this.head.next,\n            prev: this.head,\n            value\n        };\n        this.head.next.prev = newNode;\n        this.head.next = newNode;\n    }\n    remove(node) {\n        if (node === this.head || this.length === 0) {\n            return null;\n        }\n        this.count -= 1;\n        const prevNode = node.prev;\n        const nextNode = node.next;\n        prevNode.next = nextNode;\n        nextNode.prev = prevNode;\n        return node.value;\n    }\n    /** Removes the first node at the front of the list */\n    shift() {\n        return this.remove(this.head.next);\n    }\n    /** Removes the last node at the end of the list */\n    pop() {\n        return this.remove(this.head.prev);\n    }\n    /** Iterates through the list and removes nodes where filter returns true */\n    prune(filter) {\n        for (const node of this.nodes()) {\n            if (filter(node.value)) {\n                this.remove(node);\n            }\n        }\n    }\n    clear() {\n        this.count = 0;\n        this.head.next = this.head;\n        this.head.prev = this.head;\n    }\n    /** Returns the first item in the list, does not remove */\n    first() {\n        // If the list is empty, value will be the head's null\n        return this.head.next.value;\n    }\n    /** Returns the last item in the list, does not remove */\n    last() {\n        // If the list is empty, value will be the head's null\n        return this.head.prev.value;\n    }\n}\nexports.List = List;\n/**\n * A pool of Buffers which allow you to read them as if they were one\n * @internal\n */\nclass BufferPool {\n    constructor() {\n        this.buffers = new List();\n        this.totalByteLength = 0;\n    }\n    get length() {\n        return this.totalByteLength;\n    }\n    /** Adds a buffer to the internal buffer pool list */\n    append(buffer) {\n        this.buffers.push(buffer);\n        this.totalByteLength += buffer.length;\n    }\n    /**\n     * If BufferPool contains 4 bytes or more construct an int32 from the leading bytes,\n     * otherwise return null. Size can be negative, caller should error check.\n     */\n    getInt32() {\n        if (this.totalByteLength < 4) {\n            return null;\n        }\n        const firstBuffer = this.buffers.first();\n        if (firstBuffer != null && firstBuffer.byteLength >= 4) {\n            return firstBuffer.readInt32LE(0);\n        }\n        // Unlikely case: an int32 is split across buffers.\n        // Use read and put the returned buffer back on top\n        const top4Bytes = this.read(4);\n        const value = top4Bytes.readInt32LE(0);\n        // Put it back.\n        this.totalByteLength += 4;\n        this.buffers.unshift(top4Bytes);\n        return value;\n    }\n    /** Reads the requested number of bytes, optionally consuming them */\n    read(size) {\n        if (typeof size !== 'number' || size < 0) {\n            throw new error_1.MongoInvalidArgumentError('Argument \"size\" must be a non-negative number');\n        }\n        // oversized request returns empty buffer\n        if (size > this.totalByteLength) {\n            return Buffer.alloc(0);\n        }\n        // We know we have enough, we just don't know how it is spread across chunks\n        // TODO(NODE-4732): alloc API should change based on raw option\n        const result = Buffer.allocUnsafe(size);\n        for (let bytesRead = 0; bytesRead < size;) {\n            const buffer = this.buffers.shift();\n            if (buffer == null) {\n                break;\n            }\n            const bytesRemaining = size - bytesRead;\n            const bytesReadable = Math.min(bytesRemaining, buffer.byteLength);\n            const bytes = buffer.subarray(0, bytesReadable);\n            result.set(bytes, bytesRead);\n            bytesRead += bytesReadable;\n            this.totalByteLength -= bytesReadable;\n            if (bytesReadable < buffer.byteLength) {\n                this.buffers.unshift(buffer.subarray(bytesReadable));\n            }\n        }\n        return result;\n    }\n}\nexports.BufferPool = BufferPool;\n/** @public */\nclass HostAddress {\n    constructor(hostString) {\n        this.host = undefined;\n        this.port = undefined;\n        this.socketPath = undefined;\n        this.isIPv6 = false;\n        const escapedHost = hostString.split(' ').join('%20'); // escape spaces, for socket path hosts\n        if (escapedHost.endsWith('.sock')) {\n            // heuristically determine if we're working with a domain socket\n            this.socketPath = decodeURIComponent(escapedHost);\n            return;\n        }\n        const urlString = `iLoveJS://${escapedHost}`;\n        let url;\n        try {\n            url = new url_1.URL(urlString);\n        }\n        catch (urlError) {\n            const runtimeError = new error_1.MongoRuntimeError(`Unable to parse ${escapedHost} with URL`);\n            runtimeError.cause = urlError;\n            throw runtimeError;\n        }\n        const hostname = url.hostname;\n        const port = url.port;\n        let normalized = decodeURIComponent(hostname).toLowerCase();\n        if (normalized.startsWith('[') && normalized.endsWith(']')) {\n            this.isIPv6 = true;\n            normalized = normalized.substring(1, hostname.length - 1);\n        }\n        this.host = normalized.toLowerCase();\n        if (typeof port === 'number') {\n            this.port = port;\n        }\n        else if (typeof port === 'string' && port !== '') {\n            this.port = Number.parseInt(port, 10);\n        }\n        else {\n            this.port = 27017;\n        }\n        if (this.port === 0) {\n            throw new error_1.MongoParseError('Invalid port (zero) with hostname');\n        }\n        Object.freeze(this);\n    }\n    [Symbol.for('nodejs.util.inspect.custom')]() {\n        return this.inspect();\n    }\n    inspect() {\n        return `new HostAddress('${this.toString()}')`;\n    }\n    toString() {\n        if (typeof this.host === 'string') {\n            if (this.isIPv6) {\n                return `[${this.host}]:${this.port}`;\n            }\n            return `${this.host}:${this.port}`;\n        }\n        return `${this.socketPath}`;\n    }\n    static fromString(s) {\n        return new HostAddress(s);\n    }\n    static fromHostPort(host, port) {\n        if (host.includes(':')) {\n            host = `[${host}]`; // IPv6 address\n        }\n        return HostAddress.fromString(`${host}:${port}`);\n    }\n    static fromSrvRecord({ name, port }) {\n        return HostAddress.fromHostPort(name, port);\n    }\n    toHostPort() {\n        if (this.socketPath) {\n            return { host: this.socketPath, port: 0 };\n        }\n        const host = this.host ?? '';\n        const port = this.port ?? 0;\n        return { host, port };\n    }\n}\nexports.HostAddress = HostAddress;\nexports.DEFAULT_PK_FACTORY = {\n    // We prefer not to rely on ObjectId having a createPk method\n    createPk() {\n        return new bson_1.ObjectId();\n    }\n};\n/**\n * When the driver used emitWarning the code will be equal to this.\n * @public\n *\n * @example\n * ```ts\n * process.on('warning', (warning) => {\n *  if (warning.code === MONGODB_WARNING_CODE) console.error('Ah an important warning! :)')\n * })\n * ```\n */\nexports.MONGODB_WARNING_CODE = 'MONGODB DRIVER';\n/** @internal */\nfunction emitWarning(message) {\n    return process.emitWarning(message, { code: exports.MONGODB_WARNING_CODE });\n}\nexports.emitWarning = emitWarning;\nconst emittedWarnings = new Set();\n/**\n * Will emit a warning once for the duration of the application.\n * Uses the message to identify if it has already been emitted\n * so using string interpolation can cause multiple emits\n * @internal\n */\nfunction emitWarningOnce(message) {\n    if (!emittedWarnings.has(message)) {\n        emittedWarnings.add(message);\n        return emitWarning(message);\n    }\n}\nexports.emitWarningOnce = emitWarningOnce;\n/**\n * Takes a JS object and joins the values into a string separated by ', '\n */\nfunction enumToString(en) {\n    return Object.values(en).join(', ');\n}\nexports.enumToString = enumToString;\n/**\n * Determine if a server supports retryable writes.\n *\n * @internal\n */\nfunction supportsRetryableWrites(server) {\n    if (!server) {\n        return false;\n    }\n    if (server.loadBalanced) {\n        // Loadbalanced topologies will always support retry writes\n        return true;\n    }\n    if (server.description.logicalSessionTimeoutMinutes != null) {\n        // that supports sessions\n        if (server.description.type !== common_1.ServerType.Standalone) {\n            // and that is not a standalone\n            return true;\n        }\n    }\n    return false;\n}\nexports.supportsRetryableWrites = supportsRetryableWrites;\n/**\n * FisherYates Shuffle\n *\n * Reference: https://bost.ocks.org/mike/shuffle/\n * @param sequence - items to be shuffled\n * @param limit - Defaults to `0`. If nonzero shuffle will slice the randomized array e.g, `.slice(0, limit)` otherwise will return the entire randomized array.\n */\nfunction shuffle(sequence, limit = 0) {\n    const items = Array.from(sequence); // shallow copy in order to never shuffle the input\n    if (limit > items.length) {\n        throw new error_1.MongoRuntimeError('Limit must be less than the number of items');\n    }\n    let remainingItemsToShuffle = items.length;\n    const lowerBound = limit % items.length === 0 ? 1 : items.length - limit;\n    while (remainingItemsToShuffle > lowerBound) {\n        // Pick a remaining element\n        const randomIndex = Math.floor(Math.random() * remainingItemsToShuffle);\n        remainingItemsToShuffle -= 1;\n        // And swap it with the current element\n        const swapHold = items[remainingItemsToShuffle];\n        items[remainingItemsToShuffle] = items[randomIndex];\n        items[randomIndex] = swapHold;\n    }\n    return limit % items.length === 0 ? items : items.slice(lowerBound);\n}\nexports.shuffle = shuffle;\n// TODO(NODE-4936): read concern eligibility for commands should be codified in command construction\n// @see https://github.com/mongodb/specifications/blob/master/source/read-write-concern/read-write-concern.rst#read-concern\nfunction commandSupportsReadConcern(command) {\n    if (command.aggregate || command.count || command.distinct || command.find || command.geoNear) {\n        return true;\n    }\n    return false;\n}\nexports.commandSupportsReadConcern = commandSupportsReadConcern;\n/**\n * Compare objectIds. `null` is always less\n * - `+1 = oid1 is greater than oid2`\n * - `-1 = oid1 is less than oid2`\n * - `+0 = oid1 is equal oid2`\n */\nfunction compareObjectId(oid1, oid2) {\n    if (oid1 == null && oid2 == null) {\n        return 0;\n    }\n    if (oid1 == null) {\n        return -1;\n    }\n    if (oid2 == null) {\n        return 1;\n    }\n    return exports.ByteUtils.compare(oid1.id, oid2.id);\n}\nexports.compareObjectId = compareObjectId;\nfunction parseInteger(value) {\n    if (typeof value === 'number')\n        return Math.trunc(value);\n    const parsedValue = Number.parseInt(String(value), 10);\n    return Number.isNaN(parsedValue) ? null : parsedValue;\n}\nexports.parseInteger = parseInteger;\nfunction parseUnsignedInteger(value) {\n    const parsedInt = parseInteger(value);\n    return parsedInt != null && parsedInt >= 0 ? parsedInt : null;\n}\nexports.parseUnsignedInteger = parseUnsignedInteger;\n/**\n * Determines whether a provided address matches the provided parent domain.\n *\n * If a DNS server were to become compromised SRV records would still need to\n * advertise addresses that are under the same domain as the srvHost.\n *\n * @param address - The address to check against a domain\n * @param srvHost - The domain to check the provided address against\n * @returns Whether the provided address matches the parent domain\n */\nfunction matchesParentDomain(address, srvHost) {\n    // Remove trailing dot if exists on either the resolved address or the srv hostname\n    const normalizedAddress = address.endsWith('.') ? address.slice(0, address.length - 1) : address;\n    const normalizedSrvHost = srvHost.endsWith('.') ? srvHost.slice(0, srvHost.length - 1) : srvHost;\n    const allCharacterBeforeFirstDot = /^.*?\\./;\n    // Remove all characters before first dot\n    // Add leading dot back to string so\n    //   an srvHostDomain = '.trusted.site'\n    //   will not satisfy an addressDomain that endsWith '.fake-trusted.site'\n    const addressDomain = `.${normalizedAddress.replace(allCharacterBeforeFirstDot, '')}`;\n    const srvHostDomain = `.${normalizedSrvHost.replace(allCharacterBeforeFirstDot, '')}`;\n    return addressDomain.endsWith(srvHostDomain);\n}\nexports.matchesParentDomain = matchesParentDomain;\nasync function request(uri, options = {}) {\n    return new Promise((resolve, reject) => {\n        const requestOptions = {\n            method: 'GET',\n            timeout: 10000,\n            json: true,\n            ...url.parse(uri),\n            ...options\n        };\n        const req = http.request(requestOptions, res => {\n            res.setEncoding('utf8');\n            let data = '';\n            res.on('data', d => {\n                data += d;\n            });\n            res.once('end', () => {\n                if (options.json === false) {\n                    resolve(data);\n                    return;\n                }\n                try {\n                    const parsed = JSON.parse(data);\n                    resolve(parsed);\n                }\n                catch {\n                    // TODO(NODE-3483)\n                    reject(new error_1.MongoRuntimeError(`Invalid JSON response: \"${data}\"`));\n                }\n            });\n        });\n        req.once('timeout', () => req.destroy(new error_1.MongoNetworkTimeoutError(`Network request to ${uri} timed out after ${options.timeout} ms`)));\n        req.once('error', error => reject(error));\n        req.end();\n    });\n}\nexports.request = request;\n/**\n * A custom AbortController that aborts after a specified timeout.\n *\n * If `timeout` is undefined or \\<=0, the abort controller never aborts.\n *\n * This class provides two benefits over the built-in AbortSignal.timeout() method.\n * - This class provides a mechanism for cancelling the timeout\n * - This class supports infinite timeouts by interpreting a timeout of 0 as infinite.  This is\n *    consistent with existing timeout options in the Node driver (serverSelectionTimeoutMS, for example).\n * @internal\n */\nclass TimeoutController extends AbortController {\n    constructor(timeout = 0, timeoutId = timeout > 0 ? (0, timers_1.setTimeout)(() => this.abort(), timeout) : null) {\n        super();\n        this.timeoutId = timeoutId;\n    }\n    clear() {\n        if (this.timeoutId != null) {\n            (0, timers_1.clearTimeout)(this.timeoutId);\n        }\n        this.timeoutId = null;\n    }\n}\nexports.TimeoutController = TimeoutController;\n/** @internal */\nexports.DOCUMENT_DB_CHECK = /(\\.docdb\\.amazonaws\\.com$)|(\\.docdb-elastic\\.amazonaws\\.com$)/;\n/** @internal */\nexports.COSMOS_DB_CHECK = /\\.cosmos\\.azure\\.com$/;\n/** @internal */\nexports.DOCUMENT_DB_MSG = 'You appear to be connected to a DocumentDB cluster. For more information regarding feature compatibility and support please visit https://www.mongodb.com/supportability/documentdb';\n/** @internal */\nexports.COSMOS_DB_MSG = 'You appear to be connected to a CosmosDB cluster. For more information regarding feature compatibility and support please visit https://www.mongodb.com/supportability/cosmosdb';\n/** @internal */\nfunction isHostMatch(match, host) {\n    return host && match.test(host.toLowerCase()) ? true : false;\n}\nexports.isHostMatch = isHostMatch;\n//# sourceMappingURL=utils.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/utils.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/write_concern.js":
/*!***************************************************!*\
  !*** ./node_modules/mongodb/lib/write_concern.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.WriteConcern = exports.WRITE_CONCERN_KEYS = void 0;\nexports.WRITE_CONCERN_KEYS = ['w', 'wtimeout', 'j', 'journal', 'fsync'];\n/**\n * A MongoDB WriteConcern, which describes the level of acknowledgement\n * requested from MongoDB for write operations.\n * @public\n *\n * @see https://www.mongodb.com/docs/manual/reference/write-concern/\n */\nclass WriteConcern {\n    /**\n     * Constructs a WriteConcern from the write concern properties.\n     * @param w - request acknowledgment that the write operation has propagated to a specified number of mongod instances or to mongod instances with specified tags.\n     * @param wtimeoutMS - specify a time limit to prevent write operations from blocking indefinitely\n     * @param journal - request acknowledgment that the write operation has been written to the on-disk journal\n     * @param fsync - equivalent to the j option. Is deprecated and will be removed in the next major version.\n     */\n    constructor(w, wtimeoutMS, journal, fsync) {\n        if (w != null) {\n            if (!Number.isNaN(Number(w))) {\n                this.w = Number(w);\n            }\n            else {\n                this.w = w;\n            }\n        }\n        if (wtimeoutMS != null) {\n            this.wtimeoutMS = this.wtimeout = wtimeoutMS;\n        }\n        if (journal != null) {\n            this.journal = this.j = journal;\n        }\n        if (fsync != null) {\n            this.journal = this.j = fsync ? true : false;\n        }\n    }\n    /**\n     * Apply a write concern to a command document. Will modify and return the command.\n     */\n    static apply(command, writeConcern) {\n        const wc = {};\n        // The write concern document sent to the server has w/wtimeout/j fields.\n        if (writeConcern.w != null)\n            wc.w = writeConcern.w;\n        if (writeConcern.wtimeoutMS != null)\n            wc.wtimeout = writeConcern.wtimeoutMS;\n        if (writeConcern.journal != null)\n            wc.j = writeConcern.j;\n        command.writeConcern = wc;\n        return command;\n    }\n    /** Construct a WriteConcern given an options object. */\n    static fromOptions(options, inherit) {\n        if (options == null)\n            return undefined;\n        inherit = inherit ?? {};\n        let opts;\n        if (typeof options === 'string' || typeof options === 'number') {\n            opts = { w: options };\n        }\n        else if (options instanceof WriteConcern) {\n            opts = options;\n        }\n        else {\n            opts = options.writeConcern;\n        }\n        const parentOpts = inherit instanceof WriteConcern ? inherit : inherit.writeConcern;\n        const { w = undefined, wtimeout = undefined, j = undefined, fsync = undefined, journal = undefined, wtimeoutMS = undefined } = {\n            ...parentOpts,\n            ...opts\n        };\n        if (w != null ||\n            wtimeout != null ||\n            wtimeoutMS != null ||\n            j != null ||\n            journal != null ||\n            fsync != null) {\n            return new WriteConcern(w, wtimeout ?? wtimeoutMS, j ?? journal, fsync);\n        }\n        return undefined;\n    }\n}\nexports.WriteConcern = WriteConcern;\n//# sourceMappingURL=write_concern.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/lib/write_concern.js?");

/***/ }),

/***/ "./node_modules/ms/index.js":
/*!**********************************!*\
  !*** ./node_modules/ms/index.js ***!
  \**********************************/
/***/ ((module) => {

eval("/**\n * Helpers.\n */\n\nvar s = 1000;\nvar m = s * 60;\nvar h = m * 60;\nvar d = h * 24;\nvar w = d * 7;\nvar y = d * 365.25;\n\n/**\n * Parse or format the given `val`.\n *\n * Options:\n *\n *  - `long` verbose formatting [false]\n *\n * @param {String|Number} val\n * @param {Object} [options]\n * @throws {Error} throw an error if val is not a non-empty string or a number\n * @return {String|Number}\n * @api public\n */\n\nmodule.exports = function(val, options) {\n  options = options || {};\n  var type = typeof val;\n  if (type === 'string' && val.length > 0) {\n    return parse(val);\n  } else if (type === 'number' && isFinite(val)) {\n    return options.long ? fmtLong(val) : fmtShort(val);\n  }\n  throw new Error(\n    'val is not a non-empty string or a valid number. val=' +\n      JSON.stringify(val)\n  );\n};\n\n/**\n * Parse the given `str` and return milliseconds.\n *\n * @param {String} str\n * @return {Number}\n * @api private\n */\n\nfunction parse(str) {\n  str = String(str);\n  if (str.length > 100) {\n    return;\n  }\n  var match = /^(-?(?:\\d+)?\\.?\\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$/i.exec(\n    str\n  );\n  if (!match) {\n    return;\n  }\n  var n = parseFloat(match[1]);\n  var type = (match[2] || 'ms').toLowerCase();\n  switch (type) {\n    case 'years':\n    case 'year':\n    case 'yrs':\n    case 'yr':\n    case 'y':\n      return n * y;\n    case 'weeks':\n    case 'week':\n    case 'w':\n      return n * w;\n    case 'days':\n    case 'day':\n    case 'd':\n      return n * d;\n    case 'hours':\n    case 'hour':\n    case 'hrs':\n    case 'hr':\n    case 'h':\n      return n * h;\n    case 'minutes':\n    case 'minute':\n    case 'mins':\n    case 'min':\n    case 'm':\n      return n * m;\n    case 'seconds':\n    case 'second':\n    case 'secs':\n    case 'sec':\n    case 's':\n      return n * s;\n    case 'milliseconds':\n    case 'millisecond':\n    case 'msecs':\n    case 'msec':\n    case 'ms':\n      return n;\n    default:\n      return undefined;\n  }\n}\n\n/**\n * Short format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtShort(ms) {\n  var msAbs = Math.abs(ms);\n  if (msAbs >= d) {\n    return Math.round(ms / d) + 'd';\n  }\n  if (msAbs >= h) {\n    return Math.round(ms / h) + 'h';\n  }\n  if (msAbs >= m) {\n    return Math.round(ms / m) + 'm';\n  }\n  if (msAbs >= s) {\n    return Math.round(ms / s) + 's';\n  }\n  return ms + 'ms';\n}\n\n/**\n * Long format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtLong(ms) {\n  var msAbs = Math.abs(ms);\n  if (msAbs >= d) {\n    return plural(ms, msAbs, d, 'day');\n  }\n  if (msAbs >= h) {\n    return plural(ms, msAbs, h, 'hour');\n  }\n  if (msAbs >= m) {\n    return plural(ms, msAbs, m, 'minute');\n  }\n  if (msAbs >= s) {\n    return plural(ms, msAbs, s, 'second');\n  }\n  return ms + ' ms';\n}\n\n/**\n * Pluralization helper.\n */\n\nfunction plural(ms, msAbs, n, name) {\n  var isPlural = msAbs >= n * 1.5;\n  return Math.round(ms / n) + ' ' + name + (isPlural ? 's' : '');\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/ms/index.js?");

/***/ }),

/***/ "./node_modules/punycode/punycode.es6.js":
/*!***********************************************!*\
  !*** ./node_modules/punycode/punycode.es6.js ***!
  \***********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   decode: () => (/* binding */ decode),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__),\n/* harmony export */   encode: () => (/* binding */ encode),\n/* harmony export */   toASCII: () => (/* binding */ toASCII),\n/* harmony export */   toUnicode: () => (/* binding */ toUnicode),\n/* harmony export */   ucs2decode: () => (/* binding */ ucs2decode),\n/* harmony export */   ucs2encode: () => (/* binding */ ucs2encode)\n/* harmony export */ });\n\n\n/** Highest positive signed 32-bit float value */\nconst maxInt = 2147483647; // aka. 0x7FFFFFFF or 2^31-1\n\n/** Bootstring parameters */\nconst base = 36;\nconst tMin = 1;\nconst tMax = 26;\nconst skew = 38;\nconst damp = 700;\nconst initialBias = 72;\nconst initialN = 128; // 0x80\nconst delimiter = '-'; // '\\x2D'\n\n/** Regular expressions */\nconst regexPunycode = /^xn--/;\nconst regexNonASCII = /[^\\0-\\x7F]/; // Note: U+007F DEL is excluded too.\nconst regexSeparators = /[\\x2E\\u3002\\uFF0E\\uFF61]/g; // RFC 3490 separators\n\n/** Error messages */\nconst errors = {\n\t'overflow': 'Overflow: input needs wider integers to process',\n\t'not-basic': 'Illegal input >= 0x80 (not a basic code point)',\n\t'invalid-input': 'Invalid input'\n};\n\n/** Convenience shortcuts */\nconst baseMinusTMin = base - tMin;\nconst floor = Math.floor;\nconst stringFromCharCode = String.fromCharCode;\n\n/*--------------------------------------------------------------------------*/\n\n/**\n * A generic error utility function.\n * @private\n * @param {String} type The error type.\n * @returns {Error} Throws a `RangeError` with the applicable error message.\n */\nfunction error(type) {\n\tthrow new RangeError(errors[type]);\n}\n\n/**\n * A generic `Array#map` utility function.\n * @private\n * @param {Array} array The array to iterate over.\n * @param {Function} callback The function that gets called for every array\n * item.\n * @returns {Array} A new array of values returned by the callback function.\n */\nfunction map(array, callback) {\n\tconst result = [];\n\tlet length = array.length;\n\twhile (length--) {\n\t\tresult[length] = callback(array[length]);\n\t}\n\treturn result;\n}\n\n/**\n * A simple `Array#map`-like wrapper to work with domain name strings or email\n * addresses.\n * @private\n * @param {String} domain The domain name or email address.\n * @param {Function} callback The function that gets called for every\n * character.\n * @returns {String} A new string of characters returned by the callback\n * function.\n */\nfunction mapDomain(domain, callback) {\n\tconst parts = domain.split('@');\n\tlet result = '';\n\tif (parts.length > 1) {\n\t\t// In email addresses, only the domain name should be punycoded. Leave\n\t\t// the local part (i.e. everything up to `@`) intact.\n\t\tresult = parts[0] + '@';\n\t\tdomain = parts[1];\n\t}\n\t// Avoid `split(regex)` for IE8 compatibility. See #17.\n\tdomain = domain.replace(regexSeparators, '\\x2E');\n\tconst labels = domain.split('.');\n\tconst encoded = map(labels, callback).join('.');\n\treturn result + encoded;\n}\n\n/**\n * Creates an array containing the numeric code points of each Unicode\n * character in the string. While JavaScript uses UCS-2 internally,\n * this function will convert a pair of surrogate halves (each of which\n * UCS-2 exposes as separate characters) into a single code point,\n * matching UTF-16.\n * @see `punycode.ucs2.encode`\n * @see <https://mathiasbynens.be/notes/javascript-encoding>\n * @memberOf punycode.ucs2\n * @name decode\n * @param {String} string The Unicode input string (UCS-2).\n * @returns {Array} The new array of code points.\n */\nfunction ucs2decode(string) {\n\tconst output = [];\n\tlet counter = 0;\n\tconst length = string.length;\n\twhile (counter < length) {\n\t\tconst value = string.charCodeAt(counter++);\n\t\tif (value >= 0xD800 && value <= 0xDBFF && counter < length) {\n\t\t\t// It's a high surrogate, and there is a next character.\n\t\t\tconst extra = string.charCodeAt(counter++);\n\t\t\tif ((extra & 0xFC00) == 0xDC00) { // Low surrogate.\n\t\t\t\toutput.push(((value & 0x3FF) << 10) + (extra & 0x3FF) + 0x10000);\n\t\t\t} else {\n\t\t\t\t// It's an unmatched surrogate; only append this code unit, in case the\n\t\t\t\t// next code unit is the high surrogate of a surrogate pair.\n\t\t\t\toutput.push(value);\n\t\t\t\tcounter--;\n\t\t\t}\n\t\t} else {\n\t\t\toutput.push(value);\n\t\t}\n\t}\n\treturn output;\n}\n\n/**\n * Creates a string based on an array of numeric code points.\n * @see `punycode.ucs2.decode`\n * @memberOf punycode.ucs2\n * @name encode\n * @param {Array} codePoints The array of numeric code points.\n * @returns {String} The new Unicode string (UCS-2).\n */\nconst ucs2encode = codePoints => String.fromCodePoint(...codePoints);\n\n/**\n * Converts a basic code point into a digit/integer.\n * @see `digitToBasic()`\n * @private\n * @param {Number} codePoint The basic numeric code point value.\n * @returns {Number} The numeric value of a basic code point (for use in\n * representing integers) in the range `0` to `base - 1`, or `base` if\n * the code point does not represent a value.\n */\nconst basicToDigit = function(codePoint) {\n\tif (codePoint >= 0x30 && codePoint < 0x3A) {\n\t\treturn 26 + (codePoint - 0x30);\n\t}\n\tif (codePoint >= 0x41 && codePoint < 0x5B) {\n\t\treturn codePoint - 0x41;\n\t}\n\tif (codePoint >= 0x61 && codePoint < 0x7B) {\n\t\treturn codePoint - 0x61;\n\t}\n\treturn base;\n};\n\n/**\n * Converts a digit/integer into a basic code point.\n * @see `basicToDigit()`\n * @private\n * @param {Number} digit The numeric value of a basic code point.\n * @returns {Number} The basic code point whose value (when used for\n * representing integers) is `digit`, which needs to be in the range\n * `0` to `base - 1`. If `flag` is non-zero, the uppercase form is\n * used; else, the lowercase form is used. The behavior is undefined\n * if `flag` is non-zero and `digit` has no uppercase form.\n */\nconst digitToBasic = function(digit, flag) {\n\t//  0..25 map to ASCII a..z or A..Z\n\t// 26..35 map to ASCII 0..9\n\treturn digit + 22 + 75 * (digit < 26) - ((flag != 0) << 5);\n};\n\n/**\n * Bias adaptation function as per section 3.4 of RFC 3492.\n * https://tools.ietf.org/html/rfc3492#section-3.4\n * @private\n */\nconst adapt = function(delta, numPoints, firstTime) {\n\tlet k = 0;\n\tdelta = firstTime ? floor(delta / damp) : delta >> 1;\n\tdelta += floor(delta / numPoints);\n\tfor (/* no initialization */; delta > baseMinusTMin * tMax >> 1; k += base) {\n\t\tdelta = floor(delta / baseMinusTMin);\n\t}\n\treturn floor(k + (baseMinusTMin + 1) * delta / (delta + skew));\n};\n\n/**\n * Converts a Punycode string of ASCII-only symbols to a string of Unicode\n * symbols.\n * @memberOf punycode\n * @param {String} input The Punycode string of ASCII-only symbols.\n * @returns {String} The resulting string of Unicode symbols.\n */\nconst decode = function(input) {\n\t// Don't use UCS-2.\n\tconst output = [];\n\tconst inputLength = input.length;\n\tlet i = 0;\n\tlet n = initialN;\n\tlet bias = initialBias;\n\n\t// Handle the basic code points: let `basic` be the number of input code\n\t// points before the last delimiter, or `0` if there is none, then copy\n\t// the first basic code points to the output.\n\n\tlet basic = input.lastIndexOf(delimiter);\n\tif (basic < 0) {\n\t\tbasic = 0;\n\t}\n\n\tfor (let j = 0; j < basic; ++j) {\n\t\t// if it's not a basic code point\n\t\tif (input.charCodeAt(j) >= 0x80) {\n\t\t\terror('not-basic');\n\t\t}\n\t\toutput.push(input.charCodeAt(j));\n\t}\n\n\t// Main decoding loop: start just after the last delimiter if any basic code\n\t// points were copied; start at the beginning otherwise.\n\n\tfor (let index = basic > 0 ? basic + 1 : 0; index < inputLength; /* no final expression */) {\n\n\t\t// `index` is the index of the next character to be consumed.\n\t\t// Decode a generalized variable-length integer into `delta`,\n\t\t// which gets added to `i`. The overflow checking is easier\n\t\t// if we increase `i` as we go, then subtract off its starting\n\t\t// value at the end to obtain `delta`.\n\t\tconst oldi = i;\n\t\tfor (let w = 1, k = base; /* no condition */; k += base) {\n\n\t\t\tif (index >= inputLength) {\n\t\t\t\terror('invalid-input');\n\t\t\t}\n\n\t\t\tconst digit = basicToDigit(input.charCodeAt(index++));\n\n\t\t\tif (digit >= base) {\n\t\t\t\terror('invalid-input');\n\t\t\t}\n\t\t\tif (digit > floor((maxInt - i) / w)) {\n\t\t\t\terror('overflow');\n\t\t\t}\n\n\t\t\ti += digit * w;\n\t\t\tconst t = k <= bias ? tMin : (k >= bias + tMax ? tMax : k - bias);\n\n\t\t\tif (digit < t) {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tconst baseMinusT = base - t;\n\t\t\tif (w > floor(maxInt / baseMinusT)) {\n\t\t\t\terror('overflow');\n\t\t\t}\n\n\t\t\tw *= baseMinusT;\n\n\t\t}\n\n\t\tconst out = output.length + 1;\n\t\tbias = adapt(i - oldi, out, oldi == 0);\n\n\t\t// `i` was supposed to wrap around from `out` to `0`,\n\t\t// incrementing `n` each time, so we'll fix that now:\n\t\tif (floor(i / out) > maxInt - n) {\n\t\t\terror('overflow');\n\t\t}\n\n\t\tn += floor(i / out);\n\t\ti %= out;\n\n\t\t// Insert `n` at position `i` of the output.\n\t\toutput.splice(i++, 0, n);\n\n\t}\n\n\treturn String.fromCodePoint(...output);\n};\n\n/**\n * Converts a string of Unicode symbols (e.g. a domain name label) to a\n * Punycode string of ASCII-only symbols.\n * @memberOf punycode\n * @param {String} input The string of Unicode symbols.\n * @returns {String} The resulting Punycode string of ASCII-only symbols.\n */\nconst encode = function(input) {\n\tconst output = [];\n\n\t// Convert the input in UCS-2 to an array of Unicode code points.\n\tinput = ucs2decode(input);\n\n\t// Cache the length.\n\tconst inputLength = input.length;\n\n\t// Initialize the state.\n\tlet n = initialN;\n\tlet delta = 0;\n\tlet bias = initialBias;\n\n\t// Handle the basic code points.\n\tfor (const currentValue of input) {\n\t\tif (currentValue < 0x80) {\n\t\t\toutput.push(stringFromCharCode(currentValue));\n\t\t}\n\t}\n\n\tconst basicLength = output.length;\n\tlet handledCPCount = basicLength;\n\n\t// `handledCPCount` is the number of code points that have been handled;\n\t// `basicLength` is the number of basic code points.\n\n\t// Finish the basic string with a delimiter unless it's empty.\n\tif (basicLength) {\n\t\toutput.push(delimiter);\n\t}\n\n\t// Main encoding loop:\n\twhile (handledCPCount < inputLength) {\n\n\t\t// All non-basic code points < n have been handled already. Find the next\n\t\t// larger one:\n\t\tlet m = maxInt;\n\t\tfor (const currentValue of input) {\n\t\t\tif (currentValue >= n && currentValue < m) {\n\t\t\t\tm = currentValue;\n\t\t\t}\n\t\t}\n\n\t\t// Increase `delta` enough to advance the decoder's <n,i> state to <m,0>,\n\t\t// but guard against overflow.\n\t\tconst handledCPCountPlusOne = handledCPCount + 1;\n\t\tif (m - n > floor((maxInt - delta) / handledCPCountPlusOne)) {\n\t\t\terror('overflow');\n\t\t}\n\n\t\tdelta += (m - n) * handledCPCountPlusOne;\n\t\tn = m;\n\n\t\tfor (const currentValue of input) {\n\t\t\tif (currentValue < n && ++delta > maxInt) {\n\t\t\t\terror('overflow');\n\t\t\t}\n\t\t\tif (currentValue === n) {\n\t\t\t\t// Represent delta as a generalized variable-length integer.\n\t\t\t\tlet q = delta;\n\t\t\t\tfor (let k = base; /* no condition */; k += base) {\n\t\t\t\t\tconst t = k <= bias ? tMin : (k >= bias + tMax ? tMax : k - bias);\n\t\t\t\t\tif (q < t) {\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tconst qMinusT = q - t;\n\t\t\t\t\tconst baseMinusT = base - t;\n\t\t\t\t\toutput.push(\n\t\t\t\t\t\tstringFromCharCode(digitToBasic(t + qMinusT % baseMinusT, 0))\n\t\t\t\t\t);\n\t\t\t\t\tq = floor(qMinusT / baseMinusT);\n\t\t\t\t}\n\n\t\t\t\toutput.push(stringFromCharCode(digitToBasic(q, 0)));\n\t\t\t\tbias = adapt(delta, handledCPCountPlusOne, handledCPCount === basicLength);\n\t\t\t\tdelta = 0;\n\t\t\t\t++handledCPCount;\n\t\t\t}\n\t\t}\n\n\t\t++delta;\n\t\t++n;\n\n\t}\n\treturn output.join('');\n};\n\n/**\n * Converts a Punycode string representing a domain name or an email address\n * to Unicode. Only the Punycoded parts of the input will be converted, i.e.\n * it doesn't matter if you call it on a string that has already been\n * converted to Unicode.\n * @memberOf punycode\n * @param {String} input The Punycoded domain name or email address to\n * convert to Unicode.\n * @returns {String} The Unicode representation of the given Punycode\n * string.\n */\nconst toUnicode = function(input) {\n\treturn mapDomain(input, function(string) {\n\t\treturn regexPunycode.test(string)\n\t\t\t? decode(string.slice(4).toLowerCase())\n\t\t\t: string;\n\t});\n};\n\n/**\n * Converts a Unicode string representing a domain name or an email address to\n * Punycode. Only the non-ASCII parts of the domain name will be converted,\n * i.e. it doesn't matter if you call it with a domain that's already in\n * ASCII.\n * @memberOf punycode\n * @param {String} input The domain name or email address to convert, as a\n * Unicode string.\n * @returns {String} The Punycode representation of the given domain name or\n * email address.\n */\nconst toASCII = function(input) {\n\treturn mapDomain(input, function(string) {\n\t\treturn regexNonASCII.test(string)\n\t\t\t? 'xn--' + encode(string)\n\t\t\t: string;\n\t});\n};\n\n/*--------------------------------------------------------------------------*/\n\n/** Define the public API */\nconst punycode = {\n\t/**\n\t * A string representing the current Punycode.js version number.\n\t * @memberOf punycode\n\t * @type String\n\t */\n\t'version': '2.1.0',\n\t/**\n\t * An object of methods to convert from JavaScript's internal character\n\t * representation (UCS-2) to Unicode code points, and back.\n\t * @see <https://mathiasbynens.be/notes/javascript-encoding>\n\t * @memberOf punycode\n\t * @type Object\n\t */\n\t'ucs2': {\n\t\t'decode': ucs2decode,\n\t\t'encode': ucs2encode\n\t},\n\t'decode': decode,\n\t'encode': encode,\n\t'toASCII': toASCII,\n\t'toUnicode': toUnicode\n};\n\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (punycode);\n\n\n//# sourceURL=webpack://renderer/./node_modules/punycode/punycode.es6.js?");

/***/ }),

/***/ "./node_modules/react-dom/cjs/react-dom.development.js":
/*!*************************************************************!*\
  !*** ./node_modules/react-dom/cjs/react-dom.development.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("/**\n * @license React\n * react-dom.development.js\n *\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n\n\nif (true) {\n  (function() {\n\n          'use strict';\n\n/* global __REACT_DEVTOOLS_GLOBAL_HOOK__ */\nif (\n  typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ !== 'undefined' &&\n  typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStart ===\n    'function'\n) {\n  __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStart(new Error());\n}\n          var React = __webpack_require__(/*! react */ \"./node_modules/react/index.js\");\nvar Scheduler = __webpack_require__(/*! scheduler */ \"./node_modules/scheduler/index.js\");\n\nvar ReactSharedInternals = React.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED;\n\nvar suppressWarning = false;\nfunction setSuppressWarning(newSuppressWarning) {\n  {\n    suppressWarning = newSuppressWarning;\n  }\n} // In DEV, calls to console.warn and console.error get replaced\n// by calls to these methods by a Babel plugin.\n//\n// In PROD (or in packages without access to React internals),\n// they are left as they are instead.\n\nfunction warn(format) {\n  {\n    if (!suppressWarning) {\n      for (var _len = arguments.length, args = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n        args[_key - 1] = arguments[_key];\n      }\n\n      printWarning('warn', format, args);\n    }\n  }\n}\nfunction error(format) {\n  {\n    if (!suppressWarning) {\n      for (var _len2 = arguments.length, args = new Array(_len2 > 1 ? _len2 - 1 : 0), _key2 = 1; _key2 < _len2; _key2++) {\n        args[_key2 - 1] = arguments[_key2];\n      }\n\n      printWarning('error', format, args);\n    }\n  }\n}\n\nfunction printWarning(level, format, args) {\n  // When changing this logic, you might want to also\n  // update consoleWithStackDev.www.js as well.\n  {\n    var ReactDebugCurrentFrame = ReactSharedInternals.ReactDebugCurrentFrame;\n    var stack = ReactDebugCurrentFrame.getStackAddendum();\n\n    if (stack !== '') {\n      format += '%s';\n      args = args.concat([stack]);\n    } // eslint-disable-next-line react-internal/safe-string-coercion\n\n\n    var argsWithFormat = args.map(function (item) {\n      return String(item);\n    }); // Careful: RN currently depends on this prefix\n\n    argsWithFormat.unshift('Warning: ' + format); // We intentionally don't use spread (or .apply) directly because it\n    // breaks IE9: https://github.com/facebook/react/issues/13610\n    // eslint-disable-next-line react-internal/no-production-logging\n\n    Function.prototype.apply.call(console[level], console, argsWithFormat);\n  }\n}\n\nvar FunctionComponent = 0;\nvar ClassComponent = 1;\nvar IndeterminateComponent = 2; // Before we know whether it is function or class\n\nvar HostRoot = 3; // Root of a host tree. Could be nested inside another node.\n\nvar HostPortal = 4; // A subtree. Could be an entry point to a different renderer.\n\nvar HostComponent = 5;\nvar HostText = 6;\nvar Fragment = 7;\nvar Mode = 8;\nvar ContextConsumer = 9;\nvar ContextProvider = 10;\nvar ForwardRef = 11;\nvar Profiler = 12;\nvar SuspenseComponent = 13;\nvar MemoComponent = 14;\nvar SimpleMemoComponent = 15;\nvar LazyComponent = 16;\nvar IncompleteClassComponent = 17;\nvar DehydratedFragment = 18;\nvar SuspenseListComponent = 19;\nvar ScopeComponent = 21;\nvar OffscreenComponent = 22;\nvar LegacyHiddenComponent = 23;\nvar CacheComponent = 24;\nvar TracingMarkerComponent = 25;\n\n// -----------------------------------------------------------------------------\n\nvar enableClientRenderFallbackOnTextMismatch = true; // TODO: Need to review this code one more time before landing\n// the react-reconciler package.\n\nvar enableNewReconciler = false; // Support legacy Primer support on internal FB www\n\nvar enableLazyContextPropagation = false; // FB-only usage. The new API has different semantics.\n\nvar enableLegacyHidden = false; // Enables unstable_avoidThisFallback feature in Fiber\n\nvar enableSuspenseAvoidThisFallback = false; // Enables unstable_avoidThisFallback feature in Fizz\n// React DOM Chopping Block\n//\n// Similar to main Chopping Block but only flags related to React DOM. These are\n// grouped because we will likely batch all of them into a single major release.\n// -----------------------------------------------------------------------------\n// Disable support for comment nodes as React DOM containers. Already disabled\n// in open source, but www codebase still relies on it. Need to remove.\n\nvar disableCommentsAsDOMContainers = true; // Disable javascript: URL strings in href for XSS protection.\n// and client rendering, mostly to allow JSX attributes to apply to the custom\n// element's object properties instead of only HTML attributes.\n// https://github.com/facebook/react/issues/11347\n\nvar enableCustomElementPropertySupport = false; // Disables children for <textarea> elements\nvar warnAboutStringRefs = false; // -----------------------------------------------------------------------------\n// Debugging and DevTools\n// -----------------------------------------------------------------------------\n// Adds user timing marks for e.g. state updates, suspense, and work loop stuff,\n// for an experimental timeline tool.\n\nvar enableSchedulingProfiler = true; // Helps identify side effects in render-phase lifecycle hooks and setState\n\nvar enableProfilerTimer = true; // Record durations for commit and passive effects phases.\n\nvar enableProfilerCommitHooks = true; // Phase param passed to onRender callback differentiates between an \"update\" and a \"cascading-update\".\n\nvar allNativeEvents = new Set();\n/**\n * Mapping from registration name to event name\n */\n\n\nvar registrationNameDependencies = {};\n/**\n * Mapping from lowercase registration names to the properly cased version,\n * used to warn in the case of missing event handlers. Available\n * only in true.\n * @type {Object}\n */\n\nvar possibleRegistrationNames =  {} ; // Trust the developer to only use possibleRegistrationNames in true\n\nfunction registerTwoPhaseEvent(registrationName, dependencies) {\n  registerDirectEvent(registrationName, dependencies);\n  registerDirectEvent(registrationName + 'Capture', dependencies);\n}\nfunction registerDirectEvent(registrationName, dependencies) {\n  {\n    if (registrationNameDependencies[registrationName]) {\n      error('EventRegistry: More than one plugin attempted to publish the same ' + 'registration name, `%s`.', registrationName);\n    }\n  }\n\n  registrationNameDependencies[registrationName] = dependencies;\n\n  {\n    var lowerCasedName = registrationName.toLowerCase();\n    possibleRegistrationNames[lowerCasedName] = registrationName;\n\n    if (registrationName === 'onDoubleClick') {\n      possibleRegistrationNames.ondblclick = registrationName;\n    }\n  }\n\n  for (var i = 0; i < dependencies.length; i++) {\n    allNativeEvents.add(dependencies[i]);\n  }\n}\n\nvar canUseDOM = !!(typeof window !== 'undefined' && typeof window.document !== 'undefined' && typeof window.document.createElement !== 'undefined');\n\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\n\n/*\n * The `'' + value` pattern (used in in perf-sensitive code) throws for Symbol\n * and Temporal.* types. See https://github.com/facebook/react/pull/22064.\n *\n * The functions in this module will throw an easier-to-understand,\n * easier-to-debug exception with a clear errors message message explaining the\n * problem. (Instead of a confusing exception thrown inside the implementation\n * of the `value` object).\n */\n// $FlowFixMe only called in DEV, so void return is not possible.\nfunction typeName(value) {\n  {\n    // toStringTag is needed for namespaced types like Temporal.Instant\n    var hasToStringTag = typeof Symbol === 'function' && Symbol.toStringTag;\n    var type = hasToStringTag && value[Symbol.toStringTag] || value.constructor.name || 'Object';\n    return type;\n  }\n} // $FlowFixMe only called in DEV, so void return is not possible.\n\n\nfunction willCoercionThrow(value) {\n  {\n    try {\n      testStringCoercion(value);\n      return false;\n    } catch (e) {\n      return true;\n    }\n  }\n}\n\nfunction testStringCoercion(value) {\n  // If you ended up here by following an exception call stack, here's what's\n  // happened: you supplied an object or symbol value to React (as a prop, key,\n  // DOM attribute, CSS property, string ref, etc.) and when React tried to\n  // coerce it to a string using `'' + value`, an exception was thrown.\n  //\n  // The most common types that will cause this exception are `Symbol` instances\n  // and Temporal objects like `Temporal.Instant`. But any object that has a\n  // `valueOf` or `[Symbol.toPrimitive]` method that throws will also cause this\n  // exception. (Library authors do this to prevent users from using built-in\n  // numeric operators like `+` or comparison operators like `>=` because custom\n  // methods are needed to perform accurate arithmetic or comparison.)\n  //\n  // To fix the problem, coerce this object or symbol value to a string before\n  // passing it to React. The most reliable way is usually `String(value)`.\n  //\n  // To find which value is throwing, check the browser or debugger console.\n  // Before this exception was thrown, there should be `console.error` output\n  // that shows the type (Symbol, Temporal.PlainDate, etc.) that caused the\n  // problem and how that type was used: key, atrribute, input value prop, etc.\n  // In most cases, this console output also shows the component and its\n  // ancestor components where the exception happened.\n  //\n  // eslint-disable-next-line react-internal/safe-string-coercion\n  return '' + value;\n}\n\nfunction checkAttributeStringCoercion(value, attributeName) {\n  {\n    if (willCoercionThrow(value)) {\n      error('The provided `%s` attribute is an unsupported type %s.' + ' This value must be coerced to a string before before using it here.', attributeName, typeName(value));\n\n      return testStringCoercion(value); // throw (to help callers find troubleshooting comments)\n    }\n  }\n}\nfunction checkKeyStringCoercion(value) {\n  {\n    if (willCoercionThrow(value)) {\n      error('The provided key is an unsupported type %s.' + ' This value must be coerced to a string before before using it here.', typeName(value));\n\n      return testStringCoercion(value); // throw (to help callers find troubleshooting comments)\n    }\n  }\n}\nfunction checkPropStringCoercion(value, propName) {\n  {\n    if (willCoercionThrow(value)) {\n      error('The provided `%s` prop is an unsupported type %s.' + ' This value must be coerced to a string before before using it here.', propName, typeName(value));\n\n      return testStringCoercion(value); // throw (to help callers find troubleshooting comments)\n    }\n  }\n}\nfunction checkCSSPropertyStringCoercion(value, propName) {\n  {\n    if (willCoercionThrow(value)) {\n      error('The provided `%s` CSS property is an unsupported type %s.' + ' This value must be coerced to a string before before using it here.', propName, typeName(value));\n\n      return testStringCoercion(value); // throw (to help callers find troubleshooting comments)\n    }\n  }\n}\nfunction checkHtmlStringCoercion(value) {\n  {\n    if (willCoercionThrow(value)) {\n      error('The provided HTML markup uses a value of unsupported type %s.' + ' This value must be coerced to a string before before using it here.', typeName(value));\n\n      return testStringCoercion(value); // throw (to help callers find troubleshooting comments)\n    }\n  }\n}\nfunction checkFormFieldValueStringCoercion(value) {\n  {\n    if (willCoercionThrow(value)) {\n      error('Form field values (value, checked, defaultValue, or defaultChecked props)' + ' must be strings, not %s.' + ' This value must be coerced to a string before before using it here.', typeName(value));\n\n      return testStringCoercion(value); // throw (to help callers find troubleshooting comments)\n    }\n  }\n}\n\n// A reserved attribute.\n// It is handled by React separately and shouldn't be written to the DOM.\nvar RESERVED = 0; // A simple string attribute.\n// Attributes that aren't in the filter are presumed to have this type.\n\nvar STRING = 1; // A string attribute that accepts booleans in React. In HTML, these are called\n// \"enumerated\" attributes with \"true\" and \"false\" as possible values.\n// When true, it should be set to a \"true\" string.\n// When false, it should be set to a \"false\" string.\n\nvar BOOLEANISH_STRING = 2; // A real boolean attribute.\n// When true, it should be present (set either to an empty string or its name).\n// When false, it should be omitted.\n\nvar BOOLEAN = 3; // An attribute that can be used as a flag as well as with a value.\n// When true, it should be present (set either to an empty string or its name).\n// When false, it should be omitted.\n// For any other value, should be present with that value.\n\nvar OVERLOADED_BOOLEAN = 4; // An attribute that must be numeric or parse as a numeric.\n// When falsy, it should be removed.\n\nvar NUMERIC = 5; // An attribute that must be positive numeric or parse as a positive numeric.\n// When falsy, it should be removed.\n\nvar POSITIVE_NUMERIC = 6;\n\n/* eslint-disable max-len */\nvar ATTRIBUTE_NAME_START_CHAR = \":A-Z_a-z\\\\u00C0-\\\\u00D6\\\\u00D8-\\\\u00F6\\\\u00F8-\\\\u02FF\\\\u0370-\\\\u037D\\\\u037F-\\\\u1FFF\\\\u200C-\\\\u200D\\\\u2070-\\\\u218F\\\\u2C00-\\\\u2FEF\\\\u3001-\\\\uD7FF\\\\uF900-\\\\uFDCF\\\\uFDF0-\\\\uFFFD\";\n/* eslint-enable max-len */\n\nvar ATTRIBUTE_NAME_CHAR = ATTRIBUTE_NAME_START_CHAR + \"\\\\-.0-9\\\\u00B7\\\\u0300-\\\\u036F\\\\u203F-\\\\u2040\";\nvar VALID_ATTRIBUTE_NAME_REGEX = new RegExp('^[' + ATTRIBUTE_NAME_START_CHAR + '][' + ATTRIBUTE_NAME_CHAR + ']*$');\nvar illegalAttributeNameCache = {};\nvar validatedAttributeNameCache = {};\nfunction isAttributeNameSafe(attributeName) {\n  if (hasOwnProperty.call(validatedAttributeNameCache, attributeName)) {\n    return true;\n  }\n\n  if (hasOwnProperty.call(illegalAttributeNameCache, attributeName)) {\n    return false;\n  }\n\n  if (VALID_ATTRIBUTE_NAME_REGEX.test(attributeName)) {\n    validatedAttributeNameCache[attributeName] = true;\n    return true;\n  }\n\n  illegalAttributeNameCache[attributeName] = true;\n\n  {\n    error('Invalid attribute name: `%s`', attributeName);\n  }\n\n  return false;\n}\nfunction shouldIgnoreAttribute(name, propertyInfo, isCustomComponentTag) {\n  if (propertyInfo !== null) {\n    return propertyInfo.type === RESERVED;\n  }\n\n  if (isCustomComponentTag) {\n    return false;\n  }\n\n  if (name.length > 2 && (name[0] === 'o' || name[0] === 'O') && (name[1] === 'n' || name[1] === 'N')) {\n    return true;\n  }\n\n  return false;\n}\nfunction shouldRemoveAttributeWithWarning(name, value, propertyInfo, isCustomComponentTag) {\n  if (propertyInfo !== null && propertyInfo.type === RESERVED) {\n    return false;\n  }\n\n  switch (typeof value) {\n    case 'function': // $FlowIssue symbol is perfectly valid here\n\n    case 'symbol':\n      // eslint-disable-line\n      return true;\n\n    case 'boolean':\n      {\n        if (isCustomComponentTag) {\n          return false;\n        }\n\n        if (propertyInfo !== null) {\n          return !propertyInfo.acceptsBooleans;\n        } else {\n          var prefix = name.toLowerCase().slice(0, 5);\n          return prefix !== 'data-' && prefix !== 'aria-';\n        }\n      }\n\n    default:\n      return false;\n  }\n}\nfunction shouldRemoveAttribute(name, value, propertyInfo, isCustomComponentTag) {\n  if (value === null || typeof value === 'undefined') {\n    return true;\n  }\n\n  if (shouldRemoveAttributeWithWarning(name, value, propertyInfo, isCustomComponentTag)) {\n    return true;\n  }\n\n  if (isCustomComponentTag) {\n\n    return false;\n  }\n\n  if (propertyInfo !== null) {\n\n    switch (propertyInfo.type) {\n      case BOOLEAN:\n        return !value;\n\n      case OVERLOADED_BOOLEAN:\n        return value === false;\n\n      case NUMERIC:\n        return isNaN(value);\n\n      case POSITIVE_NUMERIC:\n        return isNaN(value) || value < 1;\n    }\n  }\n\n  return false;\n}\nfunction getPropertyInfo(name) {\n  return properties.hasOwnProperty(name) ? properties[name] : null;\n}\n\nfunction PropertyInfoRecord(name, type, mustUseProperty, attributeName, attributeNamespace, sanitizeURL, removeEmptyString) {\n  this.acceptsBooleans = type === BOOLEANISH_STRING || type === BOOLEAN || type === OVERLOADED_BOOLEAN;\n  this.attributeName = attributeName;\n  this.attributeNamespace = attributeNamespace;\n  this.mustUseProperty = mustUseProperty;\n  this.propertyName = name;\n  this.type = type;\n  this.sanitizeURL = sanitizeURL;\n  this.removeEmptyString = removeEmptyString;\n} // When adding attributes to this list, be sure to also add them to\n// the `possibleStandardNames` module to ensure casing and incorrect\n// name warnings.\n\n\nvar properties = {}; // These props are reserved by React. They shouldn't be written to the DOM.\n\nvar reservedProps = ['children', 'dangerouslySetInnerHTML', // TODO: This prevents the assignment of defaultValue to regular\n// elements (not just inputs). Now that ReactDOMInput assigns to the\n// defaultValue property -- do we need this?\n'defaultValue', 'defaultChecked', 'innerHTML', 'suppressContentEditableWarning', 'suppressHydrationWarning', 'style'];\n\nreservedProps.forEach(function (name) {\n  properties[name] = new PropertyInfoRecord(name, RESERVED, false, // mustUseProperty\n  name, // attributeName\n  null, // attributeNamespace\n  false, // sanitizeURL\n  false);\n}); // A few React string attributes have a different name.\n// This is a mapping from React prop names to the attribute names.\n\n[['acceptCharset', 'accept-charset'], ['className', 'class'], ['htmlFor', 'for'], ['httpEquiv', 'http-equiv']].forEach(function (_ref) {\n  var name = _ref[0],\n      attributeName = _ref[1];\n  properties[name] = new PropertyInfoRecord(name, STRING, false, // mustUseProperty\n  attributeName, // attributeName\n  null, // attributeNamespace\n  false, // sanitizeURL\n  false);\n}); // These are \"enumerated\" HTML attributes that accept \"true\" and \"false\".\n// In React, we let users pass `true` and `false` even though technically\n// these aren't boolean attributes (they are coerced to strings).\n\n['contentEditable', 'draggable', 'spellCheck', 'value'].forEach(function (name) {\n  properties[name] = new PropertyInfoRecord(name, BOOLEANISH_STRING, false, // mustUseProperty\n  name.toLowerCase(), // attributeName\n  null, // attributeNamespace\n  false, // sanitizeURL\n  false);\n}); // These are \"enumerated\" SVG attributes that accept \"true\" and \"false\".\n// In React, we let users pass `true` and `false` even though technically\n// these aren't boolean attributes (they are coerced to strings).\n// Since these are SVG attributes, their attribute names are case-sensitive.\n\n['autoReverse', 'externalResourcesRequired', 'focusable', 'preserveAlpha'].forEach(function (name) {\n  properties[name] = new PropertyInfoRecord(name, BOOLEANISH_STRING, false, // mustUseProperty\n  name, // attributeName\n  null, // attributeNamespace\n  false, // sanitizeURL\n  false);\n}); // These are HTML boolean attributes.\n\n['allowFullScreen', 'async', // Note: there is a special case that prevents it from being written to the DOM\n// on the client side because the browsers are inconsistent. Instead we call focus().\n'autoFocus', 'autoPlay', 'controls', 'default', 'defer', 'disabled', 'disablePictureInPicture', 'disableRemotePlayback', 'formNoValidate', 'hidden', 'loop', 'noModule', 'noValidate', 'open', 'playsInline', 'readOnly', 'required', 'reversed', 'scoped', 'seamless', // Microdata\n'itemScope'].forEach(function (name) {\n  properties[name] = new PropertyInfoRecord(name, BOOLEAN, false, // mustUseProperty\n  name.toLowerCase(), // attributeName\n  null, // attributeNamespace\n  false, // sanitizeURL\n  false);\n}); // These are the few React props that we set as DOM properties\n// rather than attributes. These are all booleans.\n\n['checked', // Note: `option.selected` is not updated if `select.multiple` is\n// disabled with `removeAttribute`. We have special logic for handling this.\n'multiple', 'muted', 'selected' // NOTE: if you add a camelCased prop to this list,\n// you'll need to set attributeName to name.toLowerCase()\n// instead in the assignment below.\n].forEach(function (name) {\n  properties[name] = new PropertyInfoRecord(name, BOOLEAN, true, // mustUseProperty\n  name, // attributeName\n  null, // attributeNamespace\n  false, // sanitizeURL\n  false);\n}); // These are HTML attributes that are \"overloaded booleans\": they behave like\n// booleans, but can also accept a string value.\n\n['capture', 'download' // NOTE: if you add a camelCased prop to this list,\n// you'll need to set attributeName to name.toLowerCase()\n// instead in the assignment below.\n].forEach(function (name) {\n  properties[name] = new PropertyInfoRecord(name, OVERLOADED_BOOLEAN, false, // mustUseProperty\n  name, // attributeName\n  null, // attributeNamespace\n  false, // sanitizeURL\n  false);\n}); // These are HTML attributes that must be positive numbers.\n\n['cols', 'rows', 'size', 'span' // NOTE: if you add a camelCased prop to this list,\n// you'll need to set attributeName to name.toLowerCase()\n// instead in the assignment below.\n].forEach(function (name) {\n  properties[name] = new PropertyInfoRecord(name, POSITIVE_NUMERIC, false, // mustUseProperty\n  name, // attributeName\n  null, // attributeNamespace\n  false, // sanitizeURL\n  false);\n}); // These are HTML attributes that must be numbers.\n\n['rowSpan', 'start'].forEach(function (name) {\n  properties[name] = new PropertyInfoRecord(name, NUMERIC, false, // mustUseProperty\n  name.toLowerCase(), // attributeName\n  null, // attributeNamespace\n  false, // sanitizeURL\n  false);\n});\nvar CAMELIZE = /[\\-\\:]([a-z])/g;\n\nvar capitalize = function (token) {\n  return token[1].toUpperCase();\n}; // This is a list of all SVG attributes that need special casing, namespacing,\n// or boolean value assignment. Regular attributes that just accept strings\n// and have the same names are omitted, just like in the HTML attribute filter.\n// Some of these attributes can be hard to find. This list was created by\n// scraping the MDN documentation.\n\n\n['accent-height', 'alignment-baseline', 'arabic-form', 'baseline-shift', 'cap-height', 'clip-path', 'clip-rule', 'color-interpolation', 'color-interpolation-filters', 'color-profile', 'color-rendering', 'dominant-baseline', 'enable-background', 'fill-opacity', 'fill-rule', 'flood-color', 'flood-opacity', 'font-family', 'font-size', 'font-size-adjust', 'font-stretch', 'font-style', 'font-variant', 'font-weight', 'glyph-name', 'glyph-orientation-horizontal', 'glyph-orientation-vertical', 'horiz-adv-x', 'horiz-origin-x', 'image-rendering', 'letter-spacing', 'lighting-color', 'marker-end', 'marker-mid', 'marker-start', 'overline-position', 'overline-thickness', 'paint-order', 'panose-1', 'pointer-events', 'rendering-intent', 'shape-rendering', 'stop-color', 'stop-opacity', 'strikethrough-position', 'strikethrough-thickness', 'stroke-dasharray', 'stroke-dashoffset', 'stroke-linecap', 'stroke-linejoin', 'stroke-miterlimit', 'stroke-opacity', 'stroke-width', 'text-anchor', 'text-decoration', 'text-rendering', 'underline-position', 'underline-thickness', 'unicode-bidi', 'unicode-range', 'units-per-em', 'v-alphabetic', 'v-hanging', 'v-ideographic', 'v-mathematical', 'vector-effect', 'vert-adv-y', 'vert-origin-x', 'vert-origin-y', 'word-spacing', 'writing-mode', 'xmlns:xlink', 'x-height' // NOTE: if you add a camelCased prop to this list,\n// you'll need to set attributeName to name.toLowerCase()\n// instead in the assignment below.\n].forEach(function (attributeName) {\n  var name = attributeName.replace(CAMELIZE, capitalize);\n  properties[name] = new PropertyInfoRecord(name, STRING, false, // mustUseProperty\n  attributeName, null, // attributeNamespace\n  false, // sanitizeURL\n  false);\n}); // String SVG attributes with the xlink namespace.\n\n['xlink:actuate', 'xlink:arcrole', 'xlink:role', 'xlink:show', 'xlink:title', 'xlink:type' // NOTE: if you add a camelCased prop to this list,\n// you'll need to set attributeName to name.toLowerCase()\n// instead in the assignment below.\n].forEach(function (attributeName) {\n  var name = attributeName.replace(CAMELIZE, capitalize);\n  properties[name] = new PropertyInfoRecord(name, STRING, false, // mustUseProperty\n  attributeName, 'http://www.w3.org/1999/xlink', false, // sanitizeURL\n  false);\n}); // String SVG attributes with the xml namespace.\n\n['xml:base', 'xml:lang', 'xml:space' // NOTE: if you add a camelCased prop to this list,\n// you'll need to set attributeName to name.toLowerCase()\n// instead in the assignment below.\n].forEach(function (attributeName) {\n  var name = attributeName.replace(CAMELIZE, capitalize);\n  properties[name] = new PropertyInfoRecord(name, STRING, false, // mustUseProperty\n  attributeName, 'http://www.w3.org/XML/1998/namespace', false, // sanitizeURL\n  false);\n}); // These attribute exists both in HTML and SVG.\n// The attribute name is case-sensitive in SVG so we can't just use\n// the React name like we do for attributes that exist only in HTML.\n\n['tabIndex', 'crossOrigin'].forEach(function (attributeName) {\n  properties[attributeName] = new PropertyInfoRecord(attributeName, STRING, false, // mustUseProperty\n  attributeName.toLowerCase(), // attributeName\n  null, // attributeNamespace\n  false, // sanitizeURL\n  false);\n}); // These attributes accept URLs. These must not allow javascript: URLS.\n// These will also need to accept Trusted Types object in the future.\n\nvar xlinkHref = 'xlinkHref';\nproperties[xlinkHref] = new PropertyInfoRecord('xlinkHref', STRING, false, // mustUseProperty\n'xlink:href', 'http://www.w3.org/1999/xlink', true, // sanitizeURL\nfalse);\n['src', 'href', 'action', 'formAction'].forEach(function (attributeName) {\n  properties[attributeName] = new PropertyInfoRecord(attributeName, STRING, false, // mustUseProperty\n  attributeName.toLowerCase(), // attributeName\n  null, // attributeNamespace\n  true, // sanitizeURL\n  true);\n});\n\n// and any newline or tab are filtered out as if they're not part of the URL.\n// https://url.spec.whatwg.org/#url-parsing\n// Tab or newline are defined as \\r\\n\\t:\n// https://infra.spec.whatwg.org/#ascii-tab-or-newline\n// A C0 control is a code point in the range \\u0000 NULL to \\u001F\n// INFORMATION SEPARATOR ONE, inclusive:\n// https://infra.spec.whatwg.org/#c0-control-or-space\n\n/* eslint-disable max-len */\n\nvar isJavaScriptProtocol = /^[\\u0000-\\u001F ]*j[\\r\\n\\t]*a[\\r\\n\\t]*v[\\r\\n\\t]*a[\\r\\n\\t]*s[\\r\\n\\t]*c[\\r\\n\\t]*r[\\r\\n\\t]*i[\\r\\n\\t]*p[\\r\\n\\t]*t[\\r\\n\\t]*\\:/i;\nvar didWarn = false;\n\nfunction sanitizeURL(url) {\n  {\n    if (!didWarn && isJavaScriptProtocol.test(url)) {\n      didWarn = true;\n\n      error('A future version of React will block javascript: URLs as a security precaution. ' + 'Use event handlers instead if you can. If you need to generate unsafe HTML try ' + 'using dangerouslySetInnerHTML instead. React was passed %s.', JSON.stringify(url));\n    }\n  }\n}\n\n/**\n * Get the value for a property on a node. Only used in DEV for SSR validation.\n * The \"expected\" argument is used as a hint of what the expected value is.\n * Some properties have multiple equivalent values.\n */\nfunction getValueForProperty(node, name, expected, propertyInfo) {\n  {\n    if (propertyInfo.mustUseProperty) {\n      var propertyName = propertyInfo.propertyName;\n      return node[propertyName];\n    } else {\n      // This check protects multiple uses of `expected`, which is why the\n      // react-internal/safe-string-coercion rule is disabled in several spots\n      // below.\n      {\n        checkAttributeStringCoercion(expected, name);\n      }\n\n      if ( propertyInfo.sanitizeURL) {\n        // If we haven't fully disabled javascript: URLs, and if\n        // the hydration is successful of a javascript: URL, we\n        // still want to warn on the client.\n        // eslint-disable-next-line react-internal/safe-string-coercion\n        sanitizeURL('' + expected);\n      }\n\n      var attributeName = propertyInfo.attributeName;\n      var stringValue = null;\n\n      if (propertyInfo.type === OVERLOADED_BOOLEAN) {\n        if (node.hasAttribute(attributeName)) {\n          var value = node.getAttribute(attributeName);\n\n          if (value === '') {\n            return true;\n          }\n\n          if (shouldRemoveAttribute(name, expected, propertyInfo, false)) {\n            return value;\n          } // eslint-disable-next-line react-internal/safe-string-coercion\n\n\n          if (value === '' + expected) {\n            return expected;\n          }\n\n          return value;\n        }\n      } else if (node.hasAttribute(attributeName)) {\n        if (shouldRemoveAttribute(name, expected, propertyInfo, false)) {\n          // We had an attribute but shouldn't have had one, so read it\n          // for the error message.\n          return node.getAttribute(attributeName);\n        }\n\n        if (propertyInfo.type === BOOLEAN) {\n          // If this was a boolean, it doesn't matter what the value is\n          // the fact that we have it is the same as the expected.\n          return expected;\n        } // Even if this property uses a namespace we use getAttribute\n        // because we assume its namespaced name is the same as our config.\n        // To use getAttributeNS we need the local name which we don't have\n        // in our config atm.\n\n\n        stringValue = node.getAttribute(attributeName);\n      }\n\n      if (shouldRemoveAttribute(name, expected, propertyInfo, false)) {\n        return stringValue === null ? expected : stringValue; // eslint-disable-next-line react-internal/safe-string-coercion\n      } else if (stringValue === '' + expected) {\n        return expected;\n      } else {\n        return stringValue;\n      }\n    }\n  }\n}\n/**\n * Get the value for a attribute on a node. Only used in DEV for SSR validation.\n * The third argument is used as a hint of what the expected value is. Some\n * attributes have multiple equivalent values.\n */\n\nfunction getValueForAttribute(node, name, expected, isCustomComponentTag) {\n  {\n    if (!isAttributeNameSafe(name)) {\n      return;\n    }\n\n    if (!node.hasAttribute(name)) {\n      return expected === undefined ? undefined : null;\n    }\n\n    var value = node.getAttribute(name);\n\n    {\n      checkAttributeStringCoercion(expected, name);\n    }\n\n    if (value === '' + expected) {\n      return expected;\n    }\n\n    return value;\n  }\n}\n/**\n * Sets the value for a property on a node.\n *\n * @param {DOMElement} node\n * @param {string} name\n * @param {*} value\n */\n\nfunction setValueForProperty(node, name, value, isCustomComponentTag) {\n  var propertyInfo = getPropertyInfo(name);\n\n  if (shouldIgnoreAttribute(name, propertyInfo, isCustomComponentTag)) {\n    return;\n  }\n\n  if (shouldRemoveAttribute(name, value, propertyInfo, isCustomComponentTag)) {\n    value = null;\n  }\n\n\n  if (isCustomComponentTag || propertyInfo === null) {\n    if (isAttributeNameSafe(name)) {\n      var _attributeName = name;\n\n      if (value === null) {\n        node.removeAttribute(_attributeName);\n      } else {\n        {\n          checkAttributeStringCoercion(value, name);\n        }\n\n        node.setAttribute(_attributeName,  '' + value);\n      }\n    }\n\n    return;\n  }\n\n  var mustUseProperty = propertyInfo.mustUseProperty;\n\n  if (mustUseProperty) {\n    var propertyName = propertyInfo.propertyName;\n\n    if (value === null) {\n      var type = propertyInfo.type;\n      node[propertyName] = type === BOOLEAN ? false : '';\n    } else {\n      // Contrary to `setAttribute`, object properties are properly\n      // `toString`ed by IE8/9.\n      node[propertyName] = value;\n    }\n\n    return;\n  } // The rest are treated as attributes with special cases.\n\n\n  var attributeName = propertyInfo.attributeName,\n      attributeNamespace = propertyInfo.attributeNamespace;\n\n  if (value === null) {\n    node.removeAttribute(attributeName);\n  } else {\n    var _type = propertyInfo.type;\n    var attributeValue;\n\n    if (_type === BOOLEAN || _type === OVERLOADED_BOOLEAN && value === true) {\n      // If attribute type is boolean, we know for sure it won't be an execution sink\n      // and we won't require Trusted Type here.\n      attributeValue = '';\n    } else {\n      // `setAttribute` with objects becomes only `[object]` in IE8/9,\n      // ('' + value) makes it output the correct toString()-value.\n      {\n        {\n          checkAttributeStringCoercion(value, attributeName);\n        }\n\n        attributeValue = '' + value;\n      }\n\n      if (propertyInfo.sanitizeURL) {\n        sanitizeURL(attributeValue.toString());\n      }\n    }\n\n    if (attributeNamespace) {\n      node.setAttributeNS(attributeNamespace, attributeName, attributeValue);\n    } else {\n      node.setAttribute(attributeName, attributeValue);\n    }\n  }\n}\n\n// ATTENTION\n// When adding new symbols to this file,\n// Please consider also adding to 'react-devtools-shared/src/backend/ReactSymbols'\n// The Symbol used to tag the ReactElement-like types.\nvar REACT_ELEMENT_TYPE = Symbol.for('react.element');\nvar REACT_PORTAL_TYPE = Symbol.for('react.portal');\nvar REACT_FRAGMENT_TYPE = Symbol.for('react.fragment');\nvar REACT_STRICT_MODE_TYPE = Symbol.for('react.strict_mode');\nvar REACT_PROFILER_TYPE = Symbol.for('react.profiler');\nvar REACT_PROVIDER_TYPE = Symbol.for('react.provider');\nvar REACT_CONTEXT_TYPE = Symbol.for('react.context');\nvar REACT_FORWARD_REF_TYPE = Symbol.for('react.forward_ref');\nvar REACT_SUSPENSE_TYPE = Symbol.for('react.suspense');\nvar REACT_SUSPENSE_LIST_TYPE = Symbol.for('react.suspense_list');\nvar REACT_MEMO_TYPE = Symbol.for('react.memo');\nvar REACT_LAZY_TYPE = Symbol.for('react.lazy');\nvar REACT_SCOPE_TYPE = Symbol.for('react.scope');\nvar REACT_DEBUG_TRACING_MODE_TYPE = Symbol.for('react.debug_trace_mode');\nvar REACT_OFFSCREEN_TYPE = Symbol.for('react.offscreen');\nvar REACT_LEGACY_HIDDEN_TYPE = Symbol.for('react.legacy_hidden');\nvar REACT_CACHE_TYPE = Symbol.for('react.cache');\nvar REACT_TRACING_MARKER_TYPE = Symbol.for('react.tracing_marker');\nvar MAYBE_ITERATOR_SYMBOL = Symbol.iterator;\nvar FAUX_ITERATOR_SYMBOL = '@@iterator';\nfunction getIteratorFn(maybeIterable) {\n  if (maybeIterable === null || typeof maybeIterable !== 'object') {\n    return null;\n  }\n\n  var maybeIterator = MAYBE_ITERATOR_SYMBOL && maybeIterable[MAYBE_ITERATOR_SYMBOL] || maybeIterable[FAUX_ITERATOR_SYMBOL];\n\n  if (typeof maybeIterator === 'function') {\n    return maybeIterator;\n  }\n\n  return null;\n}\n\nvar assign = Object.assign;\n\n// Helpers to patch console.logs to avoid logging during side-effect free\n// replaying on render function. This currently only patches the object\n// lazily which won't cover if the log function was extracted eagerly.\n// We could also eagerly patch the method.\nvar disabledDepth = 0;\nvar prevLog;\nvar prevInfo;\nvar prevWarn;\nvar prevError;\nvar prevGroup;\nvar prevGroupCollapsed;\nvar prevGroupEnd;\n\nfunction disabledLog() {}\n\ndisabledLog.__reactDisabledLog = true;\nfunction disableLogs() {\n  {\n    if (disabledDepth === 0) {\n      /* eslint-disable react-internal/no-production-logging */\n      prevLog = console.log;\n      prevInfo = console.info;\n      prevWarn = console.warn;\n      prevError = console.error;\n      prevGroup = console.group;\n      prevGroupCollapsed = console.groupCollapsed;\n      prevGroupEnd = console.groupEnd; // https://github.com/facebook/react/issues/19099\n\n      var props = {\n        configurable: true,\n        enumerable: true,\n        value: disabledLog,\n        writable: true\n      }; // $FlowFixMe Flow thinks console is immutable.\n\n      Object.defineProperties(console, {\n        info: props,\n        log: props,\n        warn: props,\n        error: props,\n        group: props,\n        groupCollapsed: props,\n        groupEnd: props\n      });\n      /* eslint-enable react-internal/no-production-logging */\n    }\n\n    disabledDepth++;\n  }\n}\nfunction reenableLogs() {\n  {\n    disabledDepth--;\n\n    if (disabledDepth === 0) {\n      /* eslint-disable react-internal/no-production-logging */\n      var props = {\n        configurable: true,\n        enumerable: true,\n        writable: true\n      }; // $FlowFixMe Flow thinks console is immutable.\n\n      Object.defineProperties(console, {\n        log: assign({}, props, {\n          value: prevLog\n        }),\n        info: assign({}, props, {\n          value: prevInfo\n        }),\n        warn: assign({}, props, {\n          value: prevWarn\n        }),\n        error: assign({}, props, {\n          value: prevError\n        }),\n        group: assign({}, props, {\n          value: prevGroup\n        }),\n        groupCollapsed: assign({}, props, {\n          value: prevGroupCollapsed\n        }),\n        groupEnd: assign({}, props, {\n          value: prevGroupEnd\n        })\n      });\n      /* eslint-enable react-internal/no-production-logging */\n    }\n\n    if (disabledDepth < 0) {\n      error('disabledDepth fell below zero. ' + 'This is a bug in React. Please file an issue.');\n    }\n  }\n}\n\nvar ReactCurrentDispatcher = ReactSharedInternals.ReactCurrentDispatcher;\nvar prefix;\nfunction describeBuiltInComponentFrame(name, source, ownerFn) {\n  {\n    if (prefix === undefined) {\n      // Extract the VM specific prefix used by each line.\n      try {\n        throw Error();\n      } catch (x) {\n        var match = x.stack.trim().match(/\\n( *(at )?)/);\n        prefix = match && match[1] || '';\n      }\n    } // We use the prefix to ensure our stacks line up with native stack frames.\n\n\n    return '\\n' + prefix + name;\n  }\n}\nvar reentry = false;\nvar componentFrameCache;\n\n{\n  var PossiblyWeakMap = typeof WeakMap === 'function' ? WeakMap : Map;\n  componentFrameCache = new PossiblyWeakMap();\n}\n\nfunction describeNativeComponentFrame(fn, construct) {\n  // If something asked for a stack inside a fake render, it should get ignored.\n  if ( !fn || reentry) {\n    return '';\n  }\n\n  {\n    var frame = componentFrameCache.get(fn);\n\n    if (frame !== undefined) {\n      return frame;\n    }\n  }\n\n  var control;\n  reentry = true;\n  var previousPrepareStackTrace = Error.prepareStackTrace; // $FlowFixMe It does accept undefined.\n\n  Error.prepareStackTrace = undefined;\n  var previousDispatcher;\n\n  {\n    previousDispatcher = ReactCurrentDispatcher.current; // Set the dispatcher in DEV because this might be call in the render function\n    // for warnings.\n\n    ReactCurrentDispatcher.current = null;\n    disableLogs();\n  }\n\n  try {\n    // This should throw.\n    if (construct) {\n      // Something should be setting the props in the constructor.\n      var Fake = function () {\n        throw Error();\n      }; // $FlowFixMe\n\n\n      Object.defineProperty(Fake.prototype, 'props', {\n        set: function () {\n          // We use a throwing setter instead of frozen or non-writable props\n          // because that won't throw in a non-strict mode function.\n          throw Error();\n        }\n      });\n\n      if (typeof Reflect === 'object' && Reflect.construct) {\n        // We construct a different control for this case to include any extra\n        // frames added by the construct call.\n        try {\n          Reflect.construct(Fake, []);\n        } catch (x) {\n          control = x;\n        }\n\n        Reflect.construct(fn, [], Fake);\n      } else {\n        try {\n          Fake.call();\n        } catch (x) {\n          control = x;\n        }\n\n        fn.call(Fake.prototype);\n      }\n    } else {\n      try {\n        throw Error();\n      } catch (x) {\n        control = x;\n      }\n\n      fn();\n    }\n  } catch (sample) {\n    // This is inlined manually because closure doesn't do it for us.\n    if (sample && control && typeof sample.stack === 'string') {\n      // This extracts the first frame from the sample that isn't also in the control.\n      // Skipping one frame that we assume is the frame that calls the two.\n      var sampleLines = sample.stack.split('\\n');\n      var controlLines = control.stack.split('\\n');\n      var s = sampleLines.length - 1;\n      var c = controlLines.length - 1;\n\n      while (s >= 1 && c >= 0 && sampleLines[s] !== controlLines[c]) {\n        // We expect at least one stack frame to be shared.\n        // Typically this will be the root most one. However, stack frames may be\n        // cut off due to maximum stack limits. In this case, one maybe cut off\n        // earlier than the other. We assume that the sample is longer or the same\n        // and there for cut off earlier. So we should find the root most frame in\n        // the sample somewhere in the control.\n        c--;\n      }\n\n      for (; s >= 1 && c >= 0; s--, c--) {\n        // Next we find the first one that isn't the same which should be the\n        // frame that called our sample function and the control.\n        if (sampleLines[s] !== controlLines[c]) {\n          // In V8, the first line is describing the message but other VMs don't.\n          // If we're about to return the first line, and the control is also on the same\n          // line, that's a pretty good indicator that our sample threw at same line as\n          // the control. I.e. before we entered the sample frame. So we ignore this result.\n          // This can happen if you passed a class to function component, or non-function.\n          if (s !== 1 || c !== 1) {\n            do {\n              s--;\n              c--; // We may still have similar intermediate frames from the construct call.\n              // The next one that isn't the same should be our match though.\n\n              if (c < 0 || sampleLines[s] !== controlLines[c]) {\n                // V8 adds a \"new\" prefix for native classes. Let's remove it to make it prettier.\n                var _frame = '\\n' + sampleLines[s].replace(' at new ', ' at '); // If our component frame is labeled \"<anonymous>\"\n                // but we have a user-provided \"displayName\"\n                // splice it in to make the stack more readable.\n\n\n                if (fn.displayName && _frame.includes('<anonymous>')) {\n                  _frame = _frame.replace('<anonymous>', fn.displayName);\n                }\n\n                {\n                  if (typeof fn === 'function') {\n                    componentFrameCache.set(fn, _frame);\n                  }\n                } // Return the line we found.\n\n\n                return _frame;\n              }\n            } while (s >= 1 && c >= 0);\n          }\n\n          break;\n        }\n      }\n    }\n  } finally {\n    reentry = false;\n\n    {\n      ReactCurrentDispatcher.current = previousDispatcher;\n      reenableLogs();\n    }\n\n    Error.prepareStackTrace = previousPrepareStackTrace;\n  } // Fallback to just using the name if we couldn't make it throw.\n\n\n  var name = fn ? fn.displayName || fn.name : '';\n  var syntheticFrame = name ? describeBuiltInComponentFrame(name) : '';\n\n  {\n    if (typeof fn === 'function') {\n      componentFrameCache.set(fn, syntheticFrame);\n    }\n  }\n\n  return syntheticFrame;\n}\n\nfunction describeClassComponentFrame(ctor, source, ownerFn) {\n  {\n    return describeNativeComponentFrame(ctor, true);\n  }\n}\nfunction describeFunctionComponentFrame(fn, source, ownerFn) {\n  {\n    return describeNativeComponentFrame(fn, false);\n  }\n}\n\nfunction shouldConstruct(Component) {\n  var prototype = Component.prototype;\n  return !!(prototype && prototype.isReactComponent);\n}\n\nfunction describeUnknownElementTypeFrameInDEV(type, source, ownerFn) {\n\n  if (type == null) {\n    return '';\n  }\n\n  if (typeof type === 'function') {\n    {\n      return describeNativeComponentFrame(type, shouldConstruct(type));\n    }\n  }\n\n  if (typeof type === 'string') {\n    return describeBuiltInComponentFrame(type);\n  }\n\n  switch (type) {\n    case REACT_SUSPENSE_TYPE:\n      return describeBuiltInComponentFrame('Suspense');\n\n    case REACT_SUSPENSE_LIST_TYPE:\n      return describeBuiltInComponentFrame('SuspenseList');\n  }\n\n  if (typeof type === 'object') {\n    switch (type.$$typeof) {\n      case REACT_FORWARD_REF_TYPE:\n        return describeFunctionComponentFrame(type.render);\n\n      case REACT_MEMO_TYPE:\n        // Memo may contain any component type so we recursively resolve it.\n        return describeUnknownElementTypeFrameInDEV(type.type, source, ownerFn);\n\n      case REACT_LAZY_TYPE:\n        {\n          var lazyComponent = type;\n          var payload = lazyComponent._payload;\n          var init = lazyComponent._init;\n\n          try {\n            // Lazy may contain any component type so we recursively resolve it.\n            return describeUnknownElementTypeFrameInDEV(init(payload), source, ownerFn);\n          } catch (x) {}\n        }\n    }\n  }\n\n  return '';\n}\n\nfunction describeFiber(fiber) {\n  var owner =  fiber._debugOwner ? fiber._debugOwner.type : null ;\n  var source =  fiber._debugSource ;\n\n  switch (fiber.tag) {\n    case HostComponent:\n      return describeBuiltInComponentFrame(fiber.type);\n\n    case LazyComponent:\n      return describeBuiltInComponentFrame('Lazy');\n\n    case SuspenseComponent:\n      return describeBuiltInComponentFrame('Suspense');\n\n    case SuspenseListComponent:\n      return describeBuiltInComponentFrame('SuspenseList');\n\n    case FunctionComponent:\n    case IndeterminateComponent:\n    case SimpleMemoComponent:\n      return describeFunctionComponentFrame(fiber.type);\n\n    case ForwardRef:\n      return describeFunctionComponentFrame(fiber.type.render);\n\n    case ClassComponent:\n      return describeClassComponentFrame(fiber.type);\n\n    default:\n      return '';\n  }\n}\n\nfunction getStackByFiberInDevAndProd(workInProgress) {\n  try {\n    var info = '';\n    var node = workInProgress;\n\n    do {\n      info += describeFiber(node);\n      node = node.return;\n    } while (node);\n\n    return info;\n  } catch (x) {\n    return '\\nError generating stack: ' + x.message + '\\n' + x.stack;\n  }\n}\n\nfunction getWrappedName(outerType, innerType, wrapperName) {\n  var displayName = outerType.displayName;\n\n  if (displayName) {\n    return displayName;\n  }\n\n  var functionName = innerType.displayName || innerType.name || '';\n  return functionName !== '' ? wrapperName + \"(\" + functionName + \")\" : wrapperName;\n} // Keep in sync with react-reconciler/getComponentNameFromFiber\n\n\nfunction getContextName(type) {\n  return type.displayName || 'Context';\n} // Note that the reconciler package should generally prefer to use getComponentNameFromFiber() instead.\n\n\nfunction getComponentNameFromType(type) {\n  if (type == null) {\n    // Host root, text node or just invalid type.\n    return null;\n  }\n\n  {\n    if (typeof type.tag === 'number') {\n      error('Received an unexpected object in getComponentNameFromType(). ' + 'This is likely a bug in React. Please file an issue.');\n    }\n  }\n\n  if (typeof type === 'function') {\n    return type.displayName || type.name || null;\n  }\n\n  if (typeof type === 'string') {\n    return type;\n  }\n\n  switch (type) {\n    case REACT_FRAGMENT_TYPE:\n      return 'Fragment';\n\n    case REACT_PORTAL_TYPE:\n      return 'Portal';\n\n    case REACT_PROFILER_TYPE:\n      return 'Profiler';\n\n    case REACT_STRICT_MODE_TYPE:\n      return 'StrictMode';\n\n    case REACT_SUSPENSE_TYPE:\n      return 'Suspense';\n\n    case REACT_SUSPENSE_LIST_TYPE:\n      return 'SuspenseList';\n\n  }\n\n  if (typeof type === 'object') {\n    switch (type.$$typeof) {\n      case REACT_CONTEXT_TYPE:\n        var context = type;\n        return getContextName(context) + '.Consumer';\n\n      case REACT_PROVIDER_TYPE:\n        var provider = type;\n        return getContextName(provider._context) + '.Provider';\n\n      case REACT_FORWARD_REF_TYPE:\n        return getWrappedName(type, type.render, 'ForwardRef');\n\n      case REACT_MEMO_TYPE:\n        var outerName = type.displayName || null;\n\n        if (outerName !== null) {\n          return outerName;\n        }\n\n        return getComponentNameFromType(type.type) || 'Memo';\n\n      case REACT_LAZY_TYPE:\n        {\n          var lazyComponent = type;\n          var payload = lazyComponent._payload;\n          var init = lazyComponent._init;\n\n          try {\n            return getComponentNameFromType(init(payload));\n          } catch (x) {\n            return null;\n          }\n        }\n\n      // eslint-disable-next-line no-fallthrough\n    }\n  }\n\n  return null;\n}\n\nfunction getWrappedName$1(outerType, innerType, wrapperName) {\n  var functionName = innerType.displayName || innerType.name || '';\n  return outerType.displayName || (functionName !== '' ? wrapperName + \"(\" + functionName + \")\" : wrapperName);\n} // Keep in sync with shared/getComponentNameFromType\n\n\nfunction getContextName$1(type) {\n  return type.displayName || 'Context';\n}\n\nfunction getComponentNameFromFiber(fiber) {\n  var tag = fiber.tag,\n      type = fiber.type;\n\n  switch (tag) {\n    case CacheComponent:\n      return 'Cache';\n\n    case ContextConsumer:\n      var context = type;\n      return getContextName$1(context) + '.Consumer';\n\n    case ContextProvider:\n      var provider = type;\n      return getContextName$1(provider._context) + '.Provider';\n\n    case DehydratedFragment:\n      return 'DehydratedFragment';\n\n    case ForwardRef:\n      return getWrappedName$1(type, type.render, 'ForwardRef');\n\n    case Fragment:\n      return 'Fragment';\n\n    case HostComponent:\n      // Host component type is the display name (e.g. \"div\", \"View\")\n      return type;\n\n    case HostPortal:\n      return 'Portal';\n\n    case HostRoot:\n      return 'Root';\n\n    case HostText:\n      return 'Text';\n\n    case LazyComponent:\n      // Name comes from the type in this case; we don't have a tag.\n      return getComponentNameFromType(type);\n\n    case Mode:\n      if (type === REACT_STRICT_MODE_TYPE) {\n        // Don't be less specific than shared/getComponentNameFromType\n        return 'StrictMode';\n      }\n\n      return 'Mode';\n\n    case OffscreenComponent:\n      return 'Offscreen';\n\n    case Profiler:\n      return 'Profiler';\n\n    case ScopeComponent:\n      return 'Scope';\n\n    case SuspenseComponent:\n      return 'Suspense';\n\n    case SuspenseListComponent:\n      return 'SuspenseList';\n\n    case TracingMarkerComponent:\n      return 'TracingMarker';\n    // The display name for this tags come from the user-provided type:\n\n    case ClassComponent:\n    case FunctionComponent:\n    case IncompleteClassComponent:\n    case IndeterminateComponent:\n    case MemoComponent:\n    case SimpleMemoComponent:\n      if (typeof type === 'function') {\n        return type.displayName || type.name || null;\n      }\n\n      if (typeof type === 'string') {\n        return type;\n      }\n\n      break;\n\n  }\n\n  return null;\n}\n\nvar ReactDebugCurrentFrame = ReactSharedInternals.ReactDebugCurrentFrame;\nvar current = null;\nvar isRendering = false;\nfunction getCurrentFiberOwnerNameInDevOrNull() {\n  {\n    if (current === null) {\n      return null;\n    }\n\n    var owner = current._debugOwner;\n\n    if (owner !== null && typeof owner !== 'undefined') {\n      return getComponentNameFromFiber(owner);\n    }\n  }\n\n  return null;\n}\n\nfunction getCurrentFiberStackInDev() {\n  {\n    if (current === null) {\n      return '';\n    } // Safe because if current fiber exists, we are reconciling,\n    // and it is guaranteed to be the work-in-progress version.\n\n\n    return getStackByFiberInDevAndProd(current);\n  }\n}\n\nfunction resetCurrentFiber() {\n  {\n    ReactDebugCurrentFrame.getCurrentStack = null;\n    current = null;\n    isRendering = false;\n  }\n}\nfunction setCurrentFiber(fiber) {\n  {\n    ReactDebugCurrentFrame.getCurrentStack = fiber === null ? null : getCurrentFiberStackInDev;\n    current = fiber;\n    isRendering = false;\n  }\n}\nfunction getCurrentFiber() {\n  {\n    return current;\n  }\n}\nfunction setIsRendering(rendering) {\n  {\n    isRendering = rendering;\n  }\n}\n\n// Flow does not allow string concatenation of most non-string types. To work\n// around this limitation, we use an opaque type that can only be obtained by\n// passing the value through getToStringValue first.\nfunction toString(value) {\n  // The coercion safety check is performed in getToStringValue().\n  // eslint-disable-next-line react-internal/safe-string-coercion\n  return '' + value;\n}\nfunction getToStringValue(value) {\n  switch (typeof value) {\n    case 'boolean':\n    case 'number':\n    case 'string':\n    case 'undefined':\n      return value;\n\n    case 'object':\n      {\n        checkFormFieldValueStringCoercion(value);\n      }\n\n      return value;\n\n    default:\n      // function, symbol are assigned as empty strings\n      return '';\n  }\n}\n\nvar hasReadOnlyValue = {\n  button: true,\n  checkbox: true,\n  image: true,\n  hidden: true,\n  radio: true,\n  reset: true,\n  submit: true\n};\nfunction checkControlledValueProps(tagName, props) {\n  {\n    if (!(hasReadOnlyValue[props.type] || props.onChange || props.onInput || props.readOnly || props.disabled || props.value == null)) {\n      error('You provided a `value` prop to a form field without an ' + '`onChange` handler. This will render a read-only field. If ' + 'the field should be mutable use `defaultValue`. Otherwise, ' + 'set either `onChange` or `readOnly`.');\n    }\n\n    if (!(props.onChange || props.readOnly || props.disabled || props.checked == null)) {\n      error('You provided a `checked` prop to a form field without an ' + '`onChange` handler. This will render a read-only field. If ' + 'the field should be mutable use `defaultChecked`. Otherwise, ' + 'set either `onChange` or `readOnly`.');\n    }\n  }\n}\n\nfunction isCheckable(elem) {\n  var type = elem.type;\n  var nodeName = elem.nodeName;\n  return nodeName && nodeName.toLowerCase() === 'input' && (type === 'checkbox' || type === 'radio');\n}\n\nfunction getTracker(node) {\n  return node._valueTracker;\n}\n\nfunction detachTracker(node) {\n  node._valueTracker = null;\n}\n\nfunction getValueFromNode(node) {\n  var value = '';\n\n  if (!node) {\n    return value;\n  }\n\n  if (isCheckable(node)) {\n    value = node.checked ? 'true' : 'false';\n  } else {\n    value = node.value;\n  }\n\n  return value;\n}\n\nfunction trackValueOnNode(node) {\n  var valueField = isCheckable(node) ? 'checked' : 'value';\n  var descriptor = Object.getOwnPropertyDescriptor(node.constructor.prototype, valueField);\n\n  {\n    checkFormFieldValueStringCoercion(node[valueField]);\n  }\n\n  var currentValue = '' + node[valueField]; // if someone has already defined a value or Safari, then bail\n  // and don't track value will cause over reporting of changes,\n  // but it's better then a hard failure\n  // (needed for certain tests that spyOn input values and Safari)\n\n  if (node.hasOwnProperty(valueField) || typeof descriptor === 'undefined' || typeof descriptor.get !== 'function' || typeof descriptor.set !== 'function') {\n    return;\n  }\n\n  var get = descriptor.get,\n      set = descriptor.set;\n  Object.defineProperty(node, valueField, {\n    configurable: true,\n    get: function () {\n      return get.call(this);\n    },\n    set: function (value) {\n      {\n        checkFormFieldValueStringCoercion(value);\n      }\n\n      currentValue = '' + value;\n      set.call(this, value);\n    }\n  }); // We could've passed this the first time\n  // but it triggers a bug in IE11 and Edge 14/15.\n  // Calling defineProperty() again should be equivalent.\n  // https://github.com/facebook/react/issues/11768\n\n  Object.defineProperty(node, valueField, {\n    enumerable: descriptor.enumerable\n  });\n  var tracker = {\n    getValue: function () {\n      return currentValue;\n    },\n    setValue: function (value) {\n      {\n        checkFormFieldValueStringCoercion(value);\n      }\n\n      currentValue = '' + value;\n    },\n    stopTracking: function () {\n      detachTracker(node);\n      delete node[valueField];\n    }\n  };\n  return tracker;\n}\n\nfunction track(node) {\n  if (getTracker(node)) {\n    return;\n  } // TODO: Once it's just Fiber we can move this to node._wrapperState\n\n\n  node._valueTracker = trackValueOnNode(node);\n}\nfunction updateValueIfChanged(node) {\n  if (!node) {\n    return false;\n  }\n\n  var tracker = getTracker(node); // if there is no tracker at this point it's unlikely\n  // that trying again will succeed\n\n  if (!tracker) {\n    return true;\n  }\n\n  var lastValue = tracker.getValue();\n  var nextValue = getValueFromNode(node);\n\n  if (nextValue !== lastValue) {\n    tracker.setValue(nextValue);\n    return true;\n  }\n\n  return false;\n}\n\nfunction getActiveElement(doc) {\n  doc = doc || (typeof document !== 'undefined' ? document : undefined);\n\n  if (typeof doc === 'undefined') {\n    return null;\n  }\n\n  try {\n    return doc.activeElement || doc.body;\n  } catch (e) {\n    return doc.body;\n  }\n}\n\nvar didWarnValueDefaultValue = false;\nvar didWarnCheckedDefaultChecked = false;\nvar didWarnControlledToUncontrolled = false;\nvar didWarnUncontrolledToControlled = false;\n\nfunction isControlled(props) {\n  var usesChecked = props.type === 'checkbox' || props.type === 'radio';\n  return usesChecked ? props.checked != null : props.value != null;\n}\n/**\n * Implements an <input> host component that allows setting these optional\n * props: `checked`, `value`, `defaultChecked`, and `defaultValue`.\n *\n * If `checked` or `value` are not supplied (or null/undefined), user actions\n * that affect the checked state or value will trigger updates to the element.\n *\n * If they are supplied (and not null/undefined), the rendered element will not\n * trigger updates to the element. Instead, the props must change in order for\n * the rendered element to be updated.\n *\n * The rendered element will be initialized as unchecked (or `defaultChecked`)\n * with an empty value (or `defaultValue`).\n *\n * See http://www.w3.org/TR/2012/WD-html5-20121025/the-input-element.html\n */\n\n\nfunction getHostProps(element, props) {\n  var node = element;\n  var checked = props.checked;\n  var hostProps = assign({}, props, {\n    defaultChecked: undefined,\n    defaultValue: undefined,\n    value: undefined,\n    checked: checked != null ? checked : node._wrapperState.initialChecked\n  });\n  return hostProps;\n}\nfunction initWrapperState(element, props) {\n  {\n    checkControlledValueProps('input', props);\n\n    if (props.checked !== undefined && props.defaultChecked !== undefined && !didWarnCheckedDefaultChecked) {\n      error('%s contains an input of type %s with both checked and defaultChecked props. ' + 'Input elements must be either controlled or uncontrolled ' + '(specify either the checked prop, or the defaultChecked prop, but not ' + 'both). Decide between using a controlled or uncontrolled input ' + 'element and remove one of these props. More info: ' + 'https://reactjs.org/link/controlled-components', getCurrentFiberOwnerNameInDevOrNull() || 'A component', props.type);\n\n      didWarnCheckedDefaultChecked = true;\n    }\n\n    if (props.value !== undefined && props.defaultValue !== undefined && !didWarnValueDefaultValue) {\n      error('%s contains an input of type %s with both value and defaultValue props. ' + 'Input elements must be either controlled or uncontrolled ' + '(specify either the value prop, or the defaultValue prop, but not ' + 'both). Decide between using a controlled or uncontrolled input ' + 'element and remove one of these props. More info: ' + 'https://reactjs.org/link/controlled-components', getCurrentFiberOwnerNameInDevOrNull() || 'A component', props.type);\n\n      didWarnValueDefaultValue = true;\n    }\n  }\n\n  var node = element;\n  var defaultValue = props.defaultValue == null ? '' : props.defaultValue;\n  node._wrapperState = {\n    initialChecked: props.checked != null ? props.checked : props.defaultChecked,\n    initialValue: getToStringValue(props.value != null ? props.value : defaultValue),\n    controlled: isControlled(props)\n  };\n}\nfunction updateChecked(element, props) {\n  var node = element;\n  var checked = props.checked;\n\n  if (checked != null) {\n    setValueForProperty(node, 'checked', checked, false);\n  }\n}\nfunction updateWrapper(element, props) {\n  var node = element;\n\n  {\n    var controlled = isControlled(props);\n\n    if (!node._wrapperState.controlled && controlled && !didWarnUncontrolledToControlled) {\n      error('A component is changing an uncontrolled input to be controlled. ' + 'This is likely caused by the value changing from undefined to ' + 'a defined value, which should not happen. ' + 'Decide between using a controlled or uncontrolled input ' + 'element for the lifetime of the component. More info: https://reactjs.org/link/controlled-components');\n\n      didWarnUncontrolledToControlled = true;\n    }\n\n    if (node._wrapperState.controlled && !controlled && !didWarnControlledToUncontrolled) {\n      error('A component is changing a controlled input to be uncontrolled. ' + 'This is likely caused by the value changing from a defined to ' + 'undefined, which should not happen. ' + 'Decide between using a controlled or uncontrolled input ' + 'element for the lifetime of the component. More info: https://reactjs.org/link/controlled-components');\n\n      didWarnControlledToUncontrolled = true;\n    }\n  }\n\n  updateChecked(element, props);\n  var value = getToStringValue(props.value);\n  var type = props.type;\n\n  if (value != null) {\n    if (type === 'number') {\n      if (value === 0 && node.value === '' || // We explicitly want to coerce to number here if possible.\n      // eslint-disable-next-line\n      node.value != value) {\n        node.value = toString(value);\n      }\n    } else if (node.value !== toString(value)) {\n      node.value = toString(value);\n    }\n  } else if (type === 'submit' || type === 'reset') {\n    // Submit/reset inputs need the attribute removed completely to avoid\n    // blank-text buttons.\n    node.removeAttribute('value');\n    return;\n  }\n\n  {\n    // When syncing the value attribute, the value comes from a cascade of\n    // properties:\n    //  1. The value React property\n    //  2. The defaultValue React property\n    //  3. Otherwise there should be no change\n    if (props.hasOwnProperty('value')) {\n      setDefaultValue(node, props.type, value);\n    } else if (props.hasOwnProperty('defaultValue')) {\n      setDefaultValue(node, props.type, getToStringValue(props.defaultValue));\n    }\n  }\n\n  {\n    // When syncing the checked attribute, it only changes when it needs\n    // to be removed, such as transitioning from a checkbox into a text input\n    if (props.checked == null && props.defaultChecked != null) {\n      node.defaultChecked = !!props.defaultChecked;\n    }\n  }\n}\nfunction postMountWrapper(element, props, isHydrating) {\n  var node = element; // Do not assign value if it is already set. This prevents user text input\n  // from being lost during SSR hydration.\n\n  if (props.hasOwnProperty('value') || props.hasOwnProperty('defaultValue')) {\n    var type = props.type;\n    var isButton = type === 'submit' || type === 'reset'; // Avoid setting value attribute on submit/reset inputs as it overrides the\n    // default value provided by the browser. See: #12872\n\n    if (isButton && (props.value === undefined || props.value === null)) {\n      return;\n    }\n\n    var initialValue = toString(node._wrapperState.initialValue); // Do not assign value if it is already set. This prevents user text input\n    // from being lost during SSR hydration.\n\n    if (!isHydrating) {\n      {\n        // When syncing the value attribute, the value property should use\n        // the wrapperState._initialValue property. This uses:\n        //\n        //   1. The value React property when present\n        //   2. The defaultValue React property when present\n        //   3. An empty string\n        if (initialValue !== node.value) {\n          node.value = initialValue;\n        }\n      }\n    }\n\n    {\n      // Otherwise, the value attribute is synchronized to the property,\n      // so we assign defaultValue to the same thing as the value property\n      // assignment step above.\n      node.defaultValue = initialValue;\n    }\n  } // Normally, we'd just do `node.checked = node.checked` upon initial mount, less this bug\n  // this is needed to work around a chrome bug where setting defaultChecked\n  // will sometimes influence the value of checked (even after detachment).\n  // Reference: https://bugs.chromium.org/p/chromium/issues/detail?id=608416\n  // We need to temporarily unset name to avoid disrupting radio button groups.\n\n\n  var name = node.name;\n\n  if (name !== '') {\n    node.name = '';\n  }\n\n  {\n    // When syncing the checked attribute, both the checked property and\n    // attribute are assigned at the same time using defaultChecked. This uses:\n    //\n    //   1. The checked React property when present\n    //   2. The defaultChecked React property when present\n    //   3. Otherwise, false\n    node.defaultChecked = !node.defaultChecked;\n    node.defaultChecked = !!node._wrapperState.initialChecked;\n  }\n\n  if (name !== '') {\n    node.name = name;\n  }\n}\nfunction restoreControlledState(element, props) {\n  var node = element;\n  updateWrapper(node, props);\n  updateNamedCousins(node, props);\n}\n\nfunction updateNamedCousins(rootNode, props) {\n  var name = props.name;\n\n  if (props.type === 'radio' && name != null) {\n    var queryRoot = rootNode;\n\n    while (queryRoot.parentNode) {\n      queryRoot = queryRoot.parentNode;\n    } // If `rootNode.form` was non-null, then we could try `form.elements`,\n    // but that sometimes behaves strangely in IE8. We could also try using\n    // `form.getElementsByName`, but that will only return direct children\n    // and won't include inputs that use the HTML5 `form=` attribute. Since\n    // the input might not even be in a form. It might not even be in the\n    // document. Let's just use the local `querySelectorAll` to ensure we don't\n    // miss anything.\n\n\n    {\n      checkAttributeStringCoercion(name, 'name');\n    }\n\n    var group = queryRoot.querySelectorAll('input[name=' + JSON.stringify('' + name) + '][type=\"radio\"]');\n\n    for (var i = 0; i < group.length; i++) {\n      var otherNode = group[i];\n\n      if (otherNode === rootNode || otherNode.form !== rootNode.form) {\n        continue;\n      } // This will throw if radio buttons rendered by different copies of React\n      // and the same name are rendered into the same form (same as #1939).\n      // That's probably okay; we don't support it just as we don't support\n      // mixing React radio buttons with non-React ones.\n\n\n      var otherProps = getFiberCurrentPropsFromNode(otherNode);\n\n      if (!otherProps) {\n        throw new Error('ReactDOMInput: Mixing React and non-React radio inputs with the ' + 'same `name` is not supported.');\n      } // We need update the tracked value on the named cousin since the value\n      // was changed but the input saw no event or value set\n\n\n      updateValueIfChanged(otherNode); // If this is a controlled radio button group, forcing the input that\n      // was previously checked to update will cause it to be come re-checked\n      // as appropriate.\n\n      updateWrapper(otherNode, otherProps);\n    }\n  }\n} // In Chrome, assigning defaultValue to certain input types triggers input validation.\n// For number inputs, the display value loses trailing decimal points. For email inputs,\n// Chrome raises \"The specified value <x> is not a valid email address\".\n//\n// Here we check to see if the defaultValue has actually changed, avoiding these problems\n// when the user is inputting text\n//\n// https://github.com/facebook/react/issues/7253\n\n\nfunction setDefaultValue(node, type, value) {\n  if ( // Focused number inputs synchronize on blur. See ChangeEventPlugin.js\n  type !== 'number' || getActiveElement(node.ownerDocument) !== node) {\n    if (value == null) {\n      node.defaultValue = toString(node._wrapperState.initialValue);\n    } else if (node.defaultValue !== toString(value)) {\n      node.defaultValue = toString(value);\n    }\n  }\n}\n\nvar didWarnSelectedSetOnOption = false;\nvar didWarnInvalidChild = false;\nvar didWarnInvalidInnerHTML = false;\n/**\n * Implements an <option> host component that warns when `selected` is set.\n */\n\nfunction validateProps(element, props) {\n  {\n    // If a value is not provided, then the children must be simple.\n    if (props.value == null) {\n      if (typeof props.children === 'object' && props.children !== null) {\n        React.Children.forEach(props.children, function (child) {\n          if (child == null) {\n            return;\n          }\n\n          if (typeof child === 'string' || typeof child === 'number') {\n            return;\n          }\n\n          if (!didWarnInvalidChild) {\n            didWarnInvalidChild = true;\n\n            error('Cannot infer the option value of complex children. ' + 'Pass a `value` prop or use a plain string as children to <option>.');\n          }\n        });\n      } else if (props.dangerouslySetInnerHTML != null) {\n        if (!didWarnInvalidInnerHTML) {\n          didWarnInvalidInnerHTML = true;\n\n          error('Pass a `value` prop if you set dangerouslyInnerHTML so React knows ' + 'which value should be selected.');\n        }\n      }\n    } // TODO: Remove support for `selected` in <option>.\n\n\n    if (props.selected != null && !didWarnSelectedSetOnOption) {\n      error('Use the `defaultValue` or `value` props on <select> instead of ' + 'setting `selected` on <option>.');\n\n      didWarnSelectedSetOnOption = true;\n    }\n  }\n}\nfunction postMountWrapper$1(element, props) {\n  // value=\"\" should make a value attribute (#6219)\n  if (props.value != null) {\n    element.setAttribute('value', toString(getToStringValue(props.value)));\n  }\n}\n\nvar isArrayImpl = Array.isArray; // eslint-disable-next-line no-redeclare\n\nfunction isArray(a) {\n  return isArrayImpl(a);\n}\n\nvar didWarnValueDefaultValue$1;\n\n{\n  didWarnValueDefaultValue$1 = false;\n}\n\nfunction getDeclarationErrorAddendum() {\n  var ownerName = getCurrentFiberOwnerNameInDevOrNull();\n\n  if (ownerName) {\n    return '\\n\\nCheck the render method of `' + ownerName + '`.';\n  }\n\n  return '';\n}\n\nvar valuePropNames = ['value', 'defaultValue'];\n/**\n * Validation function for `value` and `defaultValue`.\n */\n\nfunction checkSelectPropTypes(props) {\n  {\n    checkControlledValueProps('select', props);\n\n    for (var i = 0; i < valuePropNames.length; i++) {\n      var propName = valuePropNames[i];\n\n      if (props[propName] == null) {\n        continue;\n      }\n\n      var propNameIsArray = isArray(props[propName]);\n\n      if (props.multiple && !propNameIsArray) {\n        error('The `%s` prop supplied to <select> must be an array if ' + '`multiple` is true.%s', propName, getDeclarationErrorAddendum());\n      } else if (!props.multiple && propNameIsArray) {\n        error('The `%s` prop supplied to <select> must be a scalar ' + 'value if `multiple` is false.%s', propName, getDeclarationErrorAddendum());\n      }\n    }\n  }\n}\n\nfunction updateOptions(node, multiple, propValue, setDefaultSelected) {\n  var options = node.options;\n\n  if (multiple) {\n    var selectedValues = propValue;\n    var selectedValue = {};\n\n    for (var i = 0; i < selectedValues.length; i++) {\n      // Prefix to avoid chaos with special keys.\n      selectedValue['$' + selectedValues[i]] = true;\n    }\n\n    for (var _i = 0; _i < options.length; _i++) {\n      var selected = selectedValue.hasOwnProperty('$' + options[_i].value);\n\n      if (options[_i].selected !== selected) {\n        options[_i].selected = selected;\n      }\n\n      if (selected && setDefaultSelected) {\n        options[_i].defaultSelected = true;\n      }\n    }\n  } else {\n    // Do not set `select.value` as exact behavior isn't consistent across all\n    // browsers for all cases.\n    var _selectedValue = toString(getToStringValue(propValue));\n\n    var defaultSelected = null;\n\n    for (var _i2 = 0; _i2 < options.length; _i2++) {\n      if (options[_i2].value === _selectedValue) {\n        options[_i2].selected = true;\n\n        if (setDefaultSelected) {\n          options[_i2].defaultSelected = true;\n        }\n\n        return;\n      }\n\n      if (defaultSelected === null && !options[_i2].disabled) {\n        defaultSelected = options[_i2];\n      }\n    }\n\n    if (defaultSelected !== null) {\n      defaultSelected.selected = true;\n    }\n  }\n}\n/**\n * Implements a <select> host component that allows optionally setting the\n * props `value` and `defaultValue`. If `multiple` is false, the prop must be a\n * stringable. If `multiple` is true, the prop must be an array of stringables.\n *\n * If `value` is not supplied (or null/undefined), user actions that change the\n * selected option will trigger updates to the rendered options.\n *\n * If it is supplied (and not null/undefined), the rendered options will not\n * update in response to user actions. Instead, the `value` prop must change in\n * order for the rendered options to update.\n *\n * If `defaultValue` is provided, any options with the supplied values will be\n * selected.\n */\n\n\nfunction getHostProps$1(element, props) {\n  return assign({}, props, {\n    value: undefined\n  });\n}\nfunction initWrapperState$1(element, props) {\n  var node = element;\n\n  {\n    checkSelectPropTypes(props);\n  }\n\n  node._wrapperState = {\n    wasMultiple: !!props.multiple\n  };\n\n  {\n    if (props.value !== undefined && props.defaultValue !== undefined && !didWarnValueDefaultValue$1) {\n      error('Select elements must be either controlled or uncontrolled ' + '(specify either the value prop, or the defaultValue prop, but not ' + 'both). Decide between using a controlled or uncontrolled select ' + 'element and remove one of these props. More info: ' + 'https://reactjs.org/link/controlled-components');\n\n      didWarnValueDefaultValue$1 = true;\n    }\n  }\n}\nfunction postMountWrapper$2(element, props) {\n  var node = element;\n  node.multiple = !!props.multiple;\n  var value = props.value;\n\n  if (value != null) {\n    updateOptions(node, !!props.multiple, value, false);\n  } else if (props.defaultValue != null) {\n    updateOptions(node, !!props.multiple, props.defaultValue, true);\n  }\n}\nfunction postUpdateWrapper(element, props) {\n  var node = element;\n  var wasMultiple = node._wrapperState.wasMultiple;\n  node._wrapperState.wasMultiple = !!props.multiple;\n  var value = props.value;\n\n  if (value != null) {\n    updateOptions(node, !!props.multiple, value, false);\n  } else if (wasMultiple !== !!props.multiple) {\n    // For simplicity, reapply `defaultValue` if `multiple` is toggled.\n    if (props.defaultValue != null) {\n      updateOptions(node, !!props.multiple, props.defaultValue, true);\n    } else {\n      // Revert the select back to its default unselected state.\n      updateOptions(node, !!props.multiple, props.multiple ? [] : '', false);\n    }\n  }\n}\nfunction restoreControlledState$1(element, props) {\n  var node = element;\n  var value = props.value;\n\n  if (value != null) {\n    updateOptions(node, !!props.multiple, value, false);\n  }\n}\n\nvar didWarnValDefaultVal = false;\n\n/**\n * Implements a <textarea> host component that allows setting `value`, and\n * `defaultValue`. This differs from the traditional DOM API because value is\n * usually set as PCDATA children.\n *\n * If `value` is not supplied (or null/undefined), user actions that affect the\n * value will trigger updates to the element.\n *\n * If `value` is supplied (and not null/undefined), the rendered element will\n * not trigger updates to the element. Instead, the `value` prop must change in\n * order for the rendered element to be updated.\n *\n * The rendered element will be initialized with an empty value, the prop\n * `defaultValue` if specified, or the children content (deprecated).\n */\nfunction getHostProps$2(element, props) {\n  var node = element;\n\n  if (props.dangerouslySetInnerHTML != null) {\n    throw new Error('`dangerouslySetInnerHTML` does not make sense on <textarea>.');\n  } // Always set children to the same thing. In IE9, the selection range will\n  // get reset if `textContent` is mutated.  We could add a check in setTextContent\n  // to only set the value if/when the value differs from the node value (which would\n  // completely solve this IE9 bug), but Sebastian+Sophie seemed to like this\n  // solution. The value can be a boolean or object so that's why it's forced\n  // to be a string.\n\n\n  var hostProps = assign({}, props, {\n    value: undefined,\n    defaultValue: undefined,\n    children: toString(node._wrapperState.initialValue)\n  });\n\n  return hostProps;\n}\nfunction initWrapperState$2(element, props) {\n  var node = element;\n\n  {\n    checkControlledValueProps('textarea', props);\n\n    if (props.value !== undefined && props.defaultValue !== undefined && !didWarnValDefaultVal) {\n      error('%s contains a textarea with both value and defaultValue props. ' + 'Textarea elements must be either controlled or uncontrolled ' + '(specify either the value prop, or the defaultValue prop, but not ' + 'both). Decide between using a controlled or uncontrolled textarea ' + 'and remove one of these props. More info: ' + 'https://reactjs.org/link/controlled-components', getCurrentFiberOwnerNameInDevOrNull() || 'A component');\n\n      didWarnValDefaultVal = true;\n    }\n  }\n\n  var initialValue = props.value; // Only bother fetching default value if we're going to use it\n\n  if (initialValue == null) {\n    var children = props.children,\n        defaultValue = props.defaultValue;\n\n    if (children != null) {\n      {\n        error('Use the `defaultValue` or `value` props instead of setting ' + 'children on <textarea>.');\n      }\n\n      {\n        if (defaultValue != null) {\n          throw new Error('If you supply `defaultValue` on a <textarea>, do not pass children.');\n        }\n\n        if (isArray(children)) {\n          if (children.length > 1) {\n            throw new Error('<textarea> can only have at most one child.');\n          }\n\n          children = children[0];\n        }\n\n        defaultValue = children;\n      }\n    }\n\n    if (defaultValue == null) {\n      defaultValue = '';\n    }\n\n    initialValue = defaultValue;\n  }\n\n  node._wrapperState = {\n    initialValue: getToStringValue(initialValue)\n  };\n}\nfunction updateWrapper$1(element, props) {\n  var node = element;\n  var value = getToStringValue(props.value);\n  var defaultValue = getToStringValue(props.defaultValue);\n\n  if (value != null) {\n    // Cast `value` to a string to ensure the value is set correctly. While\n    // browsers typically do this as necessary, jsdom doesn't.\n    var newValue = toString(value); // To avoid side effects (such as losing text selection), only set value if changed\n\n    if (newValue !== node.value) {\n      node.value = newValue;\n    }\n\n    if (props.defaultValue == null && node.defaultValue !== newValue) {\n      node.defaultValue = newValue;\n    }\n  }\n\n  if (defaultValue != null) {\n    node.defaultValue = toString(defaultValue);\n  }\n}\nfunction postMountWrapper$3(element, props) {\n  var node = element; // This is in postMount because we need access to the DOM node, which is not\n  // available until after the component has mounted.\n\n  var textContent = node.textContent; // Only set node.value if textContent is equal to the expected\n  // initial value. In IE10/IE11 there is a bug where the placeholder attribute\n  // will populate textContent as well.\n  // https://developer.microsoft.com/microsoft-edge/platform/issues/101525/\n\n  if (textContent === node._wrapperState.initialValue) {\n    if (textContent !== '' && textContent !== null) {\n      node.value = textContent;\n    }\n  }\n}\nfunction restoreControlledState$2(element, props) {\n  // DOM component is still mounted; update\n  updateWrapper$1(element, props);\n}\n\nvar HTML_NAMESPACE = 'http://www.w3.org/1999/xhtml';\nvar MATH_NAMESPACE = 'http://www.w3.org/1998/Math/MathML';\nvar SVG_NAMESPACE = 'http://www.w3.org/2000/svg'; // Assumes there is no parent namespace.\n\nfunction getIntrinsicNamespace(type) {\n  switch (type) {\n    case 'svg':\n      return SVG_NAMESPACE;\n\n    case 'math':\n      return MATH_NAMESPACE;\n\n    default:\n      return HTML_NAMESPACE;\n  }\n}\nfunction getChildNamespace(parentNamespace, type) {\n  if (parentNamespace == null || parentNamespace === HTML_NAMESPACE) {\n    // No (or default) parent namespace: potential entry point.\n    return getIntrinsicNamespace(type);\n  }\n\n  if (parentNamespace === SVG_NAMESPACE && type === 'foreignObject') {\n    // We're leaving SVG.\n    return HTML_NAMESPACE;\n  } // By default, pass namespace below.\n\n\n  return parentNamespace;\n}\n\n/* globals MSApp */\n\n/**\n * Create a function which has 'unsafe' privileges (required by windows8 apps)\n */\nvar createMicrosoftUnsafeLocalFunction = function (func) {\n  if (typeof MSApp !== 'undefined' && MSApp.execUnsafeLocalFunction) {\n    return function (arg0, arg1, arg2, arg3) {\n      MSApp.execUnsafeLocalFunction(function () {\n        return func(arg0, arg1, arg2, arg3);\n      });\n    };\n  } else {\n    return func;\n  }\n};\n\nvar reusableSVGContainer;\n/**\n * Set the innerHTML property of a node\n *\n * @param {DOMElement} node\n * @param {string} html\n * @internal\n */\n\nvar setInnerHTML = createMicrosoftUnsafeLocalFunction(function (node, html) {\n  if (node.namespaceURI === SVG_NAMESPACE) {\n\n    if (!('innerHTML' in node)) {\n      // IE does not have innerHTML for SVG nodes, so instead we inject the\n      // new markup in a temp node and then move the child nodes across into\n      // the target node\n      reusableSVGContainer = reusableSVGContainer || document.createElement('div');\n      reusableSVGContainer.innerHTML = '<svg>' + html.valueOf().toString() + '</svg>';\n      var svgNode = reusableSVGContainer.firstChild;\n\n      while (node.firstChild) {\n        node.removeChild(node.firstChild);\n      }\n\n      while (svgNode.firstChild) {\n        node.appendChild(svgNode.firstChild);\n      }\n\n      return;\n    }\n  }\n\n  node.innerHTML = html;\n});\n\n/**\n * HTML nodeType values that represent the type of the node\n */\nvar ELEMENT_NODE = 1;\nvar TEXT_NODE = 3;\nvar COMMENT_NODE = 8;\nvar DOCUMENT_NODE = 9;\nvar DOCUMENT_FRAGMENT_NODE = 11;\n\n/**\n * Set the textContent property of a node. For text updates, it's faster\n * to set the `nodeValue` of the Text node directly instead of using\n * `.textContent` which will remove the existing node and create a new one.\n *\n * @param {DOMElement} node\n * @param {string} text\n * @internal\n */\n\nvar setTextContent = function (node, text) {\n  if (text) {\n    var firstChild = node.firstChild;\n\n    if (firstChild && firstChild === node.lastChild && firstChild.nodeType === TEXT_NODE) {\n      firstChild.nodeValue = text;\n      return;\n    }\n  }\n\n  node.textContent = text;\n};\n\n// List derived from Gecko source code:\n// https://github.com/mozilla/gecko-dev/blob/4e638efc71/layout/style/test/property_database.js\nvar shorthandToLonghand = {\n  animation: ['animationDelay', 'animationDirection', 'animationDuration', 'animationFillMode', 'animationIterationCount', 'animationName', 'animationPlayState', 'animationTimingFunction'],\n  background: ['backgroundAttachment', 'backgroundClip', 'backgroundColor', 'backgroundImage', 'backgroundOrigin', 'backgroundPositionX', 'backgroundPositionY', 'backgroundRepeat', 'backgroundSize'],\n  backgroundPosition: ['backgroundPositionX', 'backgroundPositionY'],\n  border: ['borderBottomColor', 'borderBottomStyle', 'borderBottomWidth', 'borderImageOutset', 'borderImageRepeat', 'borderImageSlice', 'borderImageSource', 'borderImageWidth', 'borderLeftColor', 'borderLeftStyle', 'borderLeftWidth', 'borderRightColor', 'borderRightStyle', 'borderRightWidth', 'borderTopColor', 'borderTopStyle', 'borderTopWidth'],\n  borderBlockEnd: ['borderBlockEndColor', 'borderBlockEndStyle', 'borderBlockEndWidth'],\n  borderBlockStart: ['borderBlockStartColor', 'borderBlockStartStyle', 'borderBlockStartWidth'],\n  borderBottom: ['borderBottomColor', 'borderBottomStyle', 'borderBottomWidth'],\n  borderColor: ['borderBottomColor', 'borderLeftColor', 'borderRightColor', 'borderTopColor'],\n  borderImage: ['borderImageOutset', 'borderImageRepeat', 'borderImageSlice', 'borderImageSource', 'borderImageWidth'],\n  borderInlineEnd: ['borderInlineEndColor', 'borderInlineEndStyle', 'borderInlineEndWidth'],\n  borderInlineStart: ['borderInlineStartColor', 'borderInlineStartStyle', 'borderInlineStartWidth'],\n  borderLeft: ['borderLeftColor', 'borderLeftStyle', 'borderLeftWidth'],\n  borderRadius: ['borderBottomLeftRadius', 'borderBottomRightRadius', 'borderTopLeftRadius', 'borderTopRightRadius'],\n  borderRight: ['borderRightColor', 'borderRightStyle', 'borderRightWidth'],\n  borderStyle: ['borderBottomStyle', 'borderLeftStyle', 'borderRightStyle', 'borderTopStyle'],\n  borderTop: ['borderTopColor', 'borderTopStyle', 'borderTopWidth'],\n  borderWidth: ['borderBottomWidth', 'borderLeftWidth', 'borderRightWidth', 'borderTopWidth'],\n  columnRule: ['columnRuleColor', 'columnRuleStyle', 'columnRuleWidth'],\n  columns: ['columnCount', 'columnWidth'],\n  flex: ['flexBasis', 'flexGrow', 'flexShrink'],\n  flexFlow: ['flexDirection', 'flexWrap'],\n  font: ['fontFamily', 'fontFeatureSettings', 'fontKerning', 'fontLanguageOverride', 'fontSize', 'fontSizeAdjust', 'fontStretch', 'fontStyle', 'fontVariant', 'fontVariantAlternates', 'fontVariantCaps', 'fontVariantEastAsian', 'fontVariantLigatures', 'fontVariantNumeric', 'fontVariantPosition', 'fontWeight', 'lineHeight'],\n  fontVariant: ['fontVariantAlternates', 'fontVariantCaps', 'fontVariantEastAsian', 'fontVariantLigatures', 'fontVariantNumeric', 'fontVariantPosition'],\n  gap: ['columnGap', 'rowGap'],\n  grid: ['gridAutoColumns', 'gridAutoFlow', 'gridAutoRows', 'gridTemplateAreas', 'gridTemplateColumns', 'gridTemplateRows'],\n  gridArea: ['gridColumnEnd', 'gridColumnStart', 'gridRowEnd', 'gridRowStart'],\n  gridColumn: ['gridColumnEnd', 'gridColumnStart'],\n  gridColumnGap: ['columnGap'],\n  gridGap: ['columnGap', 'rowGap'],\n  gridRow: ['gridRowEnd', 'gridRowStart'],\n  gridRowGap: ['rowGap'],\n  gridTemplate: ['gridTemplateAreas', 'gridTemplateColumns', 'gridTemplateRows'],\n  listStyle: ['listStyleImage', 'listStylePosition', 'listStyleType'],\n  margin: ['marginBottom', 'marginLeft', 'marginRight', 'marginTop'],\n  marker: ['markerEnd', 'markerMid', 'markerStart'],\n  mask: ['maskClip', 'maskComposite', 'maskImage', 'maskMode', 'maskOrigin', 'maskPositionX', 'maskPositionY', 'maskRepeat', 'maskSize'],\n  maskPosition: ['maskPositionX', 'maskPositionY'],\n  outline: ['outlineColor', 'outlineStyle', 'outlineWidth'],\n  overflow: ['overflowX', 'overflowY'],\n  padding: ['paddingBottom', 'paddingLeft', 'paddingRight', 'paddingTop'],\n  placeContent: ['alignContent', 'justifyContent'],\n  placeItems: ['alignItems', 'justifyItems'],\n  placeSelf: ['alignSelf', 'justifySelf'],\n  textDecoration: ['textDecorationColor', 'textDecorationLine', 'textDecorationStyle'],\n  textEmphasis: ['textEmphasisColor', 'textEmphasisStyle'],\n  transition: ['transitionDelay', 'transitionDuration', 'transitionProperty', 'transitionTimingFunction'],\n  wordWrap: ['overflowWrap']\n};\n\n/**\n * CSS properties which accept numbers but are not in units of \"px\".\n */\nvar isUnitlessNumber = {\n  animationIterationCount: true,\n  aspectRatio: true,\n  borderImageOutset: true,\n  borderImageSlice: true,\n  borderImageWidth: true,\n  boxFlex: true,\n  boxFlexGroup: true,\n  boxOrdinalGroup: true,\n  columnCount: true,\n  columns: true,\n  flex: true,\n  flexGrow: true,\n  flexPositive: true,\n  flexShrink: true,\n  flexNegative: true,\n  flexOrder: true,\n  gridArea: true,\n  gridRow: true,\n  gridRowEnd: true,\n  gridRowSpan: true,\n  gridRowStart: true,\n  gridColumn: true,\n  gridColumnEnd: true,\n  gridColumnSpan: true,\n  gridColumnStart: true,\n  fontWeight: true,\n  lineClamp: true,\n  lineHeight: true,\n  opacity: true,\n  order: true,\n  orphans: true,\n  tabSize: true,\n  widows: true,\n  zIndex: true,\n  zoom: true,\n  // SVG-related properties\n  fillOpacity: true,\n  floodOpacity: true,\n  stopOpacity: true,\n  strokeDasharray: true,\n  strokeDashoffset: true,\n  strokeMiterlimit: true,\n  strokeOpacity: true,\n  strokeWidth: true\n};\n/**\n * @param {string} prefix vendor-specific prefix, eg: Webkit\n * @param {string} key style name, eg: transitionDuration\n * @return {string} style name prefixed with `prefix`, properly camelCased, eg:\n * WebkitTransitionDuration\n */\n\nfunction prefixKey(prefix, key) {\n  return prefix + key.charAt(0).toUpperCase() + key.substring(1);\n}\n/**\n * Support style names that may come passed in prefixed by adding permutations\n * of vendor prefixes.\n */\n\n\nvar prefixes = ['Webkit', 'ms', 'Moz', 'O']; // Using Object.keys here, or else the vanilla for-in loop makes IE8 go into an\n// infinite loop, because it iterates over the newly added props too.\n\nObject.keys(isUnitlessNumber).forEach(function (prop) {\n  prefixes.forEach(function (prefix) {\n    isUnitlessNumber[prefixKey(prefix, prop)] = isUnitlessNumber[prop];\n  });\n});\n\n/**\n * Convert a value into the proper css writable value. The style name `name`\n * should be logical (no hyphens), as specified\n * in `CSSProperty.isUnitlessNumber`.\n *\n * @param {string} name CSS property name such as `topMargin`.\n * @param {*} value CSS property value such as `10px`.\n * @return {string} Normalized style value with dimensions applied.\n */\n\nfunction dangerousStyleValue(name, value, isCustomProperty) {\n  // Note that we've removed escapeTextForBrowser() calls here since the\n  // whole string will be escaped when the attribute is injected into\n  // the markup. If you provide unsafe user data here they can inject\n  // arbitrary CSS which may be problematic (I couldn't repro this):\n  // https://www.owasp.org/index.php/XSS_Filter_Evasion_Cheat_Sheet\n  // http://www.thespanner.co.uk/2007/11/26/ultimate-xss-css-injection/\n  // This is not an XSS hole but instead a potential CSS injection issue\n  // which has lead to a greater discussion about how we're going to\n  // trust URLs moving forward. See #2115901\n  var isEmpty = value == null || typeof value === 'boolean' || value === '';\n\n  if (isEmpty) {\n    return '';\n  }\n\n  if (!isCustomProperty && typeof value === 'number' && value !== 0 && !(isUnitlessNumber.hasOwnProperty(name) && isUnitlessNumber[name])) {\n    return value + 'px'; // Presumes implicit 'px' suffix for unitless numbers\n  }\n\n  {\n    checkCSSPropertyStringCoercion(value, name);\n  }\n\n  return ('' + value).trim();\n}\n\nvar uppercasePattern = /([A-Z])/g;\nvar msPattern = /^ms-/;\n/**\n * Hyphenates a camelcased CSS property name, for example:\n *\n *   > hyphenateStyleName('backgroundColor')\n *   < \"background-color\"\n *   > hyphenateStyleName('MozTransition')\n *   < \"-moz-transition\"\n *   > hyphenateStyleName('msTransition')\n *   < \"-ms-transition\"\n *\n * As Modernizr suggests (http://modernizr.com/docs/#prefixed), an `ms` prefix\n * is converted to `-ms-`.\n */\n\nfunction hyphenateStyleName(name) {\n  return name.replace(uppercasePattern, '-$1').toLowerCase().replace(msPattern, '-ms-');\n}\n\nvar warnValidStyle = function () {};\n\n{\n  // 'msTransform' is correct, but the other prefixes should be capitalized\n  var badVendoredStyleNamePattern = /^(?:webkit|moz|o)[A-Z]/;\n  var msPattern$1 = /^-ms-/;\n  var hyphenPattern = /-(.)/g; // style values shouldn't contain a semicolon\n\n  var badStyleValueWithSemicolonPattern = /;\\s*$/;\n  var warnedStyleNames = {};\n  var warnedStyleValues = {};\n  var warnedForNaNValue = false;\n  var warnedForInfinityValue = false;\n\n  var camelize = function (string) {\n    return string.replace(hyphenPattern, function (_, character) {\n      return character.toUpperCase();\n    });\n  };\n\n  var warnHyphenatedStyleName = function (name) {\n    if (warnedStyleNames.hasOwnProperty(name) && warnedStyleNames[name]) {\n      return;\n    }\n\n    warnedStyleNames[name] = true;\n\n    error('Unsupported style property %s. Did you mean %s?', name, // As Andi Smith suggests\n    // (http://www.andismith.com/blog/2012/02/modernizr-prefixed/), an `-ms` prefix\n    // is converted to lowercase `ms`.\n    camelize(name.replace(msPattern$1, 'ms-')));\n  };\n\n  var warnBadVendoredStyleName = function (name) {\n    if (warnedStyleNames.hasOwnProperty(name) && warnedStyleNames[name]) {\n      return;\n    }\n\n    warnedStyleNames[name] = true;\n\n    error('Unsupported vendor-prefixed style property %s. Did you mean %s?', name, name.charAt(0).toUpperCase() + name.slice(1));\n  };\n\n  var warnStyleValueWithSemicolon = function (name, value) {\n    if (warnedStyleValues.hasOwnProperty(value) && warnedStyleValues[value]) {\n      return;\n    }\n\n    warnedStyleValues[value] = true;\n\n    error(\"Style property values shouldn't contain a semicolon. \" + 'Try \"%s: %s\" instead.', name, value.replace(badStyleValueWithSemicolonPattern, ''));\n  };\n\n  var warnStyleValueIsNaN = function (name, value) {\n    if (warnedForNaNValue) {\n      return;\n    }\n\n    warnedForNaNValue = true;\n\n    error('`NaN` is an invalid value for the `%s` css style property.', name);\n  };\n\n  var warnStyleValueIsInfinity = function (name, value) {\n    if (warnedForInfinityValue) {\n      return;\n    }\n\n    warnedForInfinityValue = true;\n\n    error('`Infinity` is an invalid value for the `%s` css style property.', name);\n  };\n\n  warnValidStyle = function (name, value) {\n    if (name.indexOf('-') > -1) {\n      warnHyphenatedStyleName(name);\n    } else if (badVendoredStyleNamePattern.test(name)) {\n      warnBadVendoredStyleName(name);\n    } else if (badStyleValueWithSemicolonPattern.test(value)) {\n      warnStyleValueWithSemicolon(name, value);\n    }\n\n    if (typeof value === 'number') {\n      if (isNaN(value)) {\n        warnStyleValueIsNaN(name, value);\n      } else if (!isFinite(value)) {\n        warnStyleValueIsInfinity(name, value);\n      }\n    }\n  };\n}\n\nvar warnValidStyle$1 = warnValidStyle;\n\n/**\n * Operations for dealing with CSS properties.\n */\n\n/**\n * This creates a string that is expected to be equivalent to the style\n * attribute generated by server-side rendering. It by-passes warnings and\n * security checks so it's not safe to use this value for anything other than\n * comparison. It is only used in DEV for SSR validation.\n */\n\nfunction createDangerousStringForStyles(styles) {\n  {\n    var serialized = '';\n    var delimiter = '';\n\n    for (var styleName in styles) {\n      if (!styles.hasOwnProperty(styleName)) {\n        continue;\n      }\n\n      var styleValue = styles[styleName];\n\n      if (styleValue != null) {\n        var isCustomProperty = styleName.indexOf('--') === 0;\n        serialized += delimiter + (isCustomProperty ? styleName : hyphenateStyleName(styleName)) + ':';\n        serialized += dangerousStyleValue(styleName, styleValue, isCustomProperty);\n        delimiter = ';';\n      }\n    }\n\n    return serialized || null;\n  }\n}\n/**\n * Sets the value for multiple styles on a node.  If a value is specified as\n * '' (empty string), the corresponding style property will be unset.\n *\n * @param {DOMElement} node\n * @param {object} styles\n */\n\nfunction setValueForStyles(node, styles) {\n  var style = node.style;\n\n  for (var styleName in styles) {\n    if (!styles.hasOwnProperty(styleName)) {\n      continue;\n    }\n\n    var isCustomProperty = styleName.indexOf('--') === 0;\n\n    {\n      if (!isCustomProperty) {\n        warnValidStyle$1(styleName, styles[styleName]);\n      }\n    }\n\n    var styleValue = dangerousStyleValue(styleName, styles[styleName], isCustomProperty);\n\n    if (styleName === 'float') {\n      styleName = 'cssFloat';\n    }\n\n    if (isCustomProperty) {\n      style.setProperty(styleName, styleValue);\n    } else {\n      style[styleName] = styleValue;\n    }\n  }\n}\n\nfunction isValueEmpty(value) {\n  return value == null || typeof value === 'boolean' || value === '';\n}\n/**\n * Given {color: 'red', overflow: 'hidden'} returns {\n *   color: 'color',\n *   overflowX: 'overflow',\n *   overflowY: 'overflow',\n * }. This can be read as \"the overflowY property was set by the overflow\n * shorthand\". That is, the values are the property that each was derived from.\n */\n\n\nfunction expandShorthandMap(styles) {\n  var expanded = {};\n\n  for (var key in styles) {\n    var longhands = shorthandToLonghand[key] || [key];\n\n    for (var i = 0; i < longhands.length; i++) {\n      expanded[longhands[i]] = key;\n    }\n  }\n\n  return expanded;\n}\n/**\n * When mixing shorthand and longhand property names, we warn during updates if\n * we expect an incorrect result to occur. In particular, we warn for:\n *\n * Updating a shorthand property (longhand gets overwritten):\n *   {font: 'foo', fontVariant: 'bar'} -> {font: 'baz', fontVariant: 'bar'}\n *   becomes .style.font = 'baz'\n * Removing a shorthand property (longhand gets lost too):\n *   {font: 'foo', fontVariant: 'bar'} -> {fontVariant: 'bar'}\n *   becomes .style.font = ''\n * Removing a longhand property (should revert to shorthand; doesn't):\n *   {font: 'foo', fontVariant: 'bar'} -> {font: 'foo'}\n *   becomes .style.fontVariant = ''\n */\n\n\nfunction validateShorthandPropertyCollisionInDev(styleUpdates, nextStyles) {\n  {\n    if (!nextStyles) {\n      return;\n    }\n\n    var expandedUpdates = expandShorthandMap(styleUpdates);\n    var expandedStyles = expandShorthandMap(nextStyles);\n    var warnedAbout = {};\n\n    for (var key in expandedUpdates) {\n      var originalKey = expandedUpdates[key];\n      var correctOriginalKey = expandedStyles[key];\n\n      if (correctOriginalKey && originalKey !== correctOriginalKey) {\n        var warningKey = originalKey + ',' + correctOriginalKey;\n\n        if (warnedAbout[warningKey]) {\n          continue;\n        }\n\n        warnedAbout[warningKey] = true;\n\n        error('%s a style property during rerender (%s) when a ' + 'conflicting property is set (%s) can lead to styling bugs. To ' + \"avoid this, don't mix shorthand and non-shorthand properties \" + 'for the same value; instead, replace the shorthand with ' + 'separate values.', isValueEmpty(styleUpdates[originalKey]) ? 'Removing' : 'Updating', originalKey, correctOriginalKey);\n      }\n    }\n  }\n}\n\n// For HTML, certain tags should omit their close tag. We keep a list for\n// those special-case tags.\nvar omittedCloseTags = {\n  area: true,\n  base: true,\n  br: true,\n  col: true,\n  embed: true,\n  hr: true,\n  img: true,\n  input: true,\n  keygen: true,\n  link: true,\n  meta: true,\n  param: true,\n  source: true,\n  track: true,\n  wbr: true // NOTE: menuitem's close tag should be omitted, but that causes problems.\n\n};\n\n// `omittedCloseTags` except that `menuitem` should still have its closing tag.\n\nvar voidElementTags = assign({\n  menuitem: true\n}, omittedCloseTags);\n\nvar HTML = '__html';\n\nfunction assertValidProps(tag, props) {\n  if (!props) {\n    return;\n  } // Note the use of `==` which checks for null or undefined.\n\n\n  if (voidElementTags[tag]) {\n    if (props.children != null || props.dangerouslySetInnerHTML != null) {\n      throw new Error(tag + \" is a void element tag and must neither have `children` nor \" + 'use `dangerouslySetInnerHTML`.');\n    }\n  }\n\n  if (props.dangerouslySetInnerHTML != null) {\n    if (props.children != null) {\n      throw new Error('Can only set one of `children` or `props.dangerouslySetInnerHTML`.');\n    }\n\n    if (typeof props.dangerouslySetInnerHTML !== 'object' || !(HTML in props.dangerouslySetInnerHTML)) {\n      throw new Error('`props.dangerouslySetInnerHTML` must be in the form `{__html: ...}`. ' + 'Please visit https://reactjs.org/link/dangerously-set-inner-html ' + 'for more information.');\n    }\n  }\n\n  {\n    if (!props.suppressContentEditableWarning && props.contentEditable && props.children != null) {\n      error('A component is `contentEditable` and contains `children` managed by ' + 'React. It is now your responsibility to guarantee that none of ' + 'those nodes are unexpectedly modified or duplicated. This is ' + 'probably not intentional.');\n    }\n  }\n\n  if (props.style != null && typeof props.style !== 'object') {\n    throw new Error('The `style` prop expects a mapping from style properties to values, ' + \"not a string. For example, style={{marginRight: spacing + 'em'}} when \" + 'using JSX.');\n  }\n}\n\nfunction isCustomComponent(tagName, props) {\n  if (tagName.indexOf('-') === -1) {\n    return typeof props.is === 'string';\n  }\n\n  switch (tagName) {\n    // These are reserved SVG and MathML elements.\n    // We don't mind this list too much because we expect it to never grow.\n    // The alternative is to track the namespace in a few places which is convoluted.\n    // https://w3c.github.io/webcomponents/spec/custom/#custom-elements-core-concepts\n    case 'annotation-xml':\n    case 'color-profile':\n    case 'font-face':\n    case 'font-face-src':\n    case 'font-face-uri':\n    case 'font-face-format':\n    case 'font-face-name':\n    case 'missing-glyph':\n      return false;\n\n    default:\n      return true;\n  }\n}\n\n// When adding attributes to the HTML or SVG allowed attribute list, be sure to\n// also add them to this module to ensure casing and incorrect name\n// warnings.\nvar possibleStandardNames = {\n  // HTML\n  accept: 'accept',\n  acceptcharset: 'acceptCharset',\n  'accept-charset': 'acceptCharset',\n  accesskey: 'accessKey',\n  action: 'action',\n  allowfullscreen: 'allowFullScreen',\n  alt: 'alt',\n  as: 'as',\n  async: 'async',\n  autocapitalize: 'autoCapitalize',\n  autocomplete: 'autoComplete',\n  autocorrect: 'autoCorrect',\n  autofocus: 'autoFocus',\n  autoplay: 'autoPlay',\n  autosave: 'autoSave',\n  capture: 'capture',\n  cellpadding: 'cellPadding',\n  cellspacing: 'cellSpacing',\n  challenge: 'challenge',\n  charset: 'charSet',\n  checked: 'checked',\n  children: 'children',\n  cite: 'cite',\n  class: 'className',\n  classid: 'classID',\n  classname: 'className',\n  cols: 'cols',\n  colspan: 'colSpan',\n  content: 'content',\n  contenteditable: 'contentEditable',\n  contextmenu: 'contextMenu',\n  controls: 'controls',\n  controlslist: 'controlsList',\n  coords: 'coords',\n  crossorigin: 'crossOrigin',\n  dangerouslysetinnerhtml: 'dangerouslySetInnerHTML',\n  data: 'data',\n  datetime: 'dateTime',\n  default: 'default',\n  defaultchecked: 'defaultChecked',\n  defaultvalue: 'defaultValue',\n  defer: 'defer',\n  dir: 'dir',\n  disabled: 'disabled',\n  disablepictureinpicture: 'disablePictureInPicture',\n  disableremoteplayback: 'disableRemotePlayback',\n  download: 'download',\n  draggable: 'draggable',\n  enctype: 'encType',\n  enterkeyhint: 'enterKeyHint',\n  for: 'htmlFor',\n  form: 'form',\n  formmethod: 'formMethod',\n  formaction: 'formAction',\n  formenctype: 'formEncType',\n  formnovalidate: 'formNoValidate',\n  formtarget: 'formTarget',\n  frameborder: 'frameBorder',\n  headers: 'headers',\n  height: 'height',\n  hidden: 'hidden',\n  high: 'high',\n  href: 'href',\n  hreflang: 'hrefLang',\n  htmlfor: 'htmlFor',\n  httpequiv: 'httpEquiv',\n  'http-equiv': 'httpEquiv',\n  icon: 'icon',\n  id: 'id',\n  imagesizes: 'imageSizes',\n  imagesrcset: 'imageSrcSet',\n  innerhtml: 'innerHTML',\n  inputmode: 'inputMode',\n  integrity: 'integrity',\n  is: 'is',\n  itemid: 'itemID',\n  itemprop: 'itemProp',\n  itemref: 'itemRef',\n  itemscope: 'itemScope',\n  itemtype: 'itemType',\n  keyparams: 'keyParams',\n  keytype: 'keyType',\n  kind: 'kind',\n  label: 'label',\n  lang: 'lang',\n  list: 'list',\n  loop: 'loop',\n  low: 'low',\n  manifest: 'manifest',\n  marginwidth: 'marginWidth',\n  marginheight: 'marginHeight',\n  max: 'max',\n  maxlength: 'maxLength',\n  media: 'media',\n  mediagroup: 'mediaGroup',\n  method: 'method',\n  min: 'min',\n  minlength: 'minLength',\n  multiple: 'multiple',\n  muted: 'muted',\n  name: 'name',\n  nomodule: 'noModule',\n  nonce: 'nonce',\n  novalidate: 'noValidate',\n  open: 'open',\n  optimum: 'optimum',\n  pattern: 'pattern',\n  placeholder: 'placeholder',\n  playsinline: 'playsInline',\n  poster: 'poster',\n  preload: 'preload',\n  profile: 'profile',\n  radiogroup: 'radioGroup',\n  readonly: 'readOnly',\n  referrerpolicy: 'referrerPolicy',\n  rel: 'rel',\n  required: 'required',\n  reversed: 'reversed',\n  role: 'role',\n  rows: 'rows',\n  rowspan: 'rowSpan',\n  sandbox: 'sandbox',\n  scope: 'scope',\n  scoped: 'scoped',\n  scrolling: 'scrolling',\n  seamless: 'seamless',\n  selected: 'selected',\n  shape: 'shape',\n  size: 'size',\n  sizes: 'sizes',\n  span: 'span',\n  spellcheck: 'spellCheck',\n  src: 'src',\n  srcdoc: 'srcDoc',\n  srclang: 'srcLang',\n  srcset: 'srcSet',\n  start: 'start',\n  step: 'step',\n  style: 'style',\n  summary: 'summary',\n  tabindex: 'tabIndex',\n  target: 'target',\n  title: 'title',\n  type: 'type',\n  usemap: 'useMap',\n  value: 'value',\n  width: 'width',\n  wmode: 'wmode',\n  wrap: 'wrap',\n  // SVG\n  about: 'about',\n  accentheight: 'accentHeight',\n  'accent-height': 'accentHeight',\n  accumulate: 'accumulate',\n  additive: 'additive',\n  alignmentbaseline: 'alignmentBaseline',\n  'alignment-baseline': 'alignmentBaseline',\n  allowreorder: 'allowReorder',\n  alphabetic: 'alphabetic',\n  amplitude: 'amplitude',\n  arabicform: 'arabicForm',\n  'arabic-form': 'arabicForm',\n  ascent: 'ascent',\n  attributename: 'attributeName',\n  attributetype: 'attributeType',\n  autoreverse: 'autoReverse',\n  azimuth: 'azimuth',\n  basefrequency: 'baseFrequency',\n  baselineshift: 'baselineShift',\n  'baseline-shift': 'baselineShift',\n  baseprofile: 'baseProfile',\n  bbox: 'bbox',\n  begin: 'begin',\n  bias: 'bias',\n  by: 'by',\n  calcmode: 'calcMode',\n  capheight: 'capHeight',\n  'cap-height': 'capHeight',\n  clip: 'clip',\n  clippath: 'clipPath',\n  'clip-path': 'clipPath',\n  clippathunits: 'clipPathUnits',\n  cliprule: 'clipRule',\n  'clip-rule': 'clipRule',\n  color: 'color',\n  colorinterpolation: 'colorInterpolation',\n  'color-interpolation': 'colorInterpolation',\n  colorinterpolationfilters: 'colorInterpolationFilters',\n  'color-interpolation-filters': 'colorInterpolationFilters',\n  colorprofile: 'colorProfile',\n  'color-profile': 'colorProfile',\n  colorrendering: 'colorRendering',\n  'color-rendering': 'colorRendering',\n  contentscripttype: 'contentScriptType',\n  contentstyletype: 'contentStyleType',\n  cursor: 'cursor',\n  cx: 'cx',\n  cy: 'cy',\n  d: 'd',\n  datatype: 'datatype',\n  decelerate: 'decelerate',\n  descent: 'descent',\n  diffuseconstant: 'diffuseConstant',\n  direction: 'direction',\n  display: 'display',\n  divisor: 'divisor',\n  dominantbaseline: 'dominantBaseline',\n  'dominant-baseline': 'dominantBaseline',\n  dur: 'dur',\n  dx: 'dx',\n  dy: 'dy',\n  edgemode: 'edgeMode',\n  elevation: 'elevation',\n  enablebackground: 'enableBackground',\n  'enable-background': 'enableBackground',\n  end: 'end',\n  exponent: 'exponent',\n  externalresourcesrequired: 'externalResourcesRequired',\n  fill: 'fill',\n  fillopacity: 'fillOpacity',\n  'fill-opacity': 'fillOpacity',\n  fillrule: 'fillRule',\n  'fill-rule': 'fillRule',\n  filter: 'filter',\n  filterres: 'filterRes',\n  filterunits: 'filterUnits',\n  floodopacity: 'floodOpacity',\n  'flood-opacity': 'floodOpacity',\n  floodcolor: 'floodColor',\n  'flood-color': 'floodColor',\n  focusable: 'focusable',\n  fontfamily: 'fontFamily',\n  'font-family': 'fontFamily',\n  fontsize: 'fontSize',\n  'font-size': 'fontSize',\n  fontsizeadjust: 'fontSizeAdjust',\n  'font-size-adjust': 'fontSizeAdjust',\n  fontstretch: 'fontStretch',\n  'font-stretch': 'fontStretch',\n  fontstyle: 'fontStyle',\n  'font-style': 'fontStyle',\n  fontvariant: 'fontVariant',\n  'font-variant': 'fontVariant',\n  fontweight: 'fontWeight',\n  'font-weight': 'fontWeight',\n  format: 'format',\n  from: 'from',\n  fx: 'fx',\n  fy: 'fy',\n  g1: 'g1',\n  g2: 'g2',\n  glyphname: 'glyphName',\n  'glyph-name': 'glyphName',\n  glyphorientationhorizontal: 'glyphOrientationHorizontal',\n  'glyph-orientation-horizontal': 'glyphOrientationHorizontal',\n  glyphorientationvertical: 'glyphOrientationVertical',\n  'glyph-orientation-vertical': 'glyphOrientationVertical',\n  glyphref: 'glyphRef',\n  gradienttransform: 'gradientTransform',\n  gradientunits: 'gradientUnits',\n  hanging: 'hanging',\n  horizadvx: 'horizAdvX',\n  'horiz-adv-x': 'horizAdvX',\n  horizoriginx: 'horizOriginX',\n  'horiz-origin-x': 'horizOriginX',\n  ideographic: 'ideographic',\n  imagerendering: 'imageRendering',\n  'image-rendering': 'imageRendering',\n  in2: 'in2',\n  in: 'in',\n  inlist: 'inlist',\n  intercept: 'intercept',\n  k1: 'k1',\n  k2: 'k2',\n  k3: 'k3',\n  k4: 'k4',\n  k: 'k',\n  kernelmatrix: 'kernelMatrix',\n  kernelunitlength: 'kernelUnitLength',\n  kerning: 'kerning',\n  keypoints: 'keyPoints',\n  keysplines: 'keySplines',\n  keytimes: 'keyTimes',\n  lengthadjust: 'lengthAdjust',\n  letterspacing: 'letterSpacing',\n  'letter-spacing': 'letterSpacing',\n  lightingcolor: 'lightingColor',\n  'lighting-color': 'lightingColor',\n  limitingconeangle: 'limitingConeAngle',\n  local: 'local',\n  markerend: 'markerEnd',\n  'marker-end': 'markerEnd',\n  markerheight: 'markerHeight',\n  markermid: 'markerMid',\n  'marker-mid': 'markerMid',\n  markerstart: 'markerStart',\n  'marker-start': 'markerStart',\n  markerunits: 'markerUnits',\n  markerwidth: 'markerWidth',\n  mask: 'mask',\n  maskcontentunits: 'maskContentUnits',\n  maskunits: 'maskUnits',\n  mathematical: 'mathematical',\n  mode: 'mode',\n  numoctaves: 'numOctaves',\n  offset: 'offset',\n  opacity: 'opacity',\n  operator: 'operator',\n  order: 'order',\n  orient: 'orient',\n  orientation: 'orientation',\n  origin: 'origin',\n  overflow: 'overflow',\n  overlineposition: 'overlinePosition',\n  'overline-position': 'overlinePosition',\n  overlinethickness: 'overlineThickness',\n  'overline-thickness': 'overlineThickness',\n  paintorder: 'paintOrder',\n  'paint-order': 'paintOrder',\n  panose1: 'panose1',\n  'panose-1': 'panose1',\n  pathlength: 'pathLength',\n  patterncontentunits: 'patternContentUnits',\n  patterntransform: 'patternTransform',\n  patternunits: 'patternUnits',\n  pointerevents: 'pointerEvents',\n  'pointer-events': 'pointerEvents',\n  points: 'points',\n  pointsatx: 'pointsAtX',\n  pointsaty: 'pointsAtY',\n  pointsatz: 'pointsAtZ',\n  prefix: 'prefix',\n  preservealpha: 'preserveAlpha',\n  preserveaspectratio: 'preserveAspectRatio',\n  primitiveunits: 'primitiveUnits',\n  property: 'property',\n  r: 'r',\n  radius: 'radius',\n  refx: 'refX',\n  refy: 'refY',\n  renderingintent: 'renderingIntent',\n  'rendering-intent': 'renderingIntent',\n  repeatcount: 'repeatCount',\n  repeatdur: 'repeatDur',\n  requiredextensions: 'requiredExtensions',\n  requiredfeatures: 'requiredFeatures',\n  resource: 'resource',\n  restart: 'restart',\n  result: 'result',\n  results: 'results',\n  rotate: 'rotate',\n  rx: 'rx',\n  ry: 'ry',\n  scale: 'scale',\n  security: 'security',\n  seed: 'seed',\n  shaperendering: 'shapeRendering',\n  'shape-rendering': 'shapeRendering',\n  slope: 'slope',\n  spacing: 'spacing',\n  specularconstant: 'specularConstant',\n  specularexponent: 'specularExponent',\n  speed: 'speed',\n  spreadmethod: 'spreadMethod',\n  startoffset: 'startOffset',\n  stddeviation: 'stdDeviation',\n  stemh: 'stemh',\n  stemv: 'stemv',\n  stitchtiles: 'stitchTiles',\n  stopcolor: 'stopColor',\n  'stop-color': 'stopColor',\n  stopopacity: 'stopOpacity',\n  'stop-opacity': 'stopOpacity',\n  strikethroughposition: 'strikethroughPosition',\n  'strikethrough-position': 'strikethroughPosition',\n  strikethroughthickness: 'strikethroughThickness',\n  'strikethrough-thickness': 'strikethroughThickness',\n  string: 'string',\n  stroke: 'stroke',\n  strokedasharray: 'strokeDasharray',\n  'stroke-dasharray': 'strokeDasharray',\n  strokedashoffset: 'strokeDashoffset',\n  'stroke-dashoffset': 'strokeDashoffset',\n  strokelinecap: 'strokeLinecap',\n  'stroke-linecap': 'strokeLinecap',\n  strokelinejoin: 'strokeLinejoin',\n  'stroke-linejoin': 'strokeLinejoin',\n  strokemiterlimit: 'strokeMiterlimit',\n  'stroke-miterlimit': 'strokeMiterlimit',\n  strokewidth: 'strokeWidth',\n  'stroke-width': 'strokeWidth',\n  strokeopacity: 'strokeOpacity',\n  'stroke-opacity': 'strokeOpacity',\n  suppresscontenteditablewarning: 'suppressContentEditableWarning',\n  suppresshydrationwarning: 'suppressHydrationWarning',\n  surfacescale: 'surfaceScale',\n  systemlanguage: 'systemLanguage',\n  tablevalues: 'tableValues',\n  targetx: 'targetX',\n  targety: 'targetY',\n  textanchor: 'textAnchor',\n  'text-anchor': 'textAnchor',\n  textdecoration: 'textDecoration',\n  'text-decoration': 'textDecoration',\n  textlength: 'textLength',\n  textrendering: 'textRendering',\n  'text-rendering': 'textRendering',\n  to: 'to',\n  transform: 'transform',\n  typeof: 'typeof',\n  u1: 'u1',\n  u2: 'u2',\n  underlineposition: 'underlinePosition',\n  'underline-position': 'underlinePosition',\n  underlinethickness: 'underlineThickness',\n  'underline-thickness': 'underlineThickness',\n  unicode: 'unicode',\n  unicodebidi: 'unicodeBidi',\n  'unicode-bidi': 'unicodeBidi',\n  unicoderange: 'unicodeRange',\n  'unicode-range': 'unicodeRange',\n  unitsperem: 'unitsPerEm',\n  'units-per-em': 'unitsPerEm',\n  unselectable: 'unselectable',\n  valphabetic: 'vAlphabetic',\n  'v-alphabetic': 'vAlphabetic',\n  values: 'values',\n  vectoreffect: 'vectorEffect',\n  'vector-effect': 'vectorEffect',\n  version: 'version',\n  vertadvy: 'vertAdvY',\n  'vert-adv-y': 'vertAdvY',\n  vertoriginx: 'vertOriginX',\n  'vert-origin-x': 'vertOriginX',\n  vertoriginy: 'vertOriginY',\n  'vert-origin-y': 'vertOriginY',\n  vhanging: 'vHanging',\n  'v-hanging': 'vHanging',\n  videographic: 'vIdeographic',\n  'v-ideographic': 'vIdeographic',\n  viewbox: 'viewBox',\n  viewtarget: 'viewTarget',\n  visibility: 'visibility',\n  vmathematical: 'vMathematical',\n  'v-mathematical': 'vMathematical',\n  vocab: 'vocab',\n  widths: 'widths',\n  wordspacing: 'wordSpacing',\n  'word-spacing': 'wordSpacing',\n  writingmode: 'writingMode',\n  'writing-mode': 'writingMode',\n  x1: 'x1',\n  x2: 'x2',\n  x: 'x',\n  xchannelselector: 'xChannelSelector',\n  xheight: 'xHeight',\n  'x-height': 'xHeight',\n  xlinkactuate: 'xlinkActuate',\n  'xlink:actuate': 'xlinkActuate',\n  xlinkarcrole: 'xlinkArcrole',\n  'xlink:arcrole': 'xlinkArcrole',\n  xlinkhref: 'xlinkHref',\n  'xlink:href': 'xlinkHref',\n  xlinkrole: 'xlinkRole',\n  'xlink:role': 'xlinkRole',\n  xlinkshow: 'xlinkShow',\n  'xlink:show': 'xlinkShow',\n  xlinktitle: 'xlinkTitle',\n  'xlink:title': 'xlinkTitle',\n  xlinktype: 'xlinkType',\n  'xlink:type': 'xlinkType',\n  xmlbase: 'xmlBase',\n  'xml:base': 'xmlBase',\n  xmllang: 'xmlLang',\n  'xml:lang': 'xmlLang',\n  xmlns: 'xmlns',\n  'xml:space': 'xmlSpace',\n  xmlnsxlink: 'xmlnsXlink',\n  'xmlns:xlink': 'xmlnsXlink',\n  xmlspace: 'xmlSpace',\n  y1: 'y1',\n  y2: 'y2',\n  y: 'y',\n  ychannelselector: 'yChannelSelector',\n  z: 'z',\n  zoomandpan: 'zoomAndPan'\n};\n\nvar ariaProperties = {\n  'aria-current': 0,\n  // state\n  'aria-description': 0,\n  'aria-details': 0,\n  'aria-disabled': 0,\n  // state\n  'aria-hidden': 0,\n  // state\n  'aria-invalid': 0,\n  // state\n  'aria-keyshortcuts': 0,\n  'aria-label': 0,\n  'aria-roledescription': 0,\n  // Widget Attributes\n  'aria-autocomplete': 0,\n  'aria-checked': 0,\n  'aria-expanded': 0,\n  'aria-haspopup': 0,\n  'aria-level': 0,\n  'aria-modal': 0,\n  'aria-multiline': 0,\n  'aria-multiselectable': 0,\n  'aria-orientation': 0,\n  'aria-placeholder': 0,\n  'aria-pressed': 0,\n  'aria-readonly': 0,\n  'aria-required': 0,\n  'aria-selected': 0,\n  'aria-sort': 0,\n  'aria-valuemax': 0,\n  'aria-valuemin': 0,\n  'aria-valuenow': 0,\n  'aria-valuetext': 0,\n  // Live Region Attributes\n  'aria-atomic': 0,\n  'aria-busy': 0,\n  'aria-live': 0,\n  'aria-relevant': 0,\n  // Drag-and-Drop Attributes\n  'aria-dropeffect': 0,\n  'aria-grabbed': 0,\n  // Relationship Attributes\n  'aria-activedescendant': 0,\n  'aria-colcount': 0,\n  'aria-colindex': 0,\n  'aria-colspan': 0,\n  'aria-controls': 0,\n  'aria-describedby': 0,\n  'aria-errormessage': 0,\n  'aria-flowto': 0,\n  'aria-labelledby': 0,\n  'aria-owns': 0,\n  'aria-posinset': 0,\n  'aria-rowcount': 0,\n  'aria-rowindex': 0,\n  'aria-rowspan': 0,\n  'aria-setsize': 0\n};\n\nvar warnedProperties = {};\nvar rARIA = new RegExp('^(aria)-[' + ATTRIBUTE_NAME_CHAR + ']*$');\nvar rARIACamel = new RegExp('^(aria)[A-Z][' + ATTRIBUTE_NAME_CHAR + ']*$');\n\nfunction validateProperty(tagName, name) {\n  {\n    if (hasOwnProperty.call(warnedProperties, name) && warnedProperties[name]) {\n      return true;\n    }\n\n    if (rARIACamel.test(name)) {\n      var ariaName = 'aria-' + name.slice(4).toLowerCase();\n      var correctName = ariaProperties.hasOwnProperty(ariaName) ? ariaName : null; // If this is an aria-* attribute, but is not listed in the known DOM\n      // DOM properties, then it is an invalid aria-* attribute.\n\n      if (correctName == null) {\n        error('Invalid ARIA attribute `%s`. ARIA attributes follow the pattern aria-* and must be lowercase.', name);\n\n        warnedProperties[name] = true;\n        return true;\n      } // aria-* attributes should be lowercase; suggest the lowercase version.\n\n\n      if (name !== correctName) {\n        error('Invalid ARIA attribute `%s`. Did you mean `%s`?', name, correctName);\n\n        warnedProperties[name] = true;\n        return true;\n      }\n    }\n\n    if (rARIA.test(name)) {\n      var lowerCasedName = name.toLowerCase();\n      var standardName = ariaProperties.hasOwnProperty(lowerCasedName) ? lowerCasedName : null; // If this is an aria-* attribute, but is not listed in the known DOM\n      // DOM properties, then it is an invalid aria-* attribute.\n\n      if (standardName == null) {\n        warnedProperties[name] = true;\n        return false;\n      } // aria-* attributes should be lowercase; suggest the lowercase version.\n\n\n      if (name !== standardName) {\n        error('Unknown ARIA attribute `%s`. Did you mean `%s`?', name, standardName);\n\n        warnedProperties[name] = true;\n        return true;\n      }\n    }\n  }\n\n  return true;\n}\n\nfunction warnInvalidARIAProps(type, props) {\n  {\n    var invalidProps = [];\n\n    for (var key in props) {\n      var isValid = validateProperty(type, key);\n\n      if (!isValid) {\n        invalidProps.push(key);\n      }\n    }\n\n    var unknownPropString = invalidProps.map(function (prop) {\n      return '`' + prop + '`';\n    }).join(', ');\n\n    if (invalidProps.length === 1) {\n      error('Invalid aria prop %s on <%s> tag. ' + 'For details, see https://reactjs.org/link/invalid-aria-props', unknownPropString, type);\n    } else if (invalidProps.length > 1) {\n      error('Invalid aria props %s on <%s> tag. ' + 'For details, see https://reactjs.org/link/invalid-aria-props', unknownPropString, type);\n    }\n  }\n}\n\nfunction validateProperties(type, props) {\n  if (isCustomComponent(type, props)) {\n    return;\n  }\n\n  warnInvalidARIAProps(type, props);\n}\n\nvar didWarnValueNull = false;\nfunction validateProperties$1(type, props) {\n  {\n    if (type !== 'input' && type !== 'textarea' && type !== 'select') {\n      return;\n    }\n\n    if (props != null && props.value === null && !didWarnValueNull) {\n      didWarnValueNull = true;\n\n      if (type === 'select' && props.multiple) {\n        error('`value` prop on `%s` should not be null. ' + 'Consider using an empty array when `multiple` is set to `true` ' + 'to clear the component or `undefined` for uncontrolled components.', type);\n      } else {\n        error('`value` prop on `%s` should not be null. ' + 'Consider using an empty string to clear the component or `undefined` ' + 'for uncontrolled components.', type);\n      }\n    }\n  }\n}\n\nvar validateProperty$1 = function () {};\n\n{\n  var warnedProperties$1 = {};\n  var EVENT_NAME_REGEX = /^on./;\n  var INVALID_EVENT_NAME_REGEX = /^on[^A-Z]/;\n  var rARIA$1 = new RegExp('^(aria)-[' + ATTRIBUTE_NAME_CHAR + ']*$');\n  var rARIACamel$1 = new RegExp('^(aria)[A-Z][' + ATTRIBUTE_NAME_CHAR + ']*$');\n\n  validateProperty$1 = function (tagName, name, value, eventRegistry) {\n    if (hasOwnProperty.call(warnedProperties$1, name) && warnedProperties$1[name]) {\n      return true;\n    }\n\n    var lowerCasedName = name.toLowerCase();\n\n    if (lowerCasedName === 'onfocusin' || lowerCasedName === 'onfocusout') {\n      error('React uses onFocus and onBlur instead of onFocusIn and onFocusOut. ' + 'All React events are normalized to bubble, so onFocusIn and onFocusOut ' + 'are not needed/supported by React.');\n\n      warnedProperties$1[name] = true;\n      return true;\n    } // We can't rely on the event system being injected on the server.\n\n\n    if (eventRegistry != null) {\n      var registrationNameDependencies = eventRegistry.registrationNameDependencies,\n          possibleRegistrationNames = eventRegistry.possibleRegistrationNames;\n\n      if (registrationNameDependencies.hasOwnProperty(name)) {\n        return true;\n      }\n\n      var registrationName = possibleRegistrationNames.hasOwnProperty(lowerCasedName) ? possibleRegistrationNames[lowerCasedName] : null;\n\n      if (registrationName != null) {\n        error('Invalid event handler property `%s`. Did you mean `%s`?', name, registrationName);\n\n        warnedProperties$1[name] = true;\n        return true;\n      }\n\n      if (EVENT_NAME_REGEX.test(name)) {\n        error('Unknown event handler property `%s`. It will be ignored.', name);\n\n        warnedProperties$1[name] = true;\n        return true;\n      }\n    } else if (EVENT_NAME_REGEX.test(name)) {\n      // If no event plugins have been injected, we are in a server environment.\n      // So we can't tell if the event name is correct for sure, but we can filter\n      // out known bad ones like `onclick`. We can't suggest a specific replacement though.\n      if (INVALID_EVENT_NAME_REGEX.test(name)) {\n        error('Invalid event handler property `%s`. ' + 'React events use the camelCase naming convention, for example `onClick`.', name);\n      }\n\n      warnedProperties$1[name] = true;\n      return true;\n    } // Let the ARIA attribute hook validate ARIA attributes\n\n\n    if (rARIA$1.test(name) || rARIACamel$1.test(name)) {\n      return true;\n    }\n\n    if (lowerCasedName === 'innerhtml') {\n      error('Directly setting property `innerHTML` is not permitted. ' + 'For more information, lookup documentation on `dangerouslySetInnerHTML`.');\n\n      warnedProperties$1[name] = true;\n      return true;\n    }\n\n    if (lowerCasedName === 'aria') {\n      error('The `aria` attribute is reserved for future use in React. ' + 'Pass individual `aria-` attributes instead.');\n\n      warnedProperties$1[name] = true;\n      return true;\n    }\n\n    if (lowerCasedName === 'is' && value !== null && value !== undefined && typeof value !== 'string') {\n      error('Received a `%s` for a string attribute `is`. If this is expected, cast ' + 'the value to a string.', typeof value);\n\n      warnedProperties$1[name] = true;\n      return true;\n    }\n\n    if (typeof value === 'number' && isNaN(value)) {\n      error('Received NaN for the `%s` attribute. If this is expected, cast ' + 'the value to a string.', name);\n\n      warnedProperties$1[name] = true;\n      return true;\n    }\n\n    var propertyInfo = getPropertyInfo(name);\n    var isReserved = propertyInfo !== null && propertyInfo.type === RESERVED; // Known attributes should match the casing specified in the property config.\n\n    if (possibleStandardNames.hasOwnProperty(lowerCasedName)) {\n      var standardName = possibleStandardNames[lowerCasedName];\n\n      if (standardName !== name) {\n        error('Invalid DOM property `%s`. Did you mean `%s`?', name, standardName);\n\n        warnedProperties$1[name] = true;\n        return true;\n      }\n    } else if (!isReserved && name !== lowerCasedName) {\n      // Unknown attributes should have lowercase casing since that's how they\n      // will be cased anyway with server rendering.\n      error('React does not recognize the `%s` prop on a DOM element. If you ' + 'intentionally want it to appear in the DOM as a custom ' + 'attribute, spell it as lowercase `%s` instead. ' + 'If you accidentally passed it from a parent component, remove ' + 'it from the DOM element.', name, lowerCasedName);\n\n      warnedProperties$1[name] = true;\n      return true;\n    }\n\n    if (typeof value === 'boolean' && shouldRemoveAttributeWithWarning(name, value, propertyInfo, false)) {\n      if (value) {\n        error('Received `%s` for a non-boolean attribute `%s`.\\n\\n' + 'If you want to write it to the DOM, pass a string instead: ' + '%s=\"%s\" or %s={value.toString()}.', value, name, name, value, name);\n      } else {\n        error('Received `%s` for a non-boolean attribute `%s`.\\n\\n' + 'If you want to write it to the DOM, pass a string instead: ' + '%s=\"%s\" or %s={value.toString()}.\\n\\n' + 'If you used to conditionally omit it with %s={condition && value}, ' + 'pass %s={condition ? value : undefined} instead.', value, name, name, value, name, name, name);\n      }\n\n      warnedProperties$1[name] = true;\n      return true;\n    } // Now that we've validated casing, do not validate\n    // data types for reserved props\n\n\n    if (isReserved) {\n      return true;\n    } // Warn when a known attribute is a bad type\n\n\n    if (shouldRemoveAttributeWithWarning(name, value, propertyInfo, false)) {\n      warnedProperties$1[name] = true;\n      return false;\n    } // Warn when passing the strings 'false' or 'true' into a boolean prop\n\n\n    if ((value === 'false' || value === 'true') && propertyInfo !== null && propertyInfo.type === BOOLEAN) {\n      error('Received the string `%s` for the boolean attribute `%s`. ' + '%s ' + 'Did you mean %s={%s}?', value, name, value === 'false' ? 'The browser will interpret it as a truthy value.' : 'Although this works, it will not work as expected if you pass the string \"false\".', name, value);\n\n      warnedProperties$1[name] = true;\n      return true;\n    }\n\n    return true;\n  };\n}\n\nvar warnUnknownProperties = function (type, props, eventRegistry) {\n  {\n    var unknownProps = [];\n\n    for (var key in props) {\n      var isValid = validateProperty$1(type, key, props[key], eventRegistry);\n\n      if (!isValid) {\n        unknownProps.push(key);\n      }\n    }\n\n    var unknownPropString = unknownProps.map(function (prop) {\n      return '`' + prop + '`';\n    }).join(', ');\n\n    if (unknownProps.length === 1) {\n      error('Invalid value for prop %s on <%s> tag. Either remove it from the element, ' + 'or pass a string or number value to keep it in the DOM. ' + 'For details, see https://reactjs.org/link/attribute-behavior ', unknownPropString, type);\n    } else if (unknownProps.length > 1) {\n      error('Invalid values for props %s on <%s> tag. Either remove them from the element, ' + 'or pass a string or number value to keep them in the DOM. ' + 'For details, see https://reactjs.org/link/attribute-behavior ', unknownPropString, type);\n    }\n  }\n};\n\nfunction validateProperties$2(type, props, eventRegistry) {\n  if (isCustomComponent(type, props)) {\n    return;\n  }\n\n  warnUnknownProperties(type, props, eventRegistry);\n}\n\nvar IS_EVENT_HANDLE_NON_MANAGED_NODE = 1;\nvar IS_NON_DELEGATED = 1 << 1;\nvar IS_CAPTURE_PHASE = 1 << 2;\n// set to LEGACY_FB_SUPPORT. LEGACY_FB_SUPPORT only gets set when\n// we call willDeferLaterForLegacyFBSupport, thus not bailing out\n// will result in endless cycles like an infinite loop.\n// We also don't want to defer during event replaying.\n\nvar SHOULD_NOT_PROCESS_POLYFILL_EVENT_PLUGINS = IS_EVENT_HANDLE_NON_MANAGED_NODE | IS_NON_DELEGATED | IS_CAPTURE_PHASE;\n\n// This exists to avoid circular dependency between ReactDOMEventReplaying\n// and DOMPluginEventSystem.\nvar currentReplayingEvent = null;\nfunction setReplayingEvent(event) {\n  {\n    if (currentReplayingEvent !== null) {\n      error('Expected currently replaying event to be null. This error ' + 'is likely caused by a bug in React. Please file an issue.');\n    }\n  }\n\n  currentReplayingEvent = event;\n}\nfunction resetReplayingEvent() {\n  {\n    if (currentReplayingEvent === null) {\n      error('Expected currently replaying event to not be null. This error ' + 'is likely caused by a bug in React. Please file an issue.');\n    }\n  }\n\n  currentReplayingEvent = null;\n}\nfunction isReplayingEvent(event) {\n  return event === currentReplayingEvent;\n}\n\n/**\n * Gets the target node from a native browser event by accounting for\n * inconsistencies in browser DOM APIs.\n *\n * @param {object} nativeEvent Native browser event.\n * @return {DOMEventTarget} Target node.\n */\n\nfunction getEventTarget(nativeEvent) {\n  // Fallback to nativeEvent.srcElement for IE9\n  // https://github.com/facebook/react/issues/12506\n  var target = nativeEvent.target || nativeEvent.srcElement || window; // Normalize SVG <use> element events #4963\n\n  if (target.correspondingUseElement) {\n    target = target.correspondingUseElement;\n  } // Safari may fire events on text nodes (Node.TEXT_NODE is 3).\n  // @see http://www.quirksmode.org/js/events_properties.html\n\n\n  return target.nodeType === TEXT_NODE ? target.parentNode : target;\n}\n\nvar restoreImpl = null;\nvar restoreTarget = null;\nvar restoreQueue = null;\n\nfunction restoreStateOfTarget(target) {\n  // We perform this translation at the end of the event loop so that we\n  // always receive the correct fiber here\n  var internalInstance = getInstanceFromNode(target);\n\n  if (!internalInstance) {\n    // Unmounted\n    return;\n  }\n\n  if (typeof restoreImpl !== 'function') {\n    throw new Error('setRestoreImplementation() needs to be called to handle a target for controlled ' + 'events. This error is likely caused by a bug in React. Please file an issue.');\n  }\n\n  var stateNode = internalInstance.stateNode; // Guard against Fiber being unmounted.\n\n  if (stateNode) {\n    var _props = getFiberCurrentPropsFromNode(stateNode);\n\n    restoreImpl(internalInstance.stateNode, internalInstance.type, _props);\n  }\n}\n\nfunction setRestoreImplementation(impl) {\n  restoreImpl = impl;\n}\nfunction enqueueStateRestore(target) {\n  if (restoreTarget) {\n    if (restoreQueue) {\n      restoreQueue.push(target);\n    } else {\n      restoreQueue = [target];\n    }\n  } else {\n    restoreTarget = target;\n  }\n}\nfunction needsStateRestore() {\n  return restoreTarget !== null || restoreQueue !== null;\n}\nfunction restoreStateIfNeeded() {\n  if (!restoreTarget) {\n    return;\n  }\n\n  var target = restoreTarget;\n  var queuedTargets = restoreQueue;\n  restoreTarget = null;\n  restoreQueue = null;\n  restoreStateOfTarget(target);\n\n  if (queuedTargets) {\n    for (var i = 0; i < queuedTargets.length; i++) {\n      restoreStateOfTarget(queuedTargets[i]);\n    }\n  }\n}\n\n// the renderer. Such as when we're dispatching events or if third party\n// libraries need to call batchedUpdates. Eventually, this API will go away when\n// everything is batched by default. We'll then have a similar API to opt-out of\n// scheduled work and instead do synchronous work.\n// Defaults\n\nvar batchedUpdatesImpl = function (fn, bookkeeping) {\n  return fn(bookkeeping);\n};\n\nvar flushSyncImpl = function () {};\n\nvar isInsideEventHandler = false;\n\nfunction finishEventHandler() {\n  // Here we wait until all updates have propagated, which is important\n  // when using controlled components within layers:\n  // https://github.com/facebook/react/issues/1698\n  // Then we restore state of any controlled component.\n  var controlledComponentsHavePendingUpdates = needsStateRestore();\n\n  if (controlledComponentsHavePendingUpdates) {\n    // If a controlled event was fired, we may need to restore the state of\n    // the DOM node back to the controlled value. This is necessary when React\n    // bails out of the update without touching the DOM.\n    // TODO: Restore state in the microtask, after the discrete updates flush,\n    // instead of early flushing them here.\n    flushSyncImpl();\n    restoreStateIfNeeded();\n  }\n}\n\nfunction batchedUpdates(fn, a, b) {\n  if (isInsideEventHandler) {\n    // If we are currently inside another batch, we need to wait until it\n    // fully completes before restoring state.\n    return fn(a, b);\n  }\n\n  isInsideEventHandler = true;\n\n  try {\n    return batchedUpdatesImpl(fn, a, b);\n  } finally {\n    isInsideEventHandler = false;\n    finishEventHandler();\n  }\n} // TODO: Replace with flushSync\nfunction setBatchingImplementation(_batchedUpdatesImpl, _discreteUpdatesImpl, _flushSyncImpl) {\n  batchedUpdatesImpl = _batchedUpdatesImpl;\n  flushSyncImpl = _flushSyncImpl;\n}\n\nfunction isInteractive(tag) {\n  return tag === 'button' || tag === 'input' || tag === 'select' || tag === 'textarea';\n}\n\nfunction shouldPreventMouseEvent(name, type, props) {\n  switch (name) {\n    case 'onClick':\n    case 'onClickCapture':\n    case 'onDoubleClick':\n    case 'onDoubleClickCapture':\n    case 'onMouseDown':\n    case 'onMouseDownCapture':\n    case 'onMouseMove':\n    case 'onMouseMoveCapture':\n    case 'onMouseUp':\n    case 'onMouseUpCapture':\n    case 'onMouseEnter':\n      return !!(props.disabled && isInteractive(type));\n\n    default:\n      return false;\n  }\n}\n/**\n * @param {object} inst The instance, which is the source of events.\n * @param {string} registrationName Name of listener (e.g. `onClick`).\n * @return {?function} The stored callback.\n */\n\n\nfunction getListener(inst, registrationName) {\n  var stateNode = inst.stateNode;\n\n  if (stateNode === null) {\n    // Work in progress (ex: onload events in incremental mode).\n    return null;\n  }\n\n  var props = getFiberCurrentPropsFromNode(stateNode);\n\n  if (props === null) {\n    // Work in progress.\n    return null;\n  }\n\n  var listener = props[registrationName];\n\n  if (shouldPreventMouseEvent(registrationName, inst.type, props)) {\n    return null;\n  }\n\n  if (listener && typeof listener !== 'function') {\n    throw new Error(\"Expected `\" + registrationName + \"` listener to be a function, instead got a value of `\" + typeof listener + \"` type.\");\n  }\n\n  return listener;\n}\n\nvar passiveBrowserEventsSupported = false; // Check if browser support events with passive listeners\n// https://developer.mozilla.org/en-US/docs/Web/API/EventTarget/addEventListener#Safely_detecting_option_support\n\nif (canUseDOM) {\n  try {\n    var options = {}; // $FlowFixMe: Ignore Flow complaining about needing a value\n\n    Object.defineProperty(options, 'passive', {\n      get: function () {\n        passiveBrowserEventsSupported = true;\n      }\n    });\n    window.addEventListener('test', options, options);\n    window.removeEventListener('test', options, options);\n  } catch (e) {\n    passiveBrowserEventsSupported = false;\n  }\n}\n\nfunction invokeGuardedCallbackProd(name, func, context, a, b, c, d, e, f) {\n  var funcArgs = Array.prototype.slice.call(arguments, 3);\n\n  try {\n    func.apply(context, funcArgs);\n  } catch (error) {\n    this.onError(error);\n  }\n}\n\nvar invokeGuardedCallbackImpl = invokeGuardedCallbackProd;\n\n{\n  // In DEV mode, we swap out invokeGuardedCallback for a special version\n  // that plays more nicely with the browser's DevTools. The idea is to preserve\n  // \"Pause on exceptions\" behavior. Because React wraps all user-provided\n  // functions in invokeGuardedCallback, and the production version of\n  // invokeGuardedCallback uses a try-catch, all user exceptions are treated\n  // like caught exceptions, and the DevTools won't pause unless the developer\n  // takes the extra step of enabling pause on caught exceptions. This is\n  // unintuitive, though, because even though React has caught the error, from\n  // the developer's perspective, the error is uncaught.\n  //\n  // To preserve the expected \"Pause on exceptions\" behavior, we don't use a\n  // try-catch in DEV. Instead, we synchronously dispatch a fake event to a fake\n  // DOM node, and call the user-provided callback from inside an event handler\n  // for that fake event. If the callback throws, the error is \"captured\" using\n  // a global event handler. But because the error happens in a different\n  // event loop context, it does not interrupt the normal program flow.\n  // Effectively, this gives us try-catch behavior without actually using\n  // try-catch. Neat!\n  // Check that the browser supports the APIs we need to implement our special\n  // DEV version of invokeGuardedCallback\n  if (typeof window !== 'undefined' && typeof window.dispatchEvent === 'function' && typeof document !== 'undefined' && typeof document.createEvent === 'function') {\n    var fakeNode = document.createElement('react');\n\n    invokeGuardedCallbackImpl = function invokeGuardedCallbackDev(name, func, context, a, b, c, d, e, f) {\n      // If document doesn't exist we know for sure we will crash in this method\n      // when we call document.createEvent(). However this can cause confusing\n      // errors: https://github.com/facebook/create-react-app/issues/3482\n      // So we preemptively throw with a better message instead.\n      if (typeof document === 'undefined' || document === null) {\n        throw new Error('The `document` global was defined when React was initialized, but is not ' + 'defined anymore. This can happen in a test environment if a component ' + 'schedules an update from an asynchronous callback, but the test has already ' + 'finished running. To solve this, you can either unmount the component at ' + 'the end of your test (and ensure that any asynchronous operations get ' + 'canceled in `componentWillUnmount`), or you can change the test itself ' + 'to be asynchronous.');\n      }\n\n      var evt = document.createEvent('Event');\n      var didCall = false; // Keeps track of whether the user-provided callback threw an error. We\n      // set this to true at the beginning, then set it to false right after\n      // calling the function. If the function errors, `didError` will never be\n      // set to false. This strategy works even if the browser is flaky and\n      // fails to call our global error handler, because it doesn't rely on\n      // the error event at all.\n\n      var didError = true; // Keeps track of the value of window.event so that we can reset it\n      // during the callback to let user code access window.event in the\n      // browsers that support it.\n\n      var windowEvent = window.event; // Keeps track of the descriptor of window.event to restore it after event\n      // dispatching: https://github.com/facebook/react/issues/13688\n\n      var windowEventDescriptor = Object.getOwnPropertyDescriptor(window, 'event');\n\n      function restoreAfterDispatch() {\n        // We immediately remove the callback from event listeners so that\n        // nested `invokeGuardedCallback` calls do not clash. Otherwise, a\n        // nested call would trigger the fake event handlers of any call higher\n        // in the stack.\n        fakeNode.removeEventListener(evtType, callCallback, false); // We check for window.hasOwnProperty('event') to prevent the\n        // window.event assignment in both IE <= 10 as they throw an error\n        // \"Member not found\" in strict mode, and in Firefox which does not\n        // support window.event.\n\n        if (typeof window.event !== 'undefined' && window.hasOwnProperty('event')) {\n          window.event = windowEvent;\n        }\n      } // Create an event handler for our fake event. We will synchronously\n      // dispatch our fake event using `dispatchEvent`. Inside the handler, we\n      // call the user-provided callback.\n\n\n      var funcArgs = Array.prototype.slice.call(arguments, 3);\n\n      function callCallback() {\n        didCall = true;\n        restoreAfterDispatch();\n        func.apply(context, funcArgs);\n        didError = false;\n      } // Create a global error event handler. We use this to capture the value\n      // that was thrown. It's possible that this error handler will fire more\n      // than once; for example, if non-React code also calls `dispatchEvent`\n      // and a handler for that event throws. We should be resilient to most of\n      // those cases. Even if our error event handler fires more than once, the\n      // last error event is always used. If the callback actually does error,\n      // we know that the last error event is the correct one, because it's not\n      // possible for anything else to have happened in between our callback\n      // erroring and the code that follows the `dispatchEvent` call below. If\n      // the callback doesn't error, but the error event was fired, we know to\n      // ignore it because `didError` will be false, as described above.\n\n\n      var error; // Use this to track whether the error event is ever called.\n\n      var didSetError = false;\n      var isCrossOriginError = false;\n\n      function handleWindowError(event) {\n        error = event.error;\n        didSetError = true;\n\n        if (error === null && event.colno === 0 && event.lineno === 0) {\n          isCrossOriginError = true;\n        }\n\n        if (event.defaultPrevented) {\n          // Some other error handler has prevented default.\n          // Browsers silence the error report if this happens.\n          // We'll remember this to later decide whether to log it or not.\n          if (error != null && typeof error === 'object') {\n            try {\n              error._suppressLogging = true;\n            } catch (inner) {// Ignore.\n            }\n          }\n        }\n      } // Create a fake event type.\n\n\n      var evtType = \"react-\" + (name ? name : 'invokeguardedcallback'); // Attach our event handlers\n\n      window.addEventListener('error', handleWindowError);\n      fakeNode.addEventListener(evtType, callCallback, false); // Synchronously dispatch our fake event. If the user-provided function\n      // errors, it will trigger our global error handler.\n\n      evt.initEvent(evtType, false, false);\n      fakeNode.dispatchEvent(evt);\n\n      if (windowEventDescriptor) {\n        Object.defineProperty(window, 'event', windowEventDescriptor);\n      }\n\n      if (didCall && didError) {\n        if (!didSetError) {\n          // The callback errored, but the error event never fired.\n          // eslint-disable-next-line react-internal/prod-error-codes\n          error = new Error('An error was thrown inside one of your components, but React ' + \"doesn't know what it was. This is likely due to browser \" + 'flakiness. React does its best to preserve the \"Pause on ' + 'exceptions\" behavior of the DevTools, which requires some ' + \"DEV-mode only tricks. It's possible that these don't work in \" + 'your browser. Try triggering the error in production mode, ' + 'or switching to a modern browser. If you suspect that this is ' + 'actually an issue with React, please file an issue.');\n        } else if (isCrossOriginError) {\n          // eslint-disable-next-line react-internal/prod-error-codes\n          error = new Error(\"A cross-origin error was thrown. React doesn't have access to \" + 'the actual error object in development. ' + 'See https://reactjs.org/link/crossorigin-error for more information.');\n        }\n\n        this.onError(error);\n      } // Remove our event listeners\n\n\n      window.removeEventListener('error', handleWindowError);\n\n      if (!didCall) {\n        // Something went really wrong, and our event was not dispatched.\n        // https://github.com/facebook/react/issues/16734\n        // https://github.com/facebook/react/issues/16585\n        // Fall back to the production implementation.\n        restoreAfterDispatch();\n        return invokeGuardedCallbackProd.apply(this, arguments);\n      }\n    };\n  }\n}\n\nvar invokeGuardedCallbackImpl$1 = invokeGuardedCallbackImpl;\n\nvar hasError = false;\nvar caughtError = null; // Used by event system to capture/rethrow the first error.\n\nvar hasRethrowError = false;\nvar rethrowError = null;\nvar reporter = {\n  onError: function (error) {\n    hasError = true;\n    caughtError = error;\n  }\n};\n/**\n * Call a function while guarding against errors that happens within it.\n * Returns an error if it throws, otherwise null.\n *\n * In production, this is implemented using a try-catch. The reason we don't\n * use a try-catch directly is so that we can swap out a different\n * implementation in DEV mode.\n *\n * @param {String} name of the guard to use for logging or debugging\n * @param {Function} func The function to invoke\n * @param {*} context The context to use when calling the function\n * @param {...*} args Arguments for function\n */\n\nfunction invokeGuardedCallback(name, func, context, a, b, c, d, e, f) {\n  hasError = false;\n  caughtError = null;\n  invokeGuardedCallbackImpl$1.apply(reporter, arguments);\n}\n/**\n * Same as invokeGuardedCallback, but instead of returning an error, it stores\n * it in a global so it can be rethrown by `rethrowCaughtError` later.\n * TODO: See if caughtError and rethrowError can be unified.\n *\n * @param {String} name of the guard to use for logging or debugging\n * @param {Function} func The function to invoke\n * @param {*} context The context to use when calling the function\n * @param {...*} args Arguments for function\n */\n\nfunction invokeGuardedCallbackAndCatchFirstError(name, func, context, a, b, c, d, e, f) {\n  invokeGuardedCallback.apply(this, arguments);\n\n  if (hasError) {\n    var error = clearCaughtError();\n\n    if (!hasRethrowError) {\n      hasRethrowError = true;\n      rethrowError = error;\n    }\n  }\n}\n/**\n * During execution of guarded functions we will capture the first error which\n * we will rethrow to be handled by the top level error handler.\n */\n\nfunction rethrowCaughtError() {\n  if (hasRethrowError) {\n    var error = rethrowError;\n    hasRethrowError = false;\n    rethrowError = null;\n    throw error;\n  }\n}\nfunction hasCaughtError() {\n  return hasError;\n}\nfunction clearCaughtError() {\n  if (hasError) {\n    var error = caughtError;\n    hasError = false;\n    caughtError = null;\n    return error;\n  } else {\n    throw new Error('clearCaughtError was called but no error was captured. This error ' + 'is likely caused by a bug in React. Please file an issue.');\n  }\n}\n\n/**\n * `ReactInstanceMap` maintains a mapping from a public facing stateful\n * instance (key) and the internal representation (value). This allows public\n * methods to accept the user facing instance as an argument and map them back\n * to internal methods.\n *\n * Note that this module is currently shared and assumed to be stateless.\n * If this becomes an actual Map, that will break.\n */\nfunction get(key) {\n  return key._reactInternals;\n}\nfunction has(key) {\n  return key._reactInternals !== undefined;\n}\nfunction set(key, value) {\n  key._reactInternals = value;\n}\n\n// Don't change these two values. They're used by React Dev Tools.\nvar NoFlags =\n/*                      */\n0;\nvar PerformedWork =\n/*                */\n1; // You can change the rest (and add more).\n\nvar Placement =\n/*                    */\n2;\nvar Update =\n/*                       */\n4;\nvar ChildDeletion =\n/*                */\n16;\nvar ContentReset =\n/*                 */\n32;\nvar Callback =\n/*                     */\n64;\nvar DidCapture =\n/*                   */\n128;\nvar ForceClientRender =\n/*            */\n256;\nvar Ref =\n/*                          */\n512;\nvar Snapshot =\n/*                     */\n1024;\nvar Passive =\n/*                      */\n2048;\nvar Hydrating =\n/*                    */\n4096;\nvar Visibility =\n/*                   */\n8192;\nvar StoreConsistency =\n/*             */\n16384;\nvar LifecycleEffectMask = Passive | Update | Callback | Ref | Snapshot | StoreConsistency; // Union of all commit flags (flags with the lifetime of a particular commit)\n\nvar HostEffectMask =\n/*               */\n32767; // These are not really side effects, but we still reuse this field.\n\nvar Incomplete =\n/*                   */\n32768;\nvar ShouldCapture =\n/*                */\n65536;\nvar ForceUpdateForLegacySuspense =\n/* */\n131072;\nvar Forked =\n/*                       */\n1048576; // Static tags describe aspects of a fiber that are not specific to a render,\n// e.g. a fiber uses a passive effect (even if there are no updates on this particular render).\n// This enables us to defer more work in the unmount case,\n// since we can defer traversing the tree during layout to look for Passive effects,\n// and instead rely on the static flag as a signal that there may be cleanup work.\n\nvar RefStatic =\n/*                    */\n2097152;\nvar LayoutStatic =\n/*                 */\n4194304;\nvar PassiveStatic =\n/*                */\n8388608; // These flags allow us to traverse to fibers that have effects on mount\n// without traversing the entire tree after every commit for\n// double invoking\n\nvar MountLayoutDev =\n/*               */\n16777216;\nvar MountPassiveDev =\n/*              */\n33554432; // Groups of flags that are used in the commit phase to skip over trees that\n// don't contain effects, by checking subtreeFlags.\n\nvar BeforeMutationMask = // TODO: Remove Update flag from before mutation phase by re-landing Visibility\n// flag logic (see #20043)\nUpdate | Snapshot | ( 0);\nvar MutationMask = Placement | Update | ChildDeletion | ContentReset | Ref | Hydrating | Visibility;\nvar LayoutMask = Update | Callback | Ref | Visibility; // TODO: Split into PassiveMountMask and PassiveUnmountMask\n\nvar PassiveMask = Passive | ChildDeletion; // Union of tags that don't get reset on clones.\n// This allows certain concepts to persist without recalculating them,\n// e.g. whether a subtree contains passive effects or portals.\n\nvar StaticMask = LayoutStatic | PassiveStatic | RefStatic;\n\nvar ReactCurrentOwner = ReactSharedInternals.ReactCurrentOwner;\nfunction getNearestMountedFiber(fiber) {\n  var node = fiber;\n  var nearestMounted = fiber;\n\n  if (!fiber.alternate) {\n    // If there is no alternate, this might be a new tree that isn't inserted\n    // yet. If it is, then it will have a pending insertion effect on it.\n    var nextNode = node;\n\n    do {\n      node = nextNode;\n\n      if ((node.flags & (Placement | Hydrating)) !== NoFlags) {\n        // This is an insertion or in-progress hydration. The nearest possible\n        // mounted fiber is the parent but we need to continue to figure out\n        // if that one is still mounted.\n        nearestMounted = node.return;\n      }\n\n      nextNode = node.return;\n    } while (nextNode);\n  } else {\n    while (node.return) {\n      node = node.return;\n    }\n  }\n\n  if (node.tag === HostRoot) {\n    // TODO: Check if this was a nested HostRoot when used with\n    // renderContainerIntoSubtree.\n    return nearestMounted;\n  } // If we didn't hit the root, that means that we're in an disconnected tree\n  // that has been unmounted.\n\n\n  return null;\n}\nfunction getSuspenseInstanceFromFiber(fiber) {\n  if (fiber.tag === SuspenseComponent) {\n    var suspenseState = fiber.memoizedState;\n\n    if (suspenseState === null) {\n      var current = fiber.alternate;\n\n      if (current !== null) {\n        suspenseState = current.memoizedState;\n      }\n    }\n\n    if (suspenseState !== null) {\n      return suspenseState.dehydrated;\n    }\n  }\n\n  return null;\n}\nfunction getContainerFromFiber(fiber) {\n  return fiber.tag === HostRoot ? fiber.stateNode.containerInfo : null;\n}\nfunction isFiberMounted(fiber) {\n  return getNearestMountedFiber(fiber) === fiber;\n}\nfunction isMounted(component) {\n  {\n    var owner = ReactCurrentOwner.current;\n\n    if (owner !== null && owner.tag === ClassComponent) {\n      var ownerFiber = owner;\n      var instance = ownerFiber.stateNode;\n\n      if (!instance._warnedAboutRefsInRender) {\n        error('%s is accessing isMounted inside its render() function. ' + 'render() should be a pure function of props and state. It should ' + 'never access something that requires stale data from the previous ' + 'render, such as refs. Move this logic to componentDidMount and ' + 'componentDidUpdate instead.', getComponentNameFromFiber(ownerFiber) || 'A component');\n      }\n\n      instance._warnedAboutRefsInRender = true;\n    }\n  }\n\n  var fiber = get(component);\n\n  if (!fiber) {\n    return false;\n  }\n\n  return getNearestMountedFiber(fiber) === fiber;\n}\n\nfunction assertIsMounted(fiber) {\n  if (getNearestMountedFiber(fiber) !== fiber) {\n    throw new Error('Unable to find node on an unmounted component.');\n  }\n}\n\nfunction findCurrentFiberUsingSlowPath(fiber) {\n  var alternate = fiber.alternate;\n\n  if (!alternate) {\n    // If there is no alternate, then we only need to check if it is mounted.\n    var nearestMounted = getNearestMountedFiber(fiber);\n\n    if (nearestMounted === null) {\n      throw new Error('Unable to find node on an unmounted component.');\n    }\n\n    if (nearestMounted !== fiber) {\n      return null;\n    }\n\n    return fiber;\n  } // If we have two possible branches, we'll walk backwards up to the root\n  // to see what path the root points to. On the way we may hit one of the\n  // special cases and we'll deal with them.\n\n\n  var a = fiber;\n  var b = alternate;\n\n  while (true) {\n    var parentA = a.return;\n\n    if (parentA === null) {\n      // We're at the root.\n      break;\n    }\n\n    var parentB = parentA.alternate;\n\n    if (parentB === null) {\n      // There is no alternate. This is an unusual case. Currently, it only\n      // happens when a Suspense component is hidden. An extra fragment fiber\n      // is inserted in between the Suspense fiber and its children. Skip\n      // over this extra fragment fiber and proceed to the next parent.\n      var nextParent = parentA.return;\n\n      if (nextParent !== null) {\n        a = b = nextParent;\n        continue;\n      } // If there's no parent, we're at the root.\n\n\n      break;\n    } // If both copies of the parent fiber point to the same child, we can\n    // assume that the child is current. This happens when we bailout on low\n    // priority: the bailed out fiber's child reuses the current child.\n\n\n    if (parentA.child === parentB.child) {\n      var child = parentA.child;\n\n      while (child) {\n        if (child === a) {\n          // We've determined that A is the current branch.\n          assertIsMounted(parentA);\n          return fiber;\n        }\n\n        if (child === b) {\n          // We've determined that B is the current branch.\n          assertIsMounted(parentA);\n          return alternate;\n        }\n\n        child = child.sibling;\n      } // We should never have an alternate for any mounting node. So the only\n      // way this could possibly happen is if this was unmounted, if at all.\n\n\n      throw new Error('Unable to find node on an unmounted component.');\n    }\n\n    if (a.return !== b.return) {\n      // The return pointer of A and the return pointer of B point to different\n      // fibers. We assume that return pointers never criss-cross, so A must\n      // belong to the child set of A.return, and B must belong to the child\n      // set of B.return.\n      a = parentA;\n      b = parentB;\n    } else {\n      // The return pointers point to the same fiber. We'll have to use the\n      // default, slow path: scan the child sets of each parent alternate to see\n      // which child belongs to which set.\n      //\n      // Search parent A's child set\n      var didFindChild = false;\n      var _child = parentA.child;\n\n      while (_child) {\n        if (_child === a) {\n          didFindChild = true;\n          a = parentA;\n          b = parentB;\n          break;\n        }\n\n        if (_child === b) {\n          didFindChild = true;\n          b = parentA;\n          a = parentB;\n          break;\n        }\n\n        _child = _child.sibling;\n      }\n\n      if (!didFindChild) {\n        // Search parent B's child set\n        _child = parentB.child;\n\n        while (_child) {\n          if (_child === a) {\n            didFindChild = true;\n            a = parentB;\n            b = parentA;\n            break;\n          }\n\n          if (_child === b) {\n            didFindChild = true;\n            b = parentB;\n            a = parentA;\n            break;\n          }\n\n          _child = _child.sibling;\n        }\n\n        if (!didFindChild) {\n          throw new Error('Child was not found in either parent set. This indicates a bug ' + 'in React related to the return pointer. Please file an issue.');\n        }\n      }\n    }\n\n    if (a.alternate !== b) {\n      throw new Error(\"Return fibers should always be each others' alternates. \" + 'This error is likely caused by a bug in React. Please file an issue.');\n    }\n  } // If the root is not a host container, we're in a disconnected tree. I.e.\n  // unmounted.\n\n\n  if (a.tag !== HostRoot) {\n    throw new Error('Unable to find node on an unmounted component.');\n  }\n\n  if (a.stateNode.current === a) {\n    // We've determined that A is the current branch.\n    return fiber;\n  } // Otherwise B has to be current branch.\n\n\n  return alternate;\n}\nfunction findCurrentHostFiber(parent) {\n  var currentParent = findCurrentFiberUsingSlowPath(parent);\n  return currentParent !== null ? findCurrentHostFiberImpl(currentParent) : null;\n}\n\nfunction findCurrentHostFiberImpl(node) {\n  // Next we'll drill down this component to find the first HostComponent/Text.\n  if (node.tag === HostComponent || node.tag === HostText) {\n    return node;\n  }\n\n  var child = node.child;\n\n  while (child !== null) {\n    var match = findCurrentHostFiberImpl(child);\n\n    if (match !== null) {\n      return match;\n    }\n\n    child = child.sibling;\n  }\n\n  return null;\n}\n\nfunction findCurrentHostFiberWithNoPortals(parent) {\n  var currentParent = findCurrentFiberUsingSlowPath(parent);\n  return currentParent !== null ? findCurrentHostFiberWithNoPortalsImpl(currentParent) : null;\n}\n\nfunction findCurrentHostFiberWithNoPortalsImpl(node) {\n  // Next we'll drill down this component to find the first HostComponent/Text.\n  if (node.tag === HostComponent || node.tag === HostText) {\n    return node;\n  }\n\n  var child = node.child;\n\n  while (child !== null) {\n    if (child.tag !== HostPortal) {\n      var match = findCurrentHostFiberWithNoPortalsImpl(child);\n\n      if (match !== null) {\n        return match;\n      }\n    }\n\n    child = child.sibling;\n  }\n\n  return null;\n}\n\n// This module only exists as an ESM wrapper around the external CommonJS\nvar scheduleCallback = Scheduler.unstable_scheduleCallback;\nvar cancelCallback = Scheduler.unstable_cancelCallback;\nvar shouldYield = Scheduler.unstable_shouldYield;\nvar requestPaint = Scheduler.unstable_requestPaint;\nvar now = Scheduler.unstable_now;\nvar getCurrentPriorityLevel = Scheduler.unstable_getCurrentPriorityLevel;\nvar ImmediatePriority = Scheduler.unstable_ImmediatePriority;\nvar UserBlockingPriority = Scheduler.unstable_UserBlockingPriority;\nvar NormalPriority = Scheduler.unstable_NormalPriority;\nvar LowPriority = Scheduler.unstable_LowPriority;\nvar IdlePriority = Scheduler.unstable_IdlePriority;\n// this doesn't actually exist on the scheduler, but it *does*\n// on scheduler/unstable_mock, which we'll need for internal testing\nvar unstable_yieldValue = Scheduler.unstable_yieldValue;\nvar unstable_setDisableYieldValue = Scheduler.unstable_setDisableYieldValue;\n\nvar rendererID = null;\nvar injectedHook = null;\nvar injectedProfilingHooks = null;\nvar hasLoggedError = false;\nvar isDevToolsPresent = typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ !== 'undefined';\nfunction injectInternals(internals) {\n  if (typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ === 'undefined') {\n    // No DevTools\n    return false;\n  }\n\n  var hook = __REACT_DEVTOOLS_GLOBAL_HOOK__;\n\n  if (hook.isDisabled) {\n    // This isn't a real property on the hook, but it can be set to opt out\n    // of DevTools integration and associated warnings and logs.\n    // https://github.com/facebook/react/issues/3877\n    return true;\n  }\n\n  if (!hook.supportsFiber) {\n    {\n      error('The installed version of React DevTools is too old and will not work ' + 'with the current version of React. Please update React DevTools. ' + 'https://reactjs.org/link/react-devtools');\n    } // DevTools exists, even though it doesn't support Fiber.\n\n\n    return true;\n  }\n\n  try {\n    if (enableSchedulingProfiler) {\n      // Conditionally inject these hooks only if Timeline profiler is supported by this build.\n      // This gives DevTools a way to feature detect that isn't tied to version number\n      // (since profiling and timeline are controlled by different feature flags).\n      internals = assign({}, internals, {\n        getLaneLabelMap: getLaneLabelMap,\n        injectProfilingHooks: injectProfilingHooks\n      });\n    }\n\n    rendererID = hook.inject(internals); // We have successfully injected, so now it is safe to set up hooks.\n\n    injectedHook = hook;\n  } catch (err) {\n    // Catch all errors because it is unsafe to throw during initialization.\n    {\n      error('React instrumentation encountered an error: %s.', err);\n    }\n  }\n\n  if (hook.checkDCE) {\n    // This is the real DevTools.\n    return true;\n  } else {\n    // This is likely a hook installed by Fast Refresh runtime.\n    return false;\n  }\n}\nfunction onScheduleRoot(root, children) {\n  {\n    if (injectedHook && typeof injectedHook.onScheduleFiberRoot === 'function') {\n      try {\n        injectedHook.onScheduleFiberRoot(rendererID, root, children);\n      } catch (err) {\n        if ( !hasLoggedError) {\n          hasLoggedError = true;\n\n          error('React instrumentation encountered an error: %s', err);\n        }\n      }\n    }\n  }\n}\nfunction onCommitRoot(root, eventPriority) {\n  if (injectedHook && typeof injectedHook.onCommitFiberRoot === 'function') {\n    try {\n      var didError = (root.current.flags & DidCapture) === DidCapture;\n\n      if (enableProfilerTimer) {\n        var schedulerPriority;\n\n        switch (eventPriority) {\n          case DiscreteEventPriority:\n            schedulerPriority = ImmediatePriority;\n            break;\n\n          case ContinuousEventPriority:\n            schedulerPriority = UserBlockingPriority;\n            break;\n\n          case DefaultEventPriority:\n            schedulerPriority = NormalPriority;\n            break;\n\n          case IdleEventPriority:\n            schedulerPriority = IdlePriority;\n            break;\n\n          default:\n            schedulerPriority = NormalPriority;\n            break;\n        }\n\n        injectedHook.onCommitFiberRoot(rendererID, root, schedulerPriority, didError);\n      } else {\n        injectedHook.onCommitFiberRoot(rendererID, root, undefined, didError);\n      }\n    } catch (err) {\n      {\n        if (!hasLoggedError) {\n          hasLoggedError = true;\n\n          error('React instrumentation encountered an error: %s', err);\n        }\n      }\n    }\n  }\n}\nfunction onPostCommitRoot(root) {\n  if (injectedHook && typeof injectedHook.onPostCommitFiberRoot === 'function') {\n    try {\n      injectedHook.onPostCommitFiberRoot(rendererID, root);\n    } catch (err) {\n      {\n        if (!hasLoggedError) {\n          hasLoggedError = true;\n\n          error('React instrumentation encountered an error: %s', err);\n        }\n      }\n    }\n  }\n}\nfunction onCommitUnmount(fiber) {\n  if (injectedHook && typeof injectedHook.onCommitFiberUnmount === 'function') {\n    try {\n      injectedHook.onCommitFiberUnmount(rendererID, fiber);\n    } catch (err) {\n      {\n        if (!hasLoggedError) {\n          hasLoggedError = true;\n\n          error('React instrumentation encountered an error: %s', err);\n        }\n      }\n    }\n  }\n}\nfunction setIsStrictModeForDevtools(newIsStrictMode) {\n  {\n    if (typeof unstable_yieldValue === 'function') {\n      // We're in a test because Scheduler.unstable_yieldValue only exists\n      // in SchedulerMock. To reduce the noise in strict mode tests,\n      // suppress warnings and disable scheduler yielding during the double render\n      unstable_setDisableYieldValue(newIsStrictMode);\n      setSuppressWarning(newIsStrictMode);\n    }\n\n    if (injectedHook && typeof injectedHook.setStrictMode === 'function') {\n      try {\n        injectedHook.setStrictMode(rendererID, newIsStrictMode);\n      } catch (err) {\n        {\n          if (!hasLoggedError) {\n            hasLoggedError = true;\n\n            error('React instrumentation encountered an error: %s', err);\n          }\n        }\n      }\n    }\n  }\n} // Profiler API hooks\n\nfunction injectProfilingHooks(profilingHooks) {\n  injectedProfilingHooks = profilingHooks;\n}\n\nfunction getLaneLabelMap() {\n  {\n    var map = new Map();\n    var lane = 1;\n\n    for (var index = 0; index < TotalLanes; index++) {\n      var label = getLabelForLane(lane);\n      map.set(lane, label);\n      lane *= 2;\n    }\n\n    return map;\n  }\n}\n\nfunction markCommitStarted(lanes) {\n  {\n    if (injectedProfilingHooks !== null && typeof injectedProfilingHooks.markCommitStarted === 'function') {\n      injectedProfilingHooks.markCommitStarted(lanes);\n    }\n  }\n}\nfunction markCommitStopped() {\n  {\n    if (injectedProfilingHooks !== null && typeof injectedProfilingHooks.markCommitStopped === 'function') {\n      injectedProfilingHooks.markCommitStopped();\n    }\n  }\n}\nfunction markComponentRenderStarted(fiber) {\n  {\n    if (injectedProfilingHooks !== null && typeof injectedProfilingHooks.markComponentRenderStarted === 'function') {\n      injectedProfilingHooks.markComponentRenderStarted(fiber);\n    }\n  }\n}\nfunction markComponentRenderStopped() {\n  {\n    if (injectedProfilingHooks !== null && typeof injectedProfilingHooks.markComponentRenderStopped === 'function') {\n      injectedProfilingHooks.markComponentRenderStopped();\n    }\n  }\n}\nfunction markComponentPassiveEffectMountStarted(fiber) {\n  {\n    if (injectedProfilingHooks !== null && typeof injectedProfilingHooks.markComponentPassiveEffectMountStarted === 'function') {\n      injectedProfilingHooks.markComponentPassiveEffectMountStarted(fiber);\n    }\n  }\n}\nfunction markComponentPassiveEffectMountStopped() {\n  {\n    if (injectedProfilingHooks !== null && typeof injectedProfilingHooks.markComponentPassiveEffectMountStopped === 'function') {\n      injectedProfilingHooks.markComponentPassiveEffectMountStopped();\n    }\n  }\n}\nfunction markComponentPassiveEffectUnmountStarted(fiber) {\n  {\n    if (injectedProfilingHooks !== null && typeof injectedProfilingHooks.markComponentPassiveEffectUnmountStarted === 'function') {\n      injectedProfilingHooks.markComponentPassiveEffectUnmountStarted(fiber);\n    }\n  }\n}\nfunction markComponentPassiveEffectUnmountStopped() {\n  {\n    if (injectedProfilingHooks !== null && typeof injectedProfilingHooks.markComponentPassiveEffectUnmountStopped === 'function') {\n      injectedProfilingHooks.markComponentPassiveEffectUnmountStopped();\n    }\n  }\n}\nfunction markComponentLayoutEffectMountStarted(fiber) {\n  {\n    if (injectedProfilingHooks !== null && typeof injectedProfilingHooks.markComponentLayoutEffectMountStarted === 'function') {\n      injectedProfilingHooks.markComponentLayoutEffectMountStarted(fiber);\n    }\n  }\n}\nfunction markComponentLayoutEffectMountStopped() {\n  {\n    if (injectedProfilingHooks !== null && typeof injectedProfilingHooks.markComponentLayoutEffectMountStopped === 'function') {\n      injectedProfilingHooks.markComponentLayoutEffectMountStopped();\n    }\n  }\n}\nfunction markComponentLayoutEffectUnmountStarted(fiber) {\n  {\n    if (injectedProfilingHooks !== null && typeof injectedProfilingHooks.markComponentLayoutEffectUnmountStarted === 'function') {\n      injectedProfilingHooks.markComponentLayoutEffectUnmountStarted(fiber);\n    }\n  }\n}\nfunction markComponentLayoutEffectUnmountStopped() {\n  {\n    if (injectedProfilingHooks !== null && typeof injectedProfilingHooks.markComponentLayoutEffectUnmountStopped === 'function') {\n      injectedProfilingHooks.markComponentLayoutEffectUnmountStopped();\n    }\n  }\n}\nfunction markComponentErrored(fiber, thrownValue, lanes) {\n  {\n    if (injectedProfilingHooks !== null && typeof injectedProfilingHooks.markComponentErrored === 'function') {\n      injectedProfilingHooks.markComponentErrored(fiber, thrownValue, lanes);\n    }\n  }\n}\nfunction markComponentSuspended(fiber, wakeable, lanes) {\n  {\n    if (injectedProfilingHooks !== null && typeof injectedProfilingHooks.markComponentSuspended === 'function') {\n      injectedProfilingHooks.markComponentSuspended(fiber, wakeable, lanes);\n    }\n  }\n}\nfunction markLayoutEffectsStarted(lanes) {\n  {\n    if (injectedProfilingHooks !== null && typeof injectedProfilingHooks.markLayoutEffectsStarted === 'function') {\n      injectedProfilingHooks.markLayoutEffectsStarted(lanes);\n    }\n  }\n}\nfunction markLayoutEffectsStopped() {\n  {\n    if (injectedProfilingHooks !== null && typeof injectedProfilingHooks.markLayoutEffectsStopped === 'function') {\n      injectedProfilingHooks.markLayoutEffectsStopped();\n    }\n  }\n}\nfunction markPassiveEffectsStarted(lanes) {\n  {\n    if (injectedProfilingHooks !== null && typeof injectedProfilingHooks.markPassiveEffectsStarted === 'function') {\n      injectedProfilingHooks.markPassiveEffectsStarted(lanes);\n    }\n  }\n}\nfunction markPassiveEffectsStopped() {\n  {\n    if (injectedProfilingHooks !== null && typeof injectedProfilingHooks.markPassiveEffectsStopped === 'function') {\n      injectedProfilingHooks.markPassiveEffectsStopped();\n    }\n  }\n}\nfunction markRenderStarted(lanes) {\n  {\n    if (injectedProfilingHooks !== null && typeof injectedProfilingHooks.markRenderStarted === 'function') {\n      injectedProfilingHooks.markRenderStarted(lanes);\n    }\n  }\n}\nfunction markRenderYielded() {\n  {\n    if (injectedProfilingHooks !== null && typeof injectedProfilingHooks.markRenderYielded === 'function') {\n      injectedProfilingHooks.markRenderYielded();\n    }\n  }\n}\nfunction markRenderStopped() {\n  {\n    if (injectedProfilingHooks !== null && typeof injectedProfilingHooks.markRenderStopped === 'function') {\n      injectedProfilingHooks.markRenderStopped();\n    }\n  }\n}\nfunction markRenderScheduled(lane) {\n  {\n    if (injectedProfilingHooks !== null && typeof injectedProfilingHooks.markRenderScheduled === 'function') {\n      injectedProfilingHooks.markRenderScheduled(lane);\n    }\n  }\n}\nfunction markForceUpdateScheduled(fiber, lane) {\n  {\n    if (injectedProfilingHooks !== null && typeof injectedProfilingHooks.markForceUpdateScheduled === 'function') {\n      injectedProfilingHooks.markForceUpdateScheduled(fiber, lane);\n    }\n  }\n}\nfunction markStateUpdateScheduled(fiber, lane) {\n  {\n    if (injectedProfilingHooks !== null && typeof injectedProfilingHooks.markStateUpdateScheduled === 'function') {\n      injectedProfilingHooks.markStateUpdateScheduled(fiber, lane);\n    }\n  }\n}\n\nvar NoMode =\n/*                         */\n0; // TODO: Remove ConcurrentMode by reading from the root tag instead\n\nvar ConcurrentMode =\n/*                 */\n1;\nvar ProfileMode =\n/*                    */\n2;\nvar StrictLegacyMode =\n/*               */\n8;\nvar StrictEffectsMode =\n/*              */\n16;\n\n// TODO: This is pretty well supported by browsers. Maybe we can drop it.\nvar clz32 = Math.clz32 ? Math.clz32 : clz32Fallback; // Count leading zeros.\n// Based on:\n// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/clz32\n\nvar log = Math.log;\nvar LN2 = Math.LN2;\n\nfunction clz32Fallback(x) {\n  var asUint = x >>> 0;\n\n  if (asUint === 0) {\n    return 32;\n  }\n\n  return 31 - (log(asUint) / LN2 | 0) | 0;\n}\n\n// If those values are changed that package should be rebuilt and redeployed.\n\nvar TotalLanes = 31;\nvar NoLanes =\n/*                        */\n0;\nvar NoLane =\n/*                          */\n0;\nvar SyncLane =\n/*                        */\n1;\nvar InputContinuousHydrationLane =\n/*    */\n2;\nvar InputContinuousLane =\n/*             */\n4;\nvar DefaultHydrationLane =\n/*            */\n8;\nvar DefaultLane =\n/*                     */\n16;\nvar TransitionHydrationLane =\n/*                */\n32;\nvar TransitionLanes =\n/*                       */\n4194240;\nvar TransitionLane1 =\n/*                        */\n64;\nvar TransitionLane2 =\n/*                        */\n128;\nvar TransitionLane3 =\n/*                        */\n256;\nvar TransitionLane4 =\n/*                        */\n512;\nvar TransitionLane5 =\n/*                        */\n1024;\nvar TransitionLane6 =\n/*                        */\n2048;\nvar TransitionLane7 =\n/*                        */\n4096;\nvar TransitionLane8 =\n/*                        */\n8192;\nvar TransitionLane9 =\n/*                        */\n16384;\nvar TransitionLane10 =\n/*                       */\n32768;\nvar TransitionLane11 =\n/*                       */\n65536;\nvar TransitionLane12 =\n/*                       */\n131072;\nvar TransitionLane13 =\n/*                       */\n262144;\nvar TransitionLane14 =\n/*                       */\n524288;\nvar TransitionLane15 =\n/*                       */\n1048576;\nvar TransitionLane16 =\n/*                       */\n2097152;\nvar RetryLanes =\n/*                            */\n130023424;\nvar RetryLane1 =\n/*                             */\n4194304;\nvar RetryLane2 =\n/*                             */\n8388608;\nvar RetryLane3 =\n/*                             */\n16777216;\nvar RetryLane4 =\n/*                             */\n33554432;\nvar RetryLane5 =\n/*                             */\n67108864;\nvar SomeRetryLane = RetryLane1;\nvar SelectiveHydrationLane =\n/*          */\n134217728;\nvar NonIdleLanes =\n/*                          */\n268435455;\nvar IdleHydrationLane =\n/*               */\n268435456;\nvar IdleLane =\n/*                        */\n536870912;\nvar OffscreenLane =\n/*                   */\n1073741824; // This function is used for the experimental timeline (react-devtools-timeline)\n// It should be kept in sync with the Lanes values above.\n\nfunction getLabelForLane(lane) {\n  {\n    if (lane & SyncLane) {\n      return 'Sync';\n    }\n\n    if (lane & InputContinuousHydrationLane) {\n      return 'InputContinuousHydration';\n    }\n\n    if (lane & InputContinuousLane) {\n      return 'InputContinuous';\n    }\n\n    if (lane & DefaultHydrationLane) {\n      return 'DefaultHydration';\n    }\n\n    if (lane & DefaultLane) {\n      return 'Default';\n    }\n\n    if (lane & TransitionHydrationLane) {\n      return 'TransitionHydration';\n    }\n\n    if (lane & TransitionLanes) {\n      return 'Transition';\n    }\n\n    if (lane & RetryLanes) {\n      return 'Retry';\n    }\n\n    if (lane & SelectiveHydrationLane) {\n      return 'SelectiveHydration';\n    }\n\n    if (lane & IdleHydrationLane) {\n      return 'IdleHydration';\n    }\n\n    if (lane & IdleLane) {\n      return 'Idle';\n    }\n\n    if (lane & OffscreenLane) {\n      return 'Offscreen';\n    }\n  }\n}\nvar NoTimestamp = -1;\nvar nextTransitionLane = TransitionLane1;\nvar nextRetryLane = RetryLane1;\n\nfunction getHighestPriorityLanes(lanes) {\n  switch (getHighestPriorityLane(lanes)) {\n    case SyncLane:\n      return SyncLane;\n\n    case InputContinuousHydrationLane:\n      return InputContinuousHydrationLane;\n\n    case InputContinuousLane:\n      return InputContinuousLane;\n\n    case DefaultHydrationLane:\n      return DefaultHydrationLane;\n\n    case DefaultLane:\n      return DefaultLane;\n\n    case TransitionHydrationLane:\n      return TransitionHydrationLane;\n\n    case TransitionLane1:\n    case TransitionLane2:\n    case TransitionLane3:\n    case TransitionLane4:\n    case TransitionLane5:\n    case TransitionLane6:\n    case TransitionLane7:\n    case TransitionLane8:\n    case TransitionLane9:\n    case TransitionLane10:\n    case TransitionLane11:\n    case TransitionLane12:\n    case TransitionLane13:\n    case TransitionLane14:\n    case TransitionLane15:\n    case TransitionLane16:\n      return lanes & TransitionLanes;\n\n    case RetryLane1:\n    case RetryLane2:\n    case RetryLane3:\n    case RetryLane4:\n    case RetryLane5:\n      return lanes & RetryLanes;\n\n    case SelectiveHydrationLane:\n      return SelectiveHydrationLane;\n\n    case IdleHydrationLane:\n      return IdleHydrationLane;\n\n    case IdleLane:\n      return IdleLane;\n\n    case OffscreenLane:\n      return OffscreenLane;\n\n    default:\n      {\n        error('Should have found matching lanes. This is a bug in React.');\n      } // This shouldn't be reachable, but as a fallback, return the entire bitmask.\n\n\n      return lanes;\n  }\n}\n\nfunction getNextLanes(root, wipLanes) {\n  // Early bailout if there's no pending work left.\n  var pendingLanes = root.pendingLanes;\n\n  if (pendingLanes === NoLanes) {\n    return NoLanes;\n  }\n\n  var nextLanes = NoLanes;\n  var suspendedLanes = root.suspendedLanes;\n  var pingedLanes = root.pingedLanes; // Do not work on any idle work until all the non-idle work has finished,\n  // even if the work is suspended.\n\n  var nonIdlePendingLanes = pendingLanes & NonIdleLanes;\n\n  if (nonIdlePendingLanes !== NoLanes) {\n    var nonIdleUnblockedLanes = nonIdlePendingLanes & ~suspendedLanes;\n\n    if (nonIdleUnblockedLanes !== NoLanes) {\n      nextLanes = getHighestPriorityLanes(nonIdleUnblockedLanes);\n    } else {\n      var nonIdlePingedLanes = nonIdlePendingLanes & pingedLanes;\n\n      if (nonIdlePingedLanes !== NoLanes) {\n        nextLanes = getHighestPriorityLanes(nonIdlePingedLanes);\n      }\n    }\n  } else {\n    // The only remaining work is Idle.\n    var unblockedLanes = pendingLanes & ~suspendedLanes;\n\n    if (unblockedLanes !== NoLanes) {\n      nextLanes = getHighestPriorityLanes(unblockedLanes);\n    } else {\n      if (pingedLanes !== NoLanes) {\n        nextLanes = getHighestPriorityLanes(pingedLanes);\n      }\n    }\n  }\n\n  if (nextLanes === NoLanes) {\n    // This should only be reachable if we're suspended\n    // TODO: Consider warning in this path if a fallback timer is not scheduled.\n    return NoLanes;\n  } // If we're already in the middle of a render, switching lanes will interrupt\n  // it and we'll lose our progress. We should only do this if the new lanes are\n  // higher priority.\n\n\n  if (wipLanes !== NoLanes && wipLanes !== nextLanes && // If we already suspended with a delay, then interrupting is fine. Don't\n  // bother waiting until the root is complete.\n  (wipLanes & suspendedLanes) === NoLanes) {\n    var nextLane = getHighestPriorityLane(nextLanes);\n    var wipLane = getHighestPriorityLane(wipLanes);\n\n    if ( // Tests whether the next lane is equal or lower priority than the wip\n    // one. This works because the bits decrease in priority as you go left.\n    nextLane >= wipLane || // Default priority updates should not interrupt transition updates. The\n    // only difference between default updates and transition updates is that\n    // default updates do not support refresh transitions.\n    nextLane === DefaultLane && (wipLane & TransitionLanes) !== NoLanes) {\n      // Keep working on the existing in-progress tree. Do not interrupt.\n      return wipLanes;\n    }\n  }\n\n  if ((nextLanes & InputContinuousLane) !== NoLanes) {\n    // When updates are sync by default, we entangle continuous priority updates\n    // and default updates, so they render in the same batch. The only reason\n    // they use separate lanes is because continuous updates should interrupt\n    // transitions, but default updates should not.\n    nextLanes |= pendingLanes & DefaultLane;\n  } // Check for entangled lanes and add them to the batch.\n  //\n  // A lane is said to be entangled with another when it's not allowed to render\n  // in a batch that does not also include the other lane. Typically we do this\n  // when multiple updates have the same source, and we only want to respond to\n  // the most recent event from that source.\n  //\n  // Note that we apply entanglements *after* checking for partial work above.\n  // This means that if a lane is entangled during an interleaved event while\n  // it's already rendering, we won't interrupt it. This is intentional, since\n  // entanglement is usually \"best effort\": we'll try our best to render the\n  // lanes in the same batch, but it's not worth throwing out partially\n  // completed work in order to do it.\n  // TODO: Reconsider this. The counter-argument is that the partial work\n  // represents an intermediate state, which we don't want to show to the user.\n  // And by spending extra time finishing it, we're increasing the amount of\n  // time it takes to show the final state, which is what they are actually\n  // waiting for.\n  //\n  // For those exceptions where entanglement is semantically important, like\n  // useMutableSource, we should ensure that there is no partial work at the\n  // time we apply the entanglement.\n\n\n  var entangledLanes = root.entangledLanes;\n\n  if (entangledLanes !== NoLanes) {\n    var entanglements = root.entanglements;\n    var lanes = nextLanes & entangledLanes;\n\n    while (lanes > 0) {\n      var index = pickArbitraryLaneIndex(lanes);\n      var lane = 1 << index;\n      nextLanes |= entanglements[index];\n      lanes &= ~lane;\n    }\n  }\n\n  return nextLanes;\n}\nfunction getMostRecentEventTime(root, lanes) {\n  var eventTimes = root.eventTimes;\n  var mostRecentEventTime = NoTimestamp;\n\n  while (lanes > 0) {\n    var index = pickArbitraryLaneIndex(lanes);\n    var lane = 1 << index;\n    var eventTime = eventTimes[index];\n\n    if (eventTime > mostRecentEventTime) {\n      mostRecentEventTime = eventTime;\n    }\n\n    lanes &= ~lane;\n  }\n\n  return mostRecentEventTime;\n}\n\nfunction computeExpirationTime(lane, currentTime) {\n  switch (lane) {\n    case SyncLane:\n    case InputContinuousHydrationLane:\n    case InputContinuousLane:\n      // User interactions should expire slightly more quickly.\n      //\n      // NOTE: This is set to the corresponding constant as in Scheduler.js.\n      // When we made it larger, a product metric in www regressed, suggesting\n      // there's a user interaction that's being starved by a series of\n      // synchronous updates. If that theory is correct, the proper solution is\n      // to fix the starvation. However, this scenario supports the idea that\n      // expiration times are an important safeguard when starvation\n      // does happen.\n      return currentTime + 250;\n\n    case DefaultHydrationLane:\n    case DefaultLane:\n    case TransitionHydrationLane:\n    case TransitionLane1:\n    case TransitionLane2:\n    case TransitionLane3:\n    case TransitionLane4:\n    case TransitionLane5:\n    case TransitionLane6:\n    case TransitionLane7:\n    case TransitionLane8:\n    case TransitionLane9:\n    case TransitionLane10:\n    case TransitionLane11:\n    case TransitionLane12:\n    case TransitionLane13:\n    case TransitionLane14:\n    case TransitionLane15:\n    case TransitionLane16:\n      return currentTime + 5000;\n\n    case RetryLane1:\n    case RetryLane2:\n    case RetryLane3:\n    case RetryLane4:\n    case RetryLane5:\n      // TODO: Retries should be allowed to expire if they are CPU bound for\n      // too long, but when I made this change it caused a spike in browser\n      // crashes. There must be some other underlying bug; not super urgent but\n      // ideally should figure out why and fix it. Unfortunately we don't have\n      // a repro for the crashes, only detected via production metrics.\n      return NoTimestamp;\n\n    case SelectiveHydrationLane:\n    case IdleHydrationLane:\n    case IdleLane:\n    case OffscreenLane:\n      // Anything idle priority or lower should never expire.\n      return NoTimestamp;\n\n    default:\n      {\n        error('Should have found matching lanes. This is a bug in React.');\n      }\n\n      return NoTimestamp;\n  }\n}\n\nfunction markStarvedLanesAsExpired(root, currentTime) {\n  // TODO: This gets called every time we yield. We can optimize by storing\n  // the earliest expiration time on the root. Then use that to quickly bail out\n  // of this function.\n  var pendingLanes = root.pendingLanes;\n  var suspendedLanes = root.suspendedLanes;\n  var pingedLanes = root.pingedLanes;\n  var expirationTimes = root.expirationTimes; // Iterate through the pending lanes and check if we've reached their\n  // expiration time. If so, we'll assume the update is being starved and mark\n  // it as expired to force it to finish.\n\n  var lanes = pendingLanes;\n\n  while (lanes > 0) {\n    var index = pickArbitraryLaneIndex(lanes);\n    var lane = 1 << index;\n    var expirationTime = expirationTimes[index];\n\n    if (expirationTime === NoTimestamp) {\n      // Found a pending lane with no expiration time. If it's not suspended, or\n      // if it's pinged, assume it's CPU-bound. Compute a new expiration time\n      // using the current time.\n      if ((lane & suspendedLanes) === NoLanes || (lane & pingedLanes) !== NoLanes) {\n        // Assumes timestamps are monotonically increasing.\n        expirationTimes[index] = computeExpirationTime(lane, currentTime);\n      }\n    } else if (expirationTime <= currentTime) {\n      // This lane expired\n      root.expiredLanes |= lane;\n    }\n\n    lanes &= ~lane;\n  }\n} // This returns the highest priority pending lanes regardless of whether they\n// are suspended.\n\nfunction getHighestPriorityPendingLanes(root) {\n  return getHighestPriorityLanes(root.pendingLanes);\n}\nfunction getLanesToRetrySynchronouslyOnError(root) {\n  var everythingButOffscreen = root.pendingLanes & ~OffscreenLane;\n\n  if (everythingButOffscreen !== NoLanes) {\n    return everythingButOffscreen;\n  }\n\n  if (everythingButOffscreen & OffscreenLane) {\n    return OffscreenLane;\n  }\n\n  return NoLanes;\n}\nfunction includesSyncLane(lanes) {\n  return (lanes & SyncLane) !== NoLanes;\n}\nfunction includesNonIdleWork(lanes) {\n  return (lanes & NonIdleLanes) !== NoLanes;\n}\nfunction includesOnlyRetries(lanes) {\n  return (lanes & RetryLanes) === lanes;\n}\nfunction includesOnlyNonUrgentLanes(lanes) {\n  var UrgentLanes = SyncLane | InputContinuousLane | DefaultLane;\n  return (lanes & UrgentLanes) === NoLanes;\n}\nfunction includesOnlyTransitions(lanes) {\n  return (lanes & TransitionLanes) === lanes;\n}\nfunction includesBlockingLane(root, lanes) {\n\n  var SyncDefaultLanes = InputContinuousHydrationLane | InputContinuousLane | DefaultHydrationLane | DefaultLane;\n  return (lanes & SyncDefaultLanes) !== NoLanes;\n}\nfunction includesExpiredLane(root, lanes) {\n  // This is a separate check from includesBlockingLane because a lane can\n  // expire after a render has already started.\n  return (lanes & root.expiredLanes) !== NoLanes;\n}\nfunction isTransitionLane(lane) {\n  return (lane & TransitionLanes) !== NoLanes;\n}\nfunction claimNextTransitionLane() {\n  // Cycle through the lanes, assigning each new transition to the next lane.\n  // In most cases, this means every transition gets its own lane, until we\n  // run out of lanes and cycle back to the beginning.\n  var lane = nextTransitionLane;\n  nextTransitionLane <<= 1;\n\n  if ((nextTransitionLane & TransitionLanes) === NoLanes) {\n    nextTransitionLane = TransitionLane1;\n  }\n\n  return lane;\n}\nfunction claimNextRetryLane() {\n  var lane = nextRetryLane;\n  nextRetryLane <<= 1;\n\n  if ((nextRetryLane & RetryLanes) === NoLanes) {\n    nextRetryLane = RetryLane1;\n  }\n\n  return lane;\n}\nfunction getHighestPriorityLane(lanes) {\n  return lanes & -lanes;\n}\nfunction pickArbitraryLane(lanes) {\n  // This wrapper function gets inlined. Only exists so to communicate that it\n  // doesn't matter which bit is selected; you can pick any bit without\n  // affecting the algorithms where its used. Here I'm using\n  // getHighestPriorityLane because it requires the fewest operations.\n  return getHighestPriorityLane(lanes);\n}\n\nfunction pickArbitraryLaneIndex(lanes) {\n  return 31 - clz32(lanes);\n}\n\nfunction laneToIndex(lane) {\n  return pickArbitraryLaneIndex(lane);\n}\n\nfunction includesSomeLane(a, b) {\n  return (a & b) !== NoLanes;\n}\nfunction isSubsetOfLanes(set, subset) {\n  return (set & subset) === subset;\n}\nfunction mergeLanes(a, b) {\n  return a | b;\n}\nfunction removeLanes(set, subset) {\n  return set & ~subset;\n}\nfunction intersectLanes(a, b) {\n  return a & b;\n} // Seems redundant, but it changes the type from a single lane (used for\n// updates) to a group of lanes (used for flushing work).\n\nfunction laneToLanes(lane) {\n  return lane;\n}\nfunction higherPriorityLane(a, b) {\n  // This works because the bit ranges decrease in priority as you go left.\n  return a !== NoLane && a < b ? a : b;\n}\nfunction createLaneMap(initial) {\n  // Intentionally pushing one by one.\n  // https://v8.dev/blog/elements-kinds#avoid-creating-holes\n  var laneMap = [];\n\n  for (var i = 0; i < TotalLanes; i++) {\n    laneMap.push(initial);\n  }\n\n  return laneMap;\n}\nfunction markRootUpdated(root, updateLane, eventTime) {\n  root.pendingLanes |= updateLane; // If there are any suspended transitions, it's possible this new update\n  // could unblock them. Clear the suspended lanes so that we can try rendering\n  // them again.\n  //\n  // TODO: We really only need to unsuspend only lanes that are in the\n  // `subtreeLanes` of the updated fiber, or the update lanes of the return\n  // path. This would exclude suspended updates in an unrelated sibling tree,\n  // since there's no way for this update to unblock it.\n  //\n  // We don't do this if the incoming update is idle, because we never process\n  // idle updates until after all the regular updates have finished; there's no\n  // way it could unblock a transition.\n\n  if (updateLane !== IdleLane) {\n    root.suspendedLanes = NoLanes;\n    root.pingedLanes = NoLanes;\n  }\n\n  var eventTimes = root.eventTimes;\n  var index = laneToIndex(updateLane); // We can always overwrite an existing timestamp because we prefer the most\n  // recent event, and we assume time is monotonically increasing.\n\n  eventTimes[index] = eventTime;\n}\nfunction markRootSuspended(root, suspendedLanes) {\n  root.suspendedLanes |= suspendedLanes;\n  root.pingedLanes &= ~suspendedLanes; // The suspended lanes are no longer CPU-bound. Clear their expiration times.\n\n  var expirationTimes = root.expirationTimes;\n  var lanes = suspendedLanes;\n\n  while (lanes > 0) {\n    var index = pickArbitraryLaneIndex(lanes);\n    var lane = 1 << index;\n    expirationTimes[index] = NoTimestamp;\n    lanes &= ~lane;\n  }\n}\nfunction markRootPinged(root, pingedLanes, eventTime) {\n  root.pingedLanes |= root.suspendedLanes & pingedLanes;\n}\nfunction markRootFinished(root, remainingLanes) {\n  var noLongerPendingLanes = root.pendingLanes & ~remainingLanes;\n  root.pendingLanes = remainingLanes; // Let's try everything again\n\n  root.suspendedLanes = NoLanes;\n  root.pingedLanes = NoLanes;\n  root.expiredLanes &= remainingLanes;\n  root.mutableReadLanes &= remainingLanes;\n  root.entangledLanes &= remainingLanes;\n  var entanglements = root.entanglements;\n  var eventTimes = root.eventTimes;\n  var expirationTimes = root.expirationTimes; // Clear the lanes that no longer have pending work\n\n  var lanes = noLongerPendingLanes;\n\n  while (lanes > 0) {\n    var index = pickArbitraryLaneIndex(lanes);\n    var lane = 1 << index;\n    entanglements[index] = NoLanes;\n    eventTimes[index] = NoTimestamp;\n    expirationTimes[index] = NoTimestamp;\n    lanes &= ~lane;\n  }\n}\nfunction markRootEntangled(root, entangledLanes) {\n  // In addition to entangling each of the given lanes with each other, we also\n  // have to consider _transitive_ entanglements. For each lane that is already\n  // entangled with *any* of the given lanes, that lane is now transitively\n  // entangled with *all* the given lanes.\n  //\n  // Translated: If C is entangled with A, then entangling A with B also\n  // entangles C with B.\n  //\n  // If this is hard to grasp, it might help to intentionally break this\n  // function and look at the tests that fail in ReactTransition-test.js. Try\n  // commenting out one of the conditions below.\n  var rootEntangledLanes = root.entangledLanes |= entangledLanes;\n  var entanglements = root.entanglements;\n  var lanes = rootEntangledLanes;\n\n  while (lanes) {\n    var index = pickArbitraryLaneIndex(lanes);\n    var lane = 1 << index;\n\n    if ( // Is this one of the newly entangled lanes?\n    lane & entangledLanes | // Is this lane transitively entangled with the newly entangled lanes?\n    entanglements[index] & entangledLanes) {\n      entanglements[index] |= entangledLanes;\n    }\n\n    lanes &= ~lane;\n  }\n}\nfunction getBumpedLaneForHydration(root, renderLanes) {\n  var renderLane = getHighestPriorityLane(renderLanes);\n  var lane;\n\n  switch (renderLane) {\n    case InputContinuousLane:\n      lane = InputContinuousHydrationLane;\n      break;\n\n    case DefaultLane:\n      lane = DefaultHydrationLane;\n      break;\n\n    case TransitionLane1:\n    case TransitionLane2:\n    case TransitionLane3:\n    case TransitionLane4:\n    case TransitionLane5:\n    case TransitionLane6:\n    case TransitionLane7:\n    case TransitionLane8:\n    case TransitionLane9:\n    case TransitionLane10:\n    case TransitionLane11:\n    case TransitionLane12:\n    case TransitionLane13:\n    case TransitionLane14:\n    case TransitionLane15:\n    case TransitionLane16:\n    case RetryLane1:\n    case RetryLane2:\n    case RetryLane3:\n    case RetryLane4:\n    case RetryLane5:\n      lane = TransitionHydrationLane;\n      break;\n\n    case IdleLane:\n      lane = IdleHydrationLane;\n      break;\n\n    default:\n      // Everything else is already either a hydration lane, or shouldn't\n      // be retried at a hydration lane.\n      lane = NoLane;\n      break;\n  } // Check if the lane we chose is suspended. If so, that indicates that we\n  // already attempted and failed to hydrate at that level. Also check if we're\n  // already rendering that lane, which is rare but could happen.\n\n\n  if ((lane & (root.suspendedLanes | renderLanes)) !== NoLane) {\n    // Give up trying to hydrate and fall back to client render.\n    return NoLane;\n  }\n\n  return lane;\n}\nfunction addFiberToLanesMap(root, fiber, lanes) {\n\n  if (!isDevToolsPresent) {\n    return;\n  }\n\n  var pendingUpdatersLaneMap = root.pendingUpdatersLaneMap;\n\n  while (lanes > 0) {\n    var index = laneToIndex(lanes);\n    var lane = 1 << index;\n    var updaters = pendingUpdatersLaneMap[index];\n    updaters.add(fiber);\n    lanes &= ~lane;\n  }\n}\nfunction movePendingFibersToMemoized(root, lanes) {\n\n  if (!isDevToolsPresent) {\n    return;\n  }\n\n  var pendingUpdatersLaneMap = root.pendingUpdatersLaneMap;\n  var memoizedUpdaters = root.memoizedUpdaters;\n\n  while (lanes > 0) {\n    var index = laneToIndex(lanes);\n    var lane = 1 << index;\n    var updaters = pendingUpdatersLaneMap[index];\n\n    if (updaters.size > 0) {\n      updaters.forEach(function (fiber) {\n        var alternate = fiber.alternate;\n\n        if (alternate === null || !memoizedUpdaters.has(alternate)) {\n          memoizedUpdaters.add(fiber);\n        }\n      });\n      updaters.clear();\n    }\n\n    lanes &= ~lane;\n  }\n}\nfunction getTransitionsForLanes(root, lanes) {\n  {\n    return null;\n  }\n}\n\nvar DiscreteEventPriority = SyncLane;\nvar ContinuousEventPriority = InputContinuousLane;\nvar DefaultEventPriority = DefaultLane;\nvar IdleEventPriority = IdleLane;\nvar currentUpdatePriority = NoLane;\nfunction getCurrentUpdatePriority() {\n  return currentUpdatePriority;\n}\nfunction setCurrentUpdatePriority(newPriority) {\n  currentUpdatePriority = newPriority;\n}\nfunction runWithPriority(priority, fn) {\n  var previousPriority = currentUpdatePriority;\n\n  try {\n    currentUpdatePriority = priority;\n    return fn();\n  } finally {\n    currentUpdatePriority = previousPriority;\n  }\n}\nfunction higherEventPriority(a, b) {\n  return a !== 0 && a < b ? a : b;\n}\nfunction lowerEventPriority(a, b) {\n  return a === 0 || a > b ? a : b;\n}\nfunction isHigherEventPriority(a, b) {\n  return a !== 0 && a < b;\n}\nfunction lanesToEventPriority(lanes) {\n  var lane = getHighestPriorityLane(lanes);\n\n  if (!isHigherEventPriority(DiscreteEventPriority, lane)) {\n    return DiscreteEventPriority;\n  }\n\n  if (!isHigherEventPriority(ContinuousEventPriority, lane)) {\n    return ContinuousEventPriority;\n  }\n\n  if (includesNonIdleWork(lane)) {\n    return DefaultEventPriority;\n  }\n\n  return IdleEventPriority;\n}\n\n// This is imported by the event replaying implementation in React DOM. It's\n// in a separate file to break a circular dependency between the renderer and\n// the reconciler.\nfunction isRootDehydrated(root) {\n  var currentState = root.current.memoizedState;\n  return currentState.isDehydrated;\n}\n\nvar _attemptSynchronousHydration;\n\nfunction setAttemptSynchronousHydration(fn) {\n  _attemptSynchronousHydration = fn;\n}\nfunction attemptSynchronousHydration(fiber) {\n  _attemptSynchronousHydration(fiber);\n}\nvar attemptContinuousHydration;\nfunction setAttemptContinuousHydration(fn) {\n  attemptContinuousHydration = fn;\n}\nvar attemptHydrationAtCurrentPriority;\nfunction setAttemptHydrationAtCurrentPriority(fn) {\n  attemptHydrationAtCurrentPriority = fn;\n}\nvar getCurrentUpdatePriority$1;\nfunction setGetCurrentUpdatePriority(fn) {\n  getCurrentUpdatePriority$1 = fn;\n}\nvar attemptHydrationAtPriority;\nfunction setAttemptHydrationAtPriority(fn) {\n  attemptHydrationAtPriority = fn;\n} // TODO: Upgrade this definition once we're on a newer version of Flow that\n// has this definition built-in.\n\nvar hasScheduledReplayAttempt = false; // The queue of discrete events to be replayed.\n\nvar queuedDiscreteEvents = []; // Indicates if any continuous event targets are non-null for early bailout.\n// if the last target was dehydrated.\n\nvar queuedFocus = null;\nvar queuedDrag = null;\nvar queuedMouse = null; // For pointer events there can be one latest event per pointerId.\n\nvar queuedPointers = new Map();\nvar queuedPointerCaptures = new Map(); // We could consider replaying selectionchange and touchmoves too.\n\nvar queuedExplicitHydrationTargets = [];\nvar discreteReplayableEvents = ['mousedown', 'mouseup', 'touchcancel', 'touchend', 'touchstart', 'auxclick', 'dblclick', 'pointercancel', 'pointerdown', 'pointerup', 'dragend', 'dragstart', 'drop', 'compositionend', 'compositionstart', 'keydown', 'keypress', 'keyup', 'input', 'textInput', // Intentionally camelCase\n'copy', 'cut', 'paste', 'click', 'change', 'contextmenu', 'reset', 'submit'];\nfunction isDiscreteEventThatRequiresHydration(eventType) {\n  return discreteReplayableEvents.indexOf(eventType) > -1;\n}\n\nfunction createQueuedReplayableEvent(blockedOn, domEventName, eventSystemFlags, targetContainer, nativeEvent) {\n  return {\n    blockedOn: blockedOn,\n    domEventName: domEventName,\n    eventSystemFlags: eventSystemFlags,\n    nativeEvent: nativeEvent,\n    targetContainers: [targetContainer]\n  };\n}\n\nfunction clearIfContinuousEvent(domEventName, nativeEvent) {\n  switch (domEventName) {\n    case 'focusin':\n    case 'focusout':\n      queuedFocus = null;\n      break;\n\n    case 'dragenter':\n    case 'dragleave':\n      queuedDrag = null;\n      break;\n\n    case 'mouseover':\n    case 'mouseout':\n      queuedMouse = null;\n      break;\n\n    case 'pointerover':\n    case 'pointerout':\n      {\n        var pointerId = nativeEvent.pointerId;\n        queuedPointers.delete(pointerId);\n        break;\n      }\n\n    case 'gotpointercapture':\n    case 'lostpointercapture':\n      {\n        var _pointerId = nativeEvent.pointerId;\n        queuedPointerCaptures.delete(_pointerId);\n        break;\n      }\n  }\n}\n\nfunction accumulateOrCreateContinuousQueuedReplayableEvent(existingQueuedEvent, blockedOn, domEventName, eventSystemFlags, targetContainer, nativeEvent) {\n  if (existingQueuedEvent === null || existingQueuedEvent.nativeEvent !== nativeEvent) {\n    var queuedEvent = createQueuedReplayableEvent(blockedOn, domEventName, eventSystemFlags, targetContainer, nativeEvent);\n\n    if (blockedOn !== null) {\n      var _fiber2 = getInstanceFromNode(blockedOn);\n\n      if (_fiber2 !== null) {\n        // Attempt to increase the priority of this target.\n        attemptContinuousHydration(_fiber2);\n      }\n    }\n\n    return queuedEvent;\n  } // If we have already queued this exact event, then it's because\n  // the different event systems have different DOM event listeners.\n  // We can accumulate the flags, and the targetContainers, and\n  // store a single event to be replayed.\n\n\n  existingQueuedEvent.eventSystemFlags |= eventSystemFlags;\n  var targetContainers = existingQueuedEvent.targetContainers;\n\n  if (targetContainer !== null && targetContainers.indexOf(targetContainer) === -1) {\n    targetContainers.push(targetContainer);\n  }\n\n  return existingQueuedEvent;\n}\n\nfunction queueIfContinuousEvent(blockedOn, domEventName, eventSystemFlags, targetContainer, nativeEvent) {\n  // These set relatedTarget to null because the replayed event will be treated as if we\n  // moved from outside the window (no target) onto the target once it hydrates.\n  // Instead of mutating we could clone the event.\n  switch (domEventName) {\n    case 'focusin':\n      {\n        var focusEvent = nativeEvent;\n        queuedFocus = accumulateOrCreateContinuousQueuedReplayableEvent(queuedFocus, blockedOn, domEventName, eventSystemFlags, targetContainer, focusEvent);\n        return true;\n      }\n\n    case 'dragenter':\n      {\n        var dragEvent = nativeEvent;\n        queuedDrag = accumulateOrCreateContinuousQueuedReplayableEvent(queuedDrag, blockedOn, domEventName, eventSystemFlags, targetContainer, dragEvent);\n        return true;\n      }\n\n    case 'mouseover':\n      {\n        var mouseEvent = nativeEvent;\n        queuedMouse = accumulateOrCreateContinuousQueuedReplayableEvent(queuedMouse, blockedOn, domEventName, eventSystemFlags, targetContainer, mouseEvent);\n        return true;\n      }\n\n    case 'pointerover':\n      {\n        var pointerEvent = nativeEvent;\n        var pointerId = pointerEvent.pointerId;\n        queuedPointers.set(pointerId, accumulateOrCreateContinuousQueuedReplayableEvent(queuedPointers.get(pointerId) || null, blockedOn, domEventName, eventSystemFlags, targetContainer, pointerEvent));\n        return true;\n      }\n\n    case 'gotpointercapture':\n      {\n        var _pointerEvent = nativeEvent;\n        var _pointerId2 = _pointerEvent.pointerId;\n        queuedPointerCaptures.set(_pointerId2, accumulateOrCreateContinuousQueuedReplayableEvent(queuedPointerCaptures.get(_pointerId2) || null, blockedOn, domEventName, eventSystemFlags, targetContainer, _pointerEvent));\n        return true;\n      }\n  }\n\n  return false;\n} // Check if this target is unblocked. Returns true if it's unblocked.\n\nfunction attemptExplicitHydrationTarget(queuedTarget) {\n  // TODO: This function shares a lot of logic with findInstanceBlockingEvent.\n  // Try to unify them. It's a bit tricky since it would require two return\n  // values.\n  var targetInst = getClosestInstanceFromNode(queuedTarget.target);\n\n  if (targetInst !== null) {\n    var nearestMounted = getNearestMountedFiber(targetInst);\n\n    if (nearestMounted !== null) {\n      var tag = nearestMounted.tag;\n\n      if (tag === SuspenseComponent) {\n        var instance = getSuspenseInstanceFromFiber(nearestMounted);\n\n        if (instance !== null) {\n          // We're blocked on hydrating this boundary.\n          // Increase its priority.\n          queuedTarget.blockedOn = instance;\n          attemptHydrationAtPriority(queuedTarget.priority, function () {\n            attemptHydrationAtCurrentPriority(nearestMounted);\n          });\n          return;\n        }\n      } else if (tag === HostRoot) {\n        var root = nearestMounted.stateNode;\n\n        if (isRootDehydrated(root)) {\n          queuedTarget.blockedOn = getContainerFromFiber(nearestMounted); // We don't currently have a way to increase the priority of\n          // a root other than sync.\n\n          return;\n        }\n      }\n    }\n  }\n\n  queuedTarget.blockedOn = null;\n}\n\nfunction queueExplicitHydrationTarget(target) {\n  // TODO: This will read the priority if it's dispatched by the React\n  // event system but not native events. Should read window.event.type, like\n  // we do for updates (getCurrentEventPriority).\n  var updatePriority = getCurrentUpdatePriority$1();\n  var queuedTarget = {\n    blockedOn: null,\n    target: target,\n    priority: updatePriority\n  };\n  var i = 0;\n\n  for (; i < queuedExplicitHydrationTargets.length; i++) {\n    // Stop once we hit the first target with lower priority than\n    if (!isHigherEventPriority(updatePriority, queuedExplicitHydrationTargets[i].priority)) {\n      break;\n    }\n  }\n\n  queuedExplicitHydrationTargets.splice(i, 0, queuedTarget);\n\n  if (i === 0) {\n    attemptExplicitHydrationTarget(queuedTarget);\n  }\n}\n\nfunction attemptReplayContinuousQueuedEvent(queuedEvent) {\n  if (queuedEvent.blockedOn !== null) {\n    return false;\n  }\n\n  var targetContainers = queuedEvent.targetContainers;\n\n  while (targetContainers.length > 0) {\n    var targetContainer = targetContainers[0];\n    var nextBlockedOn = findInstanceBlockingEvent(queuedEvent.domEventName, queuedEvent.eventSystemFlags, targetContainer, queuedEvent.nativeEvent);\n\n    if (nextBlockedOn === null) {\n      {\n        var nativeEvent = queuedEvent.nativeEvent;\n        var nativeEventClone = new nativeEvent.constructor(nativeEvent.type, nativeEvent);\n        setReplayingEvent(nativeEventClone);\n        nativeEvent.target.dispatchEvent(nativeEventClone);\n        resetReplayingEvent();\n      }\n    } else {\n      // We're still blocked. Try again later.\n      var _fiber3 = getInstanceFromNode(nextBlockedOn);\n\n      if (_fiber3 !== null) {\n        attemptContinuousHydration(_fiber3);\n      }\n\n      queuedEvent.blockedOn = nextBlockedOn;\n      return false;\n    } // This target container was successfully dispatched. Try the next.\n\n\n    targetContainers.shift();\n  }\n\n  return true;\n}\n\nfunction attemptReplayContinuousQueuedEventInMap(queuedEvent, key, map) {\n  if (attemptReplayContinuousQueuedEvent(queuedEvent)) {\n    map.delete(key);\n  }\n}\n\nfunction replayUnblockedEvents() {\n  hasScheduledReplayAttempt = false;\n\n\n  if (queuedFocus !== null && attemptReplayContinuousQueuedEvent(queuedFocus)) {\n    queuedFocus = null;\n  }\n\n  if (queuedDrag !== null && attemptReplayContinuousQueuedEvent(queuedDrag)) {\n    queuedDrag = null;\n  }\n\n  if (queuedMouse !== null && attemptReplayContinuousQueuedEvent(queuedMouse)) {\n    queuedMouse = null;\n  }\n\n  queuedPointers.forEach(attemptReplayContinuousQueuedEventInMap);\n  queuedPointerCaptures.forEach(attemptReplayContinuousQueuedEventInMap);\n}\n\nfunction scheduleCallbackIfUnblocked(queuedEvent, unblocked) {\n  if (queuedEvent.blockedOn === unblocked) {\n    queuedEvent.blockedOn = null;\n\n    if (!hasScheduledReplayAttempt) {\n      hasScheduledReplayAttempt = true; // Schedule a callback to attempt replaying as many events as are\n      // now unblocked. This first might not actually be unblocked yet.\n      // We could check it early to avoid scheduling an unnecessary callback.\n\n      Scheduler.unstable_scheduleCallback(Scheduler.unstable_NormalPriority, replayUnblockedEvents);\n    }\n  }\n}\n\nfunction retryIfBlockedOn(unblocked) {\n  // Mark anything that was blocked on this as no longer blocked\n  // and eligible for a replay.\n  if (queuedDiscreteEvents.length > 0) {\n    scheduleCallbackIfUnblocked(queuedDiscreteEvents[0], unblocked); // This is a exponential search for each boundary that commits. I think it's\n    // worth it because we expect very few discrete events to queue up and once\n    // we are actually fully unblocked it will be fast to replay them.\n\n    for (var i = 1; i < queuedDiscreteEvents.length; i++) {\n      var queuedEvent = queuedDiscreteEvents[i];\n\n      if (queuedEvent.blockedOn === unblocked) {\n        queuedEvent.blockedOn = null;\n      }\n    }\n  }\n\n  if (queuedFocus !== null) {\n    scheduleCallbackIfUnblocked(queuedFocus, unblocked);\n  }\n\n  if (queuedDrag !== null) {\n    scheduleCallbackIfUnblocked(queuedDrag, unblocked);\n  }\n\n  if (queuedMouse !== null) {\n    scheduleCallbackIfUnblocked(queuedMouse, unblocked);\n  }\n\n  var unblock = function (queuedEvent) {\n    return scheduleCallbackIfUnblocked(queuedEvent, unblocked);\n  };\n\n  queuedPointers.forEach(unblock);\n  queuedPointerCaptures.forEach(unblock);\n\n  for (var _i = 0; _i < queuedExplicitHydrationTargets.length; _i++) {\n    var queuedTarget = queuedExplicitHydrationTargets[_i];\n\n    if (queuedTarget.blockedOn === unblocked) {\n      queuedTarget.blockedOn = null;\n    }\n  }\n\n  while (queuedExplicitHydrationTargets.length > 0) {\n    var nextExplicitTarget = queuedExplicitHydrationTargets[0];\n\n    if (nextExplicitTarget.blockedOn !== null) {\n      // We're still blocked.\n      break;\n    } else {\n      attemptExplicitHydrationTarget(nextExplicitTarget);\n\n      if (nextExplicitTarget.blockedOn === null) {\n        // We're unblocked.\n        queuedExplicitHydrationTargets.shift();\n      }\n    }\n  }\n}\n\nvar ReactCurrentBatchConfig = ReactSharedInternals.ReactCurrentBatchConfig; // TODO: can we stop exporting these?\n\nvar _enabled = true; // This is exported in FB builds for use by legacy FB layer infra.\n// We'd like to remove this but it's not clear if this is safe.\n\nfunction setEnabled(enabled) {\n  _enabled = !!enabled;\n}\nfunction isEnabled() {\n  return _enabled;\n}\nfunction createEventListenerWrapperWithPriority(targetContainer, domEventName, eventSystemFlags) {\n  var eventPriority = getEventPriority(domEventName);\n  var listenerWrapper;\n\n  switch (eventPriority) {\n    case DiscreteEventPriority:\n      listenerWrapper = dispatchDiscreteEvent;\n      break;\n\n    case ContinuousEventPriority:\n      listenerWrapper = dispatchContinuousEvent;\n      break;\n\n    case DefaultEventPriority:\n    default:\n      listenerWrapper = dispatchEvent;\n      break;\n  }\n\n  return listenerWrapper.bind(null, domEventName, eventSystemFlags, targetContainer);\n}\n\nfunction dispatchDiscreteEvent(domEventName, eventSystemFlags, container, nativeEvent) {\n  var previousPriority = getCurrentUpdatePriority();\n  var prevTransition = ReactCurrentBatchConfig.transition;\n  ReactCurrentBatchConfig.transition = null;\n\n  try {\n    setCurrentUpdatePriority(DiscreteEventPriority);\n    dispatchEvent(domEventName, eventSystemFlags, container, nativeEvent);\n  } finally {\n    setCurrentUpdatePriority(previousPriority);\n    ReactCurrentBatchConfig.transition = prevTransition;\n  }\n}\n\nfunction dispatchContinuousEvent(domEventName, eventSystemFlags, container, nativeEvent) {\n  var previousPriority = getCurrentUpdatePriority();\n  var prevTransition = ReactCurrentBatchConfig.transition;\n  ReactCurrentBatchConfig.transition = null;\n\n  try {\n    setCurrentUpdatePriority(ContinuousEventPriority);\n    dispatchEvent(domEventName, eventSystemFlags, container, nativeEvent);\n  } finally {\n    setCurrentUpdatePriority(previousPriority);\n    ReactCurrentBatchConfig.transition = prevTransition;\n  }\n}\n\nfunction dispatchEvent(domEventName, eventSystemFlags, targetContainer, nativeEvent) {\n  if (!_enabled) {\n    return;\n  }\n\n  {\n    dispatchEventWithEnableCapturePhaseSelectiveHydrationWithoutDiscreteEventReplay(domEventName, eventSystemFlags, targetContainer, nativeEvent);\n  }\n}\n\nfunction dispatchEventWithEnableCapturePhaseSelectiveHydrationWithoutDiscreteEventReplay(domEventName, eventSystemFlags, targetContainer, nativeEvent) {\n  var blockedOn = findInstanceBlockingEvent(domEventName, eventSystemFlags, targetContainer, nativeEvent);\n\n  if (blockedOn === null) {\n    dispatchEventForPluginEventSystem(domEventName, eventSystemFlags, nativeEvent, return_targetInst, targetContainer);\n    clearIfContinuousEvent(domEventName, nativeEvent);\n    return;\n  }\n\n  if (queueIfContinuousEvent(blockedOn, domEventName, eventSystemFlags, targetContainer, nativeEvent)) {\n    nativeEvent.stopPropagation();\n    return;\n  } // We need to clear only if we didn't queue because\n  // queueing is accumulative.\n\n\n  clearIfContinuousEvent(domEventName, nativeEvent);\n\n  if (eventSystemFlags & IS_CAPTURE_PHASE && isDiscreteEventThatRequiresHydration(domEventName)) {\n    while (blockedOn !== null) {\n      var fiber = getInstanceFromNode(blockedOn);\n\n      if (fiber !== null) {\n        attemptSynchronousHydration(fiber);\n      }\n\n      var nextBlockedOn = findInstanceBlockingEvent(domEventName, eventSystemFlags, targetContainer, nativeEvent);\n\n      if (nextBlockedOn === null) {\n        dispatchEventForPluginEventSystem(domEventName, eventSystemFlags, nativeEvent, return_targetInst, targetContainer);\n      }\n\n      if (nextBlockedOn === blockedOn) {\n        break;\n      }\n\n      blockedOn = nextBlockedOn;\n    }\n\n    if (blockedOn !== null) {\n      nativeEvent.stopPropagation();\n    }\n\n    return;\n  } // This is not replayable so we'll invoke it but without a target,\n  // in case the event system needs to trace it.\n\n\n  dispatchEventForPluginEventSystem(domEventName, eventSystemFlags, nativeEvent, null, targetContainer);\n}\n\nvar return_targetInst = null; // Returns a SuspenseInstance or Container if it's blocked.\n// The return_targetInst field above is conceptually part of the return value.\n\nfunction findInstanceBlockingEvent(domEventName, eventSystemFlags, targetContainer, nativeEvent) {\n  // TODO: Warn if _enabled is false.\n  return_targetInst = null;\n  var nativeEventTarget = getEventTarget(nativeEvent);\n  var targetInst = getClosestInstanceFromNode(nativeEventTarget);\n\n  if (targetInst !== null) {\n    var nearestMounted = getNearestMountedFiber(targetInst);\n\n    if (nearestMounted === null) {\n      // This tree has been unmounted already. Dispatch without a target.\n      targetInst = null;\n    } else {\n      var tag = nearestMounted.tag;\n\n      if (tag === SuspenseComponent) {\n        var instance = getSuspenseInstanceFromFiber(nearestMounted);\n\n        if (instance !== null) {\n          // Queue the event to be replayed later. Abort dispatching since we\n          // don't want this event dispatched twice through the event system.\n          // TODO: If this is the first discrete event in the queue. Schedule an increased\n          // priority for this boundary.\n          return instance;\n        } // This shouldn't happen, something went wrong but to avoid blocking\n        // the whole system, dispatch the event without a target.\n        // TODO: Warn.\n\n\n        targetInst = null;\n      } else if (tag === HostRoot) {\n        var root = nearestMounted.stateNode;\n\n        if (isRootDehydrated(root)) {\n          // If this happens during a replay something went wrong and it might block\n          // the whole system.\n          return getContainerFromFiber(nearestMounted);\n        }\n\n        targetInst = null;\n      } else if (nearestMounted !== targetInst) {\n        // If we get an event (ex: img onload) before committing that\n        // component's mount, ignore it for now (that is, treat it as if it was an\n        // event on a non-React tree). We might also consider queueing events and\n        // dispatching them after the mount.\n        targetInst = null;\n      }\n    }\n  }\n\n  return_targetInst = targetInst; // We're not blocked on anything.\n\n  return null;\n}\nfunction getEventPriority(domEventName) {\n  switch (domEventName) {\n    // Used by SimpleEventPlugin:\n    case 'cancel':\n    case 'click':\n    case 'close':\n    case 'contextmenu':\n    case 'copy':\n    case 'cut':\n    case 'auxclick':\n    case 'dblclick':\n    case 'dragend':\n    case 'dragstart':\n    case 'drop':\n    case 'focusin':\n    case 'focusout':\n    case 'input':\n    case 'invalid':\n    case 'keydown':\n    case 'keypress':\n    case 'keyup':\n    case 'mousedown':\n    case 'mouseup':\n    case 'paste':\n    case 'pause':\n    case 'play':\n    case 'pointercancel':\n    case 'pointerdown':\n    case 'pointerup':\n    case 'ratechange':\n    case 'reset':\n    case 'resize':\n    case 'seeked':\n    case 'submit':\n    case 'touchcancel':\n    case 'touchend':\n    case 'touchstart':\n    case 'volumechange': // Used by polyfills:\n    // eslint-disable-next-line no-fallthrough\n\n    case 'change':\n    case 'selectionchange':\n    case 'textInput':\n    case 'compositionstart':\n    case 'compositionend':\n    case 'compositionupdate': // Only enableCreateEventHandleAPI:\n    // eslint-disable-next-line no-fallthrough\n\n    case 'beforeblur':\n    case 'afterblur': // Not used by React but could be by user code:\n    // eslint-disable-next-line no-fallthrough\n\n    case 'beforeinput':\n    case 'blur':\n    case 'fullscreenchange':\n    case 'focus':\n    case 'hashchange':\n    case 'popstate':\n    case 'select':\n    case 'selectstart':\n      return DiscreteEventPriority;\n\n    case 'drag':\n    case 'dragenter':\n    case 'dragexit':\n    case 'dragleave':\n    case 'dragover':\n    case 'mousemove':\n    case 'mouseout':\n    case 'mouseover':\n    case 'pointermove':\n    case 'pointerout':\n    case 'pointerover':\n    case 'scroll':\n    case 'toggle':\n    case 'touchmove':\n    case 'wheel': // Not used by React but could be by user code:\n    // eslint-disable-next-line no-fallthrough\n\n    case 'mouseenter':\n    case 'mouseleave':\n    case 'pointerenter':\n    case 'pointerleave':\n      return ContinuousEventPriority;\n\n    case 'message':\n      {\n        // We might be in the Scheduler callback.\n        // Eventually this mechanism will be replaced by a check\n        // of the current priority on the native scheduler.\n        var schedulerPriority = getCurrentPriorityLevel();\n\n        switch (schedulerPriority) {\n          case ImmediatePriority:\n            return DiscreteEventPriority;\n\n          case UserBlockingPriority:\n            return ContinuousEventPriority;\n\n          case NormalPriority:\n          case LowPriority:\n            // TODO: Handle LowSchedulerPriority, somehow. Maybe the same lane as hydration.\n            return DefaultEventPriority;\n\n          case IdlePriority:\n            return IdleEventPriority;\n\n          default:\n            return DefaultEventPriority;\n        }\n      }\n\n    default:\n      return DefaultEventPriority;\n  }\n}\n\nfunction addEventBubbleListener(target, eventType, listener) {\n  target.addEventListener(eventType, listener, false);\n  return listener;\n}\nfunction addEventCaptureListener(target, eventType, listener) {\n  target.addEventListener(eventType, listener, true);\n  return listener;\n}\nfunction addEventCaptureListenerWithPassiveFlag(target, eventType, listener, passive) {\n  target.addEventListener(eventType, listener, {\n    capture: true,\n    passive: passive\n  });\n  return listener;\n}\nfunction addEventBubbleListenerWithPassiveFlag(target, eventType, listener, passive) {\n  target.addEventListener(eventType, listener, {\n    passive: passive\n  });\n  return listener;\n}\n\n/**\n * These variables store information about text content of a target node,\n * allowing comparison of content before and after a given event.\n *\n * Identify the node where selection currently begins, then observe\n * both its text content and its current position in the DOM. Since the\n * browser may natively replace the target node during composition, we can\n * use its position to find its replacement.\n *\n *\n */\nvar root = null;\nvar startText = null;\nvar fallbackText = null;\nfunction initialize(nativeEventTarget) {\n  root = nativeEventTarget;\n  startText = getText();\n  return true;\n}\nfunction reset() {\n  root = null;\n  startText = null;\n  fallbackText = null;\n}\nfunction getData() {\n  if (fallbackText) {\n    return fallbackText;\n  }\n\n  var start;\n  var startValue = startText;\n  var startLength = startValue.length;\n  var end;\n  var endValue = getText();\n  var endLength = endValue.length;\n\n  for (start = 0; start < startLength; start++) {\n    if (startValue[start] !== endValue[start]) {\n      break;\n    }\n  }\n\n  var minEnd = startLength - start;\n\n  for (end = 1; end <= minEnd; end++) {\n    if (startValue[startLength - end] !== endValue[endLength - end]) {\n      break;\n    }\n  }\n\n  var sliceTail = end > 1 ? 1 - end : undefined;\n  fallbackText = endValue.slice(start, sliceTail);\n  return fallbackText;\n}\nfunction getText() {\n  if ('value' in root) {\n    return root.value;\n  }\n\n  return root.textContent;\n}\n\n/**\n * `charCode` represents the actual \"character code\" and is safe to use with\n * `String.fromCharCode`. As such, only keys that correspond to printable\n * characters produce a valid `charCode`, the only exception to this is Enter.\n * The Tab-key is considered non-printable and does not have a `charCode`,\n * presumably because it does not produce a tab-character in browsers.\n *\n * @param {object} nativeEvent Native browser event.\n * @return {number} Normalized `charCode` property.\n */\nfunction getEventCharCode(nativeEvent) {\n  var charCode;\n  var keyCode = nativeEvent.keyCode;\n\n  if ('charCode' in nativeEvent) {\n    charCode = nativeEvent.charCode; // FF does not set `charCode` for the Enter-key, check against `keyCode`.\n\n    if (charCode === 0 && keyCode === 13) {\n      charCode = 13;\n    }\n  } else {\n    // IE8 does not implement `charCode`, but `keyCode` has the correct value.\n    charCode = keyCode;\n  } // IE and Edge (on Windows) and Chrome / Safari (on Windows and Linux)\n  // report Enter as charCode 10 when ctrl is pressed.\n\n\n  if (charCode === 10) {\n    charCode = 13;\n  } // Some non-printable keys are reported in `charCode`/`keyCode`, discard them.\n  // Must not discard the (non-)printable Enter-key.\n\n\n  if (charCode >= 32 || charCode === 13) {\n    return charCode;\n  }\n\n  return 0;\n}\n\nfunction functionThatReturnsTrue() {\n  return true;\n}\n\nfunction functionThatReturnsFalse() {\n  return false;\n} // This is intentionally a factory so that we have different returned constructors.\n// If we had a single constructor, it would be megamorphic and engines would deopt.\n\n\nfunction createSyntheticEvent(Interface) {\n  /**\n   * Synthetic events are dispatched by event plugins, typically in response to a\n   * top-level event delegation handler.\n   *\n   * These systems should generally use pooling to reduce the frequency of garbage\n   * collection. The system should check `isPersistent` to determine whether the\n   * event should be released into the pool after being dispatched. Users that\n   * need a persisted event should invoke `persist`.\n   *\n   * Synthetic events (and subclasses) implement the DOM Level 3 Events API by\n   * normalizing browser quirks. Subclasses do not necessarily have to implement a\n   * DOM interface; custom application-specific events can also subclass this.\n   */\n  function SyntheticBaseEvent(reactName, reactEventType, targetInst, nativeEvent, nativeEventTarget) {\n    this._reactName = reactName;\n    this._targetInst = targetInst;\n    this.type = reactEventType;\n    this.nativeEvent = nativeEvent;\n    this.target = nativeEventTarget;\n    this.currentTarget = null;\n\n    for (var _propName in Interface) {\n      if (!Interface.hasOwnProperty(_propName)) {\n        continue;\n      }\n\n      var normalize = Interface[_propName];\n\n      if (normalize) {\n        this[_propName] = normalize(nativeEvent);\n      } else {\n        this[_propName] = nativeEvent[_propName];\n      }\n    }\n\n    var defaultPrevented = nativeEvent.defaultPrevented != null ? nativeEvent.defaultPrevented : nativeEvent.returnValue === false;\n\n    if (defaultPrevented) {\n      this.isDefaultPrevented = functionThatReturnsTrue;\n    } else {\n      this.isDefaultPrevented = functionThatReturnsFalse;\n    }\n\n    this.isPropagationStopped = functionThatReturnsFalse;\n    return this;\n  }\n\n  assign(SyntheticBaseEvent.prototype, {\n    preventDefault: function () {\n      this.defaultPrevented = true;\n      var event = this.nativeEvent;\n\n      if (!event) {\n        return;\n      }\n\n      if (event.preventDefault) {\n        event.preventDefault(); // $FlowFixMe - flow is not aware of `unknown` in IE\n      } else if (typeof event.returnValue !== 'unknown') {\n        event.returnValue = false;\n      }\n\n      this.isDefaultPrevented = functionThatReturnsTrue;\n    },\n    stopPropagation: function () {\n      var event = this.nativeEvent;\n\n      if (!event) {\n        return;\n      }\n\n      if (event.stopPropagation) {\n        event.stopPropagation(); // $FlowFixMe - flow is not aware of `unknown` in IE\n      } else if (typeof event.cancelBubble !== 'unknown') {\n        // The ChangeEventPlugin registers a \"propertychange\" event for\n        // IE. This event does not support bubbling or cancelling, and\n        // any references to cancelBubble throw \"Member not found\".  A\n        // typeof check of \"unknown\" circumvents this issue (and is also\n        // IE specific).\n        event.cancelBubble = true;\n      }\n\n      this.isPropagationStopped = functionThatReturnsTrue;\n    },\n\n    /**\n     * We release all dispatched `SyntheticEvent`s after each event loop, adding\n     * them back into the pool. This allows a way to hold onto a reference that\n     * won't be added back into the pool.\n     */\n    persist: function () {// Modern event system doesn't use pooling.\n    },\n\n    /**\n     * Checks if this event should be released back into the pool.\n     *\n     * @return {boolean} True if this should not be released, false otherwise.\n     */\n    isPersistent: functionThatReturnsTrue\n  });\n  return SyntheticBaseEvent;\n}\n/**\n * @interface Event\n * @see http://www.w3.org/TR/DOM-Level-3-Events/\n */\n\n\nvar EventInterface = {\n  eventPhase: 0,\n  bubbles: 0,\n  cancelable: 0,\n  timeStamp: function (event) {\n    return event.timeStamp || Date.now();\n  },\n  defaultPrevented: 0,\n  isTrusted: 0\n};\nvar SyntheticEvent = createSyntheticEvent(EventInterface);\n\nvar UIEventInterface = assign({}, EventInterface, {\n  view: 0,\n  detail: 0\n});\n\nvar SyntheticUIEvent = createSyntheticEvent(UIEventInterface);\nvar lastMovementX;\nvar lastMovementY;\nvar lastMouseEvent;\n\nfunction updateMouseMovementPolyfillState(event) {\n  if (event !== lastMouseEvent) {\n    if (lastMouseEvent && event.type === 'mousemove') {\n      lastMovementX = event.screenX - lastMouseEvent.screenX;\n      lastMovementY = event.screenY - lastMouseEvent.screenY;\n    } else {\n      lastMovementX = 0;\n      lastMovementY = 0;\n    }\n\n    lastMouseEvent = event;\n  }\n}\n/**\n * @interface MouseEvent\n * @see http://www.w3.org/TR/DOM-Level-3-Events/\n */\n\n\nvar MouseEventInterface = assign({}, UIEventInterface, {\n  screenX: 0,\n  screenY: 0,\n  clientX: 0,\n  clientY: 0,\n  pageX: 0,\n  pageY: 0,\n  ctrlKey: 0,\n  shiftKey: 0,\n  altKey: 0,\n  metaKey: 0,\n  getModifierState: getEventModifierState,\n  button: 0,\n  buttons: 0,\n  relatedTarget: function (event) {\n    if (event.relatedTarget === undefined) return event.fromElement === event.srcElement ? event.toElement : event.fromElement;\n    return event.relatedTarget;\n  },\n  movementX: function (event) {\n    if ('movementX' in event) {\n      return event.movementX;\n    }\n\n    updateMouseMovementPolyfillState(event);\n    return lastMovementX;\n  },\n  movementY: function (event) {\n    if ('movementY' in event) {\n      return event.movementY;\n    } // Don't need to call updateMouseMovementPolyfillState() here\n    // because it's guaranteed to have already run when movementX\n    // was copied.\n\n\n    return lastMovementY;\n  }\n});\n\nvar SyntheticMouseEvent = createSyntheticEvent(MouseEventInterface);\n/**\n * @interface DragEvent\n * @see http://www.w3.org/TR/DOM-Level-3-Events/\n */\n\nvar DragEventInterface = assign({}, MouseEventInterface, {\n  dataTransfer: 0\n});\n\nvar SyntheticDragEvent = createSyntheticEvent(DragEventInterface);\n/**\n * @interface FocusEvent\n * @see http://www.w3.org/TR/DOM-Level-3-Events/\n */\n\nvar FocusEventInterface = assign({}, UIEventInterface, {\n  relatedTarget: 0\n});\n\nvar SyntheticFocusEvent = createSyntheticEvent(FocusEventInterface);\n/**\n * @interface Event\n * @see http://www.w3.org/TR/css3-animations/#AnimationEvent-interface\n * @see https://developer.mozilla.org/en-US/docs/Web/API/AnimationEvent\n */\n\nvar AnimationEventInterface = assign({}, EventInterface, {\n  animationName: 0,\n  elapsedTime: 0,\n  pseudoElement: 0\n});\n\nvar SyntheticAnimationEvent = createSyntheticEvent(AnimationEventInterface);\n/**\n * @interface Event\n * @see http://www.w3.org/TR/clipboard-apis/\n */\n\nvar ClipboardEventInterface = assign({}, EventInterface, {\n  clipboardData: function (event) {\n    return 'clipboardData' in event ? event.clipboardData : window.clipboardData;\n  }\n});\n\nvar SyntheticClipboardEvent = createSyntheticEvent(ClipboardEventInterface);\n/**\n * @interface Event\n * @see http://www.w3.org/TR/DOM-Level-3-Events/#events-compositionevents\n */\n\nvar CompositionEventInterface = assign({}, EventInterface, {\n  data: 0\n});\n\nvar SyntheticCompositionEvent = createSyntheticEvent(CompositionEventInterface);\n/**\n * @interface Event\n * @see http://www.w3.org/TR/2013/WD-DOM-Level-3-Events-20131105\n *      /#events-inputevents\n */\n// Happens to share the same list for now.\n\nvar SyntheticInputEvent = SyntheticCompositionEvent;\n/**\n * Normalization of deprecated HTML5 `key` values\n * @see https://developer.mozilla.org/en-US/docs/Web/API/KeyboardEvent#Key_names\n */\n\nvar normalizeKey = {\n  Esc: 'Escape',\n  Spacebar: ' ',\n  Left: 'ArrowLeft',\n  Up: 'ArrowUp',\n  Right: 'ArrowRight',\n  Down: 'ArrowDown',\n  Del: 'Delete',\n  Win: 'OS',\n  Menu: 'ContextMenu',\n  Apps: 'ContextMenu',\n  Scroll: 'ScrollLock',\n  MozPrintableKey: 'Unidentified'\n};\n/**\n * Translation from legacy `keyCode` to HTML5 `key`\n * Only special keys supported, all others depend on keyboard layout or browser\n * @see https://developer.mozilla.org/en-US/docs/Web/API/KeyboardEvent#Key_names\n */\n\nvar translateToKey = {\n  '8': 'Backspace',\n  '9': 'Tab',\n  '12': 'Clear',\n  '13': 'Enter',\n  '16': 'Shift',\n  '17': 'Control',\n  '18': 'Alt',\n  '19': 'Pause',\n  '20': 'CapsLock',\n  '27': 'Escape',\n  '32': ' ',\n  '33': 'PageUp',\n  '34': 'PageDown',\n  '35': 'End',\n  '36': 'Home',\n  '37': 'ArrowLeft',\n  '38': 'ArrowUp',\n  '39': 'ArrowRight',\n  '40': 'ArrowDown',\n  '45': 'Insert',\n  '46': 'Delete',\n  '112': 'F1',\n  '113': 'F2',\n  '114': 'F3',\n  '115': 'F4',\n  '116': 'F5',\n  '117': 'F6',\n  '118': 'F7',\n  '119': 'F8',\n  '120': 'F9',\n  '121': 'F10',\n  '122': 'F11',\n  '123': 'F12',\n  '144': 'NumLock',\n  '145': 'ScrollLock',\n  '224': 'Meta'\n};\n/**\n * @param {object} nativeEvent Native browser event.\n * @return {string} Normalized `key` property.\n */\n\nfunction getEventKey(nativeEvent) {\n  if (nativeEvent.key) {\n    // Normalize inconsistent values reported by browsers due to\n    // implementations of a working draft specification.\n    // FireFox implements `key` but returns `MozPrintableKey` for all\n    // printable characters (normalized to `Unidentified`), ignore it.\n    var key = normalizeKey[nativeEvent.key] || nativeEvent.key;\n\n    if (key !== 'Unidentified') {\n      return key;\n    }\n  } // Browser does not implement `key`, polyfill as much of it as we can.\n\n\n  if (nativeEvent.type === 'keypress') {\n    var charCode = getEventCharCode(nativeEvent); // The enter-key is technically both printable and non-printable and can\n    // thus be captured by `keypress`, no other non-printable key should.\n\n    return charCode === 13 ? 'Enter' : String.fromCharCode(charCode);\n  }\n\n  if (nativeEvent.type === 'keydown' || nativeEvent.type === 'keyup') {\n    // While user keyboard layout determines the actual meaning of each\n    // `keyCode` value, almost all function keys have a universal value.\n    return translateToKey[nativeEvent.keyCode] || 'Unidentified';\n  }\n\n  return '';\n}\n/**\n * Translation from modifier key to the associated property in the event.\n * @see http://www.w3.org/TR/DOM-Level-3-Events/#keys-Modifiers\n */\n\n\nvar modifierKeyToProp = {\n  Alt: 'altKey',\n  Control: 'ctrlKey',\n  Meta: 'metaKey',\n  Shift: 'shiftKey'\n}; // Older browsers (Safari <= 10, iOS Safari <= 10.2) do not support\n// getModifierState. If getModifierState is not supported, we map it to a set of\n// modifier keys exposed by the event. In this case, Lock-keys are not supported.\n\nfunction modifierStateGetter(keyArg) {\n  var syntheticEvent = this;\n  var nativeEvent = syntheticEvent.nativeEvent;\n\n  if (nativeEvent.getModifierState) {\n    return nativeEvent.getModifierState(keyArg);\n  }\n\n  var keyProp = modifierKeyToProp[keyArg];\n  return keyProp ? !!nativeEvent[keyProp] : false;\n}\n\nfunction getEventModifierState(nativeEvent) {\n  return modifierStateGetter;\n}\n/**\n * @interface KeyboardEvent\n * @see http://www.w3.org/TR/DOM-Level-3-Events/\n */\n\n\nvar KeyboardEventInterface = assign({}, UIEventInterface, {\n  key: getEventKey,\n  code: 0,\n  location: 0,\n  ctrlKey: 0,\n  shiftKey: 0,\n  altKey: 0,\n  metaKey: 0,\n  repeat: 0,\n  locale: 0,\n  getModifierState: getEventModifierState,\n  // Legacy Interface\n  charCode: function (event) {\n    // `charCode` is the result of a KeyPress event and represents the value of\n    // the actual printable character.\n    // KeyPress is deprecated, but its replacement is not yet final and not\n    // implemented in any major browser. Only KeyPress has charCode.\n    if (event.type === 'keypress') {\n      return getEventCharCode(event);\n    }\n\n    return 0;\n  },\n  keyCode: function (event) {\n    // `keyCode` is the result of a KeyDown/Up event and represents the value of\n    // physical keyboard key.\n    // The actual meaning of the value depends on the users' keyboard layout\n    // which cannot be detected. Assuming that it is a US keyboard layout\n    // provides a surprisingly accurate mapping for US and European users.\n    // Due to this, it is left to the user to implement at this time.\n    if (event.type === 'keydown' || event.type === 'keyup') {\n      return event.keyCode;\n    }\n\n    return 0;\n  },\n  which: function (event) {\n    // `which` is an alias for either `keyCode` or `charCode` depending on the\n    // type of the event.\n    if (event.type === 'keypress') {\n      return getEventCharCode(event);\n    }\n\n    if (event.type === 'keydown' || event.type === 'keyup') {\n      return event.keyCode;\n    }\n\n    return 0;\n  }\n});\n\nvar SyntheticKeyboardEvent = createSyntheticEvent(KeyboardEventInterface);\n/**\n * @interface PointerEvent\n * @see http://www.w3.org/TR/pointerevents/\n */\n\nvar PointerEventInterface = assign({}, MouseEventInterface, {\n  pointerId: 0,\n  width: 0,\n  height: 0,\n  pressure: 0,\n  tangentialPressure: 0,\n  tiltX: 0,\n  tiltY: 0,\n  twist: 0,\n  pointerType: 0,\n  isPrimary: 0\n});\n\nvar SyntheticPointerEvent = createSyntheticEvent(PointerEventInterface);\n/**\n * @interface TouchEvent\n * @see http://www.w3.org/TR/touch-events/\n */\n\nvar TouchEventInterface = assign({}, UIEventInterface, {\n  touches: 0,\n  targetTouches: 0,\n  changedTouches: 0,\n  altKey: 0,\n  metaKey: 0,\n  ctrlKey: 0,\n  shiftKey: 0,\n  getModifierState: getEventModifierState\n});\n\nvar SyntheticTouchEvent = createSyntheticEvent(TouchEventInterface);\n/**\n * @interface Event\n * @see http://www.w3.org/TR/2009/WD-css3-transitions-20090320/#transition-events-\n * @see https://developer.mozilla.org/en-US/docs/Web/API/TransitionEvent\n */\n\nvar TransitionEventInterface = assign({}, EventInterface, {\n  propertyName: 0,\n  elapsedTime: 0,\n  pseudoElement: 0\n});\n\nvar SyntheticTransitionEvent = createSyntheticEvent(TransitionEventInterface);\n/**\n * @interface WheelEvent\n * @see http://www.w3.org/TR/DOM-Level-3-Events/\n */\n\nvar WheelEventInterface = assign({}, MouseEventInterface, {\n  deltaX: function (event) {\n    return 'deltaX' in event ? event.deltaX : // Fallback to `wheelDeltaX` for Webkit and normalize (right is positive).\n    'wheelDeltaX' in event ? -event.wheelDeltaX : 0;\n  },\n  deltaY: function (event) {\n    return 'deltaY' in event ? event.deltaY : // Fallback to `wheelDeltaY` for Webkit and normalize (down is positive).\n    'wheelDeltaY' in event ? -event.wheelDeltaY : // Fallback to `wheelDelta` for IE<9 and normalize (down is positive).\n    'wheelDelta' in event ? -event.wheelDelta : 0;\n  },\n  deltaZ: 0,\n  // Browsers without \"deltaMode\" is reporting in raw wheel delta where one\n  // notch on the scroll is always +/- 120, roughly equivalent to pixels.\n  // A good approximation of DOM_DELTA_LINE (1) is 5% of viewport size or\n  // ~40 pixels, for DOM_DELTA_SCREEN (2) it is 87.5% of viewport size.\n  deltaMode: 0\n});\n\nvar SyntheticWheelEvent = createSyntheticEvent(WheelEventInterface);\n\nvar END_KEYCODES = [9, 13, 27, 32]; // Tab, Return, Esc, Space\n\nvar START_KEYCODE = 229;\nvar canUseCompositionEvent = canUseDOM && 'CompositionEvent' in window;\nvar documentMode = null;\n\nif (canUseDOM && 'documentMode' in document) {\n  documentMode = document.documentMode;\n} // Webkit offers a very useful `textInput` event that can be used to\n// directly represent `beforeInput`. The IE `textinput` event is not as\n// useful, so we don't use it.\n\n\nvar canUseTextInputEvent = canUseDOM && 'TextEvent' in window && !documentMode; // In IE9+, we have access to composition events, but the data supplied\n// by the native compositionend event may be incorrect. Japanese ideographic\n// spaces, for instance (\\u3000) are not recorded correctly.\n\nvar useFallbackCompositionData = canUseDOM && (!canUseCompositionEvent || documentMode && documentMode > 8 && documentMode <= 11);\nvar SPACEBAR_CODE = 32;\nvar SPACEBAR_CHAR = String.fromCharCode(SPACEBAR_CODE);\n\nfunction registerEvents() {\n  registerTwoPhaseEvent('onBeforeInput', ['compositionend', 'keypress', 'textInput', 'paste']);\n  registerTwoPhaseEvent('onCompositionEnd', ['compositionend', 'focusout', 'keydown', 'keypress', 'keyup', 'mousedown']);\n  registerTwoPhaseEvent('onCompositionStart', ['compositionstart', 'focusout', 'keydown', 'keypress', 'keyup', 'mousedown']);\n  registerTwoPhaseEvent('onCompositionUpdate', ['compositionupdate', 'focusout', 'keydown', 'keypress', 'keyup', 'mousedown']);\n} // Track whether we've ever handled a keypress on the space key.\n\n\nvar hasSpaceKeypress = false;\n/**\n * Return whether a native keypress event is assumed to be a command.\n * This is required because Firefox fires `keypress` events for key commands\n * (cut, copy, select-all, etc.) even though no character is inserted.\n */\n\nfunction isKeypressCommand(nativeEvent) {\n  return (nativeEvent.ctrlKey || nativeEvent.altKey || nativeEvent.metaKey) && // ctrlKey && altKey is equivalent to AltGr, and is not a command.\n  !(nativeEvent.ctrlKey && nativeEvent.altKey);\n}\n/**\n * Translate native top level events into event types.\n */\n\n\nfunction getCompositionEventType(domEventName) {\n  switch (domEventName) {\n    case 'compositionstart':\n      return 'onCompositionStart';\n\n    case 'compositionend':\n      return 'onCompositionEnd';\n\n    case 'compositionupdate':\n      return 'onCompositionUpdate';\n  }\n}\n/**\n * Does our fallback best-guess model think this event signifies that\n * composition has begun?\n */\n\n\nfunction isFallbackCompositionStart(domEventName, nativeEvent) {\n  return domEventName === 'keydown' && nativeEvent.keyCode === START_KEYCODE;\n}\n/**\n * Does our fallback mode think that this event is the end of composition?\n */\n\n\nfunction isFallbackCompositionEnd(domEventName, nativeEvent) {\n  switch (domEventName) {\n    case 'keyup':\n      // Command keys insert or clear IME input.\n      return END_KEYCODES.indexOf(nativeEvent.keyCode) !== -1;\n\n    case 'keydown':\n      // Expect IME keyCode on each keydown. If we get any other\n      // code we must have exited earlier.\n      return nativeEvent.keyCode !== START_KEYCODE;\n\n    case 'keypress':\n    case 'mousedown':\n    case 'focusout':\n      // Events are not possible without cancelling IME.\n      return true;\n\n    default:\n      return false;\n  }\n}\n/**\n * Google Input Tools provides composition data via a CustomEvent,\n * with the `data` property populated in the `detail` object. If this\n * is available on the event object, use it. If not, this is a plain\n * composition event and we have nothing special to extract.\n *\n * @param {object} nativeEvent\n * @return {?string}\n */\n\n\nfunction getDataFromCustomEvent(nativeEvent) {\n  var detail = nativeEvent.detail;\n\n  if (typeof detail === 'object' && 'data' in detail) {\n    return detail.data;\n  }\n\n  return null;\n}\n/**\n * Check if a composition event was triggered by Korean IME.\n * Our fallback mode does not work well with IE's Korean IME,\n * so just use native composition events when Korean IME is used.\n * Although CompositionEvent.locale property is deprecated,\n * it is available in IE, where our fallback mode is enabled.\n *\n * @param {object} nativeEvent\n * @return {boolean}\n */\n\n\nfunction isUsingKoreanIME(nativeEvent) {\n  return nativeEvent.locale === 'ko';\n} // Track the current IME composition status, if any.\n\n\nvar isComposing = false;\n/**\n * @return {?object} A SyntheticCompositionEvent.\n */\n\nfunction extractCompositionEvent(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget) {\n  var eventType;\n  var fallbackData;\n\n  if (canUseCompositionEvent) {\n    eventType = getCompositionEventType(domEventName);\n  } else if (!isComposing) {\n    if (isFallbackCompositionStart(domEventName, nativeEvent)) {\n      eventType = 'onCompositionStart';\n    }\n  } else if (isFallbackCompositionEnd(domEventName, nativeEvent)) {\n    eventType = 'onCompositionEnd';\n  }\n\n  if (!eventType) {\n    return null;\n  }\n\n  if (useFallbackCompositionData && !isUsingKoreanIME(nativeEvent)) {\n    // The current composition is stored statically and must not be\n    // overwritten while composition continues.\n    if (!isComposing && eventType === 'onCompositionStart') {\n      isComposing = initialize(nativeEventTarget);\n    } else if (eventType === 'onCompositionEnd') {\n      if (isComposing) {\n        fallbackData = getData();\n      }\n    }\n  }\n\n  var listeners = accumulateTwoPhaseListeners(targetInst, eventType);\n\n  if (listeners.length > 0) {\n    var event = new SyntheticCompositionEvent(eventType, domEventName, null, nativeEvent, nativeEventTarget);\n    dispatchQueue.push({\n      event: event,\n      listeners: listeners\n    });\n\n    if (fallbackData) {\n      // Inject data generated from fallback path into the synthetic event.\n      // This matches the property of native CompositionEventInterface.\n      event.data = fallbackData;\n    } else {\n      var customData = getDataFromCustomEvent(nativeEvent);\n\n      if (customData !== null) {\n        event.data = customData;\n      }\n    }\n  }\n}\n\nfunction getNativeBeforeInputChars(domEventName, nativeEvent) {\n  switch (domEventName) {\n    case 'compositionend':\n      return getDataFromCustomEvent(nativeEvent);\n\n    case 'keypress':\n      /**\n       * If native `textInput` events are available, our goal is to make\n       * use of them. However, there is a special case: the spacebar key.\n       * In Webkit, preventing default on a spacebar `textInput` event\n       * cancels character insertion, but it *also* causes the browser\n       * to fall back to its default spacebar behavior of scrolling the\n       * page.\n       *\n       * Tracking at:\n       * https://code.google.com/p/chromium/issues/detail?id=355103\n       *\n       * To avoid this issue, use the keypress event as if no `textInput`\n       * event is available.\n       */\n      var which = nativeEvent.which;\n\n      if (which !== SPACEBAR_CODE) {\n        return null;\n      }\n\n      hasSpaceKeypress = true;\n      return SPACEBAR_CHAR;\n\n    case 'textInput':\n      // Record the characters to be added to the DOM.\n      var chars = nativeEvent.data; // If it's a spacebar character, assume that we have already handled\n      // it at the keypress level and bail immediately. Android Chrome\n      // doesn't give us keycodes, so we need to ignore it.\n\n      if (chars === SPACEBAR_CHAR && hasSpaceKeypress) {\n        return null;\n      }\n\n      return chars;\n\n    default:\n      // For other native event types, do nothing.\n      return null;\n  }\n}\n/**\n * For browsers that do not provide the `textInput` event, extract the\n * appropriate string to use for SyntheticInputEvent.\n */\n\n\nfunction getFallbackBeforeInputChars(domEventName, nativeEvent) {\n  // If we are currently composing (IME) and using a fallback to do so,\n  // try to extract the composed characters from the fallback object.\n  // If composition event is available, we extract a string only at\n  // compositionevent, otherwise extract it at fallback events.\n  if (isComposing) {\n    if (domEventName === 'compositionend' || !canUseCompositionEvent && isFallbackCompositionEnd(domEventName, nativeEvent)) {\n      var chars = getData();\n      reset();\n      isComposing = false;\n      return chars;\n    }\n\n    return null;\n  }\n\n  switch (domEventName) {\n    case 'paste':\n      // If a paste event occurs after a keypress, throw out the input\n      // chars. Paste events should not lead to BeforeInput events.\n      return null;\n\n    case 'keypress':\n      /**\n       * As of v27, Firefox may fire keypress events even when no character\n       * will be inserted. A few possibilities:\n       *\n       * - `which` is `0`. Arrow keys, Esc key, etc.\n       *\n       * - `which` is the pressed key code, but no char is available.\n       *   Ex: 'AltGr + d` in Polish. There is no modified character for\n       *   this key combination and no character is inserted into the\n       *   document, but FF fires the keypress for char code `100` anyway.\n       *   No `input` event will occur.\n       *\n       * - `which` is the pressed key code, but a command combination is\n       *   being used. Ex: `Cmd+C`. No character is inserted, and no\n       *   `input` event will occur.\n       */\n      if (!isKeypressCommand(nativeEvent)) {\n        // IE fires the `keypress` event when a user types an emoji via\n        // Touch keyboard of Windows.  In such a case, the `char` property\n        // holds an emoji character like `\\uD83D\\uDE0A`.  Because its length\n        // is 2, the property `which` does not represent an emoji correctly.\n        // In such a case, we directly return the `char` property instead of\n        // using `which`.\n        if (nativeEvent.char && nativeEvent.char.length > 1) {\n          return nativeEvent.char;\n        } else if (nativeEvent.which) {\n          return String.fromCharCode(nativeEvent.which);\n        }\n      }\n\n      return null;\n\n    case 'compositionend':\n      return useFallbackCompositionData && !isUsingKoreanIME(nativeEvent) ? null : nativeEvent.data;\n\n    default:\n      return null;\n  }\n}\n/**\n * Extract a SyntheticInputEvent for `beforeInput`, based on either native\n * `textInput` or fallback behavior.\n *\n * @return {?object} A SyntheticInputEvent.\n */\n\n\nfunction extractBeforeInputEvent(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget) {\n  var chars;\n\n  if (canUseTextInputEvent) {\n    chars = getNativeBeforeInputChars(domEventName, nativeEvent);\n  } else {\n    chars = getFallbackBeforeInputChars(domEventName, nativeEvent);\n  } // If no characters are being inserted, no BeforeInput event should\n  // be fired.\n\n\n  if (!chars) {\n    return null;\n  }\n\n  var listeners = accumulateTwoPhaseListeners(targetInst, 'onBeforeInput');\n\n  if (listeners.length > 0) {\n    var event = new SyntheticInputEvent('onBeforeInput', 'beforeinput', null, nativeEvent, nativeEventTarget);\n    dispatchQueue.push({\n      event: event,\n      listeners: listeners\n    });\n    event.data = chars;\n  }\n}\n/**\n * Create an `onBeforeInput` event to match\n * http://www.w3.org/TR/2013/WD-DOM-Level-3-Events-20131105/#events-inputevents.\n *\n * This event plugin is based on the native `textInput` event\n * available in Chrome, Safari, Opera, and IE. This event fires after\n * `onKeyPress` and `onCompositionEnd`, but before `onInput`.\n *\n * `beforeInput` is spec'd but not implemented in any browsers, and\n * the `input` event does not provide any useful information about what has\n * actually been added, contrary to the spec. Thus, `textInput` is the best\n * available event to identify the characters that have actually been inserted\n * into the target node.\n *\n * This plugin is also responsible for emitting `composition` events, thus\n * allowing us to share composition fallback code for both `beforeInput` and\n * `composition` event types.\n */\n\n\nfunction extractEvents(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget, eventSystemFlags, targetContainer) {\n  extractCompositionEvent(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget);\n  extractBeforeInputEvent(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget);\n}\n\n/**\n * @see http://www.whatwg.org/specs/web-apps/current-work/multipage/the-input-element.html#input-type-attr-summary\n */\nvar supportedInputTypes = {\n  color: true,\n  date: true,\n  datetime: true,\n  'datetime-local': true,\n  email: true,\n  month: true,\n  number: true,\n  password: true,\n  range: true,\n  search: true,\n  tel: true,\n  text: true,\n  time: true,\n  url: true,\n  week: true\n};\n\nfunction isTextInputElement(elem) {\n  var nodeName = elem && elem.nodeName && elem.nodeName.toLowerCase();\n\n  if (nodeName === 'input') {\n    return !!supportedInputTypes[elem.type];\n  }\n\n  if (nodeName === 'textarea') {\n    return true;\n  }\n\n  return false;\n}\n\n/**\n * Checks if an event is supported in the current execution environment.\n *\n * NOTE: This will not work correctly for non-generic events such as `change`,\n * `reset`, `load`, `error`, and `select`.\n *\n * Borrows from Modernizr.\n *\n * @param {string} eventNameSuffix Event name, e.g. \"click\".\n * @return {boolean} True if the event is supported.\n * @internal\n * @license Modernizr 3.0.0pre (Custom Build) | MIT\n */\n\nfunction isEventSupported(eventNameSuffix) {\n  if (!canUseDOM) {\n    return false;\n  }\n\n  var eventName = 'on' + eventNameSuffix;\n  var isSupported = (eventName in document);\n\n  if (!isSupported) {\n    var element = document.createElement('div');\n    element.setAttribute(eventName, 'return;');\n    isSupported = typeof element[eventName] === 'function';\n  }\n\n  return isSupported;\n}\n\nfunction registerEvents$1() {\n  registerTwoPhaseEvent('onChange', ['change', 'click', 'focusin', 'focusout', 'input', 'keydown', 'keyup', 'selectionchange']);\n}\n\nfunction createAndAccumulateChangeEvent(dispatchQueue, inst, nativeEvent, target) {\n  // Flag this event loop as needing state restore.\n  enqueueStateRestore(target);\n  var listeners = accumulateTwoPhaseListeners(inst, 'onChange');\n\n  if (listeners.length > 0) {\n    var event = new SyntheticEvent('onChange', 'change', null, nativeEvent, target);\n    dispatchQueue.push({\n      event: event,\n      listeners: listeners\n    });\n  }\n}\n/**\n * For IE shims\n */\n\n\nvar activeElement = null;\nvar activeElementInst = null;\n/**\n * SECTION: handle `change` event\n */\n\nfunction shouldUseChangeEvent(elem) {\n  var nodeName = elem.nodeName && elem.nodeName.toLowerCase();\n  return nodeName === 'select' || nodeName === 'input' && elem.type === 'file';\n}\n\nfunction manualDispatchChangeEvent(nativeEvent) {\n  var dispatchQueue = [];\n  createAndAccumulateChangeEvent(dispatchQueue, activeElementInst, nativeEvent, getEventTarget(nativeEvent)); // If change and propertychange bubbled, we'd just bind to it like all the\n  // other events and have it go through ReactBrowserEventEmitter. Since it\n  // doesn't, we manually listen for the events and so we have to enqueue and\n  // process the abstract event manually.\n  //\n  // Batching is necessary here in order to ensure that all event handlers run\n  // before the next rerender (including event handlers attached to ancestor\n  // elements instead of directly on the input). Without this, controlled\n  // components don't work properly in conjunction with event bubbling because\n  // the component is rerendered and the value reverted before all the event\n  // handlers can run. See https://github.com/facebook/react/issues/708.\n\n  batchedUpdates(runEventInBatch, dispatchQueue);\n}\n\nfunction runEventInBatch(dispatchQueue) {\n  processDispatchQueue(dispatchQueue, 0);\n}\n\nfunction getInstIfValueChanged(targetInst) {\n  var targetNode = getNodeFromInstance(targetInst);\n\n  if (updateValueIfChanged(targetNode)) {\n    return targetInst;\n  }\n}\n\nfunction getTargetInstForChangeEvent(domEventName, targetInst) {\n  if (domEventName === 'change') {\n    return targetInst;\n  }\n}\n/**\n * SECTION: handle `input` event\n */\n\n\nvar isInputEventSupported = false;\n\nif (canUseDOM) {\n  // IE9 claims to support the input event but fails to trigger it when\n  // deleting text, so we ignore its input events.\n  isInputEventSupported = isEventSupported('input') && (!document.documentMode || document.documentMode > 9);\n}\n/**\n * (For IE <=9) Starts tracking propertychange events on the passed-in element\n * and override the value property so that we can distinguish user events from\n * value changes in JS.\n */\n\n\nfunction startWatchingForValueChange(target, targetInst) {\n  activeElement = target;\n  activeElementInst = targetInst;\n  activeElement.attachEvent('onpropertychange', handlePropertyChange);\n}\n/**\n * (For IE <=9) Removes the event listeners from the currently-tracked element,\n * if any exists.\n */\n\n\nfunction stopWatchingForValueChange() {\n  if (!activeElement) {\n    return;\n  }\n\n  activeElement.detachEvent('onpropertychange', handlePropertyChange);\n  activeElement = null;\n  activeElementInst = null;\n}\n/**\n * (For IE <=9) Handles a propertychange event, sending a `change` event if\n * the value of the active element has changed.\n */\n\n\nfunction handlePropertyChange(nativeEvent) {\n  if (nativeEvent.propertyName !== 'value') {\n    return;\n  }\n\n  if (getInstIfValueChanged(activeElementInst)) {\n    manualDispatchChangeEvent(nativeEvent);\n  }\n}\n\nfunction handleEventsForInputEventPolyfill(domEventName, target, targetInst) {\n  if (domEventName === 'focusin') {\n    // In IE9, propertychange fires for most input events but is buggy and\n    // doesn't fire when text is deleted, but conveniently, selectionchange\n    // appears to fire in all of the remaining cases so we catch those and\n    // forward the event if the value has changed\n    // In either case, we don't want to call the event handler if the value\n    // is changed from JS so we redefine a setter for `.value` that updates\n    // our activeElementValue variable, allowing us to ignore those changes\n    //\n    // stopWatching() should be a noop here but we call it just in case we\n    // missed a blur event somehow.\n    stopWatchingForValueChange();\n    startWatchingForValueChange(target, targetInst);\n  } else if (domEventName === 'focusout') {\n    stopWatchingForValueChange();\n  }\n} // For IE8 and IE9.\n\n\nfunction getTargetInstForInputEventPolyfill(domEventName, targetInst) {\n  if (domEventName === 'selectionchange' || domEventName === 'keyup' || domEventName === 'keydown') {\n    // On the selectionchange event, the target is just document which isn't\n    // helpful for us so just check activeElement instead.\n    //\n    // 99% of the time, keydown and keyup aren't necessary. IE8 fails to fire\n    // propertychange on the first input event after setting `value` from a\n    // script and fires only keydown, keypress, keyup. Catching keyup usually\n    // gets it and catching keydown lets us fire an event for the first\n    // keystroke if user does a key repeat (it'll be a little delayed: right\n    // before the second keystroke). Other input methods (e.g., paste) seem to\n    // fire selectionchange normally.\n    return getInstIfValueChanged(activeElementInst);\n  }\n}\n/**\n * SECTION: handle `click` event\n */\n\n\nfunction shouldUseClickEvent(elem) {\n  // Use the `click` event to detect changes to checkbox and radio inputs.\n  // This approach works across all browsers, whereas `change` does not fire\n  // until `blur` in IE8.\n  var nodeName = elem.nodeName;\n  return nodeName && nodeName.toLowerCase() === 'input' && (elem.type === 'checkbox' || elem.type === 'radio');\n}\n\nfunction getTargetInstForClickEvent(domEventName, targetInst) {\n  if (domEventName === 'click') {\n    return getInstIfValueChanged(targetInst);\n  }\n}\n\nfunction getTargetInstForInputOrChangeEvent(domEventName, targetInst) {\n  if (domEventName === 'input' || domEventName === 'change') {\n    return getInstIfValueChanged(targetInst);\n  }\n}\n\nfunction handleControlledInputBlur(node) {\n  var state = node._wrapperState;\n\n  if (!state || !state.controlled || node.type !== 'number') {\n    return;\n  }\n\n  {\n    // If controlled, assign the value attribute to the current value on blur\n    setDefaultValue(node, 'number', node.value);\n  }\n}\n/**\n * This plugin creates an `onChange` event that normalizes change events\n * across form elements. This event fires at a time when it's possible to\n * change the element's value without seeing a flicker.\n *\n * Supported elements are:\n * - input (see `isTextInputElement`)\n * - textarea\n * - select\n */\n\n\nfunction extractEvents$1(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget, eventSystemFlags, targetContainer) {\n  var targetNode = targetInst ? getNodeFromInstance(targetInst) : window;\n  var getTargetInstFunc, handleEventFunc;\n\n  if (shouldUseChangeEvent(targetNode)) {\n    getTargetInstFunc = getTargetInstForChangeEvent;\n  } else if (isTextInputElement(targetNode)) {\n    if (isInputEventSupported) {\n      getTargetInstFunc = getTargetInstForInputOrChangeEvent;\n    } else {\n      getTargetInstFunc = getTargetInstForInputEventPolyfill;\n      handleEventFunc = handleEventsForInputEventPolyfill;\n    }\n  } else if (shouldUseClickEvent(targetNode)) {\n    getTargetInstFunc = getTargetInstForClickEvent;\n  }\n\n  if (getTargetInstFunc) {\n    var inst = getTargetInstFunc(domEventName, targetInst);\n\n    if (inst) {\n      createAndAccumulateChangeEvent(dispatchQueue, inst, nativeEvent, nativeEventTarget);\n      return;\n    }\n  }\n\n  if (handleEventFunc) {\n    handleEventFunc(domEventName, targetNode, targetInst);\n  } // When blurring, set the value attribute for number inputs\n\n\n  if (domEventName === 'focusout') {\n    handleControlledInputBlur(targetNode);\n  }\n}\n\nfunction registerEvents$2() {\n  registerDirectEvent('onMouseEnter', ['mouseout', 'mouseover']);\n  registerDirectEvent('onMouseLeave', ['mouseout', 'mouseover']);\n  registerDirectEvent('onPointerEnter', ['pointerout', 'pointerover']);\n  registerDirectEvent('onPointerLeave', ['pointerout', 'pointerover']);\n}\n/**\n * For almost every interaction we care about, there will be both a top-level\n * `mouseover` and `mouseout` event that occurs. Only use `mouseout` so that\n * we do not extract duplicate events. However, moving the mouse into the\n * browser from outside will not fire a `mouseout` event. In this case, we use\n * the `mouseover` top-level event.\n */\n\n\nfunction extractEvents$2(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget, eventSystemFlags, targetContainer) {\n  var isOverEvent = domEventName === 'mouseover' || domEventName === 'pointerover';\n  var isOutEvent = domEventName === 'mouseout' || domEventName === 'pointerout';\n\n  if (isOverEvent && !isReplayingEvent(nativeEvent)) {\n    // If this is an over event with a target, we might have already dispatched\n    // the event in the out event of the other target. If this is replayed,\n    // then it's because we couldn't dispatch against this target previously\n    // so we have to do it now instead.\n    var related = nativeEvent.relatedTarget || nativeEvent.fromElement;\n\n    if (related) {\n      // If the related node is managed by React, we can assume that we have\n      // already dispatched the corresponding events during its mouseout.\n      if (getClosestInstanceFromNode(related) || isContainerMarkedAsRoot(related)) {\n        return;\n      }\n    }\n  }\n\n  if (!isOutEvent && !isOverEvent) {\n    // Must not be a mouse or pointer in or out - ignoring.\n    return;\n  }\n\n  var win; // TODO: why is this nullable in the types but we read from it?\n\n  if (nativeEventTarget.window === nativeEventTarget) {\n    // `nativeEventTarget` is probably a window object.\n    win = nativeEventTarget;\n  } else {\n    // TODO: Figure out why `ownerDocument` is sometimes undefined in IE8.\n    var doc = nativeEventTarget.ownerDocument;\n\n    if (doc) {\n      win = doc.defaultView || doc.parentWindow;\n    } else {\n      win = window;\n    }\n  }\n\n  var from;\n  var to;\n\n  if (isOutEvent) {\n    var _related = nativeEvent.relatedTarget || nativeEvent.toElement;\n\n    from = targetInst;\n    to = _related ? getClosestInstanceFromNode(_related) : null;\n\n    if (to !== null) {\n      var nearestMounted = getNearestMountedFiber(to);\n\n      if (to !== nearestMounted || to.tag !== HostComponent && to.tag !== HostText) {\n        to = null;\n      }\n    }\n  } else {\n    // Moving to a node from outside the window.\n    from = null;\n    to = targetInst;\n  }\n\n  if (from === to) {\n    // Nothing pertains to our managed components.\n    return;\n  }\n\n  var SyntheticEventCtor = SyntheticMouseEvent;\n  var leaveEventType = 'onMouseLeave';\n  var enterEventType = 'onMouseEnter';\n  var eventTypePrefix = 'mouse';\n\n  if (domEventName === 'pointerout' || domEventName === 'pointerover') {\n    SyntheticEventCtor = SyntheticPointerEvent;\n    leaveEventType = 'onPointerLeave';\n    enterEventType = 'onPointerEnter';\n    eventTypePrefix = 'pointer';\n  }\n\n  var fromNode = from == null ? win : getNodeFromInstance(from);\n  var toNode = to == null ? win : getNodeFromInstance(to);\n  var leave = new SyntheticEventCtor(leaveEventType, eventTypePrefix + 'leave', from, nativeEvent, nativeEventTarget);\n  leave.target = fromNode;\n  leave.relatedTarget = toNode;\n  var enter = null; // We should only process this nativeEvent if we are processing\n  // the first ancestor. Next time, we will ignore the event.\n\n  var nativeTargetInst = getClosestInstanceFromNode(nativeEventTarget);\n\n  if (nativeTargetInst === targetInst) {\n    var enterEvent = new SyntheticEventCtor(enterEventType, eventTypePrefix + 'enter', to, nativeEvent, nativeEventTarget);\n    enterEvent.target = toNode;\n    enterEvent.relatedTarget = fromNode;\n    enter = enterEvent;\n  }\n\n  accumulateEnterLeaveTwoPhaseListeners(dispatchQueue, leave, enter, from, to);\n}\n\n/**\n * inlined Object.is polyfill to avoid requiring consumers ship their own\n * https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/is\n */\nfunction is(x, y) {\n  return x === y && (x !== 0 || 1 / x === 1 / y) || x !== x && y !== y // eslint-disable-line no-self-compare\n  ;\n}\n\nvar objectIs = typeof Object.is === 'function' ? Object.is : is;\n\n/**\n * Performs equality by iterating through keys on an object and returning false\n * when any key has values which are not strictly equal between the arguments.\n * Returns true when the values of all keys are strictly equal.\n */\n\nfunction shallowEqual(objA, objB) {\n  if (objectIs(objA, objB)) {\n    return true;\n  }\n\n  if (typeof objA !== 'object' || objA === null || typeof objB !== 'object' || objB === null) {\n    return false;\n  }\n\n  var keysA = Object.keys(objA);\n  var keysB = Object.keys(objB);\n\n  if (keysA.length !== keysB.length) {\n    return false;\n  } // Test for A's keys different from B.\n\n\n  for (var i = 0; i < keysA.length; i++) {\n    var currentKey = keysA[i];\n\n    if (!hasOwnProperty.call(objB, currentKey) || !objectIs(objA[currentKey], objB[currentKey])) {\n      return false;\n    }\n  }\n\n  return true;\n}\n\n/**\n * Given any node return the first leaf node without children.\n *\n * @param {DOMElement|DOMTextNode} node\n * @return {DOMElement|DOMTextNode}\n */\n\nfunction getLeafNode(node) {\n  while (node && node.firstChild) {\n    node = node.firstChild;\n  }\n\n  return node;\n}\n/**\n * Get the next sibling within a container. This will walk up the\n * DOM if a node's siblings have been exhausted.\n *\n * @param {DOMElement|DOMTextNode} node\n * @return {?DOMElement|DOMTextNode}\n */\n\n\nfunction getSiblingNode(node) {\n  while (node) {\n    if (node.nextSibling) {\n      return node.nextSibling;\n    }\n\n    node = node.parentNode;\n  }\n}\n/**\n * Get object describing the nodes which contain characters at offset.\n *\n * @param {DOMElement|DOMTextNode} root\n * @param {number} offset\n * @return {?object}\n */\n\n\nfunction getNodeForCharacterOffset(root, offset) {\n  var node = getLeafNode(root);\n  var nodeStart = 0;\n  var nodeEnd = 0;\n\n  while (node) {\n    if (node.nodeType === TEXT_NODE) {\n      nodeEnd = nodeStart + node.textContent.length;\n\n      if (nodeStart <= offset && nodeEnd >= offset) {\n        return {\n          node: node,\n          offset: offset - nodeStart\n        };\n      }\n\n      nodeStart = nodeEnd;\n    }\n\n    node = getLeafNode(getSiblingNode(node));\n  }\n}\n\n/**\n * @param {DOMElement} outerNode\n * @return {?object}\n */\n\nfunction getOffsets(outerNode) {\n  var ownerDocument = outerNode.ownerDocument;\n  var win = ownerDocument && ownerDocument.defaultView || window;\n  var selection = win.getSelection && win.getSelection();\n\n  if (!selection || selection.rangeCount === 0) {\n    return null;\n  }\n\n  var anchorNode = selection.anchorNode,\n      anchorOffset = selection.anchorOffset,\n      focusNode = selection.focusNode,\n      focusOffset = selection.focusOffset; // In Firefox, anchorNode and focusNode can be \"anonymous divs\", e.g. the\n  // up/down buttons on an <input type=\"number\">. Anonymous divs do not seem to\n  // expose properties, triggering a \"Permission denied error\" if any of its\n  // properties are accessed. The only seemingly possible way to avoid erroring\n  // is to access a property that typically works for non-anonymous divs and\n  // catch any error that may otherwise arise. See\n  // https://bugzilla.mozilla.org/show_bug.cgi?id=208427\n\n  try {\n    /* eslint-disable no-unused-expressions */\n    anchorNode.nodeType;\n    focusNode.nodeType;\n    /* eslint-enable no-unused-expressions */\n  } catch (e) {\n    return null;\n  }\n\n  return getModernOffsetsFromPoints(outerNode, anchorNode, anchorOffset, focusNode, focusOffset);\n}\n/**\n * Returns {start, end} where `start` is the character/codepoint index of\n * (anchorNode, anchorOffset) within the textContent of `outerNode`, and\n * `end` is the index of (focusNode, focusOffset).\n *\n * Returns null if you pass in garbage input but we should probably just crash.\n *\n * Exported only for testing.\n */\n\nfunction getModernOffsetsFromPoints(outerNode, anchorNode, anchorOffset, focusNode, focusOffset) {\n  var length = 0;\n  var start = -1;\n  var end = -1;\n  var indexWithinAnchor = 0;\n  var indexWithinFocus = 0;\n  var node = outerNode;\n  var parentNode = null;\n\n  outer: while (true) {\n    var next = null;\n\n    while (true) {\n      if (node === anchorNode && (anchorOffset === 0 || node.nodeType === TEXT_NODE)) {\n        start = length + anchorOffset;\n      }\n\n      if (node === focusNode && (focusOffset === 0 || node.nodeType === TEXT_NODE)) {\n        end = length + focusOffset;\n      }\n\n      if (node.nodeType === TEXT_NODE) {\n        length += node.nodeValue.length;\n      }\n\n      if ((next = node.firstChild) === null) {\n        break;\n      } // Moving from `node` to its first child `next`.\n\n\n      parentNode = node;\n      node = next;\n    }\n\n    while (true) {\n      if (node === outerNode) {\n        // If `outerNode` has children, this is always the second time visiting\n        // it. If it has no children, this is still the first loop, and the only\n        // valid selection is anchorNode and focusNode both equal to this node\n        // and both offsets 0, in which case we will have handled above.\n        break outer;\n      }\n\n      if (parentNode === anchorNode && ++indexWithinAnchor === anchorOffset) {\n        start = length;\n      }\n\n      if (parentNode === focusNode && ++indexWithinFocus === focusOffset) {\n        end = length;\n      }\n\n      if ((next = node.nextSibling) !== null) {\n        break;\n      }\n\n      node = parentNode;\n      parentNode = node.parentNode;\n    } // Moving from `node` to its next sibling `next`.\n\n\n    node = next;\n  }\n\n  if (start === -1 || end === -1) {\n    // This should never happen. (Would happen if the anchor/focus nodes aren't\n    // actually inside the passed-in node.)\n    return null;\n  }\n\n  return {\n    start: start,\n    end: end\n  };\n}\n/**\n * In modern non-IE browsers, we can support both forward and backward\n * selections.\n *\n * Note: IE10+ supports the Selection object, but it does not support\n * the `extend` method, which means that even in modern IE, it's not possible\n * to programmatically create a backward selection. Thus, for all IE\n * versions, we use the old IE API to create our selections.\n *\n * @param {DOMElement|DOMTextNode} node\n * @param {object} offsets\n */\n\nfunction setOffsets(node, offsets) {\n  var doc = node.ownerDocument || document;\n  var win = doc && doc.defaultView || window; // Edge fails with \"Object expected\" in some scenarios.\n  // (For instance: TinyMCE editor used in a list component that supports pasting to add more,\n  // fails when pasting 100+ items)\n\n  if (!win.getSelection) {\n    return;\n  }\n\n  var selection = win.getSelection();\n  var length = node.textContent.length;\n  var start = Math.min(offsets.start, length);\n  var end = offsets.end === undefined ? start : Math.min(offsets.end, length); // IE 11 uses modern selection, but doesn't support the extend method.\n  // Flip backward selections, so we can set with a single range.\n\n  if (!selection.extend && start > end) {\n    var temp = end;\n    end = start;\n    start = temp;\n  }\n\n  var startMarker = getNodeForCharacterOffset(node, start);\n  var endMarker = getNodeForCharacterOffset(node, end);\n\n  if (startMarker && endMarker) {\n    if (selection.rangeCount === 1 && selection.anchorNode === startMarker.node && selection.anchorOffset === startMarker.offset && selection.focusNode === endMarker.node && selection.focusOffset === endMarker.offset) {\n      return;\n    }\n\n    var range = doc.createRange();\n    range.setStart(startMarker.node, startMarker.offset);\n    selection.removeAllRanges();\n\n    if (start > end) {\n      selection.addRange(range);\n      selection.extend(endMarker.node, endMarker.offset);\n    } else {\n      range.setEnd(endMarker.node, endMarker.offset);\n      selection.addRange(range);\n    }\n  }\n}\n\nfunction isTextNode(node) {\n  return node && node.nodeType === TEXT_NODE;\n}\n\nfunction containsNode(outerNode, innerNode) {\n  if (!outerNode || !innerNode) {\n    return false;\n  } else if (outerNode === innerNode) {\n    return true;\n  } else if (isTextNode(outerNode)) {\n    return false;\n  } else if (isTextNode(innerNode)) {\n    return containsNode(outerNode, innerNode.parentNode);\n  } else if ('contains' in outerNode) {\n    return outerNode.contains(innerNode);\n  } else if (outerNode.compareDocumentPosition) {\n    return !!(outerNode.compareDocumentPosition(innerNode) & 16);\n  } else {\n    return false;\n  }\n}\n\nfunction isInDocument(node) {\n  return node && node.ownerDocument && containsNode(node.ownerDocument.documentElement, node);\n}\n\nfunction isSameOriginFrame(iframe) {\n  try {\n    // Accessing the contentDocument of a HTMLIframeElement can cause the browser\n    // to throw, e.g. if it has a cross-origin src attribute.\n    // Safari will show an error in the console when the access results in \"Blocked a frame with origin\". e.g:\n    // iframe.contentDocument.defaultView;\n    // A safety way is to access one of the cross origin properties: Window or Location\n    // Which might result in \"SecurityError\" DOM Exception and it is compatible to Safari.\n    // https://html.spec.whatwg.org/multipage/browsers.html#integration-with-idl\n    return typeof iframe.contentWindow.location.href === 'string';\n  } catch (err) {\n    return false;\n  }\n}\n\nfunction getActiveElementDeep() {\n  var win = window;\n  var element = getActiveElement();\n\n  while (element instanceof win.HTMLIFrameElement) {\n    if (isSameOriginFrame(element)) {\n      win = element.contentWindow;\n    } else {\n      return element;\n    }\n\n    element = getActiveElement(win.document);\n  }\n\n  return element;\n}\n/**\n * @ReactInputSelection: React input selection module. Based on Selection.js,\n * but modified to be suitable for react and has a couple of bug fixes (doesn't\n * assume buttons have range selections allowed).\n * Input selection module for React.\n */\n\n/**\n * @hasSelectionCapabilities: we get the element types that support selection\n * from https://html.spec.whatwg.org/#do-not-apply, looking at `selectionStart`\n * and `selectionEnd` rows.\n */\n\n\nfunction hasSelectionCapabilities(elem) {\n  var nodeName = elem && elem.nodeName && elem.nodeName.toLowerCase();\n  return nodeName && (nodeName === 'input' && (elem.type === 'text' || elem.type === 'search' || elem.type === 'tel' || elem.type === 'url' || elem.type === 'password') || nodeName === 'textarea' || elem.contentEditable === 'true');\n}\nfunction getSelectionInformation() {\n  var focusedElem = getActiveElementDeep();\n  return {\n    focusedElem: focusedElem,\n    selectionRange: hasSelectionCapabilities(focusedElem) ? getSelection(focusedElem) : null\n  };\n}\n/**\n * @restoreSelection: If any selection information was potentially lost,\n * restore it. This is useful when performing operations that could remove dom\n * nodes and place them back in, resulting in focus being lost.\n */\n\nfunction restoreSelection(priorSelectionInformation) {\n  var curFocusedElem = getActiveElementDeep();\n  var priorFocusedElem = priorSelectionInformation.focusedElem;\n  var priorSelectionRange = priorSelectionInformation.selectionRange;\n\n  if (curFocusedElem !== priorFocusedElem && isInDocument(priorFocusedElem)) {\n    if (priorSelectionRange !== null && hasSelectionCapabilities(priorFocusedElem)) {\n      setSelection(priorFocusedElem, priorSelectionRange);\n    } // Focusing a node can change the scroll position, which is undesirable\n\n\n    var ancestors = [];\n    var ancestor = priorFocusedElem;\n\n    while (ancestor = ancestor.parentNode) {\n      if (ancestor.nodeType === ELEMENT_NODE) {\n        ancestors.push({\n          element: ancestor,\n          left: ancestor.scrollLeft,\n          top: ancestor.scrollTop\n        });\n      }\n    }\n\n    if (typeof priorFocusedElem.focus === 'function') {\n      priorFocusedElem.focus();\n    }\n\n    for (var i = 0; i < ancestors.length; i++) {\n      var info = ancestors[i];\n      info.element.scrollLeft = info.left;\n      info.element.scrollTop = info.top;\n    }\n  }\n}\n/**\n * @getSelection: Gets the selection bounds of a focused textarea, input or\n * contentEditable node.\n * -@input: Look up selection bounds of this input\n * -@return {start: selectionStart, end: selectionEnd}\n */\n\nfunction getSelection(input) {\n  var selection;\n\n  if ('selectionStart' in input) {\n    // Modern browser with input or textarea.\n    selection = {\n      start: input.selectionStart,\n      end: input.selectionEnd\n    };\n  } else {\n    // Content editable or old IE textarea.\n    selection = getOffsets(input);\n  }\n\n  return selection || {\n    start: 0,\n    end: 0\n  };\n}\n/**\n * @setSelection: Sets the selection bounds of a textarea or input and focuses\n * the input.\n * -@input     Set selection bounds of this input or textarea\n * -@offsets   Object of same form that is returned from get*\n */\n\nfunction setSelection(input, offsets) {\n  var start = offsets.start;\n  var end = offsets.end;\n\n  if (end === undefined) {\n    end = start;\n  }\n\n  if ('selectionStart' in input) {\n    input.selectionStart = start;\n    input.selectionEnd = Math.min(end, input.value.length);\n  } else {\n    setOffsets(input, offsets);\n  }\n}\n\nvar skipSelectionChangeEvent = canUseDOM && 'documentMode' in document && document.documentMode <= 11;\n\nfunction registerEvents$3() {\n  registerTwoPhaseEvent('onSelect', ['focusout', 'contextmenu', 'dragend', 'focusin', 'keydown', 'keyup', 'mousedown', 'mouseup', 'selectionchange']);\n}\n\nvar activeElement$1 = null;\nvar activeElementInst$1 = null;\nvar lastSelection = null;\nvar mouseDown = false;\n/**\n * Get an object which is a unique representation of the current selection.\n *\n * The return value will not be consistent across nodes or browsers, but\n * two identical selections on the same node will return identical objects.\n */\n\nfunction getSelection$1(node) {\n  if ('selectionStart' in node && hasSelectionCapabilities(node)) {\n    return {\n      start: node.selectionStart,\n      end: node.selectionEnd\n    };\n  } else {\n    var win = node.ownerDocument && node.ownerDocument.defaultView || window;\n    var selection = win.getSelection();\n    return {\n      anchorNode: selection.anchorNode,\n      anchorOffset: selection.anchorOffset,\n      focusNode: selection.focusNode,\n      focusOffset: selection.focusOffset\n    };\n  }\n}\n/**\n * Get document associated with the event target.\n */\n\n\nfunction getEventTargetDocument(eventTarget) {\n  return eventTarget.window === eventTarget ? eventTarget.document : eventTarget.nodeType === DOCUMENT_NODE ? eventTarget : eventTarget.ownerDocument;\n}\n/**\n * Poll selection to see whether it's changed.\n *\n * @param {object} nativeEvent\n * @param {object} nativeEventTarget\n * @return {?SyntheticEvent}\n */\n\n\nfunction constructSelectEvent(dispatchQueue, nativeEvent, nativeEventTarget) {\n  // Ensure we have the right element, and that the user is not dragging a\n  // selection (this matches native `select` event behavior). In HTML5, select\n  // fires only on input and textarea thus if there's no focused element we\n  // won't dispatch.\n  var doc = getEventTargetDocument(nativeEventTarget);\n\n  if (mouseDown || activeElement$1 == null || activeElement$1 !== getActiveElement(doc)) {\n    return;\n  } // Only fire when selection has actually changed.\n\n\n  var currentSelection = getSelection$1(activeElement$1);\n\n  if (!lastSelection || !shallowEqual(lastSelection, currentSelection)) {\n    lastSelection = currentSelection;\n    var listeners = accumulateTwoPhaseListeners(activeElementInst$1, 'onSelect');\n\n    if (listeners.length > 0) {\n      var event = new SyntheticEvent('onSelect', 'select', null, nativeEvent, nativeEventTarget);\n      dispatchQueue.push({\n        event: event,\n        listeners: listeners\n      });\n      event.target = activeElement$1;\n    }\n  }\n}\n/**\n * This plugin creates an `onSelect` event that normalizes select events\n * across form elements.\n *\n * Supported elements are:\n * - input (see `isTextInputElement`)\n * - textarea\n * - contentEditable\n *\n * This differs from native browser implementations in the following ways:\n * - Fires on contentEditable fields as well as inputs.\n * - Fires for collapsed selection.\n * - Fires after user input.\n */\n\n\nfunction extractEvents$3(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget, eventSystemFlags, targetContainer) {\n  var targetNode = targetInst ? getNodeFromInstance(targetInst) : window;\n\n  switch (domEventName) {\n    // Track the input node that has focus.\n    case 'focusin':\n      if (isTextInputElement(targetNode) || targetNode.contentEditable === 'true') {\n        activeElement$1 = targetNode;\n        activeElementInst$1 = targetInst;\n        lastSelection = null;\n      }\n\n      break;\n\n    case 'focusout':\n      activeElement$1 = null;\n      activeElementInst$1 = null;\n      lastSelection = null;\n      break;\n    // Don't fire the event while the user is dragging. This matches the\n    // semantics of the native select event.\n\n    case 'mousedown':\n      mouseDown = true;\n      break;\n\n    case 'contextmenu':\n    case 'mouseup':\n    case 'dragend':\n      mouseDown = false;\n      constructSelectEvent(dispatchQueue, nativeEvent, nativeEventTarget);\n      break;\n    // Chrome and IE fire non-standard event when selection is changed (and\n    // sometimes when it hasn't). IE's event fires out of order with respect\n    // to key and input events on deletion, so we discard it.\n    //\n    // Firefox doesn't support selectionchange, so check selection status\n    // after each key entry. The selection changes after keydown and before\n    // keyup, but we check on keydown as well in the case of holding down a\n    // key, when multiple keydown events are fired but only one keyup is.\n    // This is also our approach for IE handling, for the reason above.\n\n    case 'selectionchange':\n      if (skipSelectionChangeEvent) {\n        break;\n      }\n\n    // falls through\n\n    case 'keydown':\n    case 'keyup':\n      constructSelectEvent(dispatchQueue, nativeEvent, nativeEventTarget);\n  }\n}\n\n/**\n * Generate a mapping of standard vendor prefixes using the defined style property and event name.\n *\n * @param {string} styleProp\n * @param {string} eventName\n * @returns {object}\n */\n\nfunction makePrefixMap(styleProp, eventName) {\n  var prefixes = {};\n  prefixes[styleProp.toLowerCase()] = eventName.toLowerCase();\n  prefixes['Webkit' + styleProp] = 'webkit' + eventName;\n  prefixes['Moz' + styleProp] = 'moz' + eventName;\n  return prefixes;\n}\n/**\n * A list of event names to a configurable list of vendor prefixes.\n */\n\n\nvar vendorPrefixes = {\n  animationend: makePrefixMap('Animation', 'AnimationEnd'),\n  animationiteration: makePrefixMap('Animation', 'AnimationIteration'),\n  animationstart: makePrefixMap('Animation', 'AnimationStart'),\n  transitionend: makePrefixMap('Transition', 'TransitionEnd')\n};\n/**\n * Event names that have already been detected and prefixed (if applicable).\n */\n\nvar prefixedEventNames = {};\n/**\n * Element to check for prefixes on.\n */\n\nvar style = {};\n/**\n * Bootstrap if a DOM exists.\n */\n\nif (canUseDOM) {\n  style = document.createElement('div').style; // On some platforms, in particular some releases of Android 4.x,\n  // the un-prefixed \"animation\" and \"transition\" properties are defined on the\n  // style object but the events that fire will still be prefixed, so we need\n  // to check if the un-prefixed events are usable, and if not remove them from the map.\n\n  if (!('AnimationEvent' in window)) {\n    delete vendorPrefixes.animationend.animation;\n    delete vendorPrefixes.animationiteration.animation;\n    delete vendorPrefixes.animationstart.animation;\n  } // Same as above\n\n\n  if (!('TransitionEvent' in window)) {\n    delete vendorPrefixes.transitionend.transition;\n  }\n}\n/**\n * Attempts to determine the correct vendor prefixed event name.\n *\n * @param {string} eventName\n * @returns {string}\n */\n\n\nfunction getVendorPrefixedEventName(eventName) {\n  if (prefixedEventNames[eventName]) {\n    return prefixedEventNames[eventName];\n  } else if (!vendorPrefixes[eventName]) {\n    return eventName;\n  }\n\n  var prefixMap = vendorPrefixes[eventName];\n\n  for (var styleProp in prefixMap) {\n    if (prefixMap.hasOwnProperty(styleProp) && styleProp in style) {\n      return prefixedEventNames[eventName] = prefixMap[styleProp];\n    }\n  }\n\n  return eventName;\n}\n\nvar ANIMATION_END = getVendorPrefixedEventName('animationend');\nvar ANIMATION_ITERATION = getVendorPrefixedEventName('animationiteration');\nvar ANIMATION_START = getVendorPrefixedEventName('animationstart');\nvar TRANSITION_END = getVendorPrefixedEventName('transitionend');\n\nvar topLevelEventsToReactNames = new Map(); // NOTE: Capitalization is important in this list!\n//\n// E.g. it needs \"pointerDown\", not \"pointerdown\".\n// This is because we derive both React name (\"onPointerDown\")\n// and DOM name (\"pointerdown\") from the same list.\n//\n// Exceptions that don't match this convention are listed separately.\n//\n// prettier-ignore\n\nvar simpleEventPluginEvents = ['abort', 'auxClick', 'cancel', 'canPlay', 'canPlayThrough', 'click', 'close', 'contextMenu', 'copy', 'cut', 'drag', 'dragEnd', 'dragEnter', 'dragExit', 'dragLeave', 'dragOver', 'dragStart', 'drop', 'durationChange', 'emptied', 'encrypted', 'ended', 'error', 'gotPointerCapture', 'input', 'invalid', 'keyDown', 'keyPress', 'keyUp', 'load', 'loadedData', 'loadedMetadata', 'loadStart', 'lostPointerCapture', 'mouseDown', 'mouseMove', 'mouseOut', 'mouseOver', 'mouseUp', 'paste', 'pause', 'play', 'playing', 'pointerCancel', 'pointerDown', 'pointerMove', 'pointerOut', 'pointerOver', 'pointerUp', 'progress', 'rateChange', 'reset', 'resize', 'seeked', 'seeking', 'stalled', 'submit', 'suspend', 'timeUpdate', 'touchCancel', 'touchEnd', 'touchStart', 'volumeChange', 'scroll', 'toggle', 'touchMove', 'waiting', 'wheel'];\n\nfunction registerSimpleEvent(domEventName, reactName) {\n  topLevelEventsToReactNames.set(domEventName, reactName);\n  registerTwoPhaseEvent(reactName, [domEventName]);\n}\n\nfunction registerSimpleEvents() {\n  for (var i = 0; i < simpleEventPluginEvents.length; i++) {\n    var eventName = simpleEventPluginEvents[i];\n    var domEventName = eventName.toLowerCase();\n    var capitalizedEvent = eventName[0].toUpperCase() + eventName.slice(1);\n    registerSimpleEvent(domEventName, 'on' + capitalizedEvent);\n  } // Special cases where event names don't match.\n\n\n  registerSimpleEvent(ANIMATION_END, 'onAnimationEnd');\n  registerSimpleEvent(ANIMATION_ITERATION, 'onAnimationIteration');\n  registerSimpleEvent(ANIMATION_START, 'onAnimationStart');\n  registerSimpleEvent('dblclick', 'onDoubleClick');\n  registerSimpleEvent('focusin', 'onFocus');\n  registerSimpleEvent('focusout', 'onBlur');\n  registerSimpleEvent(TRANSITION_END, 'onTransitionEnd');\n}\n\nfunction extractEvents$4(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget, eventSystemFlags, targetContainer) {\n  var reactName = topLevelEventsToReactNames.get(domEventName);\n\n  if (reactName === undefined) {\n    return;\n  }\n\n  var SyntheticEventCtor = SyntheticEvent;\n  var reactEventType = domEventName;\n\n  switch (domEventName) {\n    case 'keypress':\n      // Firefox creates a keypress event for function keys too. This removes\n      // the unwanted keypress events. Enter is however both printable and\n      // non-printable. One would expect Tab to be as well (but it isn't).\n      if (getEventCharCode(nativeEvent) === 0) {\n        return;\n      }\n\n    /* falls through */\n\n    case 'keydown':\n    case 'keyup':\n      SyntheticEventCtor = SyntheticKeyboardEvent;\n      break;\n\n    case 'focusin':\n      reactEventType = 'focus';\n      SyntheticEventCtor = SyntheticFocusEvent;\n      break;\n\n    case 'focusout':\n      reactEventType = 'blur';\n      SyntheticEventCtor = SyntheticFocusEvent;\n      break;\n\n    case 'beforeblur':\n    case 'afterblur':\n      SyntheticEventCtor = SyntheticFocusEvent;\n      break;\n\n    case 'click':\n      // Firefox creates a click event on right mouse clicks. This removes the\n      // unwanted click events.\n      if (nativeEvent.button === 2) {\n        return;\n      }\n\n    /* falls through */\n\n    case 'auxclick':\n    case 'dblclick':\n    case 'mousedown':\n    case 'mousemove':\n    case 'mouseup': // TODO: Disabled elements should not respond to mouse events\n\n    /* falls through */\n\n    case 'mouseout':\n    case 'mouseover':\n    case 'contextmenu':\n      SyntheticEventCtor = SyntheticMouseEvent;\n      break;\n\n    case 'drag':\n    case 'dragend':\n    case 'dragenter':\n    case 'dragexit':\n    case 'dragleave':\n    case 'dragover':\n    case 'dragstart':\n    case 'drop':\n      SyntheticEventCtor = SyntheticDragEvent;\n      break;\n\n    case 'touchcancel':\n    case 'touchend':\n    case 'touchmove':\n    case 'touchstart':\n      SyntheticEventCtor = SyntheticTouchEvent;\n      break;\n\n    case ANIMATION_END:\n    case ANIMATION_ITERATION:\n    case ANIMATION_START:\n      SyntheticEventCtor = SyntheticAnimationEvent;\n      break;\n\n    case TRANSITION_END:\n      SyntheticEventCtor = SyntheticTransitionEvent;\n      break;\n\n    case 'scroll':\n      SyntheticEventCtor = SyntheticUIEvent;\n      break;\n\n    case 'wheel':\n      SyntheticEventCtor = SyntheticWheelEvent;\n      break;\n\n    case 'copy':\n    case 'cut':\n    case 'paste':\n      SyntheticEventCtor = SyntheticClipboardEvent;\n      break;\n\n    case 'gotpointercapture':\n    case 'lostpointercapture':\n    case 'pointercancel':\n    case 'pointerdown':\n    case 'pointermove':\n    case 'pointerout':\n    case 'pointerover':\n    case 'pointerup':\n      SyntheticEventCtor = SyntheticPointerEvent;\n      break;\n  }\n\n  var inCapturePhase = (eventSystemFlags & IS_CAPTURE_PHASE) !== 0;\n\n  {\n    // Some events don't bubble in the browser.\n    // In the past, React has always bubbled them, but this can be surprising.\n    // We're going to try aligning closer to the browser behavior by not bubbling\n    // them in React either. We'll start by not bubbling onScroll, and then expand.\n    var accumulateTargetOnly = !inCapturePhase && // TODO: ideally, we'd eventually add all events from\n    // nonDelegatedEvents list in DOMPluginEventSystem.\n    // Then we can remove this special list.\n    // This is a breaking change that can wait until React 18.\n    domEventName === 'scroll';\n\n    var _listeners = accumulateSinglePhaseListeners(targetInst, reactName, nativeEvent.type, inCapturePhase, accumulateTargetOnly);\n\n    if (_listeners.length > 0) {\n      // Intentionally create event lazily.\n      var _event = new SyntheticEventCtor(reactName, reactEventType, null, nativeEvent, nativeEventTarget);\n\n      dispatchQueue.push({\n        event: _event,\n        listeners: _listeners\n      });\n    }\n  }\n}\n\n// TODO: remove top-level side effect.\nregisterSimpleEvents();\nregisterEvents$2();\nregisterEvents$1();\nregisterEvents$3();\nregisterEvents();\n\nfunction extractEvents$5(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget, eventSystemFlags, targetContainer) {\n  // TODO: we should remove the concept of a \"SimpleEventPlugin\".\n  // This is the basic functionality of the event system. All\n  // the other plugins are essentially polyfills. So the plugin\n  // should probably be inlined somewhere and have its logic\n  // be core the to event system. This would potentially allow\n  // us to ship builds of React without the polyfilled plugins below.\n  extractEvents$4(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget, eventSystemFlags);\n  var shouldProcessPolyfillPlugins = (eventSystemFlags & SHOULD_NOT_PROCESS_POLYFILL_EVENT_PLUGINS) === 0; // We don't process these events unless we are in the\n  // event's native \"bubble\" phase, which means that we're\n  // not in the capture phase. That's because we emulate\n  // the capture phase here still. This is a trade-off,\n  // because in an ideal world we would not emulate and use\n  // the phases properly, like we do with the SimpleEvent\n  // plugin. However, the plugins below either expect\n  // emulation (EnterLeave) or use state localized to that\n  // plugin (BeforeInput, Change, Select). The state in\n  // these modules complicates things, as you'll essentially\n  // get the case where the capture phase event might change\n  // state, only for the following bubble event to come in\n  // later and not trigger anything as the state now\n  // invalidates the heuristics of the event plugin. We\n  // could alter all these plugins to work in such ways, but\n  // that might cause other unknown side-effects that we\n  // can't foresee right now.\n\n  if (shouldProcessPolyfillPlugins) {\n    extractEvents$2(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget);\n    extractEvents$1(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget);\n    extractEvents$3(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget);\n    extractEvents(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget);\n  }\n} // List of events that need to be individually attached to media elements.\n\n\nvar mediaEventTypes = ['abort', 'canplay', 'canplaythrough', 'durationchange', 'emptied', 'encrypted', 'ended', 'error', 'loadeddata', 'loadedmetadata', 'loadstart', 'pause', 'play', 'playing', 'progress', 'ratechange', 'resize', 'seeked', 'seeking', 'stalled', 'suspend', 'timeupdate', 'volumechange', 'waiting']; // We should not delegate these events to the container, but rather\n// set them on the actual target element itself. This is primarily\n// because these events do not consistently bubble in the DOM.\n\nvar nonDelegatedEvents = new Set(['cancel', 'close', 'invalid', 'load', 'scroll', 'toggle'].concat(mediaEventTypes));\n\nfunction executeDispatch(event, listener, currentTarget) {\n  var type = event.type || 'unknown-event';\n  event.currentTarget = currentTarget;\n  invokeGuardedCallbackAndCatchFirstError(type, listener, undefined, event);\n  event.currentTarget = null;\n}\n\nfunction processDispatchQueueItemsInOrder(event, dispatchListeners, inCapturePhase) {\n  var previousInstance;\n\n  if (inCapturePhase) {\n    for (var i = dispatchListeners.length - 1; i >= 0; i--) {\n      var _dispatchListeners$i = dispatchListeners[i],\n          instance = _dispatchListeners$i.instance,\n          currentTarget = _dispatchListeners$i.currentTarget,\n          listener = _dispatchListeners$i.listener;\n\n      if (instance !== previousInstance && event.isPropagationStopped()) {\n        return;\n      }\n\n      executeDispatch(event, listener, currentTarget);\n      previousInstance = instance;\n    }\n  } else {\n    for (var _i = 0; _i < dispatchListeners.length; _i++) {\n      var _dispatchListeners$_i = dispatchListeners[_i],\n          _instance = _dispatchListeners$_i.instance,\n          _currentTarget = _dispatchListeners$_i.currentTarget,\n          _listener = _dispatchListeners$_i.listener;\n\n      if (_instance !== previousInstance && event.isPropagationStopped()) {\n        return;\n      }\n\n      executeDispatch(event, _listener, _currentTarget);\n      previousInstance = _instance;\n    }\n  }\n}\n\nfunction processDispatchQueue(dispatchQueue, eventSystemFlags) {\n  var inCapturePhase = (eventSystemFlags & IS_CAPTURE_PHASE) !== 0;\n\n  for (var i = 0; i < dispatchQueue.length; i++) {\n    var _dispatchQueue$i = dispatchQueue[i],\n        event = _dispatchQueue$i.event,\n        listeners = _dispatchQueue$i.listeners;\n    processDispatchQueueItemsInOrder(event, listeners, inCapturePhase); //  event system doesn't use pooling.\n  } // This would be a good time to rethrow if any of the event handlers threw.\n\n\n  rethrowCaughtError();\n}\n\nfunction dispatchEventsForPlugins(domEventName, eventSystemFlags, nativeEvent, targetInst, targetContainer) {\n  var nativeEventTarget = getEventTarget(nativeEvent);\n  var dispatchQueue = [];\n  extractEvents$5(dispatchQueue, domEventName, targetInst, nativeEvent, nativeEventTarget, eventSystemFlags);\n  processDispatchQueue(dispatchQueue, eventSystemFlags);\n}\n\nfunction listenToNonDelegatedEvent(domEventName, targetElement) {\n  {\n    if (!nonDelegatedEvents.has(domEventName)) {\n      error('Did not expect a listenToNonDelegatedEvent() call for \"%s\". ' + 'This is a bug in React. Please file an issue.', domEventName);\n    }\n  }\n\n  var isCapturePhaseListener = false;\n  var listenerSet = getEventListenerSet(targetElement);\n  var listenerSetKey = getListenerSetKey(domEventName, isCapturePhaseListener);\n\n  if (!listenerSet.has(listenerSetKey)) {\n    addTrappedEventListener(targetElement, domEventName, IS_NON_DELEGATED, isCapturePhaseListener);\n    listenerSet.add(listenerSetKey);\n  }\n}\nfunction listenToNativeEvent(domEventName, isCapturePhaseListener, target) {\n  {\n    if (nonDelegatedEvents.has(domEventName) && !isCapturePhaseListener) {\n      error('Did not expect a listenToNativeEvent() call for \"%s\" in the bubble phase. ' + 'This is a bug in React. Please file an issue.', domEventName);\n    }\n  }\n\n  var eventSystemFlags = 0;\n\n  if (isCapturePhaseListener) {\n    eventSystemFlags |= IS_CAPTURE_PHASE;\n  }\n\n  addTrappedEventListener(target, domEventName, eventSystemFlags, isCapturePhaseListener);\n} // This is only used by createEventHandle when the\nvar listeningMarker = '_reactListening' + Math.random().toString(36).slice(2);\nfunction listenToAllSupportedEvents(rootContainerElement) {\n  if (!rootContainerElement[listeningMarker]) {\n    rootContainerElement[listeningMarker] = true;\n    allNativeEvents.forEach(function (domEventName) {\n      // We handle selectionchange separately because it\n      // doesn't bubble and needs to be on the document.\n      if (domEventName !== 'selectionchange') {\n        if (!nonDelegatedEvents.has(domEventName)) {\n          listenToNativeEvent(domEventName, false, rootContainerElement);\n        }\n\n        listenToNativeEvent(domEventName, true, rootContainerElement);\n      }\n    });\n    var ownerDocument = rootContainerElement.nodeType === DOCUMENT_NODE ? rootContainerElement : rootContainerElement.ownerDocument;\n\n    if (ownerDocument !== null) {\n      // The selectionchange event also needs deduplication\n      // but it is attached to the document.\n      if (!ownerDocument[listeningMarker]) {\n        ownerDocument[listeningMarker] = true;\n        listenToNativeEvent('selectionchange', false, ownerDocument);\n      }\n    }\n  }\n}\n\nfunction addTrappedEventListener(targetContainer, domEventName, eventSystemFlags, isCapturePhaseListener, isDeferredListenerForLegacyFBSupport) {\n  var listener = createEventListenerWrapperWithPriority(targetContainer, domEventName, eventSystemFlags); // If passive option is not supported, then the event will be\n  // active and not passive.\n\n  var isPassiveListener = undefined;\n\n  if (passiveBrowserEventsSupported) {\n    // Browsers introduced an intervention, making these events\n    // passive by default on document. React doesn't bind them\n    // to document anymore, but changing this now would undo\n    // the performance wins from the change. So we emulate\n    // the existing behavior manually on the roots now.\n    // https://github.com/facebook/react/issues/19651\n    if (domEventName === 'touchstart' || domEventName === 'touchmove' || domEventName === 'wheel') {\n      isPassiveListener = true;\n    }\n  }\n\n  targetContainer =  targetContainer;\n  var unsubscribeListener; // When legacyFBSupport is enabled, it's for when we\n\n\n  if (isCapturePhaseListener) {\n    if (isPassiveListener !== undefined) {\n      unsubscribeListener = addEventCaptureListenerWithPassiveFlag(targetContainer, domEventName, listener, isPassiveListener);\n    } else {\n      unsubscribeListener = addEventCaptureListener(targetContainer, domEventName, listener);\n    }\n  } else {\n    if (isPassiveListener !== undefined) {\n      unsubscribeListener = addEventBubbleListenerWithPassiveFlag(targetContainer, domEventName, listener, isPassiveListener);\n    } else {\n      unsubscribeListener = addEventBubbleListener(targetContainer, domEventName, listener);\n    }\n  }\n}\n\nfunction isMatchingRootContainer(grandContainer, targetContainer) {\n  return grandContainer === targetContainer || grandContainer.nodeType === COMMENT_NODE && grandContainer.parentNode === targetContainer;\n}\n\nfunction dispatchEventForPluginEventSystem(domEventName, eventSystemFlags, nativeEvent, targetInst, targetContainer) {\n  var ancestorInst = targetInst;\n\n  if ((eventSystemFlags & IS_EVENT_HANDLE_NON_MANAGED_NODE) === 0 && (eventSystemFlags & IS_NON_DELEGATED) === 0) {\n    var targetContainerNode = targetContainer; // If we are using the legacy FB support flag, we\n\n    if (targetInst !== null) {\n      // The below logic attempts to work out if we need to change\n      // the target fiber to a different ancestor. We had similar logic\n      // in the legacy event system, except the big difference between\n      // systems is that the modern event system now has an event listener\n      // attached to each React Root and React Portal Root. Together,\n      // the DOM nodes representing these roots are the \"rootContainer\".\n      // To figure out which ancestor instance we should use, we traverse\n      // up the fiber tree from the target instance and attempt to find\n      // root boundaries that match that of our current \"rootContainer\".\n      // If we find that \"rootContainer\", we find the parent fiber\n      // sub-tree for that root and make that our ancestor instance.\n      var node = targetInst;\n\n      mainLoop: while (true) {\n        if (node === null) {\n          return;\n        }\n\n        var nodeTag = node.tag;\n\n        if (nodeTag === HostRoot || nodeTag === HostPortal) {\n          var container = node.stateNode.containerInfo;\n\n          if (isMatchingRootContainer(container, targetContainerNode)) {\n            break;\n          }\n\n          if (nodeTag === HostPortal) {\n            // The target is a portal, but it's not the rootContainer we're looking for.\n            // Normally portals handle their own events all the way down to the root.\n            // So we should be able to stop now. However, we don't know if this portal\n            // was part of *our* root.\n            var grandNode = node.return;\n\n            while (grandNode !== null) {\n              var grandTag = grandNode.tag;\n\n              if (grandTag === HostRoot || grandTag === HostPortal) {\n                var grandContainer = grandNode.stateNode.containerInfo;\n\n                if (isMatchingRootContainer(grandContainer, targetContainerNode)) {\n                  // This is the rootContainer we're looking for and we found it as\n                  // a parent of the Portal. That means we can ignore it because the\n                  // Portal will bubble through to us.\n                  return;\n                }\n              }\n\n              grandNode = grandNode.return;\n            }\n          } // Now we need to find it's corresponding host fiber in the other\n          // tree. To do this we can use getClosestInstanceFromNode, but we\n          // need to validate that the fiber is a host instance, otherwise\n          // we need to traverse up through the DOM till we find the correct\n          // node that is from the other tree.\n\n\n          while (container !== null) {\n            var parentNode = getClosestInstanceFromNode(container);\n\n            if (parentNode === null) {\n              return;\n            }\n\n            var parentTag = parentNode.tag;\n\n            if (parentTag === HostComponent || parentTag === HostText) {\n              node = ancestorInst = parentNode;\n              continue mainLoop;\n            }\n\n            container = container.parentNode;\n          }\n        }\n\n        node = node.return;\n      }\n    }\n  }\n\n  batchedUpdates(function () {\n    return dispatchEventsForPlugins(domEventName, eventSystemFlags, nativeEvent, ancestorInst);\n  });\n}\n\nfunction createDispatchListener(instance, listener, currentTarget) {\n  return {\n    instance: instance,\n    listener: listener,\n    currentTarget: currentTarget\n  };\n}\n\nfunction accumulateSinglePhaseListeners(targetFiber, reactName, nativeEventType, inCapturePhase, accumulateTargetOnly, nativeEvent) {\n  var captureName = reactName !== null ? reactName + 'Capture' : null;\n  var reactEventName = inCapturePhase ? captureName : reactName;\n  var listeners = [];\n  var instance = targetFiber;\n  var lastHostComponent = null; // Accumulate all instances and listeners via the target -> root path.\n\n  while (instance !== null) {\n    var _instance2 = instance,\n        stateNode = _instance2.stateNode,\n        tag = _instance2.tag; // Handle listeners that are on HostComponents (i.e. <div>)\n\n    if (tag === HostComponent && stateNode !== null) {\n      lastHostComponent = stateNode; // createEventHandle listeners\n\n\n      if (reactEventName !== null) {\n        var listener = getListener(instance, reactEventName);\n\n        if (listener != null) {\n          listeners.push(createDispatchListener(instance, listener, lastHostComponent));\n        }\n      }\n    } // If we are only accumulating events for the target, then we don't\n    // continue to propagate through the React fiber tree to find other\n    // listeners.\n\n\n    if (accumulateTargetOnly) {\n      break;\n    } // If we are processing the onBeforeBlur event, then we need to take\n\n    instance = instance.return;\n  }\n\n  return listeners;\n} // We should only use this function for:\n// - BeforeInputEventPlugin\n// - ChangeEventPlugin\n// - SelectEventPlugin\n// This is because we only process these plugins\n// in the bubble phase, so we need to accumulate two\n// phase event listeners (via emulation).\n\nfunction accumulateTwoPhaseListeners(targetFiber, reactName) {\n  var captureName = reactName + 'Capture';\n  var listeners = [];\n  var instance = targetFiber; // Accumulate all instances and listeners via the target -> root path.\n\n  while (instance !== null) {\n    var _instance3 = instance,\n        stateNode = _instance3.stateNode,\n        tag = _instance3.tag; // Handle listeners that are on HostComponents (i.e. <div>)\n\n    if (tag === HostComponent && stateNode !== null) {\n      var currentTarget = stateNode;\n      var captureListener = getListener(instance, captureName);\n\n      if (captureListener != null) {\n        listeners.unshift(createDispatchListener(instance, captureListener, currentTarget));\n      }\n\n      var bubbleListener = getListener(instance, reactName);\n\n      if (bubbleListener != null) {\n        listeners.push(createDispatchListener(instance, bubbleListener, currentTarget));\n      }\n    }\n\n    instance = instance.return;\n  }\n\n  return listeners;\n}\n\nfunction getParent(inst) {\n  if (inst === null) {\n    return null;\n  }\n\n  do {\n    inst = inst.return; // TODO: If this is a HostRoot we might want to bail out.\n    // That is depending on if we want nested subtrees (layers) to bubble\n    // events to their parent. We could also go through parentNode on the\n    // host node but that wouldn't work for React Native and doesn't let us\n    // do the portal feature.\n  } while (inst && inst.tag !== HostComponent);\n\n  if (inst) {\n    return inst;\n  }\n\n  return null;\n}\n/**\n * Return the lowest common ancestor of A and B, or null if they are in\n * different trees.\n */\n\n\nfunction getLowestCommonAncestor(instA, instB) {\n  var nodeA = instA;\n  var nodeB = instB;\n  var depthA = 0;\n\n  for (var tempA = nodeA; tempA; tempA = getParent(tempA)) {\n    depthA++;\n  }\n\n  var depthB = 0;\n\n  for (var tempB = nodeB; tempB; tempB = getParent(tempB)) {\n    depthB++;\n  } // If A is deeper, crawl up.\n\n\n  while (depthA - depthB > 0) {\n    nodeA = getParent(nodeA);\n    depthA--;\n  } // If B is deeper, crawl up.\n\n\n  while (depthB - depthA > 0) {\n    nodeB = getParent(nodeB);\n    depthB--;\n  } // Walk in lockstep until we find a match.\n\n\n  var depth = depthA;\n\n  while (depth--) {\n    if (nodeA === nodeB || nodeB !== null && nodeA === nodeB.alternate) {\n      return nodeA;\n    }\n\n    nodeA = getParent(nodeA);\n    nodeB = getParent(nodeB);\n  }\n\n  return null;\n}\n\nfunction accumulateEnterLeaveListenersForEvent(dispatchQueue, event, target, common, inCapturePhase) {\n  var registrationName = event._reactName;\n  var listeners = [];\n  var instance = target;\n\n  while (instance !== null) {\n    if (instance === common) {\n      break;\n    }\n\n    var _instance4 = instance,\n        alternate = _instance4.alternate,\n        stateNode = _instance4.stateNode,\n        tag = _instance4.tag;\n\n    if (alternate !== null && alternate === common) {\n      break;\n    }\n\n    if (tag === HostComponent && stateNode !== null) {\n      var currentTarget = stateNode;\n\n      if (inCapturePhase) {\n        var captureListener = getListener(instance, registrationName);\n\n        if (captureListener != null) {\n          listeners.unshift(createDispatchListener(instance, captureListener, currentTarget));\n        }\n      } else if (!inCapturePhase) {\n        var bubbleListener = getListener(instance, registrationName);\n\n        if (bubbleListener != null) {\n          listeners.push(createDispatchListener(instance, bubbleListener, currentTarget));\n        }\n      }\n    }\n\n    instance = instance.return;\n  }\n\n  if (listeners.length !== 0) {\n    dispatchQueue.push({\n      event: event,\n      listeners: listeners\n    });\n  }\n} // We should only use this function for:\n// - EnterLeaveEventPlugin\n// This is because we only process this plugin\n// in the bubble phase, so we need to accumulate two\n// phase event listeners.\n\n\nfunction accumulateEnterLeaveTwoPhaseListeners(dispatchQueue, leaveEvent, enterEvent, from, to) {\n  var common = from && to ? getLowestCommonAncestor(from, to) : null;\n\n  if (from !== null) {\n    accumulateEnterLeaveListenersForEvent(dispatchQueue, leaveEvent, from, common, false);\n  }\n\n  if (to !== null && enterEvent !== null) {\n    accumulateEnterLeaveListenersForEvent(dispatchQueue, enterEvent, to, common, true);\n  }\n}\nfunction getListenerSetKey(domEventName, capture) {\n  return domEventName + \"__\" + (capture ? 'capture' : 'bubble');\n}\n\nvar didWarnInvalidHydration = false;\nvar DANGEROUSLY_SET_INNER_HTML = 'dangerouslySetInnerHTML';\nvar SUPPRESS_CONTENT_EDITABLE_WARNING = 'suppressContentEditableWarning';\nvar SUPPRESS_HYDRATION_WARNING = 'suppressHydrationWarning';\nvar AUTOFOCUS = 'autoFocus';\nvar CHILDREN = 'children';\nvar STYLE = 'style';\nvar HTML$1 = '__html';\nvar warnedUnknownTags;\nvar validatePropertiesInDevelopment;\nvar warnForPropDifference;\nvar warnForExtraAttributes;\nvar warnForInvalidEventListener;\nvar canDiffStyleForHydrationWarning;\nvar normalizeHTML;\n\n{\n  warnedUnknownTags = {\n    // There are working polyfills for <dialog>. Let people use it.\n    dialog: true,\n    // Electron ships a custom <webview> tag to display external web content in\n    // an isolated frame and process.\n    // This tag is not present in non Electron environments such as JSDom which\n    // is often used for testing purposes.\n    // @see https://electronjs.org/docs/api/webview-tag\n    webview: true\n  };\n\n  validatePropertiesInDevelopment = function (type, props) {\n    validateProperties(type, props);\n    validateProperties$1(type, props);\n    validateProperties$2(type, props, {\n      registrationNameDependencies: registrationNameDependencies,\n      possibleRegistrationNames: possibleRegistrationNames\n    });\n  }; // IE 11 parses & normalizes the style attribute as opposed to other\n  // browsers. It adds spaces and sorts the properties in some\n  // non-alphabetical order. Handling that would require sorting CSS\n  // properties in the client & server versions or applying\n  // `expectedStyle` to a temporary DOM node to read its `style` attribute\n  // normalized. Since it only affects IE, we're skipping style warnings\n  // in that browser completely in favor of doing all that work.\n  // See https://github.com/facebook/react/issues/11807\n\n\n  canDiffStyleForHydrationWarning = canUseDOM && !document.documentMode;\n\n  warnForPropDifference = function (propName, serverValue, clientValue) {\n    if (didWarnInvalidHydration) {\n      return;\n    }\n\n    var normalizedClientValue = normalizeMarkupForTextOrAttribute(clientValue);\n    var normalizedServerValue = normalizeMarkupForTextOrAttribute(serverValue);\n\n    if (normalizedServerValue === normalizedClientValue) {\n      return;\n    }\n\n    didWarnInvalidHydration = true;\n\n    error('Prop `%s` did not match. Server: %s Client: %s', propName, JSON.stringify(normalizedServerValue), JSON.stringify(normalizedClientValue));\n  };\n\n  warnForExtraAttributes = function (attributeNames) {\n    if (didWarnInvalidHydration) {\n      return;\n    }\n\n    didWarnInvalidHydration = true;\n    var names = [];\n    attributeNames.forEach(function (name) {\n      names.push(name);\n    });\n\n    error('Extra attributes from the server: %s', names);\n  };\n\n  warnForInvalidEventListener = function (registrationName, listener) {\n    if (listener === false) {\n      error('Expected `%s` listener to be a function, instead got `false`.\\n\\n' + 'If you used to conditionally omit it with %s={condition && value}, ' + 'pass %s={condition ? value : undefined} instead.', registrationName, registrationName, registrationName);\n    } else {\n      error('Expected `%s` listener to be a function, instead got a value of `%s` type.', registrationName, typeof listener);\n    }\n  }; // Parse the HTML and read it back to normalize the HTML string so that it\n  // can be used for comparison.\n\n\n  normalizeHTML = function (parent, html) {\n    // We could have created a separate document here to avoid\n    // re-initializing custom elements if they exist. But this breaks\n    // how <noscript> is being handled. So we use the same document.\n    // See the discussion in https://github.com/facebook/react/pull/11157.\n    var testElement = parent.namespaceURI === HTML_NAMESPACE ? parent.ownerDocument.createElement(parent.tagName) : parent.ownerDocument.createElementNS(parent.namespaceURI, parent.tagName);\n    testElement.innerHTML = html;\n    return testElement.innerHTML;\n  };\n} // HTML parsing normalizes CR and CRLF to LF.\n// It also can turn \\u0000 into \\uFFFD inside attributes.\n// https://www.w3.org/TR/html5/single-page.html#preprocessing-the-input-stream\n// If we have a mismatch, it might be caused by that.\n// We will still patch up in this case but not fire the warning.\n\n\nvar NORMALIZE_NEWLINES_REGEX = /\\r\\n?/g;\nvar NORMALIZE_NULL_AND_REPLACEMENT_REGEX = /\\u0000|\\uFFFD/g;\n\nfunction normalizeMarkupForTextOrAttribute(markup) {\n  {\n    checkHtmlStringCoercion(markup);\n  }\n\n  var markupString = typeof markup === 'string' ? markup : '' + markup;\n  return markupString.replace(NORMALIZE_NEWLINES_REGEX, '\\n').replace(NORMALIZE_NULL_AND_REPLACEMENT_REGEX, '');\n}\n\nfunction checkForUnmatchedText(serverText, clientText, isConcurrentMode, shouldWarnDev) {\n  var normalizedClientText = normalizeMarkupForTextOrAttribute(clientText);\n  var normalizedServerText = normalizeMarkupForTextOrAttribute(serverText);\n\n  if (normalizedServerText === normalizedClientText) {\n    return;\n  }\n\n  if (shouldWarnDev) {\n    {\n      if (!didWarnInvalidHydration) {\n        didWarnInvalidHydration = true;\n\n        error('Text content did not match. Server: \"%s\" Client: \"%s\"', normalizedServerText, normalizedClientText);\n      }\n    }\n  }\n\n  if (isConcurrentMode && enableClientRenderFallbackOnTextMismatch) {\n    // In concurrent roots, we throw when there's a text mismatch and revert to\n    // client rendering, up to the nearest Suspense boundary.\n    throw new Error('Text content does not match server-rendered HTML.');\n  }\n}\n\nfunction getOwnerDocumentFromRootContainer(rootContainerElement) {\n  return rootContainerElement.nodeType === DOCUMENT_NODE ? rootContainerElement : rootContainerElement.ownerDocument;\n}\n\nfunction noop() {}\n\nfunction trapClickOnNonInteractiveElement(node) {\n  // Mobile Safari does not fire properly bubble click events on\n  // non-interactive elements, which means delegated click listeners do not\n  // fire. The workaround for this bug involves attaching an empty click\n  // listener on the target node.\n  // https://www.quirksmode.org/blog/archives/2010/09/click_event_del.html\n  // Just set it using the onclick property so that we don't have to manage any\n  // bookkeeping for it. Not sure if we need to clear it when the listener is\n  // removed.\n  // TODO: Only do this for the relevant Safaris maybe?\n  node.onclick = noop;\n}\n\nfunction setInitialDOMProperties(tag, domElement, rootContainerElement, nextProps, isCustomComponentTag) {\n  for (var propKey in nextProps) {\n    if (!nextProps.hasOwnProperty(propKey)) {\n      continue;\n    }\n\n    var nextProp = nextProps[propKey];\n\n    if (propKey === STYLE) {\n      {\n        if (nextProp) {\n          // Freeze the next style object so that we can assume it won't be\n          // mutated. We have already warned for this in the past.\n          Object.freeze(nextProp);\n        }\n      } // Relies on `updateStylesByID` not mutating `styleUpdates`.\n\n\n      setValueForStyles(domElement, nextProp);\n    } else if (propKey === DANGEROUSLY_SET_INNER_HTML) {\n      var nextHtml = nextProp ? nextProp[HTML$1] : undefined;\n\n      if (nextHtml != null) {\n        setInnerHTML(domElement, nextHtml);\n      }\n    } else if (propKey === CHILDREN) {\n      if (typeof nextProp === 'string') {\n        // Avoid setting initial textContent when the text is empty. In IE11 setting\n        // textContent on a <textarea> will cause the placeholder to not\n        // show within the <textarea> until it has been focused and blurred again.\n        // https://github.com/facebook/react/issues/6731#issuecomment-254874553\n        var canSetTextContent = tag !== 'textarea' || nextProp !== '';\n\n        if (canSetTextContent) {\n          setTextContent(domElement, nextProp);\n        }\n      } else if (typeof nextProp === 'number') {\n        setTextContent(domElement, '' + nextProp);\n      }\n    } else if (propKey === SUPPRESS_CONTENT_EDITABLE_WARNING || propKey === SUPPRESS_HYDRATION_WARNING) ; else if (propKey === AUTOFOCUS) ; else if (registrationNameDependencies.hasOwnProperty(propKey)) {\n      if (nextProp != null) {\n        if ( typeof nextProp !== 'function') {\n          warnForInvalidEventListener(propKey, nextProp);\n        }\n\n        if (propKey === 'onScroll') {\n          listenToNonDelegatedEvent('scroll', domElement);\n        }\n      }\n    } else if (nextProp != null) {\n      setValueForProperty(domElement, propKey, nextProp, isCustomComponentTag);\n    }\n  }\n}\n\nfunction updateDOMProperties(domElement, updatePayload, wasCustomComponentTag, isCustomComponentTag) {\n  // TODO: Handle wasCustomComponentTag\n  for (var i = 0; i < updatePayload.length; i += 2) {\n    var propKey = updatePayload[i];\n    var propValue = updatePayload[i + 1];\n\n    if (propKey === STYLE) {\n      setValueForStyles(domElement, propValue);\n    } else if (propKey === DANGEROUSLY_SET_INNER_HTML) {\n      setInnerHTML(domElement, propValue);\n    } else if (propKey === CHILDREN) {\n      setTextContent(domElement, propValue);\n    } else {\n      setValueForProperty(domElement, propKey, propValue, isCustomComponentTag);\n    }\n  }\n}\n\nfunction createElement(type, props, rootContainerElement, parentNamespace) {\n  var isCustomComponentTag; // We create tags in the namespace of their parent container, except HTML\n  // tags get no namespace.\n\n  var ownerDocument = getOwnerDocumentFromRootContainer(rootContainerElement);\n  var domElement;\n  var namespaceURI = parentNamespace;\n\n  if (namespaceURI === HTML_NAMESPACE) {\n    namespaceURI = getIntrinsicNamespace(type);\n  }\n\n  if (namespaceURI === HTML_NAMESPACE) {\n    {\n      isCustomComponentTag = isCustomComponent(type, props); // Should this check be gated by parent namespace? Not sure we want to\n      // allow <SVG> or <mATH>.\n\n      if (!isCustomComponentTag && type !== type.toLowerCase()) {\n        error('<%s /> is using incorrect casing. ' + 'Use PascalCase for React components, ' + 'or lowercase for HTML elements.', type);\n      }\n    }\n\n    if (type === 'script') {\n      // Create the script via .innerHTML so its \"parser-inserted\" flag is\n      // set to true and it does not execute\n      var div = ownerDocument.createElement('div');\n\n      div.innerHTML = '<script><' + '/script>'; // eslint-disable-line\n      // This is guaranteed to yield a script element.\n\n      var firstChild = div.firstChild;\n      domElement = div.removeChild(firstChild);\n    } else if (typeof props.is === 'string') {\n      // $FlowIssue `createElement` should be updated for Web Components\n      domElement = ownerDocument.createElement(type, {\n        is: props.is\n      });\n    } else {\n      // Separate else branch instead of using `props.is || undefined` above because of a Firefox bug.\n      // See discussion in https://github.com/facebook/react/pull/6896\n      // and discussion in https://bugzilla.mozilla.org/show_bug.cgi?id=1276240\n      domElement = ownerDocument.createElement(type); // Normally attributes are assigned in `setInitialDOMProperties`, however the `multiple` and `size`\n      // attributes on `select`s needs to be added before `option`s are inserted.\n      // This prevents:\n      // - a bug where the `select` does not scroll to the correct option because singular\n      //  `select` elements automatically pick the first item #13222\n      // - a bug where the `select` set the first item as selected despite the `size` attribute #14239\n      // See https://github.com/facebook/react/issues/13222\n      // and https://github.com/facebook/react/issues/14239\n\n      if (type === 'select') {\n        var node = domElement;\n\n        if (props.multiple) {\n          node.multiple = true;\n        } else if (props.size) {\n          // Setting a size greater than 1 causes a select to behave like `multiple=true`, where\n          // it is possible that no option is selected.\n          //\n          // This is only necessary when a select in \"single selection mode\".\n          node.size = props.size;\n        }\n      }\n    }\n  } else {\n    domElement = ownerDocument.createElementNS(namespaceURI, type);\n  }\n\n  {\n    if (namespaceURI === HTML_NAMESPACE) {\n      if (!isCustomComponentTag && Object.prototype.toString.call(domElement) === '[object HTMLUnknownElement]' && !hasOwnProperty.call(warnedUnknownTags, type)) {\n        warnedUnknownTags[type] = true;\n\n        error('The tag <%s> is unrecognized in this browser. ' + 'If you meant to render a React component, start its name with ' + 'an uppercase letter.', type);\n      }\n    }\n  }\n\n  return domElement;\n}\nfunction createTextNode(text, rootContainerElement) {\n  return getOwnerDocumentFromRootContainer(rootContainerElement).createTextNode(text);\n}\nfunction setInitialProperties(domElement, tag, rawProps, rootContainerElement) {\n  var isCustomComponentTag = isCustomComponent(tag, rawProps);\n\n  {\n    validatePropertiesInDevelopment(tag, rawProps);\n  } // TODO: Make sure that we check isMounted before firing any of these events.\n\n\n  var props;\n\n  switch (tag) {\n    case 'dialog':\n      listenToNonDelegatedEvent('cancel', domElement);\n      listenToNonDelegatedEvent('close', domElement);\n      props = rawProps;\n      break;\n\n    case 'iframe':\n    case 'object':\n    case 'embed':\n      // We listen to this event in case to ensure emulated bubble\n      // listeners still fire for the load event.\n      listenToNonDelegatedEvent('load', domElement);\n      props = rawProps;\n      break;\n\n    case 'video':\n    case 'audio':\n      // We listen to these events in case to ensure emulated bubble\n      // listeners still fire for all the media events.\n      for (var i = 0; i < mediaEventTypes.length; i++) {\n        listenToNonDelegatedEvent(mediaEventTypes[i], domElement);\n      }\n\n      props = rawProps;\n      break;\n\n    case 'source':\n      // We listen to this event in case to ensure emulated bubble\n      // listeners still fire for the error event.\n      listenToNonDelegatedEvent('error', domElement);\n      props = rawProps;\n      break;\n\n    case 'img':\n    case 'image':\n    case 'link':\n      // We listen to these events in case to ensure emulated bubble\n      // listeners still fire for error and load events.\n      listenToNonDelegatedEvent('error', domElement);\n      listenToNonDelegatedEvent('load', domElement);\n      props = rawProps;\n      break;\n\n    case 'details':\n      // We listen to this event in case to ensure emulated bubble\n      // listeners still fire for the toggle event.\n      listenToNonDelegatedEvent('toggle', domElement);\n      props = rawProps;\n      break;\n\n    case 'input':\n      initWrapperState(domElement, rawProps);\n      props = getHostProps(domElement, rawProps); // We listen to this event in case to ensure emulated bubble\n      // listeners still fire for the invalid event.\n\n      listenToNonDelegatedEvent('invalid', domElement);\n      break;\n\n    case 'option':\n      validateProps(domElement, rawProps);\n      props = rawProps;\n      break;\n\n    case 'select':\n      initWrapperState$1(domElement, rawProps);\n      props = getHostProps$1(domElement, rawProps); // We listen to this event in case to ensure emulated bubble\n      // listeners still fire for the invalid event.\n\n      listenToNonDelegatedEvent('invalid', domElement);\n      break;\n\n    case 'textarea':\n      initWrapperState$2(domElement, rawProps);\n      props = getHostProps$2(domElement, rawProps); // We listen to this event in case to ensure emulated bubble\n      // listeners still fire for the invalid event.\n\n      listenToNonDelegatedEvent('invalid', domElement);\n      break;\n\n    default:\n      props = rawProps;\n  }\n\n  assertValidProps(tag, props);\n  setInitialDOMProperties(tag, domElement, rootContainerElement, props, isCustomComponentTag);\n\n  switch (tag) {\n    case 'input':\n      // TODO: Make sure we check if this is still unmounted or do any clean\n      // up necessary since we never stop tracking anymore.\n      track(domElement);\n      postMountWrapper(domElement, rawProps, false);\n      break;\n\n    case 'textarea':\n      // TODO: Make sure we check if this is still unmounted or do any clean\n      // up necessary since we never stop tracking anymore.\n      track(domElement);\n      postMountWrapper$3(domElement);\n      break;\n\n    case 'option':\n      postMountWrapper$1(domElement, rawProps);\n      break;\n\n    case 'select':\n      postMountWrapper$2(domElement, rawProps);\n      break;\n\n    default:\n      if (typeof props.onClick === 'function') {\n        // TODO: This cast may not be sound for SVG, MathML or custom elements.\n        trapClickOnNonInteractiveElement(domElement);\n      }\n\n      break;\n  }\n} // Calculate the diff between the two objects.\n\nfunction diffProperties(domElement, tag, lastRawProps, nextRawProps, rootContainerElement) {\n  {\n    validatePropertiesInDevelopment(tag, nextRawProps);\n  }\n\n  var updatePayload = null;\n  var lastProps;\n  var nextProps;\n\n  switch (tag) {\n    case 'input':\n      lastProps = getHostProps(domElement, lastRawProps);\n      nextProps = getHostProps(domElement, nextRawProps);\n      updatePayload = [];\n      break;\n\n    case 'select':\n      lastProps = getHostProps$1(domElement, lastRawProps);\n      nextProps = getHostProps$1(domElement, nextRawProps);\n      updatePayload = [];\n      break;\n\n    case 'textarea':\n      lastProps = getHostProps$2(domElement, lastRawProps);\n      nextProps = getHostProps$2(domElement, nextRawProps);\n      updatePayload = [];\n      break;\n\n    default:\n      lastProps = lastRawProps;\n      nextProps = nextRawProps;\n\n      if (typeof lastProps.onClick !== 'function' && typeof nextProps.onClick === 'function') {\n        // TODO: This cast may not be sound for SVG, MathML or custom elements.\n        trapClickOnNonInteractiveElement(domElement);\n      }\n\n      break;\n  }\n\n  assertValidProps(tag, nextProps);\n  var propKey;\n  var styleName;\n  var styleUpdates = null;\n\n  for (propKey in lastProps) {\n    if (nextProps.hasOwnProperty(propKey) || !lastProps.hasOwnProperty(propKey) || lastProps[propKey] == null) {\n      continue;\n    }\n\n    if (propKey === STYLE) {\n      var lastStyle = lastProps[propKey];\n\n      for (styleName in lastStyle) {\n        if (lastStyle.hasOwnProperty(styleName)) {\n          if (!styleUpdates) {\n            styleUpdates = {};\n          }\n\n          styleUpdates[styleName] = '';\n        }\n      }\n    } else if (propKey === DANGEROUSLY_SET_INNER_HTML || propKey === CHILDREN) ; else if (propKey === SUPPRESS_CONTENT_EDITABLE_WARNING || propKey === SUPPRESS_HYDRATION_WARNING) ; else if (propKey === AUTOFOCUS) ; else if (registrationNameDependencies.hasOwnProperty(propKey)) {\n      // This is a special case. If any listener updates we need to ensure\n      // that the \"current\" fiber pointer gets updated so we need a commit\n      // to update this element.\n      if (!updatePayload) {\n        updatePayload = [];\n      }\n    } else {\n      // For all other deleted properties we add it to the queue. We use\n      // the allowed property list in the commit phase instead.\n      (updatePayload = updatePayload || []).push(propKey, null);\n    }\n  }\n\n  for (propKey in nextProps) {\n    var nextProp = nextProps[propKey];\n    var lastProp = lastProps != null ? lastProps[propKey] : undefined;\n\n    if (!nextProps.hasOwnProperty(propKey) || nextProp === lastProp || nextProp == null && lastProp == null) {\n      continue;\n    }\n\n    if (propKey === STYLE) {\n      {\n        if (nextProp) {\n          // Freeze the next style object so that we can assume it won't be\n          // mutated. We have already warned for this in the past.\n          Object.freeze(nextProp);\n        }\n      }\n\n      if (lastProp) {\n        // Unset styles on `lastProp` but not on `nextProp`.\n        for (styleName in lastProp) {\n          if (lastProp.hasOwnProperty(styleName) && (!nextProp || !nextProp.hasOwnProperty(styleName))) {\n            if (!styleUpdates) {\n              styleUpdates = {};\n            }\n\n            styleUpdates[styleName] = '';\n          }\n        } // Update styles that changed since `lastProp`.\n\n\n        for (styleName in nextProp) {\n          if (nextProp.hasOwnProperty(styleName) && lastProp[styleName] !== nextProp[styleName]) {\n            if (!styleUpdates) {\n              styleUpdates = {};\n            }\n\n            styleUpdates[styleName] = nextProp[styleName];\n          }\n        }\n      } else {\n        // Relies on `updateStylesByID` not mutating `styleUpdates`.\n        if (!styleUpdates) {\n          if (!updatePayload) {\n            updatePayload = [];\n          }\n\n          updatePayload.push(propKey, styleUpdates);\n        }\n\n        styleUpdates = nextProp;\n      }\n    } else if (propKey === DANGEROUSLY_SET_INNER_HTML) {\n      var nextHtml = nextProp ? nextProp[HTML$1] : undefined;\n      var lastHtml = lastProp ? lastProp[HTML$1] : undefined;\n\n      if (nextHtml != null) {\n        if (lastHtml !== nextHtml) {\n          (updatePayload = updatePayload || []).push(propKey, nextHtml);\n        }\n      }\n    } else if (propKey === CHILDREN) {\n      if (typeof nextProp === 'string' || typeof nextProp === 'number') {\n        (updatePayload = updatePayload || []).push(propKey, '' + nextProp);\n      }\n    } else if (propKey === SUPPRESS_CONTENT_EDITABLE_WARNING || propKey === SUPPRESS_HYDRATION_WARNING) ; else if (registrationNameDependencies.hasOwnProperty(propKey)) {\n      if (nextProp != null) {\n        // We eagerly listen to this even though we haven't committed yet.\n        if ( typeof nextProp !== 'function') {\n          warnForInvalidEventListener(propKey, nextProp);\n        }\n\n        if (propKey === 'onScroll') {\n          listenToNonDelegatedEvent('scroll', domElement);\n        }\n      }\n\n      if (!updatePayload && lastProp !== nextProp) {\n        // This is a special case. If any listener updates we need to ensure\n        // that the \"current\" props pointer gets updated so we need a commit\n        // to update this element.\n        updatePayload = [];\n      }\n    } else {\n      // For any other property we always add it to the queue and then we\n      // filter it out using the allowed property list during the commit.\n      (updatePayload = updatePayload || []).push(propKey, nextProp);\n    }\n  }\n\n  if (styleUpdates) {\n    {\n      validateShorthandPropertyCollisionInDev(styleUpdates, nextProps[STYLE]);\n    }\n\n    (updatePayload = updatePayload || []).push(STYLE, styleUpdates);\n  }\n\n  return updatePayload;\n} // Apply the diff.\n\nfunction updateProperties(domElement, updatePayload, tag, lastRawProps, nextRawProps) {\n  // Update checked *before* name.\n  // In the middle of an update, it is possible to have multiple checked.\n  // When a checked radio tries to change name, browser makes another radio's checked false.\n  if (tag === 'input' && nextRawProps.type === 'radio' && nextRawProps.name != null) {\n    updateChecked(domElement, nextRawProps);\n  }\n\n  var wasCustomComponentTag = isCustomComponent(tag, lastRawProps);\n  var isCustomComponentTag = isCustomComponent(tag, nextRawProps); // Apply the diff.\n\n  updateDOMProperties(domElement, updatePayload, wasCustomComponentTag, isCustomComponentTag); // TODO: Ensure that an update gets scheduled if any of the special props\n  // changed.\n\n  switch (tag) {\n    case 'input':\n      // Update the wrapper around inputs *after* updating props. This has to\n      // happen after `updateDOMProperties`. Otherwise HTML5 input validations\n      // raise warnings and prevent the new value from being assigned.\n      updateWrapper(domElement, nextRawProps);\n      break;\n\n    case 'textarea':\n      updateWrapper$1(domElement, nextRawProps);\n      break;\n\n    case 'select':\n      // <select> value update needs to occur after <option> children\n      // reconciliation\n      postUpdateWrapper(domElement, nextRawProps);\n      break;\n  }\n}\n\nfunction getPossibleStandardName(propName) {\n  {\n    var lowerCasedName = propName.toLowerCase();\n\n    if (!possibleStandardNames.hasOwnProperty(lowerCasedName)) {\n      return null;\n    }\n\n    return possibleStandardNames[lowerCasedName] || null;\n  }\n}\n\nfunction diffHydratedProperties(domElement, tag, rawProps, parentNamespace, rootContainerElement, isConcurrentMode, shouldWarnDev) {\n  var isCustomComponentTag;\n  var extraAttributeNames;\n\n  {\n    isCustomComponentTag = isCustomComponent(tag, rawProps);\n    validatePropertiesInDevelopment(tag, rawProps);\n  } // TODO: Make sure that we check isMounted before firing any of these events.\n\n\n  switch (tag) {\n    case 'dialog':\n      listenToNonDelegatedEvent('cancel', domElement);\n      listenToNonDelegatedEvent('close', domElement);\n      break;\n\n    case 'iframe':\n    case 'object':\n    case 'embed':\n      // We listen to this event in case to ensure emulated bubble\n      // listeners still fire for the load event.\n      listenToNonDelegatedEvent('load', domElement);\n      break;\n\n    case 'video':\n    case 'audio':\n      // We listen to these events in case to ensure emulated bubble\n      // listeners still fire for all the media events.\n      for (var i = 0; i < mediaEventTypes.length; i++) {\n        listenToNonDelegatedEvent(mediaEventTypes[i], domElement);\n      }\n\n      break;\n\n    case 'source':\n      // We listen to this event in case to ensure emulated bubble\n      // listeners still fire for the error event.\n      listenToNonDelegatedEvent('error', domElement);\n      break;\n\n    case 'img':\n    case 'image':\n    case 'link':\n      // We listen to these events in case to ensure emulated bubble\n      // listeners still fire for error and load events.\n      listenToNonDelegatedEvent('error', domElement);\n      listenToNonDelegatedEvent('load', domElement);\n      break;\n\n    case 'details':\n      // We listen to this event in case to ensure emulated bubble\n      // listeners still fire for the toggle event.\n      listenToNonDelegatedEvent('toggle', domElement);\n      break;\n\n    case 'input':\n      initWrapperState(domElement, rawProps); // We listen to this event in case to ensure emulated bubble\n      // listeners still fire for the invalid event.\n\n      listenToNonDelegatedEvent('invalid', domElement);\n      break;\n\n    case 'option':\n      validateProps(domElement, rawProps);\n      break;\n\n    case 'select':\n      initWrapperState$1(domElement, rawProps); // We listen to this event in case to ensure emulated bubble\n      // listeners still fire for the invalid event.\n\n      listenToNonDelegatedEvent('invalid', domElement);\n      break;\n\n    case 'textarea':\n      initWrapperState$2(domElement, rawProps); // We listen to this event in case to ensure emulated bubble\n      // listeners still fire for the invalid event.\n\n      listenToNonDelegatedEvent('invalid', domElement);\n      break;\n  }\n\n  assertValidProps(tag, rawProps);\n\n  {\n    extraAttributeNames = new Set();\n    var attributes = domElement.attributes;\n\n    for (var _i = 0; _i < attributes.length; _i++) {\n      var name = attributes[_i].name.toLowerCase();\n\n      switch (name) {\n        // Controlled attributes are not validated\n        // TODO: Only ignore them on controlled tags.\n        case 'value':\n          break;\n\n        case 'checked':\n          break;\n\n        case 'selected':\n          break;\n\n        default:\n          // Intentionally use the original name.\n          // See discussion in https://github.com/facebook/react/pull/10676.\n          extraAttributeNames.add(attributes[_i].name);\n      }\n    }\n  }\n\n  var updatePayload = null;\n\n  for (var propKey in rawProps) {\n    if (!rawProps.hasOwnProperty(propKey)) {\n      continue;\n    }\n\n    var nextProp = rawProps[propKey];\n\n    if (propKey === CHILDREN) {\n      // For text content children we compare against textContent. This\n      // might match additional HTML that is hidden when we read it using\n      // textContent. E.g. \"foo\" will match \"f<span>oo</span>\" but that still\n      // satisfies our requirement. Our requirement is not to produce perfect\n      // HTML and attributes. Ideally we should preserve structure but it's\n      // ok not to if the visible content is still enough to indicate what\n      // even listeners these nodes might be wired up to.\n      // TODO: Warn if there is more than a single textNode as a child.\n      // TODO: Should we use domElement.firstChild.nodeValue to compare?\n      if (typeof nextProp === 'string') {\n        if (domElement.textContent !== nextProp) {\n          if (rawProps[SUPPRESS_HYDRATION_WARNING] !== true) {\n            checkForUnmatchedText(domElement.textContent, nextProp, isConcurrentMode, shouldWarnDev);\n          }\n\n          updatePayload = [CHILDREN, nextProp];\n        }\n      } else if (typeof nextProp === 'number') {\n        if (domElement.textContent !== '' + nextProp) {\n          if (rawProps[SUPPRESS_HYDRATION_WARNING] !== true) {\n            checkForUnmatchedText(domElement.textContent, nextProp, isConcurrentMode, shouldWarnDev);\n          }\n\n          updatePayload = [CHILDREN, '' + nextProp];\n        }\n      }\n    } else if (registrationNameDependencies.hasOwnProperty(propKey)) {\n      if (nextProp != null) {\n        if ( typeof nextProp !== 'function') {\n          warnForInvalidEventListener(propKey, nextProp);\n        }\n\n        if (propKey === 'onScroll') {\n          listenToNonDelegatedEvent('scroll', domElement);\n        }\n      }\n    } else if (shouldWarnDev && true && // Convince Flow we've calculated it (it's DEV-only in this method.)\n    typeof isCustomComponentTag === 'boolean') {\n      // Validate that the properties correspond to their expected values.\n      var serverValue = void 0;\n      var propertyInfo = isCustomComponentTag && enableCustomElementPropertySupport ? null : getPropertyInfo(propKey);\n\n      if (rawProps[SUPPRESS_HYDRATION_WARNING] === true) ; else if (propKey === SUPPRESS_CONTENT_EDITABLE_WARNING || propKey === SUPPRESS_HYDRATION_WARNING || // Controlled attributes are not validated\n      // TODO: Only ignore them on controlled tags.\n      propKey === 'value' || propKey === 'checked' || propKey === 'selected') ; else if (propKey === DANGEROUSLY_SET_INNER_HTML) {\n        var serverHTML = domElement.innerHTML;\n        var nextHtml = nextProp ? nextProp[HTML$1] : undefined;\n\n        if (nextHtml != null) {\n          var expectedHTML = normalizeHTML(domElement, nextHtml);\n\n          if (expectedHTML !== serverHTML) {\n            warnForPropDifference(propKey, serverHTML, expectedHTML);\n          }\n        }\n      } else if (propKey === STYLE) {\n        // $FlowFixMe - Should be inferred as not undefined.\n        extraAttributeNames.delete(propKey);\n\n        if (canDiffStyleForHydrationWarning) {\n          var expectedStyle = createDangerousStringForStyles(nextProp);\n          serverValue = domElement.getAttribute('style');\n\n          if (expectedStyle !== serverValue) {\n            warnForPropDifference(propKey, serverValue, expectedStyle);\n          }\n        }\n      } else if (isCustomComponentTag && !enableCustomElementPropertySupport) {\n        // $FlowFixMe - Should be inferred as not undefined.\n        extraAttributeNames.delete(propKey.toLowerCase());\n        serverValue = getValueForAttribute(domElement, propKey, nextProp);\n\n        if (nextProp !== serverValue) {\n          warnForPropDifference(propKey, serverValue, nextProp);\n        }\n      } else if (!shouldIgnoreAttribute(propKey, propertyInfo, isCustomComponentTag) && !shouldRemoveAttribute(propKey, nextProp, propertyInfo, isCustomComponentTag)) {\n        var isMismatchDueToBadCasing = false;\n\n        if (propertyInfo !== null) {\n          // $FlowFixMe - Should be inferred as not undefined.\n          extraAttributeNames.delete(propertyInfo.attributeName);\n          serverValue = getValueForProperty(domElement, propKey, nextProp, propertyInfo);\n        } else {\n          var ownNamespace = parentNamespace;\n\n          if (ownNamespace === HTML_NAMESPACE) {\n            ownNamespace = getIntrinsicNamespace(tag);\n          }\n\n          if (ownNamespace === HTML_NAMESPACE) {\n            // $FlowFixMe - Should be inferred as not undefined.\n            extraAttributeNames.delete(propKey.toLowerCase());\n          } else {\n            var standardName = getPossibleStandardName(propKey);\n\n            if (standardName !== null && standardName !== propKey) {\n              // If an SVG prop is supplied with bad casing, it will\n              // be successfully parsed from HTML, but will produce a mismatch\n              // (and would be incorrectly rendered on the client).\n              // However, we already warn about bad casing elsewhere.\n              // So we'll skip the misleading extra mismatch warning in this case.\n              isMismatchDueToBadCasing = true; // $FlowFixMe - Should be inferred as not undefined.\n\n              extraAttributeNames.delete(standardName);\n            } // $FlowFixMe - Should be inferred as not undefined.\n\n\n            extraAttributeNames.delete(propKey);\n          }\n\n          serverValue = getValueForAttribute(domElement, propKey, nextProp);\n        }\n\n        var dontWarnCustomElement = enableCustomElementPropertySupport  ;\n\n        if (!dontWarnCustomElement && nextProp !== serverValue && !isMismatchDueToBadCasing) {\n          warnForPropDifference(propKey, serverValue, nextProp);\n        }\n      }\n    }\n  }\n\n  {\n    if (shouldWarnDev) {\n      if ( // $FlowFixMe - Should be inferred as not undefined.\n      extraAttributeNames.size > 0 && rawProps[SUPPRESS_HYDRATION_WARNING] !== true) {\n        // $FlowFixMe - Should be inferred as not undefined.\n        warnForExtraAttributes(extraAttributeNames);\n      }\n    }\n  }\n\n  switch (tag) {\n    case 'input':\n      // TODO: Make sure we check if this is still unmounted or do any clean\n      // up necessary since we never stop tracking anymore.\n      track(domElement);\n      postMountWrapper(domElement, rawProps, true);\n      break;\n\n    case 'textarea':\n      // TODO: Make sure we check if this is still unmounted or do any clean\n      // up necessary since we never stop tracking anymore.\n      track(domElement);\n      postMountWrapper$3(domElement);\n      break;\n\n    case 'select':\n    case 'option':\n      // For input and textarea we current always set the value property at\n      // post mount to force it to diverge from attributes. However, for\n      // option and select we don't quite do the same thing and select\n      // is not resilient to the DOM state changing so we don't do that here.\n      // TODO: Consider not doing this for input and textarea.\n      break;\n\n    default:\n      if (typeof rawProps.onClick === 'function') {\n        // TODO: This cast may not be sound for SVG, MathML or custom elements.\n        trapClickOnNonInteractiveElement(domElement);\n      }\n\n      break;\n  }\n\n  return updatePayload;\n}\nfunction diffHydratedText(textNode, text, isConcurrentMode) {\n  var isDifferent = textNode.nodeValue !== text;\n  return isDifferent;\n}\nfunction warnForDeletedHydratableElement(parentNode, child) {\n  {\n    if (didWarnInvalidHydration) {\n      return;\n    }\n\n    didWarnInvalidHydration = true;\n\n    error('Did not expect server HTML to contain a <%s> in <%s>.', child.nodeName.toLowerCase(), parentNode.nodeName.toLowerCase());\n  }\n}\nfunction warnForDeletedHydratableText(parentNode, child) {\n  {\n    if (didWarnInvalidHydration) {\n      return;\n    }\n\n    didWarnInvalidHydration = true;\n\n    error('Did not expect server HTML to contain the text node \"%s\" in <%s>.', child.nodeValue, parentNode.nodeName.toLowerCase());\n  }\n}\nfunction warnForInsertedHydratedElement(parentNode, tag, props) {\n  {\n    if (didWarnInvalidHydration) {\n      return;\n    }\n\n    didWarnInvalidHydration = true;\n\n    error('Expected server HTML to contain a matching <%s> in <%s>.', tag, parentNode.nodeName.toLowerCase());\n  }\n}\nfunction warnForInsertedHydratedText(parentNode, text) {\n  {\n    if (text === '') {\n      // We expect to insert empty text nodes since they're not represented in\n      // the HTML.\n      // TODO: Remove this special case if we can just avoid inserting empty\n      // text nodes.\n      return;\n    }\n\n    if (didWarnInvalidHydration) {\n      return;\n    }\n\n    didWarnInvalidHydration = true;\n\n    error('Expected server HTML to contain a matching text node for \"%s\" in <%s>.', text, parentNode.nodeName.toLowerCase());\n  }\n}\nfunction restoreControlledState$3(domElement, tag, props) {\n  switch (tag) {\n    case 'input':\n      restoreControlledState(domElement, props);\n      return;\n\n    case 'textarea':\n      restoreControlledState$2(domElement, props);\n      return;\n\n    case 'select':\n      restoreControlledState$1(domElement, props);\n      return;\n  }\n}\n\nvar validateDOMNesting = function () {};\n\nvar updatedAncestorInfo = function () {};\n\n{\n  // This validation code was written based on the HTML5 parsing spec:\n  // https://html.spec.whatwg.org/multipage/syntax.html#has-an-element-in-scope\n  //\n  // Note: this does not catch all invalid nesting, nor does it try to (as it's\n  // not clear what practical benefit doing so provides); instead, we warn only\n  // for cases where the parser will give a parse tree differing from what React\n  // intended. For example, <b><div></div></b> is invalid but we don't warn\n  // because it still parses correctly; we do warn for other cases like nested\n  // <p> tags where the beginning of the second element implicitly closes the\n  // first, causing a confusing mess.\n  // https://html.spec.whatwg.org/multipage/syntax.html#special\n  var specialTags = ['address', 'applet', 'area', 'article', 'aside', 'base', 'basefont', 'bgsound', 'blockquote', 'body', 'br', 'button', 'caption', 'center', 'col', 'colgroup', 'dd', 'details', 'dir', 'div', 'dl', 'dt', 'embed', 'fieldset', 'figcaption', 'figure', 'footer', 'form', 'frame', 'frameset', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'head', 'header', 'hgroup', 'hr', 'html', 'iframe', 'img', 'input', 'isindex', 'li', 'link', 'listing', 'main', 'marquee', 'menu', 'menuitem', 'meta', 'nav', 'noembed', 'noframes', 'noscript', 'object', 'ol', 'p', 'param', 'plaintext', 'pre', 'script', 'section', 'select', 'source', 'style', 'summary', 'table', 'tbody', 'td', 'template', 'textarea', 'tfoot', 'th', 'thead', 'title', 'tr', 'track', 'ul', 'wbr', 'xmp']; // https://html.spec.whatwg.org/multipage/syntax.html#has-an-element-in-scope\n\n  var inScopeTags = ['applet', 'caption', 'html', 'table', 'td', 'th', 'marquee', 'object', 'template', // https://html.spec.whatwg.org/multipage/syntax.html#html-integration-point\n  // TODO: Distinguish by namespace here -- for <title>, including it here\n  // errs on the side of fewer warnings\n  'foreignObject', 'desc', 'title']; // https://html.spec.whatwg.org/multipage/syntax.html#has-an-element-in-button-scope\n\n  var buttonScopeTags = inScopeTags.concat(['button']); // https://html.spec.whatwg.org/multipage/syntax.html#generate-implied-end-tags\n\n  var impliedEndTags = ['dd', 'dt', 'li', 'option', 'optgroup', 'p', 'rp', 'rt'];\n  var emptyAncestorInfo = {\n    current: null,\n    formTag: null,\n    aTagInScope: null,\n    buttonTagInScope: null,\n    nobrTagInScope: null,\n    pTagInButtonScope: null,\n    listItemTagAutoclosing: null,\n    dlItemTagAutoclosing: null\n  };\n\n  updatedAncestorInfo = function (oldInfo, tag) {\n    var ancestorInfo = assign({}, oldInfo || emptyAncestorInfo);\n\n    var info = {\n      tag: tag\n    };\n\n    if (inScopeTags.indexOf(tag) !== -1) {\n      ancestorInfo.aTagInScope = null;\n      ancestorInfo.buttonTagInScope = null;\n      ancestorInfo.nobrTagInScope = null;\n    }\n\n    if (buttonScopeTags.indexOf(tag) !== -1) {\n      ancestorInfo.pTagInButtonScope = null;\n    } // See rules for 'li', 'dd', 'dt' start tags in\n    // https://html.spec.whatwg.org/multipage/syntax.html#parsing-main-inbody\n\n\n    if (specialTags.indexOf(tag) !== -1 && tag !== 'address' && tag !== 'div' && tag !== 'p') {\n      ancestorInfo.listItemTagAutoclosing = null;\n      ancestorInfo.dlItemTagAutoclosing = null;\n    }\n\n    ancestorInfo.current = info;\n\n    if (tag === 'form') {\n      ancestorInfo.formTag = info;\n    }\n\n    if (tag === 'a') {\n      ancestorInfo.aTagInScope = info;\n    }\n\n    if (tag === 'button') {\n      ancestorInfo.buttonTagInScope = info;\n    }\n\n    if (tag === 'nobr') {\n      ancestorInfo.nobrTagInScope = info;\n    }\n\n    if (tag === 'p') {\n      ancestorInfo.pTagInButtonScope = info;\n    }\n\n    if (tag === 'li') {\n      ancestorInfo.listItemTagAutoclosing = info;\n    }\n\n    if (tag === 'dd' || tag === 'dt') {\n      ancestorInfo.dlItemTagAutoclosing = info;\n    }\n\n    return ancestorInfo;\n  };\n  /**\n   * Returns whether\n   */\n\n\n  var isTagValidWithParent = function (tag, parentTag) {\n    // First, let's check if we're in an unusual parsing mode...\n    switch (parentTag) {\n      // https://html.spec.whatwg.org/multipage/syntax.html#parsing-main-inselect\n      case 'select':\n        return tag === 'option' || tag === 'optgroup' || tag === '#text';\n\n      case 'optgroup':\n        return tag === 'option' || tag === '#text';\n      // Strictly speaking, seeing an <option> doesn't mean we're in a <select>\n      // but\n\n      case 'option':\n        return tag === '#text';\n      // https://html.spec.whatwg.org/multipage/syntax.html#parsing-main-intd\n      // https://html.spec.whatwg.org/multipage/syntax.html#parsing-main-incaption\n      // No special behavior since these rules fall back to \"in body\" mode for\n      // all except special table nodes which cause bad parsing behavior anyway.\n      // https://html.spec.whatwg.org/multipage/syntax.html#parsing-main-intr\n\n      case 'tr':\n        return tag === 'th' || tag === 'td' || tag === 'style' || tag === 'script' || tag === 'template';\n      // https://html.spec.whatwg.org/multipage/syntax.html#parsing-main-intbody\n\n      case 'tbody':\n      case 'thead':\n      case 'tfoot':\n        return tag === 'tr' || tag === 'style' || tag === 'script' || tag === 'template';\n      // https://html.spec.whatwg.org/multipage/syntax.html#parsing-main-incolgroup\n\n      case 'colgroup':\n        return tag === 'col' || tag === 'template';\n      // https://html.spec.whatwg.org/multipage/syntax.html#parsing-main-intable\n\n      case 'table':\n        return tag === 'caption' || tag === 'colgroup' || tag === 'tbody' || tag === 'tfoot' || tag === 'thead' || tag === 'style' || tag === 'script' || tag === 'template';\n      // https://html.spec.whatwg.org/multipage/syntax.html#parsing-main-inhead\n\n      case 'head':\n        return tag === 'base' || tag === 'basefont' || tag === 'bgsound' || tag === 'link' || tag === 'meta' || tag === 'title' || tag === 'noscript' || tag === 'noframes' || tag === 'style' || tag === 'script' || tag === 'template';\n      // https://html.spec.whatwg.org/multipage/semantics.html#the-html-element\n\n      case 'html':\n        return tag === 'head' || tag === 'body' || tag === 'frameset';\n\n      case 'frameset':\n        return tag === 'frame';\n\n      case '#document':\n        return tag === 'html';\n    } // Probably in the \"in body\" parsing mode, so we outlaw only tag combos\n    // where the parsing rules cause implicit opens or closes to be added.\n    // https://html.spec.whatwg.org/multipage/syntax.html#parsing-main-inbody\n\n\n    switch (tag) {\n      case 'h1':\n      case 'h2':\n      case 'h3':\n      case 'h4':\n      case 'h5':\n      case 'h6':\n        return parentTag !== 'h1' && parentTag !== 'h2' && parentTag !== 'h3' && parentTag !== 'h4' && parentTag !== 'h5' && parentTag !== 'h6';\n\n      case 'rp':\n      case 'rt':\n        return impliedEndTags.indexOf(parentTag) === -1;\n\n      case 'body':\n      case 'caption':\n      case 'col':\n      case 'colgroup':\n      case 'frameset':\n      case 'frame':\n      case 'head':\n      case 'html':\n      case 'tbody':\n      case 'td':\n      case 'tfoot':\n      case 'th':\n      case 'thead':\n      case 'tr':\n        // These tags are only valid with a few parents that have special child\n        // parsing rules -- if we're down here, then none of those matched and\n        // so we allow it only if we don't know what the parent is, as all other\n        // cases are invalid.\n        return parentTag == null;\n    }\n\n    return true;\n  };\n  /**\n   * Returns whether\n   */\n\n\n  var findInvalidAncestorForTag = function (tag, ancestorInfo) {\n    switch (tag) {\n      case 'address':\n      case 'article':\n      case 'aside':\n      case 'blockquote':\n      case 'center':\n      case 'details':\n      case 'dialog':\n      case 'dir':\n      case 'div':\n      case 'dl':\n      case 'fieldset':\n      case 'figcaption':\n      case 'figure':\n      case 'footer':\n      case 'header':\n      case 'hgroup':\n      case 'main':\n      case 'menu':\n      case 'nav':\n      case 'ol':\n      case 'p':\n      case 'section':\n      case 'summary':\n      case 'ul':\n      case 'pre':\n      case 'listing':\n      case 'table':\n      case 'hr':\n      case 'xmp':\n      case 'h1':\n      case 'h2':\n      case 'h3':\n      case 'h4':\n      case 'h5':\n      case 'h6':\n        return ancestorInfo.pTagInButtonScope;\n\n      case 'form':\n        return ancestorInfo.formTag || ancestorInfo.pTagInButtonScope;\n\n      case 'li':\n        return ancestorInfo.listItemTagAutoclosing;\n\n      case 'dd':\n      case 'dt':\n        return ancestorInfo.dlItemTagAutoclosing;\n\n      case 'button':\n        return ancestorInfo.buttonTagInScope;\n\n      case 'a':\n        // Spec says something about storing a list of markers, but it sounds\n        // equivalent to this check.\n        return ancestorInfo.aTagInScope;\n\n      case 'nobr':\n        return ancestorInfo.nobrTagInScope;\n    }\n\n    return null;\n  };\n\n  var didWarn$1 = {};\n\n  validateDOMNesting = function (childTag, childText, ancestorInfo) {\n    ancestorInfo = ancestorInfo || emptyAncestorInfo;\n    var parentInfo = ancestorInfo.current;\n    var parentTag = parentInfo && parentInfo.tag;\n\n    if (childText != null) {\n      if (childTag != null) {\n        error('validateDOMNesting: when childText is passed, childTag should be null');\n      }\n\n      childTag = '#text';\n    }\n\n    var invalidParent = isTagValidWithParent(childTag, parentTag) ? null : parentInfo;\n    var invalidAncestor = invalidParent ? null : findInvalidAncestorForTag(childTag, ancestorInfo);\n    var invalidParentOrAncestor = invalidParent || invalidAncestor;\n\n    if (!invalidParentOrAncestor) {\n      return;\n    }\n\n    var ancestorTag = invalidParentOrAncestor.tag;\n    var warnKey = !!invalidParent + '|' + childTag + '|' + ancestorTag;\n\n    if (didWarn$1[warnKey]) {\n      return;\n    }\n\n    didWarn$1[warnKey] = true;\n    var tagDisplayName = childTag;\n    var whitespaceInfo = '';\n\n    if (childTag === '#text') {\n      if (/\\S/.test(childText)) {\n        tagDisplayName = 'Text nodes';\n      } else {\n        tagDisplayName = 'Whitespace text nodes';\n        whitespaceInfo = \" Make sure you don't have any extra whitespace between tags on \" + 'each line of your source code.';\n      }\n    } else {\n      tagDisplayName = '<' + childTag + '>';\n    }\n\n    if (invalidParent) {\n      var info = '';\n\n      if (ancestorTag === 'table' && childTag === 'tr') {\n        info += ' Add a <tbody>, <thead> or <tfoot> to your code to match the DOM tree generated by ' + 'the browser.';\n      }\n\n      error('validateDOMNesting(...): %s cannot appear as a child of <%s>.%s%s', tagDisplayName, ancestorTag, whitespaceInfo, info);\n    } else {\n      error('validateDOMNesting(...): %s cannot appear as a descendant of ' + '<%s>.', tagDisplayName, ancestorTag);\n    }\n  };\n}\n\nvar SUPPRESS_HYDRATION_WARNING$1 = 'suppressHydrationWarning';\nvar SUSPENSE_START_DATA = '$';\nvar SUSPENSE_END_DATA = '/$';\nvar SUSPENSE_PENDING_START_DATA = '$?';\nvar SUSPENSE_FALLBACK_START_DATA = '$!';\nvar STYLE$1 = 'style';\nvar eventsEnabled = null;\nvar selectionInformation = null;\nfunction getRootHostContext(rootContainerInstance) {\n  var type;\n  var namespace;\n  var nodeType = rootContainerInstance.nodeType;\n\n  switch (nodeType) {\n    case DOCUMENT_NODE:\n    case DOCUMENT_FRAGMENT_NODE:\n      {\n        type = nodeType === DOCUMENT_NODE ? '#document' : '#fragment';\n        var root = rootContainerInstance.documentElement;\n        namespace = root ? root.namespaceURI : getChildNamespace(null, '');\n        break;\n      }\n\n    default:\n      {\n        var container = nodeType === COMMENT_NODE ? rootContainerInstance.parentNode : rootContainerInstance;\n        var ownNamespace = container.namespaceURI || null;\n        type = container.tagName;\n        namespace = getChildNamespace(ownNamespace, type);\n        break;\n      }\n  }\n\n  {\n    var validatedTag = type.toLowerCase();\n    var ancestorInfo = updatedAncestorInfo(null, validatedTag);\n    return {\n      namespace: namespace,\n      ancestorInfo: ancestorInfo\n    };\n  }\n}\nfunction getChildHostContext(parentHostContext, type, rootContainerInstance) {\n  {\n    var parentHostContextDev = parentHostContext;\n    var namespace = getChildNamespace(parentHostContextDev.namespace, type);\n    var ancestorInfo = updatedAncestorInfo(parentHostContextDev.ancestorInfo, type);\n    return {\n      namespace: namespace,\n      ancestorInfo: ancestorInfo\n    };\n  }\n}\nfunction getPublicInstance(instance) {\n  return instance;\n}\nfunction prepareForCommit(containerInfo) {\n  eventsEnabled = isEnabled();\n  selectionInformation = getSelectionInformation();\n  var activeInstance = null;\n\n  setEnabled(false);\n  return activeInstance;\n}\nfunction resetAfterCommit(containerInfo) {\n  restoreSelection(selectionInformation);\n  setEnabled(eventsEnabled);\n  eventsEnabled = null;\n  selectionInformation = null;\n}\nfunction createInstance(type, props, rootContainerInstance, hostContext, internalInstanceHandle) {\n  var parentNamespace;\n\n  {\n    // TODO: take namespace into account when validating.\n    var hostContextDev = hostContext;\n    validateDOMNesting(type, null, hostContextDev.ancestorInfo);\n\n    if (typeof props.children === 'string' || typeof props.children === 'number') {\n      var string = '' + props.children;\n      var ownAncestorInfo = updatedAncestorInfo(hostContextDev.ancestorInfo, type);\n      validateDOMNesting(null, string, ownAncestorInfo);\n    }\n\n    parentNamespace = hostContextDev.namespace;\n  }\n\n  var domElement = createElement(type, props, rootContainerInstance, parentNamespace);\n  precacheFiberNode(internalInstanceHandle, domElement);\n  updateFiberProps(domElement, props);\n  return domElement;\n}\nfunction appendInitialChild(parentInstance, child) {\n  parentInstance.appendChild(child);\n}\nfunction finalizeInitialChildren(domElement, type, props, rootContainerInstance, hostContext) {\n  setInitialProperties(domElement, type, props, rootContainerInstance);\n\n  switch (type) {\n    case 'button':\n    case 'input':\n    case 'select':\n    case 'textarea':\n      return !!props.autoFocus;\n\n    case 'img':\n      return true;\n\n    default:\n      return false;\n  }\n}\nfunction prepareUpdate(domElement, type, oldProps, newProps, rootContainerInstance, hostContext) {\n  {\n    var hostContextDev = hostContext;\n\n    if (typeof newProps.children !== typeof oldProps.children && (typeof newProps.children === 'string' || typeof newProps.children === 'number')) {\n      var string = '' + newProps.children;\n      var ownAncestorInfo = updatedAncestorInfo(hostContextDev.ancestorInfo, type);\n      validateDOMNesting(null, string, ownAncestorInfo);\n    }\n  }\n\n  return diffProperties(domElement, type, oldProps, newProps);\n}\nfunction shouldSetTextContent(type, props) {\n  return type === 'textarea' || type === 'noscript' || typeof props.children === 'string' || typeof props.children === 'number' || typeof props.dangerouslySetInnerHTML === 'object' && props.dangerouslySetInnerHTML !== null && props.dangerouslySetInnerHTML.__html != null;\n}\nfunction createTextInstance(text, rootContainerInstance, hostContext, internalInstanceHandle) {\n  {\n    var hostContextDev = hostContext;\n    validateDOMNesting(null, text, hostContextDev.ancestorInfo);\n  }\n\n  var textNode = createTextNode(text, rootContainerInstance);\n  precacheFiberNode(internalInstanceHandle, textNode);\n  return textNode;\n}\nfunction getCurrentEventPriority() {\n  var currentEvent = window.event;\n\n  if (currentEvent === undefined) {\n    return DefaultEventPriority;\n  }\n\n  return getEventPriority(currentEvent.type);\n}\n// if a component just imports ReactDOM (e.g. for findDOMNode).\n// Some environments might not have setTimeout or clearTimeout.\n\nvar scheduleTimeout = typeof setTimeout === 'function' ? setTimeout : undefined;\nvar cancelTimeout = typeof clearTimeout === 'function' ? clearTimeout : undefined;\nvar noTimeout = -1;\nvar localPromise = typeof Promise === 'function' ? Promise : undefined; // -------------------\nvar scheduleMicrotask = typeof queueMicrotask === 'function' ? queueMicrotask : typeof localPromise !== 'undefined' ? function (callback) {\n  return localPromise.resolve(null).then(callback).catch(handleErrorInNextTick);\n} : scheduleTimeout; // TODO: Determine the best fallback here.\n\nfunction handleErrorInNextTick(error) {\n  setTimeout(function () {\n    throw error;\n  });\n} // -------------------\nfunction commitMount(domElement, type, newProps, internalInstanceHandle) {\n  // Despite the naming that might imply otherwise, this method only\n  // fires if there is an `Update` effect scheduled during mounting.\n  // This happens if `finalizeInitialChildren` returns `true` (which it\n  // does to implement the `autoFocus` attribute on the client). But\n  // there are also other cases when this might happen (such as patching\n  // up text content during hydration mismatch). So we'll check this again.\n  switch (type) {\n    case 'button':\n    case 'input':\n    case 'select':\n    case 'textarea':\n      if (newProps.autoFocus) {\n        domElement.focus();\n      }\n\n      return;\n\n    case 'img':\n      {\n        if (newProps.src) {\n          domElement.src = newProps.src;\n        }\n\n        return;\n      }\n  }\n}\nfunction commitUpdate(domElement, updatePayload, type, oldProps, newProps, internalInstanceHandle) {\n  // Apply the diff to the DOM node.\n  updateProperties(domElement, updatePayload, type, oldProps, newProps); // Update the props handle so that we know which props are the ones with\n  // with current event handlers.\n\n  updateFiberProps(domElement, newProps);\n}\nfunction resetTextContent(domElement) {\n  setTextContent(domElement, '');\n}\nfunction commitTextUpdate(textInstance, oldText, newText) {\n  textInstance.nodeValue = newText;\n}\nfunction appendChild(parentInstance, child) {\n  parentInstance.appendChild(child);\n}\nfunction appendChildToContainer(container, child) {\n  var parentNode;\n\n  if (container.nodeType === COMMENT_NODE) {\n    parentNode = container.parentNode;\n    parentNode.insertBefore(child, container);\n  } else {\n    parentNode = container;\n    parentNode.appendChild(child);\n  } // This container might be used for a portal.\n  // If something inside a portal is clicked, that click should bubble\n  // through the React tree. However, on Mobile Safari the click would\n  // never bubble through the *DOM* tree unless an ancestor with onclick\n  // event exists. So we wouldn't see it and dispatch it.\n  // This is why we ensure that non React root containers have inline onclick\n  // defined.\n  // https://github.com/facebook/react/issues/11918\n\n\n  var reactRootContainer = container._reactRootContainer;\n\n  if ((reactRootContainer === null || reactRootContainer === undefined) && parentNode.onclick === null) {\n    // TODO: This cast may not be sound for SVG, MathML or custom elements.\n    trapClickOnNonInteractiveElement(parentNode);\n  }\n}\nfunction insertBefore(parentInstance, child, beforeChild) {\n  parentInstance.insertBefore(child, beforeChild);\n}\nfunction insertInContainerBefore(container, child, beforeChild) {\n  if (container.nodeType === COMMENT_NODE) {\n    container.parentNode.insertBefore(child, beforeChild);\n  } else {\n    container.insertBefore(child, beforeChild);\n  }\n}\n\nfunction removeChild(parentInstance, child) {\n  parentInstance.removeChild(child);\n}\nfunction removeChildFromContainer(container, child) {\n  if (container.nodeType === COMMENT_NODE) {\n    container.parentNode.removeChild(child);\n  } else {\n    container.removeChild(child);\n  }\n}\nfunction clearSuspenseBoundary(parentInstance, suspenseInstance) {\n  var node = suspenseInstance; // Delete all nodes within this suspense boundary.\n  // There might be nested nodes so we need to keep track of how\n  // deep we are and only break out when we're back on top.\n\n  var depth = 0;\n\n  do {\n    var nextNode = node.nextSibling;\n    parentInstance.removeChild(node);\n\n    if (nextNode && nextNode.nodeType === COMMENT_NODE) {\n      var data = nextNode.data;\n\n      if (data === SUSPENSE_END_DATA) {\n        if (depth === 0) {\n          parentInstance.removeChild(nextNode); // Retry if any event replaying was blocked on this.\n\n          retryIfBlockedOn(suspenseInstance);\n          return;\n        } else {\n          depth--;\n        }\n      } else if (data === SUSPENSE_START_DATA || data === SUSPENSE_PENDING_START_DATA || data === SUSPENSE_FALLBACK_START_DATA) {\n        depth++;\n      }\n    }\n\n    node = nextNode;\n  } while (node); // TODO: Warn, we didn't find the end comment boundary.\n  // Retry if any event replaying was blocked on this.\n\n\n  retryIfBlockedOn(suspenseInstance);\n}\nfunction clearSuspenseBoundaryFromContainer(container, suspenseInstance) {\n  if (container.nodeType === COMMENT_NODE) {\n    clearSuspenseBoundary(container.parentNode, suspenseInstance);\n  } else if (container.nodeType === ELEMENT_NODE) {\n    clearSuspenseBoundary(container, suspenseInstance);\n  } // Retry if any event replaying was blocked on this.\n\n\n  retryIfBlockedOn(container);\n}\nfunction hideInstance(instance) {\n  // TODO: Does this work for all element types? What about MathML? Should we\n  // pass host context to this method?\n  instance = instance;\n  var style = instance.style;\n\n  if (typeof style.setProperty === 'function') {\n    style.setProperty('display', 'none', 'important');\n  } else {\n    style.display = 'none';\n  }\n}\nfunction hideTextInstance(textInstance) {\n  textInstance.nodeValue = '';\n}\nfunction unhideInstance(instance, props) {\n  instance = instance;\n  var styleProp = props[STYLE$1];\n  var display = styleProp !== undefined && styleProp !== null && styleProp.hasOwnProperty('display') ? styleProp.display : null;\n  instance.style.display = dangerousStyleValue('display', display);\n}\nfunction unhideTextInstance(textInstance, text) {\n  textInstance.nodeValue = text;\n}\nfunction clearContainer(container) {\n  if (container.nodeType === ELEMENT_NODE) {\n    container.textContent = '';\n  } else if (container.nodeType === DOCUMENT_NODE) {\n    if (container.documentElement) {\n      container.removeChild(container.documentElement);\n    }\n  }\n} // -------------------\nfunction canHydrateInstance(instance, type, props) {\n  if (instance.nodeType !== ELEMENT_NODE || type.toLowerCase() !== instance.nodeName.toLowerCase()) {\n    return null;\n  } // This has now been refined to an element node.\n\n\n  return instance;\n}\nfunction canHydrateTextInstance(instance, text) {\n  if (text === '' || instance.nodeType !== TEXT_NODE) {\n    // Empty strings are not parsed by HTML so there won't be a correct match here.\n    return null;\n  } // This has now been refined to a text node.\n\n\n  return instance;\n}\nfunction canHydrateSuspenseInstance(instance) {\n  if (instance.nodeType !== COMMENT_NODE) {\n    // Empty strings are not parsed by HTML so there won't be a correct match here.\n    return null;\n  } // This has now been refined to a suspense node.\n\n\n  return instance;\n}\nfunction isSuspenseInstancePending(instance) {\n  return instance.data === SUSPENSE_PENDING_START_DATA;\n}\nfunction isSuspenseInstanceFallback(instance) {\n  return instance.data === SUSPENSE_FALLBACK_START_DATA;\n}\nfunction getSuspenseInstanceFallbackErrorDetails(instance) {\n  var dataset = instance.nextSibling && instance.nextSibling.dataset;\n  var digest, message, stack;\n\n  if (dataset) {\n    digest = dataset.dgst;\n\n    {\n      message = dataset.msg;\n      stack = dataset.stck;\n    }\n  }\n\n  {\n    return {\n      message: message,\n      digest: digest,\n      stack: stack\n    };\n  } // let value = {message: undefined, hash: undefined};\n  // const nextSibling = instance.nextSibling;\n  // if (nextSibling) {\n  //   const dataset = ((nextSibling: any): HTMLTemplateElement).dataset;\n  //   value.message = dataset.msg;\n  //   value.hash = dataset.hash;\n  //   if (true) {\n  //     value.stack = dataset.stack;\n  //   }\n  // }\n  // return value;\n\n}\nfunction registerSuspenseInstanceRetry(instance, callback) {\n  instance._reactRetry = callback;\n}\n\nfunction getNextHydratable(node) {\n  // Skip non-hydratable nodes.\n  for (; node != null; node = node.nextSibling) {\n    var nodeType = node.nodeType;\n\n    if (nodeType === ELEMENT_NODE || nodeType === TEXT_NODE) {\n      break;\n    }\n\n    if (nodeType === COMMENT_NODE) {\n      var nodeData = node.data;\n\n      if (nodeData === SUSPENSE_START_DATA || nodeData === SUSPENSE_FALLBACK_START_DATA || nodeData === SUSPENSE_PENDING_START_DATA) {\n        break;\n      }\n\n      if (nodeData === SUSPENSE_END_DATA) {\n        return null;\n      }\n    }\n  }\n\n  return node;\n}\n\nfunction getNextHydratableSibling(instance) {\n  return getNextHydratable(instance.nextSibling);\n}\nfunction getFirstHydratableChild(parentInstance) {\n  return getNextHydratable(parentInstance.firstChild);\n}\nfunction getFirstHydratableChildWithinContainer(parentContainer) {\n  return getNextHydratable(parentContainer.firstChild);\n}\nfunction getFirstHydratableChildWithinSuspenseInstance(parentInstance) {\n  return getNextHydratable(parentInstance.nextSibling);\n}\nfunction hydrateInstance(instance, type, props, rootContainerInstance, hostContext, internalInstanceHandle, shouldWarnDev) {\n  precacheFiberNode(internalInstanceHandle, instance); // TODO: Possibly defer this until the commit phase where all the events\n  // get attached.\n\n  updateFiberProps(instance, props);\n  var parentNamespace;\n\n  {\n    var hostContextDev = hostContext;\n    parentNamespace = hostContextDev.namespace;\n  } // TODO: Temporary hack to check if we're in a concurrent root. We can delete\n  // when the legacy root API is removed.\n\n\n  var isConcurrentMode = (internalInstanceHandle.mode & ConcurrentMode) !== NoMode;\n  return diffHydratedProperties(instance, type, props, parentNamespace, rootContainerInstance, isConcurrentMode, shouldWarnDev);\n}\nfunction hydrateTextInstance(textInstance, text, internalInstanceHandle, shouldWarnDev) {\n  precacheFiberNode(internalInstanceHandle, textInstance); // TODO: Temporary hack to check if we're in a concurrent root. We can delete\n  // when the legacy root API is removed.\n\n  var isConcurrentMode = (internalInstanceHandle.mode & ConcurrentMode) !== NoMode;\n  return diffHydratedText(textInstance, text);\n}\nfunction hydrateSuspenseInstance(suspenseInstance, internalInstanceHandle) {\n  precacheFiberNode(internalInstanceHandle, suspenseInstance);\n}\nfunction getNextHydratableInstanceAfterSuspenseInstance(suspenseInstance) {\n  var node = suspenseInstance.nextSibling; // Skip past all nodes within this suspense boundary.\n  // There might be nested nodes so we need to keep track of how\n  // deep we are and only break out when we're back on top.\n\n  var depth = 0;\n\n  while (node) {\n    if (node.nodeType === COMMENT_NODE) {\n      var data = node.data;\n\n      if (data === SUSPENSE_END_DATA) {\n        if (depth === 0) {\n          return getNextHydratableSibling(node);\n        } else {\n          depth--;\n        }\n      } else if (data === SUSPENSE_START_DATA || data === SUSPENSE_FALLBACK_START_DATA || data === SUSPENSE_PENDING_START_DATA) {\n        depth++;\n      }\n    }\n\n    node = node.nextSibling;\n  } // TODO: Warn, we didn't find the end comment boundary.\n\n\n  return null;\n} // Returns the SuspenseInstance if this node is a direct child of a\n// SuspenseInstance. I.e. if its previous sibling is a Comment with\n// SUSPENSE_x_START_DATA. Otherwise, null.\n\nfunction getParentSuspenseInstance(targetInstance) {\n  var node = targetInstance.previousSibling; // Skip past all nodes within this suspense boundary.\n  // There might be nested nodes so we need to keep track of how\n  // deep we are and only break out when we're back on top.\n\n  var depth = 0;\n\n  while (node) {\n    if (node.nodeType === COMMENT_NODE) {\n      var data = node.data;\n\n      if (data === SUSPENSE_START_DATA || data === SUSPENSE_FALLBACK_START_DATA || data === SUSPENSE_PENDING_START_DATA) {\n        if (depth === 0) {\n          return node;\n        } else {\n          depth--;\n        }\n      } else if (data === SUSPENSE_END_DATA) {\n        depth++;\n      }\n    }\n\n    node = node.previousSibling;\n  }\n\n  return null;\n}\nfunction commitHydratedContainer(container) {\n  // Retry if any event replaying was blocked on this.\n  retryIfBlockedOn(container);\n}\nfunction commitHydratedSuspenseInstance(suspenseInstance) {\n  // Retry if any event replaying was blocked on this.\n  retryIfBlockedOn(suspenseInstance);\n}\nfunction shouldDeleteUnhydratedTailInstances(parentType) {\n  return parentType !== 'head' && parentType !== 'body';\n}\nfunction didNotMatchHydratedContainerTextInstance(parentContainer, textInstance, text, isConcurrentMode) {\n  var shouldWarnDev = true;\n  checkForUnmatchedText(textInstance.nodeValue, text, isConcurrentMode, shouldWarnDev);\n}\nfunction didNotMatchHydratedTextInstance(parentType, parentProps, parentInstance, textInstance, text, isConcurrentMode) {\n  if (parentProps[SUPPRESS_HYDRATION_WARNING$1] !== true) {\n    var shouldWarnDev = true;\n    checkForUnmatchedText(textInstance.nodeValue, text, isConcurrentMode, shouldWarnDev);\n  }\n}\nfunction didNotHydrateInstanceWithinContainer(parentContainer, instance) {\n  {\n    if (instance.nodeType === ELEMENT_NODE) {\n      warnForDeletedHydratableElement(parentContainer, instance);\n    } else if (instance.nodeType === COMMENT_NODE) ; else {\n      warnForDeletedHydratableText(parentContainer, instance);\n    }\n  }\n}\nfunction didNotHydrateInstanceWithinSuspenseInstance(parentInstance, instance) {\n  {\n    // $FlowFixMe: Only Element or Document can be parent nodes.\n    var parentNode = parentInstance.parentNode;\n\n    if (parentNode !== null) {\n      if (instance.nodeType === ELEMENT_NODE) {\n        warnForDeletedHydratableElement(parentNode, instance);\n      } else if (instance.nodeType === COMMENT_NODE) ; else {\n        warnForDeletedHydratableText(parentNode, instance);\n      }\n    }\n  }\n}\nfunction didNotHydrateInstance(parentType, parentProps, parentInstance, instance, isConcurrentMode) {\n  {\n    if (isConcurrentMode || parentProps[SUPPRESS_HYDRATION_WARNING$1] !== true) {\n      if (instance.nodeType === ELEMENT_NODE) {\n        warnForDeletedHydratableElement(parentInstance, instance);\n      } else if (instance.nodeType === COMMENT_NODE) ; else {\n        warnForDeletedHydratableText(parentInstance, instance);\n      }\n    }\n  }\n}\nfunction didNotFindHydratableInstanceWithinContainer(parentContainer, type, props) {\n  {\n    warnForInsertedHydratedElement(parentContainer, type);\n  }\n}\nfunction didNotFindHydratableTextInstanceWithinContainer(parentContainer, text) {\n  {\n    warnForInsertedHydratedText(parentContainer, text);\n  }\n}\nfunction didNotFindHydratableInstanceWithinSuspenseInstance(parentInstance, type, props) {\n  {\n    // $FlowFixMe: Only Element or Document can be parent nodes.\n    var parentNode = parentInstance.parentNode;\n    if (parentNode !== null) warnForInsertedHydratedElement(parentNode, type);\n  }\n}\nfunction didNotFindHydratableTextInstanceWithinSuspenseInstance(parentInstance, text) {\n  {\n    // $FlowFixMe: Only Element or Document can be parent nodes.\n    var parentNode = parentInstance.parentNode;\n    if (parentNode !== null) warnForInsertedHydratedText(parentNode, text);\n  }\n}\nfunction didNotFindHydratableInstance(parentType, parentProps, parentInstance, type, props, isConcurrentMode) {\n  {\n    if (isConcurrentMode || parentProps[SUPPRESS_HYDRATION_WARNING$1] !== true) {\n      warnForInsertedHydratedElement(parentInstance, type);\n    }\n  }\n}\nfunction didNotFindHydratableTextInstance(parentType, parentProps, parentInstance, text, isConcurrentMode) {\n  {\n    if (isConcurrentMode || parentProps[SUPPRESS_HYDRATION_WARNING$1] !== true) {\n      warnForInsertedHydratedText(parentInstance, text);\n    }\n  }\n}\nfunction errorHydratingContainer(parentContainer) {\n  {\n    // TODO: This gets logged by onRecoverableError, too, so we should be\n    // able to remove it.\n    error('An error occurred during hydration. The server HTML was replaced with client content in <%s>.', parentContainer.nodeName.toLowerCase());\n  }\n}\nfunction preparePortalMount(portalInstance) {\n  listenToAllSupportedEvents(portalInstance);\n}\n\nvar randomKey = Math.random().toString(36).slice(2);\nvar internalInstanceKey = '__reactFiber$' + randomKey;\nvar internalPropsKey = '__reactProps$' + randomKey;\nvar internalContainerInstanceKey = '__reactContainer$' + randomKey;\nvar internalEventHandlersKey = '__reactEvents$' + randomKey;\nvar internalEventHandlerListenersKey = '__reactListeners$' + randomKey;\nvar internalEventHandlesSetKey = '__reactHandles$' + randomKey;\nfunction detachDeletedInstance(node) {\n  // TODO: This function is only called on host components. I don't think all of\n  // these fields are relevant.\n  delete node[internalInstanceKey];\n  delete node[internalPropsKey];\n  delete node[internalEventHandlersKey];\n  delete node[internalEventHandlerListenersKey];\n  delete node[internalEventHandlesSetKey];\n}\nfunction precacheFiberNode(hostInst, node) {\n  node[internalInstanceKey] = hostInst;\n}\nfunction markContainerAsRoot(hostRoot, node) {\n  node[internalContainerInstanceKey] = hostRoot;\n}\nfunction unmarkContainerAsRoot(node) {\n  node[internalContainerInstanceKey] = null;\n}\nfunction isContainerMarkedAsRoot(node) {\n  return !!node[internalContainerInstanceKey];\n} // Given a DOM node, return the closest HostComponent or HostText fiber ancestor.\n// If the target node is part of a hydrated or not yet rendered subtree, then\n// this may also return a SuspenseComponent or HostRoot to indicate that.\n// Conceptually the HostRoot fiber is a child of the Container node. So if you\n// pass the Container node as the targetNode, you will not actually get the\n// HostRoot back. To get to the HostRoot, you need to pass a child of it.\n// The same thing applies to Suspense boundaries.\n\nfunction getClosestInstanceFromNode(targetNode) {\n  var targetInst = targetNode[internalInstanceKey];\n\n  if (targetInst) {\n    // Don't return HostRoot or SuspenseComponent here.\n    return targetInst;\n  } // If the direct event target isn't a React owned DOM node, we need to look\n  // to see if one of its parents is a React owned DOM node.\n\n\n  var parentNode = targetNode.parentNode;\n\n  while (parentNode) {\n    // We'll check if this is a container root that could include\n    // React nodes in the future. We need to check this first because\n    // if we're a child of a dehydrated container, we need to first\n    // find that inner container before moving on to finding the parent\n    // instance. Note that we don't check this field on  the targetNode\n    // itself because the fibers are conceptually between the container\n    // node and the first child. It isn't surrounding the container node.\n    // If it's not a container, we check if it's an instance.\n    targetInst = parentNode[internalContainerInstanceKey] || parentNode[internalInstanceKey];\n\n    if (targetInst) {\n      // Since this wasn't the direct target of the event, we might have\n      // stepped past dehydrated DOM nodes to get here. However they could\n      // also have been non-React nodes. We need to answer which one.\n      // If we the instance doesn't have any children, then there can't be\n      // a nested suspense boundary within it. So we can use this as a fast\n      // bailout. Most of the time, when people add non-React children to\n      // the tree, it is using a ref to a child-less DOM node.\n      // Normally we'd only need to check one of the fibers because if it\n      // has ever gone from having children to deleting them or vice versa\n      // it would have deleted the dehydrated boundary nested inside already.\n      // However, since the HostRoot starts out with an alternate it might\n      // have one on the alternate so we need to check in case this was a\n      // root.\n      var alternate = targetInst.alternate;\n\n      if (targetInst.child !== null || alternate !== null && alternate.child !== null) {\n        // Next we need to figure out if the node that skipped past is\n        // nested within a dehydrated boundary and if so, which one.\n        var suspenseInstance = getParentSuspenseInstance(targetNode);\n\n        while (suspenseInstance !== null) {\n          // We found a suspense instance. That means that we haven't\n          // hydrated it yet. Even though we leave the comments in the\n          // DOM after hydrating, and there are boundaries in the DOM\n          // that could already be hydrated, we wouldn't have found them\n          // through this pass since if the target is hydrated it would\n          // have had an internalInstanceKey on it.\n          // Let's get the fiber associated with the SuspenseComponent\n          // as the deepest instance.\n          var targetSuspenseInst = suspenseInstance[internalInstanceKey];\n\n          if (targetSuspenseInst) {\n            return targetSuspenseInst;\n          } // If we don't find a Fiber on the comment, it might be because\n          // we haven't gotten to hydrate it yet. There might still be a\n          // parent boundary that hasn't above this one so we need to find\n          // the outer most that is known.\n\n\n          suspenseInstance = getParentSuspenseInstance(suspenseInstance); // If we don't find one, then that should mean that the parent\n          // host component also hasn't hydrated yet. We can return it\n          // below since it will bail out on the isMounted check later.\n        }\n      }\n\n      return targetInst;\n    }\n\n    targetNode = parentNode;\n    parentNode = targetNode.parentNode;\n  }\n\n  return null;\n}\n/**\n * Given a DOM node, return the ReactDOMComponent or ReactDOMTextComponent\n * instance, or null if the node was not rendered by this React.\n */\n\nfunction getInstanceFromNode(node) {\n  var inst = node[internalInstanceKey] || node[internalContainerInstanceKey];\n\n  if (inst) {\n    if (inst.tag === HostComponent || inst.tag === HostText || inst.tag === SuspenseComponent || inst.tag === HostRoot) {\n      return inst;\n    } else {\n      return null;\n    }\n  }\n\n  return null;\n}\n/**\n * Given a ReactDOMComponent or ReactDOMTextComponent, return the corresponding\n * DOM node.\n */\n\nfunction getNodeFromInstance(inst) {\n  if (inst.tag === HostComponent || inst.tag === HostText) {\n    // In Fiber this, is just the state node right now. We assume it will be\n    // a host component or host text.\n    return inst.stateNode;\n  } // Without this first invariant, passing a non-DOM-component triggers the next\n  // invariant for a missing parent, which is super confusing.\n\n\n  throw new Error('getNodeFromInstance: Invalid argument.');\n}\nfunction getFiberCurrentPropsFromNode(node) {\n  return node[internalPropsKey] || null;\n}\nfunction updateFiberProps(node, props) {\n  node[internalPropsKey] = props;\n}\nfunction getEventListenerSet(node) {\n  var elementListenerSet = node[internalEventHandlersKey];\n\n  if (elementListenerSet === undefined) {\n    elementListenerSet = node[internalEventHandlersKey] = new Set();\n  }\n\n  return elementListenerSet;\n}\n\nvar loggedTypeFailures = {};\nvar ReactDebugCurrentFrame$1 = ReactSharedInternals.ReactDebugCurrentFrame;\n\nfunction setCurrentlyValidatingElement(element) {\n  {\n    if (element) {\n      var owner = element._owner;\n      var stack = describeUnknownElementTypeFrameInDEV(element.type, element._source, owner ? owner.type : null);\n      ReactDebugCurrentFrame$1.setExtraStackFrame(stack);\n    } else {\n      ReactDebugCurrentFrame$1.setExtraStackFrame(null);\n    }\n  }\n}\n\nfunction checkPropTypes(typeSpecs, values, location, componentName, element) {\n  {\n    // $FlowFixMe This is okay but Flow doesn't know it.\n    var has = Function.call.bind(hasOwnProperty);\n\n    for (var typeSpecName in typeSpecs) {\n      if (has(typeSpecs, typeSpecName)) {\n        var error$1 = void 0; // Prop type validation may throw. In case they do, we don't want to\n        // fail the render phase where it didn't fail before. So we log it.\n        // After these have been cleaned up, we'll let them throw.\n\n        try {\n          // This is intentionally an invariant that gets caught. It's the same\n          // behavior as without this statement except with a better message.\n          if (typeof typeSpecs[typeSpecName] !== 'function') {\n            // eslint-disable-next-line react-internal/prod-error-codes\n            var err = Error((componentName || 'React class') + ': ' + location + ' type `' + typeSpecName + '` is invalid; ' + 'it must be a function, usually from the `prop-types` package, but received `' + typeof typeSpecs[typeSpecName] + '`.' + 'This often happens because of typos such as `PropTypes.function` instead of `PropTypes.func`.');\n            err.name = 'Invariant Violation';\n            throw err;\n          }\n\n          error$1 = typeSpecs[typeSpecName](values, typeSpecName, componentName, location, null, 'SECRET_DO_NOT_PASS_THIS_OR_YOU_WILL_BE_FIRED');\n        } catch (ex) {\n          error$1 = ex;\n        }\n\n        if (error$1 && !(error$1 instanceof Error)) {\n          setCurrentlyValidatingElement(element);\n\n          error('%s: type specification of %s' + ' `%s` is invalid; the type checker ' + 'function must return `null` or an `Error` but returned a %s. ' + 'You may have forgotten to pass an argument to the type checker ' + 'creator (arrayOf, instanceOf, objectOf, oneOf, oneOfType, and ' + 'shape all require an argument).', componentName || 'React class', location, typeSpecName, typeof error$1);\n\n          setCurrentlyValidatingElement(null);\n        }\n\n        if (error$1 instanceof Error && !(error$1.message in loggedTypeFailures)) {\n          // Only monitor this failure once because there tends to be a lot of the\n          // same error.\n          loggedTypeFailures[error$1.message] = true;\n          setCurrentlyValidatingElement(element);\n\n          error('Failed %s type: %s', location, error$1.message);\n\n          setCurrentlyValidatingElement(null);\n        }\n      }\n    }\n  }\n}\n\nvar valueStack = [];\nvar fiberStack;\n\n{\n  fiberStack = [];\n}\n\nvar index = -1;\n\nfunction createCursor(defaultValue) {\n  return {\n    current: defaultValue\n  };\n}\n\nfunction pop(cursor, fiber) {\n  if (index < 0) {\n    {\n      error('Unexpected pop.');\n    }\n\n    return;\n  }\n\n  {\n    if (fiber !== fiberStack[index]) {\n      error('Unexpected Fiber popped.');\n    }\n  }\n\n  cursor.current = valueStack[index];\n  valueStack[index] = null;\n\n  {\n    fiberStack[index] = null;\n  }\n\n  index--;\n}\n\nfunction push(cursor, value, fiber) {\n  index++;\n  valueStack[index] = cursor.current;\n\n  {\n    fiberStack[index] = fiber;\n  }\n\n  cursor.current = value;\n}\n\nvar warnedAboutMissingGetChildContext;\n\n{\n  warnedAboutMissingGetChildContext = {};\n}\n\nvar emptyContextObject = {};\n\n{\n  Object.freeze(emptyContextObject);\n} // A cursor to the current merged context object on the stack.\n\n\nvar contextStackCursor = createCursor(emptyContextObject); // A cursor to a boolean indicating whether the context has changed.\n\nvar didPerformWorkStackCursor = createCursor(false); // Keep track of the previous context object that was on the stack.\n// We use this to get access to the parent context after we have already\n// pushed the next context provider, and now need to merge their contexts.\n\nvar previousContext = emptyContextObject;\n\nfunction getUnmaskedContext(workInProgress, Component, didPushOwnContextIfProvider) {\n  {\n    if (didPushOwnContextIfProvider && isContextProvider(Component)) {\n      // If the fiber is a context provider itself, when we read its context\n      // we may have already pushed its own child context on the stack. A context\n      // provider should not \"see\" its own child context. Therefore we read the\n      // previous (parent) context instead for a context provider.\n      return previousContext;\n    }\n\n    return contextStackCursor.current;\n  }\n}\n\nfunction cacheContext(workInProgress, unmaskedContext, maskedContext) {\n  {\n    var instance = workInProgress.stateNode;\n    instance.__reactInternalMemoizedUnmaskedChildContext = unmaskedContext;\n    instance.__reactInternalMemoizedMaskedChildContext = maskedContext;\n  }\n}\n\nfunction getMaskedContext(workInProgress, unmaskedContext) {\n  {\n    var type = workInProgress.type;\n    var contextTypes = type.contextTypes;\n\n    if (!contextTypes) {\n      return emptyContextObject;\n    } // Avoid recreating masked context unless unmasked context has changed.\n    // Failing to do this will result in unnecessary calls to componentWillReceiveProps.\n    // This may trigger infinite loops if componentWillReceiveProps calls setState.\n\n\n    var instance = workInProgress.stateNode;\n\n    if (instance && instance.__reactInternalMemoizedUnmaskedChildContext === unmaskedContext) {\n      return instance.__reactInternalMemoizedMaskedChildContext;\n    }\n\n    var context = {};\n\n    for (var key in contextTypes) {\n      context[key] = unmaskedContext[key];\n    }\n\n    {\n      var name = getComponentNameFromFiber(workInProgress) || 'Unknown';\n      checkPropTypes(contextTypes, context, 'context', name);\n    } // Cache unmasked context so we can avoid recreating masked context unless necessary.\n    // Context is created before the class component is instantiated so check for instance.\n\n\n    if (instance) {\n      cacheContext(workInProgress, unmaskedContext, context);\n    }\n\n    return context;\n  }\n}\n\nfunction hasContextChanged() {\n  {\n    return didPerformWorkStackCursor.current;\n  }\n}\n\nfunction isContextProvider(type) {\n  {\n    var childContextTypes = type.childContextTypes;\n    return childContextTypes !== null && childContextTypes !== undefined;\n  }\n}\n\nfunction popContext(fiber) {\n  {\n    pop(didPerformWorkStackCursor, fiber);\n    pop(contextStackCursor, fiber);\n  }\n}\n\nfunction popTopLevelContextObject(fiber) {\n  {\n    pop(didPerformWorkStackCursor, fiber);\n    pop(contextStackCursor, fiber);\n  }\n}\n\nfunction pushTopLevelContextObject(fiber, context, didChange) {\n  {\n    if (contextStackCursor.current !== emptyContextObject) {\n      throw new Error('Unexpected context found on stack. ' + 'This error is likely caused by a bug in React. Please file an issue.');\n    }\n\n    push(contextStackCursor, context, fiber);\n    push(didPerformWorkStackCursor, didChange, fiber);\n  }\n}\n\nfunction processChildContext(fiber, type, parentContext) {\n  {\n    var instance = fiber.stateNode;\n    var childContextTypes = type.childContextTypes; // TODO (bvaughn) Replace this behavior with an invariant() in the future.\n    // It has only been added in Fiber to match the (unintentional) behavior in Stack.\n\n    if (typeof instance.getChildContext !== 'function') {\n      {\n        var componentName = getComponentNameFromFiber(fiber) || 'Unknown';\n\n        if (!warnedAboutMissingGetChildContext[componentName]) {\n          warnedAboutMissingGetChildContext[componentName] = true;\n\n          error('%s.childContextTypes is specified but there is no getChildContext() method ' + 'on the instance. You can either define getChildContext() on %s or remove ' + 'childContextTypes from it.', componentName, componentName);\n        }\n      }\n\n      return parentContext;\n    }\n\n    var childContext = instance.getChildContext();\n\n    for (var contextKey in childContext) {\n      if (!(contextKey in childContextTypes)) {\n        throw new Error((getComponentNameFromFiber(fiber) || 'Unknown') + \".getChildContext(): key \\\"\" + contextKey + \"\\\" is not defined in childContextTypes.\");\n      }\n    }\n\n    {\n      var name = getComponentNameFromFiber(fiber) || 'Unknown';\n      checkPropTypes(childContextTypes, childContext, 'child context', name);\n    }\n\n    return assign({}, parentContext, childContext);\n  }\n}\n\nfunction pushContextProvider(workInProgress) {\n  {\n    var instance = workInProgress.stateNode; // We push the context as early as possible to ensure stack integrity.\n    // If the instance does not exist yet, we will push null at first,\n    // and replace it on the stack later when invalidating the context.\n\n    var memoizedMergedChildContext = instance && instance.__reactInternalMemoizedMergedChildContext || emptyContextObject; // Remember the parent context so we can merge with it later.\n    // Inherit the parent's did-perform-work value to avoid inadvertently blocking updates.\n\n    previousContext = contextStackCursor.current;\n    push(contextStackCursor, memoizedMergedChildContext, workInProgress);\n    push(didPerformWorkStackCursor, didPerformWorkStackCursor.current, workInProgress);\n    return true;\n  }\n}\n\nfunction invalidateContextProvider(workInProgress, type, didChange) {\n  {\n    var instance = workInProgress.stateNode;\n\n    if (!instance) {\n      throw new Error('Expected to have an instance by this point. ' + 'This error is likely caused by a bug in React. Please file an issue.');\n    }\n\n    if (didChange) {\n      // Merge parent and own context.\n      // Skip this if we're not updating due to sCU.\n      // This avoids unnecessarily recomputing memoized values.\n      var mergedContext = processChildContext(workInProgress, type, previousContext);\n      instance.__reactInternalMemoizedMergedChildContext = mergedContext; // Replace the old (or empty) context with the new one.\n      // It is important to unwind the context in the reverse order.\n\n      pop(didPerformWorkStackCursor, workInProgress);\n      pop(contextStackCursor, workInProgress); // Now push the new context and mark that it has changed.\n\n      push(contextStackCursor, mergedContext, workInProgress);\n      push(didPerformWorkStackCursor, didChange, workInProgress);\n    } else {\n      pop(didPerformWorkStackCursor, workInProgress);\n      push(didPerformWorkStackCursor, didChange, workInProgress);\n    }\n  }\n}\n\nfunction findCurrentUnmaskedContext(fiber) {\n  {\n    // Currently this is only used with renderSubtreeIntoContainer; not sure if it\n    // makes sense elsewhere\n    if (!isFiberMounted(fiber) || fiber.tag !== ClassComponent) {\n      throw new Error('Expected subtree parent to be a mounted class component. ' + 'This error is likely caused by a bug in React. Please file an issue.');\n    }\n\n    var node = fiber;\n\n    do {\n      switch (node.tag) {\n        case HostRoot:\n          return node.stateNode.context;\n\n        case ClassComponent:\n          {\n            var Component = node.type;\n\n            if (isContextProvider(Component)) {\n              return node.stateNode.__reactInternalMemoizedMergedChildContext;\n            }\n\n            break;\n          }\n      }\n\n      node = node.return;\n    } while (node !== null);\n\n    throw new Error('Found unexpected detached subtree parent. ' + 'This error is likely caused by a bug in React. Please file an issue.');\n  }\n}\n\nvar LegacyRoot = 0;\nvar ConcurrentRoot = 1;\n\nvar syncQueue = null;\nvar includesLegacySyncCallbacks = false;\nvar isFlushingSyncQueue = false;\nfunction scheduleSyncCallback(callback) {\n  // Push this callback into an internal queue. We'll flush these either in\n  // the next tick, or earlier if something calls `flushSyncCallbackQueue`.\n  if (syncQueue === null) {\n    syncQueue = [callback];\n  } else {\n    // Push onto existing queue. Don't need to schedule a callback because\n    // we already scheduled one when we created the queue.\n    syncQueue.push(callback);\n  }\n}\nfunction scheduleLegacySyncCallback(callback) {\n  includesLegacySyncCallbacks = true;\n  scheduleSyncCallback(callback);\n}\nfunction flushSyncCallbacksOnlyInLegacyMode() {\n  // Only flushes the queue if there's a legacy sync callback scheduled.\n  // TODO: There's only a single type of callback: performSyncOnWorkOnRoot. So\n  // it might make more sense for the queue to be a list of roots instead of a\n  // list of generic callbacks. Then we can have two: one for legacy roots, one\n  // for concurrent roots. And this method would only flush the legacy ones.\n  if (includesLegacySyncCallbacks) {\n    flushSyncCallbacks();\n  }\n}\nfunction flushSyncCallbacks() {\n  if (!isFlushingSyncQueue && syncQueue !== null) {\n    // Prevent re-entrance.\n    isFlushingSyncQueue = true;\n    var i = 0;\n    var previousUpdatePriority = getCurrentUpdatePriority();\n\n    try {\n      var isSync = true;\n      var queue = syncQueue; // TODO: Is this necessary anymore? The only user code that runs in this\n      // queue is in the render or commit phases.\n\n      setCurrentUpdatePriority(DiscreteEventPriority);\n\n      for (; i < queue.length; i++) {\n        var callback = queue[i];\n\n        do {\n          callback = callback(isSync);\n        } while (callback !== null);\n      }\n\n      syncQueue = null;\n      includesLegacySyncCallbacks = false;\n    } catch (error) {\n      // If something throws, leave the remaining callbacks on the queue.\n      if (syncQueue !== null) {\n        syncQueue = syncQueue.slice(i + 1);\n      } // Resume flushing in the next tick\n\n\n      scheduleCallback(ImmediatePriority, flushSyncCallbacks);\n      throw error;\n    } finally {\n      setCurrentUpdatePriority(previousUpdatePriority);\n      isFlushingSyncQueue = false;\n    }\n  }\n\n  return null;\n}\n\n// TODO: Use the unified fiber stack module instead of this local one?\n// Intentionally not using it yet to derisk the initial implementation, because\n// the way we push/pop these values is a bit unusual. If there's a mistake, I'd\n// rather the ids be wrong than crash the whole reconciler.\nvar forkStack = [];\nvar forkStackIndex = 0;\nvar treeForkProvider = null;\nvar treeForkCount = 0;\nvar idStack = [];\nvar idStackIndex = 0;\nvar treeContextProvider = null;\nvar treeContextId = 1;\nvar treeContextOverflow = '';\nfunction isForkedChild(workInProgress) {\n  warnIfNotHydrating();\n  return (workInProgress.flags & Forked) !== NoFlags;\n}\nfunction getForksAtLevel(workInProgress) {\n  warnIfNotHydrating();\n  return treeForkCount;\n}\nfunction getTreeId() {\n  var overflow = treeContextOverflow;\n  var idWithLeadingBit = treeContextId;\n  var id = idWithLeadingBit & ~getLeadingBit(idWithLeadingBit);\n  return id.toString(32) + overflow;\n}\nfunction pushTreeFork(workInProgress, totalChildren) {\n  // This is called right after we reconcile an array (or iterator) of child\n  // fibers, because that's the only place where we know how many children in\n  // the whole set without doing extra work later, or storing addtional\n  // information on the fiber.\n  //\n  // That's why this function is separate from pushTreeId  it's called during\n  // the render phase of the fork parent, not the child, which is where we push\n  // the other context values.\n  //\n  // In the Fizz implementation this is much simpler because the child is\n  // rendered in the same callstack as the parent.\n  //\n  // It might be better to just add a `forks` field to the Fiber type. It would\n  // make this module simpler.\n  warnIfNotHydrating();\n  forkStack[forkStackIndex++] = treeForkCount;\n  forkStack[forkStackIndex++] = treeForkProvider;\n  treeForkProvider = workInProgress;\n  treeForkCount = totalChildren;\n}\nfunction pushTreeId(workInProgress, totalChildren, index) {\n  warnIfNotHydrating();\n  idStack[idStackIndex++] = treeContextId;\n  idStack[idStackIndex++] = treeContextOverflow;\n  idStack[idStackIndex++] = treeContextProvider;\n  treeContextProvider = workInProgress;\n  var baseIdWithLeadingBit = treeContextId;\n  var baseOverflow = treeContextOverflow; // The leftmost 1 marks the end of the sequence, non-inclusive. It's not part\n  // of the id; we use it to account for leading 0s.\n\n  var baseLength = getBitLength(baseIdWithLeadingBit) - 1;\n  var baseId = baseIdWithLeadingBit & ~(1 << baseLength);\n  var slot = index + 1;\n  var length = getBitLength(totalChildren) + baseLength; // 30 is the max length we can store without overflowing, taking into\n  // consideration the leading 1 we use to mark the end of the sequence.\n\n  if (length > 30) {\n    // We overflowed the bitwise-safe range. Fall back to slower algorithm.\n    // This branch assumes the length of the base id is greater than 5; it won't\n    // work for smaller ids, because you need 5 bits per character.\n    //\n    // We encode the id in multiple steps: first the base id, then the\n    // remaining digits.\n    //\n    // Each 5 bit sequence corresponds to a single base 32 character. So for\n    // example, if the current id is 23 bits long, we can convert 20 of those\n    // bits into a string of 4 characters, with 3 bits left over.\n    //\n    // First calculate how many bits in the base id represent a complete\n    // sequence of characters.\n    var numberOfOverflowBits = baseLength - baseLength % 5; // Then create a bitmask that selects only those bits.\n\n    var newOverflowBits = (1 << numberOfOverflowBits) - 1; // Select the bits, and convert them to a base 32 string.\n\n    var newOverflow = (baseId & newOverflowBits).toString(32); // Now we can remove those bits from the base id.\n\n    var restOfBaseId = baseId >> numberOfOverflowBits;\n    var restOfBaseLength = baseLength - numberOfOverflowBits; // Finally, encode the rest of the bits using the normal algorithm. Because\n    // we made more room, this time it won't overflow.\n\n    var restOfLength = getBitLength(totalChildren) + restOfBaseLength;\n    var restOfNewBits = slot << restOfBaseLength;\n    var id = restOfNewBits | restOfBaseId;\n    var overflow = newOverflow + baseOverflow;\n    treeContextId = 1 << restOfLength | id;\n    treeContextOverflow = overflow;\n  } else {\n    // Normal path\n    var newBits = slot << baseLength;\n\n    var _id = newBits | baseId;\n\n    var _overflow = baseOverflow;\n    treeContextId = 1 << length | _id;\n    treeContextOverflow = _overflow;\n  }\n}\nfunction pushMaterializedTreeId(workInProgress) {\n  warnIfNotHydrating(); // This component materialized an id. This will affect any ids that appear\n  // in its children.\n\n  var returnFiber = workInProgress.return;\n\n  if (returnFiber !== null) {\n    var numberOfForks = 1;\n    var slotIndex = 0;\n    pushTreeFork(workInProgress, numberOfForks);\n    pushTreeId(workInProgress, numberOfForks, slotIndex);\n  }\n}\n\nfunction getBitLength(number) {\n  return 32 - clz32(number);\n}\n\nfunction getLeadingBit(id) {\n  return 1 << getBitLength(id) - 1;\n}\n\nfunction popTreeContext(workInProgress) {\n  // Restore the previous values.\n  // This is a bit more complicated than other context-like modules in Fiber\n  // because the same Fiber may appear on the stack multiple times and for\n  // different reasons. We have to keep popping until the work-in-progress is\n  // no longer at the top of the stack.\n  while (workInProgress === treeForkProvider) {\n    treeForkProvider = forkStack[--forkStackIndex];\n    forkStack[forkStackIndex] = null;\n    treeForkCount = forkStack[--forkStackIndex];\n    forkStack[forkStackIndex] = null;\n  }\n\n  while (workInProgress === treeContextProvider) {\n    treeContextProvider = idStack[--idStackIndex];\n    idStack[idStackIndex] = null;\n    treeContextOverflow = idStack[--idStackIndex];\n    idStack[idStackIndex] = null;\n    treeContextId = idStack[--idStackIndex];\n    idStack[idStackIndex] = null;\n  }\n}\nfunction getSuspendedTreeContext() {\n  warnIfNotHydrating();\n\n  if (treeContextProvider !== null) {\n    return {\n      id: treeContextId,\n      overflow: treeContextOverflow\n    };\n  } else {\n    return null;\n  }\n}\nfunction restoreSuspendedTreeContext(workInProgress, suspendedContext) {\n  warnIfNotHydrating();\n  idStack[idStackIndex++] = treeContextId;\n  idStack[idStackIndex++] = treeContextOverflow;\n  idStack[idStackIndex++] = treeContextProvider;\n  treeContextId = suspendedContext.id;\n  treeContextOverflow = suspendedContext.overflow;\n  treeContextProvider = workInProgress;\n}\n\nfunction warnIfNotHydrating() {\n  {\n    if (!getIsHydrating()) {\n      error('Expected to be hydrating. This is a bug in React. Please file ' + 'an issue.');\n    }\n  }\n}\n\n// This may have been an insertion or a hydration.\n\nvar hydrationParentFiber = null;\nvar nextHydratableInstance = null;\nvar isHydrating = false; // This flag allows for warning supression when we expect there to be mismatches\n// due to earlier mismatches or a suspended fiber.\n\nvar didSuspendOrErrorDEV = false; // Hydration errors that were thrown inside this boundary\n\nvar hydrationErrors = null;\n\nfunction warnIfHydrating() {\n  {\n    if (isHydrating) {\n      error('We should not be hydrating here. This is a bug in React. Please file a bug.');\n    }\n  }\n}\n\nfunction markDidThrowWhileHydratingDEV() {\n  {\n    didSuspendOrErrorDEV = true;\n  }\n}\nfunction didSuspendOrErrorWhileHydratingDEV() {\n  {\n    return didSuspendOrErrorDEV;\n  }\n}\n\nfunction enterHydrationState(fiber) {\n\n  var parentInstance = fiber.stateNode.containerInfo;\n  nextHydratableInstance = getFirstHydratableChildWithinContainer(parentInstance);\n  hydrationParentFiber = fiber;\n  isHydrating = true;\n  hydrationErrors = null;\n  didSuspendOrErrorDEV = false;\n  return true;\n}\n\nfunction reenterHydrationStateFromDehydratedSuspenseInstance(fiber, suspenseInstance, treeContext) {\n\n  nextHydratableInstance = getFirstHydratableChildWithinSuspenseInstance(suspenseInstance);\n  hydrationParentFiber = fiber;\n  isHydrating = true;\n  hydrationErrors = null;\n  didSuspendOrErrorDEV = false;\n\n  if (treeContext !== null) {\n    restoreSuspendedTreeContext(fiber, treeContext);\n  }\n\n  return true;\n}\n\nfunction warnUnhydratedInstance(returnFiber, instance) {\n  {\n    switch (returnFiber.tag) {\n      case HostRoot:\n        {\n          didNotHydrateInstanceWithinContainer(returnFiber.stateNode.containerInfo, instance);\n          break;\n        }\n\n      case HostComponent:\n        {\n          var isConcurrentMode = (returnFiber.mode & ConcurrentMode) !== NoMode;\n          didNotHydrateInstance(returnFiber.type, returnFiber.memoizedProps, returnFiber.stateNode, instance, // TODO: Delete this argument when we remove the legacy root API.\n          isConcurrentMode);\n          break;\n        }\n\n      case SuspenseComponent:\n        {\n          var suspenseState = returnFiber.memoizedState;\n          if (suspenseState.dehydrated !== null) didNotHydrateInstanceWithinSuspenseInstance(suspenseState.dehydrated, instance);\n          break;\n        }\n    }\n  }\n}\n\nfunction deleteHydratableInstance(returnFiber, instance) {\n  warnUnhydratedInstance(returnFiber, instance);\n  var childToDelete = createFiberFromHostInstanceForDeletion();\n  childToDelete.stateNode = instance;\n  childToDelete.return = returnFiber;\n  var deletions = returnFiber.deletions;\n\n  if (deletions === null) {\n    returnFiber.deletions = [childToDelete];\n    returnFiber.flags |= ChildDeletion;\n  } else {\n    deletions.push(childToDelete);\n  }\n}\n\nfunction warnNonhydratedInstance(returnFiber, fiber) {\n  {\n    if (didSuspendOrErrorDEV) {\n      // Inside a boundary that already suspended. We're currently rendering the\n      // siblings of a suspended node. The mismatch may be due to the missing\n      // data, so it's probably a false positive.\n      return;\n    }\n\n    switch (returnFiber.tag) {\n      case HostRoot:\n        {\n          var parentContainer = returnFiber.stateNode.containerInfo;\n\n          switch (fiber.tag) {\n            case HostComponent:\n              var type = fiber.type;\n              var props = fiber.pendingProps;\n              didNotFindHydratableInstanceWithinContainer(parentContainer, type);\n              break;\n\n            case HostText:\n              var text = fiber.pendingProps;\n              didNotFindHydratableTextInstanceWithinContainer(parentContainer, text);\n              break;\n          }\n\n          break;\n        }\n\n      case HostComponent:\n        {\n          var parentType = returnFiber.type;\n          var parentProps = returnFiber.memoizedProps;\n          var parentInstance = returnFiber.stateNode;\n\n          switch (fiber.tag) {\n            case HostComponent:\n              {\n                var _type = fiber.type;\n                var _props = fiber.pendingProps;\n                var isConcurrentMode = (returnFiber.mode & ConcurrentMode) !== NoMode;\n                didNotFindHydratableInstance(parentType, parentProps, parentInstance, _type, _props, // TODO: Delete this argument when we remove the legacy root API.\n                isConcurrentMode);\n                break;\n              }\n\n            case HostText:\n              {\n                var _text = fiber.pendingProps;\n\n                var _isConcurrentMode = (returnFiber.mode & ConcurrentMode) !== NoMode;\n\n                didNotFindHydratableTextInstance(parentType, parentProps, parentInstance, _text, // TODO: Delete this argument when we remove the legacy root API.\n                _isConcurrentMode);\n                break;\n              }\n          }\n\n          break;\n        }\n\n      case SuspenseComponent:\n        {\n          var suspenseState = returnFiber.memoizedState;\n          var _parentInstance = suspenseState.dehydrated;\n          if (_parentInstance !== null) switch (fiber.tag) {\n            case HostComponent:\n              var _type2 = fiber.type;\n              var _props2 = fiber.pendingProps;\n              didNotFindHydratableInstanceWithinSuspenseInstance(_parentInstance, _type2);\n              break;\n\n            case HostText:\n              var _text2 = fiber.pendingProps;\n              didNotFindHydratableTextInstanceWithinSuspenseInstance(_parentInstance, _text2);\n              break;\n          }\n          break;\n        }\n\n      default:\n        return;\n    }\n  }\n}\n\nfunction insertNonHydratedInstance(returnFiber, fiber) {\n  fiber.flags = fiber.flags & ~Hydrating | Placement;\n  warnNonhydratedInstance(returnFiber, fiber);\n}\n\nfunction tryHydrate(fiber, nextInstance) {\n  switch (fiber.tag) {\n    case HostComponent:\n      {\n        var type = fiber.type;\n        var props = fiber.pendingProps;\n        var instance = canHydrateInstance(nextInstance, type);\n\n        if (instance !== null) {\n          fiber.stateNode = instance;\n          hydrationParentFiber = fiber;\n          nextHydratableInstance = getFirstHydratableChild(instance);\n          return true;\n        }\n\n        return false;\n      }\n\n    case HostText:\n      {\n        var text = fiber.pendingProps;\n        var textInstance = canHydrateTextInstance(nextInstance, text);\n\n        if (textInstance !== null) {\n          fiber.stateNode = textInstance;\n          hydrationParentFiber = fiber; // Text Instances don't have children so there's nothing to hydrate.\n\n          nextHydratableInstance = null;\n          return true;\n        }\n\n        return false;\n      }\n\n    case SuspenseComponent:\n      {\n        var suspenseInstance = canHydrateSuspenseInstance(nextInstance);\n\n        if (suspenseInstance !== null) {\n          var suspenseState = {\n            dehydrated: suspenseInstance,\n            treeContext: getSuspendedTreeContext(),\n            retryLane: OffscreenLane\n          };\n          fiber.memoizedState = suspenseState; // Store the dehydrated fragment as a child fiber.\n          // This simplifies the code for getHostSibling and deleting nodes,\n          // since it doesn't have to consider all Suspense boundaries and\n          // check if they're dehydrated ones or not.\n\n          var dehydratedFragment = createFiberFromDehydratedFragment(suspenseInstance);\n          dehydratedFragment.return = fiber;\n          fiber.child = dehydratedFragment;\n          hydrationParentFiber = fiber; // While a Suspense Instance does have children, we won't step into\n          // it during the first pass. Instead, we'll reenter it later.\n\n          nextHydratableInstance = null;\n          return true;\n        }\n\n        return false;\n      }\n\n    default:\n      return false;\n  }\n}\n\nfunction shouldClientRenderOnMismatch(fiber) {\n  return (fiber.mode & ConcurrentMode) !== NoMode && (fiber.flags & DidCapture) === NoFlags;\n}\n\nfunction throwOnHydrationMismatch(fiber) {\n  throw new Error('Hydration failed because the initial UI does not match what was ' + 'rendered on the server.');\n}\n\nfunction tryToClaimNextHydratableInstance(fiber) {\n  if (!isHydrating) {\n    return;\n  }\n\n  var nextInstance = nextHydratableInstance;\n\n  if (!nextInstance) {\n    if (shouldClientRenderOnMismatch(fiber)) {\n      warnNonhydratedInstance(hydrationParentFiber, fiber);\n      throwOnHydrationMismatch();\n    } // Nothing to hydrate. Make it an insertion.\n\n\n    insertNonHydratedInstance(hydrationParentFiber, fiber);\n    isHydrating = false;\n    hydrationParentFiber = fiber;\n    return;\n  }\n\n  var firstAttemptedInstance = nextInstance;\n\n  if (!tryHydrate(fiber, nextInstance)) {\n    if (shouldClientRenderOnMismatch(fiber)) {\n      warnNonhydratedInstance(hydrationParentFiber, fiber);\n      throwOnHydrationMismatch();\n    } // If we can't hydrate this instance let's try the next one.\n    // We use this as a heuristic. It's based on intuition and not data so it\n    // might be flawed or unnecessary.\n\n\n    nextInstance = getNextHydratableSibling(firstAttemptedInstance);\n    var prevHydrationParentFiber = hydrationParentFiber;\n\n    if (!nextInstance || !tryHydrate(fiber, nextInstance)) {\n      // Nothing to hydrate. Make it an insertion.\n      insertNonHydratedInstance(hydrationParentFiber, fiber);\n      isHydrating = false;\n      hydrationParentFiber = fiber;\n      return;\n    } // We matched the next one, we'll now assume that the first one was\n    // superfluous and we'll delete it. Since we can't eagerly delete it\n    // we'll have to schedule a deletion. To do that, this node needs a dummy\n    // fiber associated with it.\n\n\n    deleteHydratableInstance(prevHydrationParentFiber, firstAttemptedInstance);\n  }\n}\n\nfunction prepareToHydrateHostInstance(fiber, rootContainerInstance, hostContext) {\n\n  var instance = fiber.stateNode;\n  var shouldWarnIfMismatchDev = !didSuspendOrErrorDEV;\n  var updatePayload = hydrateInstance(instance, fiber.type, fiber.memoizedProps, rootContainerInstance, hostContext, fiber, shouldWarnIfMismatchDev); // TODO: Type this specific to this type of component.\n\n  fiber.updateQueue = updatePayload; // If the update payload indicates that there is a change or if there\n  // is a new ref we mark this as an update.\n\n  if (updatePayload !== null) {\n    return true;\n  }\n\n  return false;\n}\n\nfunction prepareToHydrateHostTextInstance(fiber) {\n\n  var textInstance = fiber.stateNode;\n  var textContent = fiber.memoizedProps;\n  var shouldUpdate = hydrateTextInstance(textInstance, textContent, fiber);\n\n  if (shouldUpdate) {\n    // We assume that prepareToHydrateHostTextInstance is called in a context where the\n    // hydration parent is the parent host component of this host text.\n    var returnFiber = hydrationParentFiber;\n\n    if (returnFiber !== null) {\n      switch (returnFiber.tag) {\n        case HostRoot:\n          {\n            var parentContainer = returnFiber.stateNode.containerInfo;\n            var isConcurrentMode = (returnFiber.mode & ConcurrentMode) !== NoMode;\n            didNotMatchHydratedContainerTextInstance(parentContainer, textInstance, textContent, // TODO: Delete this argument when we remove the legacy root API.\n            isConcurrentMode);\n            break;\n          }\n\n        case HostComponent:\n          {\n            var parentType = returnFiber.type;\n            var parentProps = returnFiber.memoizedProps;\n            var parentInstance = returnFiber.stateNode;\n\n            var _isConcurrentMode2 = (returnFiber.mode & ConcurrentMode) !== NoMode;\n\n            didNotMatchHydratedTextInstance(parentType, parentProps, parentInstance, textInstance, textContent, // TODO: Delete this argument when we remove the legacy root API.\n            _isConcurrentMode2);\n            break;\n          }\n      }\n    }\n  }\n\n  return shouldUpdate;\n}\n\nfunction prepareToHydrateHostSuspenseInstance(fiber) {\n\n  var suspenseState = fiber.memoizedState;\n  var suspenseInstance = suspenseState !== null ? suspenseState.dehydrated : null;\n\n  if (!suspenseInstance) {\n    throw new Error('Expected to have a hydrated suspense instance. ' + 'This error is likely caused by a bug in React. Please file an issue.');\n  }\n\n  hydrateSuspenseInstance(suspenseInstance, fiber);\n}\n\nfunction skipPastDehydratedSuspenseInstance(fiber) {\n\n  var suspenseState = fiber.memoizedState;\n  var suspenseInstance = suspenseState !== null ? suspenseState.dehydrated : null;\n\n  if (!suspenseInstance) {\n    throw new Error('Expected to have a hydrated suspense instance. ' + 'This error is likely caused by a bug in React. Please file an issue.');\n  }\n\n  return getNextHydratableInstanceAfterSuspenseInstance(suspenseInstance);\n}\n\nfunction popToNextHostParent(fiber) {\n  var parent = fiber.return;\n\n  while (parent !== null && parent.tag !== HostComponent && parent.tag !== HostRoot && parent.tag !== SuspenseComponent) {\n    parent = parent.return;\n  }\n\n  hydrationParentFiber = parent;\n}\n\nfunction popHydrationState(fiber) {\n\n  if (fiber !== hydrationParentFiber) {\n    // We're deeper than the current hydration context, inside an inserted\n    // tree.\n    return false;\n  }\n\n  if (!isHydrating) {\n    // If we're not currently hydrating but we're in a hydration context, then\n    // we were an insertion and now need to pop up reenter hydration of our\n    // siblings.\n    popToNextHostParent(fiber);\n    isHydrating = true;\n    return false;\n  } // If we have any remaining hydratable nodes, we need to delete them now.\n  // We only do this deeper than head and body since they tend to have random\n  // other nodes in them. We also ignore components with pure text content in\n  // side of them. We also don't delete anything inside the root container.\n\n\n  if (fiber.tag !== HostRoot && (fiber.tag !== HostComponent || shouldDeleteUnhydratedTailInstances(fiber.type) && !shouldSetTextContent(fiber.type, fiber.memoizedProps))) {\n    var nextInstance = nextHydratableInstance;\n\n    if (nextInstance) {\n      if (shouldClientRenderOnMismatch(fiber)) {\n        warnIfUnhydratedTailNodes(fiber);\n        throwOnHydrationMismatch();\n      } else {\n        while (nextInstance) {\n          deleteHydratableInstance(fiber, nextInstance);\n          nextInstance = getNextHydratableSibling(nextInstance);\n        }\n      }\n    }\n  }\n\n  popToNextHostParent(fiber);\n\n  if (fiber.tag === SuspenseComponent) {\n    nextHydratableInstance = skipPastDehydratedSuspenseInstance(fiber);\n  } else {\n    nextHydratableInstance = hydrationParentFiber ? getNextHydratableSibling(fiber.stateNode) : null;\n  }\n\n  return true;\n}\n\nfunction hasUnhydratedTailNodes() {\n  return isHydrating && nextHydratableInstance !== null;\n}\n\nfunction warnIfUnhydratedTailNodes(fiber) {\n  var nextInstance = nextHydratableInstance;\n\n  while (nextInstance) {\n    warnUnhydratedInstance(fiber, nextInstance);\n    nextInstance = getNextHydratableSibling(nextInstance);\n  }\n}\n\nfunction resetHydrationState() {\n\n  hydrationParentFiber = null;\n  nextHydratableInstance = null;\n  isHydrating = false;\n  didSuspendOrErrorDEV = false;\n}\n\nfunction upgradeHydrationErrorsToRecoverable() {\n  if (hydrationErrors !== null) {\n    // Successfully completed a forced client render. The errors that occurred\n    // during the hydration attempt are now recovered. We will log them in\n    // commit phase, once the entire tree has finished.\n    queueRecoverableErrors(hydrationErrors);\n    hydrationErrors = null;\n  }\n}\n\nfunction getIsHydrating() {\n  return isHydrating;\n}\n\nfunction queueHydrationError(error) {\n  if (hydrationErrors === null) {\n    hydrationErrors = [error];\n  } else {\n    hydrationErrors.push(error);\n  }\n}\n\nvar ReactCurrentBatchConfig$1 = ReactSharedInternals.ReactCurrentBatchConfig;\nvar NoTransition = null;\nfunction requestCurrentTransition() {\n  return ReactCurrentBatchConfig$1.transition;\n}\n\nvar ReactStrictModeWarnings = {\n  recordUnsafeLifecycleWarnings: function (fiber, instance) {},\n  flushPendingUnsafeLifecycleWarnings: function () {},\n  recordLegacyContextWarning: function (fiber, instance) {},\n  flushLegacyContextWarning: function () {},\n  discardPendingWarnings: function () {}\n};\n\n{\n  var findStrictRoot = function (fiber) {\n    var maybeStrictRoot = null;\n    var node = fiber;\n\n    while (node !== null) {\n      if (node.mode & StrictLegacyMode) {\n        maybeStrictRoot = node;\n      }\n\n      node = node.return;\n    }\n\n    return maybeStrictRoot;\n  };\n\n  var setToSortedString = function (set) {\n    var array = [];\n    set.forEach(function (value) {\n      array.push(value);\n    });\n    return array.sort().join(', ');\n  };\n\n  var pendingComponentWillMountWarnings = [];\n  var pendingUNSAFE_ComponentWillMountWarnings = [];\n  var pendingComponentWillReceivePropsWarnings = [];\n  var pendingUNSAFE_ComponentWillReceivePropsWarnings = [];\n  var pendingComponentWillUpdateWarnings = [];\n  var pendingUNSAFE_ComponentWillUpdateWarnings = []; // Tracks components we have already warned about.\n\n  var didWarnAboutUnsafeLifecycles = new Set();\n\n  ReactStrictModeWarnings.recordUnsafeLifecycleWarnings = function (fiber, instance) {\n    // Dedupe strategy: Warn once per component.\n    if (didWarnAboutUnsafeLifecycles.has(fiber.type)) {\n      return;\n    }\n\n    if (typeof instance.componentWillMount === 'function' && // Don't warn about react-lifecycles-compat polyfilled components.\n    instance.componentWillMount.__suppressDeprecationWarning !== true) {\n      pendingComponentWillMountWarnings.push(fiber);\n    }\n\n    if (fiber.mode & StrictLegacyMode && typeof instance.UNSAFE_componentWillMount === 'function') {\n      pendingUNSAFE_ComponentWillMountWarnings.push(fiber);\n    }\n\n    if (typeof instance.componentWillReceiveProps === 'function' && instance.componentWillReceiveProps.__suppressDeprecationWarning !== true) {\n      pendingComponentWillReceivePropsWarnings.push(fiber);\n    }\n\n    if (fiber.mode & StrictLegacyMode && typeof instance.UNSAFE_componentWillReceiveProps === 'function') {\n      pendingUNSAFE_ComponentWillReceivePropsWarnings.push(fiber);\n    }\n\n    if (typeof instance.componentWillUpdate === 'function' && instance.componentWillUpdate.__suppressDeprecationWarning !== true) {\n      pendingComponentWillUpdateWarnings.push(fiber);\n    }\n\n    if (fiber.mode & StrictLegacyMode && typeof instance.UNSAFE_componentWillUpdate === 'function') {\n      pendingUNSAFE_ComponentWillUpdateWarnings.push(fiber);\n    }\n  };\n\n  ReactStrictModeWarnings.flushPendingUnsafeLifecycleWarnings = function () {\n    // We do an initial pass to gather component names\n    var componentWillMountUniqueNames = new Set();\n\n    if (pendingComponentWillMountWarnings.length > 0) {\n      pendingComponentWillMountWarnings.forEach(function (fiber) {\n        componentWillMountUniqueNames.add(getComponentNameFromFiber(fiber) || 'Component');\n        didWarnAboutUnsafeLifecycles.add(fiber.type);\n      });\n      pendingComponentWillMountWarnings = [];\n    }\n\n    var UNSAFE_componentWillMountUniqueNames = new Set();\n\n    if (pendingUNSAFE_ComponentWillMountWarnings.length > 0) {\n      pendingUNSAFE_ComponentWillMountWarnings.forEach(function (fiber) {\n        UNSAFE_componentWillMountUniqueNames.add(getComponentNameFromFiber(fiber) || 'Component');\n        didWarnAboutUnsafeLifecycles.add(fiber.type);\n      });\n      pendingUNSAFE_ComponentWillMountWarnings = [];\n    }\n\n    var componentWillReceivePropsUniqueNames = new Set();\n\n    if (pendingComponentWillReceivePropsWarnings.length > 0) {\n      pendingComponentWillReceivePropsWarnings.forEach(function (fiber) {\n        componentWillReceivePropsUniqueNames.add(getComponentNameFromFiber(fiber) || 'Component');\n        didWarnAboutUnsafeLifecycles.add(fiber.type);\n      });\n      pendingComponentWillReceivePropsWarnings = [];\n    }\n\n    var UNSAFE_componentWillReceivePropsUniqueNames = new Set();\n\n    if (pendingUNSAFE_ComponentWillReceivePropsWarnings.length > 0) {\n      pendingUNSAFE_ComponentWillReceivePropsWarnings.forEach(function (fiber) {\n        UNSAFE_componentWillReceivePropsUniqueNames.add(getComponentNameFromFiber(fiber) || 'Component');\n        didWarnAboutUnsafeLifecycles.add(fiber.type);\n      });\n      pendingUNSAFE_ComponentWillReceivePropsWarnings = [];\n    }\n\n    var componentWillUpdateUniqueNames = new Set();\n\n    if (pendingComponentWillUpdateWarnings.length > 0) {\n      pendingComponentWillUpdateWarnings.forEach(function (fiber) {\n        componentWillUpdateUniqueNames.add(getComponentNameFromFiber(fiber) || 'Component');\n        didWarnAboutUnsafeLifecycles.add(fiber.type);\n      });\n      pendingComponentWillUpdateWarnings = [];\n    }\n\n    var UNSAFE_componentWillUpdateUniqueNames = new Set();\n\n    if (pendingUNSAFE_ComponentWillUpdateWarnings.length > 0) {\n      pendingUNSAFE_ComponentWillUpdateWarnings.forEach(function (fiber) {\n        UNSAFE_componentWillUpdateUniqueNames.add(getComponentNameFromFiber(fiber) || 'Component');\n        didWarnAboutUnsafeLifecycles.add(fiber.type);\n      });\n      pendingUNSAFE_ComponentWillUpdateWarnings = [];\n    } // Finally, we flush all the warnings\n    // UNSAFE_ ones before the deprecated ones, since they'll be 'louder'\n\n\n    if (UNSAFE_componentWillMountUniqueNames.size > 0) {\n      var sortedNames = setToSortedString(UNSAFE_componentWillMountUniqueNames);\n\n      error('Using UNSAFE_componentWillMount in strict mode is not recommended and may indicate bugs in your code. ' + 'See https://reactjs.org/link/unsafe-component-lifecycles for details.\\n\\n' + '* Move code with side effects to componentDidMount, and set initial state in the constructor.\\n' + '\\nPlease update the following components: %s', sortedNames);\n    }\n\n    if (UNSAFE_componentWillReceivePropsUniqueNames.size > 0) {\n      var _sortedNames = setToSortedString(UNSAFE_componentWillReceivePropsUniqueNames);\n\n      error('Using UNSAFE_componentWillReceiveProps in strict mode is not recommended ' + 'and may indicate bugs in your code. ' + 'See https://reactjs.org/link/unsafe-component-lifecycles for details.\\n\\n' + '* Move data fetching code or side effects to componentDidUpdate.\\n' + \"* If you're updating state whenever props change, \" + 'refactor your code to use memoization techniques or move it to ' + 'static getDerivedStateFromProps. Learn more at: https://reactjs.org/link/derived-state\\n' + '\\nPlease update the following components: %s', _sortedNames);\n    }\n\n    if (UNSAFE_componentWillUpdateUniqueNames.size > 0) {\n      var _sortedNames2 = setToSortedString(UNSAFE_componentWillUpdateUniqueNames);\n\n      error('Using UNSAFE_componentWillUpdate in strict mode is not recommended ' + 'and may indicate bugs in your code. ' + 'See https://reactjs.org/link/unsafe-component-lifecycles for details.\\n\\n' + '* Move data fetching code or side effects to componentDidUpdate.\\n' + '\\nPlease update the following components: %s', _sortedNames2);\n    }\n\n    if (componentWillMountUniqueNames.size > 0) {\n      var _sortedNames3 = setToSortedString(componentWillMountUniqueNames);\n\n      warn('componentWillMount has been renamed, and is not recommended for use. ' + 'See https://reactjs.org/link/unsafe-component-lifecycles for details.\\n\\n' + '* Move code with side effects to componentDidMount, and set initial state in the constructor.\\n' + '* Rename componentWillMount to UNSAFE_componentWillMount to suppress ' + 'this warning in non-strict mode. In React 18.x, only the UNSAFE_ name will work. ' + 'To rename all deprecated lifecycles to their new names, you can run ' + '`npx react-codemod rename-unsafe-lifecycles` in your project source folder.\\n' + '\\nPlease update the following components: %s', _sortedNames3);\n    }\n\n    if (componentWillReceivePropsUniqueNames.size > 0) {\n      var _sortedNames4 = setToSortedString(componentWillReceivePropsUniqueNames);\n\n      warn('componentWillReceiveProps has been renamed, and is not recommended for use. ' + 'See https://reactjs.org/link/unsafe-component-lifecycles for details.\\n\\n' + '* Move data fetching code or side effects to componentDidUpdate.\\n' + \"* If you're updating state whenever props change, refactor your \" + 'code to use memoization techniques or move it to ' + 'static getDerivedStateFromProps. Learn more at: https://reactjs.org/link/derived-state\\n' + '* Rename componentWillReceiveProps to UNSAFE_componentWillReceiveProps to suppress ' + 'this warning in non-strict mode. In React 18.x, only the UNSAFE_ name will work. ' + 'To rename all deprecated lifecycles to their new names, you can run ' + '`npx react-codemod rename-unsafe-lifecycles` in your project source folder.\\n' + '\\nPlease update the following components: %s', _sortedNames4);\n    }\n\n    if (componentWillUpdateUniqueNames.size > 0) {\n      var _sortedNames5 = setToSortedString(componentWillUpdateUniqueNames);\n\n      warn('componentWillUpdate has been renamed, and is not recommended for use. ' + 'See https://reactjs.org/link/unsafe-component-lifecycles for details.\\n\\n' + '* Move data fetching code or side effects to componentDidUpdate.\\n' + '* Rename componentWillUpdate to UNSAFE_componentWillUpdate to suppress ' + 'this warning in non-strict mode. In React 18.x, only the UNSAFE_ name will work. ' + 'To rename all deprecated lifecycles to their new names, you can run ' + '`npx react-codemod rename-unsafe-lifecycles` in your project source folder.\\n' + '\\nPlease update the following components: %s', _sortedNames5);\n    }\n  };\n\n  var pendingLegacyContextWarning = new Map(); // Tracks components we have already warned about.\n\n  var didWarnAboutLegacyContext = new Set();\n\n  ReactStrictModeWarnings.recordLegacyContextWarning = function (fiber, instance) {\n    var strictRoot = findStrictRoot(fiber);\n\n    if (strictRoot === null) {\n      error('Expected to find a StrictMode component in a strict mode tree. ' + 'This error is likely caused by a bug in React. Please file an issue.');\n\n      return;\n    } // Dedup strategy: Warn once per component.\n\n\n    if (didWarnAboutLegacyContext.has(fiber.type)) {\n      return;\n    }\n\n    var warningsForRoot = pendingLegacyContextWarning.get(strictRoot);\n\n    if (fiber.type.contextTypes != null || fiber.type.childContextTypes != null || instance !== null && typeof instance.getChildContext === 'function') {\n      if (warningsForRoot === undefined) {\n        warningsForRoot = [];\n        pendingLegacyContextWarning.set(strictRoot, warningsForRoot);\n      }\n\n      warningsForRoot.push(fiber);\n    }\n  };\n\n  ReactStrictModeWarnings.flushLegacyContextWarning = function () {\n    pendingLegacyContextWarning.forEach(function (fiberArray, strictRoot) {\n      if (fiberArray.length === 0) {\n        return;\n      }\n\n      var firstFiber = fiberArray[0];\n      var uniqueNames = new Set();\n      fiberArray.forEach(function (fiber) {\n        uniqueNames.add(getComponentNameFromFiber(fiber) || 'Component');\n        didWarnAboutLegacyContext.add(fiber.type);\n      });\n      var sortedNames = setToSortedString(uniqueNames);\n\n      try {\n        setCurrentFiber(firstFiber);\n\n        error('Legacy context API has been detected within a strict-mode tree.' + '\\n\\nThe old API will be supported in all 16.x releases, but applications ' + 'using it should migrate to the new version.' + '\\n\\nPlease update the following components: %s' + '\\n\\nLearn more about this warning here: https://reactjs.org/link/legacy-context', sortedNames);\n      } finally {\n        resetCurrentFiber();\n      }\n    });\n  };\n\n  ReactStrictModeWarnings.discardPendingWarnings = function () {\n    pendingComponentWillMountWarnings = [];\n    pendingUNSAFE_ComponentWillMountWarnings = [];\n    pendingComponentWillReceivePropsWarnings = [];\n    pendingUNSAFE_ComponentWillReceivePropsWarnings = [];\n    pendingComponentWillUpdateWarnings = [];\n    pendingUNSAFE_ComponentWillUpdateWarnings = [];\n    pendingLegacyContextWarning = new Map();\n  };\n}\n\nfunction resolveDefaultProps(Component, baseProps) {\n  if (Component && Component.defaultProps) {\n    // Resolve default props. Taken from ReactElement\n    var props = assign({}, baseProps);\n    var defaultProps = Component.defaultProps;\n\n    for (var propName in defaultProps) {\n      if (props[propName] === undefined) {\n        props[propName] = defaultProps[propName];\n      }\n    }\n\n    return props;\n  }\n\n  return baseProps;\n}\n\nvar valueCursor = createCursor(null);\nvar rendererSigil;\n\n{\n  // Use this to detect multiple renderers using the same context\n  rendererSigil = {};\n}\n\nvar currentlyRenderingFiber = null;\nvar lastContextDependency = null;\nvar lastFullyObservedContext = null;\nvar isDisallowedContextReadInDEV = false;\nfunction resetContextDependencies() {\n  // This is called right before React yields execution, to ensure `readContext`\n  // cannot be called outside the render phase.\n  currentlyRenderingFiber = null;\n  lastContextDependency = null;\n  lastFullyObservedContext = null;\n\n  {\n    isDisallowedContextReadInDEV = false;\n  }\n}\nfunction enterDisallowedContextReadInDEV() {\n  {\n    isDisallowedContextReadInDEV = true;\n  }\n}\nfunction exitDisallowedContextReadInDEV() {\n  {\n    isDisallowedContextReadInDEV = false;\n  }\n}\nfunction pushProvider(providerFiber, context, nextValue) {\n  {\n    push(valueCursor, context._currentValue, providerFiber);\n    context._currentValue = nextValue;\n\n    {\n      if (context._currentRenderer !== undefined && context._currentRenderer !== null && context._currentRenderer !== rendererSigil) {\n        error('Detected multiple renderers concurrently rendering the ' + 'same context provider. This is currently unsupported.');\n      }\n\n      context._currentRenderer = rendererSigil;\n    }\n  }\n}\nfunction popProvider(context, providerFiber) {\n  var currentValue = valueCursor.current;\n  pop(valueCursor, providerFiber);\n\n  {\n    {\n      context._currentValue = currentValue;\n    }\n  }\n}\nfunction scheduleContextWorkOnParentPath(parent, renderLanes, propagationRoot) {\n  // Update the child lanes of all the ancestors, including the alternates.\n  var node = parent;\n\n  while (node !== null) {\n    var alternate = node.alternate;\n\n    if (!isSubsetOfLanes(node.childLanes, renderLanes)) {\n      node.childLanes = mergeLanes(node.childLanes, renderLanes);\n\n      if (alternate !== null) {\n        alternate.childLanes = mergeLanes(alternate.childLanes, renderLanes);\n      }\n    } else if (alternate !== null && !isSubsetOfLanes(alternate.childLanes, renderLanes)) {\n      alternate.childLanes = mergeLanes(alternate.childLanes, renderLanes);\n    }\n\n    if (node === propagationRoot) {\n      break;\n    }\n\n    node = node.return;\n  }\n\n  {\n    if (node !== propagationRoot) {\n      error('Expected to find the propagation root when scheduling context work. ' + 'This error is likely caused by a bug in React. Please file an issue.');\n    }\n  }\n}\nfunction propagateContextChange(workInProgress, context, renderLanes) {\n  {\n    propagateContextChange_eager(workInProgress, context, renderLanes);\n  }\n}\n\nfunction propagateContextChange_eager(workInProgress, context, renderLanes) {\n\n  var fiber = workInProgress.child;\n\n  if (fiber !== null) {\n    // Set the return pointer of the child to the work-in-progress fiber.\n    fiber.return = workInProgress;\n  }\n\n  while (fiber !== null) {\n    var nextFiber = void 0; // Visit this fiber.\n\n    var list = fiber.dependencies;\n\n    if (list !== null) {\n      nextFiber = fiber.child;\n      var dependency = list.firstContext;\n\n      while (dependency !== null) {\n        // Check if the context matches.\n        if (dependency.context === context) {\n          // Match! Schedule an update on this fiber.\n          if (fiber.tag === ClassComponent) {\n            // Schedule a force update on the work-in-progress.\n            var lane = pickArbitraryLane(renderLanes);\n            var update = createUpdate(NoTimestamp, lane);\n            update.tag = ForceUpdate; // TODO: Because we don't have a work-in-progress, this will add the\n            // update to the current fiber, too, which means it will persist even if\n            // this render is thrown away. Since it's a race condition, not sure it's\n            // worth fixing.\n            // Inlined `enqueueUpdate` to remove interleaved update check\n\n            var updateQueue = fiber.updateQueue;\n\n            if (updateQueue === null) ; else {\n              var sharedQueue = updateQueue.shared;\n              var pending = sharedQueue.pending;\n\n              if (pending === null) {\n                // This is the first update. Create a circular list.\n                update.next = update;\n              } else {\n                update.next = pending.next;\n                pending.next = update;\n              }\n\n              sharedQueue.pending = update;\n            }\n          }\n\n          fiber.lanes = mergeLanes(fiber.lanes, renderLanes);\n          var alternate = fiber.alternate;\n\n          if (alternate !== null) {\n            alternate.lanes = mergeLanes(alternate.lanes, renderLanes);\n          }\n\n          scheduleContextWorkOnParentPath(fiber.return, renderLanes, workInProgress); // Mark the updated lanes on the list, too.\n\n          list.lanes = mergeLanes(list.lanes, renderLanes); // Since we already found a match, we can stop traversing the\n          // dependency list.\n\n          break;\n        }\n\n        dependency = dependency.next;\n      }\n    } else if (fiber.tag === ContextProvider) {\n      // Don't scan deeper if this is a matching provider\n      nextFiber = fiber.type === workInProgress.type ? null : fiber.child;\n    } else if (fiber.tag === DehydratedFragment) {\n      // If a dehydrated suspense boundary is in this subtree, we don't know\n      // if it will have any context consumers in it. The best we can do is\n      // mark it as having updates.\n      var parentSuspense = fiber.return;\n\n      if (parentSuspense === null) {\n        throw new Error('We just came from a parent so we must have had a parent. This is a bug in React.');\n      }\n\n      parentSuspense.lanes = mergeLanes(parentSuspense.lanes, renderLanes);\n      var _alternate = parentSuspense.alternate;\n\n      if (_alternate !== null) {\n        _alternate.lanes = mergeLanes(_alternate.lanes, renderLanes);\n      } // This is intentionally passing this fiber as the parent\n      // because we want to schedule this fiber as having work\n      // on its children. We'll use the childLanes on\n      // this fiber to indicate that a context has changed.\n\n\n      scheduleContextWorkOnParentPath(parentSuspense, renderLanes, workInProgress);\n      nextFiber = fiber.sibling;\n    } else {\n      // Traverse down.\n      nextFiber = fiber.child;\n    }\n\n    if (nextFiber !== null) {\n      // Set the return pointer of the child to the work-in-progress fiber.\n      nextFiber.return = fiber;\n    } else {\n      // No child. Traverse to next sibling.\n      nextFiber = fiber;\n\n      while (nextFiber !== null) {\n        if (nextFiber === workInProgress) {\n          // We're back to the root of this subtree. Exit.\n          nextFiber = null;\n          break;\n        }\n\n        var sibling = nextFiber.sibling;\n\n        if (sibling !== null) {\n          // Set the return pointer of the sibling to the work-in-progress fiber.\n          sibling.return = nextFiber.return;\n          nextFiber = sibling;\n          break;\n        } // No more siblings. Traverse up.\n\n\n        nextFiber = nextFiber.return;\n      }\n    }\n\n    fiber = nextFiber;\n  }\n}\nfunction prepareToReadContext(workInProgress, renderLanes) {\n  currentlyRenderingFiber = workInProgress;\n  lastContextDependency = null;\n  lastFullyObservedContext = null;\n  var dependencies = workInProgress.dependencies;\n\n  if (dependencies !== null) {\n    {\n      var firstContext = dependencies.firstContext;\n\n      if (firstContext !== null) {\n        if (includesSomeLane(dependencies.lanes, renderLanes)) {\n          // Context list has a pending update. Mark that this fiber performed work.\n          markWorkInProgressReceivedUpdate();\n        } // Reset the work-in-progress list\n\n\n        dependencies.firstContext = null;\n      }\n    }\n  }\n}\nfunction readContext(context) {\n  {\n    // This warning would fire if you read context inside a Hook like useMemo.\n    // Unlike the class check below, it's not enforced in production for perf.\n    if (isDisallowedContextReadInDEV) {\n      error('Context can only be read while React is rendering. ' + 'In classes, you can read it in the render method or getDerivedStateFromProps. ' + 'In function components, you can read it directly in the function body, but not ' + 'inside Hooks like useReducer() or useMemo().');\n    }\n  }\n\n  var value =  context._currentValue ;\n\n  if (lastFullyObservedContext === context) ; else {\n    var contextItem = {\n      context: context,\n      memoizedValue: value,\n      next: null\n    };\n\n    if (lastContextDependency === null) {\n      if (currentlyRenderingFiber === null) {\n        throw new Error('Context can only be read while React is rendering. ' + 'In classes, you can read it in the render method or getDerivedStateFromProps. ' + 'In function components, you can read it directly in the function body, but not ' + 'inside Hooks like useReducer() or useMemo().');\n      } // This is the first dependency for this component. Create a new list.\n\n\n      lastContextDependency = contextItem;\n      currentlyRenderingFiber.dependencies = {\n        lanes: NoLanes,\n        firstContext: contextItem\n      };\n    } else {\n      // Append a new context item.\n      lastContextDependency = lastContextDependency.next = contextItem;\n    }\n  }\n\n  return value;\n}\n\n// render. When this render exits, either because it finishes or because it is\n// interrupted, the interleaved updates will be transferred onto the main part\n// of the queue.\n\nvar concurrentQueues = null;\nfunction pushConcurrentUpdateQueue(queue) {\n  if (concurrentQueues === null) {\n    concurrentQueues = [queue];\n  } else {\n    concurrentQueues.push(queue);\n  }\n}\nfunction finishQueueingConcurrentUpdates() {\n  // Transfer the interleaved updates onto the main queue. Each queue has a\n  // `pending` field and an `interleaved` field. When they are not null, they\n  // point to the last node in a circular linked list. We need to append the\n  // interleaved list to the end of the pending list by joining them into a\n  // single, circular list.\n  if (concurrentQueues !== null) {\n    for (var i = 0; i < concurrentQueues.length; i++) {\n      var queue = concurrentQueues[i];\n      var lastInterleavedUpdate = queue.interleaved;\n\n      if (lastInterleavedUpdate !== null) {\n        queue.interleaved = null;\n        var firstInterleavedUpdate = lastInterleavedUpdate.next;\n        var lastPendingUpdate = queue.pending;\n\n        if (lastPendingUpdate !== null) {\n          var firstPendingUpdate = lastPendingUpdate.next;\n          lastPendingUpdate.next = firstInterleavedUpdate;\n          lastInterleavedUpdate.next = firstPendingUpdate;\n        }\n\n        queue.pending = lastInterleavedUpdate;\n      }\n    }\n\n    concurrentQueues = null;\n  }\n}\nfunction enqueueConcurrentHookUpdate(fiber, queue, update, lane) {\n  var interleaved = queue.interleaved;\n\n  if (interleaved === null) {\n    // This is the first update. Create a circular list.\n    update.next = update; // At the end of the current render, this queue's interleaved updates will\n    // be transferred to the pending queue.\n\n    pushConcurrentUpdateQueue(queue);\n  } else {\n    update.next = interleaved.next;\n    interleaved.next = update;\n  }\n\n  queue.interleaved = update;\n  return markUpdateLaneFromFiberToRoot(fiber, lane);\n}\nfunction enqueueConcurrentHookUpdateAndEagerlyBailout(fiber, queue, update, lane) {\n  var interleaved = queue.interleaved;\n\n  if (interleaved === null) {\n    // This is the first update. Create a circular list.\n    update.next = update; // At the end of the current render, this queue's interleaved updates will\n    // be transferred to the pending queue.\n\n    pushConcurrentUpdateQueue(queue);\n  } else {\n    update.next = interleaved.next;\n    interleaved.next = update;\n  }\n\n  queue.interleaved = update;\n}\nfunction enqueueConcurrentClassUpdate(fiber, queue, update, lane) {\n  var interleaved = queue.interleaved;\n\n  if (interleaved === null) {\n    // This is the first update. Create a circular list.\n    update.next = update; // At the end of the current render, this queue's interleaved updates will\n    // be transferred to the pending queue.\n\n    pushConcurrentUpdateQueue(queue);\n  } else {\n    update.next = interleaved.next;\n    interleaved.next = update;\n  }\n\n  queue.interleaved = update;\n  return markUpdateLaneFromFiberToRoot(fiber, lane);\n}\nfunction enqueueConcurrentRenderForLane(fiber, lane) {\n  return markUpdateLaneFromFiberToRoot(fiber, lane);\n} // Calling this function outside this module should only be done for backwards\n// compatibility and should always be accompanied by a warning.\n\nvar unsafe_markUpdateLaneFromFiberToRoot = markUpdateLaneFromFiberToRoot;\n\nfunction markUpdateLaneFromFiberToRoot(sourceFiber, lane) {\n  // Update the source fiber's lanes\n  sourceFiber.lanes = mergeLanes(sourceFiber.lanes, lane);\n  var alternate = sourceFiber.alternate;\n\n  if (alternate !== null) {\n    alternate.lanes = mergeLanes(alternate.lanes, lane);\n  }\n\n  {\n    if (alternate === null && (sourceFiber.flags & (Placement | Hydrating)) !== NoFlags) {\n      warnAboutUpdateOnNotYetMountedFiberInDEV(sourceFiber);\n    }\n  } // Walk the parent path to the root and update the child lanes.\n\n\n  var node = sourceFiber;\n  var parent = sourceFiber.return;\n\n  while (parent !== null) {\n    parent.childLanes = mergeLanes(parent.childLanes, lane);\n    alternate = parent.alternate;\n\n    if (alternate !== null) {\n      alternate.childLanes = mergeLanes(alternate.childLanes, lane);\n    } else {\n      {\n        if ((parent.flags & (Placement | Hydrating)) !== NoFlags) {\n          warnAboutUpdateOnNotYetMountedFiberInDEV(sourceFiber);\n        }\n      }\n    }\n\n    node = parent;\n    parent = parent.return;\n  }\n\n  if (node.tag === HostRoot) {\n    var root = node.stateNode;\n    return root;\n  } else {\n    return null;\n  }\n}\n\nvar UpdateState = 0;\nvar ReplaceState = 1;\nvar ForceUpdate = 2;\nvar CaptureUpdate = 3; // Global state that is reset at the beginning of calling `processUpdateQueue`.\n// It should only be read right after calling `processUpdateQueue`, via\n// `checkHasForceUpdateAfterProcessing`.\n\nvar hasForceUpdate = false;\nvar didWarnUpdateInsideUpdate;\nvar currentlyProcessingQueue;\n\n{\n  didWarnUpdateInsideUpdate = false;\n  currentlyProcessingQueue = null;\n}\n\nfunction initializeUpdateQueue(fiber) {\n  var queue = {\n    baseState: fiber.memoizedState,\n    firstBaseUpdate: null,\n    lastBaseUpdate: null,\n    shared: {\n      pending: null,\n      interleaved: null,\n      lanes: NoLanes\n    },\n    effects: null\n  };\n  fiber.updateQueue = queue;\n}\nfunction cloneUpdateQueue(current, workInProgress) {\n  // Clone the update queue from current. Unless it's already a clone.\n  var queue = workInProgress.updateQueue;\n  var currentQueue = current.updateQueue;\n\n  if (queue === currentQueue) {\n    var clone = {\n      baseState: currentQueue.baseState,\n      firstBaseUpdate: currentQueue.firstBaseUpdate,\n      lastBaseUpdate: currentQueue.lastBaseUpdate,\n      shared: currentQueue.shared,\n      effects: currentQueue.effects\n    };\n    workInProgress.updateQueue = clone;\n  }\n}\nfunction createUpdate(eventTime, lane) {\n  var update = {\n    eventTime: eventTime,\n    lane: lane,\n    tag: UpdateState,\n    payload: null,\n    callback: null,\n    next: null\n  };\n  return update;\n}\nfunction enqueueUpdate(fiber, update, lane) {\n  var updateQueue = fiber.updateQueue;\n\n  if (updateQueue === null) {\n    // Only occurs if the fiber has been unmounted.\n    return null;\n  }\n\n  var sharedQueue = updateQueue.shared;\n\n  {\n    if (currentlyProcessingQueue === sharedQueue && !didWarnUpdateInsideUpdate) {\n      error('An update (setState, replaceState, or forceUpdate) was scheduled ' + 'from inside an update function. Update functions should be pure, ' + 'with zero side-effects. Consider using componentDidUpdate or a ' + 'callback.');\n\n      didWarnUpdateInsideUpdate = true;\n    }\n  }\n\n  if (isUnsafeClassRenderPhaseUpdate()) {\n    // This is an unsafe render phase update. Add directly to the update\n    // queue so we can process it immediately during the current render.\n    var pending = sharedQueue.pending;\n\n    if (pending === null) {\n      // This is the first update. Create a circular list.\n      update.next = update;\n    } else {\n      update.next = pending.next;\n      pending.next = update;\n    }\n\n    sharedQueue.pending = update; // Update the childLanes even though we're most likely already rendering\n    // this fiber. This is for backwards compatibility in the case where you\n    // update a different component during render phase than the one that is\n    // currently renderings (a pattern that is accompanied by a warning).\n\n    return unsafe_markUpdateLaneFromFiberToRoot(fiber, lane);\n  } else {\n    return enqueueConcurrentClassUpdate(fiber, sharedQueue, update, lane);\n  }\n}\nfunction entangleTransitions(root, fiber, lane) {\n  var updateQueue = fiber.updateQueue;\n\n  if (updateQueue === null) {\n    // Only occurs if the fiber has been unmounted.\n    return;\n  }\n\n  var sharedQueue = updateQueue.shared;\n\n  if (isTransitionLane(lane)) {\n    var queueLanes = sharedQueue.lanes; // If any entangled lanes are no longer pending on the root, then they must\n    // have finished. We can remove them from the shared queue, which represents\n    // a superset of the actually pending lanes. In some cases we may entangle\n    // more than we need to, but that's OK. In fact it's worse if we *don't*\n    // entangle when we should.\n\n    queueLanes = intersectLanes(queueLanes, root.pendingLanes); // Entangle the new transition lane with the other transition lanes.\n\n    var newQueueLanes = mergeLanes(queueLanes, lane);\n    sharedQueue.lanes = newQueueLanes; // Even if queue.lanes already include lane, we don't know for certain if\n    // the lane finished since the last time we entangled it. So we need to\n    // entangle it again, just to be sure.\n\n    markRootEntangled(root, newQueueLanes);\n  }\n}\nfunction enqueueCapturedUpdate(workInProgress, capturedUpdate) {\n  // Captured updates are updates that are thrown by a child during the render\n  // phase. They should be discarded if the render is aborted. Therefore,\n  // we should only put them on the work-in-progress queue, not the current one.\n  var queue = workInProgress.updateQueue; // Check if the work-in-progress queue is a clone.\n\n  var current = workInProgress.alternate;\n\n  if (current !== null) {\n    var currentQueue = current.updateQueue;\n\n    if (queue === currentQueue) {\n      // The work-in-progress queue is the same as current. This happens when\n      // we bail out on a parent fiber that then captures an error thrown by\n      // a child. Since we want to append the update only to the work-in\n      // -progress queue, we need to clone the updates. We usually clone during\n      // processUpdateQueue, but that didn't happen in this case because we\n      // skipped over the parent when we bailed out.\n      var newFirst = null;\n      var newLast = null;\n      var firstBaseUpdate = queue.firstBaseUpdate;\n\n      if (firstBaseUpdate !== null) {\n        // Loop through the updates and clone them.\n        var update = firstBaseUpdate;\n\n        do {\n          var clone = {\n            eventTime: update.eventTime,\n            lane: update.lane,\n            tag: update.tag,\n            payload: update.payload,\n            callback: update.callback,\n            next: null\n          };\n\n          if (newLast === null) {\n            newFirst = newLast = clone;\n          } else {\n            newLast.next = clone;\n            newLast = clone;\n          }\n\n          update = update.next;\n        } while (update !== null); // Append the captured update the end of the cloned list.\n\n\n        if (newLast === null) {\n          newFirst = newLast = capturedUpdate;\n        } else {\n          newLast.next = capturedUpdate;\n          newLast = capturedUpdate;\n        }\n      } else {\n        // There are no base updates.\n        newFirst = newLast = capturedUpdate;\n      }\n\n      queue = {\n        baseState: currentQueue.baseState,\n        firstBaseUpdate: newFirst,\n        lastBaseUpdate: newLast,\n        shared: currentQueue.shared,\n        effects: currentQueue.effects\n      };\n      workInProgress.updateQueue = queue;\n      return;\n    }\n  } // Append the update to the end of the list.\n\n\n  var lastBaseUpdate = queue.lastBaseUpdate;\n\n  if (lastBaseUpdate === null) {\n    queue.firstBaseUpdate = capturedUpdate;\n  } else {\n    lastBaseUpdate.next = capturedUpdate;\n  }\n\n  queue.lastBaseUpdate = capturedUpdate;\n}\n\nfunction getStateFromUpdate(workInProgress, queue, update, prevState, nextProps, instance) {\n  switch (update.tag) {\n    case ReplaceState:\n      {\n        var payload = update.payload;\n\n        if (typeof payload === 'function') {\n          // Updater function\n          {\n            enterDisallowedContextReadInDEV();\n          }\n\n          var nextState = payload.call(instance, prevState, nextProps);\n\n          {\n            if ( workInProgress.mode & StrictLegacyMode) {\n              setIsStrictModeForDevtools(true);\n\n              try {\n                payload.call(instance, prevState, nextProps);\n              } finally {\n                setIsStrictModeForDevtools(false);\n              }\n            }\n\n            exitDisallowedContextReadInDEV();\n          }\n\n          return nextState;\n        } // State object\n\n\n        return payload;\n      }\n\n    case CaptureUpdate:\n      {\n        workInProgress.flags = workInProgress.flags & ~ShouldCapture | DidCapture;\n      }\n    // Intentional fallthrough\n\n    case UpdateState:\n      {\n        var _payload = update.payload;\n        var partialState;\n\n        if (typeof _payload === 'function') {\n          // Updater function\n          {\n            enterDisallowedContextReadInDEV();\n          }\n\n          partialState = _payload.call(instance, prevState, nextProps);\n\n          {\n            if ( workInProgress.mode & StrictLegacyMode) {\n              setIsStrictModeForDevtools(true);\n\n              try {\n                _payload.call(instance, prevState, nextProps);\n              } finally {\n                setIsStrictModeForDevtools(false);\n              }\n            }\n\n            exitDisallowedContextReadInDEV();\n          }\n        } else {\n          // Partial state object\n          partialState = _payload;\n        }\n\n        if (partialState === null || partialState === undefined) {\n          // Null and undefined are treated as no-ops.\n          return prevState;\n        } // Merge the partial state and the previous state.\n\n\n        return assign({}, prevState, partialState);\n      }\n\n    case ForceUpdate:\n      {\n        hasForceUpdate = true;\n        return prevState;\n      }\n  }\n\n  return prevState;\n}\n\nfunction processUpdateQueue(workInProgress, props, instance, renderLanes) {\n  // This is always non-null on a ClassComponent or HostRoot\n  var queue = workInProgress.updateQueue;\n  hasForceUpdate = false;\n\n  {\n    currentlyProcessingQueue = queue.shared;\n  }\n\n  var firstBaseUpdate = queue.firstBaseUpdate;\n  var lastBaseUpdate = queue.lastBaseUpdate; // Check if there are pending updates. If so, transfer them to the base queue.\n\n  var pendingQueue = queue.shared.pending;\n\n  if (pendingQueue !== null) {\n    queue.shared.pending = null; // The pending queue is circular. Disconnect the pointer between first\n    // and last so that it's non-circular.\n\n    var lastPendingUpdate = pendingQueue;\n    var firstPendingUpdate = lastPendingUpdate.next;\n    lastPendingUpdate.next = null; // Append pending updates to base queue\n\n    if (lastBaseUpdate === null) {\n      firstBaseUpdate = firstPendingUpdate;\n    } else {\n      lastBaseUpdate.next = firstPendingUpdate;\n    }\n\n    lastBaseUpdate = lastPendingUpdate; // If there's a current queue, and it's different from the base queue, then\n    // we need to transfer the updates to that queue, too. Because the base\n    // queue is a singly-linked list with no cycles, we can append to both\n    // lists and take advantage of structural sharing.\n    // TODO: Pass `current` as argument\n\n    var current = workInProgress.alternate;\n\n    if (current !== null) {\n      // This is always non-null on a ClassComponent or HostRoot\n      var currentQueue = current.updateQueue;\n      var currentLastBaseUpdate = currentQueue.lastBaseUpdate;\n\n      if (currentLastBaseUpdate !== lastBaseUpdate) {\n        if (currentLastBaseUpdate === null) {\n          currentQueue.firstBaseUpdate = firstPendingUpdate;\n        } else {\n          currentLastBaseUpdate.next = firstPendingUpdate;\n        }\n\n        currentQueue.lastBaseUpdate = lastPendingUpdate;\n      }\n    }\n  } // These values may change as we process the queue.\n\n\n  if (firstBaseUpdate !== null) {\n    // Iterate through the list of updates to compute the result.\n    var newState = queue.baseState; // TODO: Don't need to accumulate this. Instead, we can remove renderLanes\n    // from the original lanes.\n\n    var newLanes = NoLanes;\n    var newBaseState = null;\n    var newFirstBaseUpdate = null;\n    var newLastBaseUpdate = null;\n    var update = firstBaseUpdate;\n\n    do {\n      var updateLane = update.lane;\n      var updateEventTime = update.eventTime;\n\n      if (!isSubsetOfLanes(renderLanes, updateLane)) {\n        // Priority is insufficient. Skip this update. If this is the first\n        // skipped update, the previous update/state is the new base\n        // update/state.\n        var clone = {\n          eventTime: updateEventTime,\n          lane: updateLane,\n          tag: update.tag,\n          payload: update.payload,\n          callback: update.callback,\n          next: null\n        };\n\n        if (newLastBaseUpdate === null) {\n          newFirstBaseUpdate = newLastBaseUpdate = clone;\n          newBaseState = newState;\n        } else {\n          newLastBaseUpdate = newLastBaseUpdate.next = clone;\n        } // Update the remaining priority in the queue.\n\n\n        newLanes = mergeLanes(newLanes, updateLane);\n      } else {\n        // This update does have sufficient priority.\n        if (newLastBaseUpdate !== null) {\n          var _clone = {\n            eventTime: updateEventTime,\n            // This update is going to be committed so we never want uncommit\n            // it. Using NoLane works because 0 is a subset of all bitmasks, so\n            // this will never be skipped by the check above.\n            lane: NoLane,\n            tag: update.tag,\n            payload: update.payload,\n            callback: update.callback,\n            next: null\n          };\n          newLastBaseUpdate = newLastBaseUpdate.next = _clone;\n        } // Process this update.\n\n\n        newState = getStateFromUpdate(workInProgress, queue, update, newState, props, instance);\n        var callback = update.callback;\n\n        if (callback !== null && // If the update was already committed, we should not queue its\n        // callback again.\n        update.lane !== NoLane) {\n          workInProgress.flags |= Callback;\n          var effects = queue.effects;\n\n          if (effects === null) {\n            queue.effects = [update];\n          } else {\n            effects.push(update);\n          }\n        }\n      }\n\n      update = update.next;\n\n      if (update === null) {\n        pendingQueue = queue.shared.pending;\n\n        if (pendingQueue === null) {\n          break;\n        } else {\n          // An update was scheduled from inside a reducer. Add the new\n          // pending updates to the end of the list and keep processing.\n          var _lastPendingUpdate = pendingQueue; // Intentionally unsound. Pending updates form a circular list, but we\n          // unravel them when transferring them to the base queue.\n\n          var _firstPendingUpdate = _lastPendingUpdate.next;\n          _lastPendingUpdate.next = null;\n          update = _firstPendingUpdate;\n          queue.lastBaseUpdate = _lastPendingUpdate;\n          queue.shared.pending = null;\n        }\n      }\n    } while (true);\n\n    if (newLastBaseUpdate === null) {\n      newBaseState = newState;\n    }\n\n    queue.baseState = newBaseState;\n    queue.firstBaseUpdate = newFirstBaseUpdate;\n    queue.lastBaseUpdate = newLastBaseUpdate; // Interleaved updates are stored on a separate queue. We aren't going to\n    // process them during this render, but we do need to track which lanes\n    // are remaining.\n\n    var lastInterleaved = queue.shared.interleaved;\n\n    if (lastInterleaved !== null) {\n      var interleaved = lastInterleaved;\n\n      do {\n        newLanes = mergeLanes(newLanes, interleaved.lane);\n        interleaved = interleaved.next;\n      } while (interleaved !== lastInterleaved);\n    } else if (firstBaseUpdate === null) {\n      // `queue.lanes` is used for entangling transitions. We can set it back to\n      // zero once the queue is empty.\n      queue.shared.lanes = NoLanes;\n    } // Set the remaining expiration time to be whatever is remaining in the queue.\n    // This should be fine because the only two other things that contribute to\n    // expiration time are props and context. We're already in the middle of the\n    // begin phase by the time we start processing the queue, so we've already\n    // dealt with the props. Context in components that specify\n    // shouldComponentUpdate is tricky; but we'll have to account for\n    // that regardless.\n\n\n    markSkippedUpdateLanes(newLanes);\n    workInProgress.lanes = newLanes;\n    workInProgress.memoizedState = newState;\n  }\n\n  {\n    currentlyProcessingQueue = null;\n  }\n}\n\nfunction callCallback(callback, context) {\n  if (typeof callback !== 'function') {\n    throw new Error('Invalid argument passed as callback. Expected a function. Instead ' + (\"received: \" + callback));\n  }\n\n  callback.call(context);\n}\n\nfunction resetHasForceUpdateBeforeProcessing() {\n  hasForceUpdate = false;\n}\nfunction checkHasForceUpdateAfterProcessing() {\n  return hasForceUpdate;\n}\nfunction commitUpdateQueue(finishedWork, finishedQueue, instance) {\n  // Commit the effects\n  var effects = finishedQueue.effects;\n  finishedQueue.effects = null;\n\n  if (effects !== null) {\n    for (var i = 0; i < effects.length; i++) {\n      var effect = effects[i];\n      var callback = effect.callback;\n\n      if (callback !== null) {\n        effect.callback = null;\n        callCallback(callback, instance);\n      }\n    }\n  }\n}\n\nvar fakeInternalInstance = {}; // React.Component uses a shared frozen object by default.\n// We'll use it to determine whether we need to initialize legacy refs.\n\nvar emptyRefsObject = new React.Component().refs;\nvar didWarnAboutStateAssignmentForComponent;\nvar didWarnAboutUninitializedState;\nvar didWarnAboutGetSnapshotBeforeUpdateWithoutDidUpdate;\nvar didWarnAboutLegacyLifecyclesAndDerivedState;\nvar didWarnAboutUndefinedDerivedState;\nvar warnOnUndefinedDerivedState;\nvar warnOnInvalidCallback;\nvar didWarnAboutDirectlyAssigningPropsToState;\nvar didWarnAboutContextTypeAndContextTypes;\nvar didWarnAboutInvalidateContextType;\n\n{\n  didWarnAboutStateAssignmentForComponent = new Set();\n  didWarnAboutUninitializedState = new Set();\n  didWarnAboutGetSnapshotBeforeUpdateWithoutDidUpdate = new Set();\n  didWarnAboutLegacyLifecyclesAndDerivedState = new Set();\n  didWarnAboutDirectlyAssigningPropsToState = new Set();\n  didWarnAboutUndefinedDerivedState = new Set();\n  didWarnAboutContextTypeAndContextTypes = new Set();\n  didWarnAboutInvalidateContextType = new Set();\n  var didWarnOnInvalidCallback = new Set();\n\n  warnOnInvalidCallback = function (callback, callerName) {\n    if (callback === null || typeof callback === 'function') {\n      return;\n    }\n\n    var key = callerName + '_' + callback;\n\n    if (!didWarnOnInvalidCallback.has(key)) {\n      didWarnOnInvalidCallback.add(key);\n\n      error('%s(...): Expected the last optional `callback` argument to be a ' + 'function. Instead received: %s.', callerName, callback);\n    }\n  };\n\n  warnOnUndefinedDerivedState = function (type, partialState) {\n    if (partialState === undefined) {\n      var componentName = getComponentNameFromType(type) || 'Component';\n\n      if (!didWarnAboutUndefinedDerivedState.has(componentName)) {\n        didWarnAboutUndefinedDerivedState.add(componentName);\n\n        error('%s.getDerivedStateFromProps(): A valid state object (or null) must be returned. ' + 'You have returned undefined.', componentName);\n      }\n    }\n  }; // This is so gross but it's at least non-critical and can be removed if\n  // it causes problems. This is meant to give a nicer error message for\n  // ReactDOM15.unstable_renderSubtreeIntoContainer(reactDOM16Component,\n  // ...)) which otherwise throws a \"_processChildContext is not a function\"\n  // exception.\n\n\n  Object.defineProperty(fakeInternalInstance, '_processChildContext', {\n    enumerable: false,\n    value: function () {\n      throw new Error('_processChildContext is not available in React 16+. This likely ' + 'means you have multiple copies of React and are attempting to nest ' + 'a React 15 tree inside a React 16 tree using ' + \"unstable_renderSubtreeIntoContainer, which isn't supported. Try \" + 'to make sure you have only one copy of React (and ideally, switch ' + 'to ReactDOM.createPortal).');\n    }\n  });\n  Object.freeze(fakeInternalInstance);\n}\n\nfunction applyDerivedStateFromProps(workInProgress, ctor, getDerivedStateFromProps, nextProps) {\n  var prevState = workInProgress.memoizedState;\n  var partialState = getDerivedStateFromProps(nextProps, prevState);\n\n  {\n    if ( workInProgress.mode & StrictLegacyMode) {\n      setIsStrictModeForDevtools(true);\n\n      try {\n        // Invoke the function an extra time to help detect side-effects.\n        partialState = getDerivedStateFromProps(nextProps, prevState);\n      } finally {\n        setIsStrictModeForDevtools(false);\n      }\n    }\n\n    warnOnUndefinedDerivedState(ctor, partialState);\n  } // Merge the partial state and the previous state.\n\n\n  var memoizedState = partialState === null || partialState === undefined ? prevState : assign({}, prevState, partialState);\n  workInProgress.memoizedState = memoizedState; // Once the update queue is empty, persist the derived state onto the\n  // base state.\n\n  if (workInProgress.lanes === NoLanes) {\n    // Queue is always non-null for classes\n    var updateQueue = workInProgress.updateQueue;\n    updateQueue.baseState = memoizedState;\n  }\n}\n\nvar classComponentUpdater = {\n  isMounted: isMounted,\n  enqueueSetState: function (inst, payload, callback) {\n    var fiber = get(inst);\n    var eventTime = requestEventTime();\n    var lane = requestUpdateLane(fiber);\n    var update = createUpdate(eventTime, lane);\n    update.payload = payload;\n\n    if (callback !== undefined && callback !== null) {\n      {\n        warnOnInvalidCallback(callback, 'setState');\n      }\n\n      update.callback = callback;\n    }\n\n    var root = enqueueUpdate(fiber, update, lane);\n\n    if (root !== null) {\n      scheduleUpdateOnFiber(root, fiber, lane, eventTime);\n      entangleTransitions(root, fiber, lane);\n    }\n\n    {\n      markStateUpdateScheduled(fiber, lane);\n    }\n  },\n  enqueueReplaceState: function (inst, payload, callback) {\n    var fiber = get(inst);\n    var eventTime = requestEventTime();\n    var lane = requestUpdateLane(fiber);\n    var update = createUpdate(eventTime, lane);\n    update.tag = ReplaceState;\n    update.payload = payload;\n\n    if (callback !== undefined && callback !== null) {\n      {\n        warnOnInvalidCallback(callback, 'replaceState');\n      }\n\n      update.callback = callback;\n    }\n\n    var root = enqueueUpdate(fiber, update, lane);\n\n    if (root !== null) {\n      scheduleUpdateOnFiber(root, fiber, lane, eventTime);\n      entangleTransitions(root, fiber, lane);\n    }\n\n    {\n      markStateUpdateScheduled(fiber, lane);\n    }\n  },\n  enqueueForceUpdate: function (inst, callback) {\n    var fiber = get(inst);\n    var eventTime = requestEventTime();\n    var lane = requestUpdateLane(fiber);\n    var update = createUpdate(eventTime, lane);\n    update.tag = ForceUpdate;\n\n    if (callback !== undefined && callback !== null) {\n      {\n        warnOnInvalidCallback(callback, 'forceUpdate');\n      }\n\n      update.callback = callback;\n    }\n\n    var root = enqueueUpdate(fiber, update, lane);\n\n    if (root !== null) {\n      scheduleUpdateOnFiber(root, fiber, lane, eventTime);\n      entangleTransitions(root, fiber, lane);\n    }\n\n    {\n      markForceUpdateScheduled(fiber, lane);\n    }\n  }\n};\n\nfunction checkShouldComponentUpdate(workInProgress, ctor, oldProps, newProps, oldState, newState, nextContext) {\n  var instance = workInProgress.stateNode;\n\n  if (typeof instance.shouldComponentUpdate === 'function') {\n    var shouldUpdate = instance.shouldComponentUpdate(newProps, newState, nextContext);\n\n    {\n      if ( workInProgress.mode & StrictLegacyMode) {\n        setIsStrictModeForDevtools(true);\n\n        try {\n          // Invoke the function an extra time to help detect side-effects.\n          shouldUpdate = instance.shouldComponentUpdate(newProps, newState, nextContext);\n        } finally {\n          setIsStrictModeForDevtools(false);\n        }\n      }\n\n      if (shouldUpdate === undefined) {\n        error('%s.shouldComponentUpdate(): Returned undefined instead of a ' + 'boolean value. Make sure to return true or false.', getComponentNameFromType(ctor) || 'Component');\n      }\n    }\n\n    return shouldUpdate;\n  }\n\n  if (ctor.prototype && ctor.prototype.isPureReactComponent) {\n    return !shallowEqual(oldProps, newProps) || !shallowEqual(oldState, newState);\n  }\n\n  return true;\n}\n\nfunction checkClassInstance(workInProgress, ctor, newProps) {\n  var instance = workInProgress.stateNode;\n\n  {\n    var name = getComponentNameFromType(ctor) || 'Component';\n    var renderPresent = instance.render;\n\n    if (!renderPresent) {\n      if (ctor.prototype && typeof ctor.prototype.render === 'function') {\n        error('%s(...): No `render` method found on the returned component ' + 'instance: did you accidentally return an object from the constructor?', name);\n      } else {\n        error('%s(...): No `render` method found on the returned component ' + 'instance: you may have forgotten to define `render`.', name);\n      }\n    }\n\n    if (instance.getInitialState && !instance.getInitialState.isReactClassApproved && !instance.state) {\n      error('getInitialState was defined on %s, a plain JavaScript class. ' + 'This is only supported for classes created using React.createClass. ' + 'Did you mean to define a state property instead?', name);\n    }\n\n    if (instance.getDefaultProps && !instance.getDefaultProps.isReactClassApproved) {\n      error('getDefaultProps was defined on %s, a plain JavaScript class. ' + 'This is only supported for classes created using React.createClass. ' + 'Use a static property to define defaultProps instead.', name);\n    }\n\n    if (instance.propTypes) {\n      error('propTypes was defined as an instance property on %s. Use a static ' + 'property to define propTypes instead.', name);\n    }\n\n    if (instance.contextType) {\n      error('contextType was defined as an instance property on %s. Use a static ' + 'property to define contextType instead.', name);\n    }\n\n    {\n      if (instance.contextTypes) {\n        error('contextTypes was defined as an instance property on %s. Use a static ' + 'property to define contextTypes instead.', name);\n      }\n\n      if (ctor.contextType && ctor.contextTypes && !didWarnAboutContextTypeAndContextTypes.has(ctor)) {\n        didWarnAboutContextTypeAndContextTypes.add(ctor);\n\n        error('%s declares both contextTypes and contextType static properties. ' + 'The legacy contextTypes property will be ignored.', name);\n      }\n    }\n\n    if (typeof instance.componentShouldUpdate === 'function') {\n      error('%s has a method called ' + 'componentShouldUpdate(). Did you mean shouldComponentUpdate()? ' + 'The name is phrased as a question because the function is ' + 'expected to return a value.', name);\n    }\n\n    if (ctor.prototype && ctor.prototype.isPureReactComponent && typeof instance.shouldComponentUpdate !== 'undefined') {\n      error('%s has a method called shouldComponentUpdate(). ' + 'shouldComponentUpdate should not be used when extending React.PureComponent. ' + 'Please extend React.Component if shouldComponentUpdate is used.', getComponentNameFromType(ctor) || 'A pure component');\n    }\n\n    if (typeof instance.componentDidUnmount === 'function') {\n      error('%s has a method called ' + 'componentDidUnmount(). But there is no such lifecycle method. ' + 'Did you mean componentWillUnmount()?', name);\n    }\n\n    if (typeof instance.componentDidReceiveProps === 'function') {\n      error('%s has a method called ' + 'componentDidReceiveProps(). But there is no such lifecycle method. ' + 'If you meant to update the state in response to changing props, ' + 'use componentWillReceiveProps(). If you meant to fetch data or ' + 'run side-effects or mutations after React has updated the UI, use componentDidUpdate().', name);\n    }\n\n    if (typeof instance.componentWillRecieveProps === 'function') {\n      error('%s has a method called ' + 'componentWillRecieveProps(). Did you mean componentWillReceiveProps()?', name);\n    }\n\n    if (typeof instance.UNSAFE_componentWillRecieveProps === 'function') {\n      error('%s has a method called ' + 'UNSAFE_componentWillRecieveProps(). Did you mean UNSAFE_componentWillReceiveProps()?', name);\n    }\n\n    var hasMutatedProps = instance.props !== newProps;\n\n    if (instance.props !== undefined && hasMutatedProps) {\n      error('%s(...): When calling super() in `%s`, make sure to pass ' + \"up the same props that your component's constructor was passed.\", name, name);\n    }\n\n    if (instance.defaultProps) {\n      error('Setting defaultProps as an instance property on %s is not supported and will be ignored.' + ' Instead, define defaultProps as a static property on %s.', name, name);\n    }\n\n    if (typeof instance.getSnapshotBeforeUpdate === 'function' && typeof instance.componentDidUpdate !== 'function' && !didWarnAboutGetSnapshotBeforeUpdateWithoutDidUpdate.has(ctor)) {\n      didWarnAboutGetSnapshotBeforeUpdateWithoutDidUpdate.add(ctor);\n\n      error('%s: getSnapshotBeforeUpdate() should be used with componentDidUpdate(). ' + 'This component defines getSnapshotBeforeUpdate() only.', getComponentNameFromType(ctor));\n    }\n\n    if (typeof instance.getDerivedStateFromProps === 'function') {\n      error('%s: getDerivedStateFromProps() is defined as an instance method ' + 'and will be ignored. Instead, declare it as a static method.', name);\n    }\n\n    if (typeof instance.getDerivedStateFromError === 'function') {\n      error('%s: getDerivedStateFromError() is defined as an instance method ' + 'and will be ignored. Instead, declare it as a static method.', name);\n    }\n\n    if (typeof ctor.getSnapshotBeforeUpdate === 'function') {\n      error('%s: getSnapshotBeforeUpdate() is defined as a static method ' + 'and will be ignored. Instead, declare it as an instance method.', name);\n    }\n\n    var _state = instance.state;\n\n    if (_state && (typeof _state !== 'object' || isArray(_state))) {\n      error('%s.state: must be set to an object or null', name);\n    }\n\n    if (typeof instance.getChildContext === 'function' && typeof ctor.childContextTypes !== 'object') {\n      error('%s.getChildContext(): childContextTypes must be defined in order to ' + 'use getChildContext().', name);\n    }\n  }\n}\n\nfunction adoptClassInstance(workInProgress, instance) {\n  instance.updater = classComponentUpdater;\n  workInProgress.stateNode = instance; // The instance needs access to the fiber so that it can schedule updates\n\n  set(instance, workInProgress);\n\n  {\n    instance._reactInternalInstance = fakeInternalInstance;\n  }\n}\n\nfunction constructClassInstance(workInProgress, ctor, props) {\n  var isLegacyContextConsumer = false;\n  var unmaskedContext = emptyContextObject;\n  var context = emptyContextObject;\n  var contextType = ctor.contextType;\n\n  {\n    if ('contextType' in ctor) {\n      var isValid = // Allow null for conditional declaration\n      contextType === null || contextType !== undefined && contextType.$$typeof === REACT_CONTEXT_TYPE && contextType._context === undefined; // Not a <Context.Consumer>\n\n      if (!isValid && !didWarnAboutInvalidateContextType.has(ctor)) {\n        didWarnAboutInvalidateContextType.add(ctor);\n        var addendum = '';\n\n        if (contextType === undefined) {\n          addendum = ' However, it is set to undefined. ' + 'This can be caused by a typo or by mixing up named and default imports. ' + 'This can also happen due to a circular dependency, so ' + 'try moving the createContext() call to a separate file.';\n        } else if (typeof contextType !== 'object') {\n          addendum = ' However, it is set to a ' + typeof contextType + '.';\n        } else if (contextType.$$typeof === REACT_PROVIDER_TYPE) {\n          addendum = ' Did you accidentally pass the Context.Provider instead?';\n        } else if (contextType._context !== undefined) {\n          // <Context.Consumer>\n          addendum = ' Did you accidentally pass the Context.Consumer instead?';\n        } else {\n          addendum = ' However, it is set to an object with keys {' + Object.keys(contextType).join(', ') + '}.';\n        }\n\n        error('%s defines an invalid contextType. ' + 'contextType should point to the Context object returned by React.createContext().%s', getComponentNameFromType(ctor) || 'Component', addendum);\n      }\n    }\n  }\n\n  if (typeof contextType === 'object' && contextType !== null) {\n    context = readContext(contextType);\n  } else {\n    unmaskedContext = getUnmaskedContext(workInProgress, ctor, true);\n    var contextTypes = ctor.contextTypes;\n    isLegacyContextConsumer = contextTypes !== null && contextTypes !== undefined;\n    context = isLegacyContextConsumer ? getMaskedContext(workInProgress, unmaskedContext) : emptyContextObject;\n  }\n\n  var instance = new ctor(props, context); // Instantiate twice to help detect side-effects.\n\n  {\n    if ( workInProgress.mode & StrictLegacyMode) {\n      setIsStrictModeForDevtools(true);\n\n      try {\n        instance = new ctor(props, context); // eslint-disable-line no-new\n      } finally {\n        setIsStrictModeForDevtools(false);\n      }\n    }\n  }\n\n  var state = workInProgress.memoizedState = instance.state !== null && instance.state !== undefined ? instance.state : null;\n  adoptClassInstance(workInProgress, instance);\n\n  {\n    if (typeof ctor.getDerivedStateFromProps === 'function' && state === null) {\n      var componentName = getComponentNameFromType(ctor) || 'Component';\n\n      if (!didWarnAboutUninitializedState.has(componentName)) {\n        didWarnAboutUninitializedState.add(componentName);\n\n        error('`%s` uses `getDerivedStateFromProps` but its initial state is ' + '%s. This is not recommended. Instead, define the initial state by ' + 'assigning an object to `this.state` in the constructor of `%s`. ' + 'This ensures that `getDerivedStateFromProps` arguments have a consistent shape.', componentName, instance.state === null ? 'null' : 'undefined', componentName);\n      }\n    } // If new component APIs are defined, \"unsafe\" lifecycles won't be called.\n    // Warn about these lifecycles if they are present.\n    // Don't warn about react-lifecycles-compat polyfilled methods though.\n\n\n    if (typeof ctor.getDerivedStateFromProps === 'function' || typeof instance.getSnapshotBeforeUpdate === 'function') {\n      var foundWillMountName = null;\n      var foundWillReceivePropsName = null;\n      var foundWillUpdateName = null;\n\n      if (typeof instance.componentWillMount === 'function' && instance.componentWillMount.__suppressDeprecationWarning !== true) {\n        foundWillMountName = 'componentWillMount';\n      } else if (typeof instance.UNSAFE_componentWillMount === 'function') {\n        foundWillMountName = 'UNSAFE_componentWillMount';\n      }\n\n      if (typeof instance.componentWillReceiveProps === 'function' && instance.componentWillReceiveProps.__suppressDeprecationWarning !== true) {\n        foundWillReceivePropsName = 'componentWillReceiveProps';\n      } else if (typeof instance.UNSAFE_componentWillReceiveProps === 'function') {\n        foundWillReceivePropsName = 'UNSAFE_componentWillReceiveProps';\n      }\n\n      if (typeof instance.componentWillUpdate === 'function' && instance.componentWillUpdate.__suppressDeprecationWarning !== true) {\n        foundWillUpdateName = 'componentWillUpdate';\n      } else if (typeof instance.UNSAFE_componentWillUpdate === 'function') {\n        foundWillUpdateName = 'UNSAFE_componentWillUpdate';\n      }\n\n      if (foundWillMountName !== null || foundWillReceivePropsName !== null || foundWillUpdateName !== null) {\n        var _componentName = getComponentNameFromType(ctor) || 'Component';\n\n        var newApiName = typeof ctor.getDerivedStateFromProps === 'function' ? 'getDerivedStateFromProps()' : 'getSnapshotBeforeUpdate()';\n\n        if (!didWarnAboutLegacyLifecyclesAndDerivedState.has(_componentName)) {\n          didWarnAboutLegacyLifecyclesAndDerivedState.add(_componentName);\n\n          error('Unsafe legacy lifecycles will not be called for components using new component APIs.\\n\\n' + '%s uses %s but also contains the following legacy lifecycles:%s%s%s\\n\\n' + 'The above lifecycles should be removed. Learn more about this warning here:\\n' + 'https://reactjs.org/link/unsafe-component-lifecycles', _componentName, newApiName, foundWillMountName !== null ? \"\\n  \" + foundWillMountName : '', foundWillReceivePropsName !== null ? \"\\n  \" + foundWillReceivePropsName : '', foundWillUpdateName !== null ? \"\\n  \" + foundWillUpdateName : '');\n        }\n      }\n    }\n  } // Cache unmasked context so we can avoid recreating masked context unless necessary.\n  // ReactFiberContext usually updates this cache but can't for newly-created instances.\n\n\n  if (isLegacyContextConsumer) {\n    cacheContext(workInProgress, unmaskedContext, context);\n  }\n\n  return instance;\n}\n\nfunction callComponentWillMount(workInProgress, instance) {\n  var oldState = instance.state;\n\n  if (typeof instance.componentWillMount === 'function') {\n    instance.componentWillMount();\n  }\n\n  if (typeof instance.UNSAFE_componentWillMount === 'function') {\n    instance.UNSAFE_componentWillMount();\n  }\n\n  if (oldState !== instance.state) {\n    {\n      error('%s.componentWillMount(): Assigning directly to this.state is ' + \"deprecated (except inside a component's \" + 'constructor). Use setState instead.', getComponentNameFromFiber(workInProgress) || 'Component');\n    }\n\n    classComponentUpdater.enqueueReplaceState(instance, instance.state, null);\n  }\n}\n\nfunction callComponentWillReceiveProps(workInProgress, instance, newProps, nextContext) {\n  var oldState = instance.state;\n\n  if (typeof instance.componentWillReceiveProps === 'function') {\n    instance.componentWillReceiveProps(newProps, nextContext);\n  }\n\n  if (typeof instance.UNSAFE_componentWillReceiveProps === 'function') {\n    instance.UNSAFE_componentWillReceiveProps(newProps, nextContext);\n  }\n\n  if (instance.state !== oldState) {\n    {\n      var componentName = getComponentNameFromFiber(workInProgress) || 'Component';\n\n      if (!didWarnAboutStateAssignmentForComponent.has(componentName)) {\n        didWarnAboutStateAssignmentForComponent.add(componentName);\n\n        error('%s.componentWillReceiveProps(): Assigning directly to ' + \"this.state is deprecated (except inside a component's \" + 'constructor). Use setState instead.', componentName);\n      }\n    }\n\n    classComponentUpdater.enqueueReplaceState(instance, instance.state, null);\n  }\n} // Invokes the mount life-cycles on a previously never rendered instance.\n\n\nfunction mountClassInstance(workInProgress, ctor, newProps, renderLanes) {\n  {\n    checkClassInstance(workInProgress, ctor, newProps);\n  }\n\n  var instance = workInProgress.stateNode;\n  instance.props = newProps;\n  instance.state = workInProgress.memoizedState;\n  instance.refs = emptyRefsObject;\n  initializeUpdateQueue(workInProgress);\n  var contextType = ctor.contextType;\n\n  if (typeof contextType === 'object' && contextType !== null) {\n    instance.context = readContext(contextType);\n  } else {\n    var unmaskedContext = getUnmaskedContext(workInProgress, ctor, true);\n    instance.context = getMaskedContext(workInProgress, unmaskedContext);\n  }\n\n  {\n    if (instance.state === newProps) {\n      var componentName = getComponentNameFromType(ctor) || 'Component';\n\n      if (!didWarnAboutDirectlyAssigningPropsToState.has(componentName)) {\n        didWarnAboutDirectlyAssigningPropsToState.add(componentName);\n\n        error('%s: It is not recommended to assign props directly to state ' + \"because updates to props won't be reflected in state. \" + 'In most cases, it is better to use props directly.', componentName);\n      }\n    }\n\n    if (workInProgress.mode & StrictLegacyMode) {\n      ReactStrictModeWarnings.recordLegacyContextWarning(workInProgress, instance);\n    }\n\n    {\n      ReactStrictModeWarnings.recordUnsafeLifecycleWarnings(workInProgress, instance);\n    }\n  }\n\n  instance.state = workInProgress.memoizedState;\n  var getDerivedStateFromProps = ctor.getDerivedStateFromProps;\n\n  if (typeof getDerivedStateFromProps === 'function') {\n    applyDerivedStateFromProps(workInProgress, ctor, getDerivedStateFromProps, newProps);\n    instance.state = workInProgress.memoizedState;\n  } // In order to support react-lifecycles-compat polyfilled components,\n  // Unsafe lifecycles should not be invoked for components using the new APIs.\n\n\n  if (typeof ctor.getDerivedStateFromProps !== 'function' && typeof instance.getSnapshotBeforeUpdate !== 'function' && (typeof instance.UNSAFE_componentWillMount === 'function' || typeof instance.componentWillMount === 'function')) {\n    callComponentWillMount(workInProgress, instance); // If we had additional state updates during this life-cycle, let's\n    // process them now.\n\n    processUpdateQueue(workInProgress, newProps, instance, renderLanes);\n    instance.state = workInProgress.memoizedState;\n  }\n\n  if (typeof instance.componentDidMount === 'function') {\n    var fiberFlags = Update;\n\n    {\n      fiberFlags |= LayoutStatic;\n    }\n\n    if ( (workInProgress.mode & StrictEffectsMode) !== NoMode) {\n      fiberFlags |= MountLayoutDev;\n    }\n\n    workInProgress.flags |= fiberFlags;\n  }\n}\n\nfunction resumeMountClassInstance(workInProgress, ctor, newProps, renderLanes) {\n  var instance = workInProgress.stateNode;\n  var oldProps = workInProgress.memoizedProps;\n  instance.props = oldProps;\n  var oldContext = instance.context;\n  var contextType = ctor.contextType;\n  var nextContext = emptyContextObject;\n\n  if (typeof contextType === 'object' && contextType !== null) {\n    nextContext = readContext(contextType);\n  } else {\n    var nextLegacyUnmaskedContext = getUnmaskedContext(workInProgress, ctor, true);\n    nextContext = getMaskedContext(workInProgress, nextLegacyUnmaskedContext);\n  }\n\n  var getDerivedStateFromProps = ctor.getDerivedStateFromProps;\n  var hasNewLifecycles = typeof getDerivedStateFromProps === 'function' || typeof instance.getSnapshotBeforeUpdate === 'function'; // Note: During these life-cycles, instance.props/instance.state are what\n  // ever the previously attempted to render - not the \"current\". However,\n  // during componentDidUpdate we pass the \"current\" props.\n  // In order to support react-lifecycles-compat polyfilled components,\n  // Unsafe lifecycles should not be invoked for components using the new APIs.\n\n  if (!hasNewLifecycles && (typeof instance.UNSAFE_componentWillReceiveProps === 'function' || typeof instance.componentWillReceiveProps === 'function')) {\n    if (oldProps !== newProps || oldContext !== nextContext) {\n      callComponentWillReceiveProps(workInProgress, instance, newProps, nextContext);\n    }\n  }\n\n  resetHasForceUpdateBeforeProcessing();\n  var oldState = workInProgress.memoizedState;\n  var newState = instance.state = oldState;\n  processUpdateQueue(workInProgress, newProps, instance, renderLanes);\n  newState = workInProgress.memoizedState;\n\n  if (oldProps === newProps && oldState === newState && !hasContextChanged() && !checkHasForceUpdateAfterProcessing()) {\n    // If an update was already in progress, we should schedule an Update\n    // effect even though we're bailing out, so that cWU/cDU are called.\n    if (typeof instance.componentDidMount === 'function') {\n      var fiberFlags = Update;\n\n      {\n        fiberFlags |= LayoutStatic;\n      }\n\n      if ( (workInProgress.mode & StrictEffectsMode) !== NoMode) {\n        fiberFlags |= MountLayoutDev;\n      }\n\n      workInProgress.flags |= fiberFlags;\n    }\n\n    return false;\n  }\n\n  if (typeof getDerivedStateFromProps === 'function') {\n    applyDerivedStateFromProps(workInProgress, ctor, getDerivedStateFromProps, newProps);\n    newState = workInProgress.memoizedState;\n  }\n\n  var shouldUpdate = checkHasForceUpdateAfterProcessing() || checkShouldComponentUpdate(workInProgress, ctor, oldProps, newProps, oldState, newState, nextContext);\n\n  if (shouldUpdate) {\n    // In order to support react-lifecycles-compat polyfilled components,\n    // Unsafe lifecycles should not be invoked for components using the new APIs.\n    if (!hasNewLifecycles && (typeof instance.UNSAFE_componentWillMount === 'function' || typeof instance.componentWillMount === 'function')) {\n      if (typeof instance.componentWillMount === 'function') {\n        instance.componentWillMount();\n      }\n\n      if (typeof instance.UNSAFE_componentWillMount === 'function') {\n        instance.UNSAFE_componentWillMount();\n      }\n    }\n\n    if (typeof instance.componentDidMount === 'function') {\n      var _fiberFlags = Update;\n\n      {\n        _fiberFlags |= LayoutStatic;\n      }\n\n      if ( (workInProgress.mode & StrictEffectsMode) !== NoMode) {\n        _fiberFlags |= MountLayoutDev;\n      }\n\n      workInProgress.flags |= _fiberFlags;\n    }\n  } else {\n    // If an update was already in progress, we should schedule an Update\n    // effect even though we're bailing out, so that cWU/cDU are called.\n    if (typeof instance.componentDidMount === 'function') {\n      var _fiberFlags2 = Update;\n\n      {\n        _fiberFlags2 |= LayoutStatic;\n      }\n\n      if ( (workInProgress.mode & StrictEffectsMode) !== NoMode) {\n        _fiberFlags2 |= MountLayoutDev;\n      }\n\n      workInProgress.flags |= _fiberFlags2;\n    } // If shouldComponentUpdate returned false, we should still update the\n    // memoized state to indicate that this work can be reused.\n\n\n    workInProgress.memoizedProps = newProps;\n    workInProgress.memoizedState = newState;\n  } // Update the existing instance's state, props, and context pointers even\n  // if shouldComponentUpdate returns false.\n\n\n  instance.props = newProps;\n  instance.state = newState;\n  instance.context = nextContext;\n  return shouldUpdate;\n} // Invokes the update life-cycles and returns false if it shouldn't rerender.\n\n\nfunction updateClassInstance(current, workInProgress, ctor, newProps, renderLanes) {\n  var instance = workInProgress.stateNode;\n  cloneUpdateQueue(current, workInProgress);\n  var unresolvedOldProps = workInProgress.memoizedProps;\n  var oldProps = workInProgress.type === workInProgress.elementType ? unresolvedOldProps : resolveDefaultProps(workInProgress.type, unresolvedOldProps);\n  instance.props = oldProps;\n  var unresolvedNewProps = workInProgress.pendingProps;\n  var oldContext = instance.context;\n  var contextType = ctor.contextType;\n  var nextContext = emptyContextObject;\n\n  if (typeof contextType === 'object' && contextType !== null) {\n    nextContext = readContext(contextType);\n  } else {\n    var nextUnmaskedContext = getUnmaskedContext(workInProgress, ctor, true);\n    nextContext = getMaskedContext(workInProgress, nextUnmaskedContext);\n  }\n\n  var getDerivedStateFromProps = ctor.getDerivedStateFromProps;\n  var hasNewLifecycles = typeof getDerivedStateFromProps === 'function' || typeof instance.getSnapshotBeforeUpdate === 'function'; // Note: During these life-cycles, instance.props/instance.state are what\n  // ever the previously attempted to render - not the \"current\". However,\n  // during componentDidUpdate we pass the \"current\" props.\n  // In order to support react-lifecycles-compat polyfilled components,\n  // Unsafe lifecycles should not be invoked for components using the new APIs.\n\n  if (!hasNewLifecycles && (typeof instance.UNSAFE_componentWillReceiveProps === 'function' || typeof instance.componentWillReceiveProps === 'function')) {\n    if (unresolvedOldProps !== unresolvedNewProps || oldContext !== nextContext) {\n      callComponentWillReceiveProps(workInProgress, instance, newProps, nextContext);\n    }\n  }\n\n  resetHasForceUpdateBeforeProcessing();\n  var oldState = workInProgress.memoizedState;\n  var newState = instance.state = oldState;\n  processUpdateQueue(workInProgress, newProps, instance, renderLanes);\n  newState = workInProgress.memoizedState;\n\n  if (unresolvedOldProps === unresolvedNewProps && oldState === newState && !hasContextChanged() && !checkHasForceUpdateAfterProcessing() && !(enableLazyContextPropagation   )) {\n    // If an update was already in progress, we should schedule an Update\n    // effect even though we're bailing out, so that cWU/cDU are called.\n    if (typeof instance.componentDidUpdate === 'function') {\n      if (unresolvedOldProps !== current.memoizedProps || oldState !== current.memoizedState) {\n        workInProgress.flags |= Update;\n      }\n    }\n\n    if (typeof instance.getSnapshotBeforeUpdate === 'function') {\n      if (unresolvedOldProps !== current.memoizedProps || oldState !== current.memoizedState) {\n        workInProgress.flags |= Snapshot;\n      }\n    }\n\n    return false;\n  }\n\n  if (typeof getDerivedStateFromProps === 'function') {\n    applyDerivedStateFromProps(workInProgress, ctor, getDerivedStateFromProps, newProps);\n    newState = workInProgress.memoizedState;\n  }\n\n  var shouldUpdate = checkHasForceUpdateAfterProcessing() || checkShouldComponentUpdate(workInProgress, ctor, oldProps, newProps, oldState, newState, nextContext) || // TODO: In some cases, we'll end up checking if context has changed twice,\n  // both before and after `shouldComponentUpdate` has been called. Not ideal,\n  // but I'm loath to refactor this function. This only happens for memoized\n  // components so it's not that common.\n  enableLazyContextPropagation   ;\n\n  if (shouldUpdate) {\n    // In order to support react-lifecycles-compat polyfilled components,\n    // Unsafe lifecycles should not be invoked for components using the new APIs.\n    if (!hasNewLifecycles && (typeof instance.UNSAFE_componentWillUpdate === 'function' || typeof instance.componentWillUpdate === 'function')) {\n      if (typeof instance.componentWillUpdate === 'function') {\n        instance.componentWillUpdate(newProps, newState, nextContext);\n      }\n\n      if (typeof instance.UNSAFE_componentWillUpdate === 'function') {\n        instance.UNSAFE_componentWillUpdate(newProps, newState, nextContext);\n      }\n    }\n\n    if (typeof instance.componentDidUpdate === 'function') {\n      workInProgress.flags |= Update;\n    }\n\n    if (typeof instance.getSnapshotBeforeUpdate === 'function') {\n      workInProgress.flags |= Snapshot;\n    }\n  } else {\n    // If an update was already in progress, we should schedule an Update\n    // effect even though we're bailing out, so that cWU/cDU are called.\n    if (typeof instance.componentDidUpdate === 'function') {\n      if (unresolvedOldProps !== current.memoizedProps || oldState !== current.memoizedState) {\n        workInProgress.flags |= Update;\n      }\n    }\n\n    if (typeof instance.getSnapshotBeforeUpdate === 'function') {\n      if (unresolvedOldProps !== current.memoizedProps || oldState !== current.memoizedState) {\n        workInProgress.flags |= Snapshot;\n      }\n    } // If shouldComponentUpdate returned false, we should still update the\n    // memoized props/state to indicate that this work can be reused.\n\n\n    workInProgress.memoizedProps = newProps;\n    workInProgress.memoizedState = newState;\n  } // Update the existing instance's state, props, and context pointers even\n  // if shouldComponentUpdate returns false.\n\n\n  instance.props = newProps;\n  instance.state = newState;\n  instance.context = nextContext;\n  return shouldUpdate;\n}\n\nvar didWarnAboutMaps;\nvar didWarnAboutGenerators;\nvar didWarnAboutStringRefs;\nvar ownerHasKeyUseWarning;\nvar ownerHasFunctionTypeWarning;\n\nvar warnForMissingKey = function (child, returnFiber) {};\n\n{\n  didWarnAboutMaps = false;\n  didWarnAboutGenerators = false;\n  didWarnAboutStringRefs = {};\n  /**\n   * Warn if there's no key explicitly set on dynamic arrays of children or\n   * object keys are not valid. This allows us to keep track of children between\n   * updates.\n   */\n\n  ownerHasKeyUseWarning = {};\n  ownerHasFunctionTypeWarning = {};\n\n  warnForMissingKey = function (child, returnFiber) {\n    if (child === null || typeof child !== 'object') {\n      return;\n    }\n\n    if (!child._store || child._store.validated || child.key != null) {\n      return;\n    }\n\n    if (typeof child._store !== 'object') {\n      throw new Error('React Component in warnForMissingKey should have a _store. ' + 'This error is likely caused by a bug in React. Please file an issue.');\n    }\n\n    child._store.validated = true;\n    var componentName = getComponentNameFromFiber(returnFiber) || 'Component';\n\n    if (ownerHasKeyUseWarning[componentName]) {\n      return;\n    }\n\n    ownerHasKeyUseWarning[componentName] = true;\n\n    error('Each child in a list should have a unique ' + '\"key\" prop. See https://reactjs.org/link/warning-keys for ' + 'more information.');\n  };\n}\n\nfunction coerceRef(returnFiber, current, element) {\n  var mixedRef = element.ref;\n\n  if (mixedRef !== null && typeof mixedRef !== 'function' && typeof mixedRef !== 'object') {\n    {\n      // TODO: Clean this up once we turn on the string ref warning for\n      // everyone, because the strict mode case will no longer be relevant\n      if ((returnFiber.mode & StrictLegacyMode || warnAboutStringRefs) && // We warn in ReactElement.js if owner and self are equal for string refs\n      // because these cannot be automatically converted to an arrow function\n      // using a codemod. Therefore, we don't have to warn about string refs again.\n      !(element._owner && element._self && element._owner.stateNode !== element._self)) {\n        var componentName = getComponentNameFromFiber(returnFiber) || 'Component';\n\n        if (!didWarnAboutStringRefs[componentName]) {\n          {\n            error('A string ref, \"%s\", has been found within a strict mode tree. ' + 'String refs are a source of potential bugs and should be avoided. ' + 'We recommend using useRef() or createRef() instead. ' + 'Learn more about using refs safely here: ' + 'https://reactjs.org/link/strict-mode-string-ref', mixedRef);\n          }\n\n          didWarnAboutStringRefs[componentName] = true;\n        }\n      }\n    }\n\n    if (element._owner) {\n      var owner = element._owner;\n      var inst;\n\n      if (owner) {\n        var ownerFiber = owner;\n\n        if (ownerFiber.tag !== ClassComponent) {\n          throw new Error('Function components cannot have string refs. ' + 'We recommend using useRef() instead. ' + 'Learn more about using refs safely here: ' + 'https://reactjs.org/link/strict-mode-string-ref');\n        }\n\n        inst = ownerFiber.stateNode;\n      }\n\n      if (!inst) {\n        throw new Error(\"Missing owner for string ref \" + mixedRef + \". This error is likely caused by a \" + 'bug in React. Please file an issue.');\n      } // Assigning this to a const so Flow knows it won't change in the closure\n\n\n      var resolvedInst = inst;\n\n      {\n        checkPropStringCoercion(mixedRef, 'ref');\n      }\n\n      var stringRef = '' + mixedRef; // Check if previous string ref matches new string ref\n\n      if (current !== null && current.ref !== null && typeof current.ref === 'function' && current.ref._stringRef === stringRef) {\n        return current.ref;\n      }\n\n      var ref = function (value) {\n        var refs = resolvedInst.refs;\n\n        if (refs === emptyRefsObject) {\n          // This is a lazy pooled frozen object, so we need to initialize.\n          refs = resolvedInst.refs = {};\n        }\n\n        if (value === null) {\n          delete refs[stringRef];\n        } else {\n          refs[stringRef] = value;\n        }\n      };\n\n      ref._stringRef = stringRef;\n      return ref;\n    } else {\n      if (typeof mixedRef !== 'string') {\n        throw new Error('Expected ref to be a function, a string, an object returned by React.createRef(), or null.');\n      }\n\n      if (!element._owner) {\n        throw new Error(\"Element ref was specified as a string (\" + mixedRef + \") but no owner was set. This could happen for one of\" + ' the following reasons:\\n' + '1. You may be adding a ref to a function component\\n' + \"2. You may be adding a ref to a component that was not created inside a component's render method\\n\" + '3. You have multiple copies of React loaded\\n' + 'See https://reactjs.org/link/refs-must-have-owner for more information.');\n      }\n    }\n  }\n\n  return mixedRef;\n}\n\nfunction throwOnInvalidObjectType(returnFiber, newChild) {\n  var childString = Object.prototype.toString.call(newChild);\n  throw new Error(\"Objects are not valid as a React child (found: \" + (childString === '[object Object]' ? 'object with keys {' + Object.keys(newChild).join(', ') + '}' : childString) + \"). \" + 'If you meant to render a collection of children, use an array ' + 'instead.');\n}\n\nfunction warnOnFunctionType(returnFiber) {\n  {\n    var componentName = getComponentNameFromFiber(returnFiber) || 'Component';\n\n    if (ownerHasFunctionTypeWarning[componentName]) {\n      return;\n    }\n\n    ownerHasFunctionTypeWarning[componentName] = true;\n\n    error('Functions are not valid as a React child. This may happen if ' + 'you return a Component instead of <Component /> from render. ' + 'Or maybe you meant to call this function rather than return it.');\n  }\n}\n\nfunction resolveLazy(lazyType) {\n  var payload = lazyType._payload;\n  var init = lazyType._init;\n  return init(payload);\n} // This wrapper function exists because I expect to clone the code in each path\n// to be able to optimize each path individually by branching early. This needs\n// a compiler or we can do it manually. Helpers that don't need this branching\n// live outside of this function.\n\n\nfunction ChildReconciler(shouldTrackSideEffects) {\n  function deleteChild(returnFiber, childToDelete) {\n    if (!shouldTrackSideEffects) {\n      // Noop.\n      return;\n    }\n\n    var deletions = returnFiber.deletions;\n\n    if (deletions === null) {\n      returnFiber.deletions = [childToDelete];\n      returnFiber.flags |= ChildDeletion;\n    } else {\n      deletions.push(childToDelete);\n    }\n  }\n\n  function deleteRemainingChildren(returnFiber, currentFirstChild) {\n    if (!shouldTrackSideEffects) {\n      // Noop.\n      return null;\n    } // TODO: For the shouldClone case, this could be micro-optimized a bit by\n    // assuming that after the first child we've already added everything.\n\n\n    var childToDelete = currentFirstChild;\n\n    while (childToDelete !== null) {\n      deleteChild(returnFiber, childToDelete);\n      childToDelete = childToDelete.sibling;\n    }\n\n    return null;\n  }\n\n  function mapRemainingChildren(returnFiber, currentFirstChild) {\n    // Add the remaining children to a temporary map so that we can find them by\n    // keys quickly. Implicit (null) keys get added to this set with their index\n    // instead.\n    var existingChildren = new Map();\n    var existingChild = currentFirstChild;\n\n    while (existingChild !== null) {\n      if (existingChild.key !== null) {\n        existingChildren.set(existingChild.key, existingChild);\n      } else {\n        existingChildren.set(existingChild.index, existingChild);\n      }\n\n      existingChild = existingChild.sibling;\n    }\n\n    return existingChildren;\n  }\n\n  function useFiber(fiber, pendingProps) {\n    // We currently set sibling to null and index to 0 here because it is easy\n    // to forget to do before returning it. E.g. for the single child case.\n    var clone = createWorkInProgress(fiber, pendingProps);\n    clone.index = 0;\n    clone.sibling = null;\n    return clone;\n  }\n\n  function placeChild(newFiber, lastPlacedIndex, newIndex) {\n    newFiber.index = newIndex;\n\n    if (!shouldTrackSideEffects) {\n      // During hydration, the useId algorithm needs to know which fibers are\n      // part of a list of children (arrays, iterators).\n      newFiber.flags |= Forked;\n      return lastPlacedIndex;\n    }\n\n    var current = newFiber.alternate;\n\n    if (current !== null) {\n      var oldIndex = current.index;\n\n      if (oldIndex < lastPlacedIndex) {\n        // This is a move.\n        newFiber.flags |= Placement;\n        return lastPlacedIndex;\n      } else {\n        // This item can stay in place.\n        return oldIndex;\n      }\n    } else {\n      // This is an insertion.\n      newFiber.flags |= Placement;\n      return lastPlacedIndex;\n    }\n  }\n\n  function placeSingleChild(newFiber) {\n    // This is simpler for the single child case. We only need to do a\n    // placement for inserting new children.\n    if (shouldTrackSideEffects && newFiber.alternate === null) {\n      newFiber.flags |= Placement;\n    }\n\n    return newFiber;\n  }\n\n  function updateTextNode(returnFiber, current, textContent, lanes) {\n    if (current === null || current.tag !== HostText) {\n      // Insert\n      var created = createFiberFromText(textContent, returnFiber.mode, lanes);\n      created.return = returnFiber;\n      return created;\n    } else {\n      // Update\n      var existing = useFiber(current, textContent);\n      existing.return = returnFiber;\n      return existing;\n    }\n  }\n\n  function updateElement(returnFiber, current, element, lanes) {\n    var elementType = element.type;\n\n    if (elementType === REACT_FRAGMENT_TYPE) {\n      return updateFragment(returnFiber, current, element.props.children, lanes, element.key);\n    }\n\n    if (current !== null) {\n      if (current.elementType === elementType || ( // Keep this check inline so it only runs on the false path:\n       isCompatibleFamilyForHotReloading(current, element) ) || // Lazy types should reconcile their resolved type.\n      // We need to do this after the Hot Reloading check above,\n      // because hot reloading has different semantics than prod because\n      // it doesn't resuspend. So we can't let the call below suspend.\n      typeof elementType === 'object' && elementType !== null && elementType.$$typeof === REACT_LAZY_TYPE && resolveLazy(elementType) === current.type) {\n        // Move based on index\n        var existing = useFiber(current, element.props);\n        existing.ref = coerceRef(returnFiber, current, element);\n        existing.return = returnFiber;\n\n        {\n          existing._debugSource = element._source;\n          existing._debugOwner = element._owner;\n        }\n\n        return existing;\n      }\n    } // Insert\n\n\n    var created = createFiberFromElement(element, returnFiber.mode, lanes);\n    created.ref = coerceRef(returnFiber, current, element);\n    created.return = returnFiber;\n    return created;\n  }\n\n  function updatePortal(returnFiber, current, portal, lanes) {\n    if (current === null || current.tag !== HostPortal || current.stateNode.containerInfo !== portal.containerInfo || current.stateNode.implementation !== portal.implementation) {\n      // Insert\n      var created = createFiberFromPortal(portal, returnFiber.mode, lanes);\n      created.return = returnFiber;\n      return created;\n    } else {\n      // Update\n      var existing = useFiber(current, portal.children || []);\n      existing.return = returnFiber;\n      return existing;\n    }\n  }\n\n  function updateFragment(returnFiber, current, fragment, lanes, key) {\n    if (current === null || current.tag !== Fragment) {\n      // Insert\n      var created = createFiberFromFragment(fragment, returnFiber.mode, lanes, key);\n      created.return = returnFiber;\n      return created;\n    } else {\n      // Update\n      var existing = useFiber(current, fragment);\n      existing.return = returnFiber;\n      return existing;\n    }\n  }\n\n  function createChild(returnFiber, newChild, lanes) {\n    if (typeof newChild === 'string' && newChild !== '' || typeof newChild === 'number') {\n      // Text nodes don't have keys. If the previous node is implicitly keyed\n      // we can continue to replace it without aborting even if it is not a text\n      // node.\n      var created = createFiberFromText('' + newChild, returnFiber.mode, lanes);\n      created.return = returnFiber;\n      return created;\n    }\n\n    if (typeof newChild === 'object' && newChild !== null) {\n      switch (newChild.$$typeof) {\n        case REACT_ELEMENT_TYPE:\n          {\n            var _created = createFiberFromElement(newChild, returnFiber.mode, lanes);\n\n            _created.ref = coerceRef(returnFiber, null, newChild);\n            _created.return = returnFiber;\n            return _created;\n          }\n\n        case REACT_PORTAL_TYPE:\n          {\n            var _created2 = createFiberFromPortal(newChild, returnFiber.mode, lanes);\n\n            _created2.return = returnFiber;\n            return _created2;\n          }\n\n        case REACT_LAZY_TYPE:\n          {\n            var payload = newChild._payload;\n            var init = newChild._init;\n            return createChild(returnFiber, init(payload), lanes);\n          }\n      }\n\n      if (isArray(newChild) || getIteratorFn(newChild)) {\n        var _created3 = createFiberFromFragment(newChild, returnFiber.mode, lanes, null);\n\n        _created3.return = returnFiber;\n        return _created3;\n      }\n\n      throwOnInvalidObjectType(returnFiber, newChild);\n    }\n\n    {\n      if (typeof newChild === 'function') {\n        warnOnFunctionType(returnFiber);\n      }\n    }\n\n    return null;\n  }\n\n  function updateSlot(returnFiber, oldFiber, newChild, lanes) {\n    // Update the fiber if the keys match, otherwise return null.\n    var key = oldFiber !== null ? oldFiber.key : null;\n\n    if (typeof newChild === 'string' && newChild !== '' || typeof newChild === 'number') {\n      // Text nodes don't have keys. If the previous node is implicitly keyed\n      // we can continue to replace it without aborting even if it is not a text\n      // node.\n      if (key !== null) {\n        return null;\n      }\n\n      return updateTextNode(returnFiber, oldFiber, '' + newChild, lanes);\n    }\n\n    if (typeof newChild === 'object' && newChild !== null) {\n      switch (newChild.$$typeof) {\n        case REACT_ELEMENT_TYPE:\n          {\n            if (newChild.key === key) {\n              return updateElement(returnFiber, oldFiber, newChild, lanes);\n            } else {\n              return null;\n            }\n          }\n\n        case REACT_PORTAL_TYPE:\n          {\n            if (newChild.key === key) {\n              return updatePortal(returnFiber, oldFiber, newChild, lanes);\n            } else {\n              return null;\n            }\n          }\n\n        case REACT_LAZY_TYPE:\n          {\n            var payload = newChild._payload;\n            var init = newChild._init;\n            return updateSlot(returnFiber, oldFiber, init(payload), lanes);\n          }\n      }\n\n      if (isArray(newChild) || getIteratorFn(newChild)) {\n        if (key !== null) {\n          return null;\n        }\n\n        return updateFragment(returnFiber, oldFiber, newChild, lanes, null);\n      }\n\n      throwOnInvalidObjectType(returnFiber, newChild);\n    }\n\n    {\n      if (typeof newChild === 'function') {\n        warnOnFunctionType(returnFiber);\n      }\n    }\n\n    return null;\n  }\n\n  function updateFromMap(existingChildren, returnFiber, newIdx, newChild, lanes) {\n    if (typeof newChild === 'string' && newChild !== '' || typeof newChild === 'number') {\n      // Text nodes don't have keys, so we neither have to check the old nor\n      // new node for the key. If both are text nodes, they match.\n      var matchedFiber = existingChildren.get(newIdx) || null;\n      return updateTextNode(returnFiber, matchedFiber, '' + newChild, lanes);\n    }\n\n    if (typeof newChild === 'object' && newChild !== null) {\n      switch (newChild.$$typeof) {\n        case REACT_ELEMENT_TYPE:\n          {\n            var _matchedFiber = existingChildren.get(newChild.key === null ? newIdx : newChild.key) || null;\n\n            return updateElement(returnFiber, _matchedFiber, newChild, lanes);\n          }\n\n        case REACT_PORTAL_TYPE:\n          {\n            var _matchedFiber2 = existingChildren.get(newChild.key === null ? newIdx : newChild.key) || null;\n\n            return updatePortal(returnFiber, _matchedFiber2, newChild, lanes);\n          }\n\n        case REACT_LAZY_TYPE:\n          var payload = newChild._payload;\n          var init = newChild._init;\n          return updateFromMap(existingChildren, returnFiber, newIdx, init(payload), lanes);\n      }\n\n      if (isArray(newChild) || getIteratorFn(newChild)) {\n        var _matchedFiber3 = existingChildren.get(newIdx) || null;\n\n        return updateFragment(returnFiber, _matchedFiber3, newChild, lanes, null);\n      }\n\n      throwOnInvalidObjectType(returnFiber, newChild);\n    }\n\n    {\n      if (typeof newChild === 'function') {\n        warnOnFunctionType(returnFiber);\n      }\n    }\n\n    return null;\n  }\n  /**\n   * Warns if there is a duplicate or missing key\n   */\n\n\n  function warnOnInvalidKey(child, knownKeys, returnFiber) {\n    {\n      if (typeof child !== 'object' || child === null) {\n        return knownKeys;\n      }\n\n      switch (child.$$typeof) {\n        case REACT_ELEMENT_TYPE:\n        case REACT_PORTAL_TYPE:\n          warnForMissingKey(child, returnFiber);\n          var key = child.key;\n\n          if (typeof key !== 'string') {\n            break;\n          }\n\n          if (knownKeys === null) {\n            knownKeys = new Set();\n            knownKeys.add(key);\n            break;\n          }\n\n          if (!knownKeys.has(key)) {\n            knownKeys.add(key);\n            break;\n          }\n\n          error('Encountered two children with the same key, `%s`. ' + 'Keys should be unique so that components maintain their identity ' + 'across updates. Non-unique keys may cause children to be ' + 'duplicated and/or omitted  the behavior is unsupported and ' + 'could change in a future version.', key);\n\n          break;\n\n        case REACT_LAZY_TYPE:\n          var payload = child._payload;\n          var init = child._init;\n          warnOnInvalidKey(init(payload), knownKeys, returnFiber);\n          break;\n      }\n    }\n\n    return knownKeys;\n  }\n\n  function reconcileChildrenArray(returnFiber, currentFirstChild, newChildren, lanes) {\n    // This algorithm can't optimize by searching from both ends since we\n    // don't have backpointers on fibers. I'm trying to see how far we can get\n    // with that model. If it ends up not being worth the tradeoffs, we can\n    // add it later.\n    // Even with a two ended optimization, we'd want to optimize for the case\n    // where there are few changes and brute force the comparison instead of\n    // going for the Map. It'd like to explore hitting that path first in\n    // forward-only mode and only go for the Map once we notice that we need\n    // lots of look ahead. This doesn't handle reversal as well as two ended\n    // search but that's unusual. Besides, for the two ended optimization to\n    // work on Iterables, we'd need to copy the whole set.\n    // In this first iteration, we'll just live with hitting the bad case\n    // (adding everything to a Map) in for every insert/move.\n    // If you change this code, also update reconcileChildrenIterator() which\n    // uses the same algorithm.\n    {\n      // First, validate keys.\n      var knownKeys = null;\n\n      for (var i = 0; i < newChildren.length; i++) {\n        var child = newChildren[i];\n        knownKeys = warnOnInvalidKey(child, knownKeys, returnFiber);\n      }\n    }\n\n    var resultingFirstChild = null;\n    var previousNewFiber = null;\n    var oldFiber = currentFirstChild;\n    var lastPlacedIndex = 0;\n    var newIdx = 0;\n    var nextOldFiber = null;\n\n    for (; oldFiber !== null && newIdx < newChildren.length; newIdx++) {\n      if (oldFiber.index > newIdx) {\n        nextOldFiber = oldFiber;\n        oldFiber = null;\n      } else {\n        nextOldFiber = oldFiber.sibling;\n      }\n\n      var newFiber = updateSlot(returnFiber, oldFiber, newChildren[newIdx], lanes);\n\n      if (newFiber === null) {\n        // TODO: This breaks on empty slots like null children. That's\n        // unfortunate because it triggers the slow path all the time. We need\n        // a better way to communicate whether this was a miss or null,\n        // boolean, undefined, etc.\n        if (oldFiber === null) {\n          oldFiber = nextOldFiber;\n        }\n\n        break;\n      }\n\n      if (shouldTrackSideEffects) {\n        if (oldFiber && newFiber.alternate === null) {\n          // We matched the slot, but we didn't reuse the existing fiber, so we\n          // need to delete the existing child.\n          deleteChild(returnFiber, oldFiber);\n        }\n      }\n\n      lastPlacedIndex = placeChild(newFiber, lastPlacedIndex, newIdx);\n\n      if (previousNewFiber === null) {\n        // TODO: Move out of the loop. This only happens for the first run.\n        resultingFirstChild = newFiber;\n      } else {\n        // TODO: Defer siblings if we're not at the right index for this slot.\n        // I.e. if we had null values before, then we want to defer this\n        // for each null value. However, we also don't want to call updateSlot\n        // with the previous one.\n        previousNewFiber.sibling = newFiber;\n      }\n\n      previousNewFiber = newFiber;\n      oldFiber = nextOldFiber;\n    }\n\n    if (newIdx === newChildren.length) {\n      // We've reached the end of the new children. We can delete the rest.\n      deleteRemainingChildren(returnFiber, oldFiber);\n\n      if (getIsHydrating()) {\n        var numberOfForks = newIdx;\n        pushTreeFork(returnFiber, numberOfForks);\n      }\n\n      return resultingFirstChild;\n    }\n\n    if (oldFiber === null) {\n      // If we don't have any more existing children we can choose a fast path\n      // since the rest will all be insertions.\n      for (; newIdx < newChildren.length; newIdx++) {\n        var _newFiber = createChild(returnFiber, newChildren[newIdx], lanes);\n\n        if (_newFiber === null) {\n          continue;\n        }\n\n        lastPlacedIndex = placeChild(_newFiber, lastPlacedIndex, newIdx);\n\n        if (previousNewFiber === null) {\n          // TODO: Move out of the loop. This only happens for the first run.\n          resultingFirstChild = _newFiber;\n        } else {\n          previousNewFiber.sibling = _newFiber;\n        }\n\n        previousNewFiber = _newFiber;\n      }\n\n      if (getIsHydrating()) {\n        var _numberOfForks = newIdx;\n        pushTreeFork(returnFiber, _numberOfForks);\n      }\n\n      return resultingFirstChild;\n    } // Add all children to a key map for quick lookups.\n\n\n    var existingChildren = mapRemainingChildren(returnFiber, oldFiber); // Keep scanning and use the map to restore deleted items as moves.\n\n    for (; newIdx < newChildren.length; newIdx++) {\n      var _newFiber2 = updateFromMap(existingChildren, returnFiber, newIdx, newChildren[newIdx], lanes);\n\n      if (_newFiber2 !== null) {\n        if (shouldTrackSideEffects) {\n          if (_newFiber2.alternate !== null) {\n            // The new fiber is a work in progress, but if there exists a\n            // current, that means that we reused the fiber. We need to delete\n            // it from the child list so that we don't add it to the deletion\n            // list.\n            existingChildren.delete(_newFiber2.key === null ? newIdx : _newFiber2.key);\n          }\n        }\n\n        lastPlacedIndex = placeChild(_newFiber2, lastPlacedIndex, newIdx);\n\n        if (previousNewFiber === null) {\n          resultingFirstChild = _newFiber2;\n        } else {\n          previousNewFiber.sibling = _newFiber2;\n        }\n\n        previousNewFiber = _newFiber2;\n      }\n    }\n\n    if (shouldTrackSideEffects) {\n      // Any existing children that weren't consumed above were deleted. We need\n      // to add them to the deletion list.\n      existingChildren.forEach(function (child) {\n        return deleteChild(returnFiber, child);\n      });\n    }\n\n    if (getIsHydrating()) {\n      var _numberOfForks2 = newIdx;\n      pushTreeFork(returnFiber, _numberOfForks2);\n    }\n\n    return resultingFirstChild;\n  }\n\n  function reconcileChildrenIterator(returnFiber, currentFirstChild, newChildrenIterable, lanes) {\n    // This is the same implementation as reconcileChildrenArray(),\n    // but using the iterator instead.\n    var iteratorFn = getIteratorFn(newChildrenIterable);\n\n    if (typeof iteratorFn !== 'function') {\n      throw new Error('An object is not an iterable. This error is likely caused by a bug in ' + 'React. Please file an issue.');\n    }\n\n    {\n      // We don't support rendering Generators because it's a mutation.\n      // See https://github.com/facebook/react/issues/12995\n      if (typeof Symbol === 'function' && // $FlowFixMe Flow doesn't know about toStringTag\n      newChildrenIterable[Symbol.toStringTag] === 'Generator') {\n        if (!didWarnAboutGenerators) {\n          error('Using Generators as children is unsupported and will likely yield ' + 'unexpected results because enumerating a generator mutates it. ' + 'You may convert it to an array with `Array.from()` or the ' + '`[...spread]` operator before rendering. Keep in mind ' + 'you might need to polyfill these features for older browsers.');\n        }\n\n        didWarnAboutGenerators = true;\n      } // Warn about using Maps as children\n\n\n      if (newChildrenIterable.entries === iteratorFn) {\n        if (!didWarnAboutMaps) {\n          error('Using Maps as children is not supported. ' + 'Use an array of keyed ReactElements instead.');\n        }\n\n        didWarnAboutMaps = true;\n      } // First, validate keys.\n      // We'll get a different iterator later for the main pass.\n\n\n      var _newChildren = iteratorFn.call(newChildrenIterable);\n\n      if (_newChildren) {\n        var knownKeys = null;\n\n        var _step = _newChildren.next();\n\n        for (; !_step.done; _step = _newChildren.next()) {\n          var child = _step.value;\n          knownKeys = warnOnInvalidKey(child, knownKeys, returnFiber);\n        }\n      }\n    }\n\n    var newChildren = iteratorFn.call(newChildrenIterable);\n\n    if (newChildren == null) {\n      throw new Error('An iterable object provided no iterator.');\n    }\n\n    var resultingFirstChild = null;\n    var previousNewFiber = null;\n    var oldFiber = currentFirstChild;\n    var lastPlacedIndex = 0;\n    var newIdx = 0;\n    var nextOldFiber = null;\n    var step = newChildren.next();\n\n    for (; oldFiber !== null && !step.done; newIdx++, step = newChildren.next()) {\n      if (oldFiber.index > newIdx) {\n        nextOldFiber = oldFiber;\n        oldFiber = null;\n      } else {\n        nextOldFiber = oldFiber.sibling;\n      }\n\n      var newFiber = updateSlot(returnFiber, oldFiber, step.value, lanes);\n\n      if (newFiber === null) {\n        // TODO: This breaks on empty slots like null children. That's\n        // unfortunate because it triggers the slow path all the time. We need\n        // a better way to communicate whether this was a miss or null,\n        // boolean, undefined, etc.\n        if (oldFiber === null) {\n          oldFiber = nextOldFiber;\n        }\n\n        break;\n      }\n\n      if (shouldTrackSideEffects) {\n        if (oldFiber && newFiber.alternate === null) {\n          // We matched the slot, but we didn't reuse the existing fiber, so we\n          // need to delete the existing child.\n          deleteChild(returnFiber, oldFiber);\n        }\n      }\n\n      lastPlacedIndex = placeChild(newFiber, lastPlacedIndex, newIdx);\n\n      if (previousNewFiber === null) {\n        // TODO: Move out of the loop. This only happens for the first run.\n        resultingFirstChild = newFiber;\n      } else {\n        // TODO: Defer siblings if we're not at the right index for this slot.\n        // I.e. if we had null values before, then we want to defer this\n        // for each null value. However, we also don't want to call updateSlot\n        // with the previous one.\n        previousNewFiber.sibling = newFiber;\n      }\n\n      previousNewFiber = newFiber;\n      oldFiber = nextOldFiber;\n    }\n\n    if (step.done) {\n      // We've reached the end of the new children. We can delete the rest.\n      deleteRemainingChildren(returnFiber, oldFiber);\n\n      if (getIsHydrating()) {\n        var numberOfForks = newIdx;\n        pushTreeFork(returnFiber, numberOfForks);\n      }\n\n      return resultingFirstChild;\n    }\n\n    if (oldFiber === null) {\n      // If we don't have any more existing children we can choose a fast path\n      // since the rest will all be insertions.\n      for (; !step.done; newIdx++, step = newChildren.next()) {\n        var _newFiber3 = createChild(returnFiber, step.value, lanes);\n\n        if (_newFiber3 === null) {\n          continue;\n        }\n\n        lastPlacedIndex = placeChild(_newFiber3, lastPlacedIndex, newIdx);\n\n        if (previousNewFiber === null) {\n          // TODO: Move out of the loop. This only happens for the first run.\n          resultingFirstChild = _newFiber3;\n        } else {\n          previousNewFiber.sibling = _newFiber3;\n        }\n\n        previousNewFiber = _newFiber3;\n      }\n\n      if (getIsHydrating()) {\n        var _numberOfForks3 = newIdx;\n        pushTreeFork(returnFiber, _numberOfForks3);\n      }\n\n      return resultingFirstChild;\n    } // Add all children to a key map for quick lookups.\n\n\n    var existingChildren = mapRemainingChildren(returnFiber, oldFiber); // Keep scanning and use the map to restore deleted items as moves.\n\n    for (; !step.done; newIdx++, step = newChildren.next()) {\n      var _newFiber4 = updateFromMap(existingChildren, returnFiber, newIdx, step.value, lanes);\n\n      if (_newFiber4 !== null) {\n        if (shouldTrackSideEffects) {\n          if (_newFiber4.alternate !== null) {\n            // The new fiber is a work in progress, but if there exists a\n            // current, that means that we reused the fiber. We need to delete\n            // it from the child list so that we don't add it to the deletion\n            // list.\n            existingChildren.delete(_newFiber4.key === null ? newIdx : _newFiber4.key);\n          }\n        }\n\n        lastPlacedIndex = placeChild(_newFiber4, lastPlacedIndex, newIdx);\n\n        if (previousNewFiber === null) {\n          resultingFirstChild = _newFiber4;\n        } else {\n          previousNewFiber.sibling = _newFiber4;\n        }\n\n        previousNewFiber = _newFiber4;\n      }\n    }\n\n    if (shouldTrackSideEffects) {\n      // Any existing children that weren't consumed above were deleted. We need\n      // to add them to the deletion list.\n      existingChildren.forEach(function (child) {\n        return deleteChild(returnFiber, child);\n      });\n    }\n\n    if (getIsHydrating()) {\n      var _numberOfForks4 = newIdx;\n      pushTreeFork(returnFiber, _numberOfForks4);\n    }\n\n    return resultingFirstChild;\n  }\n\n  function reconcileSingleTextNode(returnFiber, currentFirstChild, textContent, lanes) {\n    // There's no need to check for keys on text nodes since we don't have a\n    // way to define them.\n    if (currentFirstChild !== null && currentFirstChild.tag === HostText) {\n      // We already have an existing node so let's just update it and delete\n      // the rest.\n      deleteRemainingChildren(returnFiber, currentFirstChild.sibling);\n      var existing = useFiber(currentFirstChild, textContent);\n      existing.return = returnFiber;\n      return existing;\n    } // The existing first child is not a text node so we need to create one\n    // and delete the existing ones.\n\n\n    deleteRemainingChildren(returnFiber, currentFirstChild);\n    var created = createFiberFromText(textContent, returnFiber.mode, lanes);\n    created.return = returnFiber;\n    return created;\n  }\n\n  function reconcileSingleElement(returnFiber, currentFirstChild, element, lanes) {\n    var key = element.key;\n    var child = currentFirstChild;\n\n    while (child !== null) {\n      // TODO: If key === null and child.key === null, then this only applies to\n      // the first item in the list.\n      if (child.key === key) {\n        var elementType = element.type;\n\n        if (elementType === REACT_FRAGMENT_TYPE) {\n          if (child.tag === Fragment) {\n            deleteRemainingChildren(returnFiber, child.sibling);\n            var existing = useFiber(child, element.props.children);\n            existing.return = returnFiber;\n\n            {\n              existing._debugSource = element._source;\n              existing._debugOwner = element._owner;\n            }\n\n            return existing;\n          }\n        } else {\n          if (child.elementType === elementType || ( // Keep this check inline so it only runs on the false path:\n           isCompatibleFamilyForHotReloading(child, element) ) || // Lazy types should reconcile their resolved type.\n          // We need to do this after the Hot Reloading check above,\n          // because hot reloading has different semantics than prod because\n          // it doesn't resuspend. So we can't let the call below suspend.\n          typeof elementType === 'object' && elementType !== null && elementType.$$typeof === REACT_LAZY_TYPE && resolveLazy(elementType) === child.type) {\n            deleteRemainingChildren(returnFiber, child.sibling);\n\n            var _existing = useFiber(child, element.props);\n\n            _existing.ref = coerceRef(returnFiber, child, element);\n            _existing.return = returnFiber;\n\n            {\n              _existing._debugSource = element._source;\n              _existing._debugOwner = element._owner;\n            }\n\n            return _existing;\n          }\n        } // Didn't match.\n\n\n        deleteRemainingChildren(returnFiber, child);\n        break;\n      } else {\n        deleteChild(returnFiber, child);\n      }\n\n      child = child.sibling;\n    }\n\n    if (element.type === REACT_FRAGMENT_TYPE) {\n      var created = createFiberFromFragment(element.props.children, returnFiber.mode, lanes, element.key);\n      created.return = returnFiber;\n      return created;\n    } else {\n      var _created4 = createFiberFromElement(element, returnFiber.mode, lanes);\n\n      _created4.ref = coerceRef(returnFiber, currentFirstChild, element);\n      _created4.return = returnFiber;\n      return _created4;\n    }\n  }\n\n  function reconcileSinglePortal(returnFiber, currentFirstChild, portal, lanes) {\n    var key = portal.key;\n    var child = currentFirstChild;\n\n    while (child !== null) {\n      // TODO: If key === null and child.key === null, then this only applies to\n      // the first item in the list.\n      if (child.key === key) {\n        if (child.tag === HostPortal && child.stateNode.containerInfo === portal.containerInfo && child.stateNode.implementation === portal.implementation) {\n          deleteRemainingChildren(returnFiber, child.sibling);\n          var existing = useFiber(child, portal.children || []);\n          existing.return = returnFiber;\n          return existing;\n        } else {\n          deleteRemainingChildren(returnFiber, child);\n          break;\n        }\n      } else {\n        deleteChild(returnFiber, child);\n      }\n\n      child = child.sibling;\n    }\n\n    var created = createFiberFromPortal(portal, returnFiber.mode, lanes);\n    created.return = returnFiber;\n    return created;\n  } // This API will tag the children with the side-effect of the reconciliation\n  // itself. They will be added to the side-effect list as we pass through the\n  // children and the parent.\n\n\n  function reconcileChildFibers(returnFiber, currentFirstChild, newChild, lanes) {\n    // This function is not recursive.\n    // If the top level item is an array, we treat it as a set of children,\n    // not as a fragment. Nested arrays on the other hand will be treated as\n    // fragment nodes. Recursion happens at the normal flow.\n    // Handle top level unkeyed fragments as if they were arrays.\n    // This leads to an ambiguity between <>{[...]}</> and <>...</>.\n    // We treat the ambiguous cases above the same.\n    var isUnkeyedTopLevelFragment = typeof newChild === 'object' && newChild !== null && newChild.type === REACT_FRAGMENT_TYPE && newChild.key === null;\n\n    if (isUnkeyedTopLevelFragment) {\n      newChild = newChild.props.children;\n    } // Handle object types\n\n\n    if (typeof newChild === 'object' && newChild !== null) {\n      switch (newChild.$$typeof) {\n        case REACT_ELEMENT_TYPE:\n          return placeSingleChild(reconcileSingleElement(returnFiber, currentFirstChild, newChild, lanes));\n\n        case REACT_PORTAL_TYPE:\n          return placeSingleChild(reconcileSinglePortal(returnFiber, currentFirstChild, newChild, lanes));\n\n        case REACT_LAZY_TYPE:\n          var payload = newChild._payload;\n          var init = newChild._init; // TODO: This function is supposed to be non-recursive.\n\n          return reconcileChildFibers(returnFiber, currentFirstChild, init(payload), lanes);\n      }\n\n      if (isArray(newChild)) {\n        return reconcileChildrenArray(returnFiber, currentFirstChild, newChild, lanes);\n      }\n\n      if (getIteratorFn(newChild)) {\n        return reconcileChildrenIterator(returnFiber, currentFirstChild, newChild, lanes);\n      }\n\n      throwOnInvalidObjectType(returnFiber, newChild);\n    }\n\n    if (typeof newChild === 'string' && newChild !== '' || typeof newChild === 'number') {\n      return placeSingleChild(reconcileSingleTextNode(returnFiber, currentFirstChild, '' + newChild, lanes));\n    }\n\n    {\n      if (typeof newChild === 'function') {\n        warnOnFunctionType(returnFiber);\n      }\n    } // Remaining cases are all treated as empty.\n\n\n    return deleteRemainingChildren(returnFiber, currentFirstChild);\n  }\n\n  return reconcileChildFibers;\n}\n\nvar reconcileChildFibers = ChildReconciler(true);\nvar mountChildFibers = ChildReconciler(false);\nfunction cloneChildFibers(current, workInProgress) {\n  if (current !== null && workInProgress.child !== current.child) {\n    throw new Error('Resuming work not yet implemented.');\n  }\n\n  if (workInProgress.child === null) {\n    return;\n  }\n\n  var currentChild = workInProgress.child;\n  var newChild = createWorkInProgress(currentChild, currentChild.pendingProps);\n  workInProgress.child = newChild;\n  newChild.return = workInProgress;\n\n  while (currentChild.sibling !== null) {\n    currentChild = currentChild.sibling;\n    newChild = newChild.sibling = createWorkInProgress(currentChild, currentChild.pendingProps);\n    newChild.return = workInProgress;\n  }\n\n  newChild.sibling = null;\n} // Reset a workInProgress child set to prepare it for a second pass.\n\nfunction resetChildFibers(workInProgress, lanes) {\n  var child = workInProgress.child;\n\n  while (child !== null) {\n    resetWorkInProgress(child, lanes);\n    child = child.sibling;\n  }\n}\n\nvar NO_CONTEXT = {};\nvar contextStackCursor$1 = createCursor(NO_CONTEXT);\nvar contextFiberStackCursor = createCursor(NO_CONTEXT);\nvar rootInstanceStackCursor = createCursor(NO_CONTEXT);\n\nfunction requiredContext(c) {\n  if (c === NO_CONTEXT) {\n    throw new Error('Expected host context to exist. This error is likely caused by a bug ' + 'in React. Please file an issue.');\n  }\n\n  return c;\n}\n\nfunction getRootHostContainer() {\n  var rootInstance = requiredContext(rootInstanceStackCursor.current);\n  return rootInstance;\n}\n\nfunction pushHostContainer(fiber, nextRootInstance) {\n  // Push current root instance onto the stack;\n  // This allows us to reset root when portals are popped.\n  push(rootInstanceStackCursor, nextRootInstance, fiber); // Track the context and the Fiber that provided it.\n  // This enables us to pop only Fibers that provide unique contexts.\n\n  push(contextFiberStackCursor, fiber, fiber); // Finally, we need to push the host context to the stack.\n  // However, we can't just call getRootHostContext() and push it because\n  // we'd have a different number of entries on the stack depending on\n  // whether getRootHostContext() throws somewhere in renderer code or not.\n  // So we push an empty value first. This lets us safely unwind on errors.\n\n  push(contextStackCursor$1, NO_CONTEXT, fiber);\n  var nextRootContext = getRootHostContext(nextRootInstance); // Now that we know this function doesn't throw, replace it.\n\n  pop(contextStackCursor$1, fiber);\n  push(contextStackCursor$1, nextRootContext, fiber);\n}\n\nfunction popHostContainer(fiber) {\n  pop(contextStackCursor$1, fiber);\n  pop(contextFiberStackCursor, fiber);\n  pop(rootInstanceStackCursor, fiber);\n}\n\nfunction getHostContext() {\n  var context = requiredContext(contextStackCursor$1.current);\n  return context;\n}\n\nfunction pushHostContext(fiber) {\n  var rootInstance = requiredContext(rootInstanceStackCursor.current);\n  var context = requiredContext(contextStackCursor$1.current);\n  var nextContext = getChildHostContext(context, fiber.type); // Don't push this Fiber's context unless it's unique.\n\n  if (context === nextContext) {\n    return;\n  } // Track the context and the Fiber that provided it.\n  // This enables us to pop only Fibers that provide unique contexts.\n\n\n  push(contextFiberStackCursor, fiber, fiber);\n  push(contextStackCursor$1, nextContext, fiber);\n}\n\nfunction popHostContext(fiber) {\n  // Do not pop unless this Fiber provided the current context.\n  // pushHostContext() only pushes Fibers that provide unique contexts.\n  if (contextFiberStackCursor.current !== fiber) {\n    return;\n  }\n\n  pop(contextStackCursor$1, fiber);\n  pop(contextFiberStackCursor, fiber);\n}\n\nvar DefaultSuspenseContext = 0; // The Suspense Context is split into two parts. The lower bits is\n// inherited deeply down the subtree. The upper bits only affect\n// this immediate suspense boundary and gets reset each new\n// boundary or suspense list.\n\nvar SubtreeSuspenseContextMask = 1; // Subtree Flags:\n// InvisibleParentSuspenseContext indicates that one of our parent Suspense\n// boundaries is not currently showing visible main content.\n// Either because it is already showing a fallback or is not mounted at all.\n// We can use this to determine if it is desirable to trigger a fallback at\n// the parent. If not, then we might need to trigger undesirable boundaries\n// and/or suspend the commit to avoid hiding the parent content.\n\nvar InvisibleParentSuspenseContext = 1; // Shallow Flags:\n// ForceSuspenseFallback can be used by SuspenseList to force newly added\n// items into their fallback state during one of the render passes.\n\nvar ForceSuspenseFallback = 2;\nvar suspenseStackCursor = createCursor(DefaultSuspenseContext);\nfunction hasSuspenseContext(parentContext, flag) {\n  return (parentContext & flag) !== 0;\n}\nfunction setDefaultShallowSuspenseContext(parentContext) {\n  return parentContext & SubtreeSuspenseContextMask;\n}\nfunction setShallowSuspenseContext(parentContext, shallowContext) {\n  return parentContext & SubtreeSuspenseContextMask | shallowContext;\n}\nfunction addSubtreeSuspenseContext(parentContext, subtreeContext) {\n  return parentContext | subtreeContext;\n}\nfunction pushSuspenseContext(fiber, newContext) {\n  push(suspenseStackCursor, newContext, fiber);\n}\nfunction popSuspenseContext(fiber) {\n  pop(suspenseStackCursor, fiber);\n}\n\nfunction shouldCaptureSuspense(workInProgress, hasInvisibleParent) {\n  // If it was the primary children that just suspended, capture and render the\n  // fallback. Otherwise, don't capture and bubble to the next boundary.\n  var nextState = workInProgress.memoizedState;\n\n  if (nextState !== null) {\n    if (nextState.dehydrated !== null) {\n      // A dehydrated boundary always captures.\n      return true;\n    }\n\n    return false;\n  }\n\n  var props = workInProgress.memoizedProps; // Regular boundaries always capture.\n\n  {\n    return true;\n  } // If it's a boundary we should avoid, then we prefer to bubble up to the\n}\nfunction findFirstSuspended(row) {\n  var node = row;\n\n  while (node !== null) {\n    if (node.tag === SuspenseComponent) {\n      var state = node.memoizedState;\n\n      if (state !== null) {\n        var dehydrated = state.dehydrated;\n\n        if (dehydrated === null || isSuspenseInstancePending(dehydrated) || isSuspenseInstanceFallback(dehydrated)) {\n          return node;\n        }\n      }\n    } else if (node.tag === SuspenseListComponent && // revealOrder undefined can't be trusted because it don't\n    // keep track of whether it suspended or not.\n    node.memoizedProps.revealOrder !== undefined) {\n      var didSuspend = (node.flags & DidCapture) !== NoFlags;\n\n      if (didSuspend) {\n        return node;\n      }\n    } else if (node.child !== null) {\n      node.child.return = node;\n      node = node.child;\n      continue;\n    }\n\n    if (node === row) {\n      return null;\n    }\n\n    while (node.sibling === null) {\n      if (node.return === null || node.return === row) {\n        return null;\n      }\n\n      node = node.return;\n    }\n\n    node.sibling.return = node.return;\n    node = node.sibling;\n  }\n\n  return null;\n}\n\nvar NoFlags$1 =\n/*   */\n0; // Represents whether effect should fire.\n\nvar HasEffect =\n/* */\n1; // Represents the phase in which the effect (not the clean-up) fires.\n\nvar Insertion =\n/*  */\n2;\nvar Layout =\n/*    */\n4;\nvar Passive$1 =\n/*   */\n8;\n\n// and should be reset before starting a new render.\n// This tracks which mutable sources need to be reset after a render.\n\nvar workInProgressSources = [];\nfunction resetWorkInProgressVersions() {\n  for (var i = 0; i < workInProgressSources.length; i++) {\n    var mutableSource = workInProgressSources[i];\n\n    {\n      mutableSource._workInProgressVersionPrimary = null;\n    }\n  }\n\n  workInProgressSources.length = 0;\n}\n// This ensures that the version used for server rendering matches the one\n// that is eventually read during hydration.\n// If they don't match there's a potential tear and a full deopt render is required.\n\nfunction registerMutableSourceForHydration(root, mutableSource) {\n  var getVersion = mutableSource._getVersion;\n  var version = getVersion(mutableSource._source); // TODO Clear this data once all pending hydration work is finished.\n  // Retaining it forever may interfere with GC.\n\n  if (root.mutableSourceEagerHydrationData == null) {\n    root.mutableSourceEagerHydrationData = [mutableSource, version];\n  } else {\n    root.mutableSourceEagerHydrationData.push(mutableSource, version);\n  }\n}\n\nvar ReactCurrentDispatcher$1 = ReactSharedInternals.ReactCurrentDispatcher,\n    ReactCurrentBatchConfig$2 = ReactSharedInternals.ReactCurrentBatchConfig;\nvar didWarnAboutMismatchedHooksForComponent;\nvar didWarnUncachedGetSnapshot;\n\n{\n  didWarnAboutMismatchedHooksForComponent = new Set();\n}\n\n// These are set right before calling the component.\nvar renderLanes = NoLanes; // The work-in-progress fiber. I've named it differently to distinguish it from\n// the work-in-progress hook.\n\nvar currentlyRenderingFiber$1 = null; // Hooks are stored as a linked list on the fiber's memoizedState field. The\n// current hook list is the list that belongs to the current fiber. The\n// work-in-progress hook list is a new list that will be added to the\n// work-in-progress fiber.\n\nvar currentHook = null;\nvar workInProgressHook = null; // Whether an update was scheduled at any point during the render phase. This\n// does not get reset if we do another render pass; only when we're completely\n// finished evaluating this component. This is an optimization so we know\n// whether we need to clear render phase updates after a throw.\n\nvar didScheduleRenderPhaseUpdate = false; // Where an update was scheduled only during the current render pass. This\n// gets reset after each attempt.\n// TODO: Maybe there's some way to consolidate this with\n// `didScheduleRenderPhaseUpdate`. Or with `numberOfReRenders`.\n\nvar didScheduleRenderPhaseUpdateDuringThisPass = false; // Counts the number of useId hooks in this component.\n\nvar localIdCounter = 0; // Used for ids that are generated completely client-side (i.e. not during\n// hydration). This counter is global, so client ids are not stable across\n// render attempts.\n\nvar globalClientIdCounter = 0;\nvar RE_RENDER_LIMIT = 25; // In DEV, this is the name of the currently executing primitive hook\n\nvar currentHookNameInDev = null; // In DEV, this list ensures that hooks are called in the same order between renders.\n// The list stores the order of hooks used during the initial render (mount).\n// Subsequent renders (updates) reference this list.\n\nvar hookTypesDev = null;\nvar hookTypesUpdateIndexDev = -1; // In DEV, this tracks whether currently rendering component needs to ignore\n// the dependencies for Hooks that need them (e.g. useEffect or useMemo).\n// When true, such Hooks will always be \"remounted\". Only used during hot reload.\n\nvar ignorePreviousDependencies = false;\n\nfunction mountHookTypesDev() {\n  {\n    var hookName = currentHookNameInDev;\n\n    if (hookTypesDev === null) {\n      hookTypesDev = [hookName];\n    } else {\n      hookTypesDev.push(hookName);\n    }\n  }\n}\n\nfunction updateHookTypesDev() {\n  {\n    var hookName = currentHookNameInDev;\n\n    if (hookTypesDev !== null) {\n      hookTypesUpdateIndexDev++;\n\n      if (hookTypesDev[hookTypesUpdateIndexDev] !== hookName) {\n        warnOnHookMismatchInDev(hookName);\n      }\n    }\n  }\n}\n\nfunction checkDepsAreArrayDev(deps) {\n  {\n    if (deps !== undefined && deps !== null && !isArray(deps)) {\n      // Verify deps, but only on mount to avoid extra checks.\n      // It's unlikely their type would change as usually you define them inline.\n      error('%s received a final argument that is not an array (instead, received `%s`). When ' + 'specified, the final argument must be an array.', currentHookNameInDev, typeof deps);\n    }\n  }\n}\n\nfunction warnOnHookMismatchInDev(currentHookName) {\n  {\n    var componentName = getComponentNameFromFiber(currentlyRenderingFiber$1);\n\n    if (!didWarnAboutMismatchedHooksForComponent.has(componentName)) {\n      didWarnAboutMismatchedHooksForComponent.add(componentName);\n\n      if (hookTypesDev !== null) {\n        var table = '';\n        var secondColumnStart = 30;\n\n        for (var i = 0; i <= hookTypesUpdateIndexDev; i++) {\n          var oldHookName = hookTypesDev[i];\n          var newHookName = i === hookTypesUpdateIndexDev ? currentHookName : oldHookName;\n          var row = i + 1 + \". \" + oldHookName; // Extra space so second column lines up\n          // lol @ IE not supporting String#repeat\n\n          while (row.length < secondColumnStart) {\n            row += ' ';\n          }\n\n          row += newHookName + '\\n';\n          table += row;\n        }\n\n        error('React has detected a change in the order of Hooks called by %s. ' + 'This will lead to bugs and errors if not fixed. ' + 'For more information, read the Rules of Hooks: https://reactjs.org/link/rules-of-hooks\\n\\n' + '   Previous render            Next render\\n' + '   ------------------------------------------------------\\n' + '%s' + '   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n', componentName, table);\n      }\n    }\n  }\n}\n\nfunction throwInvalidHookError() {\n  throw new Error('Invalid hook call. Hooks can only be called inside of the body of a function component. This could happen for' + ' one of the following reasons:\\n' + '1. You might have mismatching versions of React and the renderer (such as React DOM)\\n' + '2. You might be breaking the Rules of Hooks\\n' + '3. You might have more than one copy of React in the same app\\n' + 'See https://reactjs.org/link/invalid-hook-call for tips about how to debug and fix this problem.');\n}\n\nfunction areHookInputsEqual(nextDeps, prevDeps) {\n  {\n    if (ignorePreviousDependencies) {\n      // Only true when this component is being hot reloaded.\n      return false;\n    }\n  }\n\n  if (prevDeps === null) {\n    {\n      error('%s received a final argument during this render, but not during ' + 'the previous render. Even though the final argument is optional, ' + 'its type cannot change between renders.', currentHookNameInDev);\n    }\n\n    return false;\n  }\n\n  {\n    // Don't bother comparing lengths in prod because these arrays should be\n    // passed inline.\n    if (nextDeps.length !== prevDeps.length) {\n      error('The final argument passed to %s changed size between renders. The ' + 'order and size of this array must remain constant.\\n\\n' + 'Previous: %s\\n' + 'Incoming: %s', currentHookNameInDev, \"[\" + prevDeps.join(', ') + \"]\", \"[\" + nextDeps.join(', ') + \"]\");\n    }\n  }\n\n  for (var i = 0; i < prevDeps.length && i < nextDeps.length; i++) {\n    if (objectIs(nextDeps[i], prevDeps[i])) {\n      continue;\n    }\n\n    return false;\n  }\n\n  return true;\n}\n\nfunction renderWithHooks(current, workInProgress, Component, props, secondArg, nextRenderLanes) {\n  renderLanes = nextRenderLanes;\n  currentlyRenderingFiber$1 = workInProgress;\n\n  {\n    hookTypesDev = current !== null ? current._debugHookTypes : null;\n    hookTypesUpdateIndexDev = -1; // Used for hot reloading:\n\n    ignorePreviousDependencies = current !== null && current.type !== workInProgress.type;\n  }\n\n  workInProgress.memoizedState = null;\n  workInProgress.updateQueue = null;\n  workInProgress.lanes = NoLanes; // The following should have already been reset\n  // currentHook = null;\n  // workInProgressHook = null;\n  // didScheduleRenderPhaseUpdate = false;\n  // localIdCounter = 0;\n  // TODO Warn if no hooks are used at all during mount, then some are used during update.\n  // Currently we will identify the update render as a mount because memoizedState === null.\n  // This is tricky because it's valid for certain types of components (e.g. React.lazy)\n  // Using memoizedState to differentiate between mount/update only works if at least one stateful hook is used.\n  // Non-stateful hooks (e.g. context) don't get added to memoizedState,\n  // so memoizedState would be null during updates and mounts.\n\n  {\n    if (current !== null && current.memoizedState !== null) {\n      ReactCurrentDispatcher$1.current = HooksDispatcherOnUpdateInDEV;\n    } else if (hookTypesDev !== null) {\n      // This dispatcher handles an edge case where a component is updating,\n      // but no stateful hooks have been used.\n      // We want to match the production code behavior (which will use HooksDispatcherOnMount),\n      // but with the extra DEV validation to ensure hooks ordering hasn't changed.\n      // This dispatcher does that.\n      ReactCurrentDispatcher$1.current = HooksDispatcherOnMountWithHookTypesInDEV;\n    } else {\n      ReactCurrentDispatcher$1.current = HooksDispatcherOnMountInDEV;\n    }\n  }\n\n  var children = Component(props, secondArg); // Check if there was a render phase update\n\n  if (didScheduleRenderPhaseUpdateDuringThisPass) {\n    // Keep rendering in a loop for as long as render phase updates continue to\n    // be scheduled. Use a counter to prevent infinite loops.\n    var numberOfReRenders = 0;\n\n    do {\n      didScheduleRenderPhaseUpdateDuringThisPass = false;\n      localIdCounter = 0;\n\n      if (numberOfReRenders >= RE_RENDER_LIMIT) {\n        throw new Error('Too many re-renders. React limits the number of renders to prevent ' + 'an infinite loop.');\n      }\n\n      numberOfReRenders += 1;\n\n      {\n        // Even when hot reloading, allow dependencies to stabilize\n        // after first render to prevent infinite render phase updates.\n        ignorePreviousDependencies = false;\n      } // Start over from the beginning of the list\n\n\n      currentHook = null;\n      workInProgressHook = null;\n      workInProgress.updateQueue = null;\n\n      {\n        // Also validate hook order for cascading updates.\n        hookTypesUpdateIndexDev = -1;\n      }\n\n      ReactCurrentDispatcher$1.current =  HooksDispatcherOnRerenderInDEV ;\n      children = Component(props, secondArg);\n    } while (didScheduleRenderPhaseUpdateDuringThisPass);\n  } // We can assume the previous dispatcher is always this one, since we set it\n  // at the beginning of the render phase and there's no re-entrance.\n\n\n  ReactCurrentDispatcher$1.current = ContextOnlyDispatcher;\n\n  {\n    workInProgress._debugHookTypes = hookTypesDev;\n  } // This check uses currentHook so that it works the same in DEV and prod bundles.\n  // hookTypesDev could catch more cases (e.g. context) but only in DEV bundles.\n\n\n  var didRenderTooFewHooks = currentHook !== null && currentHook.next !== null;\n  renderLanes = NoLanes;\n  currentlyRenderingFiber$1 = null;\n  currentHook = null;\n  workInProgressHook = null;\n\n  {\n    currentHookNameInDev = null;\n    hookTypesDev = null;\n    hookTypesUpdateIndexDev = -1; // Confirm that a static flag was not added or removed since the last\n    // render. If this fires, it suggests that we incorrectly reset the static\n    // flags in some other part of the codebase. This has happened before, for\n    // example, in the SuspenseList implementation.\n\n    if (current !== null && (current.flags & StaticMask) !== (workInProgress.flags & StaticMask) && // Disable this warning in legacy mode, because legacy Suspense is weird\n    // and creates false positives. To make this work in legacy mode, we'd\n    // need to mark fibers that commit in an incomplete state, somehow. For\n    // now I'll disable the warning that most of the bugs that would trigger\n    // it are either exclusive to concurrent mode or exist in both.\n    (current.mode & ConcurrentMode) !== NoMode) {\n      error('Internal React error: Expected static flag was missing. Please ' + 'notify the React team.');\n    }\n  }\n\n  didScheduleRenderPhaseUpdate = false; // This is reset by checkDidRenderIdHook\n  // localIdCounter = 0;\n\n  if (didRenderTooFewHooks) {\n    throw new Error('Rendered fewer hooks than expected. This may be caused by an accidental ' + 'early return statement.');\n  }\n\n  return children;\n}\nfunction checkDidRenderIdHook() {\n  // This should be called immediately after every renderWithHooks call.\n  // Conceptually, it's part of the return value of renderWithHooks; it's only a\n  // separate function to avoid using an array tuple.\n  var didRenderIdHook = localIdCounter !== 0;\n  localIdCounter = 0;\n  return didRenderIdHook;\n}\nfunction bailoutHooks(current, workInProgress, lanes) {\n  workInProgress.updateQueue = current.updateQueue; // TODO: Don't need to reset the flags here, because they're reset in the\n  // complete phase (bubbleProperties).\n\n  if ( (workInProgress.mode & StrictEffectsMode) !== NoMode) {\n    workInProgress.flags &= ~(MountPassiveDev | MountLayoutDev | Passive | Update);\n  } else {\n    workInProgress.flags &= ~(Passive | Update);\n  }\n\n  current.lanes = removeLanes(current.lanes, lanes);\n}\nfunction resetHooksAfterThrow() {\n  // We can assume the previous dispatcher is always this one, since we set it\n  // at the beginning of the render phase and there's no re-entrance.\n  ReactCurrentDispatcher$1.current = ContextOnlyDispatcher;\n\n  if (didScheduleRenderPhaseUpdate) {\n    // There were render phase updates. These are only valid for this render\n    // phase, which we are now aborting. Remove the updates from the queues so\n    // they do not persist to the next render. Do not remove updates from hooks\n    // that weren't processed.\n    //\n    // Only reset the updates from the queue if it has a clone. If it does\n    // not have a clone, that means it wasn't processed, and the updates were\n    // scheduled before we entered the render phase.\n    var hook = currentlyRenderingFiber$1.memoizedState;\n\n    while (hook !== null) {\n      var queue = hook.queue;\n\n      if (queue !== null) {\n        queue.pending = null;\n      }\n\n      hook = hook.next;\n    }\n\n    didScheduleRenderPhaseUpdate = false;\n  }\n\n  renderLanes = NoLanes;\n  currentlyRenderingFiber$1 = null;\n  currentHook = null;\n  workInProgressHook = null;\n\n  {\n    hookTypesDev = null;\n    hookTypesUpdateIndexDev = -1;\n    currentHookNameInDev = null;\n    isUpdatingOpaqueValueInRenderPhase = false;\n  }\n\n  didScheduleRenderPhaseUpdateDuringThisPass = false;\n  localIdCounter = 0;\n}\n\nfunction mountWorkInProgressHook() {\n  var hook = {\n    memoizedState: null,\n    baseState: null,\n    baseQueue: null,\n    queue: null,\n    next: null\n  };\n\n  if (workInProgressHook === null) {\n    // This is the first hook in the list\n    currentlyRenderingFiber$1.memoizedState = workInProgressHook = hook;\n  } else {\n    // Append to the end of the list\n    workInProgressHook = workInProgressHook.next = hook;\n  }\n\n  return workInProgressHook;\n}\n\nfunction updateWorkInProgressHook() {\n  // This function is used both for updates and for re-renders triggered by a\n  // render phase update. It assumes there is either a current hook we can\n  // clone, or a work-in-progress hook from a previous render pass that we can\n  // use as a base. When we reach the end of the base list, we must switch to\n  // the dispatcher used for mounts.\n  var nextCurrentHook;\n\n  if (currentHook === null) {\n    var current = currentlyRenderingFiber$1.alternate;\n\n    if (current !== null) {\n      nextCurrentHook = current.memoizedState;\n    } else {\n      nextCurrentHook = null;\n    }\n  } else {\n    nextCurrentHook = currentHook.next;\n  }\n\n  var nextWorkInProgressHook;\n\n  if (workInProgressHook === null) {\n    nextWorkInProgressHook = currentlyRenderingFiber$1.memoizedState;\n  } else {\n    nextWorkInProgressHook = workInProgressHook.next;\n  }\n\n  if (nextWorkInProgressHook !== null) {\n    // There's already a work-in-progress. Reuse it.\n    workInProgressHook = nextWorkInProgressHook;\n    nextWorkInProgressHook = workInProgressHook.next;\n    currentHook = nextCurrentHook;\n  } else {\n    // Clone from the current hook.\n    if (nextCurrentHook === null) {\n      throw new Error('Rendered more hooks than during the previous render.');\n    }\n\n    currentHook = nextCurrentHook;\n    var newHook = {\n      memoizedState: currentHook.memoizedState,\n      baseState: currentHook.baseState,\n      baseQueue: currentHook.baseQueue,\n      queue: currentHook.queue,\n      next: null\n    };\n\n    if (workInProgressHook === null) {\n      // This is the first hook in the list.\n      currentlyRenderingFiber$1.memoizedState = workInProgressHook = newHook;\n    } else {\n      // Append to the end of the list.\n      workInProgressHook = workInProgressHook.next = newHook;\n    }\n  }\n\n  return workInProgressHook;\n}\n\nfunction createFunctionComponentUpdateQueue() {\n  return {\n    lastEffect: null,\n    stores: null\n  };\n}\n\nfunction basicStateReducer(state, action) {\n  // $FlowFixMe: Flow doesn't like mixed types\n  return typeof action === 'function' ? action(state) : action;\n}\n\nfunction mountReducer(reducer, initialArg, init) {\n  var hook = mountWorkInProgressHook();\n  var initialState;\n\n  if (init !== undefined) {\n    initialState = init(initialArg);\n  } else {\n    initialState = initialArg;\n  }\n\n  hook.memoizedState = hook.baseState = initialState;\n  var queue = {\n    pending: null,\n    interleaved: null,\n    lanes: NoLanes,\n    dispatch: null,\n    lastRenderedReducer: reducer,\n    lastRenderedState: initialState\n  };\n  hook.queue = queue;\n  var dispatch = queue.dispatch = dispatchReducerAction.bind(null, currentlyRenderingFiber$1, queue);\n  return [hook.memoizedState, dispatch];\n}\n\nfunction updateReducer(reducer, initialArg, init) {\n  var hook = updateWorkInProgressHook();\n  var queue = hook.queue;\n\n  if (queue === null) {\n    throw new Error('Should have a queue. This is likely a bug in React. Please file an issue.');\n  }\n\n  queue.lastRenderedReducer = reducer;\n  var current = currentHook; // The last rebase update that is NOT part of the base state.\n\n  var baseQueue = current.baseQueue; // The last pending update that hasn't been processed yet.\n\n  var pendingQueue = queue.pending;\n\n  if (pendingQueue !== null) {\n    // We have new updates that haven't been processed yet.\n    // We'll add them to the base queue.\n    if (baseQueue !== null) {\n      // Merge the pending queue and the base queue.\n      var baseFirst = baseQueue.next;\n      var pendingFirst = pendingQueue.next;\n      baseQueue.next = pendingFirst;\n      pendingQueue.next = baseFirst;\n    }\n\n    {\n      if (current.baseQueue !== baseQueue) {\n        // Internal invariant that should never happen, but feasibly could in\n        // the future if we implement resuming, or some form of that.\n        error('Internal error: Expected work-in-progress queue to be a clone. ' + 'This is a bug in React.');\n      }\n    }\n\n    current.baseQueue = baseQueue = pendingQueue;\n    queue.pending = null;\n  }\n\n  if (baseQueue !== null) {\n    // We have a queue to process.\n    var first = baseQueue.next;\n    var newState = current.baseState;\n    var newBaseState = null;\n    var newBaseQueueFirst = null;\n    var newBaseQueueLast = null;\n    var update = first;\n\n    do {\n      var updateLane = update.lane;\n\n      if (!isSubsetOfLanes(renderLanes, updateLane)) {\n        // Priority is insufficient. Skip this update. If this is the first\n        // skipped update, the previous update/state is the new base\n        // update/state.\n        var clone = {\n          lane: updateLane,\n          action: update.action,\n          hasEagerState: update.hasEagerState,\n          eagerState: update.eagerState,\n          next: null\n        };\n\n        if (newBaseQueueLast === null) {\n          newBaseQueueFirst = newBaseQueueLast = clone;\n          newBaseState = newState;\n        } else {\n          newBaseQueueLast = newBaseQueueLast.next = clone;\n        } // Update the remaining priority in the queue.\n        // TODO: Don't need to accumulate this. Instead, we can remove\n        // renderLanes from the original lanes.\n\n\n        currentlyRenderingFiber$1.lanes = mergeLanes(currentlyRenderingFiber$1.lanes, updateLane);\n        markSkippedUpdateLanes(updateLane);\n      } else {\n        // This update does have sufficient priority.\n        if (newBaseQueueLast !== null) {\n          var _clone = {\n            // This update is going to be committed so we never want uncommit\n            // it. Using NoLane works because 0 is a subset of all bitmasks, so\n            // this will never be skipped by the check above.\n            lane: NoLane,\n            action: update.action,\n            hasEagerState: update.hasEagerState,\n            eagerState: update.eagerState,\n            next: null\n          };\n          newBaseQueueLast = newBaseQueueLast.next = _clone;\n        } // Process this update.\n\n\n        if (update.hasEagerState) {\n          // If this update is a state update (not a reducer) and was processed eagerly,\n          // we can use the eagerly computed state\n          newState = update.eagerState;\n        } else {\n          var action = update.action;\n          newState = reducer(newState, action);\n        }\n      }\n\n      update = update.next;\n    } while (update !== null && update !== first);\n\n    if (newBaseQueueLast === null) {\n      newBaseState = newState;\n    } else {\n      newBaseQueueLast.next = newBaseQueueFirst;\n    } // Mark that the fiber performed work, but only if the new state is\n    // different from the current state.\n\n\n    if (!objectIs(newState, hook.memoizedState)) {\n      markWorkInProgressReceivedUpdate();\n    }\n\n    hook.memoizedState = newState;\n    hook.baseState = newBaseState;\n    hook.baseQueue = newBaseQueueLast;\n    queue.lastRenderedState = newState;\n  } // Interleaved updates are stored on a separate queue. We aren't going to\n  // process them during this render, but we do need to track which lanes\n  // are remaining.\n\n\n  var lastInterleaved = queue.interleaved;\n\n  if (lastInterleaved !== null) {\n    var interleaved = lastInterleaved;\n\n    do {\n      var interleavedLane = interleaved.lane;\n      currentlyRenderingFiber$1.lanes = mergeLanes(currentlyRenderingFiber$1.lanes, interleavedLane);\n      markSkippedUpdateLanes(interleavedLane);\n      interleaved = interleaved.next;\n    } while (interleaved !== lastInterleaved);\n  } else if (baseQueue === null) {\n    // `queue.lanes` is used for entangling transitions. We can set it back to\n    // zero once the queue is empty.\n    queue.lanes = NoLanes;\n  }\n\n  var dispatch = queue.dispatch;\n  return [hook.memoizedState, dispatch];\n}\n\nfunction rerenderReducer(reducer, initialArg, init) {\n  var hook = updateWorkInProgressHook();\n  var queue = hook.queue;\n\n  if (queue === null) {\n    throw new Error('Should have a queue. This is likely a bug in React. Please file an issue.');\n  }\n\n  queue.lastRenderedReducer = reducer; // This is a re-render. Apply the new render phase updates to the previous\n  // work-in-progress hook.\n\n  var dispatch = queue.dispatch;\n  var lastRenderPhaseUpdate = queue.pending;\n  var newState = hook.memoizedState;\n\n  if (lastRenderPhaseUpdate !== null) {\n    // The queue doesn't persist past this render pass.\n    queue.pending = null;\n    var firstRenderPhaseUpdate = lastRenderPhaseUpdate.next;\n    var update = firstRenderPhaseUpdate;\n\n    do {\n      // Process this render phase update. We don't have to check the\n      // priority because it will always be the same as the current\n      // render's.\n      var action = update.action;\n      newState = reducer(newState, action);\n      update = update.next;\n    } while (update !== firstRenderPhaseUpdate); // Mark that the fiber performed work, but only if the new state is\n    // different from the current state.\n\n\n    if (!objectIs(newState, hook.memoizedState)) {\n      markWorkInProgressReceivedUpdate();\n    }\n\n    hook.memoizedState = newState; // Don't persist the state accumulated from the render phase updates to\n    // the base state unless the queue is empty.\n    // TODO: Not sure if this is the desired semantics, but it's what we\n    // do for gDSFP. I can't remember why.\n\n    if (hook.baseQueue === null) {\n      hook.baseState = newState;\n    }\n\n    queue.lastRenderedState = newState;\n  }\n\n  return [newState, dispatch];\n}\n\nfunction mountMutableSource(source, getSnapshot, subscribe) {\n  {\n    return undefined;\n  }\n}\n\nfunction updateMutableSource(source, getSnapshot, subscribe) {\n  {\n    return undefined;\n  }\n}\n\nfunction mountSyncExternalStore(subscribe, getSnapshot, getServerSnapshot) {\n  var fiber = currentlyRenderingFiber$1;\n  var hook = mountWorkInProgressHook();\n  var nextSnapshot;\n  var isHydrating = getIsHydrating();\n\n  if (isHydrating) {\n    if (getServerSnapshot === undefined) {\n      throw new Error('Missing getServerSnapshot, which is required for ' + 'server-rendered content. Will revert to client rendering.');\n    }\n\n    nextSnapshot = getServerSnapshot();\n\n    {\n      if (!didWarnUncachedGetSnapshot) {\n        if (nextSnapshot !== getServerSnapshot()) {\n          error('The result of getServerSnapshot should be cached to avoid an infinite loop');\n\n          didWarnUncachedGetSnapshot = true;\n        }\n      }\n    }\n  } else {\n    nextSnapshot = getSnapshot();\n\n    {\n      if (!didWarnUncachedGetSnapshot) {\n        var cachedSnapshot = getSnapshot();\n\n        if (!objectIs(nextSnapshot, cachedSnapshot)) {\n          error('The result of getSnapshot should be cached to avoid an infinite loop');\n\n          didWarnUncachedGetSnapshot = true;\n        }\n      }\n    } // Unless we're rendering a blocking lane, schedule a consistency check.\n    // Right before committing, we will walk the tree and check if any of the\n    // stores were mutated.\n    //\n    // We won't do this if we're hydrating server-rendered content, because if\n    // the content is stale, it's already visible anyway. Instead we'll patch\n    // it up in a passive effect.\n\n\n    var root = getWorkInProgressRoot();\n\n    if (root === null) {\n      throw new Error('Expected a work-in-progress root. This is a bug in React. Please file an issue.');\n    }\n\n    if (!includesBlockingLane(root, renderLanes)) {\n      pushStoreConsistencyCheck(fiber, getSnapshot, nextSnapshot);\n    }\n  } // Read the current snapshot from the store on every render. This breaks the\n  // normal rules of React, and only works because store updates are\n  // always synchronous.\n\n\n  hook.memoizedState = nextSnapshot;\n  var inst = {\n    value: nextSnapshot,\n    getSnapshot: getSnapshot\n  };\n  hook.queue = inst; // Schedule an effect to subscribe to the store.\n\n  mountEffect(subscribeToStore.bind(null, fiber, inst, subscribe), [subscribe]); // Schedule an effect to update the mutable instance fields. We will update\n  // this whenever subscribe, getSnapshot, or value changes. Because there's no\n  // clean-up function, and we track the deps correctly, we can call pushEffect\n  // directly, without storing any additional state. For the same reason, we\n  // don't need to set a static flag, either.\n  // TODO: We can move this to the passive phase once we add a pre-commit\n  // consistency check. See the next comment.\n\n  fiber.flags |= Passive;\n  pushEffect(HasEffect | Passive$1, updateStoreInstance.bind(null, fiber, inst, nextSnapshot, getSnapshot), undefined, null);\n  return nextSnapshot;\n}\n\nfunction updateSyncExternalStore(subscribe, getSnapshot, getServerSnapshot) {\n  var fiber = currentlyRenderingFiber$1;\n  var hook = updateWorkInProgressHook(); // Read the current snapshot from the store on every render. This breaks the\n  // normal rules of React, and only works because store updates are\n  // always synchronous.\n\n  var nextSnapshot = getSnapshot();\n\n  {\n    if (!didWarnUncachedGetSnapshot) {\n      var cachedSnapshot = getSnapshot();\n\n      if (!objectIs(nextSnapshot, cachedSnapshot)) {\n        error('The result of getSnapshot should be cached to avoid an infinite loop');\n\n        didWarnUncachedGetSnapshot = true;\n      }\n    }\n  }\n\n  var prevSnapshot = hook.memoizedState;\n  var snapshotChanged = !objectIs(prevSnapshot, nextSnapshot);\n\n  if (snapshotChanged) {\n    hook.memoizedState = nextSnapshot;\n    markWorkInProgressReceivedUpdate();\n  }\n\n  var inst = hook.queue;\n  updateEffect(subscribeToStore.bind(null, fiber, inst, subscribe), [subscribe]); // Whenever getSnapshot or subscribe changes, we need to check in the\n  // commit phase if there was an interleaved mutation. In concurrent mode\n  // this can happen all the time, but even in synchronous mode, an earlier\n  // effect may have mutated the store.\n\n  if (inst.getSnapshot !== getSnapshot || snapshotChanged || // Check if the susbcribe function changed. We can save some memory by\n  // checking whether we scheduled a subscription effect above.\n  workInProgressHook !== null && workInProgressHook.memoizedState.tag & HasEffect) {\n    fiber.flags |= Passive;\n    pushEffect(HasEffect | Passive$1, updateStoreInstance.bind(null, fiber, inst, nextSnapshot, getSnapshot), undefined, null); // Unless we're rendering a blocking lane, schedule a consistency check.\n    // Right before committing, we will walk the tree and check if any of the\n    // stores were mutated.\n\n    var root = getWorkInProgressRoot();\n\n    if (root === null) {\n      throw new Error('Expected a work-in-progress root. This is a bug in React. Please file an issue.');\n    }\n\n    if (!includesBlockingLane(root, renderLanes)) {\n      pushStoreConsistencyCheck(fiber, getSnapshot, nextSnapshot);\n    }\n  }\n\n  return nextSnapshot;\n}\n\nfunction pushStoreConsistencyCheck(fiber, getSnapshot, renderedSnapshot) {\n  fiber.flags |= StoreConsistency;\n  var check = {\n    getSnapshot: getSnapshot,\n    value: renderedSnapshot\n  };\n  var componentUpdateQueue = currentlyRenderingFiber$1.updateQueue;\n\n  if (componentUpdateQueue === null) {\n    componentUpdateQueue = createFunctionComponentUpdateQueue();\n    currentlyRenderingFiber$1.updateQueue = componentUpdateQueue;\n    componentUpdateQueue.stores = [check];\n  } else {\n    var stores = componentUpdateQueue.stores;\n\n    if (stores === null) {\n      componentUpdateQueue.stores = [check];\n    } else {\n      stores.push(check);\n    }\n  }\n}\n\nfunction updateStoreInstance(fiber, inst, nextSnapshot, getSnapshot) {\n  // These are updated in the passive phase\n  inst.value = nextSnapshot;\n  inst.getSnapshot = getSnapshot; // Something may have been mutated in between render and commit. This could\n  // have been in an event that fired before the passive effects, or it could\n  // have been in a layout effect. In that case, we would have used the old\n  // snapsho and getSnapshot values to bail out. We need to check one more time.\n\n  if (checkIfSnapshotChanged(inst)) {\n    // Force a re-render.\n    forceStoreRerender(fiber);\n  }\n}\n\nfunction subscribeToStore(fiber, inst, subscribe) {\n  var handleStoreChange = function () {\n    // The store changed. Check if the snapshot changed since the last time we\n    // read from the store.\n    if (checkIfSnapshotChanged(inst)) {\n      // Force a re-render.\n      forceStoreRerender(fiber);\n    }\n  }; // Subscribe to the store and return a clean-up function.\n\n\n  return subscribe(handleStoreChange);\n}\n\nfunction checkIfSnapshotChanged(inst) {\n  var latestGetSnapshot = inst.getSnapshot;\n  var prevValue = inst.value;\n\n  try {\n    var nextValue = latestGetSnapshot();\n    return !objectIs(prevValue, nextValue);\n  } catch (error) {\n    return true;\n  }\n}\n\nfunction forceStoreRerender(fiber) {\n  var root = enqueueConcurrentRenderForLane(fiber, SyncLane);\n\n  if (root !== null) {\n    scheduleUpdateOnFiber(root, fiber, SyncLane, NoTimestamp);\n  }\n}\n\nfunction mountState(initialState) {\n  var hook = mountWorkInProgressHook();\n\n  if (typeof initialState === 'function') {\n    // $FlowFixMe: Flow doesn't like mixed types\n    initialState = initialState();\n  }\n\n  hook.memoizedState = hook.baseState = initialState;\n  var queue = {\n    pending: null,\n    interleaved: null,\n    lanes: NoLanes,\n    dispatch: null,\n    lastRenderedReducer: basicStateReducer,\n    lastRenderedState: initialState\n  };\n  hook.queue = queue;\n  var dispatch = queue.dispatch = dispatchSetState.bind(null, currentlyRenderingFiber$1, queue);\n  return [hook.memoizedState, dispatch];\n}\n\nfunction updateState(initialState) {\n  return updateReducer(basicStateReducer);\n}\n\nfunction rerenderState(initialState) {\n  return rerenderReducer(basicStateReducer);\n}\n\nfunction pushEffect(tag, create, destroy, deps) {\n  var effect = {\n    tag: tag,\n    create: create,\n    destroy: destroy,\n    deps: deps,\n    // Circular\n    next: null\n  };\n  var componentUpdateQueue = currentlyRenderingFiber$1.updateQueue;\n\n  if (componentUpdateQueue === null) {\n    componentUpdateQueue = createFunctionComponentUpdateQueue();\n    currentlyRenderingFiber$1.updateQueue = componentUpdateQueue;\n    componentUpdateQueue.lastEffect = effect.next = effect;\n  } else {\n    var lastEffect = componentUpdateQueue.lastEffect;\n\n    if (lastEffect === null) {\n      componentUpdateQueue.lastEffect = effect.next = effect;\n    } else {\n      var firstEffect = lastEffect.next;\n      lastEffect.next = effect;\n      effect.next = firstEffect;\n      componentUpdateQueue.lastEffect = effect;\n    }\n  }\n\n  return effect;\n}\n\nfunction mountRef(initialValue) {\n  var hook = mountWorkInProgressHook();\n\n  {\n    var _ref2 = {\n      current: initialValue\n    };\n    hook.memoizedState = _ref2;\n    return _ref2;\n  }\n}\n\nfunction updateRef(initialValue) {\n  var hook = updateWorkInProgressHook();\n  return hook.memoizedState;\n}\n\nfunction mountEffectImpl(fiberFlags, hookFlags, create, deps) {\n  var hook = mountWorkInProgressHook();\n  var nextDeps = deps === undefined ? null : deps;\n  currentlyRenderingFiber$1.flags |= fiberFlags;\n  hook.memoizedState = pushEffect(HasEffect | hookFlags, create, undefined, nextDeps);\n}\n\nfunction updateEffectImpl(fiberFlags, hookFlags, create, deps) {\n  var hook = updateWorkInProgressHook();\n  var nextDeps = deps === undefined ? null : deps;\n  var destroy = undefined;\n\n  if (currentHook !== null) {\n    var prevEffect = currentHook.memoizedState;\n    destroy = prevEffect.destroy;\n\n    if (nextDeps !== null) {\n      var prevDeps = prevEffect.deps;\n\n      if (areHookInputsEqual(nextDeps, prevDeps)) {\n        hook.memoizedState = pushEffect(hookFlags, create, destroy, nextDeps);\n        return;\n      }\n    }\n  }\n\n  currentlyRenderingFiber$1.flags |= fiberFlags;\n  hook.memoizedState = pushEffect(HasEffect | hookFlags, create, destroy, nextDeps);\n}\n\nfunction mountEffect(create, deps) {\n  if ( (currentlyRenderingFiber$1.mode & StrictEffectsMode) !== NoMode) {\n    return mountEffectImpl(MountPassiveDev | Passive | PassiveStatic, Passive$1, create, deps);\n  } else {\n    return mountEffectImpl(Passive | PassiveStatic, Passive$1, create, deps);\n  }\n}\n\nfunction updateEffect(create, deps) {\n  return updateEffectImpl(Passive, Passive$1, create, deps);\n}\n\nfunction mountInsertionEffect(create, deps) {\n  return mountEffectImpl(Update, Insertion, create, deps);\n}\n\nfunction updateInsertionEffect(create, deps) {\n  return updateEffectImpl(Update, Insertion, create, deps);\n}\n\nfunction mountLayoutEffect(create, deps) {\n  var fiberFlags = Update;\n\n  {\n    fiberFlags |= LayoutStatic;\n  }\n\n  if ( (currentlyRenderingFiber$1.mode & StrictEffectsMode) !== NoMode) {\n    fiberFlags |= MountLayoutDev;\n  }\n\n  return mountEffectImpl(fiberFlags, Layout, create, deps);\n}\n\nfunction updateLayoutEffect(create, deps) {\n  return updateEffectImpl(Update, Layout, create, deps);\n}\n\nfunction imperativeHandleEffect(create, ref) {\n  if (typeof ref === 'function') {\n    var refCallback = ref;\n\n    var _inst = create();\n\n    refCallback(_inst);\n    return function () {\n      refCallback(null);\n    };\n  } else if (ref !== null && ref !== undefined) {\n    var refObject = ref;\n\n    {\n      if (!refObject.hasOwnProperty('current')) {\n        error('Expected useImperativeHandle() first argument to either be a ' + 'ref callback or React.createRef() object. Instead received: %s.', 'an object with keys {' + Object.keys(refObject).join(', ') + '}');\n      }\n    }\n\n    var _inst2 = create();\n\n    refObject.current = _inst2;\n    return function () {\n      refObject.current = null;\n    };\n  }\n}\n\nfunction mountImperativeHandle(ref, create, deps) {\n  {\n    if (typeof create !== 'function') {\n      error('Expected useImperativeHandle() second argument to be a function ' + 'that creates a handle. Instead received: %s.', create !== null ? typeof create : 'null');\n    }\n  } // TODO: If deps are provided, should we skip comparing the ref itself?\n\n\n  var effectDeps = deps !== null && deps !== undefined ? deps.concat([ref]) : null;\n  var fiberFlags = Update;\n\n  {\n    fiberFlags |= LayoutStatic;\n  }\n\n  if ( (currentlyRenderingFiber$1.mode & StrictEffectsMode) !== NoMode) {\n    fiberFlags |= MountLayoutDev;\n  }\n\n  return mountEffectImpl(fiberFlags, Layout, imperativeHandleEffect.bind(null, create, ref), effectDeps);\n}\n\nfunction updateImperativeHandle(ref, create, deps) {\n  {\n    if (typeof create !== 'function') {\n      error('Expected useImperativeHandle() second argument to be a function ' + 'that creates a handle. Instead received: %s.', create !== null ? typeof create : 'null');\n    }\n  } // TODO: If deps are provided, should we skip comparing the ref itself?\n\n\n  var effectDeps = deps !== null && deps !== undefined ? deps.concat([ref]) : null;\n  return updateEffectImpl(Update, Layout, imperativeHandleEffect.bind(null, create, ref), effectDeps);\n}\n\nfunction mountDebugValue(value, formatterFn) {// This hook is normally a no-op.\n  // The react-debug-hooks package injects its own implementation\n  // so that e.g. DevTools can display custom hook values.\n}\n\nvar updateDebugValue = mountDebugValue;\n\nfunction mountCallback(callback, deps) {\n  var hook = mountWorkInProgressHook();\n  var nextDeps = deps === undefined ? null : deps;\n  hook.memoizedState = [callback, nextDeps];\n  return callback;\n}\n\nfunction updateCallback(callback, deps) {\n  var hook = updateWorkInProgressHook();\n  var nextDeps = deps === undefined ? null : deps;\n  var prevState = hook.memoizedState;\n\n  if (prevState !== null) {\n    if (nextDeps !== null) {\n      var prevDeps = prevState[1];\n\n      if (areHookInputsEqual(nextDeps, prevDeps)) {\n        return prevState[0];\n      }\n    }\n  }\n\n  hook.memoizedState = [callback, nextDeps];\n  return callback;\n}\n\nfunction mountMemo(nextCreate, deps) {\n  var hook = mountWorkInProgressHook();\n  var nextDeps = deps === undefined ? null : deps;\n  var nextValue = nextCreate();\n  hook.memoizedState = [nextValue, nextDeps];\n  return nextValue;\n}\n\nfunction updateMemo(nextCreate, deps) {\n  var hook = updateWorkInProgressHook();\n  var nextDeps = deps === undefined ? null : deps;\n  var prevState = hook.memoizedState;\n\n  if (prevState !== null) {\n    // Assume these are defined. If they're not, areHookInputsEqual will warn.\n    if (nextDeps !== null) {\n      var prevDeps = prevState[1];\n\n      if (areHookInputsEqual(nextDeps, prevDeps)) {\n        return prevState[0];\n      }\n    }\n  }\n\n  var nextValue = nextCreate();\n  hook.memoizedState = [nextValue, nextDeps];\n  return nextValue;\n}\n\nfunction mountDeferredValue(value) {\n  var hook = mountWorkInProgressHook();\n  hook.memoizedState = value;\n  return value;\n}\n\nfunction updateDeferredValue(value) {\n  var hook = updateWorkInProgressHook();\n  var resolvedCurrentHook = currentHook;\n  var prevValue = resolvedCurrentHook.memoizedState;\n  return updateDeferredValueImpl(hook, prevValue, value);\n}\n\nfunction rerenderDeferredValue(value) {\n  var hook = updateWorkInProgressHook();\n\n  if (currentHook === null) {\n    // This is a rerender during a mount.\n    hook.memoizedState = value;\n    return value;\n  } else {\n    // This is a rerender during an update.\n    var prevValue = currentHook.memoizedState;\n    return updateDeferredValueImpl(hook, prevValue, value);\n  }\n}\n\nfunction updateDeferredValueImpl(hook, prevValue, value) {\n  var shouldDeferValue = !includesOnlyNonUrgentLanes(renderLanes);\n\n  if (shouldDeferValue) {\n    // This is an urgent update. If the value has changed, keep using the\n    // previous value and spawn a deferred render to update it later.\n    if (!objectIs(value, prevValue)) {\n      // Schedule a deferred render\n      var deferredLane = claimNextTransitionLane();\n      currentlyRenderingFiber$1.lanes = mergeLanes(currentlyRenderingFiber$1.lanes, deferredLane);\n      markSkippedUpdateLanes(deferredLane); // Set this to true to indicate that the rendered value is inconsistent\n      // from the latest value. The name \"baseState\" doesn't really match how we\n      // use it because we're reusing a state hook field instead of creating a\n      // new one.\n\n      hook.baseState = true;\n    } // Reuse the previous value\n\n\n    return prevValue;\n  } else {\n    // This is not an urgent update, so we can use the latest value regardless\n    // of what it is. No need to defer it.\n    // However, if we're currently inside a spawned render, then we need to mark\n    // this as an update to prevent the fiber from bailing out.\n    //\n    // `baseState` is true when the current value is different from the rendered\n    // value. The name doesn't really match how we use it because we're reusing\n    // a state hook field instead of creating a new one.\n    if (hook.baseState) {\n      // Flip this back to false.\n      hook.baseState = false;\n      markWorkInProgressReceivedUpdate();\n    }\n\n    hook.memoizedState = value;\n    return value;\n  }\n}\n\nfunction startTransition(setPending, callback, options) {\n  var previousPriority = getCurrentUpdatePriority();\n  setCurrentUpdatePriority(higherEventPriority(previousPriority, ContinuousEventPriority));\n  setPending(true);\n  var prevTransition = ReactCurrentBatchConfig$2.transition;\n  ReactCurrentBatchConfig$2.transition = {};\n  var currentTransition = ReactCurrentBatchConfig$2.transition;\n\n  {\n    ReactCurrentBatchConfig$2.transition._updatedFibers = new Set();\n  }\n\n  try {\n    setPending(false);\n    callback();\n  } finally {\n    setCurrentUpdatePriority(previousPriority);\n    ReactCurrentBatchConfig$2.transition = prevTransition;\n\n    {\n      if (prevTransition === null && currentTransition._updatedFibers) {\n        var updatedFibersCount = currentTransition._updatedFibers.size;\n\n        if (updatedFibersCount > 10) {\n          warn('Detected a large number of updates inside startTransition. ' + 'If this is due to a subscription please re-write it to use React provided hooks. ' + 'Otherwise concurrent mode guarantees are off the table.');\n        }\n\n        currentTransition._updatedFibers.clear();\n      }\n    }\n  }\n}\n\nfunction mountTransition() {\n  var _mountState = mountState(false),\n      isPending = _mountState[0],\n      setPending = _mountState[1]; // The `start` method never changes.\n\n\n  var start = startTransition.bind(null, setPending);\n  var hook = mountWorkInProgressHook();\n  hook.memoizedState = start;\n  return [isPending, start];\n}\n\nfunction updateTransition() {\n  var _updateState = updateState(),\n      isPending = _updateState[0];\n\n  var hook = updateWorkInProgressHook();\n  var start = hook.memoizedState;\n  return [isPending, start];\n}\n\nfunction rerenderTransition() {\n  var _rerenderState = rerenderState(),\n      isPending = _rerenderState[0];\n\n  var hook = updateWorkInProgressHook();\n  var start = hook.memoizedState;\n  return [isPending, start];\n}\n\nvar isUpdatingOpaqueValueInRenderPhase = false;\nfunction getIsUpdatingOpaqueValueInRenderPhaseInDEV() {\n  {\n    return isUpdatingOpaqueValueInRenderPhase;\n  }\n}\n\nfunction mountId() {\n  var hook = mountWorkInProgressHook();\n  var root = getWorkInProgressRoot(); // TODO: In Fizz, id generation is specific to each server config. Maybe we\n  // should do this in Fiber, too? Deferring this decision for now because\n  // there's no other place to store the prefix except for an internal field on\n  // the public createRoot object, which the fiber tree does not currently have\n  // a reference to.\n\n  var identifierPrefix = root.identifierPrefix;\n  var id;\n\n  if (getIsHydrating()) {\n    var treeId = getTreeId(); // Use a captial R prefix for server-generated ids.\n\n    id = ':' + identifierPrefix + 'R' + treeId; // Unless this is the first id at this level, append a number at the end\n    // that represents the position of this useId hook among all the useId\n    // hooks for this fiber.\n\n    var localId = localIdCounter++;\n\n    if (localId > 0) {\n      id += 'H' + localId.toString(32);\n    }\n\n    id += ':';\n  } else {\n    // Use a lowercase r prefix for client-generated ids.\n    var globalClientId = globalClientIdCounter++;\n    id = ':' + identifierPrefix + 'r' + globalClientId.toString(32) + ':';\n  }\n\n  hook.memoizedState = id;\n  return id;\n}\n\nfunction updateId() {\n  var hook = updateWorkInProgressHook();\n  var id = hook.memoizedState;\n  return id;\n}\n\nfunction dispatchReducerAction(fiber, queue, action) {\n  {\n    if (typeof arguments[3] === 'function') {\n      error(\"State updates from the useState() and useReducer() Hooks don't support the \" + 'second callback argument. To execute a side effect after ' + 'rendering, declare it in the component body with useEffect().');\n    }\n  }\n\n  var lane = requestUpdateLane(fiber);\n  var update = {\n    lane: lane,\n    action: action,\n    hasEagerState: false,\n    eagerState: null,\n    next: null\n  };\n\n  if (isRenderPhaseUpdate(fiber)) {\n    enqueueRenderPhaseUpdate(queue, update);\n  } else {\n    var root = enqueueConcurrentHookUpdate(fiber, queue, update, lane);\n\n    if (root !== null) {\n      var eventTime = requestEventTime();\n      scheduleUpdateOnFiber(root, fiber, lane, eventTime);\n      entangleTransitionUpdate(root, queue, lane);\n    }\n  }\n\n  markUpdateInDevTools(fiber, lane);\n}\n\nfunction dispatchSetState(fiber, queue, action) {\n  {\n    if (typeof arguments[3] === 'function') {\n      error(\"State updates from the useState() and useReducer() Hooks don't support the \" + 'second callback argument. To execute a side effect after ' + 'rendering, declare it in the component body with useEffect().');\n    }\n  }\n\n  var lane = requestUpdateLane(fiber);\n  var update = {\n    lane: lane,\n    action: action,\n    hasEagerState: false,\n    eagerState: null,\n    next: null\n  };\n\n  if (isRenderPhaseUpdate(fiber)) {\n    enqueueRenderPhaseUpdate(queue, update);\n  } else {\n    var alternate = fiber.alternate;\n\n    if (fiber.lanes === NoLanes && (alternate === null || alternate.lanes === NoLanes)) {\n      // The queue is currently empty, which means we can eagerly compute the\n      // next state before entering the render phase. If the new state is the\n      // same as the current state, we may be able to bail out entirely.\n      var lastRenderedReducer = queue.lastRenderedReducer;\n\n      if (lastRenderedReducer !== null) {\n        var prevDispatcher;\n\n        {\n          prevDispatcher = ReactCurrentDispatcher$1.current;\n          ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnUpdateInDEV;\n        }\n\n        try {\n          var currentState = queue.lastRenderedState;\n          var eagerState = lastRenderedReducer(currentState, action); // Stash the eagerly computed state, and the reducer used to compute\n          // it, on the update object. If the reducer hasn't changed by the\n          // time we enter the render phase, then the eager state can be used\n          // without calling the reducer again.\n\n          update.hasEagerState = true;\n          update.eagerState = eagerState;\n\n          if (objectIs(eagerState, currentState)) {\n            // Fast path. We can bail out without scheduling React to re-render.\n            // It's still possible that we'll need to rebase this update later,\n            // if the component re-renders for a different reason and by that\n            // time the reducer has changed.\n            // TODO: Do we still need to entangle transitions in this case?\n            enqueueConcurrentHookUpdateAndEagerlyBailout(fiber, queue, update, lane);\n            return;\n          }\n        } catch (error) {// Suppress the error. It will throw again in the render phase.\n        } finally {\n          {\n            ReactCurrentDispatcher$1.current = prevDispatcher;\n          }\n        }\n      }\n    }\n\n    var root = enqueueConcurrentHookUpdate(fiber, queue, update, lane);\n\n    if (root !== null) {\n      var eventTime = requestEventTime();\n      scheduleUpdateOnFiber(root, fiber, lane, eventTime);\n      entangleTransitionUpdate(root, queue, lane);\n    }\n  }\n\n  markUpdateInDevTools(fiber, lane);\n}\n\nfunction isRenderPhaseUpdate(fiber) {\n  var alternate = fiber.alternate;\n  return fiber === currentlyRenderingFiber$1 || alternate !== null && alternate === currentlyRenderingFiber$1;\n}\n\nfunction enqueueRenderPhaseUpdate(queue, update) {\n  // This is a render phase update. Stash it in a lazily-created map of\n  // queue -> linked list of updates. After this render pass, we'll restart\n  // and apply the stashed updates on top of the work-in-progress hook.\n  didScheduleRenderPhaseUpdateDuringThisPass = didScheduleRenderPhaseUpdate = true;\n  var pending = queue.pending;\n\n  if (pending === null) {\n    // This is the first update. Create a circular list.\n    update.next = update;\n  } else {\n    update.next = pending.next;\n    pending.next = update;\n  }\n\n  queue.pending = update;\n} // TODO: Move to ReactFiberConcurrentUpdates?\n\n\nfunction entangleTransitionUpdate(root, queue, lane) {\n  if (isTransitionLane(lane)) {\n    var queueLanes = queue.lanes; // If any entangled lanes are no longer pending on the root, then they\n    // must have finished. We can remove them from the shared queue, which\n    // represents a superset of the actually pending lanes. In some cases we\n    // may entangle more than we need to, but that's OK. In fact it's worse if\n    // we *don't* entangle when we should.\n\n    queueLanes = intersectLanes(queueLanes, root.pendingLanes); // Entangle the new transition lane with the other transition lanes.\n\n    var newQueueLanes = mergeLanes(queueLanes, lane);\n    queue.lanes = newQueueLanes; // Even if queue.lanes already include lane, we don't know for certain if\n    // the lane finished since the last time we entangled it. So we need to\n    // entangle it again, just to be sure.\n\n    markRootEntangled(root, newQueueLanes);\n  }\n}\n\nfunction markUpdateInDevTools(fiber, lane, action) {\n\n  {\n    markStateUpdateScheduled(fiber, lane);\n  }\n}\n\nvar ContextOnlyDispatcher = {\n  readContext: readContext,\n  useCallback: throwInvalidHookError,\n  useContext: throwInvalidHookError,\n  useEffect: throwInvalidHookError,\n  useImperativeHandle: throwInvalidHookError,\n  useInsertionEffect: throwInvalidHookError,\n  useLayoutEffect: throwInvalidHookError,\n  useMemo: throwInvalidHookError,\n  useReducer: throwInvalidHookError,\n  useRef: throwInvalidHookError,\n  useState: throwInvalidHookError,\n  useDebugValue: throwInvalidHookError,\n  useDeferredValue: throwInvalidHookError,\n  useTransition: throwInvalidHookError,\n  useMutableSource: throwInvalidHookError,\n  useSyncExternalStore: throwInvalidHookError,\n  useId: throwInvalidHookError,\n  unstable_isNewReconciler: enableNewReconciler\n};\n\nvar HooksDispatcherOnMountInDEV = null;\nvar HooksDispatcherOnMountWithHookTypesInDEV = null;\nvar HooksDispatcherOnUpdateInDEV = null;\nvar HooksDispatcherOnRerenderInDEV = null;\nvar InvalidNestedHooksDispatcherOnMountInDEV = null;\nvar InvalidNestedHooksDispatcherOnUpdateInDEV = null;\nvar InvalidNestedHooksDispatcherOnRerenderInDEV = null;\n\n{\n  var warnInvalidContextAccess = function () {\n    error('Context can only be read while React is rendering. ' + 'In classes, you can read it in the render method or getDerivedStateFromProps. ' + 'In function components, you can read it directly in the function body, but not ' + 'inside Hooks like useReducer() or useMemo().');\n  };\n\n  var warnInvalidHookAccess = function () {\n    error('Do not call Hooks inside useEffect(...), useMemo(...), or other built-in Hooks. ' + 'You can only call Hooks at the top level of your React function. ' + 'For more information, see ' + 'https://reactjs.org/link/rules-of-hooks');\n  };\n\n  HooksDispatcherOnMountInDEV = {\n    readContext: function (context) {\n      return readContext(context);\n    },\n    useCallback: function (callback, deps) {\n      currentHookNameInDev = 'useCallback';\n      mountHookTypesDev();\n      checkDepsAreArrayDev(deps);\n      return mountCallback(callback, deps);\n    },\n    useContext: function (context) {\n      currentHookNameInDev = 'useContext';\n      mountHookTypesDev();\n      return readContext(context);\n    },\n    useEffect: function (create, deps) {\n      currentHookNameInDev = 'useEffect';\n      mountHookTypesDev();\n      checkDepsAreArrayDev(deps);\n      return mountEffect(create, deps);\n    },\n    useImperativeHandle: function (ref, create, deps) {\n      currentHookNameInDev = 'useImperativeHandle';\n      mountHookTypesDev();\n      checkDepsAreArrayDev(deps);\n      return mountImperativeHandle(ref, create, deps);\n    },\n    useInsertionEffect: function (create, deps) {\n      currentHookNameInDev = 'useInsertionEffect';\n      mountHookTypesDev();\n      checkDepsAreArrayDev(deps);\n      return mountInsertionEffect(create, deps);\n    },\n    useLayoutEffect: function (create, deps) {\n      currentHookNameInDev = 'useLayoutEffect';\n      mountHookTypesDev();\n      checkDepsAreArrayDev(deps);\n      return mountLayoutEffect(create, deps);\n    },\n    useMemo: function (create, deps) {\n      currentHookNameInDev = 'useMemo';\n      mountHookTypesDev();\n      checkDepsAreArrayDev(deps);\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnMountInDEV;\n\n      try {\n        return mountMemo(create, deps);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useReducer: function (reducer, initialArg, init) {\n      currentHookNameInDev = 'useReducer';\n      mountHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnMountInDEV;\n\n      try {\n        return mountReducer(reducer, initialArg, init);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useRef: function (initialValue) {\n      currentHookNameInDev = 'useRef';\n      mountHookTypesDev();\n      return mountRef(initialValue);\n    },\n    useState: function (initialState) {\n      currentHookNameInDev = 'useState';\n      mountHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnMountInDEV;\n\n      try {\n        return mountState(initialState);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useDebugValue: function (value, formatterFn) {\n      currentHookNameInDev = 'useDebugValue';\n      mountHookTypesDev();\n      return mountDebugValue();\n    },\n    useDeferredValue: function (value) {\n      currentHookNameInDev = 'useDeferredValue';\n      mountHookTypesDev();\n      return mountDeferredValue(value);\n    },\n    useTransition: function () {\n      currentHookNameInDev = 'useTransition';\n      mountHookTypesDev();\n      return mountTransition();\n    },\n    useMutableSource: function (source, getSnapshot, subscribe) {\n      currentHookNameInDev = 'useMutableSource';\n      mountHookTypesDev();\n      return mountMutableSource();\n    },\n    useSyncExternalStore: function (subscribe, getSnapshot, getServerSnapshot) {\n      currentHookNameInDev = 'useSyncExternalStore';\n      mountHookTypesDev();\n      return mountSyncExternalStore(subscribe, getSnapshot, getServerSnapshot);\n    },\n    useId: function () {\n      currentHookNameInDev = 'useId';\n      mountHookTypesDev();\n      return mountId();\n    },\n    unstable_isNewReconciler: enableNewReconciler\n  };\n\n  HooksDispatcherOnMountWithHookTypesInDEV = {\n    readContext: function (context) {\n      return readContext(context);\n    },\n    useCallback: function (callback, deps) {\n      currentHookNameInDev = 'useCallback';\n      updateHookTypesDev();\n      return mountCallback(callback, deps);\n    },\n    useContext: function (context) {\n      currentHookNameInDev = 'useContext';\n      updateHookTypesDev();\n      return readContext(context);\n    },\n    useEffect: function (create, deps) {\n      currentHookNameInDev = 'useEffect';\n      updateHookTypesDev();\n      return mountEffect(create, deps);\n    },\n    useImperativeHandle: function (ref, create, deps) {\n      currentHookNameInDev = 'useImperativeHandle';\n      updateHookTypesDev();\n      return mountImperativeHandle(ref, create, deps);\n    },\n    useInsertionEffect: function (create, deps) {\n      currentHookNameInDev = 'useInsertionEffect';\n      updateHookTypesDev();\n      return mountInsertionEffect(create, deps);\n    },\n    useLayoutEffect: function (create, deps) {\n      currentHookNameInDev = 'useLayoutEffect';\n      updateHookTypesDev();\n      return mountLayoutEffect(create, deps);\n    },\n    useMemo: function (create, deps) {\n      currentHookNameInDev = 'useMemo';\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnMountInDEV;\n\n      try {\n        return mountMemo(create, deps);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useReducer: function (reducer, initialArg, init) {\n      currentHookNameInDev = 'useReducer';\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnMountInDEV;\n\n      try {\n        return mountReducer(reducer, initialArg, init);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useRef: function (initialValue) {\n      currentHookNameInDev = 'useRef';\n      updateHookTypesDev();\n      return mountRef(initialValue);\n    },\n    useState: function (initialState) {\n      currentHookNameInDev = 'useState';\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnMountInDEV;\n\n      try {\n        return mountState(initialState);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useDebugValue: function (value, formatterFn) {\n      currentHookNameInDev = 'useDebugValue';\n      updateHookTypesDev();\n      return mountDebugValue();\n    },\n    useDeferredValue: function (value) {\n      currentHookNameInDev = 'useDeferredValue';\n      updateHookTypesDev();\n      return mountDeferredValue(value);\n    },\n    useTransition: function () {\n      currentHookNameInDev = 'useTransition';\n      updateHookTypesDev();\n      return mountTransition();\n    },\n    useMutableSource: function (source, getSnapshot, subscribe) {\n      currentHookNameInDev = 'useMutableSource';\n      updateHookTypesDev();\n      return mountMutableSource();\n    },\n    useSyncExternalStore: function (subscribe, getSnapshot, getServerSnapshot) {\n      currentHookNameInDev = 'useSyncExternalStore';\n      updateHookTypesDev();\n      return mountSyncExternalStore(subscribe, getSnapshot, getServerSnapshot);\n    },\n    useId: function () {\n      currentHookNameInDev = 'useId';\n      updateHookTypesDev();\n      return mountId();\n    },\n    unstable_isNewReconciler: enableNewReconciler\n  };\n\n  HooksDispatcherOnUpdateInDEV = {\n    readContext: function (context) {\n      return readContext(context);\n    },\n    useCallback: function (callback, deps) {\n      currentHookNameInDev = 'useCallback';\n      updateHookTypesDev();\n      return updateCallback(callback, deps);\n    },\n    useContext: function (context) {\n      currentHookNameInDev = 'useContext';\n      updateHookTypesDev();\n      return readContext(context);\n    },\n    useEffect: function (create, deps) {\n      currentHookNameInDev = 'useEffect';\n      updateHookTypesDev();\n      return updateEffect(create, deps);\n    },\n    useImperativeHandle: function (ref, create, deps) {\n      currentHookNameInDev = 'useImperativeHandle';\n      updateHookTypesDev();\n      return updateImperativeHandle(ref, create, deps);\n    },\n    useInsertionEffect: function (create, deps) {\n      currentHookNameInDev = 'useInsertionEffect';\n      updateHookTypesDev();\n      return updateInsertionEffect(create, deps);\n    },\n    useLayoutEffect: function (create, deps) {\n      currentHookNameInDev = 'useLayoutEffect';\n      updateHookTypesDev();\n      return updateLayoutEffect(create, deps);\n    },\n    useMemo: function (create, deps) {\n      currentHookNameInDev = 'useMemo';\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnUpdateInDEV;\n\n      try {\n        return updateMemo(create, deps);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useReducer: function (reducer, initialArg, init) {\n      currentHookNameInDev = 'useReducer';\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnUpdateInDEV;\n\n      try {\n        return updateReducer(reducer, initialArg, init);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useRef: function (initialValue) {\n      currentHookNameInDev = 'useRef';\n      updateHookTypesDev();\n      return updateRef();\n    },\n    useState: function (initialState) {\n      currentHookNameInDev = 'useState';\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnUpdateInDEV;\n\n      try {\n        return updateState(initialState);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useDebugValue: function (value, formatterFn) {\n      currentHookNameInDev = 'useDebugValue';\n      updateHookTypesDev();\n      return updateDebugValue();\n    },\n    useDeferredValue: function (value) {\n      currentHookNameInDev = 'useDeferredValue';\n      updateHookTypesDev();\n      return updateDeferredValue(value);\n    },\n    useTransition: function () {\n      currentHookNameInDev = 'useTransition';\n      updateHookTypesDev();\n      return updateTransition();\n    },\n    useMutableSource: function (source, getSnapshot, subscribe) {\n      currentHookNameInDev = 'useMutableSource';\n      updateHookTypesDev();\n      return updateMutableSource();\n    },\n    useSyncExternalStore: function (subscribe, getSnapshot, getServerSnapshot) {\n      currentHookNameInDev = 'useSyncExternalStore';\n      updateHookTypesDev();\n      return updateSyncExternalStore(subscribe, getSnapshot);\n    },\n    useId: function () {\n      currentHookNameInDev = 'useId';\n      updateHookTypesDev();\n      return updateId();\n    },\n    unstable_isNewReconciler: enableNewReconciler\n  };\n\n  HooksDispatcherOnRerenderInDEV = {\n    readContext: function (context) {\n      return readContext(context);\n    },\n    useCallback: function (callback, deps) {\n      currentHookNameInDev = 'useCallback';\n      updateHookTypesDev();\n      return updateCallback(callback, deps);\n    },\n    useContext: function (context) {\n      currentHookNameInDev = 'useContext';\n      updateHookTypesDev();\n      return readContext(context);\n    },\n    useEffect: function (create, deps) {\n      currentHookNameInDev = 'useEffect';\n      updateHookTypesDev();\n      return updateEffect(create, deps);\n    },\n    useImperativeHandle: function (ref, create, deps) {\n      currentHookNameInDev = 'useImperativeHandle';\n      updateHookTypesDev();\n      return updateImperativeHandle(ref, create, deps);\n    },\n    useInsertionEffect: function (create, deps) {\n      currentHookNameInDev = 'useInsertionEffect';\n      updateHookTypesDev();\n      return updateInsertionEffect(create, deps);\n    },\n    useLayoutEffect: function (create, deps) {\n      currentHookNameInDev = 'useLayoutEffect';\n      updateHookTypesDev();\n      return updateLayoutEffect(create, deps);\n    },\n    useMemo: function (create, deps) {\n      currentHookNameInDev = 'useMemo';\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnRerenderInDEV;\n\n      try {\n        return updateMemo(create, deps);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useReducer: function (reducer, initialArg, init) {\n      currentHookNameInDev = 'useReducer';\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnRerenderInDEV;\n\n      try {\n        return rerenderReducer(reducer, initialArg, init);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useRef: function (initialValue) {\n      currentHookNameInDev = 'useRef';\n      updateHookTypesDev();\n      return updateRef();\n    },\n    useState: function (initialState) {\n      currentHookNameInDev = 'useState';\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnRerenderInDEV;\n\n      try {\n        return rerenderState(initialState);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useDebugValue: function (value, formatterFn) {\n      currentHookNameInDev = 'useDebugValue';\n      updateHookTypesDev();\n      return updateDebugValue();\n    },\n    useDeferredValue: function (value) {\n      currentHookNameInDev = 'useDeferredValue';\n      updateHookTypesDev();\n      return rerenderDeferredValue(value);\n    },\n    useTransition: function () {\n      currentHookNameInDev = 'useTransition';\n      updateHookTypesDev();\n      return rerenderTransition();\n    },\n    useMutableSource: function (source, getSnapshot, subscribe) {\n      currentHookNameInDev = 'useMutableSource';\n      updateHookTypesDev();\n      return updateMutableSource();\n    },\n    useSyncExternalStore: function (subscribe, getSnapshot, getServerSnapshot) {\n      currentHookNameInDev = 'useSyncExternalStore';\n      updateHookTypesDev();\n      return updateSyncExternalStore(subscribe, getSnapshot);\n    },\n    useId: function () {\n      currentHookNameInDev = 'useId';\n      updateHookTypesDev();\n      return updateId();\n    },\n    unstable_isNewReconciler: enableNewReconciler\n  };\n\n  InvalidNestedHooksDispatcherOnMountInDEV = {\n    readContext: function (context) {\n      warnInvalidContextAccess();\n      return readContext(context);\n    },\n    useCallback: function (callback, deps) {\n      currentHookNameInDev = 'useCallback';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      return mountCallback(callback, deps);\n    },\n    useContext: function (context) {\n      currentHookNameInDev = 'useContext';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      return readContext(context);\n    },\n    useEffect: function (create, deps) {\n      currentHookNameInDev = 'useEffect';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      return mountEffect(create, deps);\n    },\n    useImperativeHandle: function (ref, create, deps) {\n      currentHookNameInDev = 'useImperativeHandle';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      return mountImperativeHandle(ref, create, deps);\n    },\n    useInsertionEffect: function (create, deps) {\n      currentHookNameInDev = 'useInsertionEffect';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      return mountInsertionEffect(create, deps);\n    },\n    useLayoutEffect: function (create, deps) {\n      currentHookNameInDev = 'useLayoutEffect';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      return mountLayoutEffect(create, deps);\n    },\n    useMemo: function (create, deps) {\n      currentHookNameInDev = 'useMemo';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnMountInDEV;\n\n      try {\n        return mountMemo(create, deps);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useReducer: function (reducer, initialArg, init) {\n      currentHookNameInDev = 'useReducer';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnMountInDEV;\n\n      try {\n        return mountReducer(reducer, initialArg, init);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useRef: function (initialValue) {\n      currentHookNameInDev = 'useRef';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      return mountRef(initialValue);\n    },\n    useState: function (initialState) {\n      currentHookNameInDev = 'useState';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnMountInDEV;\n\n      try {\n        return mountState(initialState);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useDebugValue: function (value, formatterFn) {\n      currentHookNameInDev = 'useDebugValue';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      return mountDebugValue();\n    },\n    useDeferredValue: function (value) {\n      currentHookNameInDev = 'useDeferredValue';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      return mountDeferredValue(value);\n    },\n    useTransition: function () {\n      currentHookNameInDev = 'useTransition';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      return mountTransition();\n    },\n    useMutableSource: function (source, getSnapshot, subscribe) {\n      currentHookNameInDev = 'useMutableSource';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      return mountMutableSource();\n    },\n    useSyncExternalStore: function (subscribe, getSnapshot, getServerSnapshot) {\n      currentHookNameInDev = 'useSyncExternalStore';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      return mountSyncExternalStore(subscribe, getSnapshot, getServerSnapshot);\n    },\n    useId: function () {\n      currentHookNameInDev = 'useId';\n      warnInvalidHookAccess();\n      mountHookTypesDev();\n      return mountId();\n    },\n    unstable_isNewReconciler: enableNewReconciler\n  };\n\n  InvalidNestedHooksDispatcherOnUpdateInDEV = {\n    readContext: function (context) {\n      warnInvalidContextAccess();\n      return readContext(context);\n    },\n    useCallback: function (callback, deps) {\n      currentHookNameInDev = 'useCallback';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateCallback(callback, deps);\n    },\n    useContext: function (context) {\n      currentHookNameInDev = 'useContext';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return readContext(context);\n    },\n    useEffect: function (create, deps) {\n      currentHookNameInDev = 'useEffect';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateEffect(create, deps);\n    },\n    useImperativeHandle: function (ref, create, deps) {\n      currentHookNameInDev = 'useImperativeHandle';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateImperativeHandle(ref, create, deps);\n    },\n    useInsertionEffect: function (create, deps) {\n      currentHookNameInDev = 'useInsertionEffect';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateInsertionEffect(create, deps);\n    },\n    useLayoutEffect: function (create, deps) {\n      currentHookNameInDev = 'useLayoutEffect';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateLayoutEffect(create, deps);\n    },\n    useMemo: function (create, deps) {\n      currentHookNameInDev = 'useMemo';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnUpdateInDEV;\n\n      try {\n        return updateMemo(create, deps);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useReducer: function (reducer, initialArg, init) {\n      currentHookNameInDev = 'useReducer';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnUpdateInDEV;\n\n      try {\n        return updateReducer(reducer, initialArg, init);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useRef: function (initialValue) {\n      currentHookNameInDev = 'useRef';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateRef();\n    },\n    useState: function (initialState) {\n      currentHookNameInDev = 'useState';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnUpdateInDEV;\n\n      try {\n        return updateState(initialState);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useDebugValue: function (value, formatterFn) {\n      currentHookNameInDev = 'useDebugValue';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateDebugValue();\n    },\n    useDeferredValue: function (value) {\n      currentHookNameInDev = 'useDeferredValue';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateDeferredValue(value);\n    },\n    useTransition: function () {\n      currentHookNameInDev = 'useTransition';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateTransition();\n    },\n    useMutableSource: function (source, getSnapshot, subscribe) {\n      currentHookNameInDev = 'useMutableSource';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateMutableSource();\n    },\n    useSyncExternalStore: function (subscribe, getSnapshot, getServerSnapshot) {\n      currentHookNameInDev = 'useSyncExternalStore';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateSyncExternalStore(subscribe, getSnapshot);\n    },\n    useId: function () {\n      currentHookNameInDev = 'useId';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateId();\n    },\n    unstable_isNewReconciler: enableNewReconciler\n  };\n\n  InvalidNestedHooksDispatcherOnRerenderInDEV = {\n    readContext: function (context) {\n      warnInvalidContextAccess();\n      return readContext(context);\n    },\n    useCallback: function (callback, deps) {\n      currentHookNameInDev = 'useCallback';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateCallback(callback, deps);\n    },\n    useContext: function (context) {\n      currentHookNameInDev = 'useContext';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return readContext(context);\n    },\n    useEffect: function (create, deps) {\n      currentHookNameInDev = 'useEffect';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateEffect(create, deps);\n    },\n    useImperativeHandle: function (ref, create, deps) {\n      currentHookNameInDev = 'useImperativeHandle';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateImperativeHandle(ref, create, deps);\n    },\n    useInsertionEffect: function (create, deps) {\n      currentHookNameInDev = 'useInsertionEffect';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateInsertionEffect(create, deps);\n    },\n    useLayoutEffect: function (create, deps) {\n      currentHookNameInDev = 'useLayoutEffect';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateLayoutEffect(create, deps);\n    },\n    useMemo: function (create, deps) {\n      currentHookNameInDev = 'useMemo';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnUpdateInDEV;\n\n      try {\n        return updateMemo(create, deps);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useReducer: function (reducer, initialArg, init) {\n      currentHookNameInDev = 'useReducer';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnUpdateInDEV;\n\n      try {\n        return rerenderReducer(reducer, initialArg, init);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useRef: function (initialValue) {\n      currentHookNameInDev = 'useRef';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateRef();\n    },\n    useState: function (initialState) {\n      currentHookNameInDev = 'useState';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      var prevDispatcher = ReactCurrentDispatcher$1.current;\n      ReactCurrentDispatcher$1.current = InvalidNestedHooksDispatcherOnUpdateInDEV;\n\n      try {\n        return rerenderState(initialState);\n      } finally {\n        ReactCurrentDispatcher$1.current = prevDispatcher;\n      }\n    },\n    useDebugValue: function (value, formatterFn) {\n      currentHookNameInDev = 'useDebugValue';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateDebugValue();\n    },\n    useDeferredValue: function (value) {\n      currentHookNameInDev = 'useDeferredValue';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return rerenderDeferredValue(value);\n    },\n    useTransition: function () {\n      currentHookNameInDev = 'useTransition';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return rerenderTransition();\n    },\n    useMutableSource: function (source, getSnapshot, subscribe) {\n      currentHookNameInDev = 'useMutableSource';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateMutableSource();\n    },\n    useSyncExternalStore: function (subscribe, getSnapshot, getServerSnapshot) {\n      currentHookNameInDev = 'useSyncExternalStore';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateSyncExternalStore(subscribe, getSnapshot);\n    },\n    useId: function () {\n      currentHookNameInDev = 'useId';\n      warnInvalidHookAccess();\n      updateHookTypesDev();\n      return updateId();\n    },\n    unstable_isNewReconciler: enableNewReconciler\n  };\n}\n\nvar now$1 = Scheduler.unstable_now;\nvar commitTime = 0;\nvar layoutEffectStartTime = -1;\nvar profilerStartTime = -1;\nvar passiveEffectStartTime = -1;\n/**\n * Tracks whether the current update was a nested/cascading update (scheduled from a layout effect).\n *\n * The overall sequence is:\n *   1. render\n *   2. commit (and call `onRender`, `onCommit`)\n *   3. check for nested updates\n *   4. flush passive effects (and call `onPostCommit`)\n *\n * Nested updates are identified in step 3 above,\n * but step 4 still applies to the work that was just committed.\n * We use two flags to track nested updates then:\n * one tracks whether the upcoming update is a nested update,\n * and the other tracks whether the current update was a nested update.\n * The first value gets synced to the second at the start of the render phase.\n */\n\nvar currentUpdateIsNested = false;\nvar nestedUpdateScheduled = false;\n\nfunction isCurrentUpdateNested() {\n  return currentUpdateIsNested;\n}\n\nfunction markNestedUpdateScheduled() {\n  {\n    nestedUpdateScheduled = true;\n  }\n}\n\nfunction resetNestedUpdateFlag() {\n  {\n    currentUpdateIsNested = false;\n    nestedUpdateScheduled = false;\n  }\n}\n\nfunction syncNestedUpdateFlag() {\n  {\n    currentUpdateIsNested = nestedUpdateScheduled;\n    nestedUpdateScheduled = false;\n  }\n}\n\nfunction getCommitTime() {\n  return commitTime;\n}\n\nfunction recordCommitTime() {\n\n  commitTime = now$1();\n}\n\nfunction startProfilerTimer(fiber) {\n\n  profilerStartTime = now$1();\n\n  if (fiber.actualStartTime < 0) {\n    fiber.actualStartTime = now$1();\n  }\n}\n\nfunction stopProfilerTimerIfRunning(fiber) {\n\n  profilerStartTime = -1;\n}\n\nfunction stopProfilerTimerIfRunningAndRecordDelta(fiber, overrideBaseTime) {\n\n  if (profilerStartTime >= 0) {\n    var elapsedTime = now$1() - profilerStartTime;\n    fiber.actualDuration += elapsedTime;\n\n    if (overrideBaseTime) {\n      fiber.selfBaseDuration = elapsedTime;\n    }\n\n    profilerStartTime = -1;\n  }\n}\n\nfunction recordLayoutEffectDuration(fiber) {\n\n  if (layoutEffectStartTime >= 0) {\n    var elapsedTime = now$1() - layoutEffectStartTime;\n    layoutEffectStartTime = -1; // Store duration on the next nearest Profiler ancestor\n    // Or the root (for the DevTools Profiler to read)\n\n    var parentFiber = fiber.return;\n\n    while (parentFiber !== null) {\n      switch (parentFiber.tag) {\n        case HostRoot:\n          var root = parentFiber.stateNode;\n          root.effectDuration += elapsedTime;\n          return;\n\n        case Profiler:\n          var parentStateNode = parentFiber.stateNode;\n          parentStateNode.effectDuration += elapsedTime;\n          return;\n      }\n\n      parentFiber = parentFiber.return;\n    }\n  }\n}\n\nfunction recordPassiveEffectDuration(fiber) {\n\n  if (passiveEffectStartTime >= 0) {\n    var elapsedTime = now$1() - passiveEffectStartTime;\n    passiveEffectStartTime = -1; // Store duration on the next nearest Profiler ancestor\n    // Or the root (for the DevTools Profiler to read)\n\n    var parentFiber = fiber.return;\n\n    while (parentFiber !== null) {\n      switch (parentFiber.tag) {\n        case HostRoot:\n          var root = parentFiber.stateNode;\n\n          if (root !== null) {\n            root.passiveEffectDuration += elapsedTime;\n          }\n\n          return;\n\n        case Profiler:\n          var parentStateNode = parentFiber.stateNode;\n\n          if (parentStateNode !== null) {\n            // Detached fibers have their state node cleared out.\n            // In this case, the return pointer is also cleared out,\n            // so we won't be able to report the time spent in this Profiler's subtree.\n            parentStateNode.passiveEffectDuration += elapsedTime;\n          }\n\n          return;\n      }\n\n      parentFiber = parentFiber.return;\n    }\n  }\n}\n\nfunction startLayoutEffectTimer() {\n\n  layoutEffectStartTime = now$1();\n}\n\nfunction startPassiveEffectTimer() {\n\n  passiveEffectStartTime = now$1();\n}\n\nfunction transferActualDuration(fiber) {\n  // Transfer time spent rendering these children so we don't lose it\n  // after we rerender. This is used as a helper in special cases\n  // where we should count the work of multiple passes.\n  var child = fiber.child;\n\n  while (child) {\n    fiber.actualDuration += child.actualDuration;\n    child = child.sibling;\n  }\n}\n\nfunction createCapturedValueAtFiber(value, source) {\n  // If the value is an error, call this function immediately after it is thrown\n  // so the stack is accurate.\n  return {\n    value: value,\n    source: source,\n    stack: getStackByFiberInDevAndProd(source),\n    digest: null\n  };\n}\nfunction createCapturedValue(value, digest, stack) {\n  return {\n    value: value,\n    source: null,\n    stack: stack != null ? stack : null,\n    digest: digest != null ? digest : null\n  };\n}\n\n// This module is forked in different environments.\n// By default, return `true` to log errors to the console.\n// Forks can return `false` if this isn't desirable.\nfunction showErrorDialog(boundary, errorInfo) {\n  return true;\n}\n\nfunction logCapturedError(boundary, errorInfo) {\n  try {\n    var logError = showErrorDialog(boundary, errorInfo); // Allow injected showErrorDialog() to prevent default console.error logging.\n    // This enables renderers like ReactNative to better manage redbox behavior.\n\n    if (logError === false) {\n      return;\n    }\n\n    var error = errorInfo.value;\n\n    if (true) {\n      var source = errorInfo.source;\n      var stack = errorInfo.stack;\n      var componentStack = stack !== null ? stack : ''; // Browsers support silencing uncaught errors by calling\n      // `preventDefault()` in window `error` handler.\n      // We record this information as an expando on the error.\n\n      if (error != null && error._suppressLogging) {\n        if (boundary.tag === ClassComponent) {\n          // The error is recoverable and was silenced.\n          // Ignore it and don't print the stack addendum.\n          // This is handy for testing error boundaries without noise.\n          return;\n        } // The error is fatal. Since the silencing might have\n        // been accidental, we'll surface it anyway.\n        // However, the browser would have silenced the original error\n        // so we'll print it first, and then print the stack addendum.\n\n\n        console['error'](error); // Don't transform to our wrapper\n        // For a more detailed description of this block, see:\n        // https://github.com/facebook/react/pull/13384\n      }\n\n      var componentName = source ? getComponentNameFromFiber(source) : null;\n      var componentNameMessage = componentName ? \"The above error occurred in the <\" + componentName + \"> component:\" : 'The above error occurred in one of your React components:';\n      var errorBoundaryMessage;\n\n      if (boundary.tag === HostRoot) {\n        errorBoundaryMessage = 'Consider adding an error boundary to your tree to customize error handling behavior.\\n' + 'Visit https://reactjs.org/link/error-boundaries to learn more about error boundaries.';\n      } else {\n        var errorBoundaryName = getComponentNameFromFiber(boundary) || 'Anonymous';\n        errorBoundaryMessage = \"React will try to recreate this component tree from scratch \" + (\"using the error boundary you provided, \" + errorBoundaryName + \".\");\n      }\n\n      var combinedMessage = componentNameMessage + \"\\n\" + componentStack + \"\\n\\n\" + (\"\" + errorBoundaryMessage); // In development, we provide our own message with just the component stack.\n      // We don't include the original error message and JS stack because the browser\n      // has already printed it. Even if the application swallows the error, it is still\n      // displayed by the browser thanks to the DEV-only fake event trick in ReactErrorUtils.\n\n      console['error'](combinedMessage); // Don't transform to our wrapper\n    } else {}\n  } catch (e) {\n    // This method must not throw, or React internal state will get messed up.\n    // If console.error is overridden, or logCapturedError() shows a dialog that throws,\n    // we want to report this error outside of the normal stack as a last resort.\n    // https://github.com/facebook/react/issues/13188\n    setTimeout(function () {\n      throw e;\n    });\n  }\n}\n\nvar PossiblyWeakMap$1 = typeof WeakMap === 'function' ? WeakMap : Map;\n\nfunction createRootErrorUpdate(fiber, errorInfo, lane) {\n  var update = createUpdate(NoTimestamp, lane); // Unmount the root by rendering null.\n\n  update.tag = CaptureUpdate; // Caution: React DevTools currently depends on this property\n  // being called \"element\".\n\n  update.payload = {\n    element: null\n  };\n  var error = errorInfo.value;\n\n  update.callback = function () {\n    onUncaughtError(error);\n    logCapturedError(fiber, errorInfo);\n  };\n\n  return update;\n}\n\nfunction createClassErrorUpdate(fiber, errorInfo, lane) {\n  var update = createUpdate(NoTimestamp, lane);\n  update.tag = CaptureUpdate;\n  var getDerivedStateFromError = fiber.type.getDerivedStateFromError;\n\n  if (typeof getDerivedStateFromError === 'function') {\n    var error$1 = errorInfo.value;\n\n    update.payload = function () {\n      return getDerivedStateFromError(error$1);\n    };\n\n    update.callback = function () {\n      {\n        markFailedErrorBoundaryForHotReloading(fiber);\n      }\n\n      logCapturedError(fiber, errorInfo);\n    };\n  }\n\n  var inst = fiber.stateNode;\n\n  if (inst !== null && typeof inst.componentDidCatch === 'function') {\n    update.callback = function callback() {\n      {\n        markFailedErrorBoundaryForHotReloading(fiber);\n      }\n\n      logCapturedError(fiber, errorInfo);\n\n      if (typeof getDerivedStateFromError !== 'function') {\n        // To preserve the preexisting retry behavior of error boundaries,\n        // we keep track of which ones already failed during this batch.\n        // This gets reset before we yield back to the browser.\n        // TODO: Warn in strict mode if getDerivedStateFromError is\n        // not defined.\n        markLegacyErrorBoundaryAsFailed(this);\n      }\n\n      var error$1 = errorInfo.value;\n      var stack = errorInfo.stack;\n      this.componentDidCatch(error$1, {\n        componentStack: stack !== null ? stack : ''\n      });\n\n      {\n        if (typeof getDerivedStateFromError !== 'function') {\n          // If componentDidCatch is the only error boundary method defined,\n          // then it needs to call setState to recover from errors.\n          // If no state update is scheduled then the boundary will swallow the error.\n          if (!includesSomeLane(fiber.lanes, SyncLane)) {\n            error('%s: Error boundaries should implement getDerivedStateFromError(). ' + 'In that method, return a state update to display an error message or fallback UI.', getComponentNameFromFiber(fiber) || 'Unknown');\n          }\n        }\n      }\n    };\n  }\n\n  return update;\n}\n\nfunction attachPingListener(root, wakeable, lanes) {\n  // Attach a ping listener\n  //\n  // The data might resolve before we have a chance to commit the fallback. Or,\n  // in the case of a refresh, we'll never commit a fallback. So we need to\n  // attach a listener now. When it resolves (\"pings\"), we can decide whether to\n  // try rendering the tree again.\n  //\n  // Only attach a listener if one does not already exist for the lanes\n  // we're currently rendering (which acts like a \"thread ID\" here).\n  //\n  // We only need to do this in concurrent mode. Legacy Suspense always\n  // commits fallbacks synchronously, so there are no pings.\n  var pingCache = root.pingCache;\n  var threadIDs;\n\n  if (pingCache === null) {\n    pingCache = root.pingCache = new PossiblyWeakMap$1();\n    threadIDs = new Set();\n    pingCache.set(wakeable, threadIDs);\n  } else {\n    threadIDs = pingCache.get(wakeable);\n\n    if (threadIDs === undefined) {\n      threadIDs = new Set();\n      pingCache.set(wakeable, threadIDs);\n    }\n  }\n\n  if (!threadIDs.has(lanes)) {\n    // Memoize using the thread ID to prevent redundant listeners.\n    threadIDs.add(lanes);\n    var ping = pingSuspendedRoot.bind(null, root, wakeable, lanes);\n\n    {\n      if (isDevToolsPresent) {\n        // If we have pending work still, restore the original updaters\n        restorePendingUpdaters(root, lanes);\n      }\n    }\n\n    wakeable.then(ping, ping);\n  }\n}\n\nfunction attachRetryListener(suspenseBoundary, root, wakeable, lanes) {\n  // Retry listener\n  //\n  // If the fallback does commit, we need to attach a different type of\n  // listener. This one schedules an update on the Suspense boundary to turn\n  // the fallback state off.\n  //\n  // Stash the wakeable on the boundary fiber so we can access it in the\n  // commit phase.\n  //\n  // When the wakeable resolves, we'll attempt to render the boundary\n  // again (\"retry\").\n  var wakeables = suspenseBoundary.updateQueue;\n\n  if (wakeables === null) {\n    var updateQueue = new Set();\n    updateQueue.add(wakeable);\n    suspenseBoundary.updateQueue = updateQueue;\n  } else {\n    wakeables.add(wakeable);\n  }\n}\n\nfunction resetSuspendedComponent(sourceFiber, rootRenderLanes) {\n  // A legacy mode Suspense quirk, only relevant to hook components.\n\n\n  var tag = sourceFiber.tag;\n\n  if ((sourceFiber.mode & ConcurrentMode) === NoMode && (tag === FunctionComponent || tag === ForwardRef || tag === SimpleMemoComponent)) {\n    var currentSource = sourceFiber.alternate;\n\n    if (currentSource) {\n      sourceFiber.updateQueue = currentSource.updateQueue;\n      sourceFiber.memoizedState = currentSource.memoizedState;\n      sourceFiber.lanes = currentSource.lanes;\n    } else {\n      sourceFiber.updateQueue = null;\n      sourceFiber.memoizedState = null;\n    }\n  }\n}\n\nfunction getNearestSuspenseBoundaryToCapture(returnFiber) {\n  var node = returnFiber;\n\n  do {\n    if (node.tag === SuspenseComponent && shouldCaptureSuspense(node)) {\n      return node;\n    } // This boundary already captured during this render. Continue to the next\n    // boundary.\n\n\n    node = node.return;\n  } while (node !== null);\n\n  return null;\n}\n\nfunction markSuspenseBoundaryShouldCapture(suspenseBoundary, returnFiber, sourceFiber, root, rootRenderLanes) {\n  // This marks a Suspense boundary so that when we're unwinding the stack,\n  // it captures the suspended \"exception\" and does a second (fallback) pass.\n  if ((suspenseBoundary.mode & ConcurrentMode) === NoMode) {\n    // Legacy Mode Suspense\n    //\n    // If the boundary is in legacy mode, we should *not*\n    // suspend the commit. Pretend as if the suspended component rendered\n    // null and keep rendering. When the Suspense boundary completes,\n    // we'll do a second pass to render the fallback.\n    if (suspenseBoundary === returnFiber) {\n      // Special case where we suspended while reconciling the children of\n      // a Suspense boundary's inner Offscreen wrapper fiber. This happens\n      // when a React.lazy component is a direct child of a\n      // Suspense boundary.\n      //\n      // Suspense boundaries are implemented as multiple fibers, but they\n      // are a single conceptual unit. The legacy mode behavior where we\n      // pretend the suspended fiber committed as `null` won't work,\n      // because in this case the \"suspended\" fiber is the inner\n      // Offscreen wrapper.\n      //\n      // Because the contents of the boundary haven't started rendering\n      // yet (i.e. nothing in the tree has partially rendered) we can\n      // switch to the regular, concurrent mode behavior: mark the\n      // boundary with ShouldCapture and enter the unwind phase.\n      suspenseBoundary.flags |= ShouldCapture;\n    } else {\n      suspenseBoundary.flags |= DidCapture;\n      sourceFiber.flags |= ForceUpdateForLegacySuspense; // We're going to commit this fiber even though it didn't complete.\n      // But we shouldn't call any lifecycle methods or callbacks. Remove\n      // all lifecycle effect tags.\n\n      sourceFiber.flags &= ~(LifecycleEffectMask | Incomplete);\n\n      if (sourceFiber.tag === ClassComponent) {\n        var currentSourceFiber = sourceFiber.alternate;\n\n        if (currentSourceFiber === null) {\n          // This is a new mount. Change the tag so it's not mistaken for a\n          // completed class component. For example, we should not call\n          // componentWillUnmount if it is deleted.\n          sourceFiber.tag = IncompleteClassComponent;\n        } else {\n          // When we try rendering again, we should not reuse the current fiber,\n          // since it's known to be in an inconsistent state. Use a force update to\n          // prevent a bail out.\n          var update = createUpdate(NoTimestamp, SyncLane);\n          update.tag = ForceUpdate;\n          enqueueUpdate(sourceFiber, update, SyncLane);\n        }\n      } // The source fiber did not complete. Mark it with Sync priority to\n      // indicate that it still has pending work.\n\n\n      sourceFiber.lanes = mergeLanes(sourceFiber.lanes, SyncLane);\n    }\n\n    return suspenseBoundary;\n  } // Confirmed that the boundary is in a concurrent mode tree. Continue\n  // with the normal suspend path.\n  //\n  // After this we'll use a set of heuristics to determine whether this\n  // render pass will run to completion or restart or \"suspend\" the commit.\n  // The actual logic for this is spread out in different places.\n  //\n  // This first principle is that if we're going to suspend when we complete\n  // a root, then we should also restart if we get an update or ping that\n  // might unsuspend it, and vice versa. The only reason to suspend is\n  // because you think you might want to restart before committing. However,\n  // it doesn't make sense to restart only while in the period we're suspended.\n  //\n  // Restarting too aggressively is also not good because it starves out any\n  // intermediate loading state. So we use heuristics to determine when.\n  // Suspense Heuristics\n  //\n  // If nothing threw a Promise or all the same fallbacks are already showing,\n  // then don't suspend/restart.\n  //\n  // If this is an initial render of a new tree of Suspense boundaries and\n  // those trigger a fallback, then don't suspend/restart. We want to ensure\n  // that we can show the initial loading state as quickly as possible.\n  //\n  // If we hit a \"Delayed\" case, such as when we'd switch from content back into\n  // a fallback, then we should always suspend/restart. Transitions apply\n  // to this case. If none is defined, JND is used instead.\n  //\n  // If we're already showing a fallback and it gets \"retried\", allowing us to show\n  // another level, but there's still an inner boundary that would show a fallback,\n  // then we suspend/restart for 500ms since the last time we showed a fallback\n  // anywhere in the tree. This effectively throttles progressive loading into a\n  // consistent train of commits. This also gives us an opportunity to restart to\n  // get to the completed state slightly earlier.\n  //\n  // If there's ambiguity due to batching it's resolved in preference of:\n  // 1) \"delayed\", 2) \"initial render\", 3) \"retry\".\n  //\n  // We want to ensure that a \"busy\" state doesn't get force committed. We want to\n  // ensure that new initial loading states can commit as soon as possible.\n\n\n  suspenseBoundary.flags |= ShouldCapture; // TODO: I think we can remove this, since we now use `DidCapture` in\n  // the begin phase to prevent an early bailout.\n\n  suspenseBoundary.lanes = rootRenderLanes;\n  return suspenseBoundary;\n}\n\nfunction throwException(root, returnFiber, sourceFiber, value, rootRenderLanes) {\n  // The source fiber did not complete.\n  sourceFiber.flags |= Incomplete;\n\n  {\n    if (isDevToolsPresent) {\n      // If we have pending work still, restore the original updaters\n      restorePendingUpdaters(root, rootRenderLanes);\n    }\n  }\n\n  if (value !== null && typeof value === 'object' && typeof value.then === 'function') {\n    // This is a wakeable. The component suspended.\n    var wakeable = value;\n    resetSuspendedComponent(sourceFiber);\n\n    {\n      if (getIsHydrating() && sourceFiber.mode & ConcurrentMode) {\n        markDidThrowWhileHydratingDEV();\n      }\n    }\n\n\n    var suspenseBoundary = getNearestSuspenseBoundaryToCapture(returnFiber);\n\n    if (suspenseBoundary !== null) {\n      suspenseBoundary.flags &= ~ForceClientRender;\n      markSuspenseBoundaryShouldCapture(suspenseBoundary, returnFiber, sourceFiber, root, rootRenderLanes); // We only attach ping listeners in concurrent mode. Legacy Suspense always\n      // commits fallbacks synchronously, so there are no pings.\n\n      if (suspenseBoundary.mode & ConcurrentMode) {\n        attachPingListener(root, wakeable, rootRenderLanes);\n      }\n\n      attachRetryListener(suspenseBoundary, root, wakeable);\n      return;\n    } else {\n      // No boundary was found. Unless this is a sync update, this is OK.\n      // We can suspend and wait for more data to arrive.\n      if (!includesSyncLane(rootRenderLanes)) {\n        // This is not a sync update. Suspend. Since we're not activating a\n        // Suspense boundary, this will unwind all the way to the root without\n        // performing a second pass to render a fallback. (This is arguably how\n        // refresh transitions should work, too, since we're not going to commit\n        // the fallbacks anyway.)\n        //\n        // This case also applies to initial hydration.\n        attachPingListener(root, wakeable, rootRenderLanes);\n        renderDidSuspendDelayIfPossible();\n        return;\n      } // This is a sync/discrete update. We treat this case like an error\n      // because discrete renders are expected to produce a complete tree\n      // synchronously to maintain consistency with external state.\n\n\n      var uncaughtSuspenseError = new Error('A component suspended while responding to synchronous input. This ' + 'will cause the UI to be replaced with a loading indicator. To ' + 'fix, updates that suspend should be wrapped ' + 'with startTransition.'); // If we're outside a transition, fall through to the regular error path.\n      // The error will be caught by the nearest suspense boundary.\n\n      value = uncaughtSuspenseError;\n    }\n  } else {\n    // This is a regular error, not a Suspense wakeable.\n    if (getIsHydrating() && sourceFiber.mode & ConcurrentMode) {\n      markDidThrowWhileHydratingDEV();\n\n      var _suspenseBoundary = getNearestSuspenseBoundaryToCapture(returnFiber); // If the error was thrown during hydration, we may be able to recover by\n      // discarding the dehydrated content and switching to a client render.\n      // Instead of surfacing the error, find the nearest Suspense boundary\n      // and render it again without hydration.\n\n\n      if (_suspenseBoundary !== null) {\n        if ((_suspenseBoundary.flags & ShouldCapture) === NoFlags) {\n          // Set a flag to indicate that we should try rendering the normal\n          // children again, not the fallback.\n          _suspenseBoundary.flags |= ForceClientRender;\n        }\n\n        markSuspenseBoundaryShouldCapture(_suspenseBoundary, returnFiber, sourceFiber, root, rootRenderLanes); // Even though the user may not be affected by this error, we should\n        // still log it so it can be fixed.\n\n        queueHydrationError(createCapturedValueAtFiber(value, sourceFiber));\n        return;\n      }\n    }\n  }\n\n  value = createCapturedValueAtFiber(value, sourceFiber);\n  renderDidError(value); // We didn't find a boundary that could handle this type of exception. Start\n  // over and traverse parent path again, this time treating the exception\n  // as an error.\n\n  var workInProgress = returnFiber;\n\n  do {\n    switch (workInProgress.tag) {\n      case HostRoot:\n        {\n          var _errorInfo = value;\n          workInProgress.flags |= ShouldCapture;\n          var lane = pickArbitraryLane(rootRenderLanes);\n          workInProgress.lanes = mergeLanes(workInProgress.lanes, lane);\n          var update = createRootErrorUpdate(workInProgress, _errorInfo, lane);\n          enqueueCapturedUpdate(workInProgress, update);\n          return;\n        }\n\n      case ClassComponent:\n        // Capture and retry\n        var errorInfo = value;\n        var ctor = workInProgress.type;\n        var instance = workInProgress.stateNode;\n\n        if ((workInProgress.flags & DidCapture) === NoFlags && (typeof ctor.getDerivedStateFromError === 'function' || instance !== null && typeof instance.componentDidCatch === 'function' && !isAlreadyFailedLegacyErrorBoundary(instance))) {\n          workInProgress.flags |= ShouldCapture;\n\n          var _lane = pickArbitraryLane(rootRenderLanes);\n\n          workInProgress.lanes = mergeLanes(workInProgress.lanes, _lane); // Schedule the error boundary to re-render using updated state\n\n          var _update = createClassErrorUpdate(workInProgress, errorInfo, _lane);\n\n          enqueueCapturedUpdate(workInProgress, _update);\n          return;\n        }\n\n        break;\n    }\n\n    workInProgress = workInProgress.return;\n  } while (workInProgress !== null);\n}\n\nfunction getSuspendedCache() {\n  {\n    return null;\n  } // This function is called when a Suspense boundary suspends. It returns the\n}\n\nvar ReactCurrentOwner$1 = ReactSharedInternals.ReactCurrentOwner;\nvar didReceiveUpdate = false;\nvar didWarnAboutBadClass;\nvar didWarnAboutModulePatternComponent;\nvar didWarnAboutContextTypeOnFunctionComponent;\nvar didWarnAboutGetDerivedStateOnFunctionComponent;\nvar didWarnAboutFunctionRefs;\nvar didWarnAboutReassigningProps;\nvar didWarnAboutRevealOrder;\nvar didWarnAboutTailOptions;\n\n{\n  didWarnAboutBadClass = {};\n  didWarnAboutModulePatternComponent = {};\n  didWarnAboutContextTypeOnFunctionComponent = {};\n  didWarnAboutGetDerivedStateOnFunctionComponent = {};\n  didWarnAboutFunctionRefs = {};\n  didWarnAboutReassigningProps = false;\n  didWarnAboutRevealOrder = {};\n  didWarnAboutTailOptions = {};\n}\n\nfunction reconcileChildren(current, workInProgress, nextChildren, renderLanes) {\n  if (current === null) {\n    // If this is a fresh new component that hasn't been rendered yet, we\n    // won't update its child set by applying minimal side-effects. Instead,\n    // we will add them all to the child before it gets rendered. That means\n    // we can optimize this reconciliation pass by not tracking side-effects.\n    workInProgress.child = mountChildFibers(workInProgress, null, nextChildren, renderLanes);\n  } else {\n    // If the current child is the same as the work in progress, it means that\n    // we haven't yet started any work on these children. Therefore, we use\n    // the clone algorithm to create a copy of all the current children.\n    // If we had any progressed work already, that is invalid at this point so\n    // let's throw it out.\n    workInProgress.child = reconcileChildFibers(workInProgress, current.child, nextChildren, renderLanes);\n  }\n}\n\nfunction forceUnmountCurrentAndReconcile(current, workInProgress, nextChildren, renderLanes) {\n  // This function is fork of reconcileChildren. It's used in cases where we\n  // want to reconcile without matching against the existing set. This has the\n  // effect of all current children being unmounted; even if the type and key\n  // are the same, the old child is unmounted and a new child is created.\n  //\n  // To do this, we're going to go through the reconcile algorithm twice. In\n  // the first pass, we schedule a deletion for all the current children by\n  // passing null.\n  workInProgress.child = reconcileChildFibers(workInProgress, current.child, null, renderLanes); // In the second pass, we mount the new children. The trick here is that we\n  // pass null in place of where we usually pass the current child set. This has\n  // the effect of remounting all children regardless of whether their\n  // identities match.\n\n  workInProgress.child = reconcileChildFibers(workInProgress, null, nextChildren, renderLanes);\n}\n\nfunction updateForwardRef(current, workInProgress, Component, nextProps, renderLanes) {\n  // TODO: current can be non-null here even if the component\n  // hasn't yet mounted. This happens after the first render suspends.\n  // We'll need to figure out if this is fine or can cause issues.\n  {\n    if (workInProgress.type !== workInProgress.elementType) {\n      // Lazy component props can't be validated in createElement\n      // because they're only guaranteed to be resolved here.\n      var innerPropTypes = Component.propTypes;\n\n      if (innerPropTypes) {\n        checkPropTypes(innerPropTypes, nextProps, // Resolved props\n        'prop', getComponentNameFromType(Component));\n      }\n    }\n  }\n\n  var render = Component.render;\n  var ref = workInProgress.ref; // The rest is a fork of updateFunctionComponent\n\n  var nextChildren;\n  var hasId;\n  prepareToReadContext(workInProgress, renderLanes);\n\n  {\n    markComponentRenderStarted(workInProgress);\n  }\n\n  {\n    ReactCurrentOwner$1.current = workInProgress;\n    setIsRendering(true);\n    nextChildren = renderWithHooks(current, workInProgress, render, nextProps, ref, renderLanes);\n    hasId = checkDidRenderIdHook();\n\n    if ( workInProgress.mode & StrictLegacyMode) {\n      setIsStrictModeForDevtools(true);\n\n      try {\n        nextChildren = renderWithHooks(current, workInProgress, render, nextProps, ref, renderLanes);\n        hasId = checkDidRenderIdHook();\n      } finally {\n        setIsStrictModeForDevtools(false);\n      }\n    }\n\n    setIsRendering(false);\n  }\n\n  {\n    markComponentRenderStopped();\n  }\n\n  if (current !== null && !didReceiveUpdate) {\n    bailoutHooks(current, workInProgress, renderLanes);\n    return bailoutOnAlreadyFinishedWork(current, workInProgress, renderLanes);\n  }\n\n  if (getIsHydrating() && hasId) {\n    pushMaterializedTreeId(workInProgress);\n  } // React DevTools reads this flag.\n\n\n  workInProgress.flags |= PerformedWork;\n  reconcileChildren(current, workInProgress, nextChildren, renderLanes);\n  return workInProgress.child;\n}\n\nfunction updateMemoComponent(current, workInProgress, Component, nextProps, renderLanes) {\n  if (current === null) {\n    var type = Component.type;\n\n    if (isSimpleFunctionComponent(type) && Component.compare === null && // SimpleMemoComponent codepath doesn't resolve outer props either.\n    Component.defaultProps === undefined) {\n      var resolvedType = type;\n\n      {\n        resolvedType = resolveFunctionForHotReloading(type);\n      } // If this is a plain function component without default props,\n      // and with only the default shallow comparison, we upgrade it\n      // to a SimpleMemoComponent to allow fast path updates.\n\n\n      workInProgress.tag = SimpleMemoComponent;\n      workInProgress.type = resolvedType;\n\n      {\n        validateFunctionComponentInDev(workInProgress, type);\n      }\n\n      return updateSimpleMemoComponent(current, workInProgress, resolvedType, nextProps, renderLanes);\n    }\n\n    {\n      var innerPropTypes = type.propTypes;\n\n      if (innerPropTypes) {\n        // Inner memo component props aren't currently validated in createElement.\n        // We could move it there, but we'd still need this for lazy code path.\n        checkPropTypes(innerPropTypes, nextProps, // Resolved props\n        'prop', getComponentNameFromType(type));\n      }\n    }\n\n    var child = createFiberFromTypeAndProps(Component.type, null, nextProps, workInProgress, workInProgress.mode, renderLanes);\n    child.ref = workInProgress.ref;\n    child.return = workInProgress;\n    workInProgress.child = child;\n    return child;\n  }\n\n  {\n    var _type = Component.type;\n    var _innerPropTypes = _type.propTypes;\n\n    if (_innerPropTypes) {\n      // Inner memo component props aren't currently validated in createElement.\n      // We could move it there, but we'd still need this for lazy code path.\n      checkPropTypes(_innerPropTypes, nextProps, // Resolved props\n      'prop', getComponentNameFromType(_type));\n    }\n  }\n\n  var currentChild = current.child; // This is always exactly one child\n\n  var hasScheduledUpdateOrContext = checkScheduledUpdateOrContext(current, renderLanes);\n\n  if (!hasScheduledUpdateOrContext) {\n    // This will be the props with resolved defaultProps,\n    // unlike current.memoizedProps which will be the unresolved ones.\n    var prevProps = currentChild.memoizedProps; // Default to shallow comparison\n\n    var compare = Component.compare;\n    compare = compare !== null ? compare : shallowEqual;\n\n    if (compare(prevProps, nextProps) && current.ref === workInProgress.ref) {\n      return bailoutOnAlreadyFinishedWork(current, workInProgress, renderLanes);\n    }\n  } // React DevTools reads this flag.\n\n\n  workInProgress.flags |= PerformedWork;\n  var newChild = createWorkInProgress(currentChild, nextProps);\n  newChild.ref = workInProgress.ref;\n  newChild.return = workInProgress;\n  workInProgress.child = newChild;\n  return newChild;\n}\n\nfunction updateSimpleMemoComponent(current, workInProgress, Component, nextProps, renderLanes) {\n  // TODO: current can be non-null here even if the component\n  // hasn't yet mounted. This happens when the inner render suspends.\n  // We'll need to figure out if this is fine or can cause issues.\n  {\n    if (workInProgress.type !== workInProgress.elementType) {\n      // Lazy component props can't be validated in createElement\n      // because they're only guaranteed to be resolved here.\n      var outerMemoType = workInProgress.elementType;\n\n      if (outerMemoType.$$typeof === REACT_LAZY_TYPE) {\n        // We warn when you define propTypes on lazy()\n        // so let's just skip over it to find memo() outer wrapper.\n        // Inner props for memo are validated later.\n        var lazyComponent = outerMemoType;\n        var payload = lazyComponent._payload;\n        var init = lazyComponent._init;\n\n        try {\n          outerMemoType = init(payload);\n        } catch (x) {\n          outerMemoType = null;\n        } // Inner propTypes will be validated in the function component path.\n\n\n        var outerPropTypes = outerMemoType && outerMemoType.propTypes;\n\n        if (outerPropTypes) {\n          checkPropTypes(outerPropTypes, nextProps, // Resolved (SimpleMemoComponent has no defaultProps)\n          'prop', getComponentNameFromType(outerMemoType));\n        }\n      }\n    }\n  }\n\n  if (current !== null) {\n    var prevProps = current.memoizedProps;\n\n    if (shallowEqual(prevProps, nextProps) && current.ref === workInProgress.ref && ( // Prevent bailout if the implementation changed due to hot reload.\n     workInProgress.type === current.type )) {\n      didReceiveUpdate = false; // The props are shallowly equal. Reuse the previous props object, like we\n      // would during a normal fiber bailout.\n      //\n      // We don't have strong guarantees that the props object is referentially\n      // equal during updates where we can't bail out anyway  like if the props\n      // are shallowly equal, but there's a local state or context update in the\n      // same batch.\n      //\n      // However, as a principle, we should aim to make the behavior consistent\n      // across different ways of memoizing a component. For example, React.memo\n      // has a different internal Fiber layout if you pass a normal function\n      // component (SimpleMemoComponent) versus if you pass a different type\n      // like forwardRef (MemoComponent). But this is an implementation detail.\n      // Wrapping a component in forwardRef (or React.lazy, etc) shouldn't\n      // affect whether the props object is reused during a bailout.\n\n      workInProgress.pendingProps = nextProps = prevProps;\n\n      if (!checkScheduledUpdateOrContext(current, renderLanes)) {\n        // The pending lanes were cleared at the beginning of beginWork. We're\n        // about to bail out, but there might be other lanes that weren't\n        // included in the current render. Usually, the priority level of the\n        // remaining updates is accumulated during the evaluation of the\n        // component (i.e. when processing the update queue). But since since\n        // we're bailing out early *without* evaluating the component, we need\n        // to account for it here, too. Reset to the value of the current fiber.\n        // NOTE: This only applies to SimpleMemoComponent, not MemoComponent,\n        // because a MemoComponent fiber does not have hooks or an update queue;\n        // rather, it wraps around an inner component, which may or may not\n        // contains hooks.\n        // TODO: Move the reset at in beginWork out of the common path so that\n        // this is no longer necessary.\n        workInProgress.lanes = current.lanes;\n        return bailoutOnAlreadyFinishedWork(current, workInProgress, renderLanes);\n      } else if ((current.flags & ForceUpdateForLegacySuspense) !== NoFlags) {\n        // This is a special case that only exists for legacy mode.\n        // See https://github.com/facebook/react/pull/19216.\n        didReceiveUpdate = true;\n      }\n    }\n  }\n\n  return updateFunctionComponent(current, workInProgress, Component, nextProps, renderLanes);\n}\n\nfunction updateOffscreenComponent(current, workInProgress, renderLanes) {\n  var nextProps = workInProgress.pendingProps;\n  var nextChildren = nextProps.children;\n  var prevState = current !== null ? current.memoizedState : null;\n\n  if (nextProps.mode === 'hidden' || enableLegacyHidden ) {\n    // Rendering a hidden tree.\n    if ((workInProgress.mode & ConcurrentMode) === NoMode) {\n      // In legacy sync mode, don't defer the subtree. Render it now.\n      // TODO: Consider how Offscreen should work with transitions in the future\n      var nextState = {\n        baseLanes: NoLanes,\n        cachePool: null,\n        transitions: null\n      };\n      workInProgress.memoizedState = nextState;\n\n      pushRenderLanes(workInProgress, renderLanes);\n    } else if (!includesSomeLane(renderLanes, OffscreenLane)) {\n      var spawnedCachePool = null; // We're hidden, and we're not rendering at Offscreen. We will bail out\n      // and resume this tree later.\n\n      var nextBaseLanes;\n\n      if (prevState !== null) {\n        var prevBaseLanes = prevState.baseLanes;\n        nextBaseLanes = mergeLanes(prevBaseLanes, renderLanes);\n      } else {\n        nextBaseLanes = renderLanes;\n      } // Schedule this fiber to re-render at offscreen priority. Then bailout.\n\n\n      workInProgress.lanes = workInProgress.childLanes = laneToLanes(OffscreenLane);\n      var _nextState = {\n        baseLanes: nextBaseLanes,\n        cachePool: spawnedCachePool,\n        transitions: null\n      };\n      workInProgress.memoizedState = _nextState;\n      workInProgress.updateQueue = null;\n      // to avoid a push/pop misalignment.\n\n\n      pushRenderLanes(workInProgress, nextBaseLanes);\n\n      return null;\n    } else {\n      // This is the second render. The surrounding visible content has already\n      // committed. Now we resume rendering the hidden tree.\n      // Rendering at offscreen, so we can clear the base lanes.\n      var _nextState2 = {\n        baseLanes: NoLanes,\n        cachePool: null,\n        transitions: null\n      };\n      workInProgress.memoizedState = _nextState2; // Push the lanes that were skipped when we bailed out.\n\n      var subtreeRenderLanes = prevState !== null ? prevState.baseLanes : renderLanes;\n\n      pushRenderLanes(workInProgress, subtreeRenderLanes);\n    }\n  } else {\n    // Rendering a visible tree.\n    var _subtreeRenderLanes;\n\n    if (prevState !== null) {\n      // We're going from hidden -> visible.\n      _subtreeRenderLanes = mergeLanes(prevState.baseLanes, renderLanes);\n\n      workInProgress.memoizedState = null;\n    } else {\n      // We weren't previously hidden, and we still aren't, so there's nothing\n      // special to do. Need to push to the stack regardless, though, to avoid\n      // a push/pop misalignment.\n      _subtreeRenderLanes = renderLanes;\n    }\n\n    pushRenderLanes(workInProgress, _subtreeRenderLanes);\n  }\n\n  reconcileChildren(current, workInProgress, nextChildren, renderLanes);\n  return workInProgress.child;\n} // Note: These happen to have identical begin phases, for now. We shouldn't hold\n\nfunction updateFragment(current, workInProgress, renderLanes) {\n  var nextChildren = workInProgress.pendingProps;\n  reconcileChildren(current, workInProgress, nextChildren, renderLanes);\n  return workInProgress.child;\n}\n\nfunction updateMode(current, workInProgress, renderLanes) {\n  var nextChildren = workInProgress.pendingProps.children;\n  reconcileChildren(current, workInProgress, nextChildren, renderLanes);\n  return workInProgress.child;\n}\n\nfunction updateProfiler(current, workInProgress, renderLanes) {\n  {\n    workInProgress.flags |= Update;\n\n    {\n      // Reset effect durations for the next eventual effect phase.\n      // These are reset during render to allow the DevTools commit hook a chance to read them,\n      var stateNode = workInProgress.stateNode;\n      stateNode.effectDuration = 0;\n      stateNode.passiveEffectDuration = 0;\n    }\n  }\n\n  var nextProps = workInProgress.pendingProps;\n  var nextChildren = nextProps.children;\n  reconcileChildren(current, workInProgress, nextChildren, renderLanes);\n  return workInProgress.child;\n}\n\nfunction markRef(current, workInProgress) {\n  var ref = workInProgress.ref;\n\n  if (current === null && ref !== null || current !== null && current.ref !== ref) {\n    // Schedule a Ref effect\n    workInProgress.flags |= Ref;\n\n    {\n      workInProgress.flags |= RefStatic;\n    }\n  }\n}\n\nfunction updateFunctionComponent(current, workInProgress, Component, nextProps, renderLanes) {\n  {\n    if (workInProgress.type !== workInProgress.elementType) {\n      // Lazy component props can't be validated in createElement\n      // because they're only guaranteed to be resolved here.\n      var innerPropTypes = Component.propTypes;\n\n      if (innerPropTypes) {\n        checkPropTypes(innerPropTypes, nextProps, // Resolved props\n        'prop', getComponentNameFromType(Component));\n      }\n    }\n  }\n\n  var context;\n\n  {\n    var unmaskedContext = getUnmaskedContext(workInProgress, Component, true);\n    context = getMaskedContext(workInProgress, unmaskedContext);\n  }\n\n  var nextChildren;\n  var hasId;\n  prepareToReadContext(workInProgress, renderLanes);\n\n  {\n    markComponentRenderStarted(workInProgress);\n  }\n\n  {\n    ReactCurrentOwner$1.current = workInProgress;\n    setIsRendering(true);\n    nextChildren = renderWithHooks(current, workInProgress, Component, nextProps, context, renderLanes);\n    hasId = checkDidRenderIdHook();\n\n    if ( workInProgress.mode & StrictLegacyMode) {\n      setIsStrictModeForDevtools(true);\n\n      try {\n        nextChildren = renderWithHooks(current, workInProgress, Component, nextProps, context, renderLanes);\n        hasId = checkDidRenderIdHook();\n      } finally {\n        setIsStrictModeForDevtools(false);\n      }\n    }\n\n    setIsRendering(false);\n  }\n\n  {\n    markComponentRenderStopped();\n  }\n\n  if (current !== null && !didReceiveUpdate) {\n    bailoutHooks(current, workInProgress, renderLanes);\n    return bailoutOnAlreadyFinishedWork(current, workInProgress, renderLanes);\n  }\n\n  if (getIsHydrating() && hasId) {\n    pushMaterializedTreeId(workInProgress);\n  } // React DevTools reads this flag.\n\n\n  workInProgress.flags |= PerformedWork;\n  reconcileChildren(current, workInProgress, nextChildren, renderLanes);\n  return workInProgress.child;\n}\n\nfunction updateClassComponent(current, workInProgress, Component, nextProps, renderLanes) {\n  {\n    // This is used by DevTools to force a boundary to error.\n    switch (shouldError(workInProgress)) {\n      case false:\n        {\n          var _instance = workInProgress.stateNode;\n          var ctor = workInProgress.type; // TODO This way of resetting the error boundary state is a hack.\n          // Is there a better way to do this?\n\n          var tempInstance = new ctor(workInProgress.memoizedProps, _instance.context);\n          var state = tempInstance.state;\n\n          _instance.updater.enqueueSetState(_instance, state, null);\n\n          break;\n        }\n\n      case true:\n        {\n          workInProgress.flags |= DidCapture;\n          workInProgress.flags |= ShouldCapture; // eslint-disable-next-line react-internal/prod-error-codes\n\n          var error$1 = new Error('Simulated error coming from DevTools');\n          var lane = pickArbitraryLane(renderLanes);\n          workInProgress.lanes = mergeLanes(workInProgress.lanes, lane); // Schedule the error boundary to re-render using updated state\n\n          var update = createClassErrorUpdate(workInProgress, createCapturedValueAtFiber(error$1, workInProgress), lane);\n          enqueueCapturedUpdate(workInProgress, update);\n          break;\n        }\n    }\n\n    if (workInProgress.type !== workInProgress.elementType) {\n      // Lazy component props can't be validated in createElement\n      // because they're only guaranteed to be resolved here.\n      var innerPropTypes = Component.propTypes;\n\n      if (innerPropTypes) {\n        checkPropTypes(innerPropTypes, nextProps, // Resolved props\n        'prop', getComponentNameFromType(Component));\n      }\n    }\n  } // Push context providers early to prevent context stack mismatches.\n  // During mounting we don't know the child context yet as the instance doesn't exist.\n  // We will invalidate the child context in finishClassComponent() right after rendering.\n\n\n  var hasContext;\n\n  if (isContextProvider(Component)) {\n    hasContext = true;\n    pushContextProvider(workInProgress);\n  } else {\n    hasContext = false;\n  }\n\n  prepareToReadContext(workInProgress, renderLanes);\n  var instance = workInProgress.stateNode;\n  var shouldUpdate;\n\n  if (instance === null) {\n    resetSuspendedCurrentOnMountInLegacyMode(current, workInProgress); // In the initial pass we might need to construct the instance.\n\n    constructClassInstance(workInProgress, Component, nextProps);\n    mountClassInstance(workInProgress, Component, nextProps, renderLanes);\n    shouldUpdate = true;\n  } else if (current === null) {\n    // In a resume, we'll already have an instance we can reuse.\n    shouldUpdate = resumeMountClassInstance(workInProgress, Component, nextProps, renderLanes);\n  } else {\n    shouldUpdate = updateClassInstance(current, workInProgress, Component, nextProps, renderLanes);\n  }\n\n  var nextUnitOfWork = finishClassComponent(current, workInProgress, Component, shouldUpdate, hasContext, renderLanes);\n\n  {\n    var inst = workInProgress.stateNode;\n\n    if (shouldUpdate && inst.props !== nextProps) {\n      if (!didWarnAboutReassigningProps) {\n        error('It looks like %s is reassigning its own `this.props` while rendering. ' + 'This is not supported and can lead to confusing bugs.', getComponentNameFromFiber(workInProgress) || 'a component');\n      }\n\n      didWarnAboutReassigningProps = true;\n    }\n  }\n\n  return nextUnitOfWork;\n}\n\nfunction finishClassComponent(current, workInProgress, Component, shouldUpdate, hasContext, renderLanes) {\n  // Refs should update even if shouldComponentUpdate returns false\n  markRef(current, workInProgress);\n  var didCaptureError = (workInProgress.flags & DidCapture) !== NoFlags;\n\n  if (!shouldUpdate && !didCaptureError) {\n    // Context providers should defer to sCU for rendering\n    if (hasContext) {\n      invalidateContextProvider(workInProgress, Component, false);\n    }\n\n    return bailoutOnAlreadyFinishedWork(current, workInProgress, renderLanes);\n  }\n\n  var instance = workInProgress.stateNode; // Rerender\n\n  ReactCurrentOwner$1.current = workInProgress;\n  var nextChildren;\n\n  if (didCaptureError && typeof Component.getDerivedStateFromError !== 'function') {\n    // If we captured an error, but getDerivedStateFromError is not defined,\n    // unmount all the children. componentDidCatch will schedule an update to\n    // re-render a fallback. This is temporary until we migrate everyone to\n    // the new API.\n    // TODO: Warn in a future release.\n    nextChildren = null;\n\n    {\n      stopProfilerTimerIfRunning();\n    }\n  } else {\n    {\n      markComponentRenderStarted(workInProgress);\n    }\n\n    {\n      setIsRendering(true);\n      nextChildren = instance.render();\n\n      if ( workInProgress.mode & StrictLegacyMode) {\n        setIsStrictModeForDevtools(true);\n\n        try {\n          instance.render();\n        } finally {\n          setIsStrictModeForDevtools(false);\n        }\n      }\n\n      setIsRendering(false);\n    }\n\n    {\n      markComponentRenderStopped();\n    }\n  } // React DevTools reads this flag.\n\n\n  workInProgress.flags |= PerformedWork;\n\n  if (current !== null && didCaptureError) {\n    // If we're recovering from an error, reconcile without reusing any of\n    // the existing children. Conceptually, the normal children and the children\n    // that are shown on error are two different sets, so we shouldn't reuse\n    // normal children even if their identities match.\n    forceUnmountCurrentAndReconcile(current, workInProgress, nextChildren, renderLanes);\n  } else {\n    reconcileChildren(current, workInProgress, nextChildren, renderLanes);\n  } // Memoize state using the values we just used to render.\n  // TODO: Restructure so we never read values from the instance.\n\n\n  workInProgress.memoizedState = instance.state; // The context might have changed so we need to recalculate it.\n\n  if (hasContext) {\n    invalidateContextProvider(workInProgress, Component, true);\n  }\n\n  return workInProgress.child;\n}\n\nfunction pushHostRootContext(workInProgress) {\n  var root = workInProgress.stateNode;\n\n  if (root.pendingContext) {\n    pushTopLevelContextObject(workInProgress, root.pendingContext, root.pendingContext !== root.context);\n  } else if (root.context) {\n    // Should always be set\n    pushTopLevelContextObject(workInProgress, root.context, false);\n  }\n\n  pushHostContainer(workInProgress, root.containerInfo);\n}\n\nfunction updateHostRoot(current, workInProgress, renderLanes) {\n  pushHostRootContext(workInProgress);\n\n  if (current === null) {\n    throw new Error('Should have a current fiber. This is a bug in React.');\n  }\n\n  var nextProps = workInProgress.pendingProps;\n  var prevState = workInProgress.memoizedState;\n  var prevChildren = prevState.element;\n  cloneUpdateQueue(current, workInProgress);\n  processUpdateQueue(workInProgress, nextProps, null, renderLanes);\n  var nextState = workInProgress.memoizedState;\n  var root = workInProgress.stateNode;\n  // being called \"element\".\n\n\n  var nextChildren = nextState.element;\n\n  if ( prevState.isDehydrated) {\n    // This is a hydration root whose shell has not yet hydrated. We should\n    // attempt to hydrate.\n    // Flip isDehydrated to false to indicate that when this render\n    // finishes, the root will no longer be dehydrated.\n    var overrideState = {\n      element: nextChildren,\n      isDehydrated: false,\n      cache: nextState.cache,\n      pendingSuspenseBoundaries: nextState.pendingSuspenseBoundaries,\n      transitions: nextState.transitions\n    };\n    var updateQueue = workInProgress.updateQueue; // `baseState` can always be the last state because the root doesn't\n    // have reducer functions so it doesn't need rebasing.\n\n    updateQueue.baseState = overrideState;\n    workInProgress.memoizedState = overrideState;\n\n    if (workInProgress.flags & ForceClientRender) {\n      // Something errored during a previous attempt to hydrate the shell, so we\n      // forced a client render.\n      var recoverableError = createCapturedValueAtFiber(new Error('There was an error while hydrating. Because the error happened outside ' + 'of a Suspense boundary, the entire root will switch to ' + 'client rendering.'), workInProgress);\n      return mountHostRootWithoutHydrating(current, workInProgress, nextChildren, renderLanes, recoverableError);\n    } else if (nextChildren !== prevChildren) {\n      var _recoverableError = createCapturedValueAtFiber(new Error('This root received an early update, before anything was able ' + 'hydrate. Switched the entire root to client rendering.'), workInProgress);\n\n      return mountHostRootWithoutHydrating(current, workInProgress, nextChildren, renderLanes, _recoverableError);\n    } else {\n      // The outermost shell has not hydrated yet. Start hydrating.\n      enterHydrationState(workInProgress);\n\n      var child = mountChildFibers(workInProgress, null, nextChildren, renderLanes);\n      workInProgress.child = child;\n      var node = child;\n\n      while (node) {\n        // Mark each child as hydrating. This is a fast path to know whether this\n        // tree is part of a hydrating tree. This is used to determine if a child\n        // node has fully mounted yet, and for scheduling event replaying.\n        // Conceptually this is similar to Placement in that a new subtree is\n        // inserted into the React tree here. It just happens to not need DOM\n        // mutations because it already exists.\n        node.flags = node.flags & ~Placement | Hydrating;\n        node = node.sibling;\n      }\n    }\n  } else {\n    // Root is not dehydrated. Either this is a client-only root, or it\n    // already hydrated.\n    resetHydrationState();\n\n    if (nextChildren === prevChildren) {\n      return bailoutOnAlreadyFinishedWork(current, workInProgress, renderLanes);\n    }\n\n    reconcileChildren(current, workInProgress, nextChildren, renderLanes);\n  }\n\n  return workInProgress.child;\n}\n\nfunction mountHostRootWithoutHydrating(current, workInProgress, nextChildren, renderLanes, recoverableError) {\n  // Revert to client rendering.\n  resetHydrationState();\n  queueHydrationError(recoverableError);\n  workInProgress.flags |= ForceClientRender;\n  reconcileChildren(current, workInProgress, nextChildren, renderLanes);\n  return workInProgress.child;\n}\n\nfunction updateHostComponent(current, workInProgress, renderLanes) {\n  pushHostContext(workInProgress);\n\n  if (current === null) {\n    tryToClaimNextHydratableInstance(workInProgress);\n  }\n\n  var type = workInProgress.type;\n  var nextProps = workInProgress.pendingProps;\n  var prevProps = current !== null ? current.memoizedProps : null;\n  var nextChildren = nextProps.children;\n  var isDirectTextChild = shouldSetTextContent(type, nextProps);\n\n  if (isDirectTextChild) {\n    // We special case a direct text child of a host node. This is a common\n    // case. We won't handle it as a reified child. We will instead handle\n    // this in the host environment that also has access to this prop. That\n    // avoids allocating another HostText fiber and traversing it.\n    nextChildren = null;\n  } else if (prevProps !== null && shouldSetTextContent(type, prevProps)) {\n    // If we're switching from a direct text child to a normal child, or to\n    // empty, we need to schedule the text content to be reset.\n    workInProgress.flags |= ContentReset;\n  }\n\n  markRef(current, workInProgress);\n  reconcileChildren(current, workInProgress, nextChildren, renderLanes);\n  return workInProgress.child;\n}\n\nfunction updateHostText(current, workInProgress) {\n  if (current === null) {\n    tryToClaimNextHydratableInstance(workInProgress);\n  } // Nothing to do here. This is terminal. We'll do the completion step\n  // immediately after.\n\n\n  return null;\n}\n\nfunction mountLazyComponent(_current, workInProgress, elementType, renderLanes) {\n  resetSuspendedCurrentOnMountInLegacyMode(_current, workInProgress);\n  var props = workInProgress.pendingProps;\n  var lazyComponent = elementType;\n  var payload = lazyComponent._payload;\n  var init = lazyComponent._init;\n  var Component = init(payload); // Store the unwrapped component in the type.\n\n  workInProgress.type = Component;\n  var resolvedTag = workInProgress.tag = resolveLazyComponentTag(Component);\n  var resolvedProps = resolveDefaultProps(Component, props);\n  var child;\n\n  switch (resolvedTag) {\n    case FunctionComponent:\n      {\n        {\n          validateFunctionComponentInDev(workInProgress, Component);\n          workInProgress.type = Component = resolveFunctionForHotReloading(Component);\n        }\n\n        child = updateFunctionComponent(null, workInProgress, Component, resolvedProps, renderLanes);\n        return child;\n      }\n\n    case ClassComponent:\n      {\n        {\n          workInProgress.type = Component = resolveClassForHotReloading(Component);\n        }\n\n        child = updateClassComponent(null, workInProgress, Component, resolvedProps, renderLanes);\n        return child;\n      }\n\n    case ForwardRef:\n      {\n        {\n          workInProgress.type = Component = resolveForwardRefForHotReloading(Component);\n        }\n\n        child = updateForwardRef(null, workInProgress, Component, resolvedProps, renderLanes);\n        return child;\n      }\n\n    case MemoComponent:\n      {\n        {\n          if (workInProgress.type !== workInProgress.elementType) {\n            var outerPropTypes = Component.propTypes;\n\n            if (outerPropTypes) {\n              checkPropTypes(outerPropTypes, resolvedProps, // Resolved for outer only\n              'prop', getComponentNameFromType(Component));\n            }\n          }\n        }\n\n        child = updateMemoComponent(null, workInProgress, Component, resolveDefaultProps(Component.type, resolvedProps), // The inner type can have defaults too\n        renderLanes);\n        return child;\n      }\n  }\n\n  var hint = '';\n\n  {\n    if (Component !== null && typeof Component === 'object' && Component.$$typeof === REACT_LAZY_TYPE) {\n      hint = ' Did you wrap a component in React.lazy() more than once?';\n    }\n  } // This message intentionally doesn't mention ForwardRef or MemoComponent\n  // because the fact that it's a separate type of work is an\n  // implementation detail.\n\n\n  throw new Error(\"Element type is invalid. Received a promise that resolves to: \" + Component + \". \" + (\"Lazy element type must resolve to a class or function.\" + hint));\n}\n\nfunction mountIncompleteClassComponent(_current, workInProgress, Component, nextProps, renderLanes) {\n  resetSuspendedCurrentOnMountInLegacyMode(_current, workInProgress); // Promote the fiber to a class and try rendering again.\n\n  workInProgress.tag = ClassComponent; // The rest of this function is a fork of `updateClassComponent`\n  // Push context providers early to prevent context stack mismatches.\n  // During mounting we don't know the child context yet as the instance doesn't exist.\n  // We will invalidate the child context in finishClassComponent() right after rendering.\n\n  var hasContext;\n\n  if (isContextProvider(Component)) {\n    hasContext = true;\n    pushContextProvider(workInProgress);\n  } else {\n    hasContext = false;\n  }\n\n  prepareToReadContext(workInProgress, renderLanes);\n  constructClassInstance(workInProgress, Component, nextProps);\n  mountClassInstance(workInProgress, Component, nextProps, renderLanes);\n  return finishClassComponent(null, workInProgress, Component, true, hasContext, renderLanes);\n}\n\nfunction mountIndeterminateComponent(_current, workInProgress, Component, renderLanes) {\n  resetSuspendedCurrentOnMountInLegacyMode(_current, workInProgress);\n  var props = workInProgress.pendingProps;\n  var context;\n\n  {\n    var unmaskedContext = getUnmaskedContext(workInProgress, Component, false);\n    context = getMaskedContext(workInProgress, unmaskedContext);\n  }\n\n  prepareToReadContext(workInProgress, renderLanes);\n  var value;\n  var hasId;\n\n  {\n    markComponentRenderStarted(workInProgress);\n  }\n\n  {\n    if (Component.prototype && typeof Component.prototype.render === 'function') {\n      var componentName = getComponentNameFromType(Component) || 'Unknown';\n\n      if (!didWarnAboutBadClass[componentName]) {\n        error(\"The <%s /> component appears to have a render method, but doesn't extend React.Component. \" + 'This is likely to cause errors. Change %s to extend React.Component instead.', componentName, componentName);\n\n        didWarnAboutBadClass[componentName] = true;\n      }\n    }\n\n    if (workInProgress.mode & StrictLegacyMode) {\n      ReactStrictModeWarnings.recordLegacyContextWarning(workInProgress, null);\n    }\n\n    setIsRendering(true);\n    ReactCurrentOwner$1.current = workInProgress;\n    value = renderWithHooks(null, workInProgress, Component, props, context, renderLanes);\n    hasId = checkDidRenderIdHook();\n    setIsRendering(false);\n  }\n\n  {\n    markComponentRenderStopped();\n  } // React DevTools reads this flag.\n\n\n  workInProgress.flags |= PerformedWork;\n\n  {\n    // Support for module components is deprecated and is removed behind a flag.\n    // Whether or not it would crash later, we want to show a good message in DEV first.\n    if (typeof value === 'object' && value !== null && typeof value.render === 'function' && value.$$typeof === undefined) {\n      var _componentName = getComponentNameFromType(Component) || 'Unknown';\n\n      if (!didWarnAboutModulePatternComponent[_componentName]) {\n        error('The <%s /> component appears to be a function component that returns a class instance. ' + 'Change %s to a class that extends React.Component instead. ' + \"If you can't use a class try assigning the prototype on the function as a workaround. \" + \"`%s.prototype = React.Component.prototype`. Don't use an arrow function since it \" + 'cannot be called with `new` by React.', _componentName, _componentName, _componentName);\n\n        didWarnAboutModulePatternComponent[_componentName] = true;\n      }\n    }\n  }\n\n  if ( // Run these checks in production only if the flag is off.\n  // Eventually we'll delete this branch altogether.\n   typeof value === 'object' && value !== null && typeof value.render === 'function' && value.$$typeof === undefined) {\n    {\n      var _componentName2 = getComponentNameFromType(Component) || 'Unknown';\n\n      if (!didWarnAboutModulePatternComponent[_componentName2]) {\n        error('The <%s /> component appears to be a function component that returns a class instance. ' + 'Change %s to a class that extends React.Component instead. ' + \"If you can't use a class try assigning the prototype on the function as a workaround. \" + \"`%s.prototype = React.Component.prototype`. Don't use an arrow function since it \" + 'cannot be called with `new` by React.', _componentName2, _componentName2, _componentName2);\n\n        didWarnAboutModulePatternComponent[_componentName2] = true;\n      }\n    } // Proceed under the assumption that this is a class instance\n\n\n    workInProgress.tag = ClassComponent; // Throw out any hooks that were used.\n\n    workInProgress.memoizedState = null;\n    workInProgress.updateQueue = null; // Push context providers early to prevent context stack mismatches.\n    // During mounting we don't know the child context yet as the instance doesn't exist.\n    // We will invalidate the child context in finishClassComponent() right after rendering.\n\n    var hasContext = false;\n\n    if (isContextProvider(Component)) {\n      hasContext = true;\n      pushContextProvider(workInProgress);\n    } else {\n      hasContext = false;\n    }\n\n    workInProgress.memoizedState = value.state !== null && value.state !== undefined ? value.state : null;\n    initializeUpdateQueue(workInProgress);\n    adoptClassInstance(workInProgress, value);\n    mountClassInstance(workInProgress, Component, props, renderLanes);\n    return finishClassComponent(null, workInProgress, Component, true, hasContext, renderLanes);\n  } else {\n    // Proceed under the assumption that this is a function component\n    workInProgress.tag = FunctionComponent;\n\n    {\n\n      if ( workInProgress.mode & StrictLegacyMode) {\n        setIsStrictModeForDevtools(true);\n\n        try {\n          value = renderWithHooks(null, workInProgress, Component, props, context, renderLanes);\n          hasId = checkDidRenderIdHook();\n        } finally {\n          setIsStrictModeForDevtools(false);\n        }\n      }\n    }\n\n    if (getIsHydrating() && hasId) {\n      pushMaterializedTreeId(workInProgress);\n    }\n\n    reconcileChildren(null, workInProgress, value, renderLanes);\n\n    {\n      validateFunctionComponentInDev(workInProgress, Component);\n    }\n\n    return workInProgress.child;\n  }\n}\n\nfunction validateFunctionComponentInDev(workInProgress, Component) {\n  {\n    if (Component) {\n      if (Component.childContextTypes) {\n        error('%s(...): childContextTypes cannot be defined on a function component.', Component.displayName || Component.name || 'Component');\n      }\n    }\n\n    if (workInProgress.ref !== null) {\n      var info = '';\n      var ownerName = getCurrentFiberOwnerNameInDevOrNull();\n\n      if (ownerName) {\n        info += '\\n\\nCheck the render method of `' + ownerName + '`.';\n      }\n\n      var warningKey = ownerName || '';\n      var debugSource = workInProgress._debugSource;\n\n      if (debugSource) {\n        warningKey = debugSource.fileName + ':' + debugSource.lineNumber;\n      }\n\n      if (!didWarnAboutFunctionRefs[warningKey]) {\n        didWarnAboutFunctionRefs[warningKey] = true;\n\n        error('Function components cannot be given refs. ' + 'Attempts to access this ref will fail. ' + 'Did you mean to use React.forwardRef()?%s', info);\n      }\n    }\n\n    if (typeof Component.getDerivedStateFromProps === 'function') {\n      var _componentName3 = getComponentNameFromType(Component) || 'Unknown';\n\n      if (!didWarnAboutGetDerivedStateOnFunctionComponent[_componentName3]) {\n        error('%s: Function components do not support getDerivedStateFromProps.', _componentName3);\n\n        didWarnAboutGetDerivedStateOnFunctionComponent[_componentName3] = true;\n      }\n    }\n\n    if (typeof Component.contextType === 'object' && Component.contextType !== null) {\n      var _componentName4 = getComponentNameFromType(Component) || 'Unknown';\n\n      if (!didWarnAboutContextTypeOnFunctionComponent[_componentName4]) {\n        error('%s: Function components do not support contextType.', _componentName4);\n\n        didWarnAboutContextTypeOnFunctionComponent[_componentName4] = true;\n      }\n    }\n  }\n}\n\nvar SUSPENDED_MARKER = {\n  dehydrated: null,\n  treeContext: null,\n  retryLane: NoLane\n};\n\nfunction mountSuspenseOffscreenState(renderLanes) {\n  return {\n    baseLanes: renderLanes,\n    cachePool: getSuspendedCache(),\n    transitions: null\n  };\n}\n\nfunction updateSuspenseOffscreenState(prevOffscreenState, renderLanes) {\n  var cachePool = null;\n\n  return {\n    baseLanes: mergeLanes(prevOffscreenState.baseLanes, renderLanes),\n    cachePool: cachePool,\n    transitions: prevOffscreenState.transitions\n  };\n} // TODO: Probably should inline this back\n\n\nfunction shouldRemainOnFallback(suspenseContext, current, workInProgress, renderLanes) {\n  // If we're already showing a fallback, there are cases where we need to\n  // remain on that fallback regardless of whether the content has resolved.\n  // For example, SuspenseList coordinates when nested content appears.\n  if (current !== null) {\n    var suspenseState = current.memoizedState;\n\n    if (suspenseState === null) {\n      // Currently showing content. Don't hide it, even if ForceSuspenseFallback\n      // is true. More precise name might be \"ForceRemainSuspenseFallback\".\n      // Note: This is a factoring smell. Can't remain on a fallback if there's\n      // no fallback to remain on.\n      return false;\n    }\n  } // Not currently showing content. Consult the Suspense context.\n\n\n  return hasSuspenseContext(suspenseContext, ForceSuspenseFallback);\n}\n\nfunction getRemainingWorkInPrimaryTree(current, renderLanes) {\n  // TODO: Should not remove render lanes that were pinged during this render\n  return removeLanes(current.childLanes, renderLanes);\n}\n\nfunction updateSuspenseComponent(current, workInProgress, renderLanes) {\n  var nextProps = workInProgress.pendingProps; // This is used by DevTools to force a boundary to suspend.\n\n  {\n    if (shouldSuspend(workInProgress)) {\n      workInProgress.flags |= DidCapture;\n    }\n  }\n\n  var suspenseContext = suspenseStackCursor.current;\n  var showFallback = false;\n  var didSuspend = (workInProgress.flags & DidCapture) !== NoFlags;\n\n  if (didSuspend || shouldRemainOnFallback(suspenseContext, current)) {\n    // Something in this boundary's subtree already suspended. Switch to\n    // rendering the fallback children.\n    showFallback = true;\n    workInProgress.flags &= ~DidCapture;\n  } else {\n    // Attempting the main content\n    if (current === null || current.memoizedState !== null) {\n      // This is a new mount or this boundary is already showing a fallback state.\n      // Mark this subtree context as having at least one invisible parent that could\n      // handle the fallback state.\n      // Avoided boundaries are not considered since they cannot handle preferred fallback states.\n      {\n        suspenseContext = addSubtreeSuspenseContext(suspenseContext, InvisibleParentSuspenseContext);\n      }\n    }\n  }\n\n  suspenseContext = setDefaultShallowSuspenseContext(suspenseContext);\n  pushSuspenseContext(workInProgress, suspenseContext); // OK, the next part is confusing. We're about to reconcile the Suspense\n  // boundary's children. This involves some custom reconciliation logic. Two\n  // main reasons this is so complicated.\n  //\n  // First, Legacy Mode has different semantics for backwards compatibility. The\n  // primary tree will commit in an inconsistent state, so when we do the\n  // second pass to render the fallback, we do some exceedingly, uh, clever\n  // hacks to make that not totally break. Like transferring effects and\n  // deletions from hidden tree. In Concurrent Mode, it's much simpler,\n  // because we bailout on the primary tree completely and leave it in its old\n  // state, no effects. Same as what we do for Offscreen (except that\n  // Offscreen doesn't have the first render pass).\n  //\n  // Second is hydration. During hydration, the Suspense fiber has a slightly\n  // different layout, where the child points to a dehydrated fragment, which\n  // contains the DOM rendered by the server.\n  //\n  // Third, even if you set all that aside, Suspense is like error boundaries in\n  // that we first we try to render one tree, and if that fails, we render again\n  // and switch to a different tree. Like a try/catch block. So we have to track\n  // which branch we're currently rendering. Ideally we would model this using\n  // a stack.\n\n  if (current === null) {\n    // Initial mount\n    // Special path for hydration\n    // If we're currently hydrating, try to hydrate this boundary.\n    tryToClaimNextHydratableInstance(workInProgress); // This could've been a dehydrated suspense component.\n\n    var suspenseState = workInProgress.memoizedState;\n\n    if (suspenseState !== null) {\n      var dehydrated = suspenseState.dehydrated;\n\n      if (dehydrated !== null) {\n        return mountDehydratedSuspenseComponent(workInProgress, dehydrated);\n      }\n    }\n\n    var nextPrimaryChildren = nextProps.children;\n    var nextFallbackChildren = nextProps.fallback;\n\n    if (showFallback) {\n      var fallbackFragment = mountSuspenseFallbackChildren(workInProgress, nextPrimaryChildren, nextFallbackChildren, renderLanes);\n      var primaryChildFragment = workInProgress.child;\n      primaryChildFragment.memoizedState = mountSuspenseOffscreenState(renderLanes);\n      workInProgress.memoizedState = SUSPENDED_MARKER;\n\n      return fallbackFragment;\n    } else {\n      return mountSuspensePrimaryChildren(workInProgress, nextPrimaryChildren);\n    }\n  } else {\n    // This is an update.\n    // Special path for hydration\n    var prevState = current.memoizedState;\n\n    if (prevState !== null) {\n      var _dehydrated = prevState.dehydrated;\n\n      if (_dehydrated !== null) {\n        return updateDehydratedSuspenseComponent(current, workInProgress, didSuspend, nextProps, _dehydrated, prevState, renderLanes);\n      }\n    }\n\n    if (showFallback) {\n      var _nextFallbackChildren = nextProps.fallback;\n      var _nextPrimaryChildren = nextProps.children;\n      var fallbackChildFragment = updateSuspenseFallbackChildren(current, workInProgress, _nextPrimaryChildren, _nextFallbackChildren, renderLanes);\n      var _primaryChildFragment2 = workInProgress.child;\n      var prevOffscreenState = current.child.memoizedState;\n      _primaryChildFragment2.memoizedState = prevOffscreenState === null ? mountSuspenseOffscreenState(renderLanes) : updateSuspenseOffscreenState(prevOffscreenState, renderLanes);\n\n      _primaryChildFragment2.childLanes = getRemainingWorkInPrimaryTree(current, renderLanes);\n      workInProgress.memoizedState = SUSPENDED_MARKER;\n      return fallbackChildFragment;\n    } else {\n      var _nextPrimaryChildren2 = nextProps.children;\n\n      var _primaryChildFragment3 = updateSuspensePrimaryChildren(current, workInProgress, _nextPrimaryChildren2, renderLanes);\n\n      workInProgress.memoizedState = null;\n      return _primaryChildFragment3;\n    }\n  }\n}\n\nfunction mountSuspensePrimaryChildren(workInProgress, primaryChildren, renderLanes) {\n  var mode = workInProgress.mode;\n  var primaryChildProps = {\n    mode: 'visible',\n    children: primaryChildren\n  };\n  var primaryChildFragment = mountWorkInProgressOffscreenFiber(primaryChildProps, mode);\n  primaryChildFragment.return = workInProgress;\n  workInProgress.child = primaryChildFragment;\n  return primaryChildFragment;\n}\n\nfunction mountSuspenseFallbackChildren(workInProgress, primaryChildren, fallbackChildren, renderLanes) {\n  var mode = workInProgress.mode;\n  var progressedPrimaryFragment = workInProgress.child;\n  var primaryChildProps = {\n    mode: 'hidden',\n    children: primaryChildren\n  };\n  var primaryChildFragment;\n  var fallbackChildFragment;\n\n  if ((mode & ConcurrentMode) === NoMode && progressedPrimaryFragment !== null) {\n    // In legacy mode, we commit the primary tree as if it successfully\n    // completed, even though it's in an inconsistent state.\n    primaryChildFragment = progressedPrimaryFragment;\n    primaryChildFragment.childLanes = NoLanes;\n    primaryChildFragment.pendingProps = primaryChildProps;\n\n    if ( workInProgress.mode & ProfileMode) {\n      // Reset the durations from the first pass so they aren't included in the\n      // final amounts. This seems counterintuitive, since we're intentionally\n      // not measuring part of the render phase, but this makes it match what we\n      // do in Concurrent Mode.\n      primaryChildFragment.actualDuration = 0;\n      primaryChildFragment.actualStartTime = -1;\n      primaryChildFragment.selfBaseDuration = 0;\n      primaryChildFragment.treeBaseDuration = 0;\n    }\n\n    fallbackChildFragment = createFiberFromFragment(fallbackChildren, mode, renderLanes, null);\n  } else {\n    primaryChildFragment = mountWorkInProgressOffscreenFiber(primaryChildProps, mode);\n    fallbackChildFragment = createFiberFromFragment(fallbackChildren, mode, renderLanes, null);\n  }\n\n  primaryChildFragment.return = workInProgress;\n  fallbackChildFragment.return = workInProgress;\n  primaryChildFragment.sibling = fallbackChildFragment;\n  workInProgress.child = primaryChildFragment;\n  return fallbackChildFragment;\n}\n\nfunction mountWorkInProgressOffscreenFiber(offscreenProps, mode, renderLanes) {\n  // The props argument to `createFiberFromOffscreen` is `any` typed, so we use\n  // this wrapper function to constrain it.\n  return createFiberFromOffscreen(offscreenProps, mode, NoLanes, null);\n}\n\nfunction updateWorkInProgressOffscreenFiber(current, offscreenProps) {\n  // The props argument to `createWorkInProgress` is `any` typed, so we use this\n  // wrapper function to constrain it.\n  return createWorkInProgress(current, offscreenProps);\n}\n\nfunction updateSuspensePrimaryChildren(current, workInProgress, primaryChildren, renderLanes) {\n  var currentPrimaryChildFragment = current.child;\n  var currentFallbackChildFragment = currentPrimaryChildFragment.sibling;\n  var primaryChildFragment = updateWorkInProgressOffscreenFiber(currentPrimaryChildFragment, {\n    mode: 'visible',\n    children: primaryChildren\n  });\n\n  if ((workInProgress.mode & ConcurrentMode) === NoMode) {\n    primaryChildFragment.lanes = renderLanes;\n  }\n\n  primaryChildFragment.return = workInProgress;\n  primaryChildFragment.sibling = null;\n\n  if (currentFallbackChildFragment !== null) {\n    // Delete the fallback child fragment\n    var deletions = workInProgress.deletions;\n\n    if (deletions === null) {\n      workInProgress.deletions = [currentFallbackChildFragment];\n      workInProgress.flags |= ChildDeletion;\n    } else {\n      deletions.push(currentFallbackChildFragment);\n    }\n  }\n\n  workInProgress.child = primaryChildFragment;\n  return primaryChildFragment;\n}\n\nfunction updateSuspenseFallbackChildren(current, workInProgress, primaryChildren, fallbackChildren, renderLanes) {\n  var mode = workInProgress.mode;\n  var currentPrimaryChildFragment = current.child;\n  var currentFallbackChildFragment = currentPrimaryChildFragment.sibling;\n  var primaryChildProps = {\n    mode: 'hidden',\n    children: primaryChildren\n  };\n  var primaryChildFragment;\n\n  if ( // In legacy mode, we commit the primary tree as if it successfully\n  // completed, even though it's in an inconsistent state.\n  (mode & ConcurrentMode) === NoMode && // Make sure we're on the second pass, i.e. the primary child fragment was\n  // already cloned. In legacy mode, the only case where this isn't true is\n  // when DevTools forces us to display a fallback; we skip the first render\n  // pass entirely and go straight to rendering the fallback. (In Concurrent\n  // Mode, SuspenseList can also trigger this scenario, but this is a legacy-\n  // only codepath.)\n  workInProgress.child !== currentPrimaryChildFragment) {\n    var progressedPrimaryFragment = workInProgress.child;\n    primaryChildFragment = progressedPrimaryFragment;\n    primaryChildFragment.childLanes = NoLanes;\n    primaryChildFragment.pendingProps = primaryChildProps;\n\n    if ( workInProgress.mode & ProfileMode) {\n      // Reset the durations from the first pass so they aren't included in the\n      // final amounts. This seems counterintuitive, since we're intentionally\n      // not measuring part of the render phase, but this makes it match what we\n      // do in Concurrent Mode.\n      primaryChildFragment.actualDuration = 0;\n      primaryChildFragment.actualStartTime = -1;\n      primaryChildFragment.selfBaseDuration = currentPrimaryChildFragment.selfBaseDuration;\n      primaryChildFragment.treeBaseDuration = currentPrimaryChildFragment.treeBaseDuration;\n    } // The fallback fiber was added as a deletion during the first pass.\n    // However, since we're going to remain on the fallback, we no longer want\n    // to delete it.\n\n\n    workInProgress.deletions = null;\n  } else {\n    primaryChildFragment = updateWorkInProgressOffscreenFiber(currentPrimaryChildFragment, primaryChildProps); // Since we're reusing a current tree, we need to reuse the flags, too.\n    // (We don't do this in legacy mode, because in legacy mode we don't re-use\n    // the current tree; see previous branch.)\n\n    primaryChildFragment.subtreeFlags = currentPrimaryChildFragment.subtreeFlags & StaticMask;\n  }\n\n  var fallbackChildFragment;\n\n  if (currentFallbackChildFragment !== null) {\n    fallbackChildFragment = createWorkInProgress(currentFallbackChildFragment, fallbackChildren);\n  } else {\n    fallbackChildFragment = createFiberFromFragment(fallbackChildren, mode, renderLanes, null); // Needs a placement effect because the parent (the Suspense boundary) already\n    // mounted but this is a new fiber.\n\n    fallbackChildFragment.flags |= Placement;\n  }\n\n  fallbackChildFragment.return = workInProgress;\n  primaryChildFragment.return = workInProgress;\n  primaryChildFragment.sibling = fallbackChildFragment;\n  workInProgress.child = primaryChildFragment;\n  return fallbackChildFragment;\n}\n\nfunction retrySuspenseComponentWithoutHydrating(current, workInProgress, renderLanes, recoverableError) {\n  // Falling back to client rendering. Because this has performance\n  // implications, it's considered a recoverable error, even though the user\n  // likely won't observe anything wrong with the UI.\n  //\n  // The error is passed in as an argument to enforce that every caller provide\n  // a custom message, or explicitly opt out (currently the only path that opts\n  // out is legacy mode; every concurrent path provides an error).\n  if (recoverableError !== null) {\n    queueHydrationError(recoverableError);\n  } // This will add the old fiber to the deletion list\n\n\n  reconcileChildFibers(workInProgress, current.child, null, renderLanes); // We're now not suspended nor dehydrated.\n\n  var nextProps = workInProgress.pendingProps;\n  var primaryChildren = nextProps.children;\n  var primaryChildFragment = mountSuspensePrimaryChildren(workInProgress, primaryChildren); // Needs a placement effect because the parent (the Suspense boundary) already\n  // mounted but this is a new fiber.\n\n  primaryChildFragment.flags |= Placement;\n  workInProgress.memoizedState = null;\n  return primaryChildFragment;\n}\n\nfunction mountSuspenseFallbackAfterRetryWithoutHydrating(current, workInProgress, primaryChildren, fallbackChildren, renderLanes) {\n  var fiberMode = workInProgress.mode;\n  var primaryChildProps = {\n    mode: 'visible',\n    children: primaryChildren\n  };\n  var primaryChildFragment = mountWorkInProgressOffscreenFiber(primaryChildProps, fiberMode);\n  var fallbackChildFragment = createFiberFromFragment(fallbackChildren, fiberMode, renderLanes, null); // Needs a placement effect because the parent (the Suspense\n  // boundary) already mounted but this is a new fiber.\n\n  fallbackChildFragment.flags |= Placement;\n  primaryChildFragment.return = workInProgress;\n  fallbackChildFragment.return = workInProgress;\n  primaryChildFragment.sibling = fallbackChildFragment;\n  workInProgress.child = primaryChildFragment;\n\n  if ((workInProgress.mode & ConcurrentMode) !== NoMode) {\n    // We will have dropped the effect list which contains the\n    // deletion. We need to reconcile to delete the current child.\n    reconcileChildFibers(workInProgress, current.child, null, renderLanes);\n  }\n\n  return fallbackChildFragment;\n}\n\nfunction mountDehydratedSuspenseComponent(workInProgress, suspenseInstance, renderLanes) {\n  // During the first pass, we'll bail out and not drill into the children.\n  // Instead, we'll leave the content in place and try to hydrate it later.\n  if ((workInProgress.mode & ConcurrentMode) === NoMode) {\n    {\n      error('Cannot hydrate Suspense in legacy mode. Switch from ' + 'ReactDOM.hydrate(element, container) to ' + 'ReactDOMClient.hydrateRoot(container, <App />)' + '.render(element) or remove the Suspense components from ' + 'the server rendered components.');\n    }\n\n    workInProgress.lanes = laneToLanes(SyncLane);\n  } else if (isSuspenseInstanceFallback(suspenseInstance)) {\n    // This is a client-only boundary. Since we won't get any content from the server\n    // for this, we need to schedule that at a higher priority based on when it would\n    // have timed out. In theory we could render it in this pass but it would have the\n    // wrong priority associated with it and will prevent hydration of parent path.\n    // Instead, we'll leave work left on it to render it in a separate commit.\n    // TODO This time should be the time at which the server rendered response that is\n    // a parent to this boundary was displayed. However, since we currently don't have\n    // a protocol to transfer that time, we'll just estimate it by using the current\n    // time. This will mean that Suspense timeouts are slightly shifted to later than\n    // they should be.\n    // Schedule a normal pri update to render this content.\n    workInProgress.lanes = laneToLanes(DefaultHydrationLane);\n  } else {\n    // We'll continue hydrating the rest at offscreen priority since we'll already\n    // be showing the right content coming from the server, it is no rush.\n    workInProgress.lanes = laneToLanes(OffscreenLane);\n  }\n\n  return null;\n}\n\nfunction updateDehydratedSuspenseComponent(current, workInProgress, didSuspend, nextProps, suspenseInstance, suspenseState, renderLanes) {\n  if (!didSuspend) {\n    // This is the first render pass. Attempt to hydrate.\n    // We should never be hydrating at this point because it is the first pass,\n    // but after we've already committed once.\n    warnIfHydrating();\n\n    if ((workInProgress.mode & ConcurrentMode) === NoMode) {\n      return retrySuspenseComponentWithoutHydrating(current, workInProgress, renderLanes, // TODO: When we delete legacy mode, we should make this error argument\n      // required  every concurrent mode path that causes hydration to\n      // de-opt to client rendering should have an error message.\n      null);\n    }\n\n    if (isSuspenseInstanceFallback(suspenseInstance)) {\n      // This boundary is in a permanent fallback state. In this case, we'll never\n      // get an update and we'll never be able to hydrate the final content. Let's just try the\n      // client side render instead.\n      var digest, message, stack;\n\n      {\n        var _getSuspenseInstanceF = getSuspenseInstanceFallbackErrorDetails(suspenseInstance);\n\n        digest = _getSuspenseInstanceF.digest;\n        message = _getSuspenseInstanceF.message;\n        stack = _getSuspenseInstanceF.stack;\n      }\n\n      var error;\n\n      if (message) {\n        // eslint-disable-next-line react-internal/prod-error-codes\n        error = new Error(message);\n      } else {\n        error = new Error('The server could not finish this Suspense boundary, likely ' + 'due to an error during server rendering. Switched to ' + 'client rendering.');\n      }\n\n      var capturedValue = createCapturedValue(error, digest, stack);\n      return retrySuspenseComponentWithoutHydrating(current, workInProgress, renderLanes, capturedValue);\n    }\n    // any context has changed, we need to treat is as if the input might have changed.\n\n\n    var hasContextChanged = includesSomeLane(renderLanes, current.childLanes);\n\n    if (didReceiveUpdate || hasContextChanged) {\n      // This boundary has changed since the first render. This means that we are now unable to\n      // hydrate it. We might still be able to hydrate it using a higher priority lane.\n      var root = getWorkInProgressRoot();\n\n      if (root !== null) {\n        var attemptHydrationAtLane = getBumpedLaneForHydration(root, renderLanes);\n\n        if (attemptHydrationAtLane !== NoLane && attemptHydrationAtLane !== suspenseState.retryLane) {\n          // Intentionally mutating since this render will get interrupted. This\n          // is one of the very rare times where we mutate the current tree\n          // during the render phase.\n          suspenseState.retryLane = attemptHydrationAtLane; // TODO: Ideally this would inherit the event time of the current render\n\n          var eventTime = NoTimestamp;\n          enqueueConcurrentRenderForLane(current, attemptHydrationAtLane);\n          scheduleUpdateOnFiber(root, current, attemptHydrationAtLane, eventTime);\n        }\n      } // If we have scheduled higher pri work above, this will probably just abort the render\n      // since we now have higher priority work, but in case it doesn't, we need to prepare to\n      // render something, if we time out. Even if that requires us to delete everything and\n      // skip hydration.\n      // Delay having to do this as long as the suspense timeout allows us.\n\n\n      renderDidSuspendDelayIfPossible();\n\n      var _capturedValue = createCapturedValue(new Error('This Suspense boundary received an update before it finished ' + 'hydrating. This caused the boundary to switch to client rendering. ' + 'The usual way to fix this is to wrap the original update ' + 'in startTransition.'));\n\n      return retrySuspenseComponentWithoutHydrating(current, workInProgress, renderLanes, _capturedValue);\n    } else if (isSuspenseInstancePending(suspenseInstance)) {\n      // This component is still pending more data from the server, so we can't hydrate its\n      // content. We treat it as if this component suspended itself. It might seem as if\n      // we could just try to render it client-side instead. However, this will perform a\n      // lot of unnecessary work and is unlikely to complete since it often will suspend\n      // on missing data anyway. Additionally, the server might be able to render more\n      // than we can on the client yet. In that case we'd end up with more fallback states\n      // on the client than if we just leave it alone. If the server times out or errors\n      // these should update this boundary to the permanent Fallback state instead.\n      // Mark it as having captured (i.e. suspended).\n      workInProgress.flags |= DidCapture; // Leave the child in place. I.e. the dehydrated fragment.\n\n      workInProgress.child = current.child; // Register a callback to retry this boundary once the server has sent the result.\n\n      var retry = retryDehydratedSuspenseBoundary.bind(null, current);\n      registerSuspenseInstanceRetry(suspenseInstance, retry);\n      return null;\n    } else {\n      // This is the first attempt.\n      reenterHydrationStateFromDehydratedSuspenseInstance(workInProgress, suspenseInstance, suspenseState.treeContext);\n      var primaryChildren = nextProps.children;\n      var primaryChildFragment = mountSuspensePrimaryChildren(workInProgress, primaryChildren); // Mark the children as hydrating. This is a fast path to know whether this\n      // tree is part of a hydrating tree. This is used to determine if a child\n      // node has fully mounted yet, and for scheduling event replaying.\n      // Conceptually this is similar to Placement in that a new subtree is\n      // inserted into the React tree here. It just happens to not need DOM\n      // mutations because it already exists.\n\n      primaryChildFragment.flags |= Hydrating;\n      return primaryChildFragment;\n    }\n  } else {\n    // This is the second render pass. We already attempted to hydrated, but\n    // something either suspended or errored.\n    if (workInProgress.flags & ForceClientRender) {\n      // Something errored during hydration. Try again without hydrating.\n      workInProgress.flags &= ~ForceClientRender;\n\n      var _capturedValue2 = createCapturedValue(new Error('There was an error while hydrating this Suspense boundary. ' + 'Switched to client rendering.'));\n\n      return retrySuspenseComponentWithoutHydrating(current, workInProgress, renderLanes, _capturedValue2);\n    } else if (workInProgress.memoizedState !== null) {\n      // Something suspended and we should still be in dehydrated mode.\n      // Leave the existing child in place.\n      workInProgress.child = current.child; // The dehydrated completion pass expects this flag to be there\n      // but the normal suspense pass doesn't.\n\n      workInProgress.flags |= DidCapture;\n      return null;\n    } else {\n      // Suspended but we should no longer be in dehydrated mode.\n      // Therefore we now have to render the fallback.\n      var nextPrimaryChildren = nextProps.children;\n      var nextFallbackChildren = nextProps.fallback;\n      var fallbackChildFragment = mountSuspenseFallbackAfterRetryWithoutHydrating(current, workInProgress, nextPrimaryChildren, nextFallbackChildren, renderLanes);\n      var _primaryChildFragment4 = workInProgress.child;\n      _primaryChildFragment4.memoizedState = mountSuspenseOffscreenState(renderLanes);\n      workInProgress.memoizedState = SUSPENDED_MARKER;\n      return fallbackChildFragment;\n    }\n  }\n}\n\nfunction scheduleSuspenseWorkOnFiber(fiber, renderLanes, propagationRoot) {\n  fiber.lanes = mergeLanes(fiber.lanes, renderLanes);\n  var alternate = fiber.alternate;\n\n  if (alternate !== null) {\n    alternate.lanes = mergeLanes(alternate.lanes, renderLanes);\n  }\n\n  scheduleContextWorkOnParentPath(fiber.return, renderLanes, propagationRoot);\n}\n\nfunction propagateSuspenseContextChange(workInProgress, firstChild, renderLanes) {\n  // Mark any Suspense boundaries with fallbacks as having work to do.\n  // If they were previously forced into fallbacks, they may now be able\n  // to unblock.\n  var node = firstChild;\n\n  while (node !== null) {\n    if (node.tag === SuspenseComponent) {\n      var state = node.memoizedState;\n\n      if (state !== null) {\n        scheduleSuspenseWorkOnFiber(node, renderLanes, workInProgress);\n      }\n    } else if (node.tag === SuspenseListComponent) {\n      // If the tail is hidden there might not be an Suspense boundaries\n      // to schedule work on. In this case we have to schedule it on the\n      // list itself.\n      // We don't have to traverse to the children of the list since\n      // the list will propagate the change when it rerenders.\n      scheduleSuspenseWorkOnFiber(node, renderLanes, workInProgress);\n    } else if (node.child !== null) {\n      node.child.return = node;\n      node = node.child;\n      continue;\n    }\n\n    if (node === workInProgress) {\n      return;\n    }\n\n    while (node.sibling === null) {\n      if (node.return === null || node.return === workInProgress) {\n        return;\n      }\n\n      node = node.return;\n    }\n\n    node.sibling.return = node.return;\n    node = node.sibling;\n  }\n}\n\nfunction findLastContentRow(firstChild) {\n  // This is going to find the last row among these children that is already\n  // showing content on the screen, as opposed to being in fallback state or\n  // new. If a row has multiple Suspense boundaries, any of them being in the\n  // fallback state, counts as the whole row being in a fallback state.\n  // Note that the \"rows\" will be workInProgress, but any nested children\n  // will still be current since we haven't rendered them yet. The mounted\n  // order may not be the same as the new order. We use the new order.\n  var row = firstChild;\n  var lastContentRow = null;\n\n  while (row !== null) {\n    var currentRow = row.alternate; // New rows can't be content rows.\n\n    if (currentRow !== null && findFirstSuspended(currentRow) === null) {\n      lastContentRow = row;\n    }\n\n    row = row.sibling;\n  }\n\n  return lastContentRow;\n}\n\nfunction validateRevealOrder(revealOrder) {\n  {\n    if (revealOrder !== undefined && revealOrder !== 'forwards' && revealOrder !== 'backwards' && revealOrder !== 'together' && !didWarnAboutRevealOrder[revealOrder]) {\n      didWarnAboutRevealOrder[revealOrder] = true;\n\n      if (typeof revealOrder === 'string') {\n        switch (revealOrder.toLowerCase()) {\n          case 'together':\n          case 'forwards':\n          case 'backwards':\n            {\n              error('\"%s\" is not a valid value for revealOrder on <SuspenseList />. ' + 'Use lowercase \"%s\" instead.', revealOrder, revealOrder.toLowerCase());\n\n              break;\n            }\n\n          case 'forward':\n          case 'backward':\n            {\n              error('\"%s\" is not a valid value for revealOrder on <SuspenseList />. ' + 'React uses the -s suffix in the spelling. Use \"%ss\" instead.', revealOrder, revealOrder.toLowerCase());\n\n              break;\n            }\n\n          default:\n            error('\"%s\" is not a supported revealOrder on <SuspenseList />. ' + 'Did you mean \"together\", \"forwards\" or \"backwards\"?', revealOrder);\n\n            break;\n        }\n      } else {\n        error('%s is not a supported value for revealOrder on <SuspenseList />. ' + 'Did you mean \"together\", \"forwards\" or \"backwards\"?', revealOrder);\n      }\n    }\n  }\n}\n\nfunction validateTailOptions(tailMode, revealOrder) {\n  {\n    if (tailMode !== undefined && !didWarnAboutTailOptions[tailMode]) {\n      if (tailMode !== 'collapsed' && tailMode !== 'hidden') {\n        didWarnAboutTailOptions[tailMode] = true;\n\n        error('\"%s\" is not a supported value for tail on <SuspenseList />. ' + 'Did you mean \"collapsed\" or \"hidden\"?', tailMode);\n      } else if (revealOrder !== 'forwards' && revealOrder !== 'backwards') {\n        didWarnAboutTailOptions[tailMode] = true;\n\n        error('<SuspenseList tail=\"%s\" /> is only valid if revealOrder is ' + '\"forwards\" or \"backwards\". ' + 'Did you mean to specify revealOrder=\"forwards\"?', tailMode);\n      }\n    }\n  }\n}\n\nfunction validateSuspenseListNestedChild(childSlot, index) {\n  {\n    var isAnArray = isArray(childSlot);\n    var isIterable = !isAnArray && typeof getIteratorFn(childSlot) === 'function';\n\n    if (isAnArray || isIterable) {\n      var type = isAnArray ? 'array' : 'iterable';\n\n      error('A nested %s was passed to row #%s in <SuspenseList />. Wrap it in ' + 'an additional SuspenseList to configure its revealOrder: ' + '<SuspenseList revealOrder=...> ... ' + '<SuspenseList revealOrder=...>{%s}</SuspenseList> ... ' + '</SuspenseList>', type, index, type);\n\n      return false;\n    }\n  }\n\n  return true;\n}\n\nfunction validateSuspenseListChildren(children, revealOrder) {\n  {\n    if ((revealOrder === 'forwards' || revealOrder === 'backwards') && children !== undefined && children !== null && children !== false) {\n      if (isArray(children)) {\n        for (var i = 0; i < children.length; i++) {\n          if (!validateSuspenseListNestedChild(children[i], i)) {\n            return;\n          }\n        }\n      } else {\n        var iteratorFn = getIteratorFn(children);\n\n        if (typeof iteratorFn === 'function') {\n          var childrenIterator = iteratorFn.call(children);\n\n          if (childrenIterator) {\n            var step = childrenIterator.next();\n            var _i = 0;\n\n            for (; !step.done; step = childrenIterator.next()) {\n              if (!validateSuspenseListNestedChild(step.value, _i)) {\n                return;\n              }\n\n              _i++;\n            }\n          }\n        } else {\n          error('A single row was passed to a <SuspenseList revealOrder=\"%s\" />. ' + 'This is not useful since it needs multiple rows. ' + 'Did you mean to pass multiple children or an array?', revealOrder);\n        }\n      }\n    }\n  }\n}\n\nfunction initSuspenseListRenderState(workInProgress, isBackwards, tail, lastContentRow, tailMode) {\n  var renderState = workInProgress.memoizedState;\n\n  if (renderState === null) {\n    workInProgress.memoizedState = {\n      isBackwards: isBackwards,\n      rendering: null,\n      renderingStartTime: 0,\n      last: lastContentRow,\n      tail: tail,\n      tailMode: tailMode\n    };\n  } else {\n    // We can reuse the existing object from previous renders.\n    renderState.isBackwards = isBackwards;\n    renderState.rendering = null;\n    renderState.renderingStartTime = 0;\n    renderState.last = lastContentRow;\n    renderState.tail = tail;\n    renderState.tailMode = tailMode;\n  }\n} // This can end up rendering this component multiple passes.\n// The first pass splits the children fibers into two sets. A head and tail.\n// We first render the head. If anything is in fallback state, we do another\n// pass through beginWork to rerender all children (including the tail) with\n// the force suspend context. If the first render didn't have anything in\n// in fallback state. Then we render each row in the tail one-by-one.\n// That happens in the completeWork phase without going back to beginWork.\n\n\nfunction updateSuspenseListComponent(current, workInProgress, renderLanes) {\n  var nextProps = workInProgress.pendingProps;\n  var revealOrder = nextProps.revealOrder;\n  var tailMode = nextProps.tail;\n  var newChildren = nextProps.children;\n  validateRevealOrder(revealOrder);\n  validateTailOptions(tailMode, revealOrder);\n  validateSuspenseListChildren(newChildren, revealOrder);\n  reconcileChildren(current, workInProgress, newChildren, renderLanes);\n  var suspenseContext = suspenseStackCursor.current;\n  var shouldForceFallback = hasSuspenseContext(suspenseContext, ForceSuspenseFallback);\n\n  if (shouldForceFallback) {\n    suspenseContext = setShallowSuspenseContext(suspenseContext, ForceSuspenseFallback);\n    workInProgress.flags |= DidCapture;\n  } else {\n    var didSuspendBefore = current !== null && (current.flags & DidCapture) !== NoFlags;\n\n    if (didSuspendBefore) {\n      // If we previously forced a fallback, we need to schedule work\n      // on any nested boundaries to let them know to try to render\n      // again. This is the same as context updating.\n      propagateSuspenseContextChange(workInProgress, workInProgress.child, renderLanes);\n    }\n\n    suspenseContext = setDefaultShallowSuspenseContext(suspenseContext);\n  }\n\n  pushSuspenseContext(workInProgress, suspenseContext);\n\n  if ((workInProgress.mode & ConcurrentMode) === NoMode) {\n    // In legacy mode, SuspenseList doesn't work so we just\n    // use make it a noop by treating it as the default revealOrder.\n    workInProgress.memoizedState = null;\n  } else {\n    switch (revealOrder) {\n      case 'forwards':\n        {\n          var lastContentRow = findLastContentRow(workInProgress.child);\n          var tail;\n\n          if (lastContentRow === null) {\n            // The whole list is part of the tail.\n            // TODO: We could fast path by just rendering the tail now.\n            tail = workInProgress.child;\n            workInProgress.child = null;\n          } else {\n            // Disconnect the tail rows after the content row.\n            // We're going to render them separately later.\n            tail = lastContentRow.sibling;\n            lastContentRow.sibling = null;\n          }\n\n          initSuspenseListRenderState(workInProgress, false, // isBackwards\n          tail, lastContentRow, tailMode);\n          break;\n        }\n\n      case 'backwards':\n        {\n          // We're going to find the first row that has existing content.\n          // At the same time we're going to reverse the list of everything\n          // we pass in the meantime. That's going to be our tail in reverse\n          // order.\n          var _tail = null;\n          var row = workInProgress.child;\n          workInProgress.child = null;\n\n          while (row !== null) {\n            var currentRow = row.alternate; // New rows can't be content rows.\n\n            if (currentRow !== null && findFirstSuspended(currentRow) === null) {\n              // This is the beginning of the main content.\n              workInProgress.child = row;\n              break;\n            }\n\n            var nextRow = row.sibling;\n            row.sibling = _tail;\n            _tail = row;\n            row = nextRow;\n          } // TODO: If workInProgress.child is null, we can continue on the tail immediately.\n\n\n          initSuspenseListRenderState(workInProgress, true, // isBackwards\n          _tail, null, // last\n          tailMode);\n          break;\n        }\n\n      case 'together':\n        {\n          initSuspenseListRenderState(workInProgress, false, // isBackwards\n          null, // tail\n          null, // last\n          undefined);\n          break;\n        }\n\n      default:\n        {\n          // The default reveal order is the same as not having\n          // a boundary.\n          workInProgress.memoizedState = null;\n        }\n    }\n  }\n\n  return workInProgress.child;\n}\n\nfunction updatePortalComponent(current, workInProgress, renderLanes) {\n  pushHostContainer(workInProgress, workInProgress.stateNode.containerInfo);\n  var nextChildren = workInProgress.pendingProps;\n\n  if (current === null) {\n    // Portals are special because we don't append the children during mount\n    // but at commit. Therefore we need to track insertions which the normal\n    // flow doesn't do during mount. This doesn't happen at the root because\n    // the root always starts with a \"current\" with a null child.\n    // TODO: Consider unifying this with how the root works.\n    workInProgress.child = reconcileChildFibers(workInProgress, null, nextChildren, renderLanes);\n  } else {\n    reconcileChildren(current, workInProgress, nextChildren, renderLanes);\n  }\n\n  return workInProgress.child;\n}\n\nvar hasWarnedAboutUsingNoValuePropOnContextProvider = false;\n\nfunction updateContextProvider(current, workInProgress, renderLanes) {\n  var providerType = workInProgress.type;\n  var context = providerType._context;\n  var newProps = workInProgress.pendingProps;\n  var oldProps = workInProgress.memoizedProps;\n  var newValue = newProps.value;\n\n  {\n    if (!('value' in newProps)) {\n      if (!hasWarnedAboutUsingNoValuePropOnContextProvider) {\n        hasWarnedAboutUsingNoValuePropOnContextProvider = true;\n\n        error('The `value` prop is required for the `<Context.Provider>`. Did you misspell it or forget to pass it?');\n      }\n    }\n\n    var providerPropTypes = workInProgress.type.propTypes;\n\n    if (providerPropTypes) {\n      checkPropTypes(providerPropTypes, newProps, 'prop', 'Context.Provider');\n    }\n  }\n\n  pushProvider(workInProgress, context, newValue);\n\n  {\n    if (oldProps !== null) {\n      var oldValue = oldProps.value;\n\n      if (objectIs(oldValue, newValue)) {\n        // No change. Bailout early if children are the same.\n        if (oldProps.children === newProps.children && !hasContextChanged()) {\n          return bailoutOnAlreadyFinishedWork(current, workInProgress, renderLanes);\n        }\n      } else {\n        // The context value changed. Search for matching consumers and schedule\n        // them to update.\n        propagateContextChange(workInProgress, context, renderLanes);\n      }\n    }\n  }\n\n  var newChildren = newProps.children;\n  reconcileChildren(current, workInProgress, newChildren, renderLanes);\n  return workInProgress.child;\n}\n\nvar hasWarnedAboutUsingContextAsConsumer = false;\n\nfunction updateContextConsumer(current, workInProgress, renderLanes) {\n  var context = workInProgress.type; // The logic below for Context differs depending on PROD or DEV mode. In\n  // DEV mode, we create a separate object for Context.Consumer that acts\n  // like a proxy to Context. This proxy object adds unnecessary code in PROD\n  // so we use the old behaviour (Context.Consumer references Context) to\n  // reduce size and overhead. The separate object references context via\n  // a property called \"_context\", which also gives us the ability to check\n  // in DEV mode if this property exists or not and warn if it does not.\n\n  {\n    if (context._context === undefined) {\n      // This may be because it's a Context (rather than a Consumer).\n      // Or it may be because it's older React where they're the same thing.\n      // We only want to warn if we're sure it's a new React.\n      if (context !== context.Consumer) {\n        if (!hasWarnedAboutUsingContextAsConsumer) {\n          hasWarnedAboutUsingContextAsConsumer = true;\n\n          error('Rendering <Context> directly is not supported and will be removed in ' + 'a future major release. Did you mean to render <Context.Consumer> instead?');\n        }\n      }\n    } else {\n      context = context._context;\n    }\n  }\n\n  var newProps = workInProgress.pendingProps;\n  var render = newProps.children;\n\n  {\n    if (typeof render !== 'function') {\n      error('A context consumer was rendered with multiple children, or a child ' + \"that isn't a function. A context consumer expects a single child \" + 'that is a function. If you did pass a function, make sure there ' + 'is no trailing or leading whitespace around it.');\n    }\n  }\n\n  prepareToReadContext(workInProgress, renderLanes);\n  var newValue = readContext(context);\n\n  {\n    markComponentRenderStarted(workInProgress);\n  }\n\n  var newChildren;\n\n  {\n    ReactCurrentOwner$1.current = workInProgress;\n    setIsRendering(true);\n    newChildren = render(newValue);\n    setIsRendering(false);\n  }\n\n  {\n    markComponentRenderStopped();\n  } // React DevTools reads this flag.\n\n\n  workInProgress.flags |= PerformedWork;\n  reconcileChildren(current, workInProgress, newChildren, renderLanes);\n  return workInProgress.child;\n}\n\nfunction markWorkInProgressReceivedUpdate() {\n  didReceiveUpdate = true;\n}\n\nfunction resetSuspendedCurrentOnMountInLegacyMode(current, workInProgress) {\n  if ((workInProgress.mode & ConcurrentMode) === NoMode) {\n    if (current !== null) {\n      // A lazy component only mounts if it suspended inside a non-\n      // concurrent tree, in an inconsistent state. We want to treat it like\n      // a new mount, even though an empty version of it already committed.\n      // Disconnect the alternate pointers.\n      current.alternate = null;\n      workInProgress.alternate = null; // Since this is conceptually a new fiber, schedule a Placement effect\n\n      workInProgress.flags |= Placement;\n    }\n  }\n}\n\nfunction bailoutOnAlreadyFinishedWork(current, workInProgress, renderLanes) {\n  if (current !== null) {\n    // Reuse previous dependencies\n    workInProgress.dependencies = current.dependencies;\n  }\n\n  {\n    // Don't update \"base\" render times for bailouts.\n    stopProfilerTimerIfRunning();\n  }\n\n  markSkippedUpdateLanes(workInProgress.lanes); // Check if the children have any pending work.\n\n  if (!includesSomeLane(renderLanes, workInProgress.childLanes)) {\n    // The children don't have any work either. We can skip them.\n    // TODO: Once we add back resuming, we should check if the children are\n    // a work-in-progress set. If so, we need to transfer their effects.\n    {\n      return null;\n    }\n  } // This fiber doesn't have work, but its subtree does. Clone the child\n  // fibers and continue.\n\n\n  cloneChildFibers(current, workInProgress);\n  return workInProgress.child;\n}\n\nfunction remountFiber(current, oldWorkInProgress, newWorkInProgress) {\n  {\n    var returnFiber = oldWorkInProgress.return;\n\n    if (returnFiber === null) {\n      // eslint-disable-next-line react-internal/prod-error-codes\n      throw new Error('Cannot swap the root fiber.');\n    } // Disconnect from the old current.\n    // It will get deleted.\n\n\n    current.alternate = null;\n    oldWorkInProgress.alternate = null; // Connect to the new tree.\n\n    newWorkInProgress.index = oldWorkInProgress.index;\n    newWorkInProgress.sibling = oldWorkInProgress.sibling;\n    newWorkInProgress.return = oldWorkInProgress.return;\n    newWorkInProgress.ref = oldWorkInProgress.ref; // Replace the child/sibling pointers above it.\n\n    if (oldWorkInProgress === returnFiber.child) {\n      returnFiber.child = newWorkInProgress;\n    } else {\n      var prevSibling = returnFiber.child;\n\n      if (prevSibling === null) {\n        // eslint-disable-next-line react-internal/prod-error-codes\n        throw new Error('Expected parent to have a child.');\n      }\n\n      while (prevSibling.sibling !== oldWorkInProgress) {\n        prevSibling = prevSibling.sibling;\n\n        if (prevSibling === null) {\n          // eslint-disable-next-line react-internal/prod-error-codes\n          throw new Error('Expected to find the previous sibling.');\n        }\n      }\n\n      prevSibling.sibling = newWorkInProgress;\n    } // Delete the old fiber and place the new one.\n    // Since the old fiber is disconnected, we have to schedule it manually.\n\n\n    var deletions = returnFiber.deletions;\n\n    if (deletions === null) {\n      returnFiber.deletions = [current];\n      returnFiber.flags |= ChildDeletion;\n    } else {\n      deletions.push(current);\n    }\n\n    newWorkInProgress.flags |= Placement; // Restart work from the new fiber.\n\n    return newWorkInProgress;\n  }\n}\n\nfunction checkScheduledUpdateOrContext(current, renderLanes) {\n  // Before performing an early bailout, we must check if there are pending\n  // updates or context.\n  var updateLanes = current.lanes;\n\n  if (includesSomeLane(updateLanes, renderLanes)) {\n    return true;\n  } // No pending update, but because context is propagated lazily, we need\n\n  return false;\n}\n\nfunction attemptEarlyBailoutIfNoScheduledUpdate(current, workInProgress, renderLanes) {\n  // This fiber does not have any pending work. Bailout without entering\n  // the begin phase. There's still some bookkeeping we that needs to be done\n  // in this optimized path, mostly pushing stuff onto the stack.\n  switch (workInProgress.tag) {\n    case HostRoot:\n      pushHostRootContext(workInProgress);\n      var root = workInProgress.stateNode;\n\n      resetHydrationState();\n      break;\n\n    case HostComponent:\n      pushHostContext(workInProgress);\n      break;\n\n    case ClassComponent:\n      {\n        var Component = workInProgress.type;\n\n        if (isContextProvider(Component)) {\n          pushContextProvider(workInProgress);\n        }\n\n        break;\n      }\n\n    case HostPortal:\n      pushHostContainer(workInProgress, workInProgress.stateNode.containerInfo);\n      break;\n\n    case ContextProvider:\n      {\n        var newValue = workInProgress.memoizedProps.value;\n        var context = workInProgress.type._context;\n        pushProvider(workInProgress, context, newValue);\n        break;\n      }\n\n    case Profiler:\n      {\n        // Profiler should only call onRender when one of its descendants actually rendered.\n        var hasChildWork = includesSomeLane(renderLanes, workInProgress.childLanes);\n\n        if (hasChildWork) {\n          workInProgress.flags |= Update;\n        }\n\n        {\n          // Reset effect durations for the next eventual effect phase.\n          // These are reset during render to allow the DevTools commit hook a chance to read them,\n          var stateNode = workInProgress.stateNode;\n          stateNode.effectDuration = 0;\n          stateNode.passiveEffectDuration = 0;\n        }\n      }\n\n      break;\n\n    case SuspenseComponent:\n      {\n        var state = workInProgress.memoizedState;\n\n        if (state !== null) {\n          if (state.dehydrated !== null) {\n            pushSuspenseContext(workInProgress, setDefaultShallowSuspenseContext(suspenseStackCursor.current)); // We know that this component will suspend again because if it has\n            // been unsuspended it has committed as a resolved Suspense component.\n            // If it needs to be retried, it should have work scheduled on it.\n\n            workInProgress.flags |= DidCapture; // We should never render the children of a dehydrated boundary until we\n            // upgrade it. We return null instead of bailoutOnAlreadyFinishedWork.\n\n            return null;\n          } // If this boundary is currently timed out, we need to decide\n          // whether to retry the primary children, or to skip over it and\n          // go straight to the fallback. Check the priority of the primary\n          // child fragment.\n\n\n          var primaryChildFragment = workInProgress.child;\n          var primaryChildLanes = primaryChildFragment.childLanes;\n\n          if (includesSomeLane(renderLanes, primaryChildLanes)) {\n            // The primary children have pending work. Use the normal path\n            // to attempt to render the primary children again.\n            return updateSuspenseComponent(current, workInProgress, renderLanes);\n          } else {\n            // The primary child fragment does not have pending work marked\n            // on it\n            pushSuspenseContext(workInProgress, setDefaultShallowSuspenseContext(suspenseStackCursor.current)); // The primary children do not have pending work with sufficient\n            // priority. Bailout.\n\n            var child = bailoutOnAlreadyFinishedWork(current, workInProgress, renderLanes);\n\n            if (child !== null) {\n              // The fallback children have pending work. Skip over the\n              // primary children and work on the fallback.\n              return child.sibling;\n            } else {\n              // Note: We can return `null` here because we already checked\n              // whether there were nested context consumers, via the call to\n              // `bailoutOnAlreadyFinishedWork` above.\n              return null;\n            }\n          }\n        } else {\n          pushSuspenseContext(workInProgress, setDefaultShallowSuspenseContext(suspenseStackCursor.current));\n        }\n\n        break;\n      }\n\n    case SuspenseListComponent:\n      {\n        var didSuspendBefore = (current.flags & DidCapture) !== NoFlags;\n\n        var _hasChildWork = includesSomeLane(renderLanes, workInProgress.childLanes);\n\n        if (didSuspendBefore) {\n          if (_hasChildWork) {\n            // If something was in fallback state last time, and we have all the\n            // same children then we're still in progressive loading state.\n            // Something might get unblocked by state updates or retries in the\n            // tree which will affect the tail. So we need to use the normal\n            // path to compute the correct tail.\n            return updateSuspenseListComponent(current, workInProgress, renderLanes);\n          } // If none of the children had any work, that means that none of\n          // them got retried so they'll still be blocked in the same way\n          // as before. We can fast bail out.\n\n\n          workInProgress.flags |= DidCapture;\n        } // If nothing suspended before and we're rendering the same children,\n        // then the tail doesn't matter. Anything new that suspends will work\n        // in the \"together\" mode, so we can continue from the state we had.\n\n\n        var renderState = workInProgress.memoizedState;\n\n        if (renderState !== null) {\n          // Reset to the \"together\" mode in case we've started a different\n          // update in the past but didn't complete it.\n          renderState.rendering = null;\n          renderState.tail = null;\n          renderState.lastEffect = null;\n        }\n\n        pushSuspenseContext(workInProgress, suspenseStackCursor.current);\n\n        if (_hasChildWork) {\n          break;\n        } else {\n          // If none of the children had any work, that means that none of\n          // them got retried so they'll still be blocked in the same way\n          // as before. We can fast bail out.\n          return null;\n        }\n      }\n\n    case OffscreenComponent:\n    case LegacyHiddenComponent:\n      {\n        // Need to check if the tree still needs to be deferred. This is\n        // almost identical to the logic used in the normal update path,\n        // so we'll just enter that. The only difference is we'll bail out\n        // at the next level instead of this one, because the child props\n        // have not changed. Which is fine.\n        // TODO: Probably should refactor `beginWork` to split the bailout\n        // path from the normal path. I'm tempted to do a labeled break here\n        // but I won't :)\n        workInProgress.lanes = NoLanes;\n        return updateOffscreenComponent(current, workInProgress, renderLanes);\n      }\n  }\n\n  return bailoutOnAlreadyFinishedWork(current, workInProgress, renderLanes);\n}\n\nfunction beginWork(current, workInProgress, renderLanes) {\n  {\n    if (workInProgress._debugNeedsRemount && current !== null) {\n      // This will restart the begin phase with a new fiber.\n      return remountFiber(current, workInProgress, createFiberFromTypeAndProps(workInProgress.type, workInProgress.key, workInProgress.pendingProps, workInProgress._debugOwner || null, workInProgress.mode, workInProgress.lanes));\n    }\n  }\n\n  if (current !== null) {\n    var oldProps = current.memoizedProps;\n    var newProps = workInProgress.pendingProps;\n\n    if (oldProps !== newProps || hasContextChanged() || ( // Force a re-render if the implementation changed due to hot reload:\n     workInProgress.type !== current.type )) {\n      // If props or context changed, mark the fiber as having performed work.\n      // This may be unset if the props are determined to be equal later (memo).\n      didReceiveUpdate = true;\n    } else {\n      // Neither props nor legacy context changes. Check if there's a pending\n      // update or context change.\n      var hasScheduledUpdateOrContext = checkScheduledUpdateOrContext(current, renderLanes);\n\n      if (!hasScheduledUpdateOrContext && // If this is the second pass of an error or suspense boundary, there\n      // may not be work scheduled on `current`, so we check for this flag.\n      (workInProgress.flags & DidCapture) === NoFlags) {\n        // No pending updates or context. Bail out now.\n        didReceiveUpdate = false;\n        return attemptEarlyBailoutIfNoScheduledUpdate(current, workInProgress, renderLanes);\n      }\n\n      if ((current.flags & ForceUpdateForLegacySuspense) !== NoFlags) {\n        // This is a special case that only exists for legacy mode.\n        // See https://github.com/facebook/react/pull/19216.\n        didReceiveUpdate = true;\n      } else {\n        // An update was scheduled on this fiber, but there are no new props\n        // nor legacy context. Set this to false. If an update queue or context\n        // consumer produces a changed value, it will set this to true. Otherwise,\n        // the component will assume the children have not changed and bail out.\n        didReceiveUpdate = false;\n      }\n    }\n  } else {\n    didReceiveUpdate = false;\n\n    if (getIsHydrating() && isForkedChild(workInProgress)) {\n      // Check if this child belongs to a list of muliple children in\n      // its parent.\n      //\n      // In a true multi-threaded implementation, we would render children on\n      // parallel threads. This would represent the beginning of a new render\n      // thread for this subtree.\n      //\n      // We only use this for id generation during hydration, which is why the\n      // logic is located in this special branch.\n      var slotIndex = workInProgress.index;\n      var numberOfForks = getForksAtLevel();\n      pushTreeId(workInProgress, numberOfForks, slotIndex);\n    }\n  } // Before entering the begin phase, clear pending update priority.\n  // TODO: This assumes that we're about to evaluate the component and process\n  // the update queue. However, there's an exception: SimpleMemoComponent\n  // sometimes bails out later in the begin phase. This indicates that we should\n  // move this assignment out of the common path and into each branch.\n\n\n  workInProgress.lanes = NoLanes;\n\n  switch (workInProgress.tag) {\n    case IndeterminateComponent:\n      {\n        return mountIndeterminateComponent(current, workInProgress, workInProgress.type, renderLanes);\n      }\n\n    case LazyComponent:\n      {\n        var elementType = workInProgress.elementType;\n        return mountLazyComponent(current, workInProgress, elementType, renderLanes);\n      }\n\n    case FunctionComponent:\n      {\n        var Component = workInProgress.type;\n        var unresolvedProps = workInProgress.pendingProps;\n        var resolvedProps = workInProgress.elementType === Component ? unresolvedProps : resolveDefaultProps(Component, unresolvedProps);\n        return updateFunctionComponent(current, workInProgress, Component, resolvedProps, renderLanes);\n      }\n\n    case ClassComponent:\n      {\n        var _Component = workInProgress.type;\n        var _unresolvedProps = workInProgress.pendingProps;\n\n        var _resolvedProps = workInProgress.elementType === _Component ? _unresolvedProps : resolveDefaultProps(_Component, _unresolvedProps);\n\n        return updateClassComponent(current, workInProgress, _Component, _resolvedProps, renderLanes);\n      }\n\n    case HostRoot:\n      return updateHostRoot(current, workInProgress, renderLanes);\n\n    case HostComponent:\n      return updateHostComponent(current, workInProgress, renderLanes);\n\n    case HostText:\n      return updateHostText(current, workInProgress);\n\n    case SuspenseComponent:\n      return updateSuspenseComponent(current, workInProgress, renderLanes);\n\n    case HostPortal:\n      return updatePortalComponent(current, workInProgress, renderLanes);\n\n    case ForwardRef:\n      {\n        var type = workInProgress.type;\n        var _unresolvedProps2 = workInProgress.pendingProps;\n\n        var _resolvedProps2 = workInProgress.elementType === type ? _unresolvedProps2 : resolveDefaultProps(type, _unresolvedProps2);\n\n        return updateForwardRef(current, workInProgress, type, _resolvedProps2, renderLanes);\n      }\n\n    case Fragment:\n      return updateFragment(current, workInProgress, renderLanes);\n\n    case Mode:\n      return updateMode(current, workInProgress, renderLanes);\n\n    case Profiler:\n      return updateProfiler(current, workInProgress, renderLanes);\n\n    case ContextProvider:\n      return updateContextProvider(current, workInProgress, renderLanes);\n\n    case ContextConsumer:\n      return updateContextConsumer(current, workInProgress, renderLanes);\n\n    case MemoComponent:\n      {\n        var _type2 = workInProgress.type;\n        var _unresolvedProps3 = workInProgress.pendingProps; // Resolve outer props first, then resolve inner props.\n\n        var _resolvedProps3 = resolveDefaultProps(_type2, _unresolvedProps3);\n\n        {\n          if (workInProgress.type !== workInProgress.elementType) {\n            var outerPropTypes = _type2.propTypes;\n\n            if (outerPropTypes) {\n              checkPropTypes(outerPropTypes, _resolvedProps3, // Resolved for outer only\n              'prop', getComponentNameFromType(_type2));\n            }\n          }\n        }\n\n        _resolvedProps3 = resolveDefaultProps(_type2.type, _resolvedProps3);\n        return updateMemoComponent(current, workInProgress, _type2, _resolvedProps3, renderLanes);\n      }\n\n    case SimpleMemoComponent:\n      {\n        return updateSimpleMemoComponent(current, workInProgress, workInProgress.type, workInProgress.pendingProps, renderLanes);\n      }\n\n    case IncompleteClassComponent:\n      {\n        var _Component2 = workInProgress.type;\n        var _unresolvedProps4 = workInProgress.pendingProps;\n\n        var _resolvedProps4 = workInProgress.elementType === _Component2 ? _unresolvedProps4 : resolveDefaultProps(_Component2, _unresolvedProps4);\n\n        return mountIncompleteClassComponent(current, workInProgress, _Component2, _resolvedProps4, renderLanes);\n      }\n\n    case SuspenseListComponent:\n      {\n        return updateSuspenseListComponent(current, workInProgress, renderLanes);\n      }\n\n    case ScopeComponent:\n      {\n\n        break;\n      }\n\n    case OffscreenComponent:\n      {\n        return updateOffscreenComponent(current, workInProgress, renderLanes);\n      }\n  }\n\n  throw new Error(\"Unknown unit of work tag (\" + workInProgress.tag + \"). This error is likely caused by a bug in \" + 'React. Please file an issue.');\n}\n\nfunction markUpdate(workInProgress) {\n  // Tag the fiber with an update effect. This turns a Placement into\n  // a PlacementAndUpdate.\n  workInProgress.flags |= Update;\n}\n\nfunction markRef$1(workInProgress) {\n  workInProgress.flags |= Ref;\n\n  {\n    workInProgress.flags |= RefStatic;\n  }\n}\n\nvar appendAllChildren;\nvar updateHostContainer;\nvar updateHostComponent$1;\nvar updateHostText$1;\n\n{\n  // Mutation mode\n  appendAllChildren = function (parent, workInProgress, needsVisibilityToggle, isHidden) {\n    // We only have the top Fiber that was created but we need recurse down its\n    // children to find all the terminal nodes.\n    var node = workInProgress.child;\n\n    while (node !== null) {\n      if (node.tag === HostComponent || node.tag === HostText) {\n        appendInitialChild(parent, node.stateNode);\n      } else if (node.tag === HostPortal) ; else if (node.child !== null) {\n        node.child.return = node;\n        node = node.child;\n        continue;\n      }\n\n      if (node === workInProgress) {\n        return;\n      }\n\n      while (node.sibling === null) {\n        if (node.return === null || node.return === workInProgress) {\n          return;\n        }\n\n        node = node.return;\n      }\n\n      node.sibling.return = node.return;\n      node = node.sibling;\n    }\n  };\n\n  updateHostContainer = function (current, workInProgress) {// Noop\n  };\n\n  updateHostComponent$1 = function (current, workInProgress, type, newProps, rootContainerInstance) {\n    // If we have an alternate, that means this is an update and we need to\n    // schedule a side-effect to do the updates.\n    var oldProps = current.memoizedProps;\n\n    if (oldProps === newProps) {\n      // In mutation mode, this is sufficient for a bailout because\n      // we won't touch this node even if children changed.\n      return;\n    } // If we get updated because one of our children updated, we don't\n    // have newProps so we'll have to reuse them.\n    // TODO: Split the update API as separate for the props vs. children.\n    // Even better would be if children weren't special cased at all tho.\n\n\n    var instance = workInProgress.stateNode;\n    var currentHostContext = getHostContext(); // TODO: Experiencing an error where oldProps is null. Suggests a host\n    // component is hitting the resume path. Figure out why. Possibly\n    // related to `hidden`.\n\n    var updatePayload = prepareUpdate(instance, type, oldProps, newProps, rootContainerInstance, currentHostContext); // TODO: Type this specific to this type of component.\n\n    workInProgress.updateQueue = updatePayload; // If the update payload indicates that there is a change or if there\n    // is a new ref we mark this as an update. All the work is done in commitWork.\n\n    if (updatePayload) {\n      markUpdate(workInProgress);\n    }\n  };\n\n  updateHostText$1 = function (current, workInProgress, oldText, newText) {\n    // If the text differs, mark it as an update. All the work in done in commitWork.\n    if (oldText !== newText) {\n      markUpdate(workInProgress);\n    }\n  };\n}\n\nfunction cutOffTailIfNeeded(renderState, hasRenderedATailFallback) {\n  if (getIsHydrating()) {\n    // If we're hydrating, we should consume as many items as we can\n    // so we don't leave any behind.\n    return;\n  }\n\n  switch (renderState.tailMode) {\n    case 'hidden':\n      {\n        // Any insertions at the end of the tail list after this point\n        // should be invisible. If there are already mounted boundaries\n        // anything before them are not considered for collapsing.\n        // Therefore we need to go through the whole tail to find if\n        // there are any.\n        var tailNode = renderState.tail;\n        var lastTailNode = null;\n\n        while (tailNode !== null) {\n          if (tailNode.alternate !== null) {\n            lastTailNode = tailNode;\n          }\n\n          tailNode = tailNode.sibling;\n        } // Next we're simply going to delete all insertions after the\n        // last rendered item.\n\n\n        if (lastTailNode === null) {\n          // All remaining items in the tail are insertions.\n          renderState.tail = null;\n        } else {\n          // Detach the insertion after the last node that was already\n          // inserted.\n          lastTailNode.sibling = null;\n        }\n\n        break;\n      }\n\n    case 'collapsed':\n      {\n        // Any insertions at the end of the tail list after this point\n        // should be invisible. If there are already mounted boundaries\n        // anything before them are not considered for collapsing.\n        // Therefore we need to go through the whole tail to find if\n        // there are any.\n        var _tailNode = renderState.tail;\n        var _lastTailNode = null;\n\n        while (_tailNode !== null) {\n          if (_tailNode.alternate !== null) {\n            _lastTailNode = _tailNode;\n          }\n\n          _tailNode = _tailNode.sibling;\n        } // Next we're simply going to delete all insertions after the\n        // last rendered item.\n\n\n        if (_lastTailNode === null) {\n          // All remaining items in the tail are insertions.\n          if (!hasRenderedATailFallback && renderState.tail !== null) {\n            // We suspended during the head. We want to show at least one\n            // row at the tail. So we'll keep on and cut off the rest.\n            renderState.tail.sibling = null;\n          } else {\n            renderState.tail = null;\n          }\n        } else {\n          // Detach the insertion after the last node that was already\n          // inserted.\n          _lastTailNode.sibling = null;\n        }\n\n        break;\n      }\n  }\n}\n\nfunction bubbleProperties(completedWork) {\n  var didBailout = completedWork.alternate !== null && completedWork.alternate.child === completedWork.child;\n  var newChildLanes = NoLanes;\n  var subtreeFlags = NoFlags;\n\n  if (!didBailout) {\n    // Bubble up the earliest expiration time.\n    if ( (completedWork.mode & ProfileMode) !== NoMode) {\n      // In profiling mode, resetChildExpirationTime is also used to reset\n      // profiler durations.\n      var actualDuration = completedWork.actualDuration;\n      var treeBaseDuration = completedWork.selfBaseDuration;\n      var child = completedWork.child;\n\n      while (child !== null) {\n        newChildLanes = mergeLanes(newChildLanes, mergeLanes(child.lanes, child.childLanes));\n        subtreeFlags |= child.subtreeFlags;\n        subtreeFlags |= child.flags; // When a fiber is cloned, its actualDuration is reset to 0. This value will\n        // only be updated if work is done on the fiber (i.e. it doesn't bailout).\n        // When work is done, it should bubble to the parent's actualDuration. If\n        // the fiber has not been cloned though, (meaning no work was done), then\n        // this value will reflect the amount of time spent working on a previous\n        // render. In that case it should not bubble. We determine whether it was\n        // cloned by comparing the child pointer.\n\n        actualDuration += child.actualDuration;\n        treeBaseDuration += child.treeBaseDuration;\n        child = child.sibling;\n      }\n\n      completedWork.actualDuration = actualDuration;\n      completedWork.treeBaseDuration = treeBaseDuration;\n    } else {\n      var _child = completedWork.child;\n\n      while (_child !== null) {\n        newChildLanes = mergeLanes(newChildLanes, mergeLanes(_child.lanes, _child.childLanes));\n        subtreeFlags |= _child.subtreeFlags;\n        subtreeFlags |= _child.flags; // Update the return pointer so the tree is consistent. This is a code\n        // smell because it assumes the commit phase is never concurrent with\n        // the render phase. Will address during refactor to alternate model.\n\n        _child.return = completedWork;\n        _child = _child.sibling;\n      }\n    }\n\n    completedWork.subtreeFlags |= subtreeFlags;\n  } else {\n    // Bubble up the earliest expiration time.\n    if ( (completedWork.mode & ProfileMode) !== NoMode) {\n      // In profiling mode, resetChildExpirationTime is also used to reset\n      // profiler durations.\n      var _treeBaseDuration = completedWork.selfBaseDuration;\n      var _child2 = completedWork.child;\n\n      while (_child2 !== null) {\n        newChildLanes = mergeLanes(newChildLanes, mergeLanes(_child2.lanes, _child2.childLanes)); // \"Static\" flags share the lifetime of the fiber/hook they belong to,\n        // so we should bubble those up even during a bailout. All the other\n        // flags have a lifetime only of a single render + commit, so we should\n        // ignore them.\n\n        subtreeFlags |= _child2.subtreeFlags & StaticMask;\n        subtreeFlags |= _child2.flags & StaticMask;\n        _treeBaseDuration += _child2.treeBaseDuration;\n        _child2 = _child2.sibling;\n      }\n\n      completedWork.treeBaseDuration = _treeBaseDuration;\n    } else {\n      var _child3 = completedWork.child;\n\n      while (_child3 !== null) {\n        newChildLanes = mergeLanes(newChildLanes, mergeLanes(_child3.lanes, _child3.childLanes)); // \"Static\" flags share the lifetime of the fiber/hook they belong to,\n        // so we should bubble those up even during a bailout. All the other\n        // flags have a lifetime only of a single render + commit, so we should\n        // ignore them.\n\n        subtreeFlags |= _child3.subtreeFlags & StaticMask;\n        subtreeFlags |= _child3.flags & StaticMask; // Update the return pointer so the tree is consistent. This is a code\n        // smell because it assumes the commit phase is never concurrent with\n        // the render phase. Will address during refactor to alternate model.\n\n        _child3.return = completedWork;\n        _child3 = _child3.sibling;\n      }\n    }\n\n    completedWork.subtreeFlags |= subtreeFlags;\n  }\n\n  completedWork.childLanes = newChildLanes;\n  return didBailout;\n}\n\nfunction completeDehydratedSuspenseBoundary(current, workInProgress, nextState) {\n  if (hasUnhydratedTailNodes() && (workInProgress.mode & ConcurrentMode) !== NoMode && (workInProgress.flags & DidCapture) === NoFlags) {\n    warnIfUnhydratedTailNodes(workInProgress);\n    resetHydrationState();\n    workInProgress.flags |= ForceClientRender | Incomplete | ShouldCapture;\n    return false;\n  }\n\n  var wasHydrated = popHydrationState(workInProgress);\n\n  if (nextState !== null && nextState.dehydrated !== null) {\n    // We might be inside a hydration state the first time we're picking up this\n    // Suspense boundary, and also after we've reentered it for further hydration.\n    if (current === null) {\n      if (!wasHydrated) {\n        throw new Error('A dehydrated suspense component was completed without a hydrated node. ' + 'This is probably a bug in React.');\n      }\n\n      prepareToHydrateHostSuspenseInstance(workInProgress);\n      bubbleProperties(workInProgress);\n\n      {\n        if ((workInProgress.mode & ProfileMode) !== NoMode) {\n          var isTimedOutSuspense = nextState !== null;\n\n          if (isTimedOutSuspense) {\n            // Don't count time spent in a timed out Suspense subtree as part of the base duration.\n            var primaryChildFragment = workInProgress.child;\n\n            if (primaryChildFragment !== null) {\n              // $FlowFixMe Flow doesn't support type casting in combination with the -= operator\n              workInProgress.treeBaseDuration -= primaryChildFragment.treeBaseDuration;\n            }\n          }\n        }\n      }\n\n      return false;\n    } else {\n      // We might have reentered this boundary to hydrate it. If so, we need to reset the hydration\n      // state since we're now exiting out of it. popHydrationState doesn't do that for us.\n      resetHydrationState();\n\n      if ((workInProgress.flags & DidCapture) === NoFlags) {\n        // This boundary did not suspend so it's now hydrated and unsuspended.\n        workInProgress.memoizedState = null;\n      } // If nothing suspended, we need to schedule an effect to mark this boundary\n      // as having hydrated so events know that they're free to be invoked.\n      // It's also a signal to replay events and the suspense callback.\n      // If something suspended, schedule an effect to attach retry listeners.\n      // So we might as well always mark this.\n\n\n      workInProgress.flags |= Update;\n      bubbleProperties(workInProgress);\n\n      {\n        if ((workInProgress.mode & ProfileMode) !== NoMode) {\n          var _isTimedOutSuspense = nextState !== null;\n\n          if (_isTimedOutSuspense) {\n            // Don't count time spent in a timed out Suspense subtree as part of the base duration.\n            var _primaryChildFragment = workInProgress.child;\n\n            if (_primaryChildFragment !== null) {\n              // $FlowFixMe Flow doesn't support type casting in combination with the -= operator\n              workInProgress.treeBaseDuration -= _primaryChildFragment.treeBaseDuration;\n            }\n          }\n        }\n      }\n\n      return false;\n    }\n  } else {\n    // Successfully completed this tree. If this was a forced client render,\n    // there may have been recoverable errors during first hydration\n    // attempt. If so, add them to a queue so we can log them in the\n    // commit phase.\n    upgradeHydrationErrorsToRecoverable(); // Fall through to normal Suspense path\n\n    return true;\n  }\n}\n\nfunction completeWork(current, workInProgress, renderLanes) {\n  var newProps = workInProgress.pendingProps; // Note: This intentionally doesn't check if we're hydrating because comparing\n  // to the current tree provider fiber is just as fast and less error-prone.\n  // Ideally we would have a special version of the work loop only\n  // for hydration.\n\n  popTreeContext(workInProgress);\n\n  switch (workInProgress.tag) {\n    case IndeterminateComponent:\n    case LazyComponent:\n    case SimpleMemoComponent:\n    case FunctionComponent:\n    case ForwardRef:\n    case Fragment:\n    case Mode:\n    case Profiler:\n    case ContextConsumer:\n    case MemoComponent:\n      bubbleProperties(workInProgress);\n      return null;\n\n    case ClassComponent:\n      {\n        var Component = workInProgress.type;\n\n        if (isContextProvider(Component)) {\n          popContext(workInProgress);\n        }\n\n        bubbleProperties(workInProgress);\n        return null;\n      }\n\n    case HostRoot:\n      {\n        var fiberRoot = workInProgress.stateNode;\n        popHostContainer(workInProgress);\n        popTopLevelContextObject(workInProgress);\n        resetWorkInProgressVersions();\n\n        if (fiberRoot.pendingContext) {\n          fiberRoot.context = fiberRoot.pendingContext;\n          fiberRoot.pendingContext = null;\n        }\n\n        if (current === null || current.child === null) {\n          // If we hydrated, pop so that we can delete any remaining children\n          // that weren't hydrated.\n          var wasHydrated = popHydrationState(workInProgress);\n\n          if (wasHydrated) {\n            // If we hydrated, then we'll need to schedule an update for\n            // the commit side-effects on the root.\n            markUpdate(workInProgress);\n          } else {\n            if (current !== null) {\n              var prevState = current.memoizedState;\n\n              if ( // Check if this is a client root\n              !prevState.isDehydrated || // Check if we reverted to client rendering (e.g. due to an error)\n              (workInProgress.flags & ForceClientRender) !== NoFlags) {\n                // Schedule an effect to clear this container at the start of the\n                // next commit. This handles the case of React rendering into a\n                // container with previous children. It's also safe to do for\n                // updates too, because current.child would only be null if the\n                // previous render was null (so the container would already\n                // be empty).\n                workInProgress.flags |= Snapshot; // If this was a forced client render, there may have been\n                // recoverable errors during first hydration attempt. If so, add\n                // them to a queue so we can log them in the commit phase.\n\n                upgradeHydrationErrorsToRecoverable();\n              }\n            }\n          }\n        }\n\n        updateHostContainer(current, workInProgress);\n        bubbleProperties(workInProgress);\n\n        return null;\n      }\n\n    case HostComponent:\n      {\n        popHostContext(workInProgress);\n        var rootContainerInstance = getRootHostContainer();\n        var type = workInProgress.type;\n\n        if (current !== null && workInProgress.stateNode != null) {\n          updateHostComponent$1(current, workInProgress, type, newProps, rootContainerInstance);\n\n          if (current.ref !== workInProgress.ref) {\n            markRef$1(workInProgress);\n          }\n        } else {\n          if (!newProps) {\n            if (workInProgress.stateNode === null) {\n              throw new Error('We must have new props for new mounts. This error is likely ' + 'caused by a bug in React. Please file an issue.');\n            } // This can happen when we abort work.\n\n\n            bubbleProperties(workInProgress);\n            return null;\n          }\n\n          var currentHostContext = getHostContext(); // TODO: Move createInstance to beginWork and keep it on a context\n          // \"stack\" as the parent. Then append children as we go in beginWork\n          // or completeWork depending on whether we want to add them top->down or\n          // bottom->up. Top->down is faster in IE11.\n\n          var _wasHydrated = popHydrationState(workInProgress);\n\n          if (_wasHydrated) {\n            // TODO: Move this and createInstance step into the beginPhase\n            // to consolidate.\n            if (prepareToHydrateHostInstance(workInProgress, rootContainerInstance, currentHostContext)) {\n              // If changes to the hydrated node need to be applied at the\n              // commit-phase we mark this as such.\n              markUpdate(workInProgress);\n            }\n          } else {\n            var instance = createInstance(type, newProps, rootContainerInstance, currentHostContext, workInProgress);\n            appendAllChildren(instance, workInProgress, false, false);\n            workInProgress.stateNode = instance; // Certain renderers require commit-time effects for initial mount.\n            // (eg DOM renderer supports auto-focus for certain elements).\n            // Make sure such renderers get scheduled for later work.\n\n            if (finalizeInitialChildren(instance, type, newProps, rootContainerInstance)) {\n              markUpdate(workInProgress);\n            }\n          }\n\n          if (workInProgress.ref !== null) {\n            // If there is a ref on a host node we need to schedule a callback\n            markRef$1(workInProgress);\n          }\n        }\n\n        bubbleProperties(workInProgress);\n        return null;\n      }\n\n    case HostText:\n      {\n        var newText = newProps;\n\n        if (current && workInProgress.stateNode != null) {\n          var oldText = current.memoizedProps; // If we have an alternate, that means this is an update and we need\n          // to schedule a side-effect to do the updates.\n\n          updateHostText$1(current, workInProgress, oldText, newText);\n        } else {\n          if (typeof newText !== 'string') {\n            if (workInProgress.stateNode === null) {\n              throw new Error('We must have new props for new mounts. This error is likely ' + 'caused by a bug in React. Please file an issue.');\n            } // This can happen when we abort work.\n\n          }\n\n          var _rootContainerInstance = getRootHostContainer();\n\n          var _currentHostContext = getHostContext();\n\n          var _wasHydrated2 = popHydrationState(workInProgress);\n\n          if (_wasHydrated2) {\n            if (prepareToHydrateHostTextInstance(workInProgress)) {\n              markUpdate(workInProgress);\n            }\n          } else {\n            workInProgress.stateNode = createTextInstance(newText, _rootContainerInstance, _currentHostContext, workInProgress);\n          }\n        }\n\n        bubbleProperties(workInProgress);\n        return null;\n      }\n\n    case SuspenseComponent:\n      {\n        popSuspenseContext(workInProgress);\n        var nextState = workInProgress.memoizedState; // Special path for dehydrated boundaries. We may eventually move this\n        // to its own fiber type so that we can add other kinds of hydration\n        // boundaries that aren't associated with a Suspense tree. In anticipation\n        // of such a refactor, all the hydration logic is contained in\n        // this branch.\n\n        if (current === null || current.memoizedState !== null && current.memoizedState.dehydrated !== null) {\n          var fallthroughToNormalSuspensePath = completeDehydratedSuspenseBoundary(current, workInProgress, nextState);\n\n          if (!fallthroughToNormalSuspensePath) {\n            if (workInProgress.flags & ShouldCapture) {\n              // Special case. There were remaining unhydrated nodes. We treat\n              // this as a mismatch. Revert to client rendering.\n              return workInProgress;\n            } else {\n              // Did not finish hydrating, either because this is the initial\n              // render or because something suspended.\n              return null;\n            }\n          } // Continue with the normal Suspense path.\n\n        }\n\n        if ((workInProgress.flags & DidCapture) !== NoFlags) {\n          // Something suspended. Re-render with the fallback children.\n          workInProgress.lanes = renderLanes; // Do not reset the effect list.\n\n          if ( (workInProgress.mode & ProfileMode) !== NoMode) {\n            transferActualDuration(workInProgress);\n          } // Don't bubble properties in this case.\n\n\n          return workInProgress;\n        }\n\n        var nextDidTimeout = nextState !== null;\n        var prevDidTimeout = current !== null && current.memoizedState !== null;\n        // a passive effect, which is when we process the transitions\n\n\n        if (nextDidTimeout !== prevDidTimeout) {\n          // an effect to toggle the subtree's visibility. When we switch from\n          // fallback -> primary, the inner Offscreen fiber schedules this effect\n          // as part of its normal complete phase. But when we switch from\n          // primary -> fallback, the inner Offscreen fiber does not have a complete\n          // phase. So we need to schedule its effect here.\n          //\n          // We also use this flag to connect/disconnect the effects, but the same\n          // logic applies: when re-connecting, the Offscreen fiber's complete\n          // phase will handle scheduling the effect. It's only when the fallback\n          // is active that we have to do anything special.\n\n\n          if (nextDidTimeout) {\n            var _offscreenFiber2 = workInProgress.child;\n            _offscreenFiber2.flags |= Visibility; // TODO: This will still suspend a synchronous tree if anything\n            // in the concurrent tree already suspended during this render.\n            // This is a known bug.\n\n            if ((workInProgress.mode & ConcurrentMode) !== NoMode) {\n              // TODO: Move this back to throwException because this is too late\n              // if this is a large tree which is common for initial loads. We\n              // don't know if we should restart a render or not until we get\n              // this marker, and this is too late.\n              // If this render already had a ping or lower pri updates,\n              // and this is the first time we know we're going to suspend we\n              // should be able to immediately restart from within throwException.\n              var hasInvisibleChildContext = current === null && (workInProgress.memoizedProps.unstable_avoidThisFallback !== true || !enableSuspenseAvoidThisFallback);\n\n              if (hasInvisibleChildContext || hasSuspenseContext(suspenseStackCursor.current, InvisibleParentSuspenseContext)) {\n                // If this was in an invisible tree or a new render, then showing\n                // this boundary is ok.\n                renderDidSuspend();\n              } else {\n                // Otherwise, we're going to have to hide content so we should\n                // suspend for longer if possible.\n                renderDidSuspendDelayIfPossible();\n              }\n            }\n          }\n        }\n\n        var wakeables = workInProgress.updateQueue;\n\n        if (wakeables !== null) {\n          // Schedule an effect to attach a retry listener to the promise.\n          // TODO: Move to passive phase\n          workInProgress.flags |= Update;\n        }\n\n        bubbleProperties(workInProgress);\n\n        {\n          if ((workInProgress.mode & ProfileMode) !== NoMode) {\n            if (nextDidTimeout) {\n              // Don't count time spent in a timed out Suspense subtree as part of the base duration.\n              var primaryChildFragment = workInProgress.child;\n\n              if (primaryChildFragment !== null) {\n                // $FlowFixMe Flow doesn't support type casting in combination with the -= operator\n                workInProgress.treeBaseDuration -= primaryChildFragment.treeBaseDuration;\n              }\n            }\n          }\n        }\n\n        return null;\n      }\n\n    case HostPortal:\n      popHostContainer(workInProgress);\n      updateHostContainer(current, workInProgress);\n\n      if (current === null) {\n        preparePortalMount(workInProgress.stateNode.containerInfo);\n      }\n\n      bubbleProperties(workInProgress);\n      return null;\n\n    case ContextProvider:\n      // Pop provider fiber\n      var context = workInProgress.type._context;\n      popProvider(context, workInProgress);\n      bubbleProperties(workInProgress);\n      return null;\n\n    case IncompleteClassComponent:\n      {\n        // Same as class component case. I put it down here so that the tags are\n        // sequential to ensure this switch is compiled to a jump table.\n        var _Component = workInProgress.type;\n\n        if (isContextProvider(_Component)) {\n          popContext(workInProgress);\n        }\n\n        bubbleProperties(workInProgress);\n        return null;\n      }\n\n    case SuspenseListComponent:\n      {\n        popSuspenseContext(workInProgress);\n        var renderState = workInProgress.memoizedState;\n\n        if (renderState === null) {\n          // We're running in the default, \"independent\" mode.\n          // We don't do anything in this mode.\n          bubbleProperties(workInProgress);\n          return null;\n        }\n\n        var didSuspendAlready = (workInProgress.flags & DidCapture) !== NoFlags;\n        var renderedTail = renderState.rendering;\n\n        if (renderedTail === null) {\n          // We just rendered the head.\n          if (!didSuspendAlready) {\n            // This is the first pass. We need to figure out if anything is still\n            // suspended in the rendered set.\n            // If new content unsuspended, but there's still some content that\n            // didn't. Then we need to do a second pass that forces everything\n            // to keep showing their fallbacks.\n            // We might be suspended if something in this render pass suspended, or\n            // something in the previous committed pass suspended. Otherwise,\n            // there's no chance so we can skip the expensive call to\n            // findFirstSuspended.\n            var cannotBeSuspended = renderHasNotSuspendedYet() && (current === null || (current.flags & DidCapture) === NoFlags);\n\n            if (!cannotBeSuspended) {\n              var row = workInProgress.child;\n\n              while (row !== null) {\n                var suspended = findFirstSuspended(row);\n\n                if (suspended !== null) {\n                  didSuspendAlready = true;\n                  workInProgress.flags |= DidCapture;\n                  cutOffTailIfNeeded(renderState, false); // If this is a newly suspended tree, it might not get committed as\n                  // part of the second pass. In that case nothing will subscribe to\n                  // its thenables. Instead, we'll transfer its thenables to the\n                  // SuspenseList so that it can retry if they resolve.\n                  // There might be multiple of these in the list but since we're\n                  // going to wait for all of them anyway, it doesn't really matter\n                  // which ones gets to ping. In theory we could get clever and keep\n                  // track of how many dependencies remain but it gets tricky because\n                  // in the meantime, we can add/remove/change items and dependencies.\n                  // We might bail out of the loop before finding any but that\n                  // doesn't matter since that means that the other boundaries that\n                  // we did find already has their listeners attached.\n\n                  var newThenables = suspended.updateQueue;\n\n                  if (newThenables !== null) {\n                    workInProgress.updateQueue = newThenables;\n                    workInProgress.flags |= Update;\n                  } // Rerender the whole list, but this time, we'll force fallbacks\n                  // to stay in place.\n                  // Reset the effect flags before doing the second pass since that's now invalid.\n                  // Reset the child fibers to their original state.\n\n\n                  workInProgress.subtreeFlags = NoFlags;\n                  resetChildFibers(workInProgress, renderLanes); // Set up the Suspense Context to force suspense and immediately\n                  // rerender the children.\n\n                  pushSuspenseContext(workInProgress, setShallowSuspenseContext(suspenseStackCursor.current, ForceSuspenseFallback)); // Don't bubble properties in this case.\n\n                  return workInProgress.child;\n                }\n\n                row = row.sibling;\n              }\n            }\n\n            if (renderState.tail !== null && now() > getRenderTargetTime()) {\n              // We have already passed our CPU deadline but we still have rows\n              // left in the tail. We'll just give up further attempts to render\n              // the main content and only render fallbacks.\n              workInProgress.flags |= DidCapture;\n              didSuspendAlready = true;\n              cutOffTailIfNeeded(renderState, false); // Since nothing actually suspended, there will nothing to ping this\n              // to get it started back up to attempt the next item. While in terms\n              // of priority this work has the same priority as this current render,\n              // it's not part of the same transition once the transition has\n              // committed. If it's sync, we still want to yield so that it can be\n              // painted. Conceptually, this is really the same as pinging.\n              // We can use any RetryLane even if it's the one currently rendering\n              // since we're leaving it behind on this node.\n\n              workInProgress.lanes = SomeRetryLane;\n            }\n          } else {\n            cutOffTailIfNeeded(renderState, false);\n          } // Next we're going to render the tail.\n\n        } else {\n          // Append the rendered row to the child list.\n          if (!didSuspendAlready) {\n            var _suspended = findFirstSuspended(renderedTail);\n\n            if (_suspended !== null) {\n              workInProgress.flags |= DidCapture;\n              didSuspendAlready = true; // Ensure we transfer the update queue to the parent so that it doesn't\n              // get lost if this row ends up dropped during a second pass.\n\n              var _newThenables = _suspended.updateQueue;\n\n              if (_newThenables !== null) {\n                workInProgress.updateQueue = _newThenables;\n                workInProgress.flags |= Update;\n              }\n\n              cutOffTailIfNeeded(renderState, true); // This might have been modified.\n\n              if (renderState.tail === null && renderState.tailMode === 'hidden' && !renderedTail.alternate && !getIsHydrating() // We don't cut it if we're hydrating.\n              ) {\n                  // We're done.\n                  bubbleProperties(workInProgress);\n                  return null;\n                }\n            } else if ( // The time it took to render last row is greater than the remaining\n            // time we have to render. So rendering one more row would likely\n            // exceed it.\n            now() * 2 - renderState.renderingStartTime > getRenderTargetTime() && renderLanes !== OffscreenLane) {\n              // We have now passed our CPU deadline and we'll just give up further\n              // attempts to render the main content and only render fallbacks.\n              // The assumption is that this is usually faster.\n              workInProgress.flags |= DidCapture;\n              didSuspendAlready = true;\n              cutOffTailIfNeeded(renderState, false); // Since nothing actually suspended, there will nothing to ping this\n              // to get it started back up to attempt the next item. While in terms\n              // of priority this work has the same priority as this current render,\n              // it's not part of the same transition once the transition has\n              // committed. If it's sync, we still want to yield so that it can be\n              // painted. Conceptually, this is really the same as pinging.\n              // We can use any RetryLane even if it's the one currently rendering\n              // since we're leaving it behind on this node.\n\n              workInProgress.lanes = SomeRetryLane;\n            }\n          }\n\n          if (renderState.isBackwards) {\n            // The effect list of the backwards tail will have been added\n            // to the end. This breaks the guarantee that life-cycles fire in\n            // sibling order but that isn't a strong guarantee promised by React.\n            // Especially since these might also just pop in during future commits.\n            // Append to the beginning of the list.\n            renderedTail.sibling = workInProgress.child;\n            workInProgress.child = renderedTail;\n          } else {\n            var previousSibling = renderState.last;\n\n            if (previousSibling !== null) {\n              previousSibling.sibling = renderedTail;\n            } else {\n              workInProgress.child = renderedTail;\n            }\n\n            renderState.last = renderedTail;\n          }\n        }\n\n        if (renderState.tail !== null) {\n          // We still have tail rows to render.\n          // Pop a row.\n          var next = renderState.tail;\n          renderState.rendering = next;\n          renderState.tail = next.sibling;\n          renderState.renderingStartTime = now();\n          next.sibling = null; // Restore the context.\n          // TODO: We can probably just avoid popping it instead and only\n          // setting it the first time we go from not suspended to suspended.\n\n          var suspenseContext = suspenseStackCursor.current;\n\n          if (didSuspendAlready) {\n            suspenseContext = setShallowSuspenseContext(suspenseContext, ForceSuspenseFallback);\n          } else {\n            suspenseContext = setDefaultShallowSuspenseContext(suspenseContext);\n          }\n\n          pushSuspenseContext(workInProgress, suspenseContext); // Do a pass over the next row.\n          // Don't bubble properties in this case.\n\n          return next;\n        }\n\n        bubbleProperties(workInProgress);\n        return null;\n      }\n\n    case ScopeComponent:\n      {\n\n        break;\n      }\n\n    case OffscreenComponent:\n    case LegacyHiddenComponent:\n      {\n        popRenderLanes(workInProgress);\n        var _nextState = workInProgress.memoizedState;\n        var nextIsHidden = _nextState !== null;\n\n        if (current !== null) {\n          var _prevState = current.memoizedState;\n          var prevIsHidden = _prevState !== null;\n\n          if (prevIsHidden !== nextIsHidden && ( // LegacyHidden doesn't do any hiding  it only pre-renders.\n          !enableLegacyHidden )) {\n            workInProgress.flags |= Visibility;\n          }\n        }\n\n        if (!nextIsHidden || (workInProgress.mode & ConcurrentMode) === NoMode) {\n          bubbleProperties(workInProgress);\n        } else {\n          // Don't bubble properties for hidden children unless we're rendering\n          // at offscreen priority.\n          if (includesSomeLane(subtreeRenderLanes, OffscreenLane)) {\n            bubbleProperties(workInProgress);\n\n            {\n              // Check if there was an insertion or update in the hidden subtree.\n              // If so, we need to hide those nodes in the commit phase, so\n              // schedule a visibility effect.\n              if ( workInProgress.subtreeFlags & (Placement | Update)) {\n                workInProgress.flags |= Visibility;\n              }\n            }\n          }\n        }\n        return null;\n      }\n\n    case CacheComponent:\n      {\n\n        return null;\n      }\n\n    case TracingMarkerComponent:\n      {\n\n        return null;\n      }\n  }\n\n  throw new Error(\"Unknown unit of work tag (\" + workInProgress.tag + \"). This error is likely caused by a bug in \" + 'React. Please file an issue.');\n}\n\nfunction unwindWork(current, workInProgress, renderLanes) {\n  // Note: This intentionally doesn't check if we're hydrating because comparing\n  // to the current tree provider fiber is just as fast and less error-prone.\n  // Ideally we would have a special version of the work loop only\n  // for hydration.\n  popTreeContext(workInProgress);\n\n  switch (workInProgress.tag) {\n    case ClassComponent:\n      {\n        var Component = workInProgress.type;\n\n        if (isContextProvider(Component)) {\n          popContext(workInProgress);\n        }\n\n        var flags = workInProgress.flags;\n\n        if (flags & ShouldCapture) {\n          workInProgress.flags = flags & ~ShouldCapture | DidCapture;\n\n          if ( (workInProgress.mode & ProfileMode) !== NoMode) {\n            transferActualDuration(workInProgress);\n          }\n\n          return workInProgress;\n        }\n\n        return null;\n      }\n\n    case HostRoot:\n      {\n        var root = workInProgress.stateNode;\n        popHostContainer(workInProgress);\n        popTopLevelContextObject(workInProgress);\n        resetWorkInProgressVersions();\n        var _flags = workInProgress.flags;\n\n        if ((_flags & ShouldCapture) !== NoFlags && (_flags & DidCapture) === NoFlags) {\n          // There was an error during render that wasn't captured by a suspense\n          // boundary. Do a second pass on the root to unmount the children.\n          workInProgress.flags = _flags & ~ShouldCapture | DidCapture;\n          return workInProgress;\n        } // We unwound to the root without completing it. Exit.\n\n\n        return null;\n      }\n\n    case HostComponent:\n      {\n        // TODO: popHydrationState\n        popHostContext(workInProgress);\n        return null;\n      }\n\n    case SuspenseComponent:\n      {\n        popSuspenseContext(workInProgress);\n        var suspenseState = workInProgress.memoizedState;\n\n        if (suspenseState !== null && suspenseState.dehydrated !== null) {\n          if (workInProgress.alternate === null) {\n            throw new Error('Threw in newly mounted dehydrated component. This is likely a bug in ' + 'React. Please file an issue.');\n          }\n\n          resetHydrationState();\n        }\n\n        var _flags2 = workInProgress.flags;\n\n        if (_flags2 & ShouldCapture) {\n          workInProgress.flags = _flags2 & ~ShouldCapture | DidCapture; // Captured a suspense effect. Re-render the boundary.\n\n          if ( (workInProgress.mode & ProfileMode) !== NoMode) {\n            transferActualDuration(workInProgress);\n          }\n\n          return workInProgress;\n        }\n\n        return null;\n      }\n\n    case SuspenseListComponent:\n      {\n        popSuspenseContext(workInProgress); // SuspenseList doesn't actually catch anything. It should've been\n        // caught by a nested boundary. If not, it should bubble through.\n\n        return null;\n      }\n\n    case HostPortal:\n      popHostContainer(workInProgress);\n      return null;\n\n    case ContextProvider:\n      var context = workInProgress.type._context;\n      popProvider(context, workInProgress);\n      return null;\n\n    case OffscreenComponent:\n    case LegacyHiddenComponent:\n      popRenderLanes(workInProgress);\n      return null;\n\n    case CacheComponent:\n\n      return null;\n\n    default:\n      return null;\n  }\n}\n\nfunction unwindInterruptedWork(current, interruptedWork, renderLanes) {\n  // Note: This intentionally doesn't check if we're hydrating because comparing\n  // to the current tree provider fiber is just as fast and less error-prone.\n  // Ideally we would have a special version of the work loop only\n  // for hydration.\n  popTreeContext(interruptedWork);\n\n  switch (interruptedWork.tag) {\n    case ClassComponent:\n      {\n        var childContextTypes = interruptedWork.type.childContextTypes;\n\n        if (childContextTypes !== null && childContextTypes !== undefined) {\n          popContext(interruptedWork);\n        }\n\n        break;\n      }\n\n    case HostRoot:\n      {\n        var root = interruptedWork.stateNode;\n        popHostContainer(interruptedWork);\n        popTopLevelContextObject(interruptedWork);\n        resetWorkInProgressVersions();\n        break;\n      }\n\n    case HostComponent:\n      {\n        popHostContext(interruptedWork);\n        break;\n      }\n\n    case HostPortal:\n      popHostContainer(interruptedWork);\n      break;\n\n    case SuspenseComponent:\n      popSuspenseContext(interruptedWork);\n      break;\n\n    case SuspenseListComponent:\n      popSuspenseContext(interruptedWork);\n      break;\n\n    case ContextProvider:\n      var context = interruptedWork.type._context;\n      popProvider(context, interruptedWork);\n      break;\n\n    case OffscreenComponent:\n    case LegacyHiddenComponent:\n      popRenderLanes(interruptedWork);\n      break;\n  }\n}\n\nvar didWarnAboutUndefinedSnapshotBeforeUpdate = null;\n\n{\n  didWarnAboutUndefinedSnapshotBeforeUpdate = new Set();\n} // Used during the commit phase to track the state of the Offscreen component stack.\n// Allows us to avoid traversing the return path to find the nearest Offscreen ancestor.\n// Only used when enableSuspenseLayoutEffectSemantics is enabled.\n\n\nvar offscreenSubtreeIsHidden = false;\nvar offscreenSubtreeWasHidden = false;\nvar PossiblyWeakSet = typeof WeakSet === 'function' ? WeakSet : Set;\nvar nextEffect = null; // Used for Profiling builds to track updaters.\n\nvar inProgressLanes = null;\nvar inProgressRoot = null;\nfunction reportUncaughtErrorInDEV(error) {\n  // Wrapping each small part of the commit phase into a guarded\n  // callback is a bit too slow (https://github.com/facebook/react/pull/21666).\n  // But we rely on it to surface errors to DEV tools like overlays\n  // (https://github.com/facebook/react/issues/21712).\n  // As a compromise, rethrow only caught errors in a guard.\n  {\n    invokeGuardedCallback(null, function () {\n      throw error;\n    });\n    clearCaughtError();\n  }\n}\n\nvar callComponentWillUnmountWithTimer = function (current, instance) {\n  instance.props = current.memoizedProps;\n  instance.state = current.memoizedState;\n\n  if ( current.mode & ProfileMode) {\n    try {\n      startLayoutEffectTimer();\n      instance.componentWillUnmount();\n    } finally {\n      recordLayoutEffectDuration(current);\n    }\n  } else {\n    instance.componentWillUnmount();\n  }\n}; // Capture errors so they don't interrupt mounting.\n\n\nfunction safelyCallCommitHookLayoutEffectListMount(current, nearestMountedAncestor) {\n  try {\n    commitHookEffectListMount(Layout, current);\n  } catch (error) {\n    captureCommitPhaseError(current, nearestMountedAncestor, error);\n  }\n} // Capture errors so they don't interrupt unmounting.\n\n\nfunction safelyCallComponentWillUnmount(current, nearestMountedAncestor, instance) {\n  try {\n    callComponentWillUnmountWithTimer(current, instance);\n  } catch (error) {\n    captureCommitPhaseError(current, nearestMountedAncestor, error);\n  }\n} // Capture errors so they don't interrupt mounting.\n\n\nfunction safelyCallComponentDidMount(current, nearestMountedAncestor, instance) {\n  try {\n    instance.componentDidMount();\n  } catch (error) {\n    captureCommitPhaseError(current, nearestMountedAncestor, error);\n  }\n} // Capture errors so they don't interrupt mounting.\n\n\nfunction safelyAttachRef(current, nearestMountedAncestor) {\n  try {\n    commitAttachRef(current);\n  } catch (error) {\n    captureCommitPhaseError(current, nearestMountedAncestor, error);\n  }\n}\n\nfunction safelyDetachRef(current, nearestMountedAncestor) {\n  var ref = current.ref;\n\n  if (ref !== null) {\n    if (typeof ref === 'function') {\n      var retVal;\n\n      try {\n        if (enableProfilerTimer && enableProfilerCommitHooks && current.mode & ProfileMode) {\n          try {\n            startLayoutEffectTimer();\n            retVal = ref(null);\n          } finally {\n            recordLayoutEffectDuration(current);\n          }\n        } else {\n          retVal = ref(null);\n        }\n      } catch (error) {\n        captureCommitPhaseError(current, nearestMountedAncestor, error);\n      }\n\n      {\n        if (typeof retVal === 'function') {\n          error('Unexpected return value from a callback ref in %s. ' + 'A callback ref should not return a function.', getComponentNameFromFiber(current));\n        }\n      }\n    } else {\n      ref.current = null;\n    }\n  }\n}\n\nfunction safelyCallDestroy(current, nearestMountedAncestor, destroy) {\n  try {\n    destroy();\n  } catch (error) {\n    captureCommitPhaseError(current, nearestMountedAncestor, error);\n  }\n}\n\nvar focusedInstanceHandle = null;\nvar shouldFireAfterActiveInstanceBlur = false;\nfunction commitBeforeMutationEffects(root, firstChild) {\n  focusedInstanceHandle = prepareForCommit(root.containerInfo);\n  nextEffect = firstChild;\n  commitBeforeMutationEffects_begin(); // We no longer need to track the active instance fiber\n\n  var shouldFire = shouldFireAfterActiveInstanceBlur;\n  shouldFireAfterActiveInstanceBlur = false;\n  focusedInstanceHandle = null;\n  return shouldFire;\n}\n\nfunction commitBeforeMutationEffects_begin() {\n  while (nextEffect !== null) {\n    var fiber = nextEffect; // This phase is only used for beforeActiveInstanceBlur.\n\n    var child = fiber.child;\n\n    if ((fiber.subtreeFlags & BeforeMutationMask) !== NoFlags && child !== null) {\n      child.return = fiber;\n      nextEffect = child;\n    } else {\n      commitBeforeMutationEffects_complete();\n    }\n  }\n}\n\nfunction commitBeforeMutationEffects_complete() {\n  while (nextEffect !== null) {\n    var fiber = nextEffect;\n    setCurrentFiber(fiber);\n\n    try {\n      commitBeforeMutationEffectsOnFiber(fiber);\n    } catch (error) {\n      captureCommitPhaseError(fiber, fiber.return, error);\n    }\n\n    resetCurrentFiber();\n    var sibling = fiber.sibling;\n\n    if (sibling !== null) {\n      sibling.return = fiber.return;\n      nextEffect = sibling;\n      return;\n    }\n\n    nextEffect = fiber.return;\n  }\n}\n\nfunction commitBeforeMutationEffectsOnFiber(finishedWork) {\n  var current = finishedWork.alternate;\n  var flags = finishedWork.flags;\n\n  if ((flags & Snapshot) !== NoFlags) {\n    setCurrentFiber(finishedWork);\n\n    switch (finishedWork.tag) {\n      case FunctionComponent:\n      case ForwardRef:\n      case SimpleMemoComponent:\n        {\n          break;\n        }\n\n      case ClassComponent:\n        {\n          if (current !== null) {\n            var prevProps = current.memoizedProps;\n            var prevState = current.memoizedState;\n            var instance = finishedWork.stateNode; // We could update instance props and state here,\n            // but instead we rely on them being set during last render.\n            // TODO: revisit this when we implement resuming.\n\n            {\n              if (finishedWork.type === finishedWork.elementType && !didWarnAboutReassigningProps) {\n                if (instance.props !== finishedWork.memoizedProps) {\n                  error('Expected %s props to match memoized props before ' + 'getSnapshotBeforeUpdate. ' + 'This might either be because of a bug in React, or because ' + 'a component reassigns its own `this.props`. ' + 'Please file an issue.', getComponentNameFromFiber(finishedWork) || 'instance');\n                }\n\n                if (instance.state !== finishedWork.memoizedState) {\n                  error('Expected %s state to match memoized state before ' + 'getSnapshotBeforeUpdate. ' + 'This might either be because of a bug in React, or because ' + 'a component reassigns its own `this.state`. ' + 'Please file an issue.', getComponentNameFromFiber(finishedWork) || 'instance');\n                }\n              }\n            }\n\n            var snapshot = instance.getSnapshotBeforeUpdate(finishedWork.elementType === finishedWork.type ? prevProps : resolveDefaultProps(finishedWork.type, prevProps), prevState);\n\n            {\n              var didWarnSet = didWarnAboutUndefinedSnapshotBeforeUpdate;\n\n              if (snapshot === undefined && !didWarnSet.has(finishedWork.type)) {\n                didWarnSet.add(finishedWork.type);\n\n                error('%s.getSnapshotBeforeUpdate(): A snapshot value (or null) ' + 'must be returned. You have returned undefined.', getComponentNameFromFiber(finishedWork));\n              }\n            }\n\n            instance.__reactInternalSnapshotBeforeUpdate = snapshot;\n          }\n\n          break;\n        }\n\n      case HostRoot:\n        {\n          {\n            var root = finishedWork.stateNode;\n            clearContainer(root.containerInfo);\n          }\n\n          break;\n        }\n\n      case HostComponent:\n      case HostText:\n      case HostPortal:\n      case IncompleteClassComponent:\n        // Nothing to do for these component types\n        break;\n\n      default:\n        {\n          throw new Error('This unit of work tag should not have side-effects. This error is ' + 'likely caused by a bug in React. Please file an issue.');\n        }\n    }\n\n    resetCurrentFiber();\n  }\n}\n\nfunction commitHookEffectListUnmount(flags, finishedWork, nearestMountedAncestor) {\n  var updateQueue = finishedWork.updateQueue;\n  var lastEffect = updateQueue !== null ? updateQueue.lastEffect : null;\n\n  if (lastEffect !== null) {\n    var firstEffect = lastEffect.next;\n    var effect = firstEffect;\n\n    do {\n      if ((effect.tag & flags) === flags) {\n        // Unmount\n        var destroy = effect.destroy;\n        effect.destroy = undefined;\n\n        if (destroy !== undefined) {\n          {\n            if ((flags & Passive$1) !== NoFlags$1) {\n              markComponentPassiveEffectUnmountStarted(finishedWork);\n            } else if ((flags & Layout) !== NoFlags$1) {\n              markComponentLayoutEffectUnmountStarted(finishedWork);\n            }\n          }\n\n          {\n            if ((flags & Insertion) !== NoFlags$1) {\n              setIsRunningInsertionEffect(true);\n            }\n          }\n\n          safelyCallDestroy(finishedWork, nearestMountedAncestor, destroy);\n\n          {\n            if ((flags & Insertion) !== NoFlags$1) {\n              setIsRunningInsertionEffect(false);\n            }\n          }\n\n          {\n            if ((flags & Passive$1) !== NoFlags$1) {\n              markComponentPassiveEffectUnmountStopped();\n            } else if ((flags & Layout) !== NoFlags$1) {\n              markComponentLayoutEffectUnmountStopped();\n            }\n          }\n        }\n      }\n\n      effect = effect.next;\n    } while (effect !== firstEffect);\n  }\n}\n\nfunction commitHookEffectListMount(flags, finishedWork) {\n  var updateQueue = finishedWork.updateQueue;\n  var lastEffect = updateQueue !== null ? updateQueue.lastEffect : null;\n\n  if (lastEffect !== null) {\n    var firstEffect = lastEffect.next;\n    var effect = firstEffect;\n\n    do {\n      if ((effect.tag & flags) === flags) {\n        {\n          if ((flags & Passive$1) !== NoFlags$1) {\n            markComponentPassiveEffectMountStarted(finishedWork);\n          } else if ((flags & Layout) !== NoFlags$1) {\n            markComponentLayoutEffectMountStarted(finishedWork);\n          }\n        } // Mount\n\n\n        var create = effect.create;\n\n        {\n          if ((flags & Insertion) !== NoFlags$1) {\n            setIsRunningInsertionEffect(true);\n          }\n        }\n\n        effect.destroy = create();\n\n        {\n          if ((flags & Insertion) !== NoFlags$1) {\n            setIsRunningInsertionEffect(false);\n          }\n        }\n\n        {\n          if ((flags & Passive$1) !== NoFlags$1) {\n            markComponentPassiveEffectMountStopped();\n          } else if ((flags & Layout) !== NoFlags$1) {\n            markComponentLayoutEffectMountStopped();\n          }\n        }\n\n        {\n          var destroy = effect.destroy;\n\n          if (destroy !== undefined && typeof destroy !== 'function') {\n            var hookName = void 0;\n\n            if ((effect.tag & Layout) !== NoFlags) {\n              hookName = 'useLayoutEffect';\n            } else if ((effect.tag & Insertion) !== NoFlags) {\n              hookName = 'useInsertionEffect';\n            } else {\n              hookName = 'useEffect';\n            }\n\n            var addendum = void 0;\n\n            if (destroy === null) {\n              addendum = ' You returned null. If your effect does not require clean ' + 'up, return undefined (or nothing).';\n            } else if (typeof destroy.then === 'function') {\n              addendum = '\\n\\nIt looks like you wrote ' + hookName + '(async () => ...) or returned a Promise. ' + 'Instead, write the async function inside your effect ' + 'and call it immediately:\\n\\n' + hookName + '(() => {\\n' + '  async function fetchData() {\\n' + '    // You can await here\\n' + '    const response = await MyAPI.getData(someId);\\n' + '    // ...\\n' + '  }\\n' + '  fetchData();\\n' + \"}, [someId]); // Or [] if effect doesn't need props or state\\n\\n\" + 'Learn more about data fetching with Hooks: https://reactjs.org/link/hooks-data-fetching';\n            } else {\n              addendum = ' You returned: ' + destroy;\n            }\n\n            error('%s must not return anything besides a function, ' + 'which is used for clean-up.%s', hookName, addendum);\n          }\n        }\n      }\n\n      effect = effect.next;\n    } while (effect !== firstEffect);\n  }\n}\n\nfunction commitPassiveEffectDurations(finishedRoot, finishedWork) {\n  {\n    // Only Profilers with work in their subtree will have an Update effect scheduled.\n    if ((finishedWork.flags & Update) !== NoFlags) {\n      switch (finishedWork.tag) {\n        case Profiler:\n          {\n            var passiveEffectDuration = finishedWork.stateNode.passiveEffectDuration;\n            var _finishedWork$memoize = finishedWork.memoizedProps,\n                id = _finishedWork$memoize.id,\n                onPostCommit = _finishedWork$memoize.onPostCommit; // This value will still reflect the previous commit phase.\n            // It does not get reset until the start of the next commit phase.\n\n            var commitTime = getCommitTime();\n            var phase = finishedWork.alternate === null ? 'mount' : 'update';\n\n            {\n              if (isCurrentUpdateNested()) {\n                phase = 'nested-update';\n              }\n            }\n\n            if (typeof onPostCommit === 'function') {\n              onPostCommit(id, phase, passiveEffectDuration, commitTime);\n            } // Bubble times to the next nearest ancestor Profiler.\n            // After we process that Profiler, we'll bubble further up.\n\n\n            var parentFiber = finishedWork.return;\n\n            outer: while (parentFiber !== null) {\n              switch (parentFiber.tag) {\n                case HostRoot:\n                  var root = parentFiber.stateNode;\n                  root.passiveEffectDuration += passiveEffectDuration;\n                  break outer;\n\n                case Profiler:\n                  var parentStateNode = parentFiber.stateNode;\n                  parentStateNode.passiveEffectDuration += passiveEffectDuration;\n                  break outer;\n              }\n\n              parentFiber = parentFiber.return;\n            }\n\n            break;\n          }\n      }\n    }\n  }\n}\n\nfunction commitLayoutEffectOnFiber(finishedRoot, current, finishedWork, committedLanes) {\n  if ((finishedWork.flags & LayoutMask) !== NoFlags) {\n    switch (finishedWork.tag) {\n      case FunctionComponent:\n      case ForwardRef:\n      case SimpleMemoComponent:\n        {\n          if ( !offscreenSubtreeWasHidden) {\n            // At this point layout effects have already been destroyed (during mutation phase).\n            // This is done to prevent sibling component effects from interfering with each other,\n            // e.g. a destroy function in one component should never override a ref set\n            // by a create function in another component during the same commit.\n            if ( finishedWork.mode & ProfileMode) {\n              try {\n                startLayoutEffectTimer();\n                commitHookEffectListMount(Layout | HasEffect, finishedWork);\n              } finally {\n                recordLayoutEffectDuration(finishedWork);\n              }\n            } else {\n              commitHookEffectListMount(Layout | HasEffect, finishedWork);\n            }\n          }\n\n          break;\n        }\n\n      case ClassComponent:\n        {\n          var instance = finishedWork.stateNode;\n\n          if (finishedWork.flags & Update) {\n            if (!offscreenSubtreeWasHidden) {\n              if (current === null) {\n                // We could update instance props and state here,\n                // but instead we rely on them being set during last render.\n                // TODO: revisit this when we implement resuming.\n                {\n                  if (finishedWork.type === finishedWork.elementType && !didWarnAboutReassigningProps) {\n                    if (instance.props !== finishedWork.memoizedProps) {\n                      error('Expected %s props to match memoized props before ' + 'componentDidMount. ' + 'This might either be because of a bug in React, or because ' + 'a component reassigns its own `this.props`. ' + 'Please file an issue.', getComponentNameFromFiber(finishedWork) || 'instance');\n                    }\n\n                    if (instance.state !== finishedWork.memoizedState) {\n                      error('Expected %s state to match memoized state before ' + 'componentDidMount. ' + 'This might either be because of a bug in React, or because ' + 'a component reassigns its own `this.state`. ' + 'Please file an issue.', getComponentNameFromFiber(finishedWork) || 'instance');\n                    }\n                  }\n                }\n\n                if ( finishedWork.mode & ProfileMode) {\n                  try {\n                    startLayoutEffectTimer();\n                    instance.componentDidMount();\n                  } finally {\n                    recordLayoutEffectDuration(finishedWork);\n                  }\n                } else {\n                  instance.componentDidMount();\n                }\n              } else {\n                var prevProps = finishedWork.elementType === finishedWork.type ? current.memoizedProps : resolveDefaultProps(finishedWork.type, current.memoizedProps);\n                var prevState = current.memoizedState; // We could update instance props and state here,\n                // but instead we rely on them being set during last render.\n                // TODO: revisit this when we implement resuming.\n\n                {\n                  if (finishedWork.type === finishedWork.elementType && !didWarnAboutReassigningProps) {\n                    if (instance.props !== finishedWork.memoizedProps) {\n                      error('Expected %s props to match memoized props before ' + 'componentDidUpdate. ' + 'This might either be because of a bug in React, or because ' + 'a component reassigns its own `this.props`. ' + 'Please file an issue.', getComponentNameFromFiber(finishedWork) || 'instance');\n                    }\n\n                    if (instance.state !== finishedWork.memoizedState) {\n                      error('Expected %s state to match memoized state before ' + 'componentDidUpdate. ' + 'This might either be because of a bug in React, or because ' + 'a component reassigns its own `this.state`. ' + 'Please file an issue.', getComponentNameFromFiber(finishedWork) || 'instance');\n                    }\n                  }\n                }\n\n                if ( finishedWork.mode & ProfileMode) {\n                  try {\n                    startLayoutEffectTimer();\n                    instance.componentDidUpdate(prevProps, prevState, instance.__reactInternalSnapshotBeforeUpdate);\n                  } finally {\n                    recordLayoutEffectDuration(finishedWork);\n                  }\n                } else {\n                  instance.componentDidUpdate(prevProps, prevState, instance.__reactInternalSnapshotBeforeUpdate);\n                }\n              }\n            }\n          } // TODO: I think this is now always non-null by the time it reaches the\n          // commit phase. Consider removing the type check.\n\n\n          var updateQueue = finishedWork.updateQueue;\n\n          if (updateQueue !== null) {\n            {\n              if (finishedWork.type === finishedWork.elementType && !didWarnAboutReassigningProps) {\n                if (instance.props !== finishedWork.memoizedProps) {\n                  error('Expected %s props to match memoized props before ' + 'processing the update queue. ' + 'This might either be because of a bug in React, or because ' + 'a component reassigns its own `this.props`. ' + 'Please file an issue.', getComponentNameFromFiber(finishedWork) || 'instance');\n                }\n\n                if (instance.state !== finishedWork.memoizedState) {\n                  error('Expected %s state to match memoized state before ' + 'processing the update queue. ' + 'This might either be because of a bug in React, or because ' + 'a component reassigns its own `this.state`. ' + 'Please file an issue.', getComponentNameFromFiber(finishedWork) || 'instance');\n                }\n              }\n            } // We could update instance props and state here,\n            // but instead we rely on them being set during last render.\n            // TODO: revisit this when we implement resuming.\n\n\n            commitUpdateQueue(finishedWork, updateQueue, instance);\n          }\n\n          break;\n        }\n\n      case HostRoot:\n        {\n          // TODO: I think this is now always non-null by the time it reaches the\n          // commit phase. Consider removing the type check.\n          var _updateQueue = finishedWork.updateQueue;\n\n          if (_updateQueue !== null) {\n            var _instance = null;\n\n            if (finishedWork.child !== null) {\n              switch (finishedWork.child.tag) {\n                case HostComponent:\n                  _instance = getPublicInstance(finishedWork.child.stateNode);\n                  break;\n\n                case ClassComponent:\n                  _instance = finishedWork.child.stateNode;\n                  break;\n              }\n            }\n\n            commitUpdateQueue(finishedWork, _updateQueue, _instance);\n          }\n\n          break;\n        }\n\n      case HostComponent:\n        {\n          var _instance2 = finishedWork.stateNode; // Renderers may schedule work to be done after host components are mounted\n          // (eg DOM renderer may schedule auto-focus for inputs and form controls).\n          // These effects should only be committed when components are first mounted,\n          // aka when there is no current/alternate.\n\n          if (current === null && finishedWork.flags & Update) {\n            var type = finishedWork.type;\n            var props = finishedWork.memoizedProps;\n            commitMount(_instance2, type, props);\n          }\n\n          break;\n        }\n\n      case HostText:\n        {\n          // We have no life-cycles associated with text.\n          break;\n        }\n\n      case HostPortal:\n        {\n          // We have no life-cycles associated with portals.\n          break;\n        }\n\n      case Profiler:\n        {\n          {\n            var _finishedWork$memoize2 = finishedWork.memoizedProps,\n                onCommit = _finishedWork$memoize2.onCommit,\n                onRender = _finishedWork$memoize2.onRender;\n            var effectDuration = finishedWork.stateNode.effectDuration;\n            var commitTime = getCommitTime();\n            var phase = current === null ? 'mount' : 'update';\n\n            {\n              if (isCurrentUpdateNested()) {\n                phase = 'nested-update';\n              }\n            }\n\n            if (typeof onRender === 'function') {\n              onRender(finishedWork.memoizedProps.id, phase, finishedWork.actualDuration, finishedWork.treeBaseDuration, finishedWork.actualStartTime, commitTime);\n            }\n\n            {\n              if (typeof onCommit === 'function') {\n                onCommit(finishedWork.memoizedProps.id, phase, effectDuration, commitTime);\n              } // Schedule a passive effect for this Profiler to call onPostCommit hooks.\n              // This effect should be scheduled even if there is no onPostCommit callback for this Profiler,\n              // because the effect is also where times bubble to parent Profilers.\n\n\n              enqueuePendingPassiveProfilerEffect(finishedWork); // Propagate layout effect durations to the next nearest Profiler ancestor.\n              // Do not reset these values until the next render so DevTools has a chance to read them first.\n\n              var parentFiber = finishedWork.return;\n\n              outer: while (parentFiber !== null) {\n                switch (parentFiber.tag) {\n                  case HostRoot:\n                    var root = parentFiber.stateNode;\n                    root.effectDuration += effectDuration;\n                    break outer;\n\n                  case Profiler:\n                    var parentStateNode = parentFiber.stateNode;\n                    parentStateNode.effectDuration += effectDuration;\n                    break outer;\n                }\n\n                parentFiber = parentFiber.return;\n              }\n            }\n          }\n\n          break;\n        }\n\n      case SuspenseComponent:\n        {\n          commitSuspenseHydrationCallbacks(finishedRoot, finishedWork);\n          break;\n        }\n\n      case SuspenseListComponent:\n      case IncompleteClassComponent:\n      case ScopeComponent:\n      case OffscreenComponent:\n      case LegacyHiddenComponent:\n      case TracingMarkerComponent:\n        {\n          break;\n        }\n\n      default:\n        throw new Error('This unit of work tag should not have side-effects. This error is ' + 'likely caused by a bug in React. Please file an issue.');\n    }\n  }\n\n  if ( !offscreenSubtreeWasHidden) {\n    {\n      if (finishedWork.flags & Ref) {\n        commitAttachRef(finishedWork);\n      }\n    }\n  }\n}\n\nfunction reappearLayoutEffectsOnFiber(node) {\n  // Turn on layout effects in a tree that previously disappeared.\n  // TODO (Offscreen) Check: flags & LayoutStatic\n  switch (node.tag) {\n    case FunctionComponent:\n    case ForwardRef:\n    case SimpleMemoComponent:\n      {\n        if ( node.mode & ProfileMode) {\n          try {\n            startLayoutEffectTimer();\n            safelyCallCommitHookLayoutEffectListMount(node, node.return);\n          } finally {\n            recordLayoutEffectDuration(node);\n          }\n        } else {\n          safelyCallCommitHookLayoutEffectListMount(node, node.return);\n        }\n\n        break;\n      }\n\n    case ClassComponent:\n      {\n        var instance = node.stateNode;\n\n        if (typeof instance.componentDidMount === 'function') {\n          safelyCallComponentDidMount(node, node.return, instance);\n        }\n\n        safelyAttachRef(node, node.return);\n        break;\n      }\n\n    case HostComponent:\n      {\n        safelyAttachRef(node, node.return);\n        break;\n      }\n  }\n}\n\nfunction hideOrUnhideAllChildren(finishedWork, isHidden) {\n  // Only hide or unhide the top-most host nodes.\n  var hostSubtreeRoot = null;\n\n  {\n    // We only have the top Fiber that was inserted but we need to recurse down its\n    // children to find all the terminal nodes.\n    var node = finishedWork;\n\n    while (true) {\n      if (node.tag === HostComponent) {\n        if (hostSubtreeRoot === null) {\n          hostSubtreeRoot = node;\n\n          try {\n            var instance = node.stateNode;\n\n            if (isHidden) {\n              hideInstance(instance);\n            } else {\n              unhideInstance(node.stateNode, node.memoizedProps);\n            }\n          } catch (error) {\n            captureCommitPhaseError(finishedWork, finishedWork.return, error);\n          }\n        }\n      } else if (node.tag === HostText) {\n        if (hostSubtreeRoot === null) {\n          try {\n            var _instance3 = node.stateNode;\n\n            if (isHidden) {\n              hideTextInstance(_instance3);\n            } else {\n              unhideTextInstance(_instance3, node.memoizedProps);\n            }\n          } catch (error) {\n            captureCommitPhaseError(finishedWork, finishedWork.return, error);\n          }\n        }\n      } else if ((node.tag === OffscreenComponent || node.tag === LegacyHiddenComponent) && node.memoizedState !== null && node !== finishedWork) ; else if (node.child !== null) {\n        node.child.return = node;\n        node = node.child;\n        continue;\n      }\n\n      if (node === finishedWork) {\n        return;\n      }\n\n      while (node.sibling === null) {\n        if (node.return === null || node.return === finishedWork) {\n          return;\n        }\n\n        if (hostSubtreeRoot === node) {\n          hostSubtreeRoot = null;\n        }\n\n        node = node.return;\n      }\n\n      if (hostSubtreeRoot === node) {\n        hostSubtreeRoot = null;\n      }\n\n      node.sibling.return = node.return;\n      node = node.sibling;\n    }\n  }\n}\n\nfunction commitAttachRef(finishedWork) {\n  var ref = finishedWork.ref;\n\n  if (ref !== null) {\n    var instance = finishedWork.stateNode;\n    var instanceToUse;\n\n    switch (finishedWork.tag) {\n      case HostComponent:\n        instanceToUse = getPublicInstance(instance);\n        break;\n\n      default:\n        instanceToUse = instance;\n    } // Moved outside to ensure DCE works with this flag\n\n    if (typeof ref === 'function') {\n      var retVal;\n\n      if ( finishedWork.mode & ProfileMode) {\n        try {\n          startLayoutEffectTimer();\n          retVal = ref(instanceToUse);\n        } finally {\n          recordLayoutEffectDuration(finishedWork);\n        }\n      } else {\n        retVal = ref(instanceToUse);\n      }\n\n      {\n        if (typeof retVal === 'function') {\n          error('Unexpected return value from a callback ref in %s. ' + 'A callback ref should not return a function.', getComponentNameFromFiber(finishedWork));\n        }\n      }\n    } else {\n      {\n        if (!ref.hasOwnProperty('current')) {\n          error('Unexpected ref object provided for %s. ' + 'Use either a ref-setter function or React.createRef().', getComponentNameFromFiber(finishedWork));\n        }\n      }\n\n      ref.current = instanceToUse;\n    }\n  }\n}\n\nfunction detachFiberMutation(fiber) {\n  // Cut off the return pointer to disconnect it from the tree.\n  // This enables us to detect and warn against state updates on an unmounted component.\n  // It also prevents events from bubbling from within disconnected components.\n  //\n  // Ideally, we should also clear the child pointer of the parent alternate to let this\n  // get GC:ed but we don't know which for sure which parent is the current\n  // one so we'll settle for GC:ing the subtree of this child.\n  // This child itself will be GC:ed when the parent updates the next time.\n  //\n  // Note that we can't clear child or sibling pointers yet.\n  // They're needed for passive effects and for findDOMNode.\n  // We defer those fields, and all other cleanup, to the passive phase (see detachFiberAfterEffects).\n  //\n  // Don't reset the alternate yet, either. We need that so we can detach the\n  // alternate's fields in the passive phase. Clearing the return pointer is\n  // sufficient for findDOMNode semantics.\n  var alternate = fiber.alternate;\n\n  if (alternate !== null) {\n    alternate.return = null;\n  }\n\n  fiber.return = null;\n}\n\nfunction detachFiberAfterEffects(fiber) {\n  var alternate = fiber.alternate;\n\n  if (alternate !== null) {\n    fiber.alternate = null;\n    detachFiberAfterEffects(alternate);\n  } // Note: Defensively using negation instead of < in case\n  // `deletedTreeCleanUpLevel` is undefined.\n\n\n  {\n    // Clear cyclical Fiber fields. This level alone is designed to roughly\n    // approximate the planned Fiber refactor. In that world, `setState` will be\n    // bound to a special \"instance\" object instead of a Fiber. The Instance\n    // object will not have any of these fields. It will only be connected to\n    // the fiber tree via a single link at the root. So if this level alone is\n    // sufficient to fix memory issues, that bodes well for our plans.\n    fiber.child = null;\n    fiber.deletions = null;\n    fiber.sibling = null; // The `stateNode` is cyclical because on host nodes it points to the host\n    // tree, which has its own pointers to children, parents, and siblings.\n    // The other host nodes also point back to fibers, so we should detach that\n    // one, too.\n\n    if (fiber.tag === HostComponent) {\n      var hostInstance = fiber.stateNode;\n\n      if (hostInstance !== null) {\n        detachDeletedInstance(hostInstance);\n      }\n    }\n\n    fiber.stateNode = null; // I'm intentionally not clearing the `return` field in this level. We\n    // already disconnect the `return` pointer at the root of the deleted\n    // subtree (in `detachFiberMutation`). Besides, `return` by itself is not\n    // cyclical  it's only cyclical when combined with `child`, `sibling`, and\n    // `alternate`. But we'll clear it in the next level anyway, just in case.\n\n    {\n      fiber._debugOwner = null;\n    }\n\n    {\n      // Theoretically, nothing in here should be necessary, because we already\n      // disconnected the fiber from the tree. So even if something leaks this\n      // particular fiber, it won't leak anything else\n      //\n      // The purpose of this branch is to be super aggressive so we can measure\n      // if there's any difference in memory impact. If there is, that could\n      // indicate a React leak we don't know about.\n      fiber.return = null;\n      fiber.dependencies = null;\n      fiber.memoizedProps = null;\n      fiber.memoizedState = null;\n      fiber.pendingProps = null;\n      fiber.stateNode = null; // TODO: Move to `commitPassiveUnmountInsideDeletedTreeOnFiber` instead.\n\n      fiber.updateQueue = null;\n    }\n  }\n}\n\nfunction getHostParentFiber(fiber) {\n  var parent = fiber.return;\n\n  while (parent !== null) {\n    if (isHostParent(parent)) {\n      return parent;\n    }\n\n    parent = parent.return;\n  }\n\n  throw new Error('Expected to find a host parent. This error is likely caused by a bug ' + 'in React. Please file an issue.');\n}\n\nfunction isHostParent(fiber) {\n  return fiber.tag === HostComponent || fiber.tag === HostRoot || fiber.tag === HostPortal;\n}\n\nfunction getHostSibling(fiber) {\n  // We're going to search forward into the tree until we find a sibling host\n  // node. Unfortunately, if multiple insertions are done in a row we have to\n  // search past them. This leads to exponential search for the next sibling.\n  // TODO: Find a more efficient way to do this.\n  var node = fiber;\n\n  siblings: while (true) {\n    // If we didn't find anything, let's try the next sibling.\n    while (node.sibling === null) {\n      if (node.return === null || isHostParent(node.return)) {\n        // If we pop out of the root or hit the parent the fiber we are the\n        // last sibling.\n        return null;\n      }\n\n      node = node.return;\n    }\n\n    node.sibling.return = node.return;\n    node = node.sibling;\n\n    while (node.tag !== HostComponent && node.tag !== HostText && node.tag !== DehydratedFragment) {\n      // If it is not host node and, we might have a host node inside it.\n      // Try to search down until we find one.\n      if (node.flags & Placement) {\n        // If we don't have a child, try the siblings instead.\n        continue siblings;\n      } // If we don't have a child, try the siblings instead.\n      // We also skip portals because they are not part of this host tree.\n\n\n      if (node.child === null || node.tag === HostPortal) {\n        continue siblings;\n      } else {\n        node.child.return = node;\n        node = node.child;\n      }\n    } // Check if this host node is stable or about to be placed.\n\n\n    if (!(node.flags & Placement)) {\n      // Found it!\n      return node.stateNode;\n    }\n  }\n}\n\nfunction commitPlacement(finishedWork) {\n\n\n  var parentFiber = getHostParentFiber(finishedWork); // Note: these two variables *must* always be updated together.\n\n  switch (parentFiber.tag) {\n    case HostComponent:\n      {\n        var parent = parentFiber.stateNode;\n\n        if (parentFiber.flags & ContentReset) {\n          // Reset the text content of the parent before doing any insertions\n          resetTextContent(parent); // Clear ContentReset from the effect tag\n\n          parentFiber.flags &= ~ContentReset;\n        }\n\n        var before = getHostSibling(finishedWork); // We only have the top Fiber that was inserted but we need to recurse down its\n        // children to find all the terminal nodes.\n\n        insertOrAppendPlacementNode(finishedWork, before, parent);\n        break;\n      }\n\n    case HostRoot:\n    case HostPortal:\n      {\n        var _parent = parentFiber.stateNode.containerInfo;\n\n        var _before = getHostSibling(finishedWork);\n\n        insertOrAppendPlacementNodeIntoContainer(finishedWork, _before, _parent);\n        break;\n      }\n    // eslint-disable-next-line-no-fallthrough\n\n    default:\n      throw new Error('Invalid host parent fiber. This error is likely caused by a bug ' + 'in React. Please file an issue.');\n  }\n}\n\nfunction insertOrAppendPlacementNodeIntoContainer(node, before, parent) {\n  var tag = node.tag;\n  var isHost = tag === HostComponent || tag === HostText;\n\n  if (isHost) {\n    var stateNode = node.stateNode;\n\n    if (before) {\n      insertInContainerBefore(parent, stateNode, before);\n    } else {\n      appendChildToContainer(parent, stateNode);\n    }\n  } else if (tag === HostPortal) ; else {\n    var child = node.child;\n\n    if (child !== null) {\n      insertOrAppendPlacementNodeIntoContainer(child, before, parent);\n      var sibling = child.sibling;\n\n      while (sibling !== null) {\n        insertOrAppendPlacementNodeIntoContainer(sibling, before, parent);\n        sibling = sibling.sibling;\n      }\n    }\n  }\n}\n\nfunction insertOrAppendPlacementNode(node, before, parent) {\n  var tag = node.tag;\n  var isHost = tag === HostComponent || tag === HostText;\n\n  if (isHost) {\n    var stateNode = node.stateNode;\n\n    if (before) {\n      insertBefore(parent, stateNode, before);\n    } else {\n      appendChild(parent, stateNode);\n    }\n  } else if (tag === HostPortal) ; else {\n    var child = node.child;\n\n    if (child !== null) {\n      insertOrAppendPlacementNode(child, before, parent);\n      var sibling = child.sibling;\n\n      while (sibling !== null) {\n        insertOrAppendPlacementNode(sibling, before, parent);\n        sibling = sibling.sibling;\n      }\n    }\n  }\n} // These are tracked on the stack as we recursively traverse a\n// deleted subtree.\n// TODO: Update these during the whole mutation phase, not just during\n// a deletion.\n\n\nvar hostParent = null;\nvar hostParentIsContainer = false;\n\nfunction commitDeletionEffects(root, returnFiber, deletedFiber) {\n  {\n    // We only have the top Fiber that was deleted but we need to recurse down its\n    // children to find all the terminal nodes.\n    // Recursively delete all host nodes from the parent, detach refs, clean\n    // up mounted layout effects, and call componentWillUnmount.\n    // We only need to remove the topmost host child in each branch. But then we\n    // still need to keep traversing to unmount effects, refs, and cWU. TODO: We\n    // could split this into two separate traversals functions, where the second\n    // one doesn't include any removeChild logic. This is maybe the same\n    // function as \"disappearLayoutEffects\" (or whatever that turns into after\n    // the layout phase is refactored to use recursion).\n    // Before starting, find the nearest host parent on the stack so we know\n    // which instance/container to remove the children from.\n    // TODO: Instead of searching up the fiber return path on every deletion, we\n    // can track the nearest host component on the JS stack as we traverse the\n    // tree during the commit phase. This would make insertions faster, too.\n    var parent = returnFiber;\n\n    findParent: while (parent !== null) {\n      switch (parent.tag) {\n        case HostComponent:\n          {\n            hostParent = parent.stateNode;\n            hostParentIsContainer = false;\n            break findParent;\n          }\n\n        case HostRoot:\n          {\n            hostParent = parent.stateNode.containerInfo;\n            hostParentIsContainer = true;\n            break findParent;\n          }\n\n        case HostPortal:\n          {\n            hostParent = parent.stateNode.containerInfo;\n            hostParentIsContainer = true;\n            break findParent;\n          }\n      }\n\n      parent = parent.return;\n    }\n\n    if (hostParent === null) {\n      throw new Error('Expected to find a host parent. This error is likely caused by ' + 'a bug in React. Please file an issue.');\n    }\n\n    commitDeletionEffectsOnFiber(root, returnFiber, deletedFiber);\n    hostParent = null;\n    hostParentIsContainer = false;\n  }\n\n  detachFiberMutation(deletedFiber);\n}\n\nfunction recursivelyTraverseDeletionEffects(finishedRoot, nearestMountedAncestor, parent) {\n  // TODO: Use a static flag to skip trees that don't have unmount effects\n  var child = parent.child;\n\n  while (child !== null) {\n    commitDeletionEffectsOnFiber(finishedRoot, nearestMountedAncestor, child);\n    child = child.sibling;\n  }\n}\n\nfunction commitDeletionEffectsOnFiber(finishedRoot, nearestMountedAncestor, deletedFiber) {\n  onCommitUnmount(deletedFiber); // The cases in this outer switch modify the stack before they traverse\n  // into their subtree. There are simpler cases in the inner switch\n  // that don't modify the stack.\n\n  switch (deletedFiber.tag) {\n    case HostComponent:\n      {\n        if (!offscreenSubtreeWasHidden) {\n          safelyDetachRef(deletedFiber, nearestMountedAncestor);\n        } // Intentional fallthrough to next branch\n\n      }\n    // eslint-disable-next-line-no-fallthrough\n\n    case HostText:\n      {\n        // We only need to remove the nearest host child. Set the host parent\n        // to `null` on the stack to indicate that nested children don't\n        // need to be removed.\n        {\n          var prevHostParent = hostParent;\n          var prevHostParentIsContainer = hostParentIsContainer;\n          hostParent = null;\n          recursivelyTraverseDeletionEffects(finishedRoot, nearestMountedAncestor, deletedFiber);\n          hostParent = prevHostParent;\n          hostParentIsContainer = prevHostParentIsContainer;\n\n          if (hostParent !== null) {\n            // Now that all the child effects have unmounted, we can remove the\n            // node from the tree.\n            if (hostParentIsContainer) {\n              removeChildFromContainer(hostParent, deletedFiber.stateNode);\n            } else {\n              removeChild(hostParent, deletedFiber.stateNode);\n            }\n          }\n        }\n\n        return;\n      }\n\n    case DehydratedFragment:\n      {\n        // Delete the dehydrated suspense boundary and all of its content.\n\n\n        {\n          if (hostParent !== null) {\n            if (hostParentIsContainer) {\n              clearSuspenseBoundaryFromContainer(hostParent, deletedFiber.stateNode);\n            } else {\n              clearSuspenseBoundary(hostParent, deletedFiber.stateNode);\n            }\n          }\n        }\n\n        return;\n      }\n\n    case HostPortal:\n      {\n        {\n          // When we go into a portal, it becomes the parent to remove from.\n          var _prevHostParent = hostParent;\n          var _prevHostParentIsContainer = hostParentIsContainer;\n          hostParent = deletedFiber.stateNode.containerInfo;\n          hostParentIsContainer = true;\n          recursivelyTraverseDeletionEffects(finishedRoot, nearestMountedAncestor, deletedFiber);\n          hostParent = _prevHostParent;\n          hostParentIsContainer = _prevHostParentIsContainer;\n        }\n\n        return;\n      }\n\n    case FunctionComponent:\n    case ForwardRef:\n    case MemoComponent:\n    case SimpleMemoComponent:\n      {\n        if (!offscreenSubtreeWasHidden) {\n          var updateQueue = deletedFiber.updateQueue;\n\n          if (updateQueue !== null) {\n            var lastEffect = updateQueue.lastEffect;\n\n            if (lastEffect !== null) {\n              var firstEffect = lastEffect.next;\n              var effect = firstEffect;\n\n              do {\n                var _effect = effect,\n                    destroy = _effect.destroy,\n                    tag = _effect.tag;\n\n                if (destroy !== undefined) {\n                  if ((tag & Insertion) !== NoFlags$1) {\n                    safelyCallDestroy(deletedFiber, nearestMountedAncestor, destroy);\n                  } else if ((tag & Layout) !== NoFlags$1) {\n                    {\n                      markComponentLayoutEffectUnmountStarted(deletedFiber);\n                    }\n\n                    if ( deletedFiber.mode & ProfileMode) {\n                      startLayoutEffectTimer();\n                      safelyCallDestroy(deletedFiber, nearestMountedAncestor, destroy);\n                      recordLayoutEffectDuration(deletedFiber);\n                    } else {\n                      safelyCallDestroy(deletedFiber, nearestMountedAncestor, destroy);\n                    }\n\n                    {\n                      markComponentLayoutEffectUnmountStopped();\n                    }\n                  }\n                }\n\n                effect = effect.next;\n              } while (effect !== firstEffect);\n            }\n          }\n        }\n\n        recursivelyTraverseDeletionEffects(finishedRoot, nearestMountedAncestor, deletedFiber);\n        return;\n      }\n\n    case ClassComponent:\n      {\n        if (!offscreenSubtreeWasHidden) {\n          safelyDetachRef(deletedFiber, nearestMountedAncestor);\n          var instance = deletedFiber.stateNode;\n\n          if (typeof instance.componentWillUnmount === 'function') {\n            safelyCallComponentWillUnmount(deletedFiber, nearestMountedAncestor, instance);\n          }\n        }\n\n        recursivelyTraverseDeletionEffects(finishedRoot, nearestMountedAncestor, deletedFiber);\n        return;\n      }\n\n    case ScopeComponent:\n      {\n\n        recursivelyTraverseDeletionEffects(finishedRoot, nearestMountedAncestor, deletedFiber);\n        return;\n      }\n\n    case OffscreenComponent:\n      {\n        if ( // TODO: Remove this dead flag\n         deletedFiber.mode & ConcurrentMode) {\n          // If this offscreen component is hidden, we already unmounted it. Before\n          // deleting the children, track that it's already unmounted so that we\n          // don't attempt to unmount the effects again.\n          // TODO: If the tree is hidden, in most cases we should be able to skip\n          // over the nested children entirely. An exception is we haven't yet found\n          // the topmost host node to delete, which we already track on the stack.\n          // But the other case is portals, which need to be detached no matter how\n          // deeply they are nested. We should use a subtree flag to track whether a\n          // subtree includes a nested portal.\n          var prevOffscreenSubtreeWasHidden = offscreenSubtreeWasHidden;\n          offscreenSubtreeWasHidden = prevOffscreenSubtreeWasHidden || deletedFiber.memoizedState !== null;\n          recursivelyTraverseDeletionEffects(finishedRoot, nearestMountedAncestor, deletedFiber);\n          offscreenSubtreeWasHidden = prevOffscreenSubtreeWasHidden;\n        } else {\n          recursivelyTraverseDeletionEffects(finishedRoot, nearestMountedAncestor, deletedFiber);\n        }\n\n        break;\n      }\n\n    default:\n      {\n        recursivelyTraverseDeletionEffects(finishedRoot, nearestMountedAncestor, deletedFiber);\n        return;\n      }\n  }\n}\n\nfunction commitSuspenseCallback(finishedWork) {\n  // TODO: Move this to passive phase\n  var newState = finishedWork.memoizedState;\n}\n\nfunction commitSuspenseHydrationCallbacks(finishedRoot, finishedWork) {\n\n  var newState = finishedWork.memoizedState;\n\n  if (newState === null) {\n    var current = finishedWork.alternate;\n\n    if (current !== null) {\n      var prevState = current.memoizedState;\n\n      if (prevState !== null) {\n        var suspenseInstance = prevState.dehydrated;\n\n        if (suspenseInstance !== null) {\n          commitHydratedSuspenseInstance(suspenseInstance);\n        }\n      }\n    }\n  }\n}\n\nfunction attachSuspenseRetryListeners(finishedWork) {\n  // If this boundary just timed out, then it will have a set of wakeables.\n  // For each wakeable, attach a listener so that when it resolves, React\n  // attempts to re-render the boundary in the primary (pre-timeout) state.\n  var wakeables = finishedWork.updateQueue;\n\n  if (wakeables !== null) {\n    finishedWork.updateQueue = null;\n    var retryCache = finishedWork.stateNode;\n\n    if (retryCache === null) {\n      retryCache = finishedWork.stateNode = new PossiblyWeakSet();\n    }\n\n    wakeables.forEach(function (wakeable) {\n      // Memoize using the boundary fiber to prevent redundant listeners.\n      var retry = resolveRetryWakeable.bind(null, finishedWork, wakeable);\n\n      if (!retryCache.has(wakeable)) {\n        retryCache.add(wakeable);\n\n        {\n          if (isDevToolsPresent) {\n            if (inProgressLanes !== null && inProgressRoot !== null) {\n              // If we have pending work still, associate the original updaters with it.\n              restorePendingUpdaters(inProgressRoot, inProgressLanes);\n            } else {\n              throw Error('Expected finished root and lanes to be set. This is a bug in React.');\n            }\n          }\n        }\n\n        wakeable.then(retry, retry);\n      }\n    });\n  }\n} // This function detects when a Suspense boundary goes from visible to hidden.\nfunction commitMutationEffects(root, finishedWork, committedLanes) {\n  inProgressLanes = committedLanes;\n  inProgressRoot = root;\n  setCurrentFiber(finishedWork);\n  commitMutationEffectsOnFiber(finishedWork, root);\n  setCurrentFiber(finishedWork);\n  inProgressLanes = null;\n  inProgressRoot = null;\n}\n\nfunction recursivelyTraverseMutationEffects(root, parentFiber, lanes) {\n  // Deletions effects can be scheduled on any fiber type. They need to happen\n  // before the children effects hae fired.\n  var deletions = parentFiber.deletions;\n\n  if (deletions !== null) {\n    for (var i = 0; i < deletions.length; i++) {\n      var childToDelete = deletions[i];\n\n      try {\n        commitDeletionEffects(root, parentFiber, childToDelete);\n      } catch (error) {\n        captureCommitPhaseError(childToDelete, parentFiber, error);\n      }\n    }\n  }\n\n  var prevDebugFiber = getCurrentFiber();\n\n  if (parentFiber.subtreeFlags & MutationMask) {\n    var child = parentFiber.child;\n\n    while (child !== null) {\n      setCurrentFiber(child);\n      commitMutationEffectsOnFiber(child, root);\n      child = child.sibling;\n    }\n  }\n\n  setCurrentFiber(prevDebugFiber);\n}\n\nfunction commitMutationEffectsOnFiber(finishedWork, root, lanes) {\n  var current = finishedWork.alternate;\n  var flags = finishedWork.flags; // The effect flag should be checked *after* we refine the type of fiber,\n  // because the fiber tag is more specific. An exception is any flag related\n  // to reconcilation, because those can be set on all fiber types.\n\n  switch (finishedWork.tag) {\n    case FunctionComponent:\n    case ForwardRef:\n    case MemoComponent:\n    case SimpleMemoComponent:\n      {\n        recursivelyTraverseMutationEffects(root, finishedWork);\n        commitReconciliationEffects(finishedWork);\n\n        if (flags & Update) {\n          try {\n            commitHookEffectListUnmount(Insertion | HasEffect, finishedWork, finishedWork.return);\n            commitHookEffectListMount(Insertion | HasEffect, finishedWork);\n          } catch (error) {\n            captureCommitPhaseError(finishedWork, finishedWork.return, error);\n          } // Layout effects are destroyed during the mutation phase so that all\n          // destroy functions for all fibers are called before any create functions.\n          // This prevents sibling component effects from interfering with each other,\n          // e.g. a destroy function in one component should never override a ref set\n          // by a create function in another component during the same commit.\n\n\n          if ( finishedWork.mode & ProfileMode) {\n            try {\n              startLayoutEffectTimer();\n              commitHookEffectListUnmount(Layout | HasEffect, finishedWork, finishedWork.return);\n            } catch (error) {\n              captureCommitPhaseError(finishedWork, finishedWork.return, error);\n            }\n\n            recordLayoutEffectDuration(finishedWork);\n          } else {\n            try {\n              commitHookEffectListUnmount(Layout | HasEffect, finishedWork, finishedWork.return);\n            } catch (error) {\n              captureCommitPhaseError(finishedWork, finishedWork.return, error);\n            }\n          }\n        }\n\n        return;\n      }\n\n    case ClassComponent:\n      {\n        recursivelyTraverseMutationEffects(root, finishedWork);\n        commitReconciliationEffects(finishedWork);\n\n        if (flags & Ref) {\n          if (current !== null) {\n            safelyDetachRef(current, current.return);\n          }\n        }\n\n        return;\n      }\n\n    case HostComponent:\n      {\n        recursivelyTraverseMutationEffects(root, finishedWork);\n        commitReconciliationEffects(finishedWork);\n\n        if (flags & Ref) {\n          if (current !== null) {\n            safelyDetachRef(current, current.return);\n          }\n        }\n\n        {\n          // TODO: ContentReset gets cleared by the children during the commit\n          // phase. This is a refactor hazard because it means we must read\n          // flags the flags after `commitReconciliationEffects` has already run;\n          // the order matters. We should refactor so that ContentReset does not\n          // rely on mutating the flag during commit. Like by setting a flag\n          // during the render phase instead.\n          if (finishedWork.flags & ContentReset) {\n            var instance = finishedWork.stateNode;\n\n            try {\n              resetTextContent(instance);\n            } catch (error) {\n              captureCommitPhaseError(finishedWork, finishedWork.return, error);\n            }\n          }\n\n          if (flags & Update) {\n            var _instance4 = finishedWork.stateNode;\n\n            if (_instance4 != null) {\n              // Commit the work prepared earlier.\n              var newProps = finishedWork.memoizedProps; // For hydration we reuse the update path but we treat the oldProps\n              // as the newProps. The updatePayload will contain the real change in\n              // this case.\n\n              var oldProps = current !== null ? current.memoizedProps : newProps;\n              var type = finishedWork.type; // TODO: Type the updateQueue to be specific to host components.\n\n              var updatePayload = finishedWork.updateQueue;\n              finishedWork.updateQueue = null;\n\n              if (updatePayload !== null) {\n                try {\n                  commitUpdate(_instance4, updatePayload, type, oldProps, newProps, finishedWork);\n                } catch (error) {\n                  captureCommitPhaseError(finishedWork, finishedWork.return, error);\n                }\n              }\n            }\n          }\n        }\n\n        return;\n      }\n\n    case HostText:\n      {\n        recursivelyTraverseMutationEffects(root, finishedWork);\n        commitReconciliationEffects(finishedWork);\n\n        if (flags & Update) {\n          {\n            if (finishedWork.stateNode === null) {\n              throw new Error('This should have a text node initialized. This error is likely ' + 'caused by a bug in React. Please file an issue.');\n            }\n\n            var textInstance = finishedWork.stateNode;\n            var newText = finishedWork.memoizedProps; // For hydration we reuse the update path but we treat the oldProps\n            // as the newProps. The updatePayload will contain the real change in\n            // this case.\n\n            var oldText = current !== null ? current.memoizedProps : newText;\n\n            try {\n              commitTextUpdate(textInstance, oldText, newText);\n            } catch (error) {\n              captureCommitPhaseError(finishedWork, finishedWork.return, error);\n            }\n          }\n        }\n\n        return;\n      }\n\n    case HostRoot:\n      {\n        recursivelyTraverseMutationEffects(root, finishedWork);\n        commitReconciliationEffects(finishedWork);\n\n        if (flags & Update) {\n          {\n            if (current !== null) {\n              var prevRootState = current.memoizedState;\n\n              if (prevRootState.isDehydrated) {\n                try {\n                  commitHydratedContainer(root.containerInfo);\n                } catch (error) {\n                  captureCommitPhaseError(finishedWork, finishedWork.return, error);\n                }\n              }\n            }\n          }\n        }\n\n        return;\n      }\n\n    case HostPortal:\n      {\n        recursivelyTraverseMutationEffects(root, finishedWork);\n        commitReconciliationEffects(finishedWork);\n\n        return;\n      }\n\n    case SuspenseComponent:\n      {\n        recursivelyTraverseMutationEffects(root, finishedWork);\n        commitReconciliationEffects(finishedWork);\n        var offscreenFiber = finishedWork.child;\n\n        if (offscreenFiber.flags & Visibility) {\n          var offscreenInstance = offscreenFiber.stateNode;\n          var newState = offscreenFiber.memoizedState;\n          var isHidden = newState !== null; // Track the current state on the Offscreen instance so we can\n          // read it during an event\n\n          offscreenInstance.isHidden = isHidden;\n\n          if (isHidden) {\n            var wasHidden = offscreenFiber.alternate !== null && offscreenFiber.alternate.memoizedState !== null;\n\n            if (!wasHidden) {\n              // TODO: Move to passive phase\n              markCommitTimeOfFallback();\n            }\n          }\n        }\n\n        if (flags & Update) {\n          try {\n            commitSuspenseCallback(finishedWork);\n          } catch (error) {\n            captureCommitPhaseError(finishedWork, finishedWork.return, error);\n          }\n\n          attachSuspenseRetryListeners(finishedWork);\n        }\n\n        return;\n      }\n\n    case OffscreenComponent:\n      {\n        var _wasHidden = current !== null && current.memoizedState !== null;\n\n        if ( // TODO: Remove this dead flag\n         finishedWork.mode & ConcurrentMode) {\n          // Before committing the children, track on the stack whether this\n          // offscreen subtree was already hidden, so that we don't unmount the\n          // effects again.\n          var prevOffscreenSubtreeWasHidden = offscreenSubtreeWasHidden;\n          offscreenSubtreeWasHidden = prevOffscreenSubtreeWasHidden || _wasHidden;\n          recursivelyTraverseMutationEffects(root, finishedWork);\n          offscreenSubtreeWasHidden = prevOffscreenSubtreeWasHidden;\n        } else {\n          recursivelyTraverseMutationEffects(root, finishedWork);\n        }\n\n        commitReconciliationEffects(finishedWork);\n\n        if (flags & Visibility) {\n          var _offscreenInstance = finishedWork.stateNode;\n          var _newState = finishedWork.memoizedState;\n\n          var _isHidden = _newState !== null;\n\n          var offscreenBoundary = finishedWork; // Track the current state on the Offscreen instance so we can\n          // read it during an event\n\n          _offscreenInstance.isHidden = _isHidden;\n\n          {\n            if (_isHidden) {\n              if (!_wasHidden) {\n                if ((offscreenBoundary.mode & ConcurrentMode) !== NoMode) {\n                  nextEffect = offscreenBoundary;\n                  var offscreenChild = offscreenBoundary.child;\n\n                  while (offscreenChild !== null) {\n                    nextEffect = offscreenChild;\n                    disappearLayoutEffects_begin(offscreenChild);\n                    offscreenChild = offscreenChild.sibling;\n                  }\n                }\n              }\n            }\n          }\n\n          {\n            // TODO: This needs to run whenever there's an insertion or update\n            // inside a hidden Offscreen tree.\n            hideOrUnhideAllChildren(offscreenBoundary, _isHidden);\n          }\n        }\n\n        return;\n      }\n\n    case SuspenseListComponent:\n      {\n        recursivelyTraverseMutationEffects(root, finishedWork);\n        commitReconciliationEffects(finishedWork);\n\n        if (flags & Update) {\n          attachSuspenseRetryListeners(finishedWork);\n        }\n\n        return;\n      }\n\n    case ScopeComponent:\n      {\n\n        return;\n      }\n\n    default:\n      {\n        recursivelyTraverseMutationEffects(root, finishedWork);\n        commitReconciliationEffects(finishedWork);\n        return;\n      }\n  }\n}\n\nfunction commitReconciliationEffects(finishedWork) {\n  // Placement effects (insertions, reorders) can be scheduled on any fiber\n  // type. They needs to happen after the children effects have fired, but\n  // before the effects on this fiber have fired.\n  var flags = finishedWork.flags;\n\n  if (flags & Placement) {\n    try {\n      commitPlacement(finishedWork);\n    } catch (error) {\n      captureCommitPhaseError(finishedWork, finishedWork.return, error);\n    } // Clear the \"placement\" from effect tag so that we know that this is\n    // inserted, before any life-cycles like componentDidMount gets called.\n    // TODO: findDOMNode doesn't rely on this any more but isMounted does\n    // and isMounted is deprecated anyway so we should be able to kill this.\n\n\n    finishedWork.flags &= ~Placement;\n  }\n\n  if (flags & Hydrating) {\n    finishedWork.flags &= ~Hydrating;\n  }\n}\n\nfunction commitLayoutEffects(finishedWork, root, committedLanes) {\n  inProgressLanes = committedLanes;\n  inProgressRoot = root;\n  nextEffect = finishedWork;\n  commitLayoutEffects_begin(finishedWork, root, committedLanes);\n  inProgressLanes = null;\n  inProgressRoot = null;\n}\n\nfunction commitLayoutEffects_begin(subtreeRoot, root, committedLanes) {\n  // Suspense layout effects semantics don't change for legacy roots.\n  var isModernRoot = (subtreeRoot.mode & ConcurrentMode) !== NoMode;\n\n  while (nextEffect !== null) {\n    var fiber = nextEffect;\n    var firstChild = fiber.child;\n\n    if ( fiber.tag === OffscreenComponent && isModernRoot) {\n      // Keep track of the current Offscreen stack's state.\n      var isHidden = fiber.memoizedState !== null;\n      var newOffscreenSubtreeIsHidden = isHidden || offscreenSubtreeIsHidden;\n\n      if (newOffscreenSubtreeIsHidden) {\n        // The Offscreen tree is hidden. Skip over its layout effects.\n        commitLayoutMountEffects_complete(subtreeRoot, root, committedLanes);\n        continue;\n      } else {\n        // TODO (Offscreen) Also check: subtreeFlags & LayoutMask\n        var current = fiber.alternate;\n        var wasHidden = current !== null && current.memoizedState !== null;\n        var newOffscreenSubtreeWasHidden = wasHidden || offscreenSubtreeWasHidden;\n        var prevOffscreenSubtreeIsHidden = offscreenSubtreeIsHidden;\n        var prevOffscreenSubtreeWasHidden = offscreenSubtreeWasHidden; // Traverse the Offscreen subtree with the current Offscreen as the root.\n\n        offscreenSubtreeIsHidden = newOffscreenSubtreeIsHidden;\n        offscreenSubtreeWasHidden = newOffscreenSubtreeWasHidden;\n\n        if (offscreenSubtreeWasHidden && !prevOffscreenSubtreeWasHidden) {\n          // This is the root of a reappearing boundary. Turn its layout effects\n          // back on.\n          nextEffect = fiber;\n          reappearLayoutEffects_begin(fiber);\n        }\n\n        var child = firstChild;\n\n        while (child !== null) {\n          nextEffect = child;\n          commitLayoutEffects_begin(child, // New root; bubble back up to here and stop.\n          root, committedLanes);\n          child = child.sibling;\n        } // Restore Offscreen state and resume in our-progress traversal.\n\n\n        nextEffect = fiber;\n        offscreenSubtreeIsHidden = prevOffscreenSubtreeIsHidden;\n        offscreenSubtreeWasHidden = prevOffscreenSubtreeWasHidden;\n        commitLayoutMountEffects_complete(subtreeRoot, root, committedLanes);\n        continue;\n      }\n    }\n\n    if ((fiber.subtreeFlags & LayoutMask) !== NoFlags && firstChild !== null) {\n      firstChild.return = fiber;\n      nextEffect = firstChild;\n    } else {\n      commitLayoutMountEffects_complete(subtreeRoot, root, committedLanes);\n    }\n  }\n}\n\nfunction commitLayoutMountEffects_complete(subtreeRoot, root, committedLanes) {\n  while (nextEffect !== null) {\n    var fiber = nextEffect;\n\n    if ((fiber.flags & LayoutMask) !== NoFlags) {\n      var current = fiber.alternate;\n      setCurrentFiber(fiber);\n\n      try {\n        commitLayoutEffectOnFiber(root, current, fiber, committedLanes);\n      } catch (error) {\n        captureCommitPhaseError(fiber, fiber.return, error);\n      }\n\n      resetCurrentFiber();\n    }\n\n    if (fiber === subtreeRoot) {\n      nextEffect = null;\n      return;\n    }\n\n    var sibling = fiber.sibling;\n\n    if (sibling !== null) {\n      sibling.return = fiber.return;\n      nextEffect = sibling;\n      return;\n    }\n\n    nextEffect = fiber.return;\n  }\n}\n\nfunction disappearLayoutEffects_begin(subtreeRoot) {\n  while (nextEffect !== null) {\n    var fiber = nextEffect;\n    var firstChild = fiber.child; // TODO (Offscreen) Check: flags & (RefStatic | LayoutStatic)\n\n    switch (fiber.tag) {\n      case FunctionComponent:\n      case ForwardRef:\n      case MemoComponent:\n      case SimpleMemoComponent:\n        {\n          if ( fiber.mode & ProfileMode) {\n            try {\n              startLayoutEffectTimer();\n              commitHookEffectListUnmount(Layout, fiber, fiber.return);\n            } finally {\n              recordLayoutEffectDuration(fiber);\n            }\n          } else {\n            commitHookEffectListUnmount(Layout, fiber, fiber.return);\n          }\n\n          break;\n        }\n\n      case ClassComponent:\n        {\n          // TODO (Offscreen) Check: flags & RefStatic\n          safelyDetachRef(fiber, fiber.return);\n          var instance = fiber.stateNode;\n\n          if (typeof instance.componentWillUnmount === 'function') {\n            safelyCallComponentWillUnmount(fiber, fiber.return, instance);\n          }\n\n          break;\n        }\n\n      case HostComponent:\n        {\n          safelyDetachRef(fiber, fiber.return);\n          break;\n        }\n\n      case OffscreenComponent:\n        {\n          // Check if this is a\n          var isHidden = fiber.memoizedState !== null;\n\n          if (isHidden) {\n            // Nested Offscreen tree is already hidden. Don't disappear\n            // its effects.\n            disappearLayoutEffects_complete(subtreeRoot);\n            continue;\n          }\n\n          break;\n        }\n    } // TODO (Offscreen) Check: subtreeFlags & LayoutStatic\n\n\n    if (firstChild !== null) {\n      firstChild.return = fiber;\n      nextEffect = firstChild;\n    } else {\n      disappearLayoutEffects_complete(subtreeRoot);\n    }\n  }\n}\n\nfunction disappearLayoutEffects_complete(subtreeRoot) {\n  while (nextEffect !== null) {\n    var fiber = nextEffect;\n\n    if (fiber === subtreeRoot) {\n      nextEffect = null;\n      return;\n    }\n\n    var sibling = fiber.sibling;\n\n    if (sibling !== null) {\n      sibling.return = fiber.return;\n      nextEffect = sibling;\n      return;\n    }\n\n    nextEffect = fiber.return;\n  }\n}\n\nfunction reappearLayoutEffects_begin(subtreeRoot) {\n  while (nextEffect !== null) {\n    var fiber = nextEffect;\n    var firstChild = fiber.child;\n\n    if (fiber.tag === OffscreenComponent) {\n      var isHidden = fiber.memoizedState !== null;\n\n      if (isHidden) {\n        // Nested Offscreen tree is still hidden. Don't re-appear its effects.\n        reappearLayoutEffects_complete(subtreeRoot);\n        continue;\n      }\n    } // TODO (Offscreen) Check: subtreeFlags & LayoutStatic\n\n\n    if (firstChild !== null) {\n      // This node may have been reused from a previous render, so we can't\n      // assume its return pointer is correct.\n      firstChild.return = fiber;\n      nextEffect = firstChild;\n    } else {\n      reappearLayoutEffects_complete(subtreeRoot);\n    }\n  }\n}\n\nfunction reappearLayoutEffects_complete(subtreeRoot) {\n  while (nextEffect !== null) {\n    var fiber = nextEffect; // TODO (Offscreen) Check: flags & LayoutStatic\n\n    setCurrentFiber(fiber);\n\n    try {\n      reappearLayoutEffectsOnFiber(fiber);\n    } catch (error) {\n      captureCommitPhaseError(fiber, fiber.return, error);\n    }\n\n    resetCurrentFiber();\n\n    if (fiber === subtreeRoot) {\n      nextEffect = null;\n      return;\n    }\n\n    var sibling = fiber.sibling;\n\n    if (sibling !== null) {\n      // This node may have been reused from a previous render, so we can't\n      // assume its return pointer is correct.\n      sibling.return = fiber.return;\n      nextEffect = sibling;\n      return;\n    }\n\n    nextEffect = fiber.return;\n  }\n}\n\nfunction commitPassiveMountEffects(root, finishedWork, committedLanes, committedTransitions) {\n  nextEffect = finishedWork;\n  commitPassiveMountEffects_begin(finishedWork, root, committedLanes, committedTransitions);\n}\n\nfunction commitPassiveMountEffects_begin(subtreeRoot, root, committedLanes, committedTransitions) {\n  while (nextEffect !== null) {\n    var fiber = nextEffect;\n    var firstChild = fiber.child;\n\n    if ((fiber.subtreeFlags & PassiveMask) !== NoFlags && firstChild !== null) {\n      firstChild.return = fiber;\n      nextEffect = firstChild;\n    } else {\n      commitPassiveMountEffects_complete(subtreeRoot, root, committedLanes, committedTransitions);\n    }\n  }\n}\n\nfunction commitPassiveMountEffects_complete(subtreeRoot, root, committedLanes, committedTransitions) {\n  while (nextEffect !== null) {\n    var fiber = nextEffect;\n\n    if ((fiber.flags & Passive) !== NoFlags) {\n      setCurrentFiber(fiber);\n\n      try {\n        commitPassiveMountOnFiber(root, fiber, committedLanes, committedTransitions);\n      } catch (error) {\n        captureCommitPhaseError(fiber, fiber.return, error);\n      }\n\n      resetCurrentFiber();\n    }\n\n    if (fiber === subtreeRoot) {\n      nextEffect = null;\n      return;\n    }\n\n    var sibling = fiber.sibling;\n\n    if (sibling !== null) {\n      sibling.return = fiber.return;\n      nextEffect = sibling;\n      return;\n    }\n\n    nextEffect = fiber.return;\n  }\n}\n\nfunction commitPassiveMountOnFiber(finishedRoot, finishedWork, committedLanes, committedTransitions) {\n  switch (finishedWork.tag) {\n    case FunctionComponent:\n    case ForwardRef:\n    case SimpleMemoComponent:\n      {\n        if ( finishedWork.mode & ProfileMode) {\n          startPassiveEffectTimer();\n\n          try {\n            commitHookEffectListMount(Passive$1 | HasEffect, finishedWork);\n          } finally {\n            recordPassiveEffectDuration(finishedWork);\n          }\n        } else {\n          commitHookEffectListMount(Passive$1 | HasEffect, finishedWork);\n        }\n\n        break;\n      }\n  }\n}\n\nfunction commitPassiveUnmountEffects(firstChild) {\n  nextEffect = firstChild;\n  commitPassiveUnmountEffects_begin();\n}\n\nfunction commitPassiveUnmountEffects_begin() {\n  while (nextEffect !== null) {\n    var fiber = nextEffect;\n    var child = fiber.child;\n\n    if ((nextEffect.flags & ChildDeletion) !== NoFlags) {\n      var deletions = fiber.deletions;\n\n      if (deletions !== null) {\n        for (var i = 0; i < deletions.length; i++) {\n          var fiberToDelete = deletions[i];\n          nextEffect = fiberToDelete;\n          commitPassiveUnmountEffectsInsideOfDeletedTree_begin(fiberToDelete, fiber);\n        }\n\n        {\n          // A fiber was deleted from this parent fiber, but it's still part of\n          // the previous (alternate) parent fiber's list of children. Because\n          // children are a linked list, an earlier sibling that's still alive\n          // will be connected to the deleted fiber via its `alternate`:\n          //\n          //   live fiber\n          //   --alternate--> previous live fiber\n          //   --sibling--> deleted fiber\n          //\n          // We can't disconnect `alternate` on nodes that haven't been deleted\n          // yet, but we can disconnect the `sibling` and `child` pointers.\n          var previousFiber = fiber.alternate;\n\n          if (previousFiber !== null) {\n            var detachedChild = previousFiber.child;\n\n            if (detachedChild !== null) {\n              previousFiber.child = null;\n\n              do {\n                var detachedSibling = detachedChild.sibling;\n                detachedChild.sibling = null;\n                detachedChild = detachedSibling;\n              } while (detachedChild !== null);\n            }\n          }\n        }\n\n        nextEffect = fiber;\n      }\n    }\n\n    if ((fiber.subtreeFlags & PassiveMask) !== NoFlags && child !== null) {\n      child.return = fiber;\n      nextEffect = child;\n    } else {\n      commitPassiveUnmountEffects_complete();\n    }\n  }\n}\n\nfunction commitPassiveUnmountEffects_complete() {\n  while (nextEffect !== null) {\n    var fiber = nextEffect;\n\n    if ((fiber.flags & Passive) !== NoFlags) {\n      setCurrentFiber(fiber);\n      commitPassiveUnmountOnFiber(fiber);\n      resetCurrentFiber();\n    }\n\n    var sibling = fiber.sibling;\n\n    if (sibling !== null) {\n      sibling.return = fiber.return;\n      nextEffect = sibling;\n      return;\n    }\n\n    nextEffect = fiber.return;\n  }\n}\n\nfunction commitPassiveUnmountOnFiber(finishedWork) {\n  switch (finishedWork.tag) {\n    case FunctionComponent:\n    case ForwardRef:\n    case SimpleMemoComponent:\n      {\n        if ( finishedWork.mode & ProfileMode) {\n          startPassiveEffectTimer();\n          commitHookEffectListUnmount(Passive$1 | HasEffect, finishedWork, finishedWork.return);\n          recordPassiveEffectDuration(finishedWork);\n        } else {\n          commitHookEffectListUnmount(Passive$1 | HasEffect, finishedWork, finishedWork.return);\n        }\n\n        break;\n      }\n  }\n}\n\nfunction commitPassiveUnmountEffectsInsideOfDeletedTree_begin(deletedSubtreeRoot, nearestMountedAncestor) {\n  while (nextEffect !== null) {\n    var fiber = nextEffect; // Deletion effects fire in parent -> child order\n    // TODO: Check if fiber has a PassiveStatic flag\n\n    setCurrentFiber(fiber);\n    commitPassiveUnmountInsideDeletedTreeOnFiber(fiber, nearestMountedAncestor);\n    resetCurrentFiber();\n    var child = fiber.child; // TODO: Only traverse subtree if it has a PassiveStatic flag. (But, if we\n    // do this, still need to handle `deletedTreeCleanUpLevel` correctly.)\n\n    if (child !== null) {\n      child.return = fiber;\n      nextEffect = child;\n    } else {\n      commitPassiveUnmountEffectsInsideOfDeletedTree_complete(deletedSubtreeRoot);\n    }\n  }\n}\n\nfunction commitPassiveUnmountEffectsInsideOfDeletedTree_complete(deletedSubtreeRoot) {\n  while (nextEffect !== null) {\n    var fiber = nextEffect;\n    var sibling = fiber.sibling;\n    var returnFiber = fiber.return;\n\n    {\n      // Recursively traverse the entire deleted tree and clean up fiber fields.\n      // This is more aggressive than ideal, and the long term goal is to only\n      // have to detach the deleted tree at the root.\n      detachFiberAfterEffects(fiber);\n\n      if (fiber === deletedSubtreeRoot) {\n        nextEffect = null;\n        return;\n      }\n    }\n\n    if (sibling !== null) {\n      sibling.return = returnFiber;\n      nextEffect = sibling;\n      return;\n    }\n\n    nextEffect = returnFiber;\n  }\n}\n\nfunction commitPassiveUnmountInsideDeletedTreeOnFiber(current, nearestMountedAncestor) {\n  switch (current.tag) {\n    case FunctionComponent:\n    case ForwardRef:\n    case SimpleMemoComponent:\n      {\n        if ( current.mode & ProfileMode) {\n          startPassiveEffectTimer();\n          commitHookEffectListUnmount(Passive$1, current, nearestMountedAncestor);\n          recordPassiveEffectDuration(current);\n        } else {\n          commitHookEffectListUnmount(Passive$1, current, nearestMountedAncestor);\n        }\n\n        break;\n      }\n  }\n} // TODO: Reuse reappearLayoutEffects traversal here?\n\n\nfunction invokeLayoutEffectMountInDEV(fiber) {\n  {\n    // We don't need to re-check StrictEffectsMode here.\n    // This function is only called if that check has already passed.\n    switch (fiber.tag) {\n      case FunctionComponent:\n      case ForwardRef:\n      case SimpleMemoComponent:\n        {\n          try {\n            commitHookEffectListMount(Layout | HasEffect, fiber);\n          } catch (error) {\n            captureCommitPhaseError(fiber, fiber.return, error);\n          }\n\n          break;\n        }\n\n      case ClassComponent:\n        {\n          var instance = fiber.stateNode;\n\n          try {\n            instance.componentDidMount();\n          } catch (error) {\n            captureCommitPhaseError(fiber, fiber.return, error);\n          }\n\n          break;\n        }\n    }\n  }\n}\n\nfunction invokePassiveEffectMountInDEV(fiber) {\n  {\n    // We don't need to re-check StrictEffectsMode here.\n    // This function is only called if that check has already passed.\n    switch (fiber.tag) {\n      case FunctionComponent:\n      case ForwardRef:\n      case SimpleMemoComponent:\n        {\n          try {\n            commitHookEffectListMount(Passive$1 | HasEffect, fiber);\n          } catch (error) {\n            captureCommitPhaseError(fiber, fiber.return, error);\n          }\n\n          break;\n        }\n    }\n  }\n}\n\nfunction invokeLayoutEffectUnmountInDEV(fiber) {\n  {\n    // We don't need to re-check StrictEffectsMode here.\n    // This function is only called if that check has already passed.\n    switch (fiber.tag) {\n      case FunctionComponent:\n      case ForwardRef:\n      case SimpleMemoComponent:\n        {\n          try {\n            commitHookEffectListUnmount(Layout | HasEffect, fiber, fiber.return);\n          } catch (error) {\n            captureCommitPhaseError(fiber, fiber.return, error);\n          }\n\n          break;\n        }\n\n      case ClassComponent:\n        {\n          var instance = fiber.stateNode;\n\n          if (typeof instance.componentWillUnmount === 'function') {\n            safelyCallComponentWillUnmount(fiber, fiber.return, instance);\n          }\n\n          break;\n        }\n    }\n  }\n}\n\nfunction invokePassiveEffectUnmountInDEV(fiber) {\n  {\n    // We don't need to re-check StrictEffectsMode here.\n    // This function is only called if that check has already passed.\n    switch (fiber.tag) {\n      case FunctionComponent:\n      case ForwardRef:\n      case SimpleMemoComponent:\n        {\n          try {\n            commitHookEffectListUnmount(Passive$1 | HasEffect, fiber, fiber.return);\n          } catch (error) {\n            captureCommitPhaseError(fiber, fiber.return, error);\n          }\n        }\n    }\n  }\n}\n\nvar COMPONENT_TYPE = 0;\nvar HAS_PSEUDO_CLASS_TYPE = 1;\nvar ROLE_TYPE = 2;\nvar TEST_NAME_TYPE = 3;\nvar TEXT_TYPE = 4;\n\nif (typeof Symbol === 'function' && Symbol.for) {\n  var symbolFor = Symbol.for;\n  COMPONENT_TYPE = symbolFor('selector.component');\n  HAS_PSEUDO_CLASS_TYPE = symbolFor('selector.has_pseudo_class');\n  ROLE_TYPE = symbolFor('selector.role');\n  TEST_NAME_TYPE = symbolFor('selector.test_id');\n  TEXT_TYPE = symbolFor('selector.text');\n}\nvar commitHooks = [];\nfunction onCommitRoot$1() {\n  {\n    commitHooks.forEach(function (commitHook) {\n      return commitHook();\n    });\n  }\n}\n\nvar ReactCurrentActQueue = ReactSharedInternals.ReactCurrentActQueue;\nfunction isLegacyActEnvironment(fiber) {\n  {\n    // Legacy mode. We preserve the behavior of React 17's act. It assumes an\n    // act environment whenever `jest` is defined, but you can still turn off\n    // spurious warnings by setting IS_REACT_ACT_ENVIRONMENT explicitly\n    // to false.\n    var isReactActEnvironmentGlobal = // $FlowExpectedError  Flow doesn't know about IS_REACT_ACT_ENVIRONMENT global\n    typeof IS_REACT_ACT_ENVIRONMENT !== 'undefined' ? IS_REACT_ACT_ENVIRONMENT : undefined; // $FlowExpectedError - Flow doesn't know about jest\n\n    var jestIsDefined = typeof jest !== 'undefined';\n    return  jestIsDefined && isReactActEnvironmentGlobal !== false;\n  }\n}\nfunction isConcurrentActEnvironment() {\n  {\n    var isReactActEnvironmentGlobal = // $FlowExpectedError  Flow doesn't know about IS_REACT_ACT_ENVIRONMENT global\n    typeof IS_REACT_ACT_ENVIRONMENT !== 'undefined' ? IS_REACT_ACT_ENVIRONMENT : undefined;\n\n    if (!isReactActEnvironmentGlobal && ReactCurrentActQueue.current !== null) {\n      // TODO: Include link to relevant documentation page.\n      error('The current testing environment is not configured to support ' + 'act(...)');\n    }\n\n    return isReactActEnvironmentGlobal;\n  }\n}\n\nvar ceil = Math.ceil;\nvar ReactCurrentDispatcher$2 = ReactSharedInternals.ReactCurrentDispatcher,\n    ReactCurrentOwner$2 = ReactSharedInternals.ReactCurrentOwner,\n    ReactCurrentBatchConfig$3 = ReactSharedInternals.ReactCurrentBatchConfig,\n    ReactCurrentActQueue$1 = ReactSharedInternals.ReactCurrentActQueue;\nvar NoContext =\n/*             */\n0;\nvar BatchedContext =\n/*               */\n1;\nvar RenderContext =\n/*                */\n2;\nvar CommitContext =\n/*                */\n4;\nvar RootInProgress = 0;\nvar RootFatalErrored = 1;\nvar RootErrored = 2;\nvar RootSuspended = 3;\nvar RootSuspendedWithDelay = 4;\nvar RootCompleted = 5;\nvar RootDidNotComplete = 6; // Describes where we are in the React execution stack\n\nvar executionContext = NoContext; // The root we're working on\n\nvar workInProgressRoot = null; // The fiber we're working on\n\nvar workInProgress = null; // The lanes we're rendering\n\nvar workInProgressRootRenderLanes = NoLanes; // Stack that allows components to change the render lanes for its subtree\n// This is a superset of the lanes we started working on at the root. The only\n// case where it's different from `workInProgressRootRenderLanes` is when we\n// enter a subtree that is hidden and needs to be unhidden: Suspense and\n// Offscreen component.\n//\n// Most things in the work loop should deal with workInProgressRootRenderLanes.\n// Most things in begin/complete phases should deal with subtreeRenderLanes.\n\nvar subtreeRenderLanes = NoLanes;\nvar subtreeRenderLanesCursor = createCursor(NoLanes); // Whether to root completed, errored, suspended, etc.\n\nvar workInProgressRootExitStatus = RootInProgress; // A fatal error, if one is thrown\n\nvar workInProgressRootFatalError = null; // \"Included\" lanes refer to lanes that were worked on during this render. It's\n// slightly different than `renderLanes` because `renderLanes` can change as you\n// enter and exit an Offscreen tree. This value is the combination of all render\n// lanes for the entire render phase.\n\nvar workInProgressRootIncludedLanes = NoLanes; // The work left over by components that were visited during this render. Only\n// includes unprocessed updates, not work in bailed out children.\n\nvar workInProgressRootSkippedLanes = NoLanes; // Lanes that were updated (in an interleaved event) during this render.\n\nvar workInProgressRootInterleavedUpdatedLanes = NoLanes; // Lanes that were updated during the render phase (*not* an interleaved event).\n\nvar workInProgressRootPingedLanes = NoLanes; // Errors that are thrown during the render phase.\n\nvar workInProgressRootConcurrentErrors = null; // These are errors that we recovered from without surfacing them to the UI.\n// We will log them once the tree commits.\n\nvar workInProgressRootRecoverableErrors = null; // The most recent time we committed a fallback. This lets us ensure a train\n// model where we don't commit new loading states in too quick succession.\n\nvar globalMostRecentFallbackTime = 0;\nvar FALLBACK_THROTTLE_MS = 500; // The absolute time for when we should start giving up on rendering\n// more and prefer CPU suspense heuristics instead.\n\nvar workInProgressRootRenderTargetTime = Infinity; // How long a render is supposed to take before we start following CPU\n// suspense heuristics and opt out of rendering more content.\n\nvar RENDER_TIMEOUT_MS = 500;\nvar workInProgressTransitions = null;\n\nfunction resetRenderTimer() {\n  workInProgressRootRenderTargetTime = now() + RENDER_TIMEOUT_MS;\n}\n\nfunction getRenderTargetTime() {\n  return workInProgressRootRenderTargetTime;\n}\nvar hasUncaughtError = false;\nvar firstUncaughtError = null;\nvar legacyErrorBoundariesThatAlreadyFailed = null; // Only used when enableProfilerNestedUpdateScheduledHook is true;\nvar rootDoesHavePassiveEffects = false;\nvar rootWithPendingPassiveEffects = null;\nvar pendingPassiveEffectsLanes = NoLanes;\nvar pendingPassiveProfilerEffects = [];\nvar pendingPassiveTransitions = null; // Use these to prevent an infinite loop of nested updates\n\nvar NESTED_UPDATE_LIMIT = 50;\nvar nestedUpdateCount = 0;\nvar rootWithNestedUpdates = null;\nvar isFlushingPassiveEffects = false;\nvar didScheduleUpdateDuringPassiveEffects = false;\nvar NESTED_PASSIVE_UPDATE_LIMIT = 50;\nvar nestedPassiveUpdateCount = 0;\nvar rootWithPassiveNestedUpdates = null; // If two updates are scheduled within the same event, we should treat their\n// event times as simultaneous, even if the actual clock time has advanced\n// between the first and second call.\n\nvar currentEventTime = NoTimestamp;\nvar currentEventTransitionLane = NoLanes;\nvar isRunningInsertionEffect = false;\nfunction getWorkInProgressRoot() {\n  return workInProgressRoot;\n}\nfunction requestEventTime() {\n  if ((executionContext & (RenderContext | CommitContext)) !== NoContext) {\n    // We're inside React, so it's fine to read the actual time.\n    return now();\n  } // We're not inside React, so we may be in the middle of a browser event.\n\n\n  if (currentEventTime !== NoTimestamp) {\n    // Use the same start time for all updates until we enter React again.\n    return currentEventTime;\n  } // This is the first update since React yielded. Compute a new start time.\n\n\n  currentEventTime = now();\n  return currentEventTime;\n}\nfunction requestUpdateLane(fiber) {\n  // Special cases\n  var mode = fiber.mode;\n\n  if ((mode & ConcurrentMode) === NoMode) {\n    return SyncLane;\n  } else if ( (executionContext & RenderContext) !== NoContext && workInProgressRootRenderLanes !== NoLanes) {\n    // This is a render phase update. These are not officially supported. The\n    // old behavior is to give this the same \"thread\" (lanes) as\n    // whatever is currently rendering. So if you call `setState` on a component\n    // that happens later in the same render, it will flush. Ideally, we want to\n    // remove the special case and treat them as if they came from an\n    // interleaved event. Regardless, this pattern is not officially supported.\n    // This behavior is only a fallback. The flag only exists until we can roll\n    // out the setState warning, since existing code might accidentally rely on\n    // the current behavior.\n    return pickArbitraryLane(workInProgressRootRenderLanes);\n  }\n\n  var isTransition = requestCurrentTransition() !== NoTransition;\n\n  if (isTransition) {\n    if ( ReactCurrentBatchConfig$3.transition !== null) {\n      var transition = ReactCurrentBatchConfig$3.transition;\n\n      if (!transition._updatedFibers) {\n        transition._updatedFibers = new Set();\n      }\n\n      transition._updatedFibers.add(fiber);\n    } // The algorithm for assigning an update to a lane should be stable for all\n    // updates at the same priority within the same event. To do this, the\n    // inputs to the algorithm must be the same.\n    //\n    // The trick we use is to cache the first of each of these inputs within an\n    // event. Then reset the cached values once we can be sure the event is\n    // over. Our heuristic for that is whenever we enter a concurrent work loop.\n\n\n    if (currentEventTransitionLane === NoLane) {\n      // All transitions within the same event are assigned the same lane.\n      currentEventTransitionLane = claimNextTransitionLane();\n    }\n\n    return currentEventTransitionLane;\n  } // Updates originating inside certain React methods, like flushSync, have\n  // their priority set by tracking it with a context variable.\n  //\n  // The opaque type returned by the host config is internally a lane, so we can\n  // use that directly.\n  // TODO: Move this type conversion to the event priority module.\n\n\n  var updateLane = getCurrentUpdatePriority();\n\n  if (updateLane !== NoLane) {\n    return updateLane;\n  } // This update originated outside React. Ask the host environment for an\n  // appropriate priority, based on the type of event.\n  //\n  // The opaque type returned by the host config is internally a lane, so we can\n  // use that directly.\n  // TODO: Move this type conversion to the event priority module.\n\n\n  var eventLane = getCurrentEventPriority();\n  return eventLane;\n}\n\nfunction requestRetryLane(fiber) {\n  // This is a fork of `requestUpdateLane` designed specifically for Suspense\n  // \"retries\"  a special update that attempts to flip a Suspense boundary\n  // from its placeholder state to its primary/resolved state.\n  // Special cases\n  var mode = fiber.mode;\n\n  if ((mode & ConcurrentMode) === NoMode) {\n    return SyncLane;\n  }\n\n  return claimNextRetryLane();\n}\n\nfunction scheduleUpdateOnFiber(root, fiber, lane, eventTime) {\n  checkForNestedUpdates();\n\n  {\n    if (isRunningInsertionEffect) {\n      error('useInsertionEffect must not schedule updates.');\n    }\n  }\n\n  {\n    if (isFlushingPassiveEffects) {\n      didScheduleUpdateDuringPassiveEffects = true;\n    }\n  } // Mark that the root has a pending update.\n\n\n  markRootUpdated(root, lane, eventTime);\n\n  if ((executionContext & RenderContext) !== NoLanes && root === workInProgressRoot) {\n    // This update was dispatched during the render phase. This is a mistake\n    // if the update originates from user space (with the exception of local\n    // hook updates, which are handled differently and don't reach this\n    // function), but there are some internal React features that use this as\n    // an implementation detail, like selective hydration.\n    warnAboutRenderPhaseUpdatesInDEV(fiber); // Track lanes that were updated during the render phase\n  } else {\n    // This is a normal update, scheduled from outside the render phase. For\n    // example, during an input event.\n    {\n      if (isDevToolsPresent) {\n        addFiberToLanesMap(root, fiber, lane);\n      }\n    }\n\n    warnIfUpdatesNotWrappedWithActDEV(fiber);\n\n    if (root === workInProgressRoot) {\n      // Received an update to a tree that's in the middle of rendering. Mark\n      // that there was an interleaved update work on this root. Unless the\n      // `deferRenderPhaseUpdateToNextBatch` flag is off and this is a render\n      // phase update. In that case, we don't treat render phase updates as if\n      // they were interleaved, for backwards compat reasons.\n      if ( (executionContext & RenderContext) === NoContext) {\n        workInProgressRootInterleavedUpdatedLanes = mergeLanes(workInProgressRootInterleavedUpdatedLanes, lane);\n      }\n\n      if (workInProgressRootExitStatus === RootSuspendedWithDelay) {\n        // The root already suspended with a delay, which means this render\n        // definitely won't finish. Since we have a new update, let's mark it as\n        // suspended now, right before marking the incoming update. This has the\n        // effect of interrupting the current render and switching to the update.\n        // TODO: Make sure this doesn't override pings that happen while we've\n        // already started rendering.\n        markRootSuspended$1(root, workInProgressRootRenderLanes);\n      }\n    }\n\n    ensureRootIsScheduled(root, eventTime);\n\n    if (lane === SyncLane && executionContext === NoContext && (fiber.mode & ConcurrentMode) === NoMode && // Treat `act` as if it's inside `batchedUpdates`, even in legacy mode.\n    !( ReactCurrentActQueue$1.isBatchingLegacy)) {\n      // Flush the synchronous work now, unless we're already working or inside\n      // a batch. This is intentionally inside scheduleUpdateOnFiber instead of\n      // scheduleCallbackForFiber to preserve the ability to schedule a callback\n      // without immediately flushing it. We only do this for user-initiated\n      // updates, to preserve historical behavior of legacy mode.\n      resetRenderTimer();\n      flushSyncCallbacksOnlyInLegacyMode();\n    }\n  }\n}\nfunction scheduleInitialHydrationOnRoot(root, lane, eventTime) {\n  // This is a special fork of scheduleUpdateOnFiber that is only used to\n  // schedule the initial hydration of a root that has just been created. Most\n  // of the stuff in scheduleUpdateOnFiber can be skipped.\n  //\n  // The main reason for this separate path, though, is to distinguish the\n  // initial children from subsequent updates. In fully client-rendered roots\n  // (createRoot instead of hydrateRoot), all top-level renders are modeled as\n  // updates, but hydration roots are special because the initial render must\n  // match what was rendered on the server.\n  var current = root.current;\n  current.lanes = lane;\n  markRootUpdated(root, lane, eventTime);\n  ensureRootIsScheduled(root, eventTime);\n}\nfunction isUnsafeClassRenderPhaseUpdate(fiber) {\n  // Check if this is a render phase update. Only called by class components,\n  // which special (deprecated) behavior for UNSAFE_componentWillReceive props.\n  return (// TODO: Remove outdated deferRenderPhaseUpdateToNextBatch experiment. We\n    // decided not to enable it.\n     (executionContext & RenderContext) !== NoContext\n  );\n} // Use this function to schedule a task for a root. There's only one task per\n// root; if a task was already scheduled, we'll check to make sure the priority\n// of the existing task is the same as the priority of the next level that the\n// root has work on. This function is called on every update, and right before\n// exiting a task.\n\nfunction ensureRootIsScheduled(root, currentTime) {\n  var existingCallbackNode = root.callbackNode; // Check if any lanes are being starved by other work. If so, mark them as\n  // expired so we know to work on those next.\n\n  markStarvedLanesAsExpired(root, currentTime); // Determine the next lanes to work on, and their priority.\n\n  var nextLanes = getNextLanes(root, root === workInProgressRoot ? workInProgressRootRenderLanes : NoLanes);\n\n  if (nextLanes === NoLanes) {\n    // Special case: There's nothing to work on.\n    if (existingCallbackNode !== null) {\n      cancelCallback$1(existingCallbackNode);\n    }\n\n    root.callbackNode = null;\n    root.callbackPriority = NoLane;\n    return;\n  } // We use the highest priority lane to represent the priority of the callback.\n\n\n  var newCallbackPriority = getHighestPriorityLane(nextLanes); // Check if there's an existing task. We may be able to reuse it.\n\n  var existingCallbackPriority = root.callbackPriority;\n\n  if (existingCallbackPriority === newCallbackPriority && // Special case related to `act`. If the currently scheduled task is a\n  // Scheduler task, rather than an `act` task, cancel it and re-scheduled\n  // on the `act` queue.\n  !( ReactCurrentActQueue$1.current !== null && existingCallbackNode !== fakeActCallbackNode)) {\n    {\n      // If we're going to re-use an existing task, it needs to exist.\n      // Assume that discrete update microtasks are non-cancellable and null.\n      // TODO: Temporary until we confirm this warning is not fired.\n      if (existingCallbackNode == null && existingCallbackPriority !== SyncLane) {\n        error('Expected scheduled callback to exist. This error is likely caused by a bug in React. Please file an issue.');\n      }\n    } // The priority hasn't changed. We can reuse the existing task. Exit.\n\n\n    return;\n  }\n\n  if (existingCallbackNode != null) {\n    // Cancel the existing callback. We'll schedule a new one below.\n    cancelCallback$1(existingCallbackNode);\n  } // Schedule a new callback.\n\n\n  var newCallbackNode;\n\n  if (newCallbackPriority === SyncLane) {\n    // Special case: Sync React callbacks are scheduled on a special\n    // internal queue\n    if (root.tag === LegacyRoot) {\n      if ( ReactCurrentActQueue$1.isBatchingLegacy !== null) {\n        ReactCurrentActQueue$1.didScheduleLegacyUpdate = true;\n      }\n\n      scheduleLegacySyncCallback(performSyncWorkOnRoot.bind(null, root));\n    } else {\n      scheduleSyncCallback(performSyncWorkOnRoot.bind(null, root));\n    }\n\n    {\n      // Flush the queue in a microtask.\n      if ( ReactCurrentActQueue$1.current !== null) {\n        // Inside `act`, use our internal `act` queue so that these get flushed\n        // at the end of the current scope even when using the sync version\n        // of `act`.\n        ReactCurrentActQueue$1.current.push(flushSyncCallbacks);\n      } else {\n        scheduleMicrotask(function () {\n          // In Safari, appending an iframe forces microtasks to run.\n          // https://github.com/facebook/react/issues/22459\n          // We don't support running callbacks in the middle of render\n          // or commit so we need to check against that.\n          if ((executionContext & (RenderContext | CommitContext)) === NoContext) {\n            // Note that this would still prematurely flush the callbacks\n            // if this happens outside render or commit phase (e.g. in an event).\n            flushSyncCallbacks();\n          }\n        });\n      }\n    }\n\n    newCallbackNode = null;\n  } else {\n    var schedulerPriorityLevel;\n\n    switch (lanesToEventPriority(nextLanes)) {\n      case DiscreteEventPriority:\n        schedulerPriorityLevel = ImmediatePriority;\n        break;\n\n      case ContinuousEventPriority:\n        schedulerPriorityLevel = UserBlockingPriority;\n        break;\n\n      case DefaultEventPriority:\n        schedulerPriorityLevel = NormalPriority;\n        break;\n\n      case IdleEventPriority:\n        schedulerPriorityLevel = IdlePriority;\n        break;\n\n      default:\n        schedulerPriorityLevel = NormalPriority;\n        break;\n    }\n\n    newCallbackNode = scheduleCallback$1(schedulerPriorityLevel, performConcurrentWorkOnRoot.bind(null, root));\n  }\n\n  root.callbackPriority = newCallbackPriority;\n  root.callbackNode = newCallbackNode;\n} // This is the entry point for every concurrent task, i.e. anything that\n// goes through Scheduler.\n\n\nfunction performConcurrentWorkOnRoot(root, didTimeout) {\n  {\n    resetNestedUpdateFlag();\n  } // Since we know we're in a React event, we can clear the current\n  // event time. The next update will compute a new event time.\n\n\n  currentEventTime = NoTimestamp;\n  currentEventTransitionLane = NoLanes;\n\n  if ((executionContext & (RenderContext | CommitContext)) !== NoContext) {\n    throw new Error('Should not already be working.');\n  } // Flush any pending passive effects before deciding which lanes to work on,\n  // in case they schedule additional work.\n\n\n  var originalCallbackNode = root.callbackNode;\n  var didFlushPassiveEffects = flushPassiveEffects();\n\n  if (didFlushPassiveEffects) {\n    // Something in the passive effect phase may have canceled the current task.\n    // Check if the task node for this root was changed.\n    if (root.callbackNode !== originalCallbackNode) {\n      // The current task was canceled. Exit. We don't need to call\n      // `ensureRootIsScheduled` because the check above implies either that\n      // there's a new task, or that there's no remaining work on this root.\n      return null;\n    }\n  } // Determine the next lanes to work on, using the fields stored\n  // on the root.\n\n\n  var lanes = getNextLanes(root, root === workInProgressRoot ? workInProgressRootRenderLanes : NoLanes);\n\n  if (lanes === NoLanes) {\n    // Defensive coding. This is never expected to happen.\n    return null;\n  } // We disable time-slicing in some cases: if the work has been CPU-bound\n  // for too long (\"expired\" work, to prevent starvation), or we're in\n  // sync-updates-by-default mode.\n  // TODO: We only check `didTimeout` defensively, to account for a Scheduler\n  // bug we're still investigating. Once the bug in Scheduler is fixed,\n  // we can remove this, since we track expiration ourselves.\n\n\n  var shouldTimeSlice = !includesBlockingLane(root, lanes) && !includesExpiredLane(root, lanes) && ( !didTimeout);\n  var exitStatus = shouldTimeSlice ? renderRootConcurrent(root, lanes) : renderRootSync(root, lanes);\n\n  if (exitStatus !== RootInProgress) {\n    if (exitStatus === RootErrored) {\n      // If something threw an error, try rendering one more time. We'll\n      // render synchronously to block concurrent data mutations, and we'll\n      // includes all pending updates are included. If it still fails after\n      // the second attempt, we'll give up and commit the resulting tree.\n      var errorRetryLanes = getLanesToRetrySynchronouslyOnError(root);\n\n      if (errorRetryLanes !== NoLanes) {\n        lanes = errorRetryLanes;\n        exitStatus = recoverFromConcurrentError(root, errorRetryLanes);\n      }\n    }\n\n    if (exitStatus === RootFatalErrored) {\n      var fatalError = workInProgressRootFatalError;\n      prepareFreshStack(root, NoLanes);\n      markRootSuspended$1(root, lanes);\n      ensureRootIsScheduled(root, now());\n      throw fatalError;\n    }\n\n    if (exitStatus === RootDidNotComplete) {\n      // The render unwound without completing the tree. This happens in special\n      // cases where need to exit the current render without producing a\n      // consistent tree or committing.\n      //\n      // This should only happen during a concurrent render, not a discrete or\n      // synchronous update. We should have already checked for this when we\n      // unwound the stack.\n      markRootSuspended$1(root, lanes);\n    } else {\n      // The render completed.\n      // Check if this render may have yielded to a concurrent event, and if so,\n      // confirm that any newly rendered stores are consistent.\n      // TODO: It's possible that even a concurrent render may never have yielded\n      // to the main thread, if it was fast enough, or if it expired. We could\n      // skip the consistency check in that case, too.\n      var renderWasConcurrent = !includesBlockingLane(root, lanes);\n      var finishedWork = root.current.alternate;\n\n      if (renderWasConcurrent && !isRenderConsistentWithExternalStores(finishedWork)) {\n        // A store was mutated in an interleaved event. Render again,\n        // synchronously, to block further mutations.\n        exitStatus = renderRootSync(root, lanes); // We need to check again if something threw\n\n        if (exitStatus === RootErrored) {\n          var _errorRetryLanes = getLanesToRetrySynchronouslyOnError(root);\n\n          if (_errorRetryLanes !== NoLanes) {\n            lanes = _errorRetryLanes;\n            exitStatus = recoverFromConcurrentError(root, _errorRetryLanes); // We assume the tree is now consistent because we didn't yield to any\n            // concurrent events.\n          }\n        }\n\n        if (exitStatus === RootFatalErrored) {\n          var _fatalError = workInProgressRootFatalError;\n          prepareFreshStack(root, NoLanes);\n          markRootSuspended$1(root, lanes);\n          ensureRootIsScheduled(root, now());\n          throw _fatalError;\n        }\n      } // We now have a consistent tree. The next step is either to commit it,\n      // or, if something suspended, wait to commit it after a timeout.\n\n\n      root.finishedWork = finishedWork;\n      root.finishedLanes = lanes;\n      finishConcurrentRender(root, exitStatus, lanes);\n    }\n  }\n\n  ensureRootIsScheduled(root, now());\n\n  if (root.callbackNode === originalCallbackNode) {\n    // The task node scheduled for this root is the same one that's\n    // currently executed. Need to return a continuation.\n    return performConcurrentWorkOnRoot.bind(null, root);\n  }\n\n  return null;\n}\n\nfunction recoverFromConcurrentError(root, errorRetryLanes) {\n  // If an error occurred during hydration, discard server response and fall\n  // back to client side render.\n  // Before rendering again, save the errors from the previous attempt.\n  var errorsFromFirstAttempt = workInProgressRootConcurrentErrors;\n\n  if (isRootDehydrated(root)) {\n    // The shell failed to hydrate. Set a flag to force a client rendering\n    // during the next attempt. To do this, we call prepareFreshStack now\n    // to create the root work-in-progress fiber. This is a bit weird in terms\n    // of factoring, because it relies on renderRootSync not calling\n    // prepareFreshStack again in the call below, which happens because the\n    // root and lanes haven't changed.\n    //\n    // TODO: I think what we should do is set ForceClientRender inside\n    // throwException, like we do for nested Suspense boundaries. The reason\n    // it's here instead is so we can switch to the synchronous work loop, too.\n    // Something to consider for a future refactor.\n    var rootWorkInProgress = prepareFreshStack(root, errorRetryLanes);\n    rootWorkInProgress.flags |= ForceClientRender;\n\n    {\n      errorHydratingContainer(root.containerInfo);\n    }\n  }\n\n  var exitStatus = renderRootSync(root, errorRetryLanes);\n\n  if (exitStatus !== RootErrored) {\n    // Successfully finished rendering on retry\n    // The errors from the failed first attempt have been recovered. Add\n    // them to the collection of recoverable errors. We'll log them in the\n    // commit phase.\n    var errorsFromSecondAttempt = workInProgressRootRecoverableErrors;\n    workInProgressRootRecoverableErrors = errorsFromFirstAttempt; // The errors from the second attempt should be queued after the errors\n    // from the first attempt, to preserve the causal sequence.\n\n    if (errorsFromSecondAttempt !== null) {\n      queueRecoverableErrors(errorsFromSecondAttempt);\n    }\n  }\n\n  return exitStatus;\n}\n\nfunction queueRecoverableErrors(errors) {\n  if (workInProgressRootRecoverableErrors === null) {\n    workInProgressRootRecoverableErrors = errors;\n  } else {\n    workInProgressRootRecoverableErrors.push.apply(workInProgressRootRecoverableErrors, errors);\n  }\n}\n\nfunction finishConcurrentRender(root, exitStatus, lanes) {\n  switch (exitStatus) {\n    case RootInProgress:\n    case RootFatalErrored:\n      {\n        throw new Error('Root did not complete. This is a bug in React.');\n      }\n    // Flow knows about invariant, so it complains if I add a break\n    // statement, but eslint doesn't know about invariant, so it complains\n    // if I do. eslint-disable-next-line no-fallthrough\n\n    case RootErrored:\n      {\n        // We should have already attempted to retry this tree. If we reached\n        // this point, it errored again. Commit it.\n        commitRoot(root, workInProgressRootRecoverableErrors, workInProgressTransitions);\n        break;\n      }\n\n    case RootSuspended:\n      {\n        markRootSuspended$1(root, lanes); // We have an acceptable loading state. We need to figure out if we\n        // should immediately commit it or wait a bit.\n\n        if (includesOnlyRetries(lanes) && // do not delay if we're inside an act() scope\n        !shouldForceFlushFallbacksInDEV()) {\n          // This render only included retries, no updates. Throttle committing\n          // retries so that we don't show too many loading states too quickly.\n          var msUntilTimeout = globalMostRecentFallbackTime + FALLBACK_THROTTLE_MS - now(); // Don't bother with a very short suspense time.\n\n          if (msUntilTimeout > 10) {\n            var nextLanes = getNextLanes(root, NoLanes);\n\n            if (nextLanes !== NoLanes) {\n              // There's additional work on this root.\n              break;\n            }\n\n            var suspendedLanes = root.suspendedLanes;\n\n            if (!isSubsetOfLanes(suspendedLanes, lanes)) {\n              // We should prefer to render the fallback of at the last\n              // suspended level. Ping the last suspended level to try\n              // rendering it again.\n              // FIXME: What if the suspended lanes are Idle? Should not restart.\n              var eventTime = requestEventTime();\n              markRootPinged(root, suspendedLanes);\n              break;\n            } // The render is suspended, it hasn't timed out, and there's no\n            // lower priority work to do. Instead of committing the fallback\n            // immediately, wait for more data to arrive.\n\n\n            root.timeoutHandle = scheduleTimeout(commitRoot.bind(null, root, workInProgressRootRecoverableErrors, workInProgressTransitions), msUntilTimeout);\n            break;\n          }\n        } // The work expired. Commit immediately.\n\n\n        commitRoot(root, workInProgressRootRecoverableErrors, workInProgressTransitions);\n        break;\n      }\n\n    case RootSuspendedWithDelay:\n      {\n        markRootSuspended$1(root, lanes);\n\n        if (includesOnlyTransitions(lanes)) {\n          // This is a transition, so we should exit without committing a\n          // placeholder and without scheduling a timeout. Delay indefinitely\n          // until we receive more data.\n          break;\n        }\n\n        if (!shouldForceFlushFallbacksInDEV()) {\n          // This is not a transition, but we did trigger an avoided state.\n          // Schedule a placeholder to display after a short delay, using the Just\n          // Noticeable Difference.\n          // TODO: Is the JND optimization worth the added complexity? If this is\n          // the only reason we track the event time, then probably not.\n          // Consider removing.\n          var mostRecentEventTime = getMostRecentEventTime(root, lanes);\n          var eventTimeMs = mostRecentEventTime;\n          var timeElapsedMs = now() - eventTimeMs;\n\n          var _msUntilTimeout = jnd(timeElapsedMs) - timeElapsedMs; // Don't bother with a very short suspense time.\n\n\n          if (_msUntilTimeout > 10) {\n            // Instead of committing the fallback immediately, wait for more data\n            // to arrive.\n            root.timeoutHandle = scheduleTimeout(commitRoot.bind(null, root, workInProgressRootRecoverableErrors, workInProgressTransitions), _msUntilTimeout);\n            break;\n          }\n        } // Commit the placeholder.\n\n\n        commitRoot(root, workInProgressRootRecoverableErrors, workInProgressTransitions);\n        break;\n      }\n\n    case RootCompleted:\n      {\n        // The work completed. Ready to commit.\n        commitRoot(root, workInProgressRootRecoverableErrors, workInProgressTransitions);\n        break;\n      }\n\n    default:\n      {\n        throw new Error('Unknown root exit status.');\n      }\n  }\n}\n\nfunction isRenderConsistentWithExternalStores(finishedWork) {\n  // Search the rendered tree for external store reads, and check whether the\n  // stores were mutated in a concurrent event. Intentionally using an iterative\n  // loop instead of recursion so we can exit early.\n  var node = finishedWork;\n\n  while (true) {\n    if (node.flags & StoreConsistency) {\n      var updateQueue = node.updateQueue;\n\n      if (updateQueue !== null) {\n        var checks = updateQueue.stores;\n\n        if (checks !== null) {\n          for (var i = 0; i < checks.length; i++) {\n            var check = checks[i];\n            var getSnapshot = check.getSnapshot;\n            var renderedValue = check.value;\n\n            try {\n              if (!objectIs(getSnapshot(), renderedValue)) {\n                // Found an inconsistent store.\n                return false;\n              }\n            } catch (error) {\n              // If `getSnapshot` throws, return `false`. This will schedule\n              // a re-render, and the error will be rethrown during render.\n              return false;\n            }\n          }\n        }\n      }\n    }\n\n    var child = node.child;\n\n    if (node.subtreeFlags & StoreConsistency && child !== null) {\n      child.return = node;\n      node = child;\n      continue;\n    }\n\n    if (node === finishedWork) {\n      return true;\n    }\n\n    while (node.sibling === null) {\n      if (node.return === null || node.return === finishedWork) {\n        return true;\n      }\n\n      node = node.return;\n    }\n\n    node.sibling.return = node.return;\n    node = node.sibling;\n  } // Flow doesn't know this is unreachable, but eslint does\n  // eslint-disable-next-line no-unreachable\n\n\n  return true;\n}\n\nfunction markRootSuspended$1(root, suspendedLanes) {\n  // When suspending, we should always exclude lanes that were pinged or (more\n  // rarely, since we try to avoid it) updated during the render phase.\n  // TODO: Lol maybe there's a better way to factor this besides this\n  // obnoxiously named function :)\n  suspendedLanes = removeLanes(suspendedLanes, workInProgressRootPingedLanes);\n  suspendedLanes = removeLanes(suspendedLanes, workInProgressRootInterleavedUpdatedLanes);\n  markRootSuspended(root, suspendedLanes);\n} // This is the entry point for synchronous tasks that don't go\n// through Scheduler\n\n\nfunction performSyncWorkOnRoot(root) {\n  {\n    syncNestedUpdateFlag();\n  }\n\n  if ((executionContext & (RenderContext | CommitContext)) !== NoContext) {\n    throw new Error('Should not already be working.');\n  }\n\n  flushPassiveEffects();\n  var lanes = getNextLanes(root, NoLanes);\n\n  if (!includesSomeLane(lanes, SyncLane)) {\n    // There's no remaining sync work left.\n    ensureRootIsScheduled(root, now());\n    return null;\n  }\n\n  var exitStatus = renderRootSync(root, lanes);\n\n  if (root.tag !== LegacyRoot && exitStatus === RootErrored) {\n    // If something threw an error, try rendering one more time. We'll render\n    // synchronously to block concurrent data mutations, and we'll includes\n    // all pending updates are included. If it still fails after the second\n    // attempt, we'll give up and commit the resulting tree.\n    var errorRetryLanes = getLanesToRetrySynchronouslyOnError(root);\n\n    if (errorRetryLanes !== NoLanes) {\n      lanes = errorRetryLanes;\n      exitStatus = recoverFromConcurrentError(root, errorRetryLanes);\n    }\n  }\n\n  if (exitStatus === RootFatalErrored) {\n    var fatalError = workInProgressRootFatalError;\n    prepareFreshStack(root, NoLanes);\n    markRootSuspended$1(root, lanes);\n    ensureRootIsScheduled(root, now());\n    throw fatalError;\n  }\n\n  if (exitStatus === RootDidNotComplete) {\n    throw new Error('Root did not complete. This is a bug in React.');\n  } // We now have a consistent tree. Because this is a sync render, we\n  // will commit it even if something suspended.\n\n\n  var finishedWork = root.current.alternate;\n  root.finishedWork = finishedWork;\n  root.finishedLanes = lanes;\n  commitRoot(root, workInProgressRootRecoverableErrors, workInProgressTransitions); // Before exiting, make sure there's a callback scheduled for the next\n  // pending level.\n\n  ensureRootIsScheduled(root, now());\n  return null;\n}\n\nfunction flushRoot(root, lanes) {\n  if (lanes !== NoLanes) {\n    markRootEntangled(root, mergeLanes(lanes, SyncLane));\n    ensureRootIsScheduled(root, now());\n\n    if ((executionContext & (RenderContext | CommitContext)) === NoContext) {\n      resetRenderTimer();\n      flushSyncCallbacks();\n    }\n  }\n}\nfunction batchedUpdates$1(fn, a) {\n  var prevExecutionContext = executionContext;\n  executionContext |= BatchedContext;\n\n  try {\n    return fn(a);\n  } finally {\n    executionContext = prevExecutionContext; // If there were legacy sync updates, flush them at the end of the outer\n    // most batchedUpdates-like method.\n\n    if (executionContext === NoContext && // Treat `act` as if it's inside `batchedUpdates`, even in legacy mode.\n    !( ReactCurrentActQueue$1.isBatchingLegacy)) {\n      resetRenderTimer();\n      flushSyncCallbacksOnlyInLegacyMode();\n    }\n  }\n}\nfunction discreteUpdates(fn, a, b, c, d) {\n  var previousPriority = getCurrentUpdatePriority();\n  var prevTransition = ReactCurrentBatchConfig$3.transition;\n\n  try {\n    ReactCurrentBatchConfig$3.transition = null;\n    setCurrentUpdatePriority(DiscreteEventPriority);\n    return fn(a, b, c, d);\n  } finally {\n    setCurrentUpdatePriority(previousPriority);\n    ReactCurrentBatchConfig$3.transition = prevTransition;\n\n    if (executionContext === NoContext) {\n      resetRenderTimer();\n    }\n  }\n} // Overload the definition to the two valid signatures.\n// Warning, this opts-out of checking the function body.\n\n// eslint-disable-next-line no-redeclare\nfunction flushSync(fn) {\n  // In legacy mode, we flush pending passive effects at the beginning of the\n  // next event, not at the end of the previous one.\n  if (rootWithPendingPassiveEffects !== null && rootWithPendingPassiveEffects.tag === LegacyRoot && (executionContext & (RenderContext | CommitContext)) === NoContext) {\n    flushPassiveEffects();\n  }\n\n  var prevExecutionContext = executionContext;\n  executionContext |= BatchedContext;\n  var prevTransition = ReactCurrentBatchConfig$3.transition;\n  var previousPriority = getCurrentUpdatePriority();\n\n  try {\n    ReactCurrentBatchConfig$3.transition = null;\n    setCurrentUpdatePriority(DiscreteEventPriority);\n\n    if (fn) {\n      return fn();\n    } else {\n      return undefined;\n    }\n  } finally {\n    setCurrentUpdatePriority(previousPriority);\n    ReactCurrentBatchConfig$3.transition = prevTransition;\n    executionContext = prevExecutionContext; // Flush the immediate callbacks that were scheduled during this batch.\n    // Note that this will happen even if batchedUpdates is higher up\n    // the stack.\n\n    if ((executionContext & (RenderContext | CommitContext)) === NoContext) {\n      flushSyncCallbacks();\n    }\n  }\n}\nfunction isAlreadyRendering() {\n  // Used by the renderer to print a warning if certain APIs are called from\n  // the wrong context.\n  return  (executionContext & (RenderContext | CommitContext)) !== NoContext;\n}\nfunction pushRenderLanes(fiber, lanes) {\n  push(subtreeRenderLanesCursor, subtreeRenderLanes, fiber);\n  subtreeRenderLanes = mergeLanes(subtreeRenderLanes, lanes);\n  workInProgressRootIncludedLanes = mergeLanes(workInProgressRootIncludedLanes, lanes);\n}\nfunction popRenderLanes(fiber) {\n  subtreeRenderLanes = subtreeRenderLanesCursor.current;\n  pop(subtreeRenderLanesCursor, fiber);\n}\n\nfunction prepareFreshStack(root, lanes) {\n  root.finishedWork = null;\n  root.finishedLanes = NoLanes;\n  var timeoutHandle = root.timeoutHandle;\n\n  if (timeoutHandle !== noTimeout) {\n    // The root previous suspended and scheduled a timeout to commit a fallback\n    // state. Now that we have additional work, cancel the timeout.\n    root.timeoutHandle = noTimeout; // $FlowFixMe Complains noTimeout is not a TimeoutID, despite the check above\n\n    cancelTimeout(timeoutHandle);\n  }\n\n  if (workInProgress !== null) {\n    var interruptedWork = workInProgress.return;\n\n    while (interruptedWork !== null) {\n      var current = interruptedWork.alternate;\n      unwindInterruptedWork(current, interruptedWork);\n      interruptedWork = interruptedWork.return;\n    }\n  }\n\n  workInProgressRoot = root;\n  var rootWorkInProgress = createWorkInProgress(root.current, null);\n  workInProgress = rootWorkInProgress;\n  workInProgressRootRenderLanes = subtreeRenderLanes = workInProgressRootIncludedLanes = lanes;\n  workInProgressRootExitStatus = RootInProgress;\n  workInProgressRootFatalError = null;\n  workInProgressRootSkippedLanes = NoLanes;\n  workInProgressRootInterleavedUpdatedLanes = NoLanes;\n  workInProgressRootPingedLanes = NoLanes;\n  workInProgressRootConcurrentErrors = null;\n  workInProgressRootRecoverableErrors = null;\n  finishQueueingConcurrentUpdates();\n\n  {\n    ReactStrictModeWarnings.discardPendingWarnings();\n  }\n\n  return rootWorkInProgress;\n}\n\nfunction handleError(root, thrownValue) {\n  do {\n    var erroredWork = workInProgress;\n\n    try {\n      // Reset module-level state that was set during the render phase.\n      resetContextDependencies();\n      resetHooksAfterThrow();\n      resetCurrentFiber(); // TODO: I found and added this missing line while investigating a\n      // separate issue. Write a regression test using string refs.\n\n      ReactCurrentOwner$2.current = null;\n\n      if (erroredWork === null || erroredWork.return === null) {\n        // Expected to be working on a non-root fiber. This is a fatal error\n        // because there's no ancestor that can handle it; the root is\n        // supposed to capture all errors that weren't caught by an error\n        // boundary.\n        workInProgressRootExitStatus = RootFatalErrored;\n        workInProgressRootFatalError = thrownValue; // Set `workInProgress` to null. This represents advancing to the next\n        // sibling, or the parent if there are no siblings. But since the root\n        // has no siblings nor a parent, we set it to null. Usually this is\n        // handled by `completeUnitOfWork` or `unwindWork`, but since we're\n        // intentionally not calling those, we need set it here.\n        // TODO: Consider calling `unwindWork` to pop the contexts.\n\n        workInProgress = null;\n        return;\n      }\n\n      if (enableProfilerTimer && erroredWork.mode & ProfileMode) {\n        // Record the time spent rendering before an error was thrown. This\n        // avoids inaccurate Profiler durations in the case of a\n        // suspended render.\n        stopProfilerTimerIfRunningAndRecordDelta(erroredWork, true);\n      }\n\n      if (enableSchedulingProfiler) {\n        markComponentRenderStopped();\n\n        if (thrownValue !== null && typeof thrownValue === 'object' && typeof thrownValue.then === 'function') {\n          var wakeable = thrownValue;\n          markComponentSuspended(erroredWork, wakeable, workInProgressRootRenderLanes);\n        } else {\n          markComponentErrored(erroredWork, thrownValue, workInProgressRootRenderLanes);\n        }\n      }\n\n      throwException(root, erroredWork.return, erroredWork, thrownValue, workInProgressRootRenderLanes);\n      completeUnitOfWork(erroredWork);\n    } catch (yetAnotherThrownValue) {\n      // Something in the return path also threw.\n      thrownValue = yetAnotherThrownValue;\n\n      if (workInProgress === erroredWork && erroredWork !== null) {\n        // If this boundary has already errored, then we had trouble processing\n        // the error. Bubble it to the next boundary.\n        erroredWork = erroredWork.return;\n        workInProgress = erroredWork;\n      } else {\n        erroredWork = workInProgress;\n      }\n\n      continue;\n    } // Return to the normal work loop.\n\n\n    return;\n  } while (true);\n}\n\nfunction pushDispatcher() {\n  var prevDispatcher = ReactCurrentDispatcher$2.current;\n  ReactCurrentDispatcher$2.current = ContextOnlyDispatcher;\n\n  if (prevDispatcher === null) {\n    // The React isomorphic package does not include a default dispatcher.\n    // Instead the first renderer will lazily attach one, in order to give\n    // nicer error messages.\n    return ContextOnlyDispatcher;\n  } else {\n    return prevDispatcher;\n  }\n}\n\nfunction popDispatcher(prevDispatcher) {\n  ReactCurrentDispatcher$2.current = prevDispatcher;\n}\n\nfunction markCommitTimeOfFallback() {\n  globalMostRecentFallbackTime = now();\n}\nfunction markSkippedUpdateLanes(lane) {\n  workInProgressRootSkippedLanes = mergeLanes(lane, workInProgressRootSkippedLanes);\n}\nfunction renderDidSuspend() {\n  if (workInProgressRootExitStatus === RootInProgress) {\n    workInProgressRootExitStatus = RootSuspended;\n  }\n}\nfunction renderDidSuspendDelayIfPossible() {\n  if (workInProgressRootExitStatus === RootInProgress || workInProgressRootExitStatus === RootSuspended || workInProgressRootExitStatus === RootErrored) {\n    workInProgressRootExitStatus = RootSuspendedWithDelay;\n  } // Check if there are updates that we skipped tree that might have unblocked\n  // this render.\n\n\n  if (workInProgressRoot !== null && (includesNonIdleWork(workInProgressRootSkippedLanes) || includesNonIdleWork(workInProgressRootInterleavedUpdatedLanes))) {\n    // Mark the current render as suspended so that we switch to working on\n    // the updates that were skipped. Usually we only suspend at the end of\n    // the render phase.\n    // TODO: We should probably always mark the root as suspended immediately\n    // (inside this function), since by suspending at the end of the render\n    // phase introduces a potential mistake where we suspend lanes that were\n    // pinged or updated while we were rendering.\n    markRootSuspended$1(workInProgressRoot, workInProgressRootRenderLanes);\n  }\n}\nfunction renderDidError(error) {\n  if (workInProgressRootExitStatus !== RootSuspendedWithDelay) {\n    workInProgressRootExitStatus = RootErrored;\n  }\n\n  if (workInProgressRootConcurrentErrors === null) {\n    workInProgressRootConcurrentErrors = [error];\n  } else {\n    workInProgressRootConcurrentErrors.push(error);\n  }\n} // Called during render to determine if anything has suspended.\n// Returns false if we're not sure.\n\nfunction renderHasNotSuspendedYet() {\n  // If something errored or completed, we can't really be sure,\n  // so those are false.\n  return workInProgressRootExitStatus === RootInProgress;\n}\n\nfunction renderRootSync(root, lanes) {\n  var prevExecutionContext = executionContext;\n  executionContext |= RenderContext;\n  var prevDispatcher = pushDispatcher(); // If the root or lanes have changed, throw out the existing stack\n  // and prepare a fresh one. Otherwise we'll continue where we left off.\n\n  if (workInProgressRoot !== root || workInProgressRootRenderLanes !== lanes) {\n    {\n      if (isDevToolsPresent) {\n        var memoizedUpdaters = root.memoizedUpdaters;\n\n        if (memoizedUpdaters.size > 0) {\n          restorePendingUpdaters(root, workInProgressRootRenderLanes);\n          memoizedUpdaters.clear();\n        } // At this point, move Fibers that scheduled the upcoming work from the Map to the Set.\n        // If we bailout on this work, we'll move them back (like above).\n        // It's important to move them now in case the work spawns more work at the same priority with different updaters.\n        // That way we can keep the current update and future updates separate.\n\n\n        movePendingFibersToMemoized(root, lanes);\n      }\n    }\n\n    workInProgressTransitions = getTransitionsForLanes();\n    prepareFreshStack(root, lanes);\n  }\n\n  {\n    markRenderStarted(lanes);\n  }\n\n  do {\n    try {\n      workLoopSync();\n      break;\n    } catch (thrownValue) {\n      handleError(root, thrownValue);\n    }\n  } while (true);\n\n  resetContextDependencies();\n  executionContext = prevExecutionContext;\n  popDispatcher(prevDispatcher);\n\n  if (workInProgress !== null) {\n    // This is a sync render, so we should have finished the whole tree.\n    throw new Error('Cannot commit an incomplete root. This error is likely caused by a ' + 'bug in React. Please file an issue.');\n  }\n\n  {\n    markRenderStopped();\n  } // Set this to null to indicate there's no in-progress render.\n\n\n  workInProgressRoot = null;\n  workInProgressRootRenderLanes = NoLanes;\n  return workInProgressRootExitStatus;\n} // The work loop is an extremely hot path. Tell Closure not to inline it.\n\n/** @noinline */\n\n\nfunction workLoopSync() {\n  // Already timed out, so perform work without checking if we need to yield.\n  while (workInProgress !== null) {\n    performUnitOfWork(workInProgress);\n  }\n}\n\nfunction renderRootConcurrent(root, lanes) {\n  var prevExecutionContext = executionContext;\n  executionContext |= RenderContext;\n  var prevDispatcher = pushDispatcher(); // If the root or lanes have changed, throw out the existing stack\n  // and prepare a fresh one. Otherwise we'll continue where we left off.\n\n  if (workInProgressRoot !== root || workInProgressRootRenderLanes !== lanes) {\n    {\n      if (isDevToolsPresent) {\n        var memoizedUpdaters = root.memoizedUpdaters;\n\n        if (memoizedUpdaters.size > 0) {\n          restorePendingUpdaters(root, workInProgressRootRenderLanes);\n          memoizedUpdaters.clear();\n        } // At this point, move Fibers that scheduled the upcoming work from the Map to the Set.\n        // If we bailout on this work, we'll move them back (like above).\n        // It's important to move them now in case the work spawns more work at the same priority with different updaters.\n        // That way we can keep the current update and future updates separate.\n\n\n        movePendingFibersToMemoized(root, lanes);\n      }\n    }\n\n    workInProgressTransitions = getTransitionsForLanes();\n    resetRenderTimer();\n    prepareFreshStack(root, lanes);\n  }\n\n  {\n    markRenderStarted(lanes);\n  }\n\n  do {\n    try {\n      workLoopConcurrent();\n      break;\n    } catch (thrownValue) {\n      handleError(root, thrownValue);\n    }\n  } while (true);\n\n  resetContextDependencies();\n  popDispatcher(prevDispatcher);\n  executionContext = prevExecutionContext;\n\n\n  if (workInProgress !== null) {\n    // Still work remaining.\n    {\n      markRenderYielded();\n    }\n\n    return RootInProgress;\n  } else {\n    // Completed the tree.\n    {\n      markRenderStopped();\n    } // Set this to null to indicate there's no in-progress render.\n\n\n    workInProgressRoot = null;\n    workInProgressRootRenderLanes = NoLanes; // Return the final exit status.\n\n    return workInProgressRootExitStatus;\n  }\n}\n/** @noinline */\n\n\nfunction workLoopConcurrent() {\n  // Perform work until Scheduler asks us to yield\n  while (workInProgress !== null && !shouldYield()) {\n    performUnitOfWork(workInProgress);\n  }\n}\n\nfunction performUnitOfWork(unitOfWork) {\n  // The current, flushed, state of this fiber is the alternate. Ideally\n  // nothing should rely on this, but relying on it here means that we don't\n  // need an additional field on the work in progress.\n  var current = unitOfWork.alternate;\n  setCurrentFiber(unitOfWork);\n  var next;\n\n  if ( (unitOfWork.mode & ProfileMode) !== NoMode) {\n    startProfilerTimer(unitOfWork);\n    next = beginWork$1(current, unitOfWork, subtreeRenderLanes);\n    stopProfilerTimerIfRunningAndRecordDelta(unitOfWork, true);\n  } else {\n    next = beginWork$1(current, unitOfWork, subtreeRenderLanes);\n  }\n\n  resetCurrentFiber();\n  unitOfWork.memoizedProps = unitOfWork.pendingProps;\n\n  if (next === null) {\n    // If this doesn't spawn new work, complete the current work.\n    completeUnitOfWork(unitOfWork);\n  } else {\n    workInProgress = next;\n  }\n\n  ReactCurrentOwner$2.current = null;\n}\n\nfunction completeUnitOfWork(unitOfWork) {\n  // Attempt to complete the current unit of work, then move to the next\n  // sibling. If there are no more siblings, return to the parent fiber.\n  var completedWork = unitOfWork;\n\n  do {\n    // The current, flushed, state of this fiber is the alternate. Ideally\n    // nothing should rely on this, but relying on it here means that we don't\n    // need an additional field on the work in progress.\n    var current = completedWork.alternate;\n    var returnFiber = completedWork.return; // Check if the work completed or if something threw.\n\n    if ((completedWork.flags & Incomplete) === NoFlags) {\n      setCurrentFiber(completedWork);\n      var next = void 0;\n\n      if ( (completedWork.mode & ProfileMode) === NoMode) {\n        next = completeWork(current, completedWork, subtreeRenderLanes);\n      } else {\n        startProfilerTimer(completedWork);\n        next = completeWork(current, completedWork, subtreeRenderLanes); // Update render duration assuming we didn't error.\n\n        stopProfilerTimerIfRunningAndRecordDelta(completedWork, false);\n      }\n\n      resetCurrentFiber();\n\n      if (next !== null) {\n        // Completing this fiber spawned new work. Work on that next.\n        workInProgress = next;\n        return;\n      }\n    } else {\n      // This fiber did not complete because something threw. Pop values off\n      // the stack without entering the complete phase. If this is a boundary,\n      // capture values if possible.\n      var _next = unwindWork(current, completedWork); // Because this fiber did not complete, don't reset its lanes.\n\n\n      if (_next !== null) {\n        // If completing this work spawned new work, do that next. We'll come\n        // back here again.\n        // Since we're restarting, remove anything that is not a host effect\n        // from the effect tag.\n        _next.flags &= HostEffectMask;\n        workInProgress = _next;\n        return;\n      }\n\n      if ( (completedWork.mode & ProfileMode) !== NoMode) {\n        // Record the render duration for the fiber that errored.\n        stopProfilerTimerIfRunningAndRecordDelta(completedWork, false); // Include the time spent working on failed children before continuing.\n\n        var actualDuration = completedWork.actualDuration;\n        var child = completedWork.child;\n\n        while (child !== null) {\n          actualDuration += child.actualDuration;\n          child = child.sibling;\n        }\n\n        completedWork.actualDuration = actualDuration;\n      }\n\n      if (returnFiber !== null) {\n        // Mark the parent fiber as incomplete and clear its subtree flags.\n        returnFiber.flags |= Incomplete;\n        returnFiber.subtreeFlags = NoFlags;\n        returnFiber.deletions = null;\n      } else {\n        // We've unwound all the way to the root.\n        workInProgressRootExitStatus = RootDidNotComplete;\n        workInProgress = null;\n        return;\n      }\n    }\n\n    var siblingFiber = completedWork.sibling;\n\n    if (siblingFiber !== null) {\n      // If there is more work to do in this returnFiber, do that next.\n      workInProgress = siblingFiber;\n      return;\n    } // Otherwise, return to the parent\n\n\n    completedWork = returnFiber; // Update the next thing we're working on in case something throws.\n\n    workInProgress = completedWork;\n  } while (completedWork !== null); // We've reached the root.\n\n\n  if (workInProgressRootExitStatus === RootInProgress) {\n    workInProgressRootExitStatus = RootCompleted;\n  }\n}\n\nfunction commitRoot(root, recoverableErrors, transitions) {\n  // TODO: This no longer makes any sense. We already wrap the mutation and\n  // layout phases. Should be able to remove.\n  var previousUpdateLanePriority = getCurrentUpdatePriority();\n  var prevTransition = ReactCurrentBatchConfig$3.transition;\n\n  try {\n    ReactCurrentBatchConfig$3.transition = null;\n    setCurrentUpdatePriority(DiscreteEventPriority);\n    commitRootImpl(root, recoverableErrors, transitions, previousUpdateLanePriority);\n  } finally {\n    ReactCurrentBatchConfig$3.transition = prevTransition;\n    setCurrentUpdatePriority(previousUpdateLanePriority);\n  }\n\n  return null;\n}\n\nfunction commitRootImpl(root, recoverableErrors, transitions, renderPriorityLevel) {\n  do {\n    // `flushPassiveEffects` will call `flushSyncUpdateQueue` at the end, which\n    // means `flushPassiveEffects` will sometimes result in additional\n    // passive effects. So we need to keep flushing in a loop until there are\n    // no more pending effects.\n    // TODO: Might be better if `flushPassiveEffects` did not automatically\n    // flush synchronous work at the end, to avoid factoring hazards like this.\n    flushPassiveEffects();\n  } while (rootWithPendingPassiveEffects !== null);\n\n  flushRenderPhaseStrictModeWarningsInDEV();\n\n  if ((executionContext & (RenderContext | CommitContext)) !== NoContext) {\n    throw new Error('Should not already be working.');\n  }\n\n  var finishedWork = root.finishedWork;\n  var lanes = root.finishedLanes;\n\n  {\n    markCommitStarted(lanes);\n  }\n\n  if (finishedWork === null) {\n\n    {\n      markCommitStopped();\n    }\n\n    return null;\n  } else {\n    {\n      if (lanes === NoLanes) {\n        error('root.finishedLanes should not be empty during a commit. This is a ' + 'bug in React.');\n      }\n    }\n  }\n\n  root.finishedWork = null;\n  root.finishedLanes = NoLanes;\n\n  if (finishedWork === root.current) {\n    throw new Error('Cannot commit the same tree as before. This error is likely caused by ' + 'a bug in React. Please file an issue.');\n  } // commitRoot never returns a continuation; it always finishes synchronously.\n  // So we can clear these now to allow a new callback to be scheduled.\n\n\n  root.callbackNode = null;\n  root.callbackPriority = NoLane; // Update the first and last pending times on this root. The new first\n  // pending time is whatever is left on the root fiber.\n\n  var remainingLanes = mergeLanes(finishedWork.lanes, finishedWork.childLanes);\n  markRootFinished(root, remainingLanes);\n\n  if (root === workInProgressRoot) {\n    // We can reset these now that they are finished.\n    workInProgressRoot = null;\n    workInProgress = null;\n    workInProgressRootRenderLanes = NoLanes;\n  } // If there are pending passive effects, schedule a callback to process them.\n  // Do this as early as possible, so it is queued before anything else that\n  // might get scheduled in the commit phase. (See #16714.)\n  // TODO: Delete all other places that schedule the passive effect callback\n  // They're redundant.\n\n\n  if ((finishedWork.subtreeFlags & PassiveMask) !== NoFlags || (finishedWork.flags & PassiveMask) !== NoFlags) {\n    if (!rootDoesHavePassiveEffects) {\n      rootDoesHavePassiveEffects = true;\n      // to store it in pendingPassiveTransitions until they get processed\n      // We need to pass this through as an argument to commitRoot\n      // because workInProgressTransitions might have changed between\n      // the previous render and commit if we throttle the commit\n      // with setTimeout\n\n      pendingPassiveTransitions = transitions;\n      scheduleCallback$1(NormalPriority, function () {\n        flushPassiveEffects(); // This render triggered passive effects: release the root cache pool\n        // *after* passive effects fire to avoid freeing a cache pool that may\n        // be referenced by a node in the tree (HostRoot, Cache boundary etc)\n\n        return null;\n      });\n    }\n  } // Check if there are any effects in the whole tree.\n  // TODO: This is left over from the effect list implementation, where we had\n  // to check for the existence of `firstEffect` to satisfy Flow. I think the\n  // only other reason this optimization exists is because it affects profiling.\n  // Reconsider whether this is necessary.\n\n\n  var subtreeHasEffects = (finishedWork.subtreeFlags & (BeforeMutationMask | MutationMask | LayoutMask | PassiveMask)) !== NoFlags;\n  var rootHasEffect = (finishedWork.flags & (BeforeMutationMask | MutationMask | LayoutMask | PassiveMask)) !== NoFlags;\n\n  if (subtreeHasEffects || rootHasEffect) {\n    var prevTransition = ReactCurrentBatchConfig$3.transition;\n    ReactCurrentBatchConfig$3.transition = null;\n    var previousPriority = getCurrentUpdatePriority();\n    setCurrentUpdatePriority(DiscreteEventPriority);\n    var prevExecutionContext = executionContext;\n    executionContext |= CommitContext; // Reset this to null before calling lifecycles\n\n    ReactCurrentOwner$2.current = null; // The commit phase is broken into several sub-phases. We do a separate pass\n    // of the effect list for each phase: all mutation effects come before all\n    // layout effects, and so on.\n    // The first phase a \"before mutation\" phase. We use this phase to read the\n    // state of the host tree right before we mutate it. This is where\n    // getSnapshotBeforeUpdate is called.\n\n    var shouldFireAfterActiveInstanceBlur = commitBeforeMutationEffects(root, finishedWork);\n\n    {\n      // Mark the current commit time to be shared by all Profilers in this\n      // batch. This enables them to be grouped later.\n      recordCommitTime();\n    }\n\n\n    commitMutationEffects(root, finishedWork, lanes);\n\n    resetAfterCommit(root.containerInfo); // The work-in-progress tree is now the current tree. This must come after\n    // the mutation phase, so that the previous tree is still current during\n    // componentWillUnmount, but before the layout phase, so that the finished\n    // work is current during componentDidMount/Update.\n\n    root.current = finishedWork; // The next phase is the layout phase, where we call effects that read\n\n    {\n      markLayoutEffectsStarted(lanes);\n    }\n\n    commitLayoutEffects(finishedWork, root, lanes);\n\n    {\n      markLayoutEffectsStopped();\n    }\n    // opportunity to paint.\n\n\n    requestPaint();\n    executionContext = prevExecutionContext; // Reset the priority to the previous non-sync value.\n\n    setCurrentUpdatePriority(previousPriority);\n    ReactCurrentBatchConfig$3.transition = prevTransition;\n  } else {\n    // No effects.\n    root.current = finishedWork; // Measure these anyway so the flamegraph explicitly shows that there were\n    // no effects.\n    // TODO: Maybe there's a better way to report this.\n\n    {\n      recordCommitTime();\n    }\n  }\n\n  var rootDidHavePassiveEffects = rootDoesHavePassiveEffects;\n\n  if (rootDoesHavePassiveEffects) {\n    // This commit has passive effects. Stash a reference to them. But don't\n    // schedule a callback until after flushing layout work.\n    rootDoesHavePassiveEffects = false;\n    rootWithPendingPassiveEffects = root;\n    pendingPassiveEffectsLanes = lanes;\n  } else {\n\n    {\n      nestedPassiveUpdateCount = 0;\n      rootWithPassiveNestedUpdates = null;\n    }\n  } // Read this again, since an effect might have updated it\n\n\n  remainingLanes = root.pendingLanes; // Check if there's remaining work on this root\n  // TODO: This is part of the `componentDidCatch` implementation. Its purpose\n  // is to detect whether something might have called setState inside\n  // `componentDidCatch`. The mechanism is known to be flawed because `setState`\n  // inside `componentDidCatch` is itself flawed  that's why we recommend\n  // `getDerivedStateFromError` instead. However, it could be improved by\n  // checking if remainingLanes includes Sync work, instead of whether there's\n  // any work remaining at all (which would also include stuff like Suspense\n  // retries or transitions). It's been like this for a while, though, so fixing\n  // it probably isn't that urgent.\n\n  if (remainingLanes === NoLanes) {\n    // If there's no remaining work, we can clear the set of already failed\n    // error boundaries.\n    legacyErrorBoundariesThatAlreadyFailed = null;\n  }\n\n  {\n    if (!rootDidHavePassiveEffects) {\n      commitDoubleInvokeEffectsInDEV(root.current, false);\n    }\n  }\n\n  onCommitRoot(finishedWork.stateNode, renderPriorityLevel);\n\n  {\n    if (isDevToolsPresent) {\n      root.memoizedUpdaters.clear();\n    }\n  }\n\n  {\n    onCommitRoot$1();\n  } // Always call this before exiting `commitRoot`, to ensure that any\n  // additional work on this root is scheduled.\n\n\n  ensureRootIsScheduled(root, now());\n\n  if (recoverableErrors !== null) {\n    // There were errors during this render, but recovered from them without\n    // needing to surface it to the UI. We log them here.\n    var onRecoverableError = root.onRecoverableError;\n\n    for (var i = 0; i < recoverableErrors.length; i++) {\n      var recoverableError = recoverableErrors[i];\n      var componentStack = recoverableError.stack;\n      var digest = recoverableError.digest;\n      onRecoverableError(recoverableError.value, {\n        componentStack: componentStack,\n        digest: digest\n      });\n    }\n  }\n\n  if (hasUncaughtError) {\n    hasUncaughtError = false;\n    var error$1 = firstUncaughtError;\n    firstUncaughtError = null;\n    throw error$1;\n  } // If the passive effects are the result of a discrete render, flush them\n  // synchronously at the end of the current task so that the result is\n  // immediately observable. Otherwise, we assume that they are not\n  // order-dependent and do not need to be observed by external systems, so we\n  // can wait until after paint.\n  // TODO: We can optimize this by not scheduling the callback earlier. Since we\n  // currently schedule the callback in multiple places, will wait until those\n  // are consolidated.\n\n\n  if (includesSomeLane(pendingPassiveEffectsLanes, SyncLane) && root.tag !== LegacyRoot) {\n    flushPassiveEffects();\n  } // Read this again, since a passive effect might have updated it\n\n\n  remainingLanes = root.pendingLanes;\n\n  if (includesSomeLane(remainingLanes, SyncLane)) {\n    {\n      markNestedUpdateScheduled();\n    } // Count the number of times the root synchronously re-renders without\n    // finishing. If there are too many, it indicates an infinite update loop.\n\n\n    if (root === rootWithNestedUpdates) {\n      nestedUpdateCount++;\n    } else {\n      nestedUpdateCount = 0;\n      rootWithNestedUpdates = root;\n    }\n  } else {\n    nestedUpdateCount = 0;\n  } // If layout work was scheduled, flush it now.\n\n\n  flushSyncCallbacks();\n\n  {\n    markCommitStopped();\n  }\n\n  return null;\n}\n\nfunction flushPassiveEffects() {\n  // Returns whether passive effects were flushed.\n  // TODO: Combine this check with the one in flushPassiveEFfectsImpl. We should\n  // probably just combine the two functions. I believe they were only separate\n  // in the first place because we used to wrap it with\n  // `Scheduler.runWithPriority`, which accepts a function. But now we track the\n  // priority within React itself, so we can mutate the variable directly.\n  if (rootWithPendingPassiveEffects !== null) {\n    var renderPriority = lanesToEventPriority(pendingPassiveEffectsLanes);\n    var priority = lowerEventPriority(DefaultEventPriority, renderPriority);\n    var prevTransition = ReactCurrentBatchConfig$3.transition;\n    var previousPriority = getCurrentUpdatePriority();\n\n    try {\n      ReactCurrentBatchConfig$3.transition = null;\n      setCurrentUpdatePriority(priority);\n      return flushPassiveEffectsImpl();\n    } finally {\n      setCurrentUpdatePriority(previousPriority);\n      ReactCurrentBatchConfig$3.transition = prevTransition; // Once passive effects have run for the tree - giving components a\n    }\n  }\n\n  return false;\n}\nfunction enqueuePendingPassiveProfilerEffect(fiber) {\n  {\n    pendingPassiveProfilerEffects.push(fiber);\n\n    if (!rootDoesHavePassiveEffects) {\n      rootDoesHavePassiveEffects = true;\n      scheduleCallback$1(NormalPriority, function () {\n        flushPassiveEffects();\n        return null;\n      });\n    }\n  }\n}\n\nfunction flushPassiveEffectsImpl() {\n  if (rootWithPendingPassiveEffects === null) {\n    return false;\n  } // Cache and clear the transitions flag\n\n\n  var transitions = pendingPassiveTransitions;\n  pendingPassiveTransitions = null;\n  var root = rootWithPendingPassiveEffects;\n  var lanes = pendingPassiveEffectsLanes;\n  rootWithPendingPassiveEffects = null; // TODO: This is sometimes out of sync with rootWithPendingPassiveEffects.\n  // Figure out why and fix it. It's not causing any known issues (probably\n  // because it's only used for profiling), but it's a refactor hazard.\n\n  pendingPassiveEffectsLanes = NoLanes;\n\n  if ((executionContext & (RenderContext | CommitContext)) !== NoContext) {\n    throw new Error('Cannot flush passive effects while already rendering.');\n  }\n\n  {\n    isFlushingPassiveEffects = true;\n    didScheduleUpdateDuringPassiveEffects = false;\n  }\n\n  {\n    markPassiveEffectsStarted(lanes);\n  }\n\n  var prevExecutionContext = executionContext;\n  executionContext |= CommitContext;\n  commitPassiveUnmountEffects(root.current);\n  commitPassiveMountEffects(root, root.current, lanes, transitions); // TODO: Move to commitPassiveMountEffects\n\n  {\n    var profilerEffects = pendingPassiveProfilerEffects;\n    pendingPassiveProfilerEffects = [];\n\n    for (var i = 0; i < profilerEffects.length; i++) {\n      var _fiber = profilerEffects[i];\n      commitPassiveEffectDurations(root, _fiber);\n    }\n  }\n\n  {\n    markPassiveEffectsStopped();\n  }\n\n  {\n    commitDoubleInvokeEffectsInDEV(root.current, true);\n  }\n\n  executionContext = prevExecutionContext;\n  flushSyncCallbacks();\n\n  {\n    // If additional passive effects were scheduled, increment a counter. If this\n    // exceeds the limit, we'll fire a warning.\n    if (didScheduleUpdateDuringPassiveEffects) {\n      if (root === rootWithPassiveNestedUpdates) {\n        nestedPassiveUpdateCount++;\n      } else {\n        nestedPassiveUpdateCount = 0;\n        rootWithPassiveNestedUpdates = root;\n      }\n    } else {\n      nestedPassiveUpdateCount = 0;\n    }\n\n    isFlushingPassiveEffects = false;\n    didScheduleUpdateDuringPassiveEffects = false;\n  } // TODO: Move to commitPassiveMountEffects\n\n\n  onPostCommitRoot(root);\n\n  {\n    var stateNode = root.current.stateNode;\n    stateNode.effectDuration = 0;\n    stateNode.passiveEffectDuration = 0;\n  }\n\n  return true;\n}\n\nfunction isAlreadyFailedLegacyErrorBoundary(instance) {\n  return legacyErrorBoundariesThatAlreadyFailed !== null && legacyErrorBoundariesThatAlreadyFailed.has(instance);\n}\nfunction markLegacyErrorBoundaryAsFailed(instance) {\n  if (legacyErrorBoundariesThatAlreadyFailed === null) {\n    legacyErrorBoundariesThatAlreadyFailed = new Set([instance]);\n  } else {\n    legacyErrorBoundariesThatAlreadyFailed.add(instance);\n  }\n}\n\nfunction prepareToThrowUncaughtError(error) {\n  if (!hasUncaughtError) {\n    hasUncaughtError = true;\n    firstUncaughtError = error;\n  }\n}\n\nvar onUncaughtError = prepareToThrowUncaughtError;\n\nfunction captureCommitPhaseErrorOnRoot(rootFiber, sourceFiber, error) {\n  var errorInfo = createCapturedValueAtFiber(error, sourceFiber);\n  var update = createRootErrorUpdate(rootFiber, errorInfo, SyncLane);\n  var root = enqueueUpdate(rootFiber, update, SyncLane);\n  var eventTime = requestEventTime();\n\n  if (root !== null) {\n    markRootUpdated(root, SyncLane, eventTime);\n    ensureRootIsScheduled(root, eventTime);\n  }\n}\n\nfunction captureCommitPhaseError(sourceFiber, nearestMountedAncestor, error$1) {\n  {\n    reportUncaughtErrorInDEV(error$1);\n    setIsRunningInsertionEffect(false);\n  }\n\n  if (sourceFiber.tag === HostRoot) {\n    // Error was thrown at the root. There is no parent, so the root\n    // itself should capture it.\n    captureCommitPhaseErrorOnRoot(sourceFiber, sourceFiber, error$1);\n    return;\n  }\n\n  var fiber = null;\n\n  {\n    fiber = nearestMountedAncestor;\n  }\n\n  while (fiber !== null) {\n    if (fiber.tag === HostRoot) {\n      captureCommitPhaseErrorOnRoot(fiber, sourceFiber, error$1);\n      return;\n    } else if (fiber.tag === ClassComponent) {\n      var ctor = fiber.type;\n      var instance = fiber.stateNode;\n\n      if (typeof ctor.getDerivedStateFromError === 'function' || typeof instance.componentDidCatch === 'function' && !isAlreadyFailedLegacyErrorBoundary(instance)) {\n        var errorInfo = createCapturedValueAtFiber(error$1, sourceFiber);\n        var update = createClassErrorUpdate(fiber, errorInfo, SyncLane);\n        var root = enqueueUpdate(fiber, update, SyncLane);\n        var eventTime = requestEventTime();\n\n        if (root !== null) {\n          markRootUpdated(root, SyncLane, eventTime);\n          ensureRootIsScheduled(root, eventTime);\n        }\n\n        return;\n      }\n    }\n\n    fiber = fiber.return;\n  }\n\n  {\n    // TODO: Until we re-land skipUnmountedBoundaries (see #20147), this warning\n    // will fire for errors that are thrown by destroy functions inside deleted\n    // trees. What it should instead do is propagate the error to the parent of\n    // the deleted tree. In the meantime, do not add this warning to the\n    // allowlist; this is only for our internal use.\n    error('Internal React error: Attempted to capture a commit phase error ' + 'inside a detached tree. This indicates a bug in React. Likely ' + 'causes include deleting the same fiber more than once, committing an ' + 'already-finished tree, or an inconsistent return pointer.\\n\\n' + 'Error message:\\n\\n%s', error$1);\n  }\n}\nfunction pingSuspendedRoot(root, wakeable, pingedLanes) {\n  var pingCache = root.pingCache;\n\n  if (pingCache !== null) {\n    // The wakeable resolved, so we no longer need to memoize, because it will\n    // never be thrown again.\n    pingCache.delete(wakeable);\n  }\n\n  var eventTime = requestEventTime();\n  markRootPinged(root, pingedLanes);\n  warnIfSuspenseResolutionNotWrappedWithActDEV(root);\n\n  if (workInProgressRoot === root && isSubsetOfLanes(workInProgressRootRenderLanes, pingedLanes)) {\n    // Received a ping at the same priority level at which we're currently\n    // rendering. We might want to restart this render. This should mirror\n    // the logic of whether or not a root suspends once it completes.\n    // TODO: If we're rendering sync either due to Sync, Batched or expired,\n    // we should probably never restart.\n    // If we're suspended with delay, or if it's a retry, we'll always suspend\n    // so we can always restart.\n    if (workInProgressRootExitStatus === RootSuspendedWithDelay || workInProgressRootExitStatus === RootSuspended && includesOnlyRetries(workInProgressRootRenderLanes) && now() - globalMostRecentFallbackTime < FALLBACK_THROTTLE_MS) {\n      // Restart from the root.\n      prepareFreshStack(root, NoLanes);\n    } else {\n      // Even though we can't restart right now, we might get an\n      // opportunity later. So we mark this render as having a ping.\n      workInProgressRootPingedLanes = mergeLanes(workInProgressRootPingedLanes, pingedLanes);\n    }\n  }\n\n  ensureRootIsScheduled(root, eventTime);\n}\n\nfunction retryTimedOutBoundary(boundaryFiber, retryLane) {\n  // The boundary fiber (a Suspense component or SuspenseList component)\n  // previously was rendered in its fallback state. One of the promises that\n  // suspended it has resolved, which means at least part of the tree was\n  // likely unblocked. Try rendering again, at a new lanes.\n  if (retryLane === NoLane) {\n    // TODO: Assign this to `suspenseState.retryLane`? to avoid\n    // unnecessary entanglement?\n    retryLane = requestRetryLane(boundaryFiber);\n  } // TODO: Special case idle priority?\n\n\n  var eventTime = requestEventTime();\n  var root = enqueueConcurrentRenderForLane(boundaryFiber, retryLane);\n\n  if (root !== null) {\n    markRootUpdated(root, retryLane, eventTime);\n    ensureRootIsScheduled(root, eventTime);\n  }\n}\n\nfunction retryDehydratedSuspenseBoundary(boundaryFiber) {\n  var suspenseState = boundaryFiber.memoizedState;\n  var retryLane = NoLane;\n\n  if (suspenseState !== null) {\n    retryLane = suspenseState.retryLane;\n  }\n\n  retryTimedOutBoundary(boundaryFiber, retryLane);\n}\nfunction resolveRetryWakeable(boundaryFiber, wakeable) {\n  var retryLane = NoLane; // Default\n\n  var retryCache;\n\n  switch (boundaryFiber.tag) {\n    case SuspenseComponent:\n      retryCache = boundaryFiber.stateNode;\n      var suspenseState = boundaryFiber.memoizedState;\n\n      if (suspenseState !== null) {\n        retryLane = suspenseState.retryLane;\n      }\n\n      break;\n\n    case SuspenseListComponent:\n      retryCache = boundaryFiber.stateNode;\n      break;\n\n    default:\n      throw new Error('Pinged unknown suspense boundary type. ' + 'This is probably a bug in React.');\n  }\n\n  if (retryCache !== null) {\n    // The wakeable resolved, so we no longer need to memoize, because it will\n    // never be thrown again.\n    retryCache.delete(wakeable);\n  }\n\n  retryTimedOutBoundary(boundaryFiber, retryLane);\n} // Computes the next Just Noticeable Difference (JND) boundary.\n// The theory is that a person can't tell the difference between small differences in time.\n// Therefore, if we wait a bit longer than necessary that won't translate to a noticeable\n// difference in the experience. However, waiting for longer might mean that we can avoid\n// showing an intermediate loading state. The longer we have already waited, the harder it\n// is to tell small differences in time. Therefore, the longer we've already waited,\n// the longer we can wait additionally. At some point we have to give up though.\n// We pick a train model where the next boundary commits at a consistent schedule.\n// These particular numbers are vague estimates. We expect to adjust them based on research.\n\nfunction jnd(timeElapsed) {\n  return timeElapsed < 120 ? 120 : timeElapsed < 480 ? 480 : timeElapsed < 1080 ? 1080 : timeElapsed < 1920 ? 1920 : timeElapsed < 3000 ? 3000 : timeElapsed < 4320 ? 4320 : ceil(timeElapsed / 1960) * 1960;\n}\n\nfunction checkForNestedUpdates() {\n  if (nestedUpdateCount > NESTED_UPDATE_LIMIT) {\n    nestedUpdateCount = 0;\n    rootWithNestedUpdates = null;\n    throw new Error('Maximum update depth exceeded. This can happen when a component ' + 'repeatedly calls setState inside componentWillUpdate or ' + 'componentDidUpdate. React limits the number of nested updates to ' + 'prevent infinite loops.');\n  }\n\n  {\n    if (nestedPassiveUpdateCount > NESTED_PASSIVE_UPDATE_LIMIT) {\n      nestedPassiveUpdateCount = 0;\n      rootWithPassiveNestedUpdates = null;\n\n      error('Maximum update depth exceeded. This can happen when a component ' + \"calls setState inside useEffect, but useEffect either doesn't \" + 'have a dependency array, or one of the dependencies changes on ' + 'every render.');\n    }\n  }\n}\n\nfunction flushRenderPhaseStrictModeWarningsInDEV() {\n  {\n    ReactStrictModeWarnings.flushLegacyContextWarning();\n\n    {\n      ReactStrictModeWarnings.flushPendingUnsafeLifecycleWarnings();\n    }\n  }\n}\n\nfunction commitDoubleInvokeEffectsInDEV(fiber, hasPassiveEffects) {\n  {\n    // TODO (StrictEffects) Should we set a marker on the root if it contains strict effects\n    // so we don't traverse unnecessarily? similar to subtreeFlags but just at the root level.\n    // Maybe not a big deal since this is DEV only behavior.\n    setCurrentFiber(fiber);\n    invokeEffectsInDev(fiber, MountLayoutDev, invokeLayoutEffectUnmountInDEV);\n\n    if (hasPassiveEffects) {\n      invokeEffectsInDev(fiber, MountPassiveDev, invokePassiveEffectUnmountInDEV);\n    }\n\n    invokeEffectsInDev(fiber, MountLayoutDev, invokeLayoutEffectMountInDEV);\n\n    if (hasPassiveEffects) {\n      invokeEffectsInDev(fiber, MountPassiveDev, invokePassiveEffectMountInDEV);\n    }\n\n    resetCurrentFiber();\n  }\n}\n\nfunction invokeEffectsInDev(firstChild, fiberFlags, invokeEffectFn) {\n  {\n    // We don't need to re-check StrictEffectsMode here.\n    // This function is only called if that check has already passed.\n    var current = firstChild;\n    var subtreeRoot = null;\n\n    while (current !== null) {\n      var primarySubtreeFlag = current.subtreeFlags & fiberFlags;\n\n      if (current !== subtreeRoot && current.child !== null && primarySubtreeFlag !== NoFlags) {\n        current = current.child;\n      } else {\n        if ((current.flags & fiberFlags) !== NoFlags) {\n          invokeEffectFn(current);\n        }\n\n        if (current.sibling !== null) {\n          current = current.sibling;\n        } else {\n          current = subtreeRoot = current.return;\n        }\n      }\n    }\n  }\n}\n\nvar didWarnStateUpdateForNotYetMountedComponent = null;\nfunction warnAboutUpdateOnNotYetMountedFiberInDEV(fiber) {\n  {\n    if ((executionContext & RenderContext) !== NoContext) {\n      // We let the other warning about render phase updates deal with this one.\n      return;\n    }\n\n    if (!(fiber.mode & ConcurrentMode)) {\n      return;\n    }\n\n    var tag = fiber.tag;\n\n    if (tag !== IndeterminateComponent && tag !== HostRoot && tag !== ClassComponent && tag !== FunctionComponent && tag !== ForwardRef && tag !== MemoComponent && tag !== SimpleMemoComponent) {\n      // Only warn for user-defined components, not internal ones like Suspense.\n      return;\n    } // We show the whole stack but dedupe on the top component's name because\n    // the problematic code almost always lies inside that component.\n\n\n    var componentName = getComponentNameFromFiber(fiber) || 'ReactComponent';\n\n    if (didWarnStateUpdateForNotYetMountedComponent !== null) {\n      if (didWarnStateUpdateForNotYetMountedComponent.has(componentName)) {\n        return;\n      }\n\n      didWarnStateUpdateForNotYetMountedComponent.add(componentName);\n    } else {\n      didWarnStateUpdateForNotYetMountedComponent = new Set([componentName]);\n    }\n\n    var previousFiber = current;\n\n    try {\n      setCurrentFiber(fiber);\n\n      error(\"Can't perform a React state update on a component that hasn't mounted yet. \" + 'This indicates that you have a side-effect in your render function that ' + 'asynchronously later calls tries to update the component. Move this work to ' + 'useEffect instead.');\n    } finally {\n      if (previousFiber) {\n        setCurrentFiber(fiber);\n      } else {\n        resetCurrentFiber();\n      }\n    }\n  }\n}\nvar beginWork$1;\n\n{\n  var dummyFiber = null;\n\n  beginWork$1 = function (current, unitOfWork, lanes) {\n    // If a component throws an error, we replay it again in a synchronously\n    // dispatched event, so that the debugger will treat it as an uncaught\n    // error See ReactErrorUtils for more information.\n    // Before entering the begin phase, copy the work-in-progress onto a dummy\n    // fiber. If beginWork throws, we'll use this to reset the state.\n    var originalWorkInProgressCopy = assignFiberPropertiesInDEV(dummyFiber, unitOfWork);\n\n    try {\n      return beginWork(current, unitOfWork, lanes);\n    } catch (originalError) {\n      if (didSuspendOrErrorWhileHydratingDEV() || originalError !== null && typeof originalError === 'object' && typeof originalError.then === 'function') {\n        // Don't replay promises.\n        // Don't replay errors if we are hydrating and have already suspended or handled an error\n        throw originalError;\n      } // Keep this code in sync with handleError; any changes here must have\n      // corresponding changes there.\n\n\n      resetContextDependencies();\n      resetHooksAfterThrow(); // Don't reset current debug fiber, since we're about to work on the\n      // same fiber again.\n      // Unwind the failed stack frame\n\n      unwindInterruptedWork(current, unitOfWork); // Restore the original properties of the fiber.\n\n      assignFiberPropertiesInDEV(unitOfWork, originalWorkInProgressCopy);\n\n      if ( unitOfWork.mode & ProfileMode) {\n        // Reset the profiler timer.\n        startProfilerTimer(unitOfWork);\n      } // Run beginWork again.\n\n\n      invokeGuardedCallback(null, beginWork, null, current, unitOfWork, lanes);\n\n      if (hasCaughtError()) {\n        var replayError = clearCaughtError();\n\n        if (typeof replayError === 'object' && replayError !== null && replayError._suppressLogging && typeof originalError === 'object' && originalError !== null && !originalError._suppressLogging) {\n          // If suppressed, let the flag carry over to the original error which is the one we'll rethrow.\n          originalError._suppressLogging = true;\n        }\n      } // We always throw the original error in case the second render pass is not idempotent.\n      // This can happen if a memoized function or CommonJS module doesn't throw after first invocation.\n\n\n      throw originalError;\n    }\n  };\n}\n\nvar didWarnAboutUpdateInRender = false;\nvar didWarnAboutUpdateInRenderForAnotherComponent;\n\n{\n  didWarnAboutUpdateInRenderForAnotherComponent = new Set();\n}\n\nfunction warnAboutRenderPhaseUpdatesInDEV(fiber) {\n  {\n    if (isRendering && !getIsUpdatingOpaqueValueInRenderPhaseInDEV()) {\n      switch (fiber.tag) {\n        case FunctionComponent:\n        case ForwardRef:\n        case SimpleMemoComponent:\n          {\n            var renderingComponentName = workInProgress && getComponentNameFromFiber(workInProgress) || 'Unknown'; // Dedupe by the rendering component because it's the one that needs to be fixed.\n\n            var dedupeKey = renderingComponentName;\n\n            if (!didWarnAboutUpdateInRenderForAnotherComponent.has(dedupeKey)) {\n              didWarnAboutUpdateInRenderForAnotherComponent.add(dedupeKey);\n              var setStateComponentName = getComponentNameFromFiber(fiber) || 'Unknown';\n\n              error('Cannot update a component (`%s`) while rendering a ' + 'different component (`%s`). To locate the bad setState() call inside `%s`, ' + 'follow the stack trace as described in https://reactjs.org/link/setstate-in-render', setStateComponentName, renderingComponentName, renderingComponentName);\n            }\n\n            break;\n          }\n\n        case ClassComponent:\n          {\n            if (!didWarnAboutUpdateInRender) {\n              error('Cannot update during an existing state transition (such as ' + 'within `render`). Render methods should be a pure ' + 'function of props and state.');\n\n              didWarnAboutUpdateInRender = true;\n            }\n\n            break;\n          }\n      }\n    }\n  }\n}\n\nfunction restorePendingUpdaters(root, lanes) {\n  {\n    if (isDevToolsPresent) {\n      var memoizedUpdaters = root.memoizedUpdaters;\n      memoizedUpdaters.forEach(function (schedulingFiber) {\n        addFiberToLanesMap(root, schedulingFiber, lanes);\n      }); // This function intentionally does not clear memoized updaters.\n      // Those may still be relevant to the current commit\n      // and a future one (e.g. Suspense).\n    }\n  }\n}\nvar fakeActCallbackNode = {};\n\nfunction scheduleCallback$1(priorityLevel, callback) {\n  {\n    // If we're currently inside an `act` scope, bypass Scheduler and push to\n    // the `act` queue instead.\n    var actQueue = ReactCurrentActQueue$1.current;\n\n    if (actQueue !== null) {\n      actQueue.push(callback);\n      return fakeActCallbackNode;\n    } else {\n      return scheduleCallback(priorityLevel, callback);\n    }\n  }\n}\n\nfunction cancelCallback$1(callbackNode) {\n  if ( callbackNode === fakeActCallbackNode) {\n    return;\n  } // In production, always call Scheduler. This function will be stripped out.\n\n\n  return cancelCallback(callbackNode);\n}\n\nfunction shouldForceFlushFallbacksInDEV() {\n  // Never force flush in production. This function should get stripped out.\n  return  ReactCurrentActQueue$1.current !== null;\n}\n\nfunction warnIfUpdatesNotWrappedWithActDEV(fiber) {\n  {\n    if (fiber.mode & ConcurrentMode) {\n      if (!isConcurrentActEnvironment()) {\n        // Not in an act environment. No need to warn.\n        return;\n      }\n    } else {\n      // Legacy mode has additional cases where we suppress a warning.\n      if (!isLegacyActEnvironment()) {\n        // Not in an act environment. No need to warn.\n        return;\n      }\n\n      if (executionContext !== NoContext) {\n        // Legacy mode doesn't warn if the update is batched, i.e.\n        // batchedUpdates or flushSync.\n        return;\n      }\n\n      if (fiber.tag !== FunctionComponent && fiber.tag !== ForwardRef && fiber.tag !== SimpleMemoComponent) {\n        // For backwards compatibility with pre-hooks code, legacy mode only\n        // warns for updates that originate from a hook.\n        return;\n      }\n    }\n\n    if (ReactCurrentActQueue$1.current === null) {\n      var previousFiber = current;\n\n      try {\n        setCurrentFiber(fiber);\n\n        error('An update to %s inside a test was not wrapped in act(...).\\n\\n' + 'When testing, code that causes React state updates should be ' + 'wrapped into act(...):\\n\\n' + 'act(() => {\\n' + '  /* fire events that update state */\\n' + '});\\n' + '/* assert on the output */\\n\\n' + \"This ensures that you're testing the behavior the user would see \" + 'in the browser.' + ' Learn more at https://reactjs.org/link/wrap-tests-with-act', getComponentNameFromFiber(fiber));\n      } finally {\n        if (previousFiber) {\n          setCurrentFiber(fiber);\n        } else {\n          resetCurrentFiber();\n        }\n      }\n    }\n  }\n}\n\nfunction warnIfSuspenseResolutionNotWrappedWithActDEV(root) {\n  {\n    if (root.tag !== LegacyRoot && isConcurrentActEnvironment() && ReactCurrentActQueue$1.current === null) {\n      error('A suspended resource finished loading inside a test, but the event ' + 'was not wrapped in act(...).\\n\\n' + 'When testing, code that resolves suspended data should be wrapped ' + 'into act(...):\\n\\n' + 'act(() => {\\n' + '  /* finish loading suspended data */\\n' + '});\\n' + '/* assert on the output */\\n\\n' + \"This ensures that you're testing the behavior the user would see \" + 'in the browser.' + ' Learn more at https://reactjs.org/link/wrap-tests-with-act');\n    }\n  }\n}\n\nfunction setIsRunningInsertionEffect(isRunning) {\n  {\n    isRunningInsertionEffect = isRunning;\n  }\n}\n\n/* eslint-disable react-internal/prod-error-codes */\nvar resolveFamily = null; // $FlowFixMe Flow gets confused by a WeakSet feature check below.\n\nvar failedBoundaries = null;\nvar setRefreshHandler = function (handler) {\n  {\n    resolveFamily = handler;\n  }\n};\nfunction resolveFunctionForHotReloading(type) {\n  {\n    if (resolveFamily === null) {\n      // Hot reloading is disabled.\n      return type;\n    }\n\n    var family = resolveFamily(type);\n\n    if (family === undefined) {\n      return type;\n    } // Use the latest known implementation.\n\n\n    return family.current;\n  }\n}\nfunction resolveClassForHotReloading(type) {\n  // No implementation differences.\n  return resolveFunctionForHotReloading(type);\n}\nfunction resolveForwardRefForHotReloading(type) {\n  {\n    if (resolveFamily === null) {\n      // Hot reloading is disabled.\n      return type;\n    }\n\n    var family = resolveFamily(type);\n\n    if (family === undefined) {\n      // Check if we're dealing with a real forwardRef. Don't want to crash early.\n      if (type !== null && type !== undefined && typeof type.render === 'function') {\n        // ForwardRef is special because its resolved .type is an object,\n        // but it's possible that we only have its inner render function in the map.\n        // If that inner render function is different, we'll build a new forwardRef type.\n        var currentRender = resolveFunctionForHotReloading(type.render);\n\n        if (type.render !== currentRender) {\n          var syntheticType = {\n            $$typeof: REACT_FORWARD_REF_TYPE,\n            render: currentRender\n          };\n\n          if (type.displayName !== undefined) {\n            syntheticType.displayName = type.displayName;\n          }\n\n          return syntheticType;\n        }\n      }\n\n      return type;\n    } // Use the latest known implementation.\n\n\n    return family.current;\n  }\n}\nfunction isCompatibleFamilyForHotReloading(fiber, element) {\n  {\n    if (resolveFamily === null) {\n      // Hot reloading is disabled.\n      return false;\n    }\n\n    var prevType = fiber.elementType;\n    var nextType = element.type; // If we got here, we know types aren't === equal.\n\n    var needsCompareFamilies = false;\n    var $$typeofNextType = typeof nextType === 'object' && nextType !== null ? nextType.$$typeof : null;\n\n    switch (fiber.tag) {\n      case ClassComponent:\n        {\n          if (typeof nextType === 'function') {\n            needsCompareFamilies = true;\n          }\n\n          break;\n        }\n\n      case FunctionComponent:\n        {\n          if (typeof nextType === 'function') {\n            needsCompareFamilies = true;\n          } else if ($$typeofNextType === REACT_LAZY_TYPE) {\n            // We don't know the inner type yet.\n            // We're going to assume that the lazy inner type is stable,\n            // and so it is sufficient to avoid reconciling it away.\n            // We're not going to unwrap or actually use the new lazy type.\n            needsCompareFamilies = true;\n          }\n\n          break;\n        }\n\n      case ForwardRef:\n        {\n          if ($$typeofNextType === REACT_FORWARD_REF_TYPE) {\n            needsCompareFamilies = true;\n          } else if ($$typeofNextType === REACT_LAZY_TYPE) {\n            needsCompareFamilies = true;\n          }\n\n          break;\n        }\n\n      case MemoComponent:\n      case SimpleMemoComponent:\n        {\n          if ($$typeofNextType === REACT_MEMO_TYPE) {\n            // TODO: if it was but can no longer be simple,\n            // we shouldn't set this.\n            needsCompareFamilies = true;\n          } else if ($$typeofNextType === REACT_LAZY_TYPE) {\n            needsCompareFamilies = true;\n          }\n\n          break;\n        }\n\n      default:\n        return false;\n    } // Check if both types have a family and it's the same one.\n\n\n    if (needsCompareFamilies) {\n      // Note: memo() and forwardRef() we'll compare outer rather than inner type.\n      // This means both of them need to be registered to preserve state.\n      // If we unwrapped and compared the inner types for wrappers instead,\n      // then we would risk falsely saying two separate memo(Foo)\n      // calls are equivalent because they wrap the same Foo function.\n      var prevFamily = resolveFamily(prevType);\n\n      if (prevFamily !== undefined && prevFamily === resolveFamily(nextType)) {\n        return true;\n      }\n    }\n\n    return false;\n  }\n}\nfunction markFailedErrorBoundaryForHotReloading(fiber) {\n  {\n    if (resolveFamily === null) {\n      // Hot reloading is disabled.\n      return;\n    }\n\n    if (typeof WeakSet !== 'function') {\n      return;\n    }\n\n    if (failedBoundaries === null) {\n      failedBoundaries = new WeakSet();\n    }\n\n    failedBoundaries.add(fiber);\n  }\n}\nvar scheduleRefresh = function (root, update) {\n  {\n    if (resolveFamily === null) {\n      // Hot reloading is disabled.\n      return;\n    }\n\n    var staleFamilies = update.staleFamilies,\n        updatedFamilies = update.updatedFamilies;\n    flushPassiveEffects();\n    flushSync(function () {\n      scheduleFibersWithFamiliesRecursively(root.current, updatedFamilies, staleFamilies);\n    });\n  }\n};\nvar scheduleRoot = function (root, element) {\n  {\n    if (root.context !== emptyContextObject) {\n      // Super edge case: root has a legacy _renderSubtree context\n      // but we don't know the parentComponent so we can't pass it.\n      // Just ignore. We'll delete this with _renderSubtree code path later.\n      return;\n    }\n\n    flushPassiveEffects();\n    flushSync(function () {\n      updateContainer(element, root, null, null);\n    });\n  }\n};\n\nfunction scheduleFibersWithFamiliesRecursively(fiber, updatedFamilies, staleFamilies) {\n  {\n    var alternate = fiber.alternate,\n        child = fiber.child,\n        sibling = fiber.sibling,\n        tag = fiber.tag,\n        type = fiber.type;\n    var candidateType = null;\n\n    switch (tag) {\n      case FunctionComponent:\n      case SimpleMemoComponent:\n      case ClassComponent:\n        candidateType = type;\n        break;\n\n      case ForwardRef:\n        candidateType = type.render;\n        break;\n    }\n\n    if (resolveFamily === null) {\n      throw new Error('Expected resolveFamily to be set during hot reload.');\n    }\n\n    var needsRender = false;\n    var needsRemount = false;\n\n    if (candidateType !== null) {\n      var family = resolveFamily(candidateType);\n\n      if (family !== undefined) {\n        if (staleFamilies.has(family)) {\n          needsRemount = true;\n        } else if (updatedFamilies.has(family)) {\n          if (tag === ClassComponent) {\n            needsRemount = true;\n          } else {\n            needsRender = true;\n          }\n        }\n      }\n    }\n\n    if (failedBoundaries !== null) {\n      if (failedBoundaries.has(fiber) || alternate !== null && failedBoundaries.has(alternate)) {\n        needsRemount = true;\n      }\n    }\n\n    if (needsRemount) {\n      fiber._debugNeedsRemount = true;\n    }\n\n    if (needsRemount || needsRender) {\n      var _root = enqueueConcurrentRenderForLane(fiber, SyncLane);\n\n      if (_root !== null) {\n        scheduleUpdateOnFiber(_root, fiber, SyncLane, NoTimestamp);\n      }\n    }\n\n    if (child !== null && !needsRemount) {\n      scheduleFibersWithFamiliesRecursively(child, updatedFamilies, staleFamilies);\n    }\n\n    if (sibling !== null) {\n      scheduleFibersWithFamiliesRecursively(sibling, updatedFamilies, staleFamilies);\n    }\n  }\n}\n\nvar findHostInstancesForRefresh = function (root, families) {\n  {\n    var hostInstances = new Set();\n    var types = new Set(families.map(function (family) {\n      return family.current;\n    }));\n    findHostInstancesForMatchingFibersRecursively(root.current, types, hostInstances);\n    return hostInstances;\n  }\n};\n\nfunction findHostInstancesForMatchingFibersRecursively(fiber, types, hostInstances) {\n  {\n    var child = fiber.child,\n        sibling = fiber.sibling,\n        tag = fiber.tag,\n        type = fiber.type;\n    var candidateType = null;\n\n    switch (tag) {\n      case FunctionComponent:\n      case SimpleMemoComponent:\n      case ClassComponent:\n        candidateType = type;\n        break;\n\n      case ForwardRef:\n        candidateType = type.render;\n        break;\n    }\n\n    var didMatch = false;\n\n    if (candidateType !== null) {\n      if (types.has(candidateType)) {\n        didMatch = true;\n      }\n    }\n\n    if (didMatch) {\n      // We have a match. This only drills down to the closest host components.\n      // There's no need to search deeper because for the purpose of giving\n      // visual feedback, \"flashing\" outermost parent rectangles is sufficient.\n      findHostInstancesForFiberShallowly(fiber, hostInstances);\n    } else {\n      // If there's no match, maybe there will be one further down in the child tree.\n      if (child !== null) {\n        findHostInstancesForMatchingFibersRecursively(child, types, hostInstances);\n      }\n    }\n\n    if (sibling !== null) {\n      findHostInstancesForMatchingFibersRecursively(sibling, types, hostInstances);\n    }\n  }\n}\n\nfunction findHostInstancesForFiberShallowly(fiber, hostInstances) {\n  {\n    var foundHostInstances = findChildHostInstancesForFiberShallowly(fiber, hostInstances);\n\n    if (foundHostInstances) {\n      return;\n    } // If we didn't find any host children, fallback to closest host parent.\n\n\n    var node = fiber;\n\n    while (true) {\n      switch (node.tag) {\n        case HostComponent:\n          hostInstances.add(node.stateNode);\n          return;\n\n        case HostPortal:\n          hostInstances.add(node.stateNode.containerInfo);\n          return;\n\n        case HostRoot:\n          hostInstances.add(node.stateNode.containerInfo);\n          return;\n      }\n\n      if (node.return === null) {\n        throw new Error('Expected to reach root first.');\n      }\n\n      node = node.return;\n    }\n  }\n}\n\nfunction findChildHostInstancesForFiberShallowly(fiber, hostInstances) {\n  {\n    var node = fiber;\n    var foundHostInstances = false;\n\n    while (true) {\n      if (node.tag === HostComponent) {\n        // We got a match.\n        foundHostInstances = true;\n        hostInstances.add(node.stateNode); // There may still be more, so keep searching.\n      } else if (node.child !== null) {\n        node.child.return = node;\n        node = node.child;\n        continue;\n      }\n\n      if (node === fiber) {\n        return foundHostInstances;\n      }\n\n      while (node.sibling === null) {\n        if (node.return === null || node.return === fiber) {\n          return foundHostInstances;\n        }\n\n        node = node.return;\n      }\n\n      node.sibling.return = node.return;\n      node = node.sibling;\n    }\n  }\n\n  return false;\n}\n\nvar hasBadMapPolyfill;\n\n{\n  hasBadMapPolyfill = false;\n\n  try {\n    var nonExtensibleObject = Object.preventExtensions({});\n    /* eslint-disable no-new */\n\n    new Map([[nonExtensibleObject, null]]);\n    new Set([nonExtensibleObject]);\n    /* eslint-enable no-new */\n  } catch (e) {\n    // TODO: Consider warning about bad polyfills\n    hasBadMapPolyfill = true;\n  }\n}\n\nfunction FiberNode(tag, pendingProps, key, mode) {\n  // Instance\n  this.tag = tag;\n  this.key = key;\n  this.elementType = null;\n  this.type = null;\n  this.stateNode = null; // Fiber\n\n  this.return = null;\n  this.child = null;\n  this.sibling = null;\n  this.index = 0;\n  this.ref = null;\n  this.pendingProps = pendingProps;\n  this.memoizedProps = null;\n  this.updateQueue = null;\n  this.memoizedState = null;\n  this.dependencies = null;\n  this.mode = mode; // Effects\n\n  this.flags = NoFlags;\n  this.subtreeFlags = NoFlags;\n  this.deletions = null;\n  this.lanes = NoLanes;\n  this.childLanes = NoLanes;\n  this.alternate = null;\n\n  {\n    // Note: The following is done to avoid a v8 performance cliff.\n    //\n    // Initializing the fields below to smis and later updating them with\n    // double values will cause Fibers to end up having separate shapes.\n    // This behavior/bug has something to do with Object.preventExtension().\n    // Fortunately this only impacts DEV builds.\n    // Unfortunately it makes React unusably slow for some applications.\n    // To work around this, initialize the fields below with doubles.\n    //\n    // Learn more about this here:\n    // https://github.com/facebook/react/issues/14365\n    // https://bugs.chromium.org/p/v8/issues/detail?id=8538\n    this.actualDuration = Number.NaN;\n    this.actualStartTime = Number.NaN;\n    this.selfBaseDuration = Number.NaN;\n    this.treeBaseDuration = Number.NaN; // It's okay to replace the initial doubles with smis after initialization.\n    // This won't trigger the performance cliff mentioned above,\n    // and it simplifies other profiler code (including DevTools).\n\n    this.actualDuration = 0;\n    this.actualStartTime = -1;\n    this.selfBaseDuration = 0;\n    this.treeBaseDuration = 0;\n  }\n\n  {\n    // This isn't directly used but is handy for debugging internals:\n    this._debugSource = null;\n    this._debugOwner = null;\n    this._debugNeedsRemount = false;\n    this._debugHookTypes = null;\n\n    if (!hasBadMapPolyfill && typeof Object.preventExtensions === 'function') {\n      Object.preventExtensions(this);\n    }\n  }\n} // This is a constructor function, rather than a POJO constructor, still\n// please ensure we do the following:\n// 1) Nobody should add any instance methods on this. Instance methods can be\n//    more difficult to predict when they get optimized and they are almost\n//    never inlined properly in static compilers.\n// 2) Nobody should rely on `instanceof Fiber` for type testing. We should\n//    always know when it is a fiber.\n// 3) We might want to experiment with using numeric keys since they are easier\n//    to optimize in a non-JIT environment.\n// 4) We can easily go from a constructor to a createFiber object literal if that\n//    is faster.\n// 5) It should be easy to port this to a C struct and keep a C implementation\n//    compatible.\n\n\nvar createFiber = function (tag, pendingProps, key, mode) {\n  // $FlowFixMe: the shapes are exact here but Flow doesn't like constructors\n  return new FiberNode(tag, pendingProps, key, mode);\n};\n\nfunction shouldConstruct$1(Component) {\n  var prototype = Component.prototype;\n  return !!(prototype && prototype.isReactComponent);\n}\n\nfunction isSimpleFunctionComponent(type) {\n  return typeof type === 'function' && !shouldConstruct$1(type) && type.defaultProps === undefined;\n}\nfunction resolveLazyComponentTag(Component) {\n  if (typeof Component === 'function') {\n    return shouldConstruct$1(Component) ? ClassComponent : FunctionComponent;\n  } else if (Component !== undefined && Component !== null) {\n    var $$typeof = Component.$$typeof;\n\n    if ($$typeof === REACT_FORWARD_REF_TYPE) {\n      return ForwardRef;\n    }\n\n    if ($$typeof === REACT_MEMO_TYPE) {\n      return MemoComponent;\n    }\n  }\n\n  return IndeterminateComponent;\n} // This is used to create an alternate fiber to do work on.\n\nfunction createWorkInProgress(current, pendingProps) {\n  var workInProgress = current.alternate;\n\n  if (workInProgress === null) {\n    // We use a double buffering pooling technique because we know that we'll\n    // only ever need at most two versions of a tree. We pool the \"other\" unused\n    // node that we're free to reuse. This is lazily created to avoid allocating\n    // extra objects for things that are never updated. It also allow us to\n    // reclaim the extra memory if needed.\n    workInProgress = createFiber(current.tag, pendingProps, current.key, current.mode);\n    workInProgress.elementType = current.elementType;\n    workInProgress.type = current.type;\n    workInProgress.stateNode = current.stateNode;\n\n    {\n      // DEV-only fields\n      workInProgress._debugSource = current._debugSource;\n      workInProgress._debugOwner = current._debugOwner;\n      workInProgress._debugHookTypes = current._debugHookTypes;\n    }\n\n    workInProgress.alternate = current;\n    current.alternate = workInProgress;\n  } else {\n    workInProgress.pendingProps = pendingProps; // Needed because Blocks store data on type.\n\n    workInProgress.type = current.type; // We already have an alternate.\n    // Reset the effect tag.\n\n    workInProgress.flags = NoFlags; // The effects are no longer valid.\n\n    workInProgress.subtreeFlags = NoFlags;\n    workInProgress.deletions = null;\n\n    {\n      // We intentionally reset, rather than copy, actualDuration & actualStartTime.\n      // This prevents time from endlessly accumulating in new commits.\n      // This has the downside of resetting values for different priority renders,\n      // But works for yielding (the common case) and should support resuming.\n      workInProgress.actualDuration = 0;\n      workInProgress.actualStartTime = -1;\n    }\n  } // Reset all effects except static ones.\n  // Static effects are not specific to a render.\n\n\n  workInProgress.flags = current.flags & StaticMask;\n  workInProgress.childLanes = current.childLanes;\n  workInProgress.lanes = current.lanes;\n  workInProgress.child = current.child;\n  workInProgress.memoizedProps = current.memoizedProps;\n  workInProgress.memoizedState = current.memoizedState;\n  workInProgress.updateQueue = current.updateQueue; // Clone the dependencies object. This is mutated during the render phase, so\n  // it cannot be shared with the current fiber.\n\n  var currentDependencies = current.dependencies;\n  workInProgress.dependencies = currentDependencies === null ? null : {\n    lanes: currentDependencies.lanes,\n    firstContext: currentDependencies.firstContext\n  }; // These will be overridden during the parent's reconciliation\n\n  workInProgress.sibling = current.sibling;\n  workInProgress.index = current.index;\n  workInProgress.ref = current.ref;\n\n  {\n    workInProgress.selfBaseDuration = current.selfBaseDuration;\n    workInProgress.treeBaseDuration = current.treeBaseDuration;\n  }\n\n  {\n    workInProgress._debugNeedsRemount = current._debugNeedsRemount;\n\n    switch (workInProgress.tag) {\n      case IndeterminateComponent:\n      case FunctionComponent:\n      case SimpleMemoComponent:\n        workInProgress.type = resolveFunctionForHotReloading(current.type);\n        break;\n\n      case ClassComponent:\n        workInProgress.type = resolveClassForHotReloading(current.type);\n        break;\n\n      case ForwardRef:\n        workInProgress.type = resolveForwardRefForHotReloading(current.type);\n        break;\n    }\n  }\n\n  return workInProgress;\n} // Used to reuse a Fiber for a second pass.\n\nfunction resetWorkInProgress(workInProgress, renderLanes) {\n  // This resets the Fiber to what createFiber or createWorkInProgress would\n  // have set the values to before during the first pass. Ideally this wouldn't\n  // be necessary but unfortunately many code paths reads from the workInProgress\n  // when they should be reading from current and writing to workInProgress.\n  // We assume pendingProps, index, key, ref, return are still untouched to\n  // avoid doing another reconciliation.\n  // Reset the effect flags but keep any Placement tags, since that's something\n  // that child fiber is setting, not the reconciliation.\n  workInProgress.flags &= StaticMask | Placement; // The effects are no longer valid.\n\n  var current = workInProgress.alternate;\n\n  if (current === null) {\n    // Reset to createFiber's initial values.\n    workInProgress.childLanes = NoLanes;\n    workInProgress.lanes = renderLanes;\n    workInProgress.child = null;\n    workInProgress.subtreeFlags = NoFlags;\n    workInProgress.memoizedProps = null;\n    workInProgress.memoizedState = null;\n    workInProgress.updateQueue = null;\n    workInProgress.dependencies = null;\n    workInProgress.stateNode = null;\n\n    {\n      // Note: We don't reset the actualTime counts. It's useful to accumulate\n      // actual time across multiple render passes.\n      workInProgress.selfBaseDuration = 0;\n      workInProgress.treeBaseDuration = 0;\n    }\n  } else {\n    // Reset to the cloned values that createWorkInProgress would've.\n    workInProgress.childLanes = current.childLanes;\n    workInProgress.lanes = current.lanes;\n    workInProgress.child = current.child;\n    workInProgress.subtreeFlags = NoFlags;\n    workInProgress.deletions = null;\n    workInProgress.memoizedProps = current.memoizedProps;\n    workInProgress.memoizedState = current.memoizedState;\n    workInProgress.updateQueue = current.updateQueue; // Needed because Blocks store data on type.\n\n    workInProgress.type = current.type; // Clone the dependencies object. This is mutated during the render phase, so\n    // it cannot be shared with the current fiber.\n\n    var currentDependencies = current.dependencies;\n    workInProgress.dependencies = currentDependencies === null ? null : {\n      lanes: currentDependencies.lanes,\n      firstContext: currentDependencies.firstContext\n    };\n\n    {\n      // Note: We don't reset the actualTime counts. It's useful to accumulate\n      // actual time across multiple render passes.\n      workInProgress.selfBaseDuration = current.selfBaseDuration;\n      workInProgress.treeBaseDuration = current.treeBaseDuration;\n    }\n  }\n\n  return workInProgress;\n}\nfunction createHostRootFiber(tag, isStrictMode, concurrentUpdatesByDefaultOverride) {\n  var mode;\n\n  if (tag === ConcurrentRoot) {\n    mode = ConcurrentMode;\n\n    if (isStrictMode === true) {\n      mode |= StrictLegacyMode;\n\n      {\n        mode |= StrictEffectsMode;\n      }\n    }\n  } else {\n    mode = NoMode;\n  }\n\n  if ( isDevToolsPresent) {\n    // Always collect profile timings when DevTools are present.\n    // This enables DevTools to start capturing timing at any point\n    // Without some nodes in the tree having empty base times.\n    mode |= ProfileMode;\n  }\n\n  return createFiber(HostRoot, null, null, mode);\n}\nfunction createFiberFromTypeAndProps(type, // React$ElementType\nkey, pendingProps, owner, mode, lanes) {\n  var fiberTag = IndeterminateComponent; // The resolved type is set if we know what the final type will be. I.e. it's not lazy.\n\n  var resolvedType = type;\n\n  if (typeof type === 'function') {\n    if (shouldConstruct$1(type)) {\n      fiberTag = ClassComponent;\n\n      {\n        resolvedType = resolveClassForHotReloading(resolvedType);\n      }\n    } else {\n      {\n        resolvedType = resolveFunctionForHotReloading(resolvedType);\n      }\n    }\n  } else if (typeof type === 'string') {\n    fiberTag = HostComponent;\n  } else {\n    getTag: switch (type) {\n      case REACT_FRAGMENT_TYPE:\n        return createFiberFromFragment(pendingProps.children, mode, lanes, key);\n\n      case REACT_STRICT_MODE_TYPE:\n        fiberTag = Mode;\n        mode |= StrictLegacyMode;\n\n        if ( (mode & ConcurrentMode) !== NoMode) {\n          // Strict effects should never run on legacy roots\n          mode |= StrictEffectsMode;\n        }\n\n        break;\n\n      case REACT_PROFILER_TYPE:\n        return createFiberFromProfiler(pendingProps, mode, lanes, key);\n\n      case REACT_SUSPENSE_TYPE:\n        return createFiberFromSuspense(pendingProps, mode, lanes, key);\n\n      case REACT_SUSPENSE_LIST_TYPE:\n        return createFiberFromSuspenseList(pendingProps, mode, lanes, key);\n\n      case REACT_OFFSCREEN_TYPE:\n        return createFiberFromOffscreen(pendingProps, mode, lanes, key);\n\n      case REACT_LEGACY_HIDDEN_TYPE:\n\n      // eslint-disable-next-line no-fallthrough\n\n      case REACT_SCOPE_TYPE:\n\n      // eslint-disable-next-line no-fallthrough\n\n      case REACT_CACHE_TYPE:\n\n      // eslint-disable-next-line no-fallthrough\n\n      case REACT_TRACING_MARKER_TYPE:\n\n      // eslint-disable-next-line no-fallthrough\n\n      case REACT_DEBUG_TRACING_MODE_TYPE:\n\n      // eslint-disable-next-line no-fallthrough\n\n      default:\n        {\n          if (typeof type === 'object' && type !== null) {\n            switch (type.$$typeof) {\n              case REACT_PROVIDER_TYPE:\n                fiberTag = ContextProvider;\n                break getTag;\n\n              case REACT_CONTEXT_TYPE:\n                // This is a consumer\n                fiberTag = ContextConsumer;\n                break getTag;\n\n              case REACT_FORWARD_REF_TYPE:\n                fiberTag = ForwardRef;\n\n                {\n                  resolvedType = resolveForwardRefForHotReloading(resolvedType);\n                }\n\n                break getTag;\n\n              case REACT_MEMO_TYPE:\n                fiberTag = MemoComponent;\n                break getTag;\n\n              case REACT_LAZY_TYPE:\n                fiberTag = LazyComponent;\n                resolvedType = null;\n                break getTag;\n            }\n          }\n\n          var info = '';\n\n          {\n            if (type === undefined || typeof type === 'object' && type !== null && Object.keys(type).length === 0) {\n              info += ' You likely forgot to export your component from the file ' + \"it's defined in, or you might have mixed up default and \" + 'named imports.';\n            }\n\n            var ownerName = owner ? getComponentNameFromFiber(owner) : null;\n\n            if (ownerName) {\n              info += '\\n\\nCheck the render method of `' + ownerName + '`.';\n            }\n          }\n\n          throw new Error('Element type is invalid: expected a string (for built-in ' + 'components) or a class/function (for composite components) ' + (\"but got: \" + (type == null ? type : typeof type) + \".\" + info));\n        }\n    }\n  }\n\n  var fiber = createFiber(fiberTag, pendingProps, key, mode);\n  fiber.elementType = type;\n  fiber.type = resolvedType;\n  fiber.lanes = lanes;\n\n  {\n    fiber._debugOwner = owner;\n  }\n\n  return fiber;\n}\nfunction createFiberFromElement(element, mode, lanes) {\n  var owner = null;\n\n  {\n    owner = element._owner;\n  }\n\n  var type = element.type;\n  var key = element.key;\n  var pendingProps = element.props;\n  var fiber = createFiberFromTypeAndProps(type, key, pendingProps, owner, mode, lanes);\n\n  {\n    fiber._debugSource = element._source;\n    fiber._debugOwner = element._owner;\n  }\n\n  return fiber;\n}\nfunction createFiberFromFragment(elements, mode, lanes, key) {\n  var fiber = createFiber(Fragment, elements, key, mode);\n  fiber.lanes = lanes;\n  return fiber;\n}\n\nfunction createFiberFromProfiler(pendingProps, mode, lanes, key) {\n  {\n    if (typeof pendingProps.id !== 'string') {\n      error('Profiler must specify an \"id\" of type `string` as a prop. Received the type `%s` instead.', typeof pendingProps.id);\n    }\n  }\n\n  var fiber = createFiber(Profiler, pendingProps, key, mode | ProfileMode);\n  fiber.elementType = REACT_PROFILER_TYPE;\n  fiber.lanes = lanes;\n\n  {\n    fiber.stateNode = {\n      effectDuration: 0,\n      passiveEffectDuration: 0\n    };\n  }\n\n  return fiber;\n}\n\nfunction createFiberFromSuspense(pendingProps, mode, lanes, key) {\n  var fiber = createFiber(SuspenseComponent, pendingProps, key, mode);\n  fiber.elementType = REACT_SUSPENSE_TYPE;\n  fiber.lanes = lanes;\n  return fiber;\n}\nfunction createFiberFromSuspenseList(pendingProps, mode, lanes, key) {\n  var fiber = createFiber(SuspenseListComponent, pendingProps, key, mode);\n  fiber.elementType = REACT_SUSPENSE_LIST_TYPE;\n  fiber.lanes = lanes;\n  return fiber;\n}\nfunction createFiberFromOffscreen(pendingProps, mode, lanes, key) {\n  var fiber = createFiber(OffscreenComponent, pendingProps, key, mode);\n  fiber.elementType = REACT_OFFSCREEN_TYPE;\n  fiber.lanes = lanes;\n  var primaryChildInstance = {\n    isHidden: false\n  };\n  fiber.stateNode = primaryChildInstance;\n  return fiber;\n}\nfunction createFiberFromText(content, mode, lanes) {\n  var fiber = createFiber(HostText, content, null, mode);\n  fiber.lanes = lanes;\n  return fiber;\n}\nfunction createFiberFromHostInstanceForDeletion() {\n  var fiber = createFiber(HostComponent, null, null, NoMode);\n  fiber.elementType = 'DELETED';\n  return fiber;\n}\nfunction createFiberFromDehydratedFragment(dehydratedNode) {\n  var fiber = createFiber(DehydratedFragment, null, null, NoMode);\n  fiber.stateNode = dehydratedNode;\n  return fiber;\n}\nfunction createFiberFromPortal(portal, mode, lanes) {\n  var pendingProps = portal.children !== null ? portal.children : [];\n  var fiber = createFiber(HostPortal, pendingProps, portal.key, mode);\n  fiber.lanes = lanes;\n  fiber.stateNode = {\n    containerInfo: portal.containerInfo,\n    pendingChildren: null,\n    // Used by persistent updates\n    implementation: portal.implementation\n  };\n  return fiber;\n} // Used for stashing WIP properties to replay failed work in DEV.\n\nfunction assignFiberPropertiesInDEV(target, source) {\n  if (target === null) {\n    // This Fiber's initial properties will always be overwritten.\n    // We only use a Fiber to ensure the same hidden class so DEV isn't slow.\n    target = createFiber(IndeterminateComponent, null, null, NoMode);\n  } // This is intentionally written as a list of all properties.\n  // We tried to use Object.assign() instead but this is called in\n  // the hottest path, and Object.assign() was too slow:\n  // https://github.com/facebook/react/issues/12502\n  // This code is DEV-only so size is not a concern.\n\n\n  target.tag = source.tag;\n  target.key = source.key;\n  target.elementType = source.elementType;\n  target.type = source.type;\n  target.stateNode = source.stateNode;\n  target.return = source.return;\n  target.child = source.child;\n  target.sibling = source.sibling;\n  target.index = source.index;\n  target.ref = source.ref;\n  target.pendingProps = source.pendingProps;\n  target.memoizedProps = source.memoizedProps;\n  target.updateQueue = source.updateQueue;\n  target.memoizedState = source.memoizedState;\n  target.dependencies = source.dependencies;\n  target.mode = source.mode;\n  target.flags = source.flags;\n  target.subtreeFlags = source.subtreeFlags;\n  target.deletions = source.deletions;\n  target.lanes = source.lanes;\n  target.childLanes = source.childLanes;\n  target.alternate = source.alternate;\n\n  {\n    target.actualDuration = source.actualDuration;\n    target.actualStartTime = source.actualStartTime;\n    target.selfBaseDuration = source.selfBaseDuration;\n    target.treeBaseDuration = source.treeBaseDuration;\n  }\n\n  target._debugSource = source._debugSource;\n  target._debugOwner = source._debugOwner;\n  target._debugNeedsRemount = source._debugNeedsRemount;\n  target._debugHookTypes = source._debugHookTypes;\n  return target;\n}\n\nfunction FiberRootNode(containerInfo, tag, hydrate, identifierPrefix, onRecoverableError) {\n  this.tag = tag;\n  this.containerInfo = containerInfo;\n  this.pendingChildren = null;\n  this.current = null;\n  this.pingCache = null;\n  this.finishedWork = null;\n  this.timeoutHandle = noTimeout;\n  this.context = null;\n  this.pendingContext = null;\n  this.callbackNode = null;\n  this.callbackPriority = NoLane;\n  this.eventTimes = createLaneMap(NoLanes);\n  this.expirationTimes = createLaneMap(NoTimestamp);\n  this.pendingLanes = NoLanes;\n  this.suspendedLanes = NoLanes;\n  this.pingedLanes = NoLanes;\n  this.expiredLanes = NoLanes;\n  this.mutableReadLanes = NoLanes;\n  this.finishedLanes = NoLanes;\n  this.entangledLanes = NoLanes;\n  this.entanglements = createLaneMap(NoLanes);\n  this.identifierPrefix = identifierPrefix;\n  this.onRecoverableError = onRecoverableError;\n\n  {\n    this.mutableSourceEagerHydrationData = null;\n  }\n\n  {\n    this.effectDuration = 0;\n    this.passiveEffectDuration = 0;\n  }\n\n  {\n    this.memoizedUpdaters = new Set();\n    var pendingUpdatersLaneMap = this.pendingUpdatersLaneMap = [];\n\n    for (var _i = 0; _i < TotalLanes; _i++) {\n      pendingUpdatersLaneMap.push(new Set());\n    }\n  }\n\n  {\n    switch (tag) {\n      case ConcurrentRoot:\n        this._debugRootType = hydrate ? 'hydrateRoot()' : 'createRoot()';\n        break;\n\n      case LegacyRoot:\n        this._debugRootType = hydrate ? 'hydrate()' : 'render()';\n        break;\n    }\n  }\n}\n\nfunction createFiberRoot(containerInfo, tag, hydrate, initialChildren, hydrationCallbacks, isStrictMode, concurrentUpdatesByDefaultOverride, // TODO: We have several of these arguments that are conceptually part of the\n// host config, but because they are passed in at runtime, we have to thread\n// them through the root constructor. Perhaps we should put them all into a\n// single type, like a DynamicHostConfig that is defined by the renderer.\nidentifierPrefix, onRecoverableError, transitionCallbacks) {\n  var root = new FiberRootNode(containerInfo, tag, hydrate, identifierPrefix, onRecoverableError);\n  // stateNode is any.\n\n\n  var uninitializedFiber = createHostRootFiber(tag, isStrictMode);\n  root.current = uninitializedFiber;\n  uninitializedFiber.stateNode = root;\n\n  {\n    var _initialState = {\n      element: initialChildren,\n      isDehydrated: hydrate,\n      cache: null,\n      // not enabled yet\n      transitions: null,\n      pendingSuspenseBoundaries: null\n    };\n    uninitializedFiber.memoizedState = _initialState;\n  }\n\n  initializeUpdateQueue(uninitializedFiber);\n  return root;\n}\n\nvar ReactVersion = '18.2.0';\n\nfunction createPortal(children, containerInfo, // TODO: figure out the API for cross-renderer implementation.\nimplementation) {\n  var key = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;\n\n  {\n    checkKeyStringCoercion(key);\n  }\n\n  return {\n    // This tag allow us to uniquely identify this as a React Portal\n    $$typeof: REACT_PORTAL_TYPE,\n    key: key == null ? null : '' + key,\n    children: children,\n    containerInfo: containerInfo,\n    implementation: implementation\n  };\n}\n\nvar didWarnAboutNestedUpdates;\nvar didWarnAboutFindNodeInStrictMode;\n\n{\n  didWarnAboutNestedUpdates = false;\n  didWarnAboutFindNodeInStrictMode = {};\n}\n\nfunction getContextForSubtree(parentComponent) {\n  if (!parentComponent) {\n    return emptyContextObject;\n  }\n\n  var fiber = get(parentComponent);\n  var parentContext = findCurrentUnmaskedContext(fiber);\n\n  if (fiber.tag === ClassComponent) {\n    var Component = fiber.type;\n\n    if (isContextProvider(Component)) {\n      return processChildContext(fiber, Component, parentContext);\n    }\n  }\n\n  return parentContext;\n}\n\nfunction findHostInstanceWithWarning(component, methodName) {\n  {\n    var fiber = get(component);\n\n    if (fiber === undefined) {\n      if (typeof component.render === 'function') {\n        throw new Error('Unable to find node on an unmounted component.');\n      } else {\n        var keys = Object.keys(component).join(',');\n        throw new Error(\"Argument appears to not be a ReactComponent. Keys: \" + keys);\n      }\n    }\n\n    var hostFiber = findCurrentHostFiber(fiber);\n\n    if (hostFiber === null) {\n      return null;\n    }\n\n    if (hostFiber.mode & StrictLegacyMode) {\n      var componentName = getComponentNameFromFiber(fiber) || 'Component';\n\n      if (!didWarnAboutFindNodeInStrictMode[componentName]) {\n        didWarnAboutFindNodeInStrictMode[componentName] = true;\n        var previousFiber = current;\n\n        try {\n          setCurrentFiber(hostFiber);\n\n          if (fiber.mode & StrictLegacyMode) {\n            error('%s is deprecated in StrictMode. ' + '%s was passed an instance of %s which is inside StrictMode. ' + 'Instead, add a ref directly to the element you want to reference. ' + 'Learn more about using refs safely here: ' + 'https://reactjs.org/link/strict-mode-find-node', methodName, methodName, componentName);\n          } else {\n            error('%s is deprecated in StrictMode. ' + '%s was passed an instance of %s which renders StrictMode children. ' + 'Instead, add a ref directly to the element you want to reference. ' + 'Learn more about using refs safely here: ' + 'https://reactjs.org/link/strict-mode-find-node', methodName, methodName, componentName);\n          }\n        } finally {\n          // Ideally this should reset to previous but this shouldn't be called in\n          // render and there's another warning for that anyway.\n          if (previousFiber) {\n            setCurrentFiber(previousFiber);\n          } else {\n            resetCurrentFiber();\n          }\n        }\n      }\n    }\n\n    return hostFiber.stateNode;\n  }\n}\n\nfunction createContainer(containerInfo, tag, hydrationCallbacks, isStrictMode, concurrentUpdatesByDefaultOverride, identifierPrefix, onRecoverableError, transitionCallbacks) {\n  var hydrate = false;\n  var initialChildren = null;\n  return createFiberRoot(containerInfo, tag, hydrate, initialChildren, hydrationCallbacks, isStrictMode, concurrentUpdatesByDefaultOverride, identifierPrefix, onRecoverableError);\n}\nfunction createHydrationContainer(initialChildren, // TODO: Remove `callback` when we delete legacy mode.\ncallback, containerInfo, tag, hydrationCallbacks, isStrictMode, concurrentUpdatesByDefaultOverride, identifierPrefix, onRecoverableError, transitionCallbacks) {\n  var hydrate = true;\n  var root = createFiberRoot(containerInfo, tag, hydrate, initialChildren, hydrationCallbacks, isStrictMode, concurrentUpdatesByDefaultOverride, identifierPrefix, onRecoverableError); // TODO: Move this to FiberRoot constructor\n\n  root.context = getContextForSubtree(null); // Schedule the initial render. In a hydration root, this is different from\n  // a regular update because the initial render must match was was rendered\n  // on the server.\n  // NOTE: This update intentionally doesn't have a payload. We're only using\n  // the update to schedule work on the root fiber (and, for legacy roots, to\n  // enqueue the callback if one is provided).\n\n  var current = root.current;\n  var eventTime = requestEventTime();\n  var lane = requestUpdateLane(current);\n  var update = createUpdate(eventTime, lane);\n  update.callback = callback !== undefined && callback !== null ? callback : null;\n  enqueueUpdate(current, update, lane);\n  scheduleInitialHydrationOnRoot(root, lane, eventTime);\n  return root;\n}\nfunction updateContainer(element, container, parentComponent, callback) {\n  {\n    onScheduleRoot(container, element);\n  }\n\n  var current$1 = container.current;\n  var eventTime = requestEventTime();\n  var lane = requestUpdateLane(current$1);\n\n  {\n    markRenderScheduled(lane);\n  }\n\n  var context = getContextForSubtree(parentComponent);\n\n  if (container.context === null) {\n    container.context = context;\n  } else {\n    container.pendingContext = context;\n  }\n\n  {\n    if (isRendering && current !== null && !didWarnAboutNestedUpdates) {\n      didWarnAboutNestedUpdates = true;\n\n      error('Render methods should be a pure function of props and state; ' + 'triggering nested component updates from render is not allowed. ' + 'If necessary, trigger nested updates in componentDidUpdate.\\n\\n' + 'Check the render method of %s.', getComponentNameFromFiber(current) || 'Unknown');\n    }\n  }\n\n  var update = createUpdate(eventTime, lane); // Caution: React DevTools currently depends on this property\n  // being called \"element\".\n\n  update.payload = {\n    element: element\n  };\n  callback = callback === undefined ? null : callback;\n\n  if (callback !== null) {\n    {\n      if (typeof callback !== 'function') {\n        error('render(...): Expected the last optional `callback` argument to be a ' + 'function. Instead received: %s.', callback);\n      }\n    }\n\n    update.callback = callback;\n  }\n\n  var root = enqueueUpdate(current$1, update, lane);\n\n  if (root !== null) {\n    scheduleUpdateOnFiber(root, current$1, lane, eventTime);\n    entangleTransitions(root, current$1, lane);\n  }\n\n  return lane;\n}\nfunction getPublicRootInstance(container) {\n  var containerFiber = container.current;\n\n  if (!containerFiber.child) {\n    return null;\n  }\n\n  switch (containerFiber.child.tag) {\n    case HostComponent:\n      return getPublicInstance(containerFiber.child.stateNode);\n\n    default:\n      return containerFiber.child.stateNode;\n  }\n}\nfunction attemptSynchronousHydration$1(fiber) {\n  switch (fiber.tag) {\n    case HostRoot:\n      {\n        var root = fiber.stateNode;\n\n        if (isRootDehydrated(root)) {\n          // Flush the first scheduled \"update\".\n          var lanes = getHighestPriorityPendingLanes(root);\n          flushRoot(root, lanes);\n        }\n\n        break;\n      }\n\n    case SuspenseComponent:\n      {\n        flushSync(function () {\n          var root = enqueueConcurrentRenderForLane(fiber, SyncLane);\n\n          if (root !== null) {\n            var eventTime = requestEventTime();\n            scheduleUpdateOnFiber(root, fiber, SyncLane, eventTime);\n          }\n        }); // If we're still blocked after this, we need to increase\n        // the priority of any promises resolving within this\n        // boundary so that they next attempt also has higher pri.\n\n        var retryLane = SyncLane;\n        markRetryLaneIfNotHydrated(fiber, retryLane);\n        break;\n      }\n  }\n}\n\nfunction markRetryLaneImpl(fiber, retryLane) {\n  var suspenseState = fiber.memoizedState;\n\n  if (suspenseState !== null && suspenseState.dehydrated !== null) {\n    suspenseState.retryLane = higherPriorityLane(suspenseState.retryLane, retryLane);\n  }\n} // Increases the priority of thenables when they resolve within this boundary.\n\n\nfunction markRetryLaneIfNotHydrated(fiber, retryLane) {\n  markRetryLaneImpl(fiber, retryLane);\n  var alternate = fiber.alternate;\n\n  if (alternate) {\n    markRetryLaneImpl(alternate, retryLane);\n  }\n}\nfunction attemptContinuousHydration$1(fiber) {\n  if (fiber.tag !== SuspenseComponent) {\n    // We ignore HostRoots here because we can't increase\n    // their priority and they should not suspend on I/O,\n    // since you have to wrap anything that might suspend in\n    // Suspense.\n    return;\n  }\n\n  var lane = SelectiveHydrationLane;\n  var root = enqueueConcurrentRenderForLane(fiber, lane);\n\n  if (root !== null) {\n    var eventTime = requestEventTime();\n    scheduleUpdateOnFiber(root, fiber, lane, eventTime);\n  }\n\n  markRetryLaneIfNotHydrated(fiber, lane);\n}\nfunction attemptHydrationAtCurrentPriority$1(fiber) {\n  if (fiber.tag !== SuspenseComponent) {\n    // We ignore HostRoots here because we can't increase\n    // their priority other than synchronously flush it.\n    return;\n  }\n\n  var lane = requestUpdateLane(fiber);\n  var root = enqueueConcurrentRenderForLane(fiber, lane);\n\n  if (root !== null) {\n    var eventTime = requestEventTime();\n    scheduleUpdateOnFiber(root, fiber, lane, eventTime);\n  }\n\n  markRetryLaneIfNotHydrated(fiber, lane);\n}\nfunction findHostInstanceWithNoPortals(fiber) {\n  var hostFiber = findCurrentHostFiberWithNoPortals(fiber);\n\n  if (hostFiber === null) {\n    return null;\n  }\n\n  return hostFiber.stateNode;\n}\n\nvar shouldErrorImpl = function (fiber) {\n  return null;\n};\n\nfunction shouldError(fiber) {\n  return shouldErrorImpl(fiber);\n}\n\nvar shouldSuspendImpl = function (fiber) {\n  return false;\n};\n\nfunction shouldSuspend(fiber) {\n  return shouldSuspendImpl(fiber);\n}\nvar overrideHookState = null;\nvar overrideHookStateDeletePath = null;\nvar overrideHookStateRenamePath = null;\nvar overrideProps = null;\nvar overridePropsDeletePath = null;\nvar overridePropsRenamePath = null;\nvar scheduleUpdate = null;\nvar setErrorHandler = null;\nvar setSuspenseHandler = null;\n\n{\n  var copyWithDeleteImpl = function (obj, path, index) {\n    var key = path[index];\n    var updated = isArray(obj) ? obj.slice() : assign({}, obj);\n\n    if (index + 1 === path.length) {\n      if (isArray(updated)) {\n        updated.splice(key, 1);\n      } else {\n        delete updated[key];\n      }\n\n      return updated;\n    } // $FlowFixMe number or string is fine here\n\n\n    updated[key] = copyWithDeleteImpl(obj[key], path, index + 1);\n    return updated;\n  };\n\n  var copyWithDelete = function (obj, path) {\n    return copyWithDeleteImpl(obj, path, 0);\n  };\n\n  var copyWithRenameImpl = function (obj, oldPath, newPath, index) {\n    var oldKey = oldPath[index];\n    var updated = isArray(obj) ? obj.slice() : assign({}, obj);\n\n    if (index + 1 === oldPath.length) {\n      var newKey = newPath[index]; // $FlowFixMe number or string is fine here\n\n      updated[newKey] = updated[oldKey];\n\n      if (isArray(updated)) {\n        updated.splice(oldKey, 1);\n      } else {\n        delete updated[oldKey];\n      }\n    } else {\n      // $FlowFixMe number or string is fine here\n      updated[oldKey] = copyWithRenameImpl( // $FlowFixMe number or string is fine here\n      obj[oldKey], oldPath, newPath, index + 1);\n    }\n\n    return updated;\n  };\n\n  var copyWithRename = function (obj, oldPath, newPath) {\n    if (oldPath.length !== newPath.length) {\n      warn('copyWithRename() expects paths of the same length');\n\n      return;\n    } else {\n      for (var i = 0; i < newPath.length - 1; i++) {\n        if (oldPath[i] !== newPath[i]) {\n          warn('copyWithRename() expects paths to be the same except for the deepest key');\n\n          return;\n        }\n      }\n    }\n\n    return copyWithRenameImpl(obj, oldPath, newPath, 0);\n  };\n\n  var copyWithSetImpl = function (obj, path, index, value) {\n    if (index >= path.length) {\n      return value;\n    }\n\n    var key = path[index];\n    var updated = isArray(obj) ? obj.slice() : assign({}, obj); // $FlowFixMe number or string is fine here\n\n    updated[key] = copyWithSetImpl(obj[key], path, index + 1, value);\n    return updated;\n  };\n\n  var copyWithSet = function (obj, path, value) {\n    return copyWithSetImpl(obj, path, 0, value);\n  };\n\n  var findHook = function (fiber, id) {\n    // For now, the \"id\" of stateful hooks is just the stateful hook index.\n    // This may change in the future with e.g. nested hooks.\n    var currentHook = fiber.memoizedState;\n\n    while (currentHook !== null && id > 0) {\n      currentHook = currentHook.next;\n      id--;\n    }\n\n    return currentHook;\n  }; // Support DevTools editable values for useState and useReducer.\n\n\n  overrideHookState = function (fiber, id, path, value) {\n    var hook = findHook(fiber, id);\n\n    if (hook !== null) {\n      var newState = copyWithSet(hook.memoizedState, path, value);\n      hook.memoizedState = newState;\n      hook.baseState = newState; // We aren't actually adding an update to the queue,\n      // because there is no update we can add for useReducer hooks that won't trigger an error.\n      // (There's no appropriate action type for DevTools overrides.)\n      // As a result though, React will see the scheduled update as a noop and bailout.\n      // Shallow cloning props works as a workaround for now to bypass the bailout check.\n\n      fiber.memoizedProps = assign({}, fiber.memoizedProps);\n      var root = enqueueConcurrentRenderForLane(fiber, SyncLane);\n\n      if (root !== null) {\n        scheduleUpdateOnFiber(root, fiber, SyncLane, NoTimestamp);\n      }\n    }\n  };\n\n  overrideHookStateDeletePath = function (fiber, id, path) {\n    var hook = findHook(fiber, id);\n\n    if (hook !== null) {\n      var newState = copyWithDelete(hook.memoizedState, path);\n      hook.memoizedState = newState;\n      hook.baseState = newState; // We aren't actually adding an update to the queue,\n      // because there is no update we can add for useReducer hooks that won't trigger an error.\n      // (There's no appropriate action type for DevTools overrides.)\n      // As a result though, React will see the scheduled update as a noop and bailout.\n      // Shallow cloning props works as a workaround for now to bypass the bailout check.\n\n      fiber.memoizedProps = assign({}, fiber.memoizedProps);\n      var root = enqueueConcurrentRenderForLane(fiber, SyncLane);\n\n      if (root !== null) {\n        scheduleUpdateOnFiber(root, fiber, SyncLane, NoTimestamp);\n      }\n    }\n  };\n\n  overrideHookStateRenamePath = function (fiber, id, oldPath, newPath) {\n    var hook = findHook(fiber, id);\n\n    if (hook !== null) {\n      var newState = copyWithRename(hook.memoizedState, oldPath, newPath);\n      hook.memoizedState = newState;\n      hook.baseState = newState; // We aren't actually adding an update to the queue,\n      // because there is no update we can add for useReducer hooks that won't trigger an error.\n      // (There's no appropriate action type for DevTools overrides.)\n      // As a result though, React will see the scheduled update as a noop and bailout.\n      // Shallow cloning props works as a workaround for now to bypass the bailout check.\n\n      fiber.memoizedProps = assign({}, fiber.memoizedProps);\n      var root = enqueueConcurrentRenderForLane(fiber, SyncLane);\n\n      if (root !== null) {\n        scheduleUpdateOnFiber(root, fiber, SyncLane, NoTimestamp);\n      }\n    }\n  }; // Support DevTools props for function components, forwardRef, memo, host components, etc.\n\n\n  overrideProps = function (fiber, path, value) {\n    fiber.pendingProps = copyWithSet(fiber.memoizedProps, path, value);\n\n    if (fiber.alternate) {\n      fiber.alternate.pendingProps = fiber.pendingProps;\n    }\n\n    var root = enqueueConcurrentRenderForLane(fiber, SyncLane);\n\n    if (root !== null) {\n      scheduleUpdateOnFiber(root, fiber, SyncLane, NoTimestamp);\n    }\n  };\n\n  overridePropsDeletePath = function (fiber, path) {\n    fiber.pendingProps = copyWithDelete(fiber.memoizedProps, path);\n\n    if (fiber.alternate) {\n      fiber.alternate.pendingProps = fiber.pendingProps;\n    }\n\n    var root = enqueueConcurrentRenderForLane(fiber, SyncLane);\n\n    if (root !== null) {\n      scheduleUpdateOnFiber(root, fiber, SyncLane, NoTimestamp);\n    }\n  };\n\n  overridePropsRenamePath = function (fiber, oldPath, newPath) {\n    fiber.pendingProps = copyWithRename(fiber.memoizedProps, oldPath, newPath);\n\n    if (fiber.alternate) {\n      fiber.alternate.pendingProps = fiber.pendingProps;\n    }\n\n    var root = enqueueConcurrentRenderForLane(fiber, SyncLane);\n\n    if (root !== null) {\n      scheduleUpdateOnFiber(root, fiber, SyncLane, NoTimestamp);\n    }\n  };\n\n  scheduleUpdate = function (fiber) {\n    var root = enqueueConcurrentRenderForLane(fiber, SyncLane);\n\n    if (root !== null) {\n      scheduleUpdateOnFiber(root, fiber, SyncLane, NoTimestamp);\n    }\n  };\n\n  setErrorHandler = function (newShouldErrorImpl) {\n    shouldErrorImpl = newShouldErrorImpl;\n  };\n\n  setSuspenseHandler = function (newShouldSuspendImpl) {\n    shouldSuspendImpl = newShouldSuspendImpl;\n  };\n}\n\nfunction findHostInstanceByFiber(fiber) {\n  var hostFiber = findCurrentHostFiber(fiber);\n\n  if (hostFiber === null) {\n    return null;\n  }\n\n  return hostFiber.stateNode;\n}\n\nfunction emptyFindFiberByHostInstance(instance) {\n  return null;\n}\n\nfunction getCurrentFiberForDevTools() {\n  return current;\n}\n\nfunction injectIntoDevTools(devToolsConfig) {\n  var findFiberByHostInstance = devToolsConfig.findFiberByHostInstance;\n  var ReactCurrentDispatcher = ReactSharedInternals.ReactCurrentDispatcher;\n  return injectInternals({\n    bundleType: devToolsConfig.bundleType,\n    version: devToolsConfig.version,\n    rendererPackageName: devToolsConfig.rendererPackageName,\n    rendererConfig: devToolsConfig.rendererConfig,\n    overrideHookState: overrideHookState,\n    overrideHookStateDeletePath: overrideHookStateDeletePath,\n    overrideHookStateRenamePath: overrideHookStateRenamePath,\n    overrideProps: overrideProps,\n    overridePropsDeletePath: overridePropsDeletePath,\n    overridePropsRenamePath: overridePropsRenamePath,\n    setErrorHandler: setErrorHandler,\n    setSuspenseHandler: setSuspenseHandler,\n    scheduleUpdate: scheduleUpdate,\n    currentDispatcherRef: ReactCurrentDispatcher,\n    findHostInstanceByFiber: findHostInstanceByFiber,\n    findFiberByHostInstance: findFiberByHostInstance || emptyFindFiberByHostInstance,\n    // React Refresh\n    findHostInstancesForRefresh:  findHostInstancesForRefresh ,\n    scheduleRefresh:  scheduleRefresh ,\n    scheduleRoot:  scheduleRoot ,\n    setRefreshHandler:  setRefreshHandler ,\n    // Enables DevTools to append owner stacks to error messages in DEV mode.\n    getCurrentFiber:  getCurrentFiberForDevTools ,\n    // Enables DevTools to detect reconciler version rather than renderer version\n    // which may not match for third party renderers.\n    reconcilerVersion: ReactVersion\n  });\n}\n\n/* global reportError */\n\nvar defaultOnRecoverableError = typeof reportError === 'function' ? // In modern browsers, reportError will dispatch an error event,\n// emulating an uncaught JavaScript error.\nreportError : function (error) {\n  // In older browsers and test environments, fallback to console.error.\n  // eslint-disable-next-line react-internal/no-production-logging\n  console['error'](error);\n};\n\nfunction ReactDOMRoot(internalRoot) {\n  this._internalRoot = internalRoot;\n}\n\nReactDOMHydrationRoot.prototype.render = ReactDOMRoot.prototype.render = function (children) {\n  var root = this._internalRoot;\n\n  if (root === null) {\n    throw new Error('Cannot update an unmounted root.');\n  }\n\n  {\n    if (typeof arguments[1] === 'function') {\n      error('render(...): does not support the second callback argument. ' + 'To execute a side effect after rendering, declare it in a component body with useEffect().');\n    } else if (isValidContainer(arguments[1])) {\n      error('You passed a container to the second argument of root.render(...). ' + \"You don't need to pass it again since you already passed it to create the root.\");\n    } else if (typeof arguments[1] !== 'undefined') {\n      error('You passed a second argument to root.render(...) but it only accepts ' + 'one argument.');\n    }\n\n    var container = root.containerInfo;\n\n    if (container.nodeType !== COMMENT_NODE) {\n      var hostInstance = findHostInstanceWithNoPortals(root.current);\n\n      if (hostInstance) {\n        if (hostInstance.parentNode !== container) {\n          error('render(...): It looks like the React-rendered content of the ' + 'root container was removed without using React. This is not ' + 'supported and will cause errors. Instead, call ' + \"root.unmount() to empty a root's container.\");\n        }\n      }\n    }\n  }\n\n  updateContainer(children, root, null, null);\n};\n\nReactDOMHydrationRoot.prototype.unmount = ReactDOMRoot.prototype.unmount = function () {\n  {\n    if (typeof arguments[0] === 'function') {\n      error('unmount(...): does not support a callback argument. ' + 'To execute a side effect after rendering, declare it in a component body with useEffect().');\n    }\n  }\n\n  var root = this._internalRoot;\n\n  if (root !== null) {\n    this._internalRoot = null;\n    var container = root.containerInfo;\n\n    {\n      if (isAlreadyRendering()) {\n        error('Attempted to synchronously unmount a root while React was already ' + 'rendering. React cannot finish unmounting the root until the ' + 'current render has completed, which may lead to a race condition.');\n      }\n    }\n\n    flushSync(function () {\n      updateContainer(null, root, null, null);\n    });\n    unmarkContainerAsRoot(container);\n  }\n};\n\nfunction createRoot(container, options) {\n  if (!isValidContainer(container)) {\n    throw new Error('createRoot(...): Target container is not a DOM element.');\n  }\n\n  warnIfReactDOMContainerInDEV(container);\n  var isStrictMode = false;\n  var concurrentUpdatesByDefaultOverride = false;\n  var identifierPrefix = '';\n  var onRecoverableError = defaultOnRecoverableError;\n  var transitionCallbacks = null;\n\n  if (options !== null && options !== undefined) {\n    {\n      if (options.hydrate) {\n        warn('hydrate through createRoot is deprecated. Use ReactDOMClient.hydrateRoot(container, <App />) instead.');\n      } else {\n        if (typeof options === 'object' && options !== null && options.$$typeof === REACT_ELEMENT_TYPE) {\n          error('You passed a JSX element to createRoot. You probably meant to ' + 'call root.render instead. ' + 'Example usage:\\n\\n' + '  let root = createRoot(domContainer);\\n' + '  root.render(<App />);');\n        }\n      }\n    }\n\n    if (options.unstable_strictMode === true) {\n      isStrictMode = true;\n    }\n\n    if (options.identifierPrefix !== undefined) {\n      identifierPrefix = options.identifierPrefix;\n    }\n\n    if (options.onRecoverableError !== undefined) {\n      onRecoverableError = options.onRecoverableError;\n    }\n\n    if (options.transitionCallbacks !== undefined) {\n      transitionCallbacks = options.transitionCallbacks;\n    }\n  }\n\n  var root = createContainer(container, ConcurrentRoot, null, isStrictMode, concurrentUpdatesByDefaultOverride, identifierPrefix, onRecoverableError);\n  markContainerAsRoot(root.current, container);\n  var rootContainerElement = container.nodeType === COMMENT_NODE ? container.parentNode : container;\n  listenToAllSupportedEvents(rootContainerElement);\n  return new ReactDOMRoot(root);\n}\n\nfunction ReactDOMHydrationRoot(internalRoot) {\n  this._internalRoot = internalRoot;\n}\n\nfunction scheduleHydration(target) {\n  if (target) {\n    queueExplicitHydrationTarget(target);\n  }\n}\n\nReactDOMHydrationRoot.prototype.unstable_scheduleHydration = scheduleHydration;\nfunction hydrateRoot(container, initialChildren, options) {\n  if (!isValidContainer(container)) {\n    throw new Error('hydrateRoot(...): Target container is not a DOM element.');\n  }\n\n  warnIfReactDOMContainerInDEV(container);\n\n  {\n    if (initialChildren === undefined) {\n      error('Must provide initial children as second argument to hydrateRoot. ' + 'Example usage: hydrateRoot(domContainer, <App />)');\n    }\n  } // For now we reuse the whole bag of options since they contain\n  // the hydration callbacks.\n\n\n  var hydrationCallbacks = options != null ? options : null; // TODO: Delete this option\n\n  var mutableSources = options != null && options.hydratedSources || null;\n  var isStrictMode = false;\n  var concurrentUpdatesByDefaultOverride = false;\n  var identifierPrefix = '';\n  var onRecoverableError = defaultOnRecoverableError;\n\n  if (options !== null && options !== undefined) {\n    if (options.unstable_strictMode === true) {\n      isStrictMode = true;\n    }\n\n    if (options.identifierPrefix !== undefined) {\n      identifierPrefix = options.identifierPrefix;\n    }\n\n    if (options.onRecoverableError !== undefined) {\n      onRecoverableError = options.onRecoverableError;\n    }\n  }\n\n  var root = createHydrationContainer(initialChildren, null, container, ConcurrentRoot, hydrationCallbacks, isStrictMode, concurrentUpdatesByDefaultOverride, identifierPrefix, onRecoverableError);\n  markContainerAsRoot(root.current, container); // This can't be a comment node since hydration doesn't work on comment nodes anyway.\n\n  listenToAllSupportedEvents(container);\n\n  if (mutableSources) {\n    for (var i = 0; i < mutableSources.length; i++) {\n      var mutableSource = mutableSources[i];\n      registerMutableSourceForHydration(root, mutableSource);\n    }\n  }\n\n  return new ReactDOMHydrationRoot(root);\n}\nfunction isValidContainer(node) {\n  return !!(node && (node.nodeType === ELEMENT_NODE || node.nodeType === DOCUMENT_NODE || node.nodeType === DOCUMENT_FRAGMENT_NODE || !disableCommentsAsDOMContainers  ));\n} // TODO: Remove this function which also includes comment nodes.\n// We only use it in places that are currently more relaxed.\n\nfunction isValidContainerLegacy(node) {\n  return !!(node && (node.nodeType === ELEMENT_NODE || node.nodeType === DOCUMENT_NODE || node.nodeType === DOCUMENT_FRAGMENT_NODE || node.nodeType === COMMENT_NODE && node.nodeValue === ' react-mount-point-unstable '));\n}\n\nfunction warnIfReactDOMContainerInDEV(container) {\n  {\n    if (container.nodeType === ELEMENT_NODE && container.tagName && container.tagName.toUpperCase() === 'BODY') {\n      error('createRoot(): Creating roots directly with document.body is ' + 'discouraged, since its children are often manipulated by third-party ' + 'scripts and browser extensions. This may lead to subtle ' + 'reconciliation issues. Try using a container element created ' + 'for your app.');\n    }\n\n    if (isContainerMarkedAsRoot(container)) {\n      if (container._reactRootContainer) {\n        error('You are calling ReactDOMClient.createRoot() on a container that was previously ' + 'passed to ReactDOM.render(). This is not supported.');\n      } else {\n        error('You are calling ReactDOMClient.createRoot() on a container that ' + 'has already been passed to createRoot() before. Instead, call ' + 'root.render() on the existing root instead if you want to update it.');\n      }\n    }\n  }\n}\n\nvar ReactCurrentOwner$3 = ReactSharedInternals.ReactCurrentOwner;\nvar topLevelUpdateWarnings;\n\n{\n  topLevelUpdateWarnings = function (container) {\n    if (container._reactRootContainer && container.nodeType !== COMMENT_NODE) {\n      var hostInstance = findHostInstanceWithNoPortals(container._reactRootContainer.current);\n\n      if (hostInstance) {\n        if (hostInstance.parentNode !== container) {\n          error('render(...): It looks like the React-rendered content of this ' + 'container was removed without using React. This is not ' + 'supported and will cause errors. Instead, call ' + 'ReactDOM.unmountComponentAtNode to empty a container.');\n        }\n      }\n    }\n\n    var isRootRenderedBySomeReact = !!container._reactRootContainer;\n    var rootEl = getReactRootElementInContainer(container);\n    var hasNonRootReactChild = !!(rootEl && getInstanceFromNode(rootEl));\n\n    if (hasNonRootReactChild && !isRootRenderedBySomeReact) {\n      error('render(...): Replacing React-rendered children with a new root ' + 'component. If you intended to update the children of this node, ' + 'you should instead have the existing children update their state ' + 'and render the new components instead of calling ReactDOM.render.');\n    }\n\n    if (container.nodeType === ELEMENT_NODE && container.tagName && container.tagName.toUpperCase() === 'BODY') {\n      error('render(): Rendering components directly into document.body is ' + 'discouraged, since its children are often manipulated by third-party ' + 'scripts and browser extensions. This may lead to subtle ' + 'reconciliation issues. Try rendering into a container element created ' + 'for your app.');\n    }\n  };\n}\n\nfunction getReactRootElementInContainer(container) {\n  if (!container) {\n    return null;\n  }\n\n  if (container.nodeType === DOCUMENT_NODE) {\n    return container.documentElement;\n  } else {\n    return container.firstChild;\n  }\n}\n\nfunction noopOnRecoverableError() {// This isn't reachable because onRecoverableError isn't called in the\n  // legacy API.\n}\n\nfunction legacyCreateRootFromDOMContainer(container, initialChildren, parentComponent, callback, isHydrationContainer) {\n  if (isHydrationContainer) {\n    if (typeof callback === 'function') {\n      var originalCallback = callback;\n\n      callback = function () {\n        var instance = getPublicRootInstance(root);\n        originalCallback.call(instance);\n      };\n    }\n\n    var root = createHydrationContainer(initialChildren, callback, container, LegacyRoot, null, // hydrationCallbacks\n    false, // isStrictMode\n    false, // concurrentUpdatesByDefaultOverride,\n    '', // identifierPrefix\n    noopOnRecoverableError);\n    container._reactRootContainer = root;\n    markContainerAsRoot(root.current, container);\n    var rootContainerElement = container.nodeType === COMMENT_NODE ? container.parentNode : container;\n    listenToAllSupportedEvents(rootContainerElement);\n    flushSync();\n    return root;\n  } else {\n    // First clear any existing content.\n    var rootSibling;\n\n    while (rootSibling = container.lastChild) {\n      container.removeChild(rootSibling);\n    }\n\n    if (typeof callback === 'function') {\n      var _originalCallback = callback;\n\n      callback = function () {\n        var instance = getPublicRootInstance(_root);\n\n        _originalCallback.call(instance);\n      };\n    }\n\n    var _root = createContainer(container, LegacyRoot, null, // hydrationCallbacks\n    false, // isStrictMode\n    false, // concurrentUpdatesByDefaultOverride,\n    '', // identifierPrefix\n    noopOnRecoverableError);\n\n    container._reactRootContainer = _root;\n    markContainerAsRoot(_root.current, container);\n\n    var _rootContainerElement = container.nodeType === COMMENT_NODE ? container.parentNode : container;\n\n    listenToAllSupportedEvents(_rootContainerElement); // Initial mount should not be batched.\n\n    flushSync(function () {\n      updateContainer(initialChildren, _root, parentComponent, callback);\n    });\n    return _root;\n  }\n}\n\nfunction warnOnInvalidCallback$1(callback, callerName) {\n  {\n    if (callback !== null && typeof callback !== 'function') {\n      error('%s(...): Expected the last optional `callback` argument to be a ' + 'function. Instead received: %s.', callerName, callback);\n    }\n  }\n}\n\nfunction legacyRenderSubtreeIntoContainer(parentComponent, children, container, forceHydrate, callback) {\n  {\n    topLevelUpdateWarnings(container);\n    warnOnInvalidCallback$1(callback === undefined ? null : callback, 'render');\n  }\n\n  var maybeRoot = container._reactRootContainer;\n  var root;\n\n  if (!maybeRoot) {\n    // Initial mount\n    root = legacyCreateRootFromDOMContainer(container, children, parentComponent, callback, forceHydrate);\n  } else {\n    root = maybeRoot;\n\n    if (typeof callback === 'function') {\n      var originalCallback = callback;\n\n      callback = function () {\n        var instance = getPublicRootInstance(root);\n        originalCallback.call(instance);\n      };\n    } // Update\n\n\n    updateContainer(children, root, parentComponent, callback);\n  }\n\n  return getPublicRootInstance(root);\n}\n\nfunction findDOMNode(componentOrElement) {\n  {\n    var owner = ReactCurrentOwner$3.current;\n\n    if (owner !== null && owner.stateNode !== null) {\n      var warnedAboutRefsInRender = owner.stateNode._warnedAboutRefsInRender;\n\n      if (!warnedAboutRefsInRender) {\n        error('%s is accessing findDOMNode inside its render(). ' + 'render() should be a pure function of props and state. It should ' + 'never access something that requires stale data from the previous ' + 'render, such as refs. Move this logic to componentDidMount and ' + 'componentDidUpdate instead.', getComponentNameFromType(owner.type) || 'A component');\n      }\n\n      owner.stateNode._warnedAboutRefsInRender = true;\n    }\n  }\n\n  if (componentOrElement == null) {\n    return null;\n  }\n\n  if (componentOrElement.nodeType === ELEMENT_NODE) {\n    return componentOrElement;\n  }\n\n  {\n    return findHostInstanceWithWarning(componentOrElement, 'findDOMNode');\n  }\n}\nfunction hydrate(element, container, callback) {\n  {\n    error('ReactDOM.hydrate is no longer supported in React 18. Use hydrateRoot ' + 'instead. Until you switch to the new API, your app will behave as ' + \"if it's running React 17. Learn \" + 'more: https://reactjs.org/link/switch-to-createroot');\n  }\n\n  if (!isValidContainerLegacy(container)) {\n    throw new Error('Target container is not a DOM element.');\n  }\n\n  {\n    var isModernRoot = isContainerMarkedAsRoot(container) && container._reactRootContainer === undefined;\n\n    if (isModernRoot) {\n      error('You are calling ReactDOM.hydrate() on a container that was previously ' + 'passed to ReactDOMClient.createRoot(). This is not supported. ' + 'Did you mean to call hydrateRoot(container, element)?');\n    }\n  } // TODO: throw or warn if we couldn't hydrate?\n\n\n  return legacyRenderSubtreeIntoContainer(null, element, container, true, callback);\n}\nfunction render(element, container, callback) {\n  {\n    error('ReactDOM.render is no longer supported in React 18. Use createRoot ' + 'instead. Until you switch to the new API, your app will behave as ' + \"if it's running React 17. Learn \" + 'more: https://reactjs.org/link/switch-to-createroot');\n  }\n\n  if (!isValidContainerLegacy(container)) {\n    throw new Error('Target container is not a DOM element.');\n  }\n\n  {\n    var isModernRoot = isContainerMarkedAsRoot(container) && container._reactRootContainer === undefined;\n\n    if (isModernRoot) {\n      error('You are calling ReactDOM.render() on a container that was previously ' + 'passed to ReactDOMClient.createRoot(). This is not supported. ' + 'Did you mean to call root.render(element)?');\n    }\n  }\n\n  return legacyRenderSubtreeIntoContainer(null, element, container, false, callback);\n}\nfunction unstable_renderSubtreeIntoContainer(parentComponent, element, containerNode, callback) {\n  {\n    error('ReactDOM.unstable_renderSubtreeIntoContainer() is no longer supported ' + 'in React 18. Consider using a portal instead. Until you switch to ' + \"the createRoot API, your app will behave as if it's running React \" + '17. Learn more: https://reactjs.org/link/switch-to-createroot');\n  }\n\n  if (!isValidContainerLegacy(containerNode)) {\n    throw new Error('Target container is not a DOM element.');\n  }\n\n  if (parentComponent == null || !has(parentComponent)) {\n    throw new Error('parentComponent must be a valid React Component');\n  }\n\n  return legacyRenderSubtreeIntoContainer(parentComponent, element, containerNode, false, callback);\n}\nfunction unmountComponentAtNode(container) {\n  if (!isValidContainerLegacy(container)) {\n    throw new Error('unmountComponentAtNode(...): Target container is not a DOM element.');\n  }\n\n  {\n    var isModernRoot = isContainerMarkedAsRoot(container) && container._reactRootContainer === undefined;\n\n    if (isModernRoot) {\n      error('You are calling ReactDOM.unmountComponentAtNode() on a container that was previously ' + 'passed to ReactDOMClient.createRoot(). This is not supported. Did you mean to call root.unmount()?');\n    }\n  }\n\n  if (container._reactRootContainer) {\n    {\n      var rootEl = getReactRootElementInContainer(container);\n      var renderedByDifferentReact = rootEl && !getInstanceFromNode(rootEl);\n\n      if (renderedByDifferentReact) {\n        error(\"unmountComponentAtNode(): The node you're attempting to unmount \" + 'was rendered by another copy of React.');\n      }\n    } // Unmount should not be batched.\n\n\n    flushSync(function () {\n      legacyRenderSubtreeIntoContainer(null, null, container, false, function () {\n        // $FlowFixMe This should probably use `delete container._reactRootContainer`\n        container._reactRootContainer = null;\n        unmarkContainerAsRoot(container);\n      });\n    }); // If you call unmountComponentAtNode twice in quick succession, you'll\n    // get `true` twice. That's probably fine?\n\n    return true;\n  } else {\n    {\n      var _rootEl = getReactRootElementInContainer(container);\n\n      var hasNonRootReactChild = !!(_rootEl && getInstanceFromNode(_rootEl)); // Check if the container itself is a React root node.\n\n      var isContainerReactRoot = container.nodeType === ELEMENT_NODE && isValidContainerLegacy(container.parentNode) && !!container.parentNode._reactRootContainer;\n\n      if (hasNonRootReactChild) {\n        error(\"unmountComponentAtNode(): The node you're attempting to unmount \" + 'was rendered by React and is not a top-level container. %s', isContainerReactRoot ? 'You may have accidentally passed in a React root node instead ' + 'of its container.' : 'Instead, have the parent component update its state and ' + 'rerender in order to remove this component.');\n      }\n    }\n\n    return false;\n  }\n}\n\nsetAttemptSynchronousHydration(attemptSynchronousHydration$1);\nsetAttemptContinuousHydration(attemptContinuousHydration$1);\nsetAttemptHydrationAtCurrentPriority(attemptHydrationAtCurrentPriority$1);\nsetGetCurrentUpdatePriority(getCurrentUpdatePriority);\nsetAttemptHydrationAtPriority(runWithPriority);\n\n{\n  if (typeof Map !== 'function' || // $FlowIssue Flow incorrectly thinks Map has no prototype\n  Map.prototype == null || typeof Map.prototype.forEach !== 'function' || typeof Set !== 'function' || // $FlowIssue Flow incorrectly thinks Set has no prototype\n  Set.prototype == null || typeof Set.prototype.clear !== 'function' || typeof Set.prototype.forEach !== 'function') {\n    error('React depends on Map and Set built-in types. Make sure that you load a ' + 'polyfill in older browsers. https://reactjs.org/link/react-polyfills');\n  }\n}\n\nsetRestoreImplementation(restoreControlledState$3);\nsetBatchingImplementation(batchedUpdates$1, discreteUpdates, flushSync);\n\nfunction createPortal$1(children, container) {\n  var key = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n\n  if (!isValidContainer(container)) {\n    throw new Error('Target container is not a DOM element.');\n  } // TODO: pass ReactDOM portal implementation as third argument\n  // $FlowFixMe The Flow type is opaque but there's no way to actually create it.\n\n\n  return createPortal(children, container, null, key);\n}\n\nfunction renderSubtreeIntoContainer(parentComponent, element, containerNode, callback) {\n  return unstable_renderSubtreeIntoContainer(parentComponent, element, containerNode, callback);\n}\n\nvar Internals = {\n  usingClientEntryPoint: false,\n  // Keep in sync with ReactTestUtils.js.\n  // This is an array for better minification.\n  Events: [getInstanceFromNode, getNodeFromInstance, getFiberCurrentPropsFromNode, enqueueStateRestore, restoreStateIfNeeded, batchedUpdates$1]\n};\n\nfunction createRoot$1(container, options) {\n  {\n    if (!Internals.usingClientEntryPoint && !false) {\n      error('You are importing createRoot from \"react-dom\" which is not supported. ' + 'You should instead import it from \"react-dom/client\".');\n    }\n  }\n\n  return createRoot(container, options);\n}\n\nfunction hydrateRoot$1(container, initialChildren, options) {\n  {\n    if (!Internals.usingClientEntryPoint && !false) {\n      error('You are importing hydrateRoot from \"react-dom\" which is not supported. ' + 'You should instead import it from \"react-dom/client\".');\n    }\n  }\n\n  return hydrateRoot(container, initialChildren, options);\n} // Overload the definition to the two valid signatures.\n// Warning, this opts-out of checking the function body.\n\n\n// eslint-disable-next-line no-redeclare\nfunction flushSync$1(fn) {\n  {\n    if (isAlreadyRendering()) {\n      error('flushSync was called from inside a lifecycle method. React cannot ' + 'flush when React is already rendering. Consider moving this call to ' + 'a scheduler task or micro task.');\n    }\n  }\n\n  return flushSync(fn);\n}\nvar foundDevTools = injectIntoDevTools({\n  findFiberByHostInstance: getClosestInstanceFromNode,\n  bundleType:  1 ,\n  version: ReactVersion,\n  rendererPackageName: 'react-dom'\n});\n\n{\n  if (!foundDevTools && canUseDOM && window.top === window.self) {\n    // If we're in Chrome or Firefox, provide a download link if not installed.\n    if (navigator.userAgent.indexOf('Chrome') > -1 && navigator.userAgent.indexOf('Edge') === -1 || navigator.userAgent.indexOf('Firefox') > -1) {\n      var protocol = window.location.protocol; // Don't warn in exotic cases like chrome-extension://.\n\n      if (/^(https?|file):$/.test(protocol)) {\n        // eslint-disable-next-line react-internal/no-production-logging\n        console.info('%cDownload the React DevTools ' + 'for a better development experience: ' + 'https://reactjs.org/link/react-devtools' + (protocol === 'file:' ? '\\nYou might need to use a local HTTP server (instead of file://): ' + 'https://reactjs.org/link/react-devtools-faq' : ''), 'font-weight:bold');\n      }\n    }\n  }\n}\n\nexports.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED = Internals;\nexports.createPortal = createPortal$1;\nexports.createRoot = createRoot$1;\nexports.findDOMNode = findDOMNode;\nexports.flushSync = flushSync$1;\nexports.hydrate = hydrate;\nexports.hydrateRoot = hydrateRoot$1;\nexports.render = render;\nexports.unmountComponentAtNode = unmountComponentAtNode;\nexports.unstable_batchedUpdates = batchedUpdates$1;\nexports.unstable_renderSubtreeIntoContainer = renderSubtreeIntoContainer;\nexports.version = ReactVersion;\n          /* global __REACT_DEVTOOLS_GLOBAL_HOOK__ */\nif (\n  typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ !== 'undefined' &&\n  typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStop ===\n    'function'\n) {\n  __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStop(new Error());\n}\n        \n  })();\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/react-dom/cjs/react-dom.development.js?");

/***/ }),

/***/ "./node_modules/react-dom/index.js":
/*!*****************************************!*\
  !*** ./node_modules/react-dom/index.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nfunction checkDCE() {\n  /* global __REACT_DEVTOOLS_GLOBAL_HOOK__ */\n  if (\n    typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ === 'undefined' ||\n    typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE !== 'function'\n  ) {\n    return;\n  }\n  if (true) {\n    // This branch is unreachable because this function is only called\n    // in production, but the condition is true only in development.\n    // Therefore if the branch is still here, dead code elimination wasn't\n    // properly applied.\n    // Don't change the message. React DevTools relies on it. Also make sure\n    // this message doesn't occur elsewhere in this function, or it will cause\n    // a false positive.\n    throw new Error('^_^');\n  }\n  try {\n    // Verify that the code above has been dead code eliminated (DCE'd).\n    __REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE(checkDCE);\n  } catch (err) {\n    // DevTools shouldn't crash React, no matter what.\n    // We should still report in case we break this code.\n    console.error(err);\n  }\n}\n\nif (false) {} else {\n  module.exports = __webpack_require__(/*! ./cjs/react-dom.development.js */ \"./node_modules/react-dom/cjs/react-dom.development.js\");\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/react-dom/index.js?");

/***/ }),

/***/ "./node_modules/react/cjs/react.development.js":
/*!*****************************************************!*\
  !*** ./node_modules/react/cjs/react.development.js ***!
  \*****************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("/* module decorator */ module = __webpack_require__.nmd(module);\n/**\n * @license React\n * react.development.js\n *\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n\n\nif (true) {\n  (function() {\n\n          'use strict';\n\n/* global __REACT_DEVTOOLS_GLOBAL_HOOK__ */\nif (\n  typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ !== 'undefined' &&\n  typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStart ===\n    'function'\n) {\n  __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStart(new Error());\n}\n          var ReactVersion = '18.2.0';\n\n// ATTENTION\n// When adding new symbols to this file,\n// Please consider also adding to 'react-devtools-shared/src/backend/ReactSymbols'\n// The Symbol used to tag the ReactElement-like types.\nvar REACT_ELEMENT_TYPE = Symbol.for('react.element');\nvar REACT_PORTAL_TYPE = Symbol.for('react.portal');\nvar REACT_FRAGMENT_TYPE = Symbol.for('react.fragment');\nvar REACT_STRICT_MODE_TYPE = Symbol.for('react.strict_mode');\nvar REACT_PROFILER_TYPE = Symbol.for('react.profiler');\nvar REACT_PROVIDER_TYPE = Symbol.for('react.provider');\nvar REACT_CONTEXT_TYPE = Symbol.for('react.context');\nvar REACT_FORWARD_REF_TYPE = Symbol.for('react.forward_ref');\nvar REACT_SUSPENSE_TYPE = Symbol.for('react.suspense');\nvar REACT_SUSPENSE_LIST_TYPE = Symbol.for('react.suspense_list');\nvar REACT_MEMO_TYPE = Symbol.for('react.memo');\nvar REACT_LAZY_TYPE = Symbol.for('react.lazy');\nvar REACT_OFFSCREEN_TYPE = Symbol.for('react.offscreen');\nvar MAYBE_ITERATOR_SYMBOL = Symbol.iterator;\nvar FAUX_ITERATOR_SYMBOL = '@@iterator';\nfunction getIteratorFn(maybeIterable) {\n  if (maybeIterable === null || typeof maybeIterable !== 'object') {\n    return null;\n  }\n\n  var maybeIterator = MAYBE_ITERATOR_SYMBOL && maybeIterable[MAYBE_ITERATOR_SYMBOL] || maybeIterable[FAUX_ITERATOR_SYMBOL];\n\n  if (typeof maybeIterator === 'function') {\n    return maybeIterator;\n  }\n\n  return null;\n}\n\n/**\n * Keeps track of the current dispatcher.\n */\nvar ReactCurrentDispatcher = {\n  /**\n   * @internal\n   * @type {ReactComponent}\n   */\n  current: null\n};\n\n/**\n * Keeps track of the current batch's configuration such as how long an update\n * should suspend for if it needs to.\n */\nvar ReactCurrentBatchConfig = {\n  transition: null\n};\n\nvar ReactCurrentActQueue = {\n  current: null,\n  // Used to reproduce behavior of `batchedUpdates` in legacy mode.\n  isBatchingLegacy: false,\n  didScheduleLegacyUpdate: false\n};\n\n/**\n * Keeps track of the current owner.\n *\n * The current owner is the component who should own any components that are\n * currently being constructed.\n */\nvar ReactCurrentOwner = {\n  /**\n   * @internal\n   * @type {ReactComponent}\n   */\n  current: null\n};\n\nvar ReactDebugCurrentFrame = {};\nvar currentExtraStackFrame = null;\nfunction setExtraStackFrame(stack) {\n  {\n    currentExtraStackFrame = stack;\n  }\n}\n\n{\n  ReactDebugCurrentFrame.setExtraStackFrame = function (stack) {\n    {\n      currentExtraStackFrame = stack;\n    }\n  }; // Stack implementation injected by the current renderer.\n\n\n  ReactDebugCurrentFrame.getCurrentStack = null;\n\n  ReactDebugCurrentFrame.getStackAddendum = function () {\n    var stack = ''; // Add an extra top frame while an element is being validated\n\n    if (currentExtraStackFrame) {\n      stack += currentExtraStackFrame;\n    } // Delegate to the injected renderer-specific implementation\n\n\n    var impl = ReactDebugCurrentFrame.getCurrentStack;\n\n    if (impl) {\n      stack += impl() || '';\n    }\n\n    return stack;\n  };\n}\n\n// -----------------------------------------------------------------------------\n\nvar enableScopeAPI = false; // Experimental Create Event Handle API.\nvar enableCacheElement = false;\nvar enableTransitionTracing = false; // No known bugs, but needs performance testing\n\nvar enableLegacyHidden = false; // Enables unstable_avoidThisFallback feature in Fiber\n// stuff. Intended to enable React core members to more easily debug scheduling\n// issues in DEV builds.\n\nvar enableDebugTracing = false; // Track which Fiber(s) schedule render work.\n\nvar ReactSharedInternals = {\n  ReactCurrentDispatcher: ReactCurrentDispatcher,\n  ReactCurrentBatchConfig: ReactCurrentBatchConfig,\n  ReactCurrentOwner: ReactCurrentOwner\n};\n\n{\n  ReactSharedInternals.ReactDebugCurrentFrame = ReactDebugCurrentFrame;\n  ReactSharedInternals.ReactCurrentActQueue = ReactCurrentActQueue;\n}\n\n// by calls to these methods by a Babel plugin.\n//\n// In PROD (or in packages without access to React internals),\n// they are left as they are instead.\n\nfunction warn(format) {\n  {\n    {\n      for (var _len = arguments.length, args = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n        args[_key - 1] = arguments[_key];\n      }\n\n      printWarning('warn', format, args);\n    }\n  }\n}\nfunction error(format) {\n  {\n    {\n      for (var _len2 = arguments.length, args = new Array(_len2 > 1 ? _len2 - 1 : 0), _key2 = 1; _key2 < _len2; _key2++) {\n        args[_key2 - 1] = arguments[_key2];\n      }\n\n      printWarning('error', format, args);\n    }\n  }\n}\n\nfunction printWarning(level, format, args) {\n  // When changing this logic, you might want to also\n  // update consoleWithStackDev.www.js as well.\n  {\n    var ReactDebugCurrentFrame = ReactSharedInternals.ReactDebugCurrentFrame;\n    var stack = ReactDebugCurrentFrame.getStackAddendum();\n\n    if (stack !== '') {\n      format += '%s';\n      args = args.concat([stack]);\n    } // eslint-disable-next-line react-internal/safe-string-coercion\n\n\n    var argsWithFormat = args.map(function (item) {\n      return String(item);\n    }); // Careful: RN currently depends on this prefix\n\n    argsWithFormat.unshift('Warning: ' + format); // We intentionally don't use spread (or .apply) directly because it\n    // breaks IE9: https://github.com/facebook/react/issues/13610\n    // eslint-disable-next-line react-internal/no-production-logging\n\n    Function.prototype.apply.call(console[level], console, argsWithFormat);\n  }\n}\n\nvar didWarnStateUpdateForUnmountedComponent = {};\n\nfunction warnNoop(publicInstance, callerName) {\n  {\n    var _constructor = publicInstance.constructor;\n    var componentName = _constructor && (_constructor.displayName || _constructor.name) || 'ReactClass';\n    var warningKey = componentName + \".\" + callerName;\n\n    if (didWarnStateUpdateForUnmountedComponent[warningKey]) {\n      return;\n    }\n\n    error(\"Can't call %s on a component that is not yet mounted. \" + 'This is a no-op, but it might indicate a bug in your application. ' + 'Instead, assign to `this.state` directly or define a `state = {};` ' + 'class property with the desired state in the %s component.', callerName, componentName);\n\n    didWarnStateUpdateForUnmountedComponent[warningKey] = true;\n  }\n}\n/**\n * This is the abstract API for an update queue.\n */\n\n\nvar ReactNoopUpdateQueue = {\n  /**\n   * Checks whether or not this composite component is mounted.\n   * @param {ReactClass} publicInstance The instance we want to test.\n   * @return {boolean} True if mounted, false otherwise.\n   * @protected\n   * @final\n   */\n  isMounted: function (publicInstance) {\n    return false;\n  },\n\n  /**\n   * Forces an update. This should only be invoked when it is known with\n   * certainty that we are **not** in a DOM transaction.\n   *\n   * You may want to call this when you know that some deeper aspect of the\n   * component's state has changed but `setState` was not called.\n   *\n   * This will not invoke `shouldComponentUpdate`, but it will invoke\n   * `componentWillUpdate` and `componentDidUpdate`.\n   *\n   * @param {ReactClass} publicInstance The instance that should rerender.\n   * @param {?function} callback Called after component is updated.\n   * @param {?string} callerName name of the calling function in the public API.\n   * @internal\n   */\n  enqueueForceUpdate: function (publicInstance, callback, callerName) {\n    warnNoop(publicInstance, 'forceUpdate');\n  },\n\n  /**\n   * Replaces all of the state. Always use this or `setState` to mutate state.\n   * You should treat `this.state` as immutable.\n   *\n   * There is no guarantee that `this.state` will be immediately updated, so\n   * accessing `this.state` after calling this method may return the old value.\n   *\n   * @param {ReactClass} publicInstance The instance that should rerender.\n   * @param {object} completeState Next state.\n   * @param {?function} callback Called after component is updated.\n   * @param {?string} callerName name of the calling function in the public API.\n   * @internal\n   */\n  enqueueReplaceState: function (publicInstance, completeState, callback, callerName) {\n    warnNoop(publicInstance, 'replaceState');\n  },\n\n  /**\n   * Sets a subset of the state. This only exists because _pendingState is\n   * internal. This provides a merging strategy that is not available to deep\n   * properties which is confusing. TODO: Expose pendingState or don't use it\n   * during the merge.\n   *\n   * @param {ReactClass} publicInstance The instance that should rerender.\n   * @param {object} partialState Next partial state to be merged with state.\n   * @param {?function} callback Called after component is updated.\n   * @param {?string} Name of the calling function in the public API.\n   * @internal\n   */\n  enqueueSetState: function (publicInstance, partialState, callback, callerName) {\n    warnNoop(publicInstance, 'setState');\n  }\n};\n\nvar assign = Object.assign;\n\nvar emptyObject = {};\n\n{\n  Object.freeze(emptyObject);\n}\n/**\n * Base class helpers for the updating state of a component.\n */\n\n\nfunction Component(props, context, updater) {\n  this.props = props;\n  this.context = context; // If a component has string refs, we will assign a different object later.\n\n  this.refs = emptyObject; // We initialize the default updater but the real one gets injected by the\n  // renderer.\n\n  this.updater = updater || ReactNoopUpdateQueue;\n}\n\nComponent.prototype.isReactComponent = {};\n/**\n * Sets a subset of the state. Always use this to mutate\n * state. You should treat `this.state` as immutable.\n *\n * There is no guarantee that `this.state` will be immediately updated, so\n * accessing `this.state` after calling this method may return the old value.\n *\n * There is no guarantee that calls to `setState` will run synchronously,\n * as they may eventually be batched together.  You can provide an optional\n * callback that will be executed when the call to setState is actually\n * completed.\n *\n * When a function is provided to setState, it will be called at some point in\n * the future (not synchronously). It will be called with the up to date\n * component arguments (state, props, context). These values can be different\n * from this.* because your function may be called after receiveProps but before\n * shouldComponentUpdate, and this new state, props, and context will not yet be\n * assigned to this.\n *\n * @param {object|function} partialState Next partial state or function to\n *        produce next partial state to be merged with current state.\n * @param {?function} callback Called after state is updated.\n * @final\n * @protected\n */\n\nComponent.prototype.setState = function (partialState, callback) {\n  if (typeof partialState !== 'object' && typeof partialState !== 'function' && partialState != null) {\n    throw new Error('setState(...): takes an object of state variables to update or a ' + 'function which returns an object of state variables.');\n  }\n\n  this.updater.enqueueSetState(this, partialState, callback, 'setState');\n};\n/**\n * Forces an update. This should only be invoked when it is known with\n * certainty that we are **not** in a DOM transaction.\n *\n * You may want to call this when you know that some deeper aspect of the\n * component's state has changed but `setState` was not called.\n *\n * This will not invoke `shouldComponentUpdate`, but it will invoke\n * `componentWillUpdate` and `componentDidUpdate`.\n *\n * @param {?function} callback Called after update is complete.\n * @final\n * @protected\n */\n\n\nComponent.prototype.forceUpdate = function (callback) {\n  this.updater.enqueueForceUpdate(this, callback, 'forceUpdate');\n};\n/**\n * Deprecated APIs. These APIs used to exist on classic React classes but since\n * we would like to deprecate them, we're not going to move them over to this\n * modern base class. Instead, we define a getter that warns if it's accessed.\n */\n\n\n{\n  var deprecatedAPIs = {\n    isMounted: ['isMounted', 'Instead, make sure to clean up subscriptions and pending requests in ' + 'componentWillUnmount to prevent memory leaks.'],\n    replaceState: ['replaceState', 'Refactor your code to use setState instead (see ' + 'https://github.com/facebook/react/issues/3236).']\n  };\n\n  var defineDeprecationWarning = function (methodName, info) {\n    Object.defineProperty(Component.prototype, methodName, {\n      get: function () {\n        warn('%s(...) is deprecated in plain JavaScript React classes. %s', info[0], info[1]);\n\n        return undefined;\n      }\n    });\n  };\n\n  for (var fnName in deprecatedAPIs) {\n    if (deprecatedAPIs.hasOwnProperty(fnName)) {\n      defineDeprecationWarning(fnName, deprecatedAPIs[fnName]);\n    }\n  }\n}\n\nfunction ComponentDummy() {}\n\nComponentDummy.prototype = Component.prototype;\n/**\n * Convenience component with default shallow equality check for sCU.\n */\n\nfunction PureComponent(props, context, updater) {\n  this.props = props;\n  this.context = context; // If a component has string refs, we will assign a different object later.\n\n  this.refs = emptyObject;\n  this.updater = updater || ReactNoopUpdateQueue;\n}\n\nvar pureComponentPrototype = PureComponent.prototype = new ComponentDummy();\npureComponentPrototype.constructor = PureComponent; // Avoid an extra prototype jump for these methods.\n\nassign(pureComponentPrototype, Component.prototype);\npureComponentPrototype.isPureReactComponent = true;\n\n// an immutable object with a single mutable value\nfunction createRef() {\n  var refObject = {\n    current: null\n  };\n\n  {\n    Object.seal(refObject);\n  }\n\n  return refObject;\n}\n\nvar isArrayImpl = Array.isArray; // eslint-disable-next-line no-redeclare\n\nfunction isArray(a) {\n  return isArrayImpl(a);\n}\n\n/*\n * The `'' + value` pattern (used in in perf-sensitive code) throws for Symbol\n * and Temporal.* types. See https://github.com/facebook/react/pull/22064.\n *\n * The functions in this module will throw an easier-to-understand,\n * easier-to-debug exception with a clear errors message message explaining the\n * problem. (Instead of a confusing exception thrown inside the implementation\n * of the `value` object).\n */\n// $FlowFixMe only called in DEV, so void return is not possible.\nfunction typeName(value) {\n  {\n    // toStringTag is needed for namespaced types like Temporal.Instant\n    var hasToStringTag = typeof Symbol === 'function' && Symbol.toStringTag;\n    var type = hasToStringTag && value[Symbol.toStringTag] || value.constructor.name || 'Object';\n    return type;\n  }\n} // $FlowFixMe only called in DEV, so void return is not possible.\n\n\nfunction willCoercionThrow(value) {\n  {\n    try {\n      testStringCoercion(value);\n      return false;\n    } catch (e) {\n      return true;\n    }\n  }\n}\n\nfunction testStringCoercion(value) {\n  // If you ended up here by following an exception call stack, here's what's\n  // happened: you supplied an object or symbol value to React (as a prop, key,\n  // DOM attribute, CSS property, string ref, etc.) and when React tried to\n  // coerce it to a string using `'' + value`, an exception was thrown.\n  //\n  // The most common types that will cause this exception are `Symbol` instances\n  // and Temporal objects like `Temporal.Instant`. But any object that has a\n  // `valueOf` or `[Symbol.toPrimitive]` method that throws will also cause this\n  // exception. (Library authors do this to prevent users from using built-in\n  // numeric operators like `+` or comparison operators like `>=` because custom\n  // methods are needed to perform accurate arithmetic or comparison.)\n  //\n  // To fix the problem, coerce this object or symbol value to a string before\n  // passing it to React. The most reliable way is usually `String(value)`.\n  //\n  // To find which value is throwing, check the browser or debugger console.\n  // Before this exception was thrown, there should be `console.error` output\n  // that shows the type (Symbol, Temporal.PlainDate, etc.) that caused the\n  // problem and how that type was used: key, atrribute, input value prop, etc.\n  // In most cases, this console output also shows the component and its\n  // ancestor components where the exception happened.\n  //\n  // eslint-disable-next-line react-internal/safe-string-coercion\n  return '' + value;\n}\nfunction checkKeyStringCoercion(value) {\n  {\n    if (willCoercionThrow(value)) {\n      error('The provided key is an unsupported type %s.' + ' This value must be coerced to a string before before using it here.', typeName(value));\n\n      return testStringCoercion(value); // throw (to help callers find troubleshooting comments)\n    }\n  }\n}\n\nfunction getWrappedName(outerType, innerType, wrapperName) {\n  var displayName = outerType.displayName;\n\n  if (displayName) {\n    return displayName;\n  }\n\n  var functionName = innerType.displayName || innerType.name || '';\n  return functionName !== '' ? wrapperName + \"(\" + functionName + \")\" : wrapperName;\n} // Keep in sync with react-reconciler/getComponentNameFromFiber\n\n\nfunction getContextName(type) {\n  return type.displayName || 'Context';\n} // Note that the reconciler package should generally prefer to use getComponentNameFromFiber() instead.\n\n\nfunction getComponentNameFromType(type) {\n  if (type == null) {\n    // Host root, text node or just invalid type.\n    return null;\n  }\n\n  {\n    if (typeof type.tag === 'number') {\n      error('Received an unexpected object in getComponentNameFromType(). ' + 'This is likely a bug in React. Please file an issue.');\n    }\n  }\n\n  if (typeof type === 'function') {\n    return type.displayName || type.name || null;\n  }\n\n  if (typeof type === 'string') {\n    return type;\n  }\n\n  switch (type) {\n    case REACT_FRAGMENT_TYPE:\n      return 'Fragment';\n\n    case REACT_PORTAL_TYPE:\n      return 'Portal';\n\n    case REACT_PROFILER_TYPE:\n      return 'Profiler';\n\n    case REACT_STRICT_MODE_TYPE:\n      return 'StrictMode';\n\n    case REACT_SUSPENSE_TYPE:\n      return 'Suspense';\n\n    case REACT_SUSPENSE_LIST_TYPE:\n      return 'SuspenseList';\n\n  }\n\n  if (typeof type === 'object') {\n    switch (type.$$typeof) {\n      case REACT_CONTEXT_TYPE:\n        var context = type;\n        return getContextName(context) + '.Consumer';\n\n      case REACT_PROVIDER_TYPE:\n        var provider = type;\n        return getContextName(provider._context) + '.Provider';\n\n      case REACT_FORWARD_REF_TYPE:\n        return getWrappedName(type, type.render, 'ForwardRef');\n\n      case REACT_MEMO_TYPE:\n        var outerName = type.displayName || null;\n\n        if (outerName !== null) {\n          return outerName;\n        }\n\n        return getComponentNameFromType(type.type) || 'Memo';\n\n      case REACT_LAZY_TYPE:\n        {\n          var lazyComponent = type;\n          var payload = lazyComponent._payload;\n          var init = lazyComponent._init;\n\n          try {\n            return getComponentNameFromType(init(payload));\n          } catch (x) {\n            return null;\n          }\n        }\n\n      // eslint-disable-next-line no-fallthrough\n    }\n  }\n\n  return null;\n}\n\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\n\nvar RESERVED_PROPS = {\n  key: true,\n  ref: true,\n  __self: true,\n  __source: true\n};\nvar specialPropKeyWarningShown, specialPropRefWarningShown, didWarnAboutStringRefs;\n\n{\n  didWarnAboutStringRefs = {};\n}\n\nfunction hasValidRef(config) {\n  {\n    if (hasOwnProperty.call(config, 'ref')) {\n      var getter = Object.getOwnPropertyDescriptor(config, 'ref').get;\n\n      if (getter && getter.isReactWarning) {\n        return false;\n      }\n    }\n  }\n\n  return config.ref !== undefined;\n}\n\nfunction hasValidKey(config) {\n  {\n    if (hasOwnProperty.call(config, 'key')) {\n      var getter = Object.getOwnPropertyDescriptor(config, 'key').get;\n\n      if (getter && getter.isReactWarning) {\n        return false;\n      }\n    }\n  }\n\n  return config.key !== undefined;\n}\n\nfunction defineKeyPropWarningGetter(props, displayName) {\n  var warnAboutAccessingKey = function () {\n    {\n      if (!specialPropKeyWarningShown) {\n        specialPropKeyWarningShown = true;\n\n        error('%s: `key` is not a prop. Trying to access it will result ' + 'in `undefined` being returned. If you need to access the same ' + 'value within the child component, you should pass it as a different ' + 'prop. (https://reactjs.org/link/special-props)', displayName);\n      }\n    }\n  };\n\n  warnAboutAccessingKey.isReactWarning = true;\n  Object.defineProperty(props, 'key', {\n    get: warnAboutAccessingKey,\n    configurable: true\n  });\n}\n\nfunction defineRefPropWarningGetter(props, displayName) {\n  var warnAboutAccessingRef = function () {\n    {\n      if (!specialPropRefWarningShown) {\n        specialPropRefWarningShown = true;\n\n        error('%s: `ref` is not a prop. Trying to access it will result ' + 'in `undefined` being returned. If you need to access the same ' + 'value within the child component, you should pass it as a different ' + 'prop. (https://reactjs.org/link/special-props)', displayName);\n      }\n    }\n  };\n\n  warnAboutAccessingRef.isReactWarning = true;\n  Object.defineProperty(props, 'ref', {\n    get: warnAboutAccessingRef,\n    configurable: true\n  });\n}\n\nfunction warnIfStringRefCannotBeAutoConverted(config) {\n  {\n    if (typeof config.ref === 'string' && ReactCurrentOwner.current && config.__self && ReactCurrentOwner.current.stateNode !== config.__self) {\n      var componentName = getComponentNameFromType(ReactCurrentOwner.current.type);\n\n      if (!didWarnAboutStringRefs[componentName]) {\n        error('Component \"%s\" contains the string ref \"%s\". ' + 'Support for string refs will be removed in a future major release. ' + 'This case cannot be automatically converted to an arrow function. ' + 'We ask you to manually fix this case by using useRef() or createRef() instead. ' + 'Learn more about using refs safely here: ' + 'https://reactjs.org/link/strict-mode-string-ref', componentName, config.ref);\n\n        didWarnAboutStringRefs[componentName] = true;\n      }\n    }\n  }\n}\n/**\n * Factory method to create a new React element. This no longer adheres to\n * the class pattern, so do not use new to call it. Also, instanceof check\n * will not work. Instead test $$typeof field against Symbol.for('react.element') to check\n * if something is a React Element.\n *\n * @param {*} type\n * @param {*} props\n * @param {*} key\n * @param {string|object} ref\n * @param {*} owner\n * @param {*} self A *temporary* helper to detect places where `this` is\n * different from the `owner` when React.createElement is called, so that we\n * can warn. We want to get rid of owner and replace string `ref`s with arrow\n * functions, and as long as `this` and owner are the same, there will be no\n * change in behavior.\n * @param {*} source An annotation object (added by a transpiler or otherwise)\n * indicating filename, line number, and/or other information.\n * @internal\n */\n\n\nvar ReactElement = function (type, key, ref, self, source, owner, props) {\n  var element = {\n    // This tag allows us to uniquely identify this as a React Element\n    $$typeof: REACT_ELEMENT_TYPE,\n    // Built-in properties that belong on the element\n    type: type,\n    key: key,\n    ref: ref,\n    props: props,\n    // Record the component responsible for creating this element.\n    _owner: owner\n  };\n\n  {\n    // The validation flag is currently mutative. We put it on\n    // an external backing store so that we can freeze the whole object.\n    // This can be replaced with a WeakMap once they are implemented in\n    // commonly used development environments.\n    element._store = {}; // To make comparing ReactElements easier for testing purposes, we make\n    // the validation flag non-enumerable (where possible, which should\n    // include every environment we run tests in), so the test framework\n    // ignores it.\n\n    Object.defineProperty(element._store, 'validated', {\n      configurable: false,\n      enumerable: false,\n      writable: true,\n      value: false\n    }); // self and source are DEV only properties.\n\n    Object.defineProperty(element, '_self', {\n      configurable: false,\n      enumerable: false,\n      writable: false,\n      value: self\n    }); // Two elements created in two different places should be considered\n    // equal for testing purposes and therefore we hide it from enumeration.\n\n    Object.defineProperty(element, '_source', {\n      configurable: false,\n      enumerable: false,\n      writable: false,\n      value: source\n    });\n\n    if (Object.freeze) {\n      Object.freeze(element.props);\n      Object.freeze(element);\n    }\n  }\n\n  return element;\n};\n/**\n * Create and return a new ReactElement of the given type.\n * See https://reactjs.org/docs/react-api.html#createelement\n */\n\nfunction createElement(type, config, children) {\n  var propName; // Reserved names are extracted\n\n  var props = {};\n  var key = null;\n  var ref = null;\n  var self = null;\n  var source = null;\n\n  if (config != null) {\n    if (hasValidRef(config)) {\n      ref = config.ref;\n\n      {\n        warnIfStringRefCannotBeAutoConverted(config);\n      }\n    }\n\n    if (hasValidKey(config)) {\n      {\n        checkKeyStringCoercion(config.key);\n      }\n\n      key = '' + config.key;\n    }\n\n    self = config.__self === undefined ? null : config.__self;\n    source = config.__source === undefined ? null : config.__source; // Remaining properties are added to a new props object\n\n    for (propName in config) {\n      if (hasOwnProperty.call(config, propName) && !RESERVED_PROPS.hasOwnProperty(propName)) {\n        props[propName] = config[propName];\n      }\n    }\n  } // Children can be more than one argument, and those are transferred onto\n  // the newly allocated props object.\n\n\n  var childrenLength = arguments.length - 2;\n\n  if (childrenLength === 1) {\n    props.children = children;\n  } else if (childrenLength > 1) {\n    var childArray = Array(childrenLength);\n\n    for (var i = 0; i < childrenLength; i++) {\n      childArray[i] = arguments[i + 2];\n    }\n\n    {\n      if (Object.freeze) {\n        Object.freeze(childArray);\n      }\n    }\n\n    props.children = childArray;\n  } // Resolve default props\n\n\n  if (type && type.defaultProps) {\n    var defaultProps = type.defaultProps;\n\n    for (propName in defaultProps) {\n      if (props[propName] === undefined) {\n        props[propName] = defaultProps[propName];\n      }\n    }\n  }\n\n  {\n    if (key || ref) {\n      var displayName = typeof type === 'function' ? type.displayName || type.name || 'Unknown' : type;\n\n      if (key) {\n        defineKeyPropWarningGetter(props, displayName);\n      }\n\n      if (ref) {\n        defineRefPropWarningGetter(props, displayName);\n      }\n    }\n  }\n\n  return ReactElement(type, key, ref, self, source, ReactCurrentOwner.current, props);\n}\nfunction cloneAndReplaceKey(oldElement, newKey) {\n  var newElement = ReactElement(oldElement.type, newKey, oldElement.ref, oldElement._self, oldElement._source, oldElement._owner, oldElement.props);\n  return newElement;\n}\n/**\n * Clone and return a new ReactElement using element as the starting point.\n * See https://reactjs.org/docs/react-api.html#cloneelement\n */\n\nfunction cloneElement(element, config, children) {\n  if (element === null || element === undefined) {\n    throw new Error(\"React.cloneElement(...): The argument must be a React element, but you passed \" + element + \".\");\n  }\n\n  var propName; // Original props are copied\n\n  var props = assign({}, element.props); // Reserved names are extracted\n\n  var key = element.key;\n  var ref = element.ref; // Self is preserved since the owner is preserved.\n\n  var self = element._self; // Source is preserved since cloneElement is unlikely to be targeted by a\n  // transpiler, and the original source is probably a better indicator of the\n  // true owner.\n\n  var source = element._source; // Owner will be preserved, unless ref is overridden\n\n  var owner = element._owner;\n\n  if (config != null) {\n    if (hasValidRef(config)) {\n      // Silently steal the ref from the parent.\n      ref = config.ref;\n      owner = ReactCurrentOwner.current;\n    }\n\n    if (hasValidKey(config)) {\n      {\n        checkKeyStringCoercion(config.key);\n      }\n\n      key = '' + config.key;\n    } // Remaining properties override existing props\n\n\n    var defaultProps;\n\n    if (element.type && element.type.defaultProps) {\n      defaultProps = element.type.defaultProps;\n    }\n\n    for (propName in config) {\n      if (hasOwnProperty.call(config, propName) && !RESERVED_PROPS.hasOwnProperty(propName)) {\n        if (config[propName] === undefined && defaultProps !== undefined) {\n          // Resolve default props\n          props[propName] = defaultProps[propName];\n        } else {\n          props[propName] = config[propName];\n        }\n      }\n    }\n  } // Children can be more than one argument, and those are transferred onto\n  // the newly allocated props object.\n\n\n  var childrenLength = arguments.length - 2;\n\n  if (childrenLength === 1) {\n    props.children = children;\n  } else if (childrenLength > 1) {\n    var childArray = Array(childrenLength);\n\n    for (var i = 0; i < childrenLength; i++) {\n      childArray[i] = arguments[i + 2];\n    }\n\n    props.children = childArray;\n  }\n\n  return ReactElement(element.type, key, ref, self, source, owner, props);\n}\n/**\n * Verifies the object is a ReactElement.\n * See https://reactjs.org/docs/react-api.html#isvalidelement\n * @param {?object} object\n * @return {boolean} True if `object` is a ReactElement.\n * @final\n */\n\nfunction isValidElement(object) {\n  return typeof object === 'object' && object !== null && object.$$typeof === REACT_ELEMENT_TYPE;\n}\n\nvar SEPARATOR = '.';\nvar SUBSEPARATOR = ':';\n/**\n * Escape and wrap key so it is safe to use as a reactid\n *\n * @param {string} key to be escaped.\n * @return {string} the escaped key.\n */\n\nfunction escape(key) {\n  var escapeRegex = /[=:]/g;\n  var escaperLookup = {\n    '=': '=0',\n    ':': '=2'\n  };\n  var escapedString = key.replace(escapeRegex, function (match) {\n    return escaperLookup[match];\n  });\n  return '$' + escapedString;\n}\n/**\n * TODO: Test that a single child and an array with one item have the same key\n * pattern.\n */\n\n\nvar didWarnAboutMaps = false;\nvar userProvidedKeyEscapeRegex = /\\/+/g;\n\nfunction escapeUserProvidedKey(text) {\n  return text.replace(userProvidedKeyEscapeRegex, '$&/');\n}\n/**\n * Generate a key string that identifies a element within a set.\n *\n * @param {*} element A element that could contain a manual key.\n * @param {number} index Index that is used if a manual key is not provided.\n * @return {string}\n */\n\n\nfunction getElementKey(element, index) {\n  // Do some typechecking here since we call this blindly. We want to ensure\n  // that we don't block potential future ES APIs.\n  if (typeof element === 'object' && element !== null && element.key != null) {\n    // Explicit key\n    {\n      checkKeyStringCoercion(element.key);\n    }\n\n    return escape('' + element.key);\n  } // Implicit key determined by the index in the set\n\n\n  return index.toString(36);\n}\n\nfunction mapIntoArray(children, array, escapedPrefix, nameSoFar, callback) {\n  var type = typeof children;\n\n  if (type === 'undefined' || type === 'boolean') {\n    // All of the above are perceived as null.\n    children = null;\n  }\n\n  var invokeCallback = false;\n\n  if (children === null) {\n    invokeCallback = true;\n  } else {\n    switch (type) {\n      case 'string':\n      case 'number':\n        invokeCallback = true;\n        break;\n\n      case 'object':\n        switch (children.$$typeof) {\n          case REACT_ELEMENT_TYPE:\n          case REACT_PORTAL_TYPE:\n            invokeCallback = true;\n        }\n\n    }\n  }\n\n  if (invokeCallback) {\n    var _child = children;\n    var mappedChild = callback(_child); // If it's the only child, treat the name as if it was wrapped in an array\n    // so that it's consistent if the number of children grows:\n\n    var childKey = nameSoFar === '' ? SEPARATOR + getElementKey(_child, 0) : nameSoFar;\n\n    if (isArray(mappedChild)) {\n      var escapedChildKey = '';\n\n      if (childKey != null) {\n        escapedChildKey = escapeUserProvidedKey(childKey) + '/';\n      }\n\n      mapIntoArray(mappedChild, array, escapedChildKey, '', function (c) {\n        return c;\n      });\n    } else if (mappedChild != null) {\n      if (isValidElement(mappedChild)) {\n        {\n          // The `if` statement here prevents auto-disabling of the safe\n          // coercion ESLint rule, so we must manually disable it below.\n          // $FlowFixMe Flow incorrectly thinks React.Portal doesn't have a key\n          if (mappedChild.key && (!_child || _child.key !== mappedChild.key)) {\n            checkKeyStringCoercion(mappedChild.key);\n          }\n        }\n\n        mappedChild = cloneAndReplaceKey(mappedChild, // Keep both the (mapped) and old keys if they differ, just as\n        // traverseAllChildren used to do for objects as children\n        escapedPrefix + ( // $FlowFixMe Flow incorrectly thinks React.Portal doesn't have a key\n        mappedChild.key && (!_child || _child.key !== mappedChild.key) ? // $FlowFixMe Flow incorrectly thinks existing element's key can be a number\n        // eslint-disable-next-line react-internal/safe-string-coercion\n        escapeUserProvidedKey('' + mappedChild.key) + '/' : '') + childKey);\n      }\n\n      array.push(mappedChild);\n    }\n\n    return 1;\n  }\n\n  var child;\n  var nextName;\n  var subtreeCount = 0; // Count of children found in the current subtree.\n\n  var nextNamePrefix = nameSoFar === '' ? SEPARATOR : nameSoFar + SUBSEPARATOR;\n\n  if (isArray(children)) {\n    for (var i = 0; i < children.length; i++) {\n      child = children[i];\n      nextName = nextNamePrefix + getElementKey(child, i);\n      subtreeCount += mapIntoArray(child, array, escapedPrefix, nextName, callback);\n    }\n  } else {\n    var iteratorFn = getIteratorFn(children);\n\n    if (typeof iteratorFn === 'function') {\n      var iterableChildren = children;\n\n      {\n        // Warn about using Maps as children\n        if (iteratorFn === iterableChildren.entries) {\n          if (!didWarnAboutMaps) {\n            warn('Using Maps as children is not supported. ' + 'Use an array of keyed ReactElements instead.');\n          }\n\n          didWarnAboutMaps = true;\n        }\n      }\n\n      var iterator = iteratorFn.call(iterableChildren);\n      var step;\n      var ii = 0;\n\n      while (!(step = iterator.next()).done) {\n        child = step.value;\n        nextName = nextNamePrefix + getElementKey(child, ii++);\n        subtreeCount += mapIntoArray(child, array, escapedPrefix, nextName, callback);\n      }\n    } else if (type === 'object') {\n      // eslint-disable-next-line react-internal/safe-string-coercion\n      var childrenString = String(children);\n      throw new Error(\"Objects are not valid as a React child (found: \" + (childrenString === '[object Object]' ? 'object with keys {' + Object.keys(children).join(', ') + '}' : childrenString) + \"). \" + 'If you meant to render a collection of children, use an array ' + 'instead.');\n    }\n  }\n\n  return subtreeCount;\n}\n\n/**\n * Maps children that are typically specified as `props.children`.\n *\n * See https://reactjs.org/docs/react-api.html#reactchildrenmap\n *\n * The provided mapFunction(child, index) will be called for each\n * leaf child.\n *\n * @param {?*} children Children tree container.\n * @param {function(*, int)} func The map function.\n * @param {*} context Context for mapFunction.\n * @return {object} Object containing the ordered map of results.\n */\nfunction mapChildren(children, func, context) {\n  if (children == null) {\n    return children;\n  }\n\n  var result = [];\n  var count = 0;\n  mapIntoArray(children, result, '', '', function (child) {\n    return func.call(context, child, count++);\n  });\n  return result;\n}\n/**\n * Count the number of children that are typically specified as\n * `props.children`.\n *\n * See https://reactjs.org/docs/react-api.html#reactchildrencount\n *\n * @param {?*} children Children tree container.\n * @return {number} The number of children.\n */\n\n\nfunction countChildren(children) {\n  var n = 0;\n  mapChildren(children, function () {\n    n++; // Don't return anything\n  });\n  return n;\n}\n\n/**\n * Iterates through children that are typically specified as `props.children`.\n *\n * See https://reactjs.org/docs/react-api.html#reactchildrenforeach\n *\n * The provided forEachFunc(child, index) will be called for each\n * leaf child.\n *\n * @param {?*} children Children tree container.\n * @param {function(*, int)} forEachFunc\n * @param {*} forEachContext Context for forEachContext.\n */\nfunction forEachChildren(children, forEachFunc, forEachContext) {\n  mapChildren(children, function () {\n    forEachFunc.apply(this, arguments); // Don't return anything.\n  }, forEachContext);\n}\n/**\n * Flatten a children object (typically specified as `props.children`) and\n * return an array with appropriately re-keyed children.\n *\n * See https://reactjs.org/docs/react-api.html#reactchildrentoarray\n */\n\n\nfunction toArray(children) {\n  return mapChildren(children, function (child) {\n    return child;\n  }) || [];\n}\n/**\n * Returns the first child in a collection of children and verifies that there\n * is only one child in the collection.\n *\n * See https://reactjs.org/docs/react-api.html#reactchildrenonly\n *\n * The current implementation of this function assumes that a single child gets\n * passed without a wrapper, but the purpose of this helper function is to\n * abstract away the particular structure of children.\n *\n * @param {?object} children Child collection structure.\n * @return {ReactElement} The first and only `ReactElement` contained in the\n * structure.\n */\n\n\nfunction onlyChild(children) {\n  if (!isValidElement(children)) {\n    throw new Error('React.Children.only expected to receive a single React element child.');\n  }\n\n  return children;\n}\n\nfunction createContext(defaultValue) {\n  // TODO: Second argument used to be an optional `calculateChangedBits`\n  // function. Warn to reserve for future use?\n  var context = {\n    $$typeof: REACT_CONTEXT_TYPE,\n    // As a workaround to support multiple concurrent renderers, we categorize\n    // some renderers as primary and others as secondary. We only expect\n    // there to be two concurrent renderers at most: React Native (primary) and\n    // Fabric (secondary); React DOM (primary) and React ART (secondary).\n    // Secondary renderers store their context values on separate fields.\n    _currentValue: defaultValue,\n    _currentValue2: defaultValue,\n    // Used to track how many concurrent renderers this context currently\n    // supports within in a single renderer. Such as parallel server rendering.\n    _threadCount: 0,\n    // These are circular\n    Provider: null,\n    Consumer: null,\n    // Add these to use same hidden class in VM as ServerContext\n    _defaultValue: null,\n    _globalName: null\n  };\n  context.Provider = {\n    $$typeof: REACT_PROVIDER_TYPE,\n    _context: context\n  };\n  var hasWarnedAboutUsingNestedContextConsumers = false;\n  var hasWarnedAboutUsingConsumerProvider = false;\n  var hasWarnedAboutDisplayNameOnConsumer = false;\n\n  {\n    // A separate object, but proxies back to the original context object for\n    // backwards compatibility. It has a different $$typeof, so we can properly\n    // warn for the incorrect usage of Context as a Consumer.\n    var Consumer = {\n      $$typeof: REACT_CONTEXT_TYPE,\n      _context: context\n    }; // $FlowFixMe: Flow complains about not setting a value, which is intentional here\n\n    Object.defineProperties(Consumer, {\n      Provider: {\n        get: function () {\n          if (!hasWarnedAboutUsingConsumerProvider) {\n            hasWarnedAboutUsingConsumerProvider = true;\n\n            error('Rendering <Context.Consumer.Provider> is not supported and will be removed in ' + 'a future major release. Did you mean to render <Context.Provider> instead?');\n          }\n\n          return context.Provider;\n        },\n        set: function (_Provider) {\n          context.Provider = _Provider;\n        }\n      },\n      _currentValue: {\n        get: function () {\n          return context._currentValue;\n        },\n        set: function (_currentValue) {\n          context._currentValue = _currentValue;\n        }\n      },\n      _currentValue2: {\n        get: function () {\n          return context._currentValue2;\n        },\n        set: function (_currentValue2) {\n          context._currentValue2 = _currentValue2;\n        }\n      },\n      _threadCount: {\n        get: function () {\n          return context._threadCount;\n        },\n        set: function (_threadCount) {\n          context._threadCount = _threadCount;\n        }\n      },\n      Consumer: {\n        get: function () {\n          if (!hasWarnedAboutUsingNestedContextConsumers) {\n            hasWarnedAboutUsingNestedContextConsumers = true;\n\n            error('Rendering <Context.Consumer.Consumer> is not supported and will be removed in ' + 'a future major release. Did you mean to render <Context.Consumer> instead?');\n          }\n\n          return context.Consumer;\n        }\n      },\n      displayName: {\n        get: function () {\n          return context.displayName;\n        },\n        set: function (displayName) {\n          if (!hasWarnedAboutDisplayNameOnConsumer) {\n            warn('Setting `displayName` on Context.Consumer has no effect. ' + \"You should set it directly on the context with Context.displayName = '%s'.\", displayName);\n\n            hasWarnedAboutDisplayNameOnConsumer = true;\n          }\n        }\n      }\n    }); // $FlowFixMe: Flow complains about missing properties because it doesn't understand defineProperty\n\n    context.Consumer = Consumer;\n  }\n\n  {\n    context._currentRenderer = null;\n    context._currentRenderer2 = null;\n  }\n\n  return context;\n}\n\nvar Uninitialized = -1;\nvar Pending = 0;\nvar Resolved = 1;\nvar Rejected = 2;\n\nfunction lazyInitializer(payload) {\n  if (payload._status === Uninitialized) {\n    var ctor = payload._result;\n    var thenable = ctor(); // Transition to the next state.\n    // This might throw either because it's missing or throws. If so, we treat it\n    // as still uninitialized and try again next time. Which is the same as what\n    // happens if the ctor or any wrappers processing the ctor throws. This might\n    // end up fixing it if the resolution was a concurrency bug.\n\n    thenable.then(function (moduleObject) {\n      if (payload._status === Pending || payload._status === Uninitialized) {\n        // Transition to the next state.\n        var resolved = payload;\n        resolved._status = Resolved;\n        resolved._result = moduleObject;\n      }\n    }, function (error) {\n      if (payload._status === Pending || payload._status === Uninitialized) {\n        // Transition to the next state.\n        var rejected = payload;\n        rejected._status = Rejected;\n        rejected._result = error;\n      }\n    });\n\n    if (payload._status === Uninitialized) {\n      // In case, we're still uninitialized, then we're waiting for the thenable\n      // to resolve. Set it as pending in the meantime.\n      var pending = payload;\n      pending._status = Pending;\n      pending._result = thenable;\n    }\n  }\n\n  if (payload._status === Resolved) {\n    var moduleObject = payload._result;\n\n    {\n      if (moduleObject === undefined) {\n        error('lazy: Expected the result of a dynamic imp' + 'ort() call. ' + 'Instead received: %s\\n\\nYour code should look like: \\n  ' + // Break up imports to avoid accidentally parsing them as dependencies.\n        'const MyComponent = lazy(() => imp' + \"ort('./MyComponent'))\\n\\n\" + 'Did you accidentally put curly braces around the import?', moduleObject);\n      }\n    }\n\n    {\n      if (!('default' in moduleObject)) {\n        error('lazy: Expected the result of a dynamic imp' + 'ort() call. ' + 'Instead received: %s\\n\\nYour code should look like: \\n  ' + // Break up imports to avoid accidentally parsing them as dependencies.\n        'const MyComponent = lazy(() => imp' + \"ort('./MyComponent'))\", moduleObject);\n      }\n    }\n\n    return moduleObject.default;\n  } else {\n    throw payload._result;\n  }\n}\n\nfunction lazy(ctor) {\n  var payload = {\n    // We use these fields to store the result.\n    _status: Uninitialized,\n    _result: ctor\n  };\n  var lazyType = {\n    $$typeof: REACT_LAZY_TYPE,\n    _payload: payload,\n    _init: lazyInitializer\n  };\n\n  {\n    // In production, this would just set it on the object.\n    var defaultProps;\n    var propTypes; // $FlowFixMe\n\n    Object.defineProperties(lazyType, {\n      defaultProps: {\n        configurable: true,\n        get: function () {\n          return defaultProps;\n        },\n        set: function (newDefaultProps) {\n          error('React.lazy(...): It is not supported to assign `defaultProps` to ' + 'a lazy component import. Either specify them where the component ' + 'is defined, or create a wrapping component around it.');\n\n          defaultProps = newDefaultProps; // Match production behavior more closely:\n          // $FlowFixMe\n\n          Object.defineProperty(lazyType, 'defaultProps', {\n            enumerable: true\n          });\n        }\n      },\n      propTypes: {\n        configurable: true,\n        get: function () {\n          return propTypes;\n        },\n        set: function (newPropTypes) {\n          error('React.lazy(...): It is not supported to assign `propTypes` to ' + 'a lazy component import. Either specify them where the component ' + 'is defined, or create a wrapping component around it.');\n\n          propTypes = newPropTypes; // Match production behavior more closely:\n          // $FlowFixMe\n\n          Object.defineProperty(lazyType, 'propTypes', {\n            enumerable: true\n          });\n        }\n      }\n    });\n  }\n\n  return lazyType;\n}\n\nfunction forwardRef(render) {\n  {\n    if (render != null && render.$$typeof === REACT_MEMO_TYPE) {\n      error('forwardRef requires a render function but received a `memo` ' + 'component. Instead of forwardRef(memo(...)), use ' + 'memo(forwardRef(...)).');\n    } else if (typeof render !== 'function') {\n      error('forwardRef requires a render function but was given %s.', render === null ? 'null' : typeof render);\n    } else {\n      if (render.length !== 0 && render.length !== 2) {\n        error('forwardRef render functions accept exactly two parameters: props and ref. %s', render.length === 1 ? 'Did you forget to use the ref parameter?' : 'Any additional parameter will be undefined.');\n      }\n    }\n\n    if (render != null) {\n      if (render.defaultProps != null || render.propTypes != null) {\n        error('forwardRef render functions do not support propTypes or defaultProps. ' + 'Did you accidentally pass a React component?');\n      }\n    }\n  }\n\n  var elementType = {\n    $$typeof: REACT_FORWARD_REF_TYPE,\n    render: render\n  };\n\n  {\n    var ownName;\n    Object.defineProperty(elementType, 'displayName', {\n      enumerable: false,\n      configurable: true,\n      get: function () {\n        return ownName;\n      },\n      set: function (name) {\n        ownName = name; // The inner component shouldn't inherit this display name in most cases,\n        // because the component may be used elsewhere.\n        // But it's nice for anonymous functions to inherit the name,\n        // so that our component-stack generation logic will display their frames.\n        // An anonymous function generally suggests a pattern like:\n        //   React.forwardRef((props, ref) => {...});\n        // This kind of inner function is not used elsewhere so the side effect is okay.\n\n        if (!render.name && !render.displayName) {\n          render.displayName = name;\n        }\n      }\n    });\n  }\n\n  return elementType;\n}\n\nvar REACT_MODULE_REFERENCE;\n\n{\n  REACT_MODULE_REFERENCE = Symbol.for('react.module.reference');\n}\n\nfunction isValidElementType(type) {\n  if (typeof type === 'string' || typeof type === 'function') {\n    return true;\n  } // Note: typeof might be other than 'symbol' or 'number' (e.g. if it's a polyfill).\n\n\n  if (type === REACT_FRAGMENT_TYPE || type === REACT_PROFILER_TYPE || enableDebugTracing  || type === REACT_STRICT_MODE_TYPE || type === REACT_SUSPENSE_TYPE || type === REACT_SUSPENSE_LIST_TYPE || enableLegacyHidden  || type === REACT_OFFSCREEN_TYPE || enableScopeAPI  || enableCacheElement  || enableTransitionTracing ) {\n    return true;\n  }\n\n  if (typeof type === 'object' && type !== null) {\n    if (type.$$typeof === REACT_LAZY_TYPE || type.$$typeof === REACT_MEMO_TYPE || type.$$typeof === REACT_PROVIDER_TYPE || type.$$typeof === REACT_CONTEXT_TYPE || type.$$typeof === REACT_FORWARD_REF_TYPE || // This needs to include all possible module reference object\n    // types supported by any Flight configuration anywhere since\n    // we don't know which Flight build this will end up being used\n    // with.\n    type.$$typeof === REACT_MODULE_REFERENCE || type.getModuleId !== undefined) {\n      return true;\n    }\n  }\n\n  return false;\n}\n\nfunction memo(type, compare) {\n  {\n    if (!isValidElementType(type)) {\n      error('memo: The first argument must be a component. Instead ' + 'received: %s', type === null ? 'null' : typeof type);\n    }\n  }\n\n  var elementType = {\n    $$typeof: REACT_MEMO_TYPE,\n    type: type,\n    compare: compare === undefined ? null : compare\n  };\n\n  {\n    var ownName;\n    Object.defineProperty(elementType, 'displayName', {\n      enumerable: false,\n      configurable: true,\n      get: function () {\n        return ownName;\n      },\n      set: function (name) {\n        ownName = name; // The inner component shouldn't inherit this display name in most cases,\n        // because the component may be used elsewhere.\n        // But it's nice for anonymous functions to inherit the name,\n        // so that our component-stack generation logic will display their frames.\n        // An anonymous function generally suggests a pattern like:\n        //   React.memo((props) => {...});\n        // This kind of inner function is not used elsewhere so the side effect is okay.\n\n        if (!type.name && !type.displayName) {\n          type.displayName = name;\n        }\n      }\n    });\n  }\n\n  return elementType;\n}\n\nfunction resolveDispatcher() {\n  var dispatcher = ReactCurrentDispatcher.current;\n\n  {\n    if (dispatcher === null) {\n      error('Invalid hook call. Hooks can only be called inside of the body of a function component. This could happen for' + ' one of the following reasons:\\n' + '1. You might have mismatching versions of React and the renderer (such as React DOM)\\n' + '2. You might be breaking the Rules of Hooks\\n' + '3. You might have more than one copy of React in the same app\\n' + 'See https://reactjs.org/link/invalid-hook-call for tips about how to debug and fix this problem.');\n    }\n  } // Will result in a null access error if accessed outside render phase. We\n  // intentionally don't throw our own error because this is in a hot path.\n  // Also helps ensure this is inlined.\n\n\n  return dispatcher;\n}\nfunction useContext(Context) {\n  var dispatcher = resolveDispatcher();\n\n  {\n    // TODO: add a more generic warning for invalid values.\n    if (Context._context !== undefined) {\n      var realContext = Context._context; // Don't deduplicate because this legitimately causes bugs\n      // and nobody should be using this in existing code.\n\n      if (realContext.Consumer === Context) {\n        error('Calling useContext(Context.Consumer) is not supported, may cause bugs, and will be ' + 'removed in a future major release. Did you mean to call useContext(Context) instead?');\n      } else if (realContext.Provider === Context) {\n        error('Calling useContext(Context.Provider) is not supported. ' + 'Did you mean to call useContext(Context) instead?');\n      }\n    }\n  }\n\n  return dispatcher.useContext(Context);\n}\nfunction useState(initialState) {\n  var dispatcher = resolveDispatcher();\n  return dispatcher.useState(initialState);\n}\nfunction useReducer(reducer, initialArg, init) {\n  var dispatcher = resolveDispatcher();\n  return dispatcher.useReducer(reducer, initialArg, init);\n}\nfunction useRef(initialValue) {\n  var dispatcher = resolveDispatcher();\n  return dispatcher.useRef(initialValue);\n}\nfunction useEffect(create, deps) {\n  var dispatcher = resolveDispatcher();\n  return dispatcher.useEffect(create, deps);\n}\nfunction useInsertionEffect(create, deps) {\n  var dispatcher = resolveDispatcher();\n  return dispatcher.useInsertionEffect(create, deps);\n}\nfunction useLayoutEffect(create, deps) {\n  var dispatcher = resolveDispatcher();\n  return dispatcher.useLayoutEffect(create, deps);\n}\nfunction useCallback(callback, deps) {\n  var dispatcher = resolveDispatcher();\n  return dispatcher.useCallback(callback, deps);\n}\nfunction useMemo(create, deps) {\n  var dispatcher = resolveDispatcher();\n  return dispatcher.useMemo(create, deps);\n}\nfunction useImperativeHandle(ref, create, deps) {\n  var dispatcher = resolveDispatcher();\n  return dispatcher.useImperativeHandle(ref, create, deps);\n}\nfunction useDebugValue(value, formatterFn) {\n  {\n    var dispatcher = resolveDispatcher();\n    return dispatcher.useDebugValue(value, formatterFn);\n  }\n}\nfunction useTransition() {\n  var dispatcher = resolveDispatcher();\n  return dispatcher.useTransition();\n}\nfunction useDeferredValue(value) {\n  var dispatcher = resolveDispatcher();\n  return dispatcher.useDeferredValue(value);\n}\nfunction useId() {\n  var dispatcher = resolveDispatcher();\n  return dispatcher.useId();\n}\nfunction useSyncExternalStore(subscribe, getSnapshot, getServerSnapshot) {\n  var dispatcher = resolveDispatcher();\n  return dispatcher.useSyncExternalStore(subscribe, getSnapshot, getServerSnapshot);\n}\n\n// Helpers to patch console.logs to avoid logging during side-effect free\n// replaying on render function. This currently only patches the object\n// lazily which won't cover if the log function was extracted eagerly.\n// We could also eagerly patch the method.\nvar disabledDepth = 0;\nvar prevLog;\nvar prevInfo;\nvar prevWarn;\nvar prevError;\nvar prevGroup;\nvar prevGroupCollapsed;\nvar prevGroupEnd;\n\nfunction disabledLog() {}\n\ndisabledLog.__reactDisabledLog = true;\nfunction disableLogs() {\n  {\n    if (disabledDepth === 0) {\n      /* eslint-disable react-internal/no-production-logging */\n      prevLog = console.log;\n      prevInfo = console.info;\n      prevWarn = console.warn;\n      prevError = console.error;\n      prevGroup = console.group;\n      prevGroupCollapsed = console.groupCollapsed;\n      prevGroupEnd = console.groupEnd; // https://github.com/facebook/react/issues/19099\n\n      var props = {\n        configurable: true,\n        enumerable: true,\n        value: disabledLog,\n        writable: true\n      }; // $FlowFixMe Flow thinks console is immutable.\n\n      Object.defineProperties(console, {\n        info: props,\n        log: props,\n        warn: props,\n        error: props,\n        group: props,\n        groupCollapsed: props,\n        groupEnd: props\n      });\n      /* eslint-enable react-internal/no-production-logging */\n    }\n\n    disabledDepth++;\n  }\n}\nfunction reenableLogs() {\n  {\n    disabledDepth--;\n\n    if (disabledDepth === 0) {\n      /* eslint-disable react-internal/no-production-logging */\n      var props = {\n        configurable: true,\n        enumerable: true,\n        writable: true\n      }; // $FlowFixMe Flow thinks console is immutable.\n\n      Object.defineProperties(console, {\n        log: assign({}, props, {\n          value: prevLog\n        }),\n        info: assign({}, props, {\n          value: prevInfo\n        }),\n        warn: assign({}, props, {\n          value: prevWarn\n        }),\n        error: assign({}, props, {\n          value: prevError\n        }),\n        group: assign({}, props, {\n          value: prevGroup\n        }),\n        groupCollapsed: assign({}, props, {\n          value: prevGroupCollapsed\n        }),\n        groupEnd: assign({}, props, {\n          value: prevGroupEnd\n        })\n      });\n      /* eslint-enable react-internal/no-production-logging */\n    }\n\n    if (disabledDepth < 0) {\n      error('disabledDepth fell below zero. ' + 'This is a bug in React. Please file an issue.');\n    }\n  }\n}\n\nvar ReactCurrentDispatcher$1 = ReactSharedInternals.ReactCurrentDispatcher;\nvar prefix;\nfunction describeBuiltInComponentFrame(name, source, ownerFn) {\n  {\n    if (prefix === undefined) {\n      // Extract the VM specific prefix used by each line.\n      try {\n        throw Error();\n      } catch (x) {\n        var match = x.stack.trim().match(/\\n( *(at )?)/);\n        prefix = match && match[1] || '';\n      }\n    } // We use the prefix to ensure our stacks line up with native stack frames.\n\n\n    return '\\n' + prefix + name;\n  }\n}\nvar reentry = false;\nvar componentFrameCache;\n\n{\n  var PossiblyWeakMap = typeof WeakMap === 'function' ? WeakMap : Map;\n  componentFrameCache = new PossiblyWeakMap();\n}\n\nfunction describeNativeComponentFrame(fn, construct) {\n  // If something asked for a stack inside a fake render, it should get ignored.\n  if ( !fn || reentry) {\n    return '';\n  }\n\n  {\n    var frame = componentFrameCache.get(fn);\n\n    if (frame !== undefined) {\n      return frame;\n    }\n  }\n\n  var control;\n  reentry = true;\n  var previousPrepareStackTrace = Error.prepareStackTrace; // $FlowFixMe It does accept undefined.\n\n  Error.prepareStackTrace = undefined;\n  var previousDispatcher;\n\n  {\n    previousDispatcher = ReactCurrentDispatcher$1.current; // Set the dispatcher in DEV because this might be call in the render function\n    // for warnings.\n\n    ReactCurrentDispatcher$1.current = null;\n    disableLogs();\n  }\n\n  try {\n    // This should throw.\n    if (construct) {\n      // Something should be setting the props in the constructor.\n      var Fake = function () {\n        throw Error();\n      }; // $FlowFixMe\n\n\n      Object.defineProperty(Fake.prototype, 'props', {\n        set: function () {\n          // We use a throwing setter instead of frozen or non-writable props\n          // because that won't throw in a non-strict mode function.\n          throw Error();\n        }\n      });\n\n      if (typeof Reflect === 'object' && Reflect.construct) {\n        // We construct a different control for this case to include any extra\n        // frames added by the construct call.\n        try {\n          Reflect.construct(Fake, []);\n        } catch (x) {\n          control = x;\n        }\n\n        Reflect.construct(fn, [], Fake);\n      } else {\n        try {\n          Fake.call();\n        } catch (x) {\n          control = x;\n        }\n\n        fn.call(Fake.prototype);\n      }\n    } else {\n      try {\n        throw Error();\n      } catch (x) {\n        control = x;\n      }\n\n      fn();\n    }\n  } catch (sample) {\n    // This is inlined manually because closure doesn't do it for us.\n    if (sample && control && typeof sample.stack === 'string') {\n      // This extracts the first frame from the sample that isn't also in the control.\n      // Skipping one frame that we assume is the frame that calls the two.\n      var sampleLines = sample.stack.split('\\n');\n      var controlLines = control.stack.split('\\n');\n      var s = sampleLines.length - 1;\n      var c = controlLines.length - 1;\n\n      while (s >= 1 && c >= 0 && sampleLines[s] !== controlLines[c]) {\n        // We expect at least one stack frame to be shared.\n        // Typically this will be the root most one. However, stack frames may be\n        // cut off due to maximum stack limits. In this case, one maybe cut off\n        // earlier than the other. We assume that the sample is longer or the same\n        // and there for cut off earlier. So we should find the root most frame in\n        // the sample somewhere in the control.\n        c--;\n      }\n\n      for (; s >= 1 && c >= 0; s--, c--) {\n        // Next we find the first one that isn't the same which should be the\n        // frame that called our sample function and the control.\n        if (sampleLines[s] !== controlLines[c]) {\n          // In V8, the first line is describing the message but other VMs don't.\n          // If we're about to return the first line, and the control is also on the same\n          // line, that's a pretty good indicator that our sample threw at same line as\n          // the control. I.e. before we entered the sample frame. So we ignore this result.\n          // This can happen if you passed a class to function component, or non-function.\n          if (s !== 1 || c !== 1) {\n            do {\n              s--;\n              c--; // We may still have similar intermediate frames from the construct call.\n              // The next one that isn't the same should be our match though.\n\n              if (c < 0 || sampleLines[s] !== controlLines[c]) {\n                // V8 adds a \"new\" prefix for native classes. Let's remove it to make it prettier.\n                var _frame = '\\n' + sampleLines[s].replace(' at new ', ' at '); // If our component frame is labeled \"<anonymous>\"\n                // but we have a user-provided \"displayName\"\n                // splice it in to make the stack more readable.\n\n\n                if (fn.displayName && _frame.includes('<anonymous>')) {\n                  _frame = _frame.replace('<anonymous>', fn.displayName);\n                }\n\n                {\n                  if (typeof fn === 'function') {\n                    componentFrameCache.set(fn, _frame);\n                  }\n                } // Return the line we found.\n\n\n                return _frame;\n              }\n            } while (s >= 1 && c >= 0);\n          }\n\n          break;\n        }\n      }\n    }\n  } finally {\n    reentry = false;\n\n    {\n      ReactCurrentDispatcher$1.current = previousDispatcher;\n      reenableLogs();\n    }\n\n    Error.prepareStackTrace = previousPrepareStackTrace;\n  } // Fallback to just using the name if we couldn't make it throw.\n\n\n  var name = fn ? fn.displayName || fn.name : '';\n  var syntheticFrame = name ? describeBuiltInComponentFrame(name) : '';\n\n  {\n    if (typeof fn === 'function') {\n      componentFrameCache.set(fn, syntheticFrame);\n    }\n  }\n\n  return syntheticFrame;\n}\nfunction describeFunctionComponentFrame(fn, source, ownerFn) {\n  {\n    return describeNativeComponentFrame(fn, false);\n  }\n}\n\nfunction shouldConstruct(Component) {\n  var prototype = Component.prototype;\n  return !!(prototype && prototype.isReactComponent);\n}\n\nfunction describeUnknownElementTypeFrameInDEV(type, source, ownerFn) {\n\n  if (type == null) {\n    return '';\n  }\n\n  if (typeof type === 'function') {\n    {\n      return describeNativeComponentFrame(type, shouldConstruct(type));\n    }\n  }\n\n  if (typeof type === 'string') {\n    return describeBuiltInComponentFrame(type);\n  }\n\n  switch (type) {\n    case REACT_SUSPENSE_TYPE:\n      return describeBuiltInComponentFrame('Suspense');\n\n    case REACT_SUSPENSE_LIST_TYPE:\n      return describeBuiltInComponentFrame('SuspenseList');\n  }\n\n  if (typeof type === 'object') {\n    switch (type.$$typeof) {\n      case REACT_FORWARD_REF_TYPE:\n        return describeFunctionComponentFrame(type.render);\n\n      case REACT_MEMO_TYPE:\n        // Memo may contain any component type so we recursively resolve it.\n        return describeUnknownElementTypeFrameInDEV(type.type, source, ownerFn);\n\n      case REACT_LAZY_TYPE:\n        {\n          var lazyComponent = type;\n          var payload = lazyComponent._payload;\n          var init = lazyComponent._init;\n\n          try {\n            // Lazy may contain any component type so we recursively resolve it.\n            return describeUnknownElementTypeFrameInDEV(init(payload), source, ownerFn);\n          } catch (x) {}\n        }\n    }\n  }\n\n  return '';\n}\n\nvar loggedTypeFailures = {};\nvar ReactDebugCurrentFrame$1 = ReactSharedInternals.ReactDebugCurrentFrame;\n\nfunction setCurrentlyValidatingElement(element) {\n  {\n    if (element) {\n      var owner = element._owner;\n      var stack = describeUnknownElementTypeFrameInDEV(element.type, element._source, owner ? owner.type : null);\n      ReactDebugCurrentFrame$1.setExtraStackFrame(stack);\n    } else {\n      ReactDebugCurrentFrame$1.setExtraStackFrame(null);\n    }\n  }\n}\n\nfunction checkPropTypes(typeSpecs, values, location, componentName, element) {\n  {\n    // $FlowFixMe This is okay but Flow doesn't know it.\n    var has = Function.call.bind(hasOwnProperty);\n\n    for (var typeSpecName in typeSpecs) {\n      if (has(typeSpecs, typeSpecName)) {\n        var error$1 = void 0; // Prop type validation may throw. In case they do, we don't want to\n        // fail the render phase where it didn't fail before. So we log it.\n        // After these have been cleaned up, we'll let them throw.\n\n        try {\n          // This is intentionally an invariant that gets caught. It's the same\n          // behavior as without this statement except with a better message.\n          if (typeof typeSpecs[typeSpecName] !== 'function') {\n            // eslint-disable-next-line react-internal/prod-error-codes\n            var err = Error((componentName || 'React class') + ': ' + location + ' type `' + typeSpecName + '` is invalid; ' + 'it must be a function, usually from the `prop-types` package, but received `' + typeof typeSpecs[typeSpecName] + '`.' + 'This often happens because of typos such as `PropTypes.function` instead of `PropTypes.func`.');\n            err.name = 'Invariant Violation';\n            throw err;\n          }\n\n          error$1 = typeSpecs[typeSpecName](values, typeSpecName, componentName, location, null, 'SECRET_DO_NOT_PASS_THIS_OR_YOU_WILL_BE_FIRED');\n        } catch (ex) {\n          error$1 = ex;\n        }\n\n        if (error$1 && !(error$1 instanceof Error)) {\n          setCurrentlyValidatingElement(element);\n\n          error('%s: type specification of %s' + ' `%s` is invalid; the type checker ' + 'function must return `null` or an `Error` but returned a %s. ' + 'You may have forgotten to pass an argument to the type checker ' + 'creator (arrayOf, instanceOf, objectOf, oneOf, oneOfType, and ' + 'shape all require an argument).', componentName || 'React class', location, typeSpecName, typeof error$1);\n\n          setCurrentlyValidatingElement(null);\n        }\n\n        if (error$1 instanceof Error && !(error$1.message in loggedTypeFailures)) {\n          // Only monitor this failure once because there tends to be a lot of the\n          // same error.\n          loggedTypeFailures[error$1.message] = true;\n          setCurrentlyValidatingElement(element);\n\n          error('Failed %s type: %s', location, error$1.message);\n\n          setCurrentlyValidatingElement(null);\n        }\n      }\n    }\n  }\n}\n\nfunction setCurrentlyValidatingElement$1(element) {\n  {\n    if (element) {\n      var owner = element._owner;\n      var stack = describeUnknownElementTypeFrameInDEV(element.type, element._source, owner ? owner.type : null);\n      setExtraStackFrame(stack);\n    } else {\n      setExtraStackFrame(null);\n    }\n  }\n}\n\nvar propTypesMisspellWarningShown;\n\n{\n  propTypesMisspellWarningShown = false;\n}\n\nfunction getDeclarationErrorAddendum() {\n  if (ReactCurrentOwner.current) {\n    var name = getComponentNameFromType(ReactCurrentOwner.current.type);\n\n    if (name) {\n      return '\\n\\nCheck the render method of `' + name + '`.';\n    }\n  }\n\n  return '';\n}\n\nfunction getSourceInfoErrorAddendum(source) {\n  if (source !== undefined) {\n    var fileName = source.fileName.replace(/^.*[\\\\\\/]/, '');\n    var lineNumber = source.lineNumber;\n    return '\\n\\nCheck your code at ' + fileName + ':' + lineNumber + '.';\n  }\n\n  return '';\n}\n\nfunction getSourceInfoErrorAddendumForProps(elementProps) {\n  if (elementProps !== null && elementProps !== undefined) {\n    return getSourceInfoErrorAddendum(elementProps.__source);\n  }\n\n  return '';\n}\n/**\n * Warn if there's no key explicitly set on dynamic arrays of children or\n * object keys are not valid. This allows us to keep track of children between\n * updates.\n */\n\n\nvar ownerHasKeyUseWarning = {};\n\nfunction getCurrentComponentErrorInfo(parentType) {\n  var info = getDeclarationErrorAddendum();\n\n  if (!info) {\n    var parentName = typeof parentType === 'string' ? parentType : parentType.displayName || parentType.name;\n\n    if (parentName) {\n      info = \"\\n\\nCheck the top-level render call using <\" + parentName + \">.\";\n    }\n  }\n\n  return info;\n}\n/**\n * Warn if the element doesn't have an explicit key assigned to it.\n * This element is in an array. The array could grow and shrink or be\n * reordered. All children that haven't already been validated are required to\n * have a \"key\" property assigned to it. Error statuses are cached so a warning\n * will only be shown once.\n *\n * @internal\n * @param {ReactElement} element Element that requires a key.\n * @param {*} parentType element's parent's type.\n */\n\n\nfunction validateExplicitKey(element, parentType) {\n  if (!element._store || element._store.validated || element.key != null) {\n    return;\n  }\n\n  element._store.validated = true;\n  var currentComponentErrorInfo = getCurrentComponentErrorInfo(parentType);\n\n  if (ownerHasKeyUseWarning[currentComponentErrorInfo]) {\n    return;\n  }\n\n  ownerHasKeyUseWarning[currentComponentErrorInfo] = true; // Usually the current owner is the offender, but if it accepts children as a\n  // property, it may be the creator of the child that's responsible for\n  // assigning it a key.\n\n  var childOwner = '';\n\n  if (element && element._owner && element._owner !== ReactCurrentOwner.current) {\n    // Give the component that originally created this child.\n    childOwner = \" It was passed a child from \" + getComponentNameFromType(element._owner.type) + \".\";\n  }\n\n  {\n    setCurrentlyValidatingElement$1(element);\n\n    error('Each child in a list should have a unique \"key\" prop.' + '%s%s See https://reactjs.org/link/warning-keys for more information.', currentComponentErrorInfo, childOwner);\n\n    setCurrentlyValidatingElement$1(null);\n  }\n}\n/**\n * Ensure that every element either is passed in a static location, in an\n * array with an explicit keys property defined, or in an object literal\n * with valid key property.\n *\n * @internal\n * @param {ReactNode} node Statically passed child of any type.\n * @param {*} parentType node's parent's type.\n */\n\n\nfunction validateChildKeys(node, parentType) {\n  if (typeof node !== 'object') {\n    return;\n  }\n\n  if (isArray(node)) {\n    for (var i = 0; i < node.length; i++) {\n      var child = node[i];\n\n      if (isValidElement(child)) {\n        validateExplicitKey(child, parentType);\n      }\n    }\n  } else if (isValidElement(node)) {\n    // This element was passed in a valid location.\n    if (node._store) {\n      node._store.validated = true;\n    }\n  } else if (node) {\n    var iteratorFn = getIteratorFn(node);\n\n    if (typeof iteratorFn === 'function') {\n      // Entry iterators used to provide implicit keys,\n      // but now we print a separate warning for them later.\n      if (iteratorFn !== node.entries) {\n        var iterator = iteratorFn.call(node);\n        var step;\n\n        while (!(step = iterator.next()).done) {\n          if (isValidElement(step.value)) {\n            validateExplicitKey(step.value, parentType);\n          }\n        }\n      }\n    }\n  }\n}\n/**\n * Given an element, validate that its props follow the propTypes definition,\n * provided by the type.\n *\n * @param {ReactElement} element\n */\n\n\nfunction validatePropTypes(element) {\n  {\n    var type = element.type;\n\n    if (type === null || type === undefined || typeof type === 'string') {\n      return;\n    }\n\n    var propTypes;\n\n    if (typeof type === 'function') {\n      propTypes = type.propTypes;\n    } else if (typeof type === 'object' && (type.$$typeof === REACT_FORWARD_REF_TYPE || // Note: Memo only checks outer props here.\n    // Inner props are checked in the reconciler.\n    type.$$typeof === REACT_MEMO_TYPE)) {\n      propTypes = type.propTypes;\n    } else {\n      return;\n    }\n\n    if (propTypes) {\n      // Intentionally inside to avoid triggering lazy initializers:\n      var name = getComponentNameFromType(type);\n      checkPropTypes(propTypes, element.props, 'prop', name, element);\n    } else if (type.PropTypes !== undefined && !propTypesMisspellWarningShown) {\n      propTypesMisspellWarningShown = true; // Intentionally inside to avoid triggering lazy initializers:\n\n      var _name = getComponentNameFromType(type);\n\n      error('Component %s declared `PropTypes` instead of `propTypes`. Did you misspell the property assignment?', _name || 'Unknown');\n    }\n\n    if (typeof type.getDefaultProps === 'function' && !type.getDefaultProps.isReactClassApproved) {\n      error('getDefaultProps is only used on classic React.createClass ' + 'definitions. Use a static property named `defaultProps` instead.');\n    }\n  }\n}\n/**\n * Given a fragment, validate that it can only be provided with fragment props\n * @param {ReactElement} fragment\n */\n\n\nfunction validateFragmentProps(fragment) {\n  {\n    var keys = Object.keys(fragment.props);\n\n    for (var i = 0; i < keys.length; i++) {\n      var key = keys[i];\n\n      if (key !== 'children' && key !== 'key') {\n        setCurrentlyValidatingElement$1(fragment);\n\n        error('Invalid prop `%s` supplied to `React.Fragment`. ' + 'React.Fragment can only have `key` and `children` props.', key);\n\n        setCurrentlyValidatingElement$1(null);\n        break;\n      }\n    }\n\n    if (fragment.ref !== null) {\n      setCurrentlyValidatingElement$1(fragment);\n\n      error('Invalid attribute `ref` supplied to `React.Fragment`.');\n\n      setCurrentlyValidatingElement$1(null);\n    }\n  }\n}\nfunction createElementWithValidation(type, props, children) {\n  var validType = isValidElementType(type); // We warn in this case but don't throw. We expect the element creation to\n  // succeed and there will likely be errors in render.\n\n  if (!validType) {\n    var info = '';\n\n    if (type === undefined || typeof type === 'object' && type !== null && Object.keys(type).length === 0) {\n      info += ' You likely forgot to export your component from the file ' + \"it's defined in, or you might have mixed up default and named imports.\";\n    }\n\n    var sourceInfo = getSourceInfoErrorAddendumForProps(props);\n\n    if (sourceInfo) {\n      info += sourceInfo;\n    } else {\n      info += getDeclarationErrorAddendum();\n    }\n\n    var typeString;\n\n    if (type === null) {\n      typeString = 'null';\n    } else if (isArray(type)) {\n      typeString = 'array';\n    } else if (type !== undefined && type.$$typeof === REACT_ELEMENT_TYPE) {\n      typeString = \"<\" + (getComponentNameFromType(type.type) || 'Unknown') + \" />\";\n      info = ' Did you accidentally export a JSX literal instead of a component?';\n    } else {\n      typeString = typeof type;\n    }\n\n    {\n      error('React.createElement: type is invalid -- expected a string (for ' + 'built-in components) or a class/function (for composite ' + 'components) but got: %s.%s', typeString, info);\n    }\n  }\n\n  var element = createElement.apply(this, arguments); // The result can be nullish if a mock or a custom function is used.\n  // TODO: Drop this when these are no longer allowed as the type argument.\n\n  if (element == null) {\n    return element;\n  } // Skip key warning if the type isn't valid since our key validation logic\n  // doesn't expect a non-string/function type and can throw confusing errors.\n  // We don't want exception behavior to differ between dev and prod.\n  // (Rendering will throw with a helpful message and as soon as the type is\n  // fixed, the key warnings will appear.)\n\n\n  if (validType) {\n    for (var i = 2; i < arguments.length; i++) {\n      validateChildKeys(arguments[i], type);\n    }\n  }\n\n  if (type === REACT_FRAGMENT_TYPE) {\n    validateFragmentProps(element);\n  } else {\n    validatePropTypes(element);\n  }\n\n  return element;\n}\nvar didWarnAboutDeprecatedCreateFactory = false;\nfunction createFactoryWithValidation(type) {\n  var validatedFactory = createElementWithValidation.bind(null, type);\n  validatedFactory.type = type;\n\n  {\n    if (!didWarnAboutDeprecatedCreateFactory) {\n      didWarnAboutDeprecatedCreateFactory = true;\n\n      warn('React.createFactory() is deprecated and will be removed in ' + 'a future major release. Consider using JSX ' + 'or use React.createElement() directly instead.');\n    } // Legacy hook: remove it\n\n\n    Object.defineProperty(validatedFactory, 'type', {\n      enumerable: false,\n      get: function () {\n        warn('Factory.type is deprecated. Access the class directly ' + 'before passing it to createFactory.');\n\n        Object.defineProperty(this, 'type', {\n          value: type\n        });\n        return type;\n      }\n    });\n  }\n\n  return validatedFactory;\n}\nfunction cloneElementWithValidation(element, props, children) {\n  var newElement = cloneElement.apply(this, arguments);\n\n  for (var i = 2; i < arguments.length; i++) {\n    validateChildKeys(arguments[i], newElement.type);\n  }\n\n  validatePropTypes(newElement);\n  return newElement;\n}\n\nfunction startTransition(scope, options) {\n  var prevTransition = ReactCurrentBatchConfig.transition;\n  ReactCurrentBatchConfig.transition = {};\n  var currentTransition = ReactCurrentBatchConfig.transition;\n\n  {\n    ReactCurrentBatchConfig.transition._updatedFibers = new Set();\n  }\n\n  try {\n    scope();\n  } finally {\n    ReactCurrentBatchConfig.transition = prevTransition;\n\n    {\n      if (prevTransition === null && currentTransition._updatedFibers) {\n        var updatedFibersCount = currentTransition._updatedFibers.size;\n\n        if (updatedFibersCount > 10) {\n          warn('Detected a large number of updates inside startTransition. ' + 'If this is due to a subscription please re-write it to use React provided hooks. ' + 'Otherwise concurrent mode guarantees are off the table.');\n        }\n\n        currentTransition._updatedFibers.clear();\n      }\n    }\n  }\n}\n\nvar didWarnAboutMessageChannel = false;\nvar enqueueTaskImpl = null;\nfunction enqueueTask(task) {\n  if (enqueueTaskImpl === null) {\n    try {\n      // read require off the module object to get around the bundlers.\n      // we don't want them to detect a require and bundle a Node polyfill.\n      var requireString = ('require' + Math.random()).slice(0, 7);\n      var nodeRequire = module && module[requireString]; // assuming we're in node, let's try to get node's\n      // version of setImmediate, bypassing fake timers if any.\n\n      enqueueTaskImpl = nodeRequire.call(module, 'timers').setImmediate;\n    } catch (_err) {\n      // we're in a browser\n      // we can't use regular timers because they may still be faked\n      // so we try MessageChannel+postMessage instead\n      enqueueTaskImpl = function (callback) {\n        {\n          if (didWarnAboutMessageChannel === false) {\n            didWarnAboutMessageChannel = true;\n\n            if (typeof MessageChannel === 'undefined') {\n              error('This browser does not have a MessageChannel implementation, ' + 'so enqueuing tasks via await act(async () => ...) will fail. ' + 'Please file an issue at https://github.com/facebook/react/issues ' + 'if you encounter this warning.');\n            }\n          }\n        }\n\n        var channel = new MessageChannel();\n        channel.port1.onmessage = callback;\n        channel.port2.postMessage(undefined);\n      };\n    }\n  }\n\n  return enqueueTaskImpl(task);\n}\n\nvar actScopeDepth = 0;\nvar didWarnNoAwaitAct = false;\nfunction act(callback) {\n  {\n    // `act` calls can be nested, so we track the depth. This represents the\n    // number of `act` scopes on the stack.\n    var prevActScopeDepth = actScopeDepth;\n    actScopeDepth++;\n\n    if (ReactCurrentActQueue.current === null) {\n      // This is the outermost `act` scope. Initialize the queue. The reconciler\n      // will detect the queue and use it instead of Scheduler.\n      ReactCurrentActQueue.current = [];\n    }\n\n    var prevIsBatchingLegacy = ReactCurrentActQueue.isBatchingLegacy;\n    var result;\n\n    try {\n      // Used to reproduce behavior of `batchedUpdates` in legacy mode. Only\n      // set to `true` while the given callback is executed, not for updates\n      // triggered during an async event, because this is how the legacy\n      // implementation of `act` behaved.\n      ReactCurrentActQueue.isBatchingLegacy = true;\n      result = callback(); // Replicate behavior of original `act` implementation in legacy mode,\n      // which flushed updates immediately after the scope function exits, even\n      // if it's an async function.\n\n      if (!prevIsBatchingLegacy && ReactCurrentActQueue.didScheduleLegacyUpdate) {\n        var queue = ReactCurrentActQueue.current;\n\n        if (queue !== null) {\n          ReactCurrentActQueue.didScheduleLegacyUpdate = false;\n          flushActQueue(queue);\n        }\n      }\n    } catch (error) {\n      popActScope(prevActScopeDepth);\n      throw error;\n    } finally {\n      ReactCurrentActQueue.isBatchingLegacy = prevIsBatchingLegacy;\n    }\n\n    if (result !== null && typeof result === 'object' && typeof result.then === 'function') {\n      var thenableResult = result; // The callback is an async function (i.e. returned a promise). Wait\n      // for it to resolve before exiting the current scope.\n\n      var wasAwaited = false;\n      var thenable = {\n        then: function (resolve, reject) {\n          wasAwaited = true;\n          thenableResult.then(function (returnValue) {\n            popActScope(prevActScopeDepth);\n\n            if (actScopeDepth === 0) {\n              // We've exited the outermost act scope. Recursively flush the\n              // queue until there's no remaining work.\n              recursivelyFlushAsyncActWork(returnValue, resolve, reject);\n            } else {\n              resolve(returnValue);\n            }\n          }, function (error) {\n            // The callback threw an error.\n            popActScope(prevActScopeDepth);\n            reject(error);\n          });\n        }\n      };\n\n      {\n        if (!didWarnNoAwaitAct && typeof Promise !== 'undefined') {\n          // eslint-disable-next-line no-undef\n          Promise.resolve().then(function () {}).then(function () {\n            if (!wasAwaited) {\n              didWarnNoAwaitAct = true;\n\n              error('You called act(async () => ...) without await. ' + 'This could lead to unexpected testing behaviour, ' + 'interleaving multiple act calls and mixing their ' + 'scopes. ' + 'You should - await act(async () => ...);');\n            }\n          });\n        }\n      }\n\n      return thenable;\n    } else {\n      var returnValue = result; // The callback is not an async function. Exit the current scope\n      // immediately, without awaiting.\n\n      popActScope(prevActScopeDepth);\n\n      if (actScopeDepth === 0) {\n        // Exiting the outermost act scope. Flush the queue.\n        var _queue = ReactCurrentActQueue.current;\n\n        if (_queue !== null) {\n          flushActQueue(_queue);\n          ReactCurrentActQueue.current = null;\n        } // Return a thenable. If the user awaits it, we'll flush again in\n        // case additional work was scheduled by a microtask.\n\n\n        var _thenable = {\n          then: function (resolve, reject) {\n            // Confirm we haven't re-entered another `act` scope, in case\n            // the user does something weird like await the thenable\n            // multiple times.\n            if (ReactCurrentActQueue.current === null) {\n              // Recursively flush the queue until there's no remaining work.\n              ReactCurrentActQueue.current = [];\n              recursivelyFlushAsyncActWork(returnValue, resolve, reject);\n            } else {\n              resolve(returnValue);\n            }\n          }\n        };\n        return _thenable;\n      } else {\n        // Since we're inside a nested `act` scope, the returned thenable\n        // immediately resolves. The outer scope will flush the queue.\n        var _thenable2 = {\n          then: function (resolve, reject) {\n            resolve(returnValue);\n          }\n        };\n        return _thenable2;\n      }\n    }\n  }\n}\n\nfunction popActScope(prevActScopeDepth) {\n  {\n    if (prevActScopeDepth !== actScopeDepth - 1) {\n      error('You seem to have overlapping act() calls, this is not supported. ' + 'Be sure to await previous act() calls before making a new one. ');\n    }\n\n    actScopeDepth = prevActScopeDepth;\n  }\n}\n\nfunction recursivelyFlushAsyncActWork(returnValue, resolve, reject) {\n  {\n    var queue = ReactCurrentActQueue.current;\n\n    if (queue !== null) {\n      try {\n        flushActQueue(queue);\n        enqueueTask(function () {\n          if (queue.length === 0) {\n            // No additional work was scheduled. Finish.\n            ReactCurrentActQueue.current = null;\n            resolve(returnValue);\n          } else {\n            // Keep flushing work until there's none left.\n            recursivelyFlushAsyncActWork(returnValue, resolve, reject);\n          }\n        });\n      } catch (error) {\n        reject(error);\n      }\n    } else {\n      resolve(returnValue);\n    }\n  }\n}\n\nvar isFlushing = false;\n\nfunction flushActQueue(queue) {\n  {\n    if (!isFlushing) {\n      // Prevent re-entrance.\n      isFlushing = true;\n      var i = 0;\n\n      try {\n        for (; i < queue.length; i++) {\n          var callback = queue[i];\n\n          do {\n            callback = callback(true);\n          } while (callback !== null);\n        }\n\n        queue.length = 0;\n      } catch (error) {\n        // If something throws, leave the remaining callbacks on the queue.\n        queue = queue.slice(i + 1);\n        throw error;\n      } finally {\n        isFlushing = false;\n      }\n    }\n  }\n}\n\nvar createElement$1 =  createElementWithValidation ;\nvar cloneElement$1 =  cloneElementWithValidation ;\nvar createFactory =  createFactoryWithValidation ;\nvar Children = {\n  map: mapChildren,\n  forEach: forEachChildren,\n  count: countChildren,\n  toArray: toArray,\n  only: onlyChild\n};\n\nexports.Children = Children;\nexports.Component = Component;\nexports.Fragment = REACT_FRAGMENT_TYPE;\nexports.Profiler = REACT_PROFILER_TYPE;\nexports.PureComponent = PureComponent;\nexports.StrictMode = REACT_STRICT_MODE_TYPE;\nexports.Suspense = REACT_SUSPENSE_TYPE;\nexports.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED = ReactSharedInternals;\nexports.cloneElement = cloneElement$1;\nexports.createContext = createContext;\nexports.createElement = createElement$1;\nexports.createFactory = createFactory;\nexports.createRef = createRef;\nexports.forwardRef = forwardRef;\nexports.isValidElement = isValidElement;\nexports.lazy = lazy;\nexports.memo = memo;\nexports.startTransition = startTransition;\nexports.unstable_act = act;\nexports.useCallback = useCallback;\nexports.useContext = useContext;\nexports.useDebugValue = useDebugValue;\nexports.useDeferredValue = useDeferredValue;\nexports.useEffect = useEffect;\nexports.useId = useId;\nexports.useImperativeHandle = useImperativeHandle;\nexports.useInsertionEffect = useInsertionEffect;\nexports.useLayoutEffect = useLayoutEffect;\nexports.useMemo = useMemo;\nexports.useReducer = useReducer;\nexports.useRef = useRef;\nexports.useState = useState;\nexports.useSyncExternalStore = useSyncExternalStore;\nexports.useTransition = useTransition;\nexports.version = ReactVersion;\n          /* global __REACT_DEVTOOLS_GLOBAL_HOOK__ */\nif (\n  typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ !== 'undefined' &&\n  typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStop ===\n    'function'\n) {\n  __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStop(new Error());\n}\n        \n  })();\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/react/cjs/react.development.js?");

/***/ }),

/***/ "./node_modules/react/index.js":
/*!*************************************!*\
  !*** ./node_modules/react/index.js ***!
  \*************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nif (false) {} else {\n  module.exports = __webpack_require__(/*! ./cjs/react.development.js */ \"./node_modules/react/cjs/react.development.js\");\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/react/index.js?");

/***/ }),

/***/ "./node_modules/sax/lib/sax.js":
/*!*************************************!*\
  !*** ./node_modules/sax/lib/sax.js ***!
  \*************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval(";(function (sax) { // wrapper for non-node envs\n  sax.parser = function (strict, opt) { return new SAXParser(strict, opt) }\n  sax.SAXParser = SAXParser\n  sax.SAXStream = SAXStream\n  sax.createStream = createStream\n\n  // When we pass the MAX_BUFFER_LENGTH position, start checking for buffer overruns.\n  // When we check, schedule the next check for MAX_BUFFER_LENGTH - (max(buffer lengths)),\n  // since that's the earliest that a buffer overrun could occur.  This way, checks are\n  // as rare as required, but as often as necessary to ensure never crossing this bound.\n  // Furthermore, buffers are only tested at most once per write(), so passing a very\n  // large string into write() might have undesirable effects, but this is manageable by\n  // the caller, so it is assumed to be safe.  Thus, a call to write() may, in the extreme\n  // edge case, result in creating at most one complete copy of the string passed in.\n  // Set to Infinity to have unlimited buffers.\n  sax.MAX_BUFFER_LENGTH = 64 * 1024\n\n  var buffers = [\n    'comment', 'sgmlDecl', 'textNode', 'tagName', 'doctype',\n    'procInstName', 'procInstBody', 'entity', 'attribName',\n    'attribValue', 'cdata', 'script'\n  ]\n\n  sax.EVENTS = [\n    'text',\n    'processinginstruction',\n    'sgmldeclaration',\n    'doctype',\n    'comment',\n    'opentagstart',\n    'attribute',\n    'opentag',\n    'closetag',\n    'opencdata',\n    'cdata',\n    'closecdata',\n    'error',\n    'end',\n    'ready',\n    'script',\n    'opennamespace',\n    'closenamespace'\n  ]\n\n  function SAXParser (strict, opt) {\n    if (!(this instanceof SAXParser)) {\n      return new SAXParser(strict, opt)\n    }\n\n    var parser = this\n    clearBuffers(parser)\n    parser.q = parser.c = ''\n    parser.bufferCheckPosition = sax.MAX_BUFFER_LENGTH\n    parser.opt = opt || {}\n    parser.opt.lowercase = parser.opt.lowercase || parser.opt.lowercasetags\n    parser.looseCase = parser.opt.lowercase ? 'toLowerCase' : 'toUpperCase'\n    parser.tags = []\n    parser.closed = parser.closedRoot = parser.sawRoot = false\n    parser.tag = parser.error = null\n    parser.strict = !!strict\n    parser.noscript = !!(strict || parser.opt.noscript)\n    parser.state = S.BEGIN\n    parser.strictEntities = parser.opt.strictEntities\n    parser.ENTITIES = parser.strictEntities ? Object.create(sax.XML_ENTITIES) : Object.create(sax.ENTITIES)\n    parser.attribList = []\n\n    // namespaces form a prototype chain.\n    // it always points at the current tag,\n    // which protos to its parent tag.\n    if (parser.opt.xmlns) {\n      parser.ns = Object.create(rootNS)\n    }\n\n    // mostly just for error reporting\n    parser.trackPosition = parser.opt.position !== false\n    if (parser.trackPosition) {\n      parser.position = parser.line = parser.column = 0\n    }\n    emit(parser, 'onready')\n  }\n\n  if (!Object.create) {\n    Object.create = function (o) {\n      function F () {}\n      F.prototype = o\n      var newf = new F()\n      return newf\n    }\n  }\n\n  if (!Object.keys) {\n    Object.keys = function (o) {\n      var a = []\n      for (var i in o) if (o.hasOwnProperty(i)) a.push(i)\n      return a\n    }\n  }\n\n  function checkBufferLength (parser) {\n    var maxAllowed = Math.max(sax.MAX_BUFFER_LENGTH, 10)\n    var maxActual = 0\n    for (var i = 0, l = buffers.length; i < l; i++) {\n      var len = parser[buffers[i]].length\n      if (len > maxAllowed) {\n        // Text/cdata nodes can get big, and since they're buffered,\n        // we can get here under normal conditions.\n        // Avoid issues by emitting the text node now,\n        // so at least it won't get any bigger.\n        switch (buffers[i]) {\n          case 'textNode':\n            closeText(parser)\n            break\n\n          case 'cdata':\n            emitNode(parser, 'oncdata', parser.cdata)\n            parser.cdata = ''\n            break\n\n          case 'script':\n            emitNode(parser, 'onscript', parser.script)\n            parser.script = ''\n            break\n\n          default:\n            error(parser, 'Max buffer length exceeded: ' + buffers[i])\n        }\n      }\n      maxActual = Math.max(maxActual, len)\n    }\n    // schedule the next check for the earliest possible buffer overrun.\n    var m = sax.MAX_BUFFER_LENGTH - maxActual\n    parser.bufferCheckPosition = m + parser.position\n  }\n\n  function clearBuffers (parser) {\n    for (var i = 0, l = buffers.length; i < l; i++) {\n      parser[buffers[i]] = ''\n    }\n  }\n\n  function flushBuffers (parser) {\n    closeText(parser)\n    if (parser.cdata !== '') {\n      emitNode(parser, 'oncdata', parser.cdata)\n      parser.cdata = ''\n    }\n    if (parser.script !== '') {\n      emitNode(parser, 'onscript', parser.script)\n      parser.script = ''\n    }\n  }\n\n  SAXParser.prototype = {\n    end: function () { end(this) },\n    write: write,\n    resume: function () { this.error = null; return this },\n    close: function () { return this.write(null) },\n    flush: function () { flushBuffers(this) }\n  }\n\n  var Stream\n  try {\n    Stream = (__webpack_require__(/*! stream */ \"stream\").Stream)\n  } catch (ex) {\n    Stream = function () {}\n  }\n\n  var streamWraps = sax.EVENTS.filter(function (ev) {\n    return ev !== 'error' && ev !== 'end'\n  })\n\n  function createStream (strict, opt) {\n    return new SAXStream(strict, opt)\n  }\n\n  function SAXStream (strict, opt) {\n    if (!(this instanceof SAXStream)) {\n      return new SAXStream(strict, opt)\n    }\n\n    Stream.apply(this)\n\n    this._parser = new SAXParser(strict, opt)\n    this.writable = true\n    this.readable = true\n\n    var me = this\n\n    this._parser.onend = function () {\n      me.emit('end')\n    }\n\n    this._parser.onerror = function (er) {\n      me.emit('error', er)\n\n      // if didn't throw, then means error was handled.\n      // go ahead and clear error, so we can write again.\n      me._parser.error = null\n    }\n\n    this._decoder = null\n\n    streamWraps.forEach(function (ev) {\n      Object.defineProperty(me, 'on' + ev, {\n        get: function () {\n          return me._parser['on' + ev]\n        },\n        set: function (h) {\n          if (!h) {\n            me.removeAllListeners(ev)\n            me._parser['on' + ev] = h\n            return h\n          }\n          me.on(ev, h)\n        },\n        enumerable: true,\n        configurable: false\n      })\n    })\n  }\n\n  SAXStream.prototype = Object.create(Stream.prototype, {\n    constructor: {\n      value: SAXStream\n    }\n  })\n\n  SAXStream.prototype.write = function (data) {\n    if (typeof Buffer === 'function' &&\n      typeof Buffer.isBuffer === 'function' &&\n      Buffer.isBuffer(data)) {\n      if (!this._decoder) {\n        var SD = (__webpack_require__(/*! string_decoder */ \"string_decoder\").StringDecoder)\n        this._decoder = new SD('utf8')\n      }\n      data = this._decoder.write(data)\n    }\n\n    this._parser.write(data.toString())\n    this.emit('data', data)\n    return true\n  }\n\n  SAXStream.prototype.end = function (chunk) {\n    if (chunk && chunk.length) {\n      this.write(chunk)\n    }\n    this._parser.end()\n    return true\n  }\n\n  SAXStream.prototype.on = function (ev, handler) {\n    var me = this\n    if (!me._parser['on' + ev] && streamWraps.indexOf(ev) !== -1) {\n      me._parser['on' + ev] = function () {\n        var args = arguments.length === 1 ? [arguments[0]] : Array.apply(null, arguments)\n        args.splice(0, 0, ev)\n        me.emit.apply(me, args)\n      }\n    }\n\n    return Stream.prototype.on.call(me, ev, handler)\n  }\n\n  // this really needs to be replaced with character classes.\n  // XML allows all manner of ridiculous numbers and digits.\n  var CDATA = '[CDATA['\n  var DOCTYPE = 'DOCTYPE'\n  var XML_NAMESPACE = 'http://www.w3.org/XML/1998/namespace'\n  var XMLNS_NAMESPACE = 'http://www.w3.org/2000/xmlns/'\n  var rootNS = { xml: XML_NAMESPACE, xmlns: XMLNS_NAMESPACE }\n\n  // http://www.w3.org/TR/REC-xml/#NT-NameStartChar\n  // This implementation works on strings, a single character at a time\n  // as such, it cannot ever support astral-plane characters (10000-EFFFF)\n  // without a significant breaking change to either this  parser, or the\n  // JavaScript language.  Implementation of an emoji-capable xml parser\n  // is left as an exercise for the reader.\n  var nameStart = /[:_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD]/\n\n  var nameBody = /[:_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\u00B7\\u0300-\\u036F\\u203F-\\u2040.\\d-]/\n\n  var entityStart = /[#:_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD]/\n  var entityBody = /[#:_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\u00B7\\u0300-\\u036F\\u203F-\\u2040.\\d-]/\n\n  function isWhitespace (c) {\n    return c === ' ' || c === '\\n' || c === '\\r' || c === '\\t'\n  }\n\n  function isQuote (c) {\n    return c === '\"' || c === '\\''\n  }\n\n  function isAttribEnd (c) {\n    return c === '>' || isWhitespace(c)\n  }\n\n  function isMatch (regex, c) {\n    return regex.test(c)\n  }\n\n  function notMatch (regex, c) {\n    return !isMatch(regex, c)\n  }\n\n  var S = 0\n  sax.STATE = {\n    BEGIN: S++, // leading byte order mark or whitespace\n    BEGIN_WHITESPACE: S++, // leading whitespace\n    TEXT: S++, // general stuff\n    TEXT_ENTITY: S++, // &amp and such.\n    OPEN_WAKA: S++, // <\n    SGML_DECL: S++, // <!BLARG\n    SGML_DECL_QUOTED: S++, // <!BLARG foo \"bar\n    DOCTYPE: S++, // <!DOCTYPE\n    DOCTYPE_QUOTED: S++, // <!DOCTYPE \"//blah\n    DOCTYPE_DTD: S++, // <!DOCTYPE \"//blah\" [ ...\n    DOCTYPE_DTD_QUOTED: S++, // <!DOCTYPE \"//blah\" [ \"foo\n    COMMENT_STARTING: S++, // <!-\n    COMMENT: S++, // <!--\n    COMMENT_ENDING: S++, // <!-- blah -\n    COMMENT_ENDED: S++, // <!-- blah --\n    CDATA: S++, // <![CDATA[ something\n    CDATA_ENDING: S++, // ]\n    CDATA_ENDING_2: S++, // ]]\n    PROC_INST: S++, // <?hi\n    PROC_INST_BODY: S++, // <?hi there\n    PROC_INST_ENDING: S++, // <?hi \"there\" ?\n    OPEN_TAG: S++, // <strong\n    OPEN_TAG_SLASH: S++, // <strong /\n    ATTRIB: S++, // <a\n    ATTRIB_NAME: S++, // <a foo\n    ATTRIB_NAME_SAW_WHITE: S++, // <a foo _\n    ATTRIB_VALUE: S++, // <a foo=\n    ATTRIB_VALUE_QUOTED: S++, // <a foo=\"bar\n    ATTRIB_VALUE_CLOSED: S++, // <a foo=\"bar\"\n    ATTRIB_VALUE_UNQUOTED: S++, // <a foo=bar\n    ATTRIB_VALUE_ENTITY_Q: S++, // <foo bar=\"&quot;\"\n    ATTRIB_VALUE_ENTITY_U: S++, // <foo bar=&quot\n    CLOSE_TAG: S++, // </a\n    CLOSE_TAG_SAW_WHITE: S++, // </a   >\n    SCRIPT: S++, // <script> ...\n    SCRIPT_ENDING: S++ // <script> ... <\n  }\n\n  sax.XML_ENTITIES = {\n    'amp': '&',\n    'gt': '>',\n    'lt': '<',\n    'quot': '\"',\n    'apos': \"'\"\n  }\n\n  sax.ENTITIES = {\n    'amp': '&',\n    'gt': '>',\n    'lt': '<',\n    'quot': '\"',\n    'apos': \"'\",\n    'AElig': 198,\n    'Aacute': 193,\n    'Acirc': 194,\n    'Agrave': 192,\n    'Aring': 197,\n    'Atilde': 195,\n    'Auml': 196,\n    'Ccedil': 199,\n    'ETH': 208,\n    'Eacute': 201,\n    'Ecirc': 202,\n    'Egrave': 200,\n    'Euml': 203,\n    'Iacute': 205,\n    'Icirc': 206,\n    'Igrave': 204,\n    'Iuml': 207,\n    'Ntilde': 209,\n    'Oacute': 211,\n    'Ocirc': 212,\n    'Ograve': 210,\n    'Oslash': 216,\n    'Otilde': 213,\n    'Ouml': 214,\n    'THORN': 222,\n    'Uacute': 218,\n    'Ucirc': 219,\n    'Ugrave': 217,\n    'Uuml': 220,\n    'Yacute': 221,\n    'aacute': 225,\n    'acirc': 226,\n    'aelig': 230,\n    'agrave': 224,\n    'aring': 229,\n    'atilde': 227,\n    'auml': 228,\n    'ccedil': 231,\n    'eacute': 233,\n    'ecirc': 234,\n    'egrave': 232,\n    'eth': 240,\n    'euml': 235,\n    'iacute': 237,\n    'icirc': 238,\n    'igrave': 236,\n    'iuml': 239,\n    'ntilde': 241,\n    'oacute': 243,\n    'ocirc': 244,\n    'ograve': 242,\n    'oslash': 248,\n    'otilde': 245,\n    'ouml': 246,\n    'szlig': 223,\n    'thorn': 254,\n    'uacute': 250,\n    'ucirc': 251,\n    'ugrave': 249,\n    'uuml': 252,\n    'yacute': 253,\n    'yuml': 255,\n    'copy': 169,\n    'reg': 174,\n    'nbsp': 160,\n    'iexcl': 161,\n    'cent': 162,\n    'pound': 163,\n    'curren': 164,\n    'yen': 165,\n    'brvbar': 166,\n    'sect': 167,\n    'uml': 168,\n    'ordf': 170,\n    'laquo': 171,\n    'not': 172,\n    'shy': 173,\n    'macr': 175,\n    'deg': 176,\n    'plusmn': 177,\n    'sup1': 185,\n    'sup2': 178,\n    'sup3': 179,\n    'acute': 180,\n    'micro': 181,\n    'para': 182,\n    'middot': 183,\n    'cedil': 184,\n    'ordm': 186,\n    'raquo': 187,\n    'frac14': 188,\n    'frac12': 189,\n    'frac34': 190,\n    'iquest': 191,\n    'times': 215,\n    'divide': 247,\n    'OElig': 338,\n    'oelig': 339,\n    'Scaron': 352,\n    'scaron': 353,\n    'Yuml': 376,\n    'fnof': 402,\n    'circ': 710,\n    'tilde': 732,\n    'Alpha': 913,\n    'Beta': 914,\n    'Gamma': 915,\n    'Delta': 916,\n    'Epsilon': 917,\n    'Zeta': 918,\n    'Eta': 919,\n    'Theta': 920,\n    'Iota': 921,\n    'Kappa': 922,\n    'Lambda': 923,\n    'Mu': 924,\n    'Nu': 925,\n    'Xi': 926,\n    'Omicron': 927,\n    'Pi': 928,\n    'Rho': 929,\n    'Sigma': 931,\n    'Tau': 932,\n    'Upsilon': 933,\n    'Phi': 934,\n    'Chi': 935,\n    'Psi': 936,\n    'Omega': 937,\n    'alpha': 945,\n    'beta': 946,\n    'gamma': 947,\n    'delta': 948,\n    'epsilon': 949,\n    'zeta': 950,\n    'eta': 951,\n    'theta': 952,\n    'iota': 953,\n    'kappa': 954,\n    'lambda': 955,\n    'mu': 956,\n    'nu': 957,\n    'xi': 958,\n    'omicron': 959,\n    'pi': 960,\n    'rho': 961,\n    'sigmaf': 962,\n    'sigma': 963,\n    'tau': 964,\n    'upsilon': 965,\n    'phi': 966,\n    'chi': 967,\n    'psi': 968,\n    'omega': 969,\n    'thetasym': 977,\n    'upsih': 978,\n    'piv': 982,\n    'ensp': 8194,\n    'emsp': 8195,\n    'thinsp': 8201,\n    'zwnj': 8204,\n    'zwj': 8205,\n    'lrm': 8206,\n    'rlm': 8207,\n    'ndash': 8211,\n    'mdash': 8212,\n    'lsquo': 8216,\n    'rsquo': 8217,\n    'sbquo': 8218,\n    'ldquo': 8220,\n    'rdquo': 8221,\n    'bdquo': 8222,\n    'dagger': 8224,\n    'Dagger': 8225,\n    'bull': 8226,\n    'hellip': 8230,\n    'permil': 8240,\n    'prime': 8242,\n    'Prime': 8243,\n    'lsaquo': 8249,\n    'rsaquo': 8250,\n    'oline': 8254,\n    'frasl': 8260,\n    'euro': 8364,\n    'image': 8465,\n    'weierp': 8472,\n    'real': 8476,\n    'trade': 8482,\n    'alefsym': 8501,\n    'larr': 8592,\n    'uarr': 8593,\n    'rarr': 8594,\n    'darr': 8595,\n    'harr': 8596,\n    'crarr': 8629,\n    'lArr': 8656,\n    'uArr': 8657,\n    'rArr': 8658,\n    'dArr': 8659,\n    'hArr': 8660,\n    'forall': 8704,\n    'part': 8706,\n    'exist': 8707,\n    'empty': 8709,\n    'nabla': 8711,\n    'isin': 8712,\n    'notin': 8713,\n    'ni': 8715,\n    'prod': 8719,\n    'sum': 8721,\n    'minus': 8722,\n    'lowast': 8727,\n    'radic': 8730,\n    'prop': 8733,\n    'infin': 8734,\n    'ang': 8736,\n    'and': 8743,\n    'or': 8744,\n    'cap': 8745,\n    'cup': 8746,\n    'int': 8747,\n    'there4': 8756,\n    'sim': 8764,\n    'cong': 8773,\n    'asymp': 8776,\n    'ne': 8800,\n    'equiv': 8801,\n    'le': 8804,\n    'ge': 8805,\n    'sub': 8834,\n    'sup': 8835,\n    'nsub': 8836,\n    'sube': 8838,\n    'supe': 8839,\n    'oplus': 8853,\n    'otimes': 8855,\n    'perp': 8869,\n    'sdot': 8901,\n    'lceil': 8968,\n    'rceil': 8969,\n    'lfloor': 8970,\n    'rfloor': 8971,\n    'lang': 9001,\n    'rang': 9002,\n    'loz': 9674,\n    'spades': 9824,\n    'clubs': 9827,\n    'hearts': 9829,\n    'diams': 9830\n  }\n\n  Object.keys(sax.ENTITIES).forEach(function (key) {\n    var e = sax.ENTITIES[key]\n    var s = typeof e === 'number' ? String.fromCharCode(e) : e\n    sax.ENTITIES[key] = s\n  })\n\n  for (var s in sax.STATE) {\n    sax.STATE[sax.STATE[s]] = s\n  }\n\n  // shorthand\n  S = sax.STATE\n\n  function emit (parser, event, data) {\n    parser[event] && parser[event](data)\n  }\n\n  function emitNode (parser, nodeType, data) {\n    if (parser.textNode) closeText(parser)\n    emit(parser, nodeType, data)\n  }\n\n  function closeText (parser) {\n    parser.textNode = textopts(parser.opt, parser.textNode)\n    if (parser.textNode) emit(parser, 'ontext', parser.textNode)\n    parser.textNode = ''\n  }\n\n  function textopts (opt, text) {\n    if (opt.trim) text = text.trim()\n    if (opt.normalize) text = text.replace(/\\s+/g, ' ')\n    return text\n  }\n\n  function error (parser, er) {\n    closeText(parser)\n    if (parser.trackPosition) {\n      er += '\\nLine: ' + parser.line +\n        '\\nColumn: ' + parser.column +\n        '\\nChar: ' + parser.c\n    }\n    er = new Error(er)\n    parser.error = er\n    emit(parser, 'onerror', er)\n    return parser\n  }\n\n  function end (parser) {\n    if (parser.sawRoot && !parser.closedRoot) strictFail(parser, 'Unclosed root tag')\n    if ((parser.state !== S.BEGIN) &&\n      (parser.state !== S.BEGIN_WHITESPACE) &&\n      (parser.state !== S.TEXT)) {\n      error(parser, 'Unexpected end')\n    }\n    closeText(parser)\n    parser.c = ''\n    parser.closed = true\n    emit(parser, 'onend')\n    SAXParser.call(parser, parser.strict, parser.opt)\n    return parser\n  }\n\n  function strictFail (parser, message) {\n    if (typeof parser !== 'object' || !(parser instanceof SAXParser)) {\n      throw new Error('bad call to strictFail')\n    }\n    if (parser.strict) {\n      error(parser, message)\n    }\n  }\n\n  function newTag (parser) {\n    if (!parser.strict) parser.tagName = parser.tagName[parser.looseCase]()\n    var parent = parser.tags[parser.tags.length - 1] || parser\n    var tag = parser.tag = { name: parser.tagName, attributes: {} }\n\n    // will be overridden if tag contails an xmlns=\"foo\" or xmlns:foo=\"bar\"\n    if (parser.opt.xmlns) {\n      tag.ns = parent.ns\n    }\n    parser.attribList.length = 0\n    emitNode(parser, 'onopentagstart', tag)\n  }\n\n  function qname (name, attribute) {\n    var i = name.indexOf(':')\n    var qualName = i < 0 ? [ '', name ] : name.split(':')\n    var prefix = qualName[0]\n    var local = qualName[1]\n\n    // <x \"xmlns\"=\"http://foo\">\n    if (attribute && name === 'xmlns') {\n      prefix = 'xmlns'\n      local = ''\n    }\n\n    return { prefix: prefix, local: local }\n  }\n\n  function attrib (parser) {\n    if (!parser.strict) {\n      parser.attribName = parser.attribName[parser.looseCase]()\n    }\n\n    if (parser.attribList.indexOf(parser.attribName) !== -1 ||\n      parser.tag.attributes.hasOwnProperty(parser.attribName)) {\n      parser.attribName = parser.attribValue = ''\n      return\n    }\n\n    if (parser.opt.xmlns) {\n      var qn = qname(parser.attribName, true)\n      var prefix = qn.prefix\n      var local = qn.local\n\n      if (prefix === 'xmlns') {\n        // namespace binding attribute. push the binding into scope\n        if (local === 'xml' && parser.attribValue !== XML_NAMESPACE) {\n          strictFail(parser,\n            'xml: prefix must be bound to ' + XML_NAMESPACE + '\\n' +\n            'Actual: ' + parser.attribValue)\n        } else if (local === 'xmlns' && parser.attribValue !== XMLNS_NAMESPACE) {\n          strictFail(parser,\n            'xmlns: prefix must be bound to ' + XMLNS_NAMESPACE + '\\n' +\n            'Actual: ' + parser.attribValue)\n        } else {\n          var tag = parser.tag\n          var parent = parser.tags[parser.tags.length - 1] || parser\n          if (tag.ns === parent.ns) {\n            tag.ns = Object.create(parent.ns)\n          }\n          tag.ns[local] = parser.attribValue\n        }\n      }\n\n      // defer onattribute events until all attributes have been seen\n      // so any new bindings can take effect. preserve attribute order\n      // so deferred events can be emitted in document order\n      parser.attribList.push([parser.attribName, parser.attribValue])\n    } else {\n      // in non-xmlns mode, we can emit the event right away\n      parser.tag.attributes[parser.attribName] = parser.attribValue\n      emitNode(parser, 'onattribute', {\n        name: parser.attribName,\n        value: parser.attribValue\n      })\n    }\n\n    parser.attribName = parser.attribValue = ''\n  }\n\n  function openTag (parser, selfClosing) {\n    if (parser.opt.xmlns) {\n      // emit namespace binding events\n      var tag = parser.tag\n\n      // add namespace info to tag\n      var qn = qname(parser.tagName)\n      tag.prefix = qn.prefix\n      tag.local = qn.local\n      tag.uri = tag.ns[qn.prefix] || ''\n\n      if (tag.prefix && !tag.uri) {\n        strictFail(parser, 'Unbound namespace prefix: ' +\n          JSON.stringify(parser.tagName))\n        tag.uri = qn.prefix\n      }\n\n      var parent = parser.tags[parser.tags.length - 1] || parser\n      if (tag.ns && parent.ns !== tag.ns) {\n        Object.keys(tag.ns).forEach(function (p) {\n          emitNode(parser, 'onopennamespace', {\n            prefix: p,\n            uri: tag.ns[p]\n          })\n        })\n      }\n\n      // handle deferred onattribute events\n      // Note: do not apply default ns to attributes:\n      //   http://www.w3.org/TR/REC-xml-names/#defaulting\n      for (var i = 0, l = parser.attribList.length; i < l; i++) {\n        var nv = parser.attribList[i]\n        var name = nv[0]\n        var value = nv[1]\n        var qualName = qname(name, true)\n        var prefix = qualName.prefix\n        var local = qualName.local\n        var uri = prefix === '' ? '' : (tag.ns[prefix] || '')\n        var a = {\n          name: name,\n          value: value,\n          prefix: prefix,\n          local: local,\n          uri: uri\n        }\n\n        // if there's any attributes with an undefined namespace,\n        // then fail on them now.\n        if (prefix && prefix !== 'xmlns' && !uri) {\n          strictFail(parser, 'Unbound namespace prefix: ' +\n            JSON.stringify(prefix))\n          a.uri = prefix\n        }\n        parser.tag.attributes[name] = a\n        emitNode(parser, 'onattribute', a)\n      }\n      parser.attribList.length = 0\n    }\n\n    parser.tag.isSelfClosing = !!selfClosing\n\n    // process the tag\n    parser.sawRoot = true\n    parser.tags.push(parser.tag)\n    emitNode(parser, 'onopentag', parser.tag)\n    if (!selfClosing) {\n      // special case for <script> in non-strict mode.\n      if (!parser.noscript && parser.tagName.toLowerCase() === 'script') {\n        parser.state = S.SCRIPT\n      } else {\n        parser.state = S.TEXT\n      }\n      parser.tag = null\n      parser.tagName = ''\n    }\n    parser.attribName = parser.attribValue = ''\n    parser.attribList.length = 0\n  }\n\n  function closeTag (parser) {\n    if (!parser.tagName) {\n      strictFail(parser, 'Weird empty close tag.')\n      parser.textNode += '</>'\n      parser.state = S.TEXT\n      return\n    }\n\n    if (parser.script) {\n      if (parser.tagName !== 'script') {\n        parser.script += '</' + parser.tagName + '>'\n        parser.tagName = ''\n        parser.state = S.SCRIPT\n        return\n      }\n      emitNode(parser, 'onscript', parser.script)\n      parser.script = ''\n    }\n\n    // first make sure that the closing tag actually exists.\n    // <a><b></c></b></a> will close everything, otherwise.\n    var t = parser.tags.length\n    var tagName = parser.tagName\n    if (!parser.strict) {\n      tagName = tagName[parser.looseCase]()\n    }\n    var closeTo = tagName\n    while (t--) {\n      var close = parser.tags[t]\n      if (close.name !== closeTo) {\n        // fail the first time in strict mode\n        strictFail(parser, 'Unexpected close tag')\n      } else {\n        break\n      }\n    }\n\n    // didn't find it.  we already failed for strict, so just abort.\n    if (t < 0) {\n      strictFail(parser, 'Unmatched closing tag: ' + parser.tagName)\n      parser.textNode += '</' + parser.tagName + '>'\n      parser.state = S.TEXT\n      return\n    }\n    parser.tagName = tagName\n    var s = parser.tags.length\n    while (s-- > t) {\n      var tag = parser.tag = parser.tags.pop()\n      parser.tagName = parser.tag.name\n      emitNode(parser, 'onclosetag', parser.tagName)\n\n      var x = {}\n      for (var i in tag.ns) {\n        x[i] = tag.ns[i]\n      }\n\n      var parent = parser.tags[parser.tags.length - 1] || parser\n      if (parser.opt.xmlns && tag.ns !== parent.ns) {\n        // remove namespace bindings introduced by tag\n        Object.keys(tag.ns).forEach(function (p) {\n          var n = tag.ns[p]\n          emitNode(parser, 'onclosenamespace', { prefix: p, uri: n })\n        })\n      }\n    }\n    if (t === 0) parser.closedRoot = true\n    parser.tagName = parser.attribValue = parser.attribName = ''\n    parser.attribList.length = 0\n    parser.state = S.TEXT\n  }\n\n  function parseEntity (parser) {\n    var entity = parser.entity\n    var entityLC = entity.toLowerCase()\n    var num\n    var numStr = ''\n\n    if (parser.ENTITIES[entity]) {\n      return parser.ENTITIES[entity]\n    }\n    if (parser.ENTITIES[entityLC]) {\n      return parser.ENTITIES[entityLC]\n    }\n    entity = entityLC\n    if (entity.charAt(0) === '#') {\n      if (entity.charAt(1) === 'x') {\n        entity = entity.slice(2)\n        num = parseInt(entity, 16)\n        numStr = num.toString(16)\n      } else {\n        entity = entity.slice(1)\n        num = parseInt(entity, 10)\n        numStr = num.toString(10)\n      }\n    }\n    entity = entity.replace(/^0+/, '')\n    if (isNaN(num) || numStr.toLowerCase() !== entity) {\n      strictFail(parser, 'Invalid character entity')\n      return '&' + parser.entity + ';'\n    }\n\n    return String.fromCodePoint(num)\n  }\n\n  function beginWhiteSpace (parser, c) {\n    if (c === '<') {\n      parser.state = S.OPEN_WAKA\n      parser.startTagPosition = parser.position\n    } else if (!isWhitespace(c)) {\n      // have to process this as a text node.\n      // weird, but happens.\n      strictFail(parser, 'Non-whitespace before first tag.')\n      parser.textNode = c\n      parser.state = S.TEXT\n    }\n  }\n\n  function charAt (chunk, i) {\n    var result = ''\n    if (i < chunk.length) {\n      result = chunk.charAt(i)\n    }\n    return result\n  }\n\n  function write (chunk) {\n    var parser = this\n    if (this.error) {\n      throw this.error\n    }\n    if (parser.closed) {\n      return error(parser,\n        'Cannot write after close. Assign an onready handler.')\n    }\n    if (chunk === null) {\n      return end(parser)\n    }\n    if (typeof chunk === 'object') {\n      chunk = chunk.toString()\n    }\n    var i = 0\n    var c = ''\n    while (true) {\n      c = charAt(chunk, i++)\n      parser.c = c\n\n      if (!c) {\n        break\n      }\n\n      if (parser.trackPosition) {\n        parser.position++\n        if (c === '\\n') {\n          parser.line++\n          parser.column = 0\n        } else {\n          parser.column++\n        }\n      }\n\n      switch (parser.state) {\n        case S.BEGIN:\n          parser.state = S.BEGIN_WHITESPACE\n          if (c === '\\uFEFF') {\n            continue\n          }\n          beginWhiteSpace(parser, c)\n          continue\n\n        case S.BEGIN_WHITESPACE:\n          beginWhiteSpace(parser, c)\n          continue\n\n        case S.TEXT:\n          if (parser.sawRoot && !parser.closedRoot) {\n            var starti = i - 1\n            while (c && c !== '<' && c !== '&') {\n              c = charAt(chunk, i++)\n              if (c && parser.trackPosition) {\n                parser.position++\n                if (c === '\\n') {\n                  parser.line++\n                  parser.column = 0\n                } else {\n                  parser.column++\n                }\n              }\n            }\n            parser.textNode += chunk.substring(starti, i - 1)\n          }\n          if (c === '<' && !(parser.sawRoot && parser.closedRoot && !parser.strict)) {\n            parser.state = S.OPEN_WAKA\n            parser.startTagPosition = parser.position\n          } else {\n            if (!isWhitespace(c) && (!parser.sawRoot || parser.closedRoot)) {\n              strictFail(parser, 'Text data outside of root node.')\n            }\n            if (c === '&') {\n              parser.state = S.TEXT_ENTITY\n            } else {\n              parser.textNode += c\n            }\n          }\n          continue\n\n        case S.SCRIPT:\n          // only non-strict\n          if (c === '<') {\n            parser.state = S.SCRIPT_ENDING\n          } else {\n            parser.script += c\n          }\n          continue\n\n        case S.SCRIPT_ENDING:\n          if (c === '/') {\n            parser.state = S.CLOSE_TAG\n          } else {\n            parser.script += '<' + c\n            parser.state = S.SCRIPT\n          }\n          continue\n\n        case S.OPEN_WAKA:\n          // either a /, ?, !, or text is coming next.\n          if (c === '!') {\n            parser.state = S.SGML_DECL\n            parser.sgmlDecl = ''\n          } else if (isWhitespace(c)) {\n            // wait for it...\n          } else if (isMatch(nameStart, c)) {\n            parser.state = S.OPEN_TAG\n            parser.tagName = c\n          } else if (c === '/') {\n            parser.state = S.CLOSE_TAG\n            parser.tagName = ''\n          } else if (c === '?') {\n            parser.state = S.PROC_INST\n            parser.procInstName = parser.procInstBody = ''\n          } else {\n            strictFail(parser, 'Unencoded <')\n            // if there was some whitespace, then add that in.\n            if (parser.startTagPosition + 1 < parser.position) {\n              var pad = parser.position - parser.startTagPosition\n              c = new Array(pad).join(' ') + c\n            }\n            parser.textNode += '<' + c\n            parser.state = S.TEXT\n          }\n          continue\n\n        case S.SGML_DECL:\n          if ((parser.sgmlDecl + c).toUpperCase() === CDATA) {\n            emitNode(parser, 'onopencdata')\n            parser.state = S.CDATA\n            parser.sgmlDecl = ''\n            parser.cdata = ''\n          } else if (parser.sgmlDecl + c === '--') {\n            parser.state = S.COMMENT\n            parser.comment = ''\n            parser.sgmlDecl = ''\n          } else if ((parser.sgmlDecl + c).toUpperCase() === DOCTYPE) {\n            parser.state = S.DOCTYPE\n            if (parser.doctype || parser.sawRoot) {\n              strictFail(parser,\n                'Inappropriately located doctype declaration')\n            }\n            parser.doctype = ''\n            parser.sgmlDecl = ''\n          } else if (c === '>') {\n            emitNode(parser, 'onsgmldeclaration', parser.sgmlDecl)\n            parser.sgmlDecl = ''\n            parser.state = S.TEXT\n          } else if (isQuote(c)) {\n            parser.state = S.SGML_DECL_QUOTED\n            parser.sgmlDecl += c\n          } else {\n            parser.sgmlDecl += c\n          }\n          continue\n\n        case S.SGML_DECL_QUOTED:\n          if (c === parser.q) {\n            parser.state = S.SGML_DECL\n            parser.q = ''\n          }\n          parser.sgmlDecl += c\n          continue\n\n        case S.DOCTYPE:\n          if (c === '>') {\n            parser.state = S.TEXT\n            emitNode(parser, 'ondoctype', parser.doctype)\n            parser.doctype = true // just remember that we saw it.\n          } else {\n            parser.doctype += c\n            if (c === '[') {\n              parser.state = S.DOCTYPE_DTD\n            } else if (isQuote(c)) {\n              parser.state = S.DOCTYPE_QUOTED\n              parser.q = c\n            }\n          }\n          continue\n\n        case S.DOCTYPE_QUOTED:\n          parser.doctype += c\n          if (c === parser.q) {\n            parser.q = ''\n            parser.state = S.DOCTYPE\n          }\n          continue\n\n        case S.DOCTYPE_DTD:\n          parser.doctype += c\n          if (c === ']') {\n            parser.state = S.DOCTYPE\n          } else if (isQuote(c)) {\n            parser.state = S.DOCTYPE_DTD_QUOTED\n            parser.q = c\n          }\n          continue\n\n        case S.DOCTYPE_DTD_QUOTED:\n          parser.doctype += c\n          if (c === parser.q) {\n            parser.state = S.DOCTYPE_DTD\n            parser.q = ''\n          }\n          continue\n\n        case S.COMMENT:\n          if (c === '-') {\n            parser.state = S.COMMENT_ENDING\n          } else {\n            parser.comment += c\n          }\n          continue\n\n        case S.COMMENT_ENDING:\n          if (c === '-') {\n            parser.state = S.COMMENT_ENDED\n            parser.comment = textopts(parser.opt, parser.comment)\n            if (parser.comment) {\n              emitNode(parser, 'oncomment', parser.comment)\n            }\n            parser.comment = ''\n          } else {\n            parser.comment += '-' + c\n            parser.state = S.COMMENT\n          }\n          continue\n\n        case S.COMMENT_ENDED:\n          if (c !== '>') {\n            strictFail(parser, 'Malformed comment')\n            // allow <!-- blah -- bloo --> in non-strict mode,\n            // which is a comment of \" blah -- bloo \"\n            parser.comment += '--' + c\n            parser.state = S.COMMENT\n          } else {\n            parser.state = S.TEXT\n          }\n          continue\n\n        case S.CDATA:\n          if (c === ']') {\n            parser.state = S.CDATA_ENDING\n          } else {\n            parser.cdata += c\n          }\n          continue\n\n        case S.CDATA_ENDING:\n          if (c === ']') {\n            parser.state = S.CDATA_ENDING_2\n          } else {\n            parser.cdata += ']' + c\n            parser.state = S.CDATA\n          }\n          continue\n\n        case S.CDATA_ENDING_2:\n          if (c === '>') {\n            if (parser.cdata) {\n              emitNode(parser, 'oncdata', parser.cdata)\n            }\n            emitNode(parser, 'onclosecdata')\n            parser.cdata = ''\n            parser.state = S.TEXT\n          } else if (c === ']') {\n            parser.cdata += ']'\n          } else {\n            parser.cdata += ']]' + c\n            parser.state = S.CDATA\n          }\n          continue\n\n        case S.PROC_INST:\n          if (c === '?') {\n            parser.state = S.PROC_INST_ENDING\n          } else if (isWhitespace(c)) {\n            parser.state = S.PROC_INST_BODY\n          } else {\n            parser.procInstName += c\n          }\n          continue\n\n        case S.PROC_INST_BODY:\n          if (!parser.procInstBody && isWhitespace(c)) {\n            continue\n          } else if (c === '?') {\n            parser.state = S.PROC_INST_ENDING\n          } else {\n            parser.procInstBody += c\n          }\n          continue\n\n        case S.PROC_INST_ENDING:\n          if (c === '>') {\n            emitNode(parser, 'onprocessinginstruction', {\n              name: parser.procInstName,\n              body: parser.procInstBody\n            })\n            parser.procInstName = parser.procInstBody = ''\n            parser.state = S.TEXT\n          } else {\n            parser.procInstBody += '?' + c\n            parser.state = S.PROC_INST_BODY\n          }\n          continue\n\n        case S.OPEN_TAG:\n          if (isMatch(nameBody, c)) {\n            parser.tagName += c\n          } else {\n            newTag(parser)\n            if (c === '>') {\n              openTag(parser)\n            } else if (c === '/') {\n              parser.state = S.OPEN_TAG_SLASH\n            } else {\n              if (!isWhitespace(c)) {\n                strictFail(parser, 'Invalid character in tag name')\n              }\n              parser.state = S.ATTRIB\n            }\n          }\n          continue\n\n        case S.OPEN_TAG_SLASH:\n          if (c === '>') {\n            openTag(parser, true)\n            closeTag(parser)\n          } else {\n            strictFail(parser, 'Forward-slash in opening tag not followed by >')\n            parser.state = S.ATTRIB\n          }\n          continue\n\n        case S.ATTRIB:\n          // haven't read the attribute name yet.\n          if (isWhitespace(c)) {\n            continue\n          } else if (c === '>') {\n            openTag(parser)\n          } else if (c === '/') {\n            parser.state = S.OPEN_TAG_SLASH\n          } else if (isMatch(nameStart, c)) {\n            parser.attribName = c\n            parser.attribValue = ''\n            parser.state = S.ATTRIB_NAME\n          } else {\n            strictFail(parser, 'Invalid attribute name')\n          }\n          continue\n\n        case S.ATTRIB_NAME:\n          if (c === '=') {\n            parser.state = S.ATTRIB_VALUE\n          } else if (c === '>') {\n            strictFail(parser, 'Attribute without value')\n            parser.attribValue = parser.attribName\n            attrib(parser)\n            openTag(parser)\n          } else if (isWhitespace(c)) {\n            parser.state = S.ATTRIB_NAME_SAW_WHITE\n          } else if (isMatch(nameBody, c)) {\n            parser.attribName += c\n          } else {\n            strictFail(parser, 'Invalid attribute name')\n          }\n          continue\n\n        case S.ATTRIB_NAME_SAW_WHITE:\n          if (c === '=') {\n            parser.state = S.ATTRIB_VALUE\n          } else if (isWhitespace(c)) {\n            continue\n          } else {\n            strictFail(parser, 'Attribute without value')\n            parser.tag.attributes[parser.attribName] = ''\n            parser.attribValue = ''\n            emitNode(parser, 'onattribute', {\n              name: parser.attribName,\n              value: ''\n            })\n            parser.attribName = ''\n            if (c === '>') {\n              openTag(parser)\n            } else if (isMatch(nameStart, c)) {\n              parser.attribName = c\n              parser.state = S.ATTRIB_NAME\n            } else {\n              strictFail(parser, 'Invalid attribute name')\n              parser.state = S.ATTRIB\n            }\n          }\n          continue\n\n        case S.ATTRIB_VALUE:\n          if (isWhitespace(c)) {\n            continue\n          } else if (isQuote(c)) {\n            parser.q = c\n            parser.state = S.ATTRIB_VALUE_QUOTED\n          } else {\n            strictFail(parser, 'Unquoted attribute value')\n            parser.state = S.ATTRIB_VALUE_UNQUOTED\n            parser.attribValue = c\n          }\n          continue\n\n        case S.ATTRIB_VALUE_QUOTED:\n          if (c !== parser.q) {\n            if (c === '&') {\n              parser.state = S.ATTRIB_VALUE_ENTITY_Q\n            } else {\n              parser.attribValue += c\n            }\n            continue\n          }\n          attrib(parser)\n          parser.q = ''\n          parser.state = S.ATTRIB_VALUE_CLOSED\n          continue\n\n        case S.ATTRIB_VALUE_CLOSED:\n          if (isWhitespace(c)) {\n            parser.state = S.ATTRIB\n          } else if (c === '>') {\n            openTag(parser)\n          } else if (c === '/') {\n            parser.state = S.OPEN_TAG_SLASH\n          } else if (isMatch(nameStart, c)) {\n            strictFail(parser, 'No whitespace between attributes')\n            parser.attribName = c\n            parser.attribValue = ''\n            parser.state = S.ATTRIB_NAME\n          } else {\n            strictFail(parser, 'Invalid attribute name')\n          }\n          continue\n\n        case S.ATTRIB_VALUE_UNQUOTED:\n          if (!isAttribEnd(c)) {\n            if (c === '&') {\n              parser.state = S.ATTRIB_VALUE_ENTITY_U\n            } else {\n              parser.attribValue += c\n            }\n            continue\n          }\n          attrib(parser)\n          if (c === '>') {\n            openTag(parser)\n          } else {\n            parser.state = S.ATTRIB\n          }\n          continue\n\n        case S.CLOSE_TAG:\n          if (!parser.tagName) {\n            if (isWhitespace(c)) {\n              continue\n            } else if (notMatch(nameStart, c)) {\n              if (parser.script) {\n                parser.script += '</' + c\n                parser.state = S.SCRIPT\n              } else {\n                strictFail(parser, 'Invalid tagname in closing tag.')\n              }\n            } else {\n              parser.tagName = c\n            }\n          } else if (c === '>') {\n            closeTag(parser)\n          } else if (isMatch(nameBody, c)) {\n            parser.tagName += c\n          } else if (parser.script) {\n            parser.script += '</' + parser.tagName\n            parser.tagName = ''\n            parser.state = S.SCRIPT\n          } else {\n            if (!isWhitespace(c)) {\n              strictFail(parser, 'Invalid tagname in closing tag')\n            }\n            parser.state = S.CLOSE_TAG_SAW_WHITE\n          }\n          continue\n\n        case S.CLOSE_TAG_SAW_WHITE:\n          if (isWhitespace(c)) {\n            continue\n          }\n          if (c === '>') {\n            closeTag(parser)\n          } else {\n            strictFail(parser, 'Invalid characters in closing tag')\n          }\n          continue\n\n        case S.TEXT_ENTITY:\n        case S.ATTRIB_VALUE_ENTITY_Q:\n        case S.ATTRIB_VALUE_ENTITY_U:\n          var returnState\n          var buffer\n          switch (parser.state) {\n            case S.TEXT_ENTITY:\n              returnState = S.TEXT\n              buffer = 'textNode'\n              break\n\n            case S.ATTRIB_VALUE_ENTITY_Q:\n              returnState = S.ATTRIB_VALUE_QUOTED\n              buffer = 'attribValue'\n              break\n\n            case S.ATTRIB_VALUE_ENTITY_U:\n              returnState = S.ATTRIB_VALUE_UNQUOTED\n              buffer = 'attribValue'\n              break\n          }\n\n          if (c === ';') {\n            parser[buffer] += parseEntity(parser)\n            parser.entity = ''\n            parser.state = returnState\n          } else if (isMatch(parser.entity.length ? entityBody : entityStart, c)) {\n            parser.entity += c\n          } else {\n            strictFail(parser, 'Invalid character in entity name')\n            parser[buffer] += '&' + parser.entity + c\n            parser.entity = ''\n            parser.state = returnState\n          }\n\n          continue\n\n        default:\n          throw new Error(parser, 'Unknown state: ' + parser.state)\n      }\n    } // while\n\n    if (parser.position >= parser.bufferCheckPosition) {\n      checkBufferLength(parser)\n    }\n    return parser\n  }\n\n  /*! http://mths.be/fromcodepoint v0.1.0 by @mathias */\n  /* istanbul ignore next */\n  if (!String.fromCodePoint) {\n    (function () {\n      var stringFromCharCode = String.fromCharCode\n      var floor = Math.floor\n      var fromCodePoint = function () {\n        var MAX_SIZE = 0x4000\n        var codeUnits = []\n        var highSurrogate\n        var lowSurrogate\n        var index = -1\n        var length = arguments.length\n        if (!length) {\n          return ''\n        }\n        var result = ''\n        while (++index < length) {\n          var codePoint = Number(arguments[index])\n          if (\n            !isFinite(codePoint) || // `NaN`, `+Infinity`, or `-Infinity`\n            codePoint < 0 || // not a valid Unicode code point\n            codePoint > 0x10FFFF || // not a valid Unicode code point\n            floor(codePoint) !== codePoint // not an integer\n          ) {\n            throw RangeError('Invalid code point: ' + codePoint)\n          }\n          if (codePoint <= 0xFFFF) { // BMP code point\n            codeUnits.push(codePoint)\n          } else { // Astral code point; split in surrogate halves\n            // http://mathiasbynens.be/notes/javascript-encoding#surrogate-formulae\n            codePoint -= 0x10000\n            highSurrogate = (codePoint >> 10) + 0xD800\n            lowSurrogate = (codePoint % 0x400) + 0xDC00\n            codeUnits.push(highSurrogate, lowSurrogate)\n          }\n          if (index + 1 === length || codeUnits.length > MAX_SIZE) {\n            result += stringFromCharCode.apply(null, codeUnits)\n            codeUnits.length = 0\n          }\n        }\n        return result\n      }\n      /* istanbul ignore next */\n      if (Object.defineProperty) {\n        Object.defineProperty(String, 'fromCodePoint', {\n          value: fromCodePoint,\n          configurable: true,\n          writable: true\n        })\n      } else {\n        String.fromCodePoint = fromCodePoint\n      }\n    }())\n  }\n})( false ? 0 : exports)\n\n\n//# sourceURL=webpack://renderer/./node_modules/sax/lib/sax.js?");

/***/ }),

/***/ "./node_modules/scheduler/cjs/scheduler.development.js":
/*!*************************************************************!*\
  !*** ./node_modules/scheduler/cjs/scheduler.development.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("/**\n * @license React\n * scheduler.development.js\n *\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n\n\nif (true) {\n  (function() {\n\n          'use strict';\n\n/* global __REACT_DEVTOOLS_GLOBAL_HOOK__ */\nif (\n  typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ !== 'undefined' &&\n  typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStart ===\n    'function'\n) {\n  __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStart(new Error());\n}\n          var enableSchedulerDebugging = false;\nvar enableProfiling = false;\nvar frameYieldMs = 5;\n\nfunction push(heap, node) {\n  var index = heap.length;\n  heap.push(node);\n  siftUp(heap, node, index);\n}\nfunction peek(heap) {\n  return heap.length === 0 ? null : heap[0];\n}\nfunction pop(heap) {\n  if (heap.length === 0) {\n    return null;\n  }\n\n  var first = heap[0];\n  var last = heap.pop();\n\n  if (last !== first) {\n    heap[0] = last;\n    siftDown(heap, last, 0);\n  }\n\n  return first;\n}\n\nfunction siftUp(heap, node, i) {\n  var index = i;\n\n  while (index > 0) {\n    var parentIndex = index - 1 >>> 1;\n    var parent = heap[parentIndex];\n\n    if (compare(parent, node) > 0) {\n      // The parent is larger. Swap positions.\n      heap[parentIndex] = node;\n      heap[index] = parent;\n      index = parentIndex;\n    } else {\n      // The parent is smaller. Exit.\n      return;\n    }\n  }\n}\n\nfunction siftDown(heap, node, i) {\n  var index = i;\n  var length = heap.length;\n  var halfLength = length >>> 1;\n\n  while (index < halfLength) {\n    var leftIndex = (index + 1) * 2 - 1;\n    var left = heap[leftIndex];\n    var rightIndex = leftIndex + 1;\n    var right = heap[rightIndex]; // If the left or right node is smaller, swap with the smaller of those.\n\n    if (compare(left, node) < 0) {\n      if (rightIndex < length && compare(right, left) < 0) {\n        heap[index] = right;\n        heap[rightIndex] = node;\n        index = rightIndex;\n      } else {\n        heap[index] = left;\n        heap[leftIndex] = node;\n        index = leftIndex;\n      }\n    } else if (rightIndex < length && compare(right, node) < 0) {\n      heap[index] = right;\n      heap[rightIndex] = node;\n      index = rightIndex;\n    } else {\n      // Neither child is smaller. Exit.\n      return;\n    }\n  }\n}\n\nfunction compare(a, b) {\n  // Compare sort index first, then task id.\n  var diff = a.sortIndex - b.sortIndex;\n  return diff !== 0 ? diff : a.id - b.id;\n}\n\n// TODO: Use symbols?\nvar ImmediatePriority = 1;\nvar UserBlockingPriority = 2;\nvar NormalPriority = 3;\nvar LowPriority = 4;\nvar IdlePriority = 5;\n\nfunction markTaskErrored(task, ms) {\n}\n\n/* eslint-disable no-var */\n\nvar hasPerformanceNow = typeof performance === 'object' && typeof performance.now === 'function';\n\nif (hasPerformanceNow) {\n  var localPerformance = performance;\n\n  exports.unstable_now = function () {\n    return localPerformance.now();\n  };\n} else {\n  var localDate = Date;\n  var initialTime = localDate.now();\n\n  exports.unstable_now = function () {\n    return localDate.now() - initialTime;\n  };\n} // Max 31 bit integer. The max integer size in V8 for 32-bit systems.\n// Math.pow(2, 30) - 1\n// 0b111111111111111111111111111111\n\n\nvar maxSigned31BitInt = 1073741823; // Times out immediately\n\nvar IMMEDIATE_PRIORITY_TIMEOUT = -1; // Eventually times out\n\nvar USER_BLOCKING_PRIORITY_TIMEOUT = 250;\nvar NORMAL_PRIORITY_TIMEOUT = 5000;\nvar LOW_PRIORITY_TIMEOUT = 10000; // Never times out\n\nvar IDLE_PRIORITY_TIMEOUT = maxSigned31BitInt; // Tasks are stored on a min heap\n\nvar taskQueue = [];\nvar timerQueue = []; // Incrementing id counter. Used to maintain insertion order.\n\nvar taskIdCounter = 1; // Pausing the scheduler is useful for debugging.\nvar currentTask = null;\nvar currentPriorityLevel = NormalPriority; // This is set while performing work, to prevent re-entrance.\n\nvar isPerformingWork = false;\nvar isHostCallbackScheduled = false;\nvar isHostTimeoutScheduled = false; // Capture local references to native APIs, in case a polyfill overrides them.\n\nvar localSetTimeout = typeof setTimeout === 'function' ? setTimeout : null;\nvar localClearTimeout = typeof clearTimeout === 'function' ? clearTimeout : null;\nvar localSetImmediate = typeof setImmediate !== 'undefined' ? setImmediate : null; // IE and Node.js + jsdom\n\nvar isInputPending = typeof navigator !== 'undefined' && navigator.scheduling !== undefined && navigator.scheduling.isInputPending !== undefined ? navigator.scheduling.isInputPending.bind(navigator.scheduling) : null;\n\nfunction advanceTimers(currentTime) {\n  // Check for tasks that are no longer delayed and add them to the queue.\n  var timer = peek(timerQueue);\n\n  while (timer !== null) {\n    if (timer.callback === null) {\n      // Timer was cancelled.\n      pop(timerQueue);\n    } else if (timer.startTime <= currentTime) {\n      // Timer fired. Transfer to the task queue.\n      pop(timerQueue);\n      timer.sortIndex = timer.expirationTime;\n      push(taskQueue, timer);\n    } else {\n      // Remaining timers are pending.\n      return;\n    }\n\n    timer = peek(timerQueue);\n  }\n}\n\nfunction handleTimeout(currentTime) {\n  isHostTimeoutScheduled = false;\n  advanceTimers(currentTime);\n\n  if (!isHostCallbackScheduled) {\n    if (peek(taskQueue) !== null) {\n      isHostCallbackScheduled = true;\n      requestHostCallback(flushWork);\n    } else {\n      var firstTimer = peek(timerQueue);\n\n      if (firstTimer !== null) {\n        requestHostTimeout(handleTimeout, firstTimer.startTime - currentTime);\n      }\n    }\n  }\n}\n\nfunction flushWork(hasTimeRemaining, initialTime) {\n\n\n  isHostCallbackScheduled = false;\n\n  if (isHostTimeoutScheduled) {\n    // We scheduled a timeout but it's no longer needed. Cancel it.\n    isHostTimeoutScheduled = false;\n    cancelHostTimeout();\n  }\n\n  isPerformingWork = true;\n  var previousPriorityLevel = currentPriorityLevel;\n\n  try {\n    if (enableProfiling) {\n      try {\n        return workLoop(hasTimeRemaining, initialTime);\n      } catch (error) {\n        if (currentTask !== null) {\n          var currentTime = exports.unstable_now();\n          markTaskErrored(currentTask, currentTime);\n          currentTask.isQueued = false;\n        }\n\n        throw error;\n      }\n    } else {\n      // No catch in prod code path.\n      return workLoop(hasTimeRemaining, initialTime);\n    }\n  } finally {\n    currentTask = null;\n    currentPriorityLevel = previousPriorityLevel;\n    isPerformingWork = false;\n  }\n}\n\nfunction workLoop(hasTimeRemaining, initialTime) {\n  var currentTime = initialTime;\n  advanceTimers(currentTime);\n  currentTask = peek(taskQueue);\n\n  while (currentTask !== null && !(enableSchedulerDebugging )) {\n    if (currentTask.expirationTime > currentTime && (!hasTimeRemaining || shouldYieldToHost())) {\n      // This currentTask hasn't expired, and we've reached the deadline.\n      break;\n    }\n\n    var callback = currentTask.callback;\n\n    if (typeof callback === 'function') {\n      currentTask.callback = null;\n      currentPriorityLevel = currentTask.priorityLevel;\n      var didUserCallbackTimeout = currentTask.expirationTime <= currentTime;\n\n      var continuationCallback = callback(didUserCallbackTimeout);\n      currentTime = exports.unstable_now();\n\n      if (typeof continuationCallback === 'function') {\n        currentTask.callback = continuationCallback;\n      } else {\n\n        if (currentTask === peek(taskQueue)) {\n          pop(taskQueue);\n        }\n      }\n\n      advanceTimers(currentTime);\n    } else {\n      pop(taskQueue);\n    }\n\n    currentTask = peek(taskQueue);\n  } // Return whether there's additional work\n\n\n  if (currentTask !== null) {\n    return true;\n  } else {\n    var firstTimer = peek(timerQueue);\n\n    if (firstTimer !== null) {\n      requestHostTimeout(handleTimeout, firstTimer.startTime - currentTime);\n    }\n\n    return false;\n  }\n}\n\nfunction unstable_runWithPriority(priorityLevel, eventHandler) {\n  switch (priorityLevel) {\n    case ImmediatePriority:\n    case UserBlockingPriority:\n    case NormalPriority:\n    case LowPriority:\n    case IdlePriority:\n      break;\n\n    default:\n      priorityLevel = NormalPriority;\n  }\n\n  var previousPriorityLevel = currentPriorityLevel;\n  currentPriorityLevel = priorityLevel;\n\n  try {\n    return eventHandler();\n  } finally {\n    currentPriorityLevel = previousPriorityLevel;\n  }\n}\n\nfunction unstable_next(eventHandler) {\n  var priorityLevel;\n\n  switch (currentPriorityLevel) {\n    case ImmediatePriority:\n    case UserBlockingPriority:\n    case NormalPriority:\n      // Shift down to normal priority\n      priorityLevel = NormalPriority;\n      break;\n\n    default:\n      // Anything lower than normal priority should remain at the current level.\n      priorityLevel = currentPriorityLevel;\n      break;\n  }\n\n  var previousPriorityLevel = currentPriorityLevel;\n  currentPriorityLevel = priorityLevel;\n\n  try {\n    return eventHandler();\n  } finally {\n    currentPriorityLevel = previousPriorityLevel;\n  }\n}\n\nfunction unstable_wrapCallback(callback) {\n  var parentPriorityLevel = currentPriorityLevel;\n  return function () {\n    // This is a fork of runWithPriority, inlined for performance.\n    var previousPriorityLevel = currentPriorityLevel;\n    currentPriorityLevel = parentPriorityLevel;\n\n    try {\n      return callback.apply(this, arguments);\n    } finally {\n      currentPriorityLevel = previousPriorityLevel;\n    }\n  };\n}\n\nfunction unstable_scheduleCallback(priorityLevel, callback, options) {\n  var currentTime = exports.unstable_now();\n  var startTime;\n\n  if (typeof options === 'object' && options !== null) {\n    var delay = options.delay;\n\n    if (typeof delay === 'number' && delay > 0) {\n      startTime = currentTime + delay;\n    } else {\n      startTime = currentTime;\n    }\n  } else {\n    startTime = currentTime;\n  }\n\n  var timeout;\n\n  switch (priorityLevel) {\n    case ImmediatePriority:\n      timeout = IMMEDIATE_PRIORITY_TIMEOUT;\n      break;\n\n    case UserBlockingPriority:\n      timeout = USER_BLOCKING_PRIORITY_TIMEOUT;\n      break;\n\n    case IdlePriority:\n      timeout = IDLE_PRIORITY_TIMEOUT;\n      break;\n\n    case LowPriority:\n      timeout = LOW_PRIORITY_TIMEOUT;\n      break;\n\n    case NormalPriority:\n    default:\n      timeout = NORMAL_PRIORITY_TIMEOUT;\n      break;\n  }\n\n  var expirationTime = startTime + timeout;\n  var newTask = {\n    id: taskIdCounter++,\n    callback: callback,\n    priorityLevel: priorityLevel,\n    startTime: startTime,\n    expirationTime: expirationTime,\n    sortIndex: -1\n  };\n\n  if (startTime > currentTime) {\n    // This is a delayed task.\n    newTask.sortIndex = startTime;\n    push(timerQueue, newTask);\n\n    if (peek(taskQueue) === null && newTask === peek(timerQueue)) {\n      // All tasks are delayed, and this is the task with the earliest delay.\n      if (isHostTimeoutScheduled) {\n        // Cancel an existing timeout.\n        cancelHostTimeout();\n      } else {\n        isHostTimeoutScheduled = true;\n      } // Schedule a timeout.\n\n\n      requestHostTimeout(handleTimeout, startTime - currentTime);\n    }\n  } else {\n    newTask.sortIndex = expirationTime;\n    push(taskQueue, newTask);\n    // wait until the next time we yield.\n\n\n    if (!isHostCallbackScheduled && !isPerformingWork) {\n      isHostCallbackScheduled = true;\n      requestHostCallback(flushWork);\n    }\n  }\n\n  return newTask;\n}\n\nfunction unstable_pauseExecution() {\n}\n\nfunction unstable_continueExecution() {\n\n  if (!isHostCallbackScheduled && !isPerformingWork) {\n    isHostCallbackScheduled = true;\n    requestHostCallback(flushWork);\n  }\n}\n\nfunction unstable_getFirstCallbackNode() {\n  return peek(taskQueue);\n}\n\nfunction unstable_cancelCallback(task) {\n  // remove from the queue because you can't remove arbitrary nodes from an\n  // array based heap, only the first one.)\n\n\n  task.callback = null;\n}\n\nfunction unstable_getCurrentPriorityLevel() {\n  return currentPriorityLevel;\n}\n\nvar isMessageLoopRunning = false;\nvar scheduledHostCallback = null;\nvar taskTimeoutID = -1; // Scheduler periodically yields in case there is other work on the main\n// thread, like user events. By default, it yields multiple times per frame.\n// It does not attempt to align with frame boundaries, since most tasks don't\n// need to be frame aligned; for those that do, use requestAnimationFrame.\n\nvar frameInterval = frameYieldMs;\nvar startTime = -1;\n\nfunction shouldYieldToHost() {\n  var timeElapsed = exports.unstable_now() - startTime;\n\n  if (timeElapsed < frameInterval) {\n    // The main thread has only been blocked for a really short amount of time;\n    // smaller than a single frame. Don't yield yet.\n    return false;\n  } // The main thread has been blocked for a non-negligible amount of time. We\n\n\n  return true;\n}\n\nfunction requestPaint() {\n\n}\n\nfunction forceFrameRate(fps) {\n  if (fps < 0 || fps > 125) {\n    // Using console['error'] to evade Babel and ESLint\n    console['error']('forceFrameRate takes a positive int between 0 and 125, ' + 'forcing frame rates higher than 125 fps is not supported');\n    return;\n  }\n\n  if (fps > 0) {\n    frameInterval = Math.floor(1000 / fps);\n  } else {\n    // reset the framerate\n    frameInterval = frameYieldMs;\n  }\n}\n\nvar performWorkUntilDeadline = function () {\n  if (scheduledHostCallback !== null) {\n    var currentTime = exports.unstable_now(); // Keep track of the start time so we can measure how long the main thread\n    // has been blocked.\n\n    startTime = currentTime;\n    var hasTimeRemaining = true; // If a scheduler task throws, exit the current browser task so the\n    // error can be observed.\n    //\n    // Intentionally not using a try-catch, since that makes some debugging\n    // techniques harder. Instead, if `scheduledHostCallback` errors, then\n    // `hasMoreWork` will remain true, and we'll continue the work loop.\n\n    var hasMoreWork = true;\n\n    try {\n      hasMoreWork = scheduledHostCallback(hasTimeRemaining, currentTime);\n    } finally {\n      if (hasMoreWork) {\n        // If there's more work, schedule the next message event at the end\n        // of the preceding one.\n        schedulePerformWorkUntilDeadline();\n      } else {\n        isMessageLoopRunning = false;\n        scheduledHostCallback = null;\n      }\n    }\n  } else {\n    isMessageLoopRunning = false;\n  } // Yielding to the browser will give it a chance to paint, so we can\n};\n\nvar schedulePerformWorkUntilDeadline;\n\nif (typeof localSetImmediate === 'function') {\n  // Node.js and old IE.\n  // There's a few reasons for why we prefer setImmediate.\n  //\n  // Unlike MessageChannel, it doesn't prevent a Node.js process from exiting.\n  // (Even though this is a DOM fork of the Scheduler, you could get here\n  // with a mix of Node.js 15+, which has a MessageChannel, and jsdom.)\n  // https://github.com/facebook/react/issues/20756\n  //\n  // But also, it runs earlier which is the semantic we want.\n  // If other browsers ever implement it, it's better to use it.\n  // Although both of these would be inferior to native scheduling.\n  schedulePerformWorkUntilDeadline = function () {\n    localSetImmediate(performWorkUntilDeadline);\n  };\n} else if (typeof MessageChannel !== 'undefined') {\n  // DOM and Worker environments.\n  // We prefer MessageChannel because of the 4ms setTimeout clamping.\n  var channel = new MessageChannel();\n  var port = channel.port2;\n  channel.port1.onmessage = performWorkUntilDeadline;\n\n  schedulePerformWorkUntilDeadline = function () {\n    port.postMessage(null);\n  };\n} else {\n  // We should only fallback here in non-browser environments.\n  schedulePerformWorkUntilDeadline = function () {\n    localSetTimeout(performWorkUntilDeadline, 0);\n  };\n}\n\nfunction requestHostCallback(callback) {\n  scheduledHostCallback = callback;\n\n  if (!isMessageLoopRunning) {\n    isMessageLoopRunning = true;\n    schedulePerformWorkUntilDeadline();\n  }\n}\n\nfunction requestHostTimeout(callback, ms) {\n  taskTimeoutID = localSetTimeout(function () {\n    callback(exports.unstable_now());\n  }, ms);\n}\n\nfunction cancelHostTimeout() {\n  localClearTimeout(taskTimeoutID);\n  taskTimeoutID = -1;\n}\n\nvar unstable_requestPaint = requestPaint;\nvar unstable_Profiling =  null;\n\nexports.unstable_IdlePriority = IdlePriority;\nexports.unstable_ImmediatePriority = ImmediatePriority;\nexports.unstable_LowPriority = LowPriority;\nexports.unstable_NormalPriority = NormalPriority;\nexports.unstable_Profiling = unstable_Profiling;\nexports.unstable_UserBlockingPriority = UserBlockingPriority;\nexports.unstable_cancelCallback = unstable_cancelCallback;\nexports.unstable_continueExecution = unstable_continueExecution;\nexports.unstable_forceFrameRate = forceFrameRate;\nexports.unstable_getCurrentPriorityLevel = unstable_getCurrentPriorityLevel;\nexports.unstable_getFirstCallbackNode = unstable_getFirstCallbackNode;\nexports.unstable_next = unstable_next;\nexports.unstable_pauseExecution = unstable_pauseExecution;\nexports.unstable_requestPaint = unstable_requestPaint;\nexports.unstable_runWithPriority = unstable_runWithPriority;\nexports.unstable_scheduleCallback = unstable_scheduleCallback;\nexports.unstable_shouldYield = shouldYieldToHost;\nexports.unstable_wrapCallback = unstable_wrapCallback;\n          /* global __REACT_DEVTOOLS_GLOBAL_HOOK__ */\nif (\n  typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ !== 'undefined' &&\n  typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStop ===\n    'function'\n) {\n  __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStop(new Error());\n}\n        \n  })();\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/scheduler/cjs/scheduler.development.js?");

/***/ }),

/***/ "./node_modules/scheduler/index.js":
/*!*****************************************!*\
  !*** ./node_modules/scheduler/index.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nif (false) {} else {\n  module.exports = __webpack_require__(/*! ./cjs/scheduler.development.js */ \"./node_modules/scheduler/cjs/scheduler.development.js\");\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/scheduler/index.js?");

/***/ }),

/***/ "./node_modules/semver/classes/comparator.js":
/*!***************************************************!*\
  !*** ./node_modules/semver/classes/comparator.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const ANY = Symbol('SemVer ANY')\n// hoisted class for cyclic dependency\nclass Comparator {\n  static get ANY () {\n    return ANY\n  }\n\n  constructor (comp, options) {\n    options = parseOptions(options)\n\n    if (comp instanceof Comparator) {\n      if (comp.loose === !!options.loose) {\n        return comp\n      } else {\n        comp = comp.value\n      }\n    }\n\n    comp = comp.trim().split(/\\s+/).join(' ')\n    debug('comparator', comp, options)\n    this.options = options\n    this.loose = !!options.loose\n    this.parse(comp)\n\n    if (this.semver === ANY) {\n      this.value = ''\n    } else {\n      this.value = this.operator + this.semver.version\n    }\n\n    debug('comp', this)\n  }\n\n  parse (comp) {\n    const r = this.options.loose ? re[t.COMPARATORLOOSE] : re[t.COMPARATOR]\n    const m = comp.match(r)\n\n    if (!m) {\n      throw new TypeError(`Invalid comparator: ${comp}`)\n    }\n\n    this.operator = m[1] !== undefined ? m[1] : ''\n    if (this.operator === '=') {\n      this.operator = ''\n    }\n\n    // if it literally is just '>' or '' then allow anything.\n    if (!m[2]) {\n      this.semver = ANY\n    } else {\n      this.semver = new SemVer(m[2], this.options.loose)\n    }\n  }\n\n  toString () {\n    return this.value\n  }\n\n  test (version) {\n    debug('Comparator.test', version, this.options.loose)\n\n    if (this.semver === ANY || version === ANY) {\n      return true\n    }\n\n    if (typeof version === 'string') {\n      try {\n        version = new SemVer(version, this.options)\n      } catch (er) {\n        return false\n      }\n    }\n\n    return cmp(version, this.operator, this.semver, this.options)\n  }\n\n  intersects (comp, options) {\n    if (!(comp instanceof Comparator)) {\n      throw new TypeError('a Comparator is required')\n    }\n\n    if (this.operator === '') {\n      if (this.value === '') {\n        return true\n      }\n      return new Range(comp.value, options).test(this.value)\n    } else if (comp.operator === '') {\n      if (comp.value === '') {\n        return true\n      }\n      return new Range(this.value, options).test(comp.semver)\n    }\n\n    options = parseOptions(options)\n\n    // Special cases where nothing can possibly be lower\n    if (options.includePrerelease &&\n      (this.value === '<0.0.0-0' || comp.value === '<0.0.0-0')) {\n      return false\n    }\n    if (!options.includePrerelease &&\n      (this.value.startsWith('<0.0.0') || comp.value.startsWith('<0.0.0'))) {\n      return false\n    }\n\n    // Same direction increasing (> or >=)\n    if (this.operator.startsWith('>') && comp.operator.startsWith('>')) {\n      return true\n    }\n    // Same direction decreasing (< or <=)\n    if (this.operator.startsWith('<') && comp.operator.startsWith('<')) {\n      return true\n    }\n    // same SemVer and both sides are inclusive (<= or >=)\n    if (\n      (this.semver.version === comp.semver.version) &&\n      this.operator.includes('=') && comp.operator.includes('=')) {\n      return true\n    }\n    // opposite directions less than\n    if (cmp(this.semver, '<', comp.semver, options) &&\n      this.operator.startsWith('>') && comp.operator.startsWith('<')) {\n      return true\n    }\n    // opposite directions greater than\n    if (cmp(this.semver, '>', comp.semver, options) &&\n      this.operator.startsWith('<') && comp.operator.startsWith('>')) {\n      return true\n    }\n    return false\n  }\n}\n\nmodule.exports = Comparator\n\nconst parseOptions = __webpack_require__(/*! ../internal/parse-options */ \"./node_modules/semver/internal/parse-options.js\")\nconst { safeRe: re, t } = __webpack_require__(/*! ../internal/re */ \"./node_modules/semver/internal/re.js\")\nconst cmp = __webpack_require__(/*! ../functions/cmp */ \"./node_modules/semver/functions/cmp.js\")\nconst debug = __webpack_require__(/*! ../internal/debug */ \"./node_modules/semver/internal/debug.js\")\nconst SemVer = __webpack_require__(/*! ./semver */ \"./node_modules/semver/classes/semver.js\")\nconst Range = __webpack_require__(/*! ./range */ \"./node_modules/semver/classes/range.js\")\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/classes/comparator.js?");

/***/ }),

/***/ "./node_modules/semver/classes/range.js":
/*!**********************************************!*\
  !*** ./node_modules/semver/classes/range.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("// hoisted class for cyclic dependency\nclass Range {\n  constructor (range, options) {\n    options = parseOptions(options)\n\n    if (range instanceof Range) {\n      if (\n        range.loose === !!options.loose &&\n        range.includePrerelease === !!options.includePrerelease\n      ) {\n        return range\n      } else {\n        return new Range(range.raw, options)\n      }\n    }\n\n    if (range instanceof Comparator) {\n      // just put it in the set and return\n      this.raw = range.value\n      this.set = [[range]]\n      this.format()\n      return this\n    }\n\n    this.options = options\n    this.loose = !!options.loose\n    this.includePrerelease = !!options.includePrerelease\n\n    // First reduce all whitespace as much as possible so we do not have to rely\n    // on potentially slow regexes like \\s*. This is then stored and used for\n    // future error messages as well.\n    this.raw = range\n      .trim()\n      .split(/\\s+/)\n      .join(' ')\n\n    // First, split on ||\n    this.set = this.raw\n      .split('||')\n      // map the range to a 2d array of comparators\n      .map(r => this.parseRange(r.trim()))\n      // throw out any comparator lists that are empty\n      // this generally means that it was not a valid range, which is allowed\n      // in loose mode, but will still throw if the WHOLE range is invalid.\n      .filter(c => c.length)\n\n    if (!this.set.length) {\n      throw new TypeError(`Invalid SemVer Range: ${this.raw}`)\n    }\n\n    // if we have any that are not the null set, throw out null sets.\n    if (this.set.length > 1) {\n      // keep the first one, in case they're all null sets\n      const first = this.set[0]\n      this.set = this.set.filter(c => !isNullSet(c[0]))\n      if (this.set.length === 0) {\n        this.set = [first]\n      } else if (this.set.length > 1) {\n        // if we have any that are *, then the range is just *\n        for (const c of this.set) {\n          if (c.length === 1 && isAny(c[0])) {\n            this.set = [c]\n            break\n          }\n        }\n      }\n    }\n\n    this.format()\n  }\n\n  format () {\n    this.range = this.set\n      .map((comps) => comps.join(' ').trim())\n      .join('||')\n      .trim()\n    return this.range\n  }\n\n  toString () {\n    return this.range\n  }\n\n  parseRange (range) {\n    // memoize range parsing for performance.\n    // this is a very hot path, and fully deterministic.\n    const memoOpts =\n      (this.options.includePrerelease && FLAG_INCLUDE_PRERELEASE) |\n      (this.options.loose && FLAG_LOOSE)\n    const memoKey = memoOpts + ':' + range\n    const cached = cache.get(memoKey)\n    if (cached) {\n      return cached\n    }\n\n    const loose = this.options.loose\n    // `1.2.3 - 1.2.4` => `>=1.2.3 <=1.2.4`\n    const hr = loose ? re[t.HYPHENRANGELOOSE] : re[t.HYPHENRANGE]\n    range = range.replace(hr, hyphenReplace(this.options.includePrerelease))\n    debug('hyphen replace', range)\n\n    // `> 1.2.3 < 1.2.5` => `>1.2.3 <1.2.5`\n    range = range.replace(re[t.COMPARATORTRIM], comparatorTrimReplace)\n    debug('comparator trim', range)\n\n    // `~ 1.2.3` => `~1.2.3`\n    range = range.replace(re[t.TILDETRIM], tildeTrimReplace)\n    debug('tilde trim', range)\n\n    // `^ 1.2.3` => `^1.2.3`\n    range = range.replace(re[t.CARETTRIM], caretTrimReplace)\n    debug('caret trim', range)\n\n    // At this point, the range is completely trimmed and\n    // ready to be split into comparators.\n\n    let rangeList = range\n      .split(' ')\n      .map(comp => parseComparator(comp, this.options))\n      .join(' ')\n      .split(/\\s+/)\n      // >=0.0.0 is equivalent to *\n      .map(comp => replaceGTE0(comp, this.options))\n\n    if (loose) {\n      // in loose mode, throw out any that are not valid comparators\n      rangeList = rangeList.filter(comp => {\n        debug('loose invalid filter', comp, this.options)\n        return !!comp.match(re[t.COMPARATORLOOSE])\n      })\n    }\n    debug('range list', rangeList)\n\n    // if any comparators are the null set, then replace with JUST null set\n    // if more than one comparator, remove any * comparators\n    // also, don't include the same comparator more than once\n    const rangeMap = new Map()\n    const comparators = rangeList.map(comp => new Comparator(comp, this.options))\n    for (const comp of comparators) {\n      if (isNullSet(comp)) {\n        return [comp]\n      }\n      rangeMap.set(comp.value, comp)\n    }\n    if (rangeMap.size > 1 && rangeMap.has('')) {\n      rangeMap.delete('')\n    }\n\n    const result = [...rangeMap.values()]\n    cache.set(memoKey, result)\n    return result\n  }\n\n  intersects (range, options) {\n    if (!(range instanceof Range)) {\n      throw new TypeError('a Range is required')\n    }\n\n    return this.set.some((thisComparators) => {\n      return (\n        isSatisfiable(thisComparators, options) &&\n        range.set.some((rangeComparators) => {\n          return (\n            isSatisfiable(rangeComparators, options) &&\n            thisComparators.every((thisComparator) => {\n              return rangeComparators.every((rangeComparator) => {\n                return thisComparator.intersects(rangeComparator, options)\n              })\n            })\n          )\n        })\n      )\n    })\n  }\n\n  // if ANY of the sets match ALL of its comparators, then pass\n  test (version) {\n    if (!version) {\n      return false\n    }\n\n    if (typeof version === 'string') {\n      try {\n        version = new SemVer(version, this.options)\n      } catch (er) {\n        return false\n      }\n    }\n\n    for (let i = 0; i < this.set.length; i++) {\n      if (testSet(this.set[i], version, this.options)) {\n        return true\n      }\n    }\n    return false\n  }\n}\n\nmodule.exports = Range\n\nconst LRU = __webpack_require__(/*! lru-cache */ \"./node_modules/semver/node_modules/lru-cache/index.js\")\nconst cache = new LRU({ max: 1000 })\n\nconst parseOptions = __webpack_require__(/*! ../internal/parse-options */ \"./node_modules/semver/internal/parse-options.js\")\nconst Comparator = __webpack_require__(/*! ./comparator */ \"./node_modules/semver/classes/comparator.js\")\nconst debug = __webpack_require__(/*! ../internal/debug */ \"./node_modules/semver/internal/debug.js\")\nconst SemVer = __webpack_require__(/*! ./semver */ \"./node_modules/semver/classes/semver.js\")\nconst {\n  safeRe: re,\n  t,\n  comparatorTrimReplace,\n  tildeTrimReplace,\n  caretTrimReplace,\n} = __webpack_require__(/*! ../internal/re */ \"./node_modules/semver/internal/re.js\")\nconst { FLAG_INCLUDE_PRERELEASE, FLAG_LOOSE } = __webpack_require__(/*! ../internal/constants */ \"./node_modules/semver/internal/constants.js\")\n\nconst isNullSet = c => c.value === '<0.0.0-0'\nconst isAny = c => c.value === ''\n\n// take a set of comparators and determine whether there\n// exists a version which can satisfy it\nconst isSatisfiable = (comparators, options) => {\n  let result = true\n  const remainingComparators = comparators.slice()\n  let testComparator = remainingComparators.pop()\n\n  while (result && remainingComparators.length) {\n    result = remainingComparators.every((otherComparator) => {\n      return testComparator.intersects(otherComparator, options)\n    })\n\n    testComparator = remainingComparators.pop()\n  }\n\n  return result\n}\n\n// comprised of xranges, tildes, stars, and gtlt's at this point.\n// already replaced the hyphen ranges\n// turn into a set of JUST comparators.\nconst parseComparator = (comp, options) => {\n  debug('comp', comp, options)\n  comp = replaceCarets(comp, options)\n  debug('caret', comp)\n  comp = replaceTildes(comp, options)\n  debug('tildes', comp)\n  comp = replaceXRanges(comp, options)\n  debug('xrange', comp)\n  comp = replaceStars(comp, options)\n  debug('stars', comp)\n  return comp\n}\n\nconst isX = id => !id || id.toLowerCase() === 'x' || id === '*'\n\n// ~, ~> --> * (any, kinda silly)\n// ~2, ~2.x, ~2.x.x, ~>2, ~>2.x ~>2.x.x --> >=2.0.0 <3.0.0-0\n// ~2.0, ~2.0.x, ~>2.0, ~>2.0.x --> >=2.0.0 <2.1.0-0\n// ~1.2, ~1.2.x, ~>1.2, ~>1.2.x --> >=1.2.0 <1.3.0-0\n// ~1.2.3, ~>1.2.3 --> >=1.2.3 <1.3.0-0\n// ~1.2.0, ~>1.2.0 --> >=1.2.0 <1.3.0-0\n// ~0.0.1 --> >=0.0.1 <0.1.0-0\nconst replaceTildes = (comp, options) => {\n  return comp\n    .trim()\n    .split(/\\s+/)\n    .map((c) => replaceTilde(c, options))\n    .join(' ')\n}\n\nconst replaceTilde = (comp, options) => {\n  const r = options.loose ? re[t.TILDELOOSE] : re[t.TILDE]\n  return comp.replace(r, (_, M, m, p, pr) => {\n    debug('tilde', comp, _, M, m, p, pr)\n    let ret\n\n    if (isX(M)) {\n      ret = ''\n    } else if (isX(m)) {\n      ret = `>=${M}.0.0 <${+M + 1}.0.0-0`\n    } else if (isX(p)) {\n      // ~1.2 == >=1.2.0 <1.3.0-0\n      ret = `>=${M}.${m}.0 <${M}.${+m + 1}.0-0`\n    } else if (pr) {\n      debug('replaceTilde pr', pr)\n      ret = `>=${M}.${m}.${p}-${pr\n      } <${M}.${+m + 1}.0-0`\n    } else {\n      // ~1.2.3 == >=1.2.3 <1.3.0-0\n      ret = `>=${M}.${m}.${p\n      } <${M}.${+m + 1}.0-0`\n    }\n\n    debug('tilde return', ret)\n    return ret\n  })\n}\n\n// ^ --> * (any, kinda silly)\n// ^2, ^2.x, ^2.x.x --> >=2.0.0 <3.0.0-0\n// ^2.0, ^2.0.x --> >=2.0.0 <3.0.0-0\n// ^1.2, ^1.2.x --> >=1.2.0 <2.0.0-0\n// ^1.2.3 --> >=1.2.3 <2.0.0-0\n// ^1.2.0 --> >=1.2.0 <2.0.0-0\n// ^0.0.1 --> >=0.0.1 <0.0.2-0\n// ^0.1.0 --> >=0.1.0 <0.2.0-0\nconst replaceCarets = (comp, options) => {\n  return comp\n    .trim()\n    .split(/\\s+/)\n    .map((c) => replaceCaret(c, options))\n    .join(' ')\n}\n\nconst replaceCaret = (comp, options) => {\n  debug('caret', comp, options)\n  const r = options.loose ? re[t.CARETLOOSE] : re[t.CARET]\n  const z = options.includePrerelease ? '-0' : ''\n  return comp.replace(r, (_, M, m, p, pr) => {\n    debug('caret', comp, _, M, m, p, pr)\n    let ret\n\n    if (isX(M)) {\n      ret = ''\n    } else if (isX(m)) {\n      ret = `>=${M}.0.0${z} <${+M + 1}.0.0-0`\n    } else if (isX(p)) {\n      if (M === '0') {\n        ret = `>=${M}.${m}.0${z} <${M}.${+m + 1}.0-0`\n      } else {\n        ret = `>=${M}.${m}.0${z} <${+M + 1}.0.0-0`\n      }\n    } else if (pr) {\n      debug('replaceCaret pr', pr)\n      if (M === '0') {\n        if (m === '0') {\n          ret = `>=${M}.${m}.${p}-${pr\n          } <${M}.${m}.${+p + 1}-0`\n        } else {\n          ret = `>=${M}.${m}.${p}-${pr\n          } <${M}.${+m + 1}.0-0`\n        }\n      } else {\n        ret = `>=${M}.${m}.${p}-${pr\n        } <${+M + 1}.0.0-0`\n      }\n    } else {\n      debug('no pr')\n      if (M === '0') {\n        if (m === '0') {\n          ret = `>=${M}.${m}.${p\n          }${z} <${M}.${m}.${+p + 1}-0`\n        } else {\n          ret = `>=${M}.${m}.${p\n          }${z} <${M}.${+m + 1}.0-0`\n        }\n      } else {\n        ret = `>=${M}.${m}.${p\n        } <${+M + 1}.0.0-0`\n      }\n    }\n\n    debug('caret return', ret)\n    return ret\n  })\n}\n\nconst replaceXRanges = (comp, options) => {\n  debug('replaceXRanges', comp, options)\n  return comp\n    .split(/\\s+/)\n    .map((c) => replaceXRange(c, options))\n    .join(' ')\n}\n\nconst replaceXRange = (comp, options) => {\n  comp = comp.trim()\n  const r = options.loose ? re[t.XRANGELOOSE] : re[t.XRANGE]\n  return comp.replace(r, (ret, gtlt, M, m, p, pr) => {\n    debug('xRange', comp, ret, gtlt, M, m, p, pr)\n    const xM = isX(M)\n    const xm = xM || isX(m)\n    const xp = xm || isX(p)\n    const anyX = xp\n\n    if (gtlt === '=' && anyX) {\n      gtlt = ''\n    }\n\n    // if we're including prereleases in the match, then we need\n    // to fix this to -0, the lowest possible prerelease value\n    pr = options.includePrerelease ? '-0' : ''\n\n    if (xM) {\n      if (gtlt === '>' || gtlt === '<') {\n        // nothing is allowed\n        ret = '<0.0.0-0'\n      } else {\n        // nothing is forbidden\n        ret = '*'\n      }\n    } else if (gtlt && anyX) {\n      // we know patch is an x, because we have any x at all.\n      // replace X with 0\n      if (xm) {\n        m = 0\n      }\n      p = 0\n\n      if (gtlt === '>') {\n        // >1 => >=2.0.0\n        // >1.2 => >=1.3.0\n        gtlt = '>='\n        if (xm) {\n          M = +M + 1\n          m = 0\n          p = 0\n        } else {\n          m = +m + 1\n          p = 0\n        }\n      } else if (gtlt === '<=') {\n        // <=0.7.x is actually <0.8.0, since any 0.7.x should\n        // pass.  Similarly, <=7.x is actually <8.0.0, etc.\n        gtlt = '<'\n        if (xm) {\n          M = +M + 1\n        } else {\n          m = +m + 1\n        }\n      }\n\n      if (gtlt === '<') {\n        pr = '-0'\n      }\n\n      ret = `${gtlt + M}.${m}.${p}${pr}`\n    } else if (xm) {\n      ret = `>=${M}.0.0${pr} <${+M + 1}.0.0-0`\n    } else if (xp) {\n      ret = `>=${M}.${m}.0${pr\n      } <${M}.${+m + 1}.0-0`\n    }\n\n    debug('xRange return', ret)\n\n    return ret\n  })\n}\n\n// Because * is AND-ed with everything else in the comparator,\n// and '' means \"any version\", just remove the *s entirely.\nconst replaceStars = (comp, options) => {\n  debug('replaceStars', comp, options)\n  // Looseness is ignored here.  star is always as loose as it gets!\n  return comp\n    .trim()\n    .replace(re[t.STAR], '')\n}\n\nconst replaceGTE0 = (comp, options) => {\n  debug('replaceGTE0', comp, options)\n  return comp\n    .trim()\n    .replace(re[options.includePrerelease ? t.GTE0PRE : t.GTE0], '')\n}\n\n// This function is passed to string.replace(re[t.HYPHENRANGE])\n// M, m, patch, prerelease, build\n// 1.2 - 3.4.5 => >=1.2.0 <=3.4.5\n// 1.2.3 - 3.4 => >=1.2.0 <3.5.0-0 Any 3.4.x will do\n// 1.2 - 3.4 => >=1.2.0 <3.5.0-0\nconst hyphenReplace = incPr => ($0,\n  from, fM, fm, fp, fpr, fb,\n  to, tM, tm, tp, tpr, tb) => {\n  if (isX(fM)) {\n    from = ''\n  } else if (isX(fm)) {\n    from = `>=${fM}.0.0${incPr ? '-0' : ''}`\n  } else if (isX(fp)) {\n    from = `>=${fM}.${fm}.0${incPr ? '-0' : ''}`\n  } else if (fpr) {\n    from = `>=${from}`\n  } else {\n    from = `>=${from}${incPr ? '-0' : ''}`\n  }\n\n  if (isX(tM)) {\n    to = ''\n  } else if (isX(tm)) {\n    to = `<${+tM + 1}.0.0-0`\n  } else if (isX(tp)) {\n    to = `<${tM}.${+tm + 1}.0-0`\n  } else if (tpr) {\n    to = `<=${tM}.${tm}.${tp}-${tpr}`\n  } else if (incPr) {\n    to = `<${tM}.${tm}.${+tp + 1}-0`\n  } else {\n    to = `<=${to}`\n  }\n\n  return `${from} ${to}`.trim()\n}\n\nconst testSet = (set, version, options) => {\n  for (let i = 0; i < set.length; i++) {\n    if (!set[i].test(version)) {\n      return false\n    }\n  }\n\n  if (version.prerelease.length && !options.includePrerelease) {\n    // Find the set of versions that are allowed to have prereleases\n    // For example, ^1.2.3-pr.1 desugars to >=1.2.3-pr.1 <2.0.0\n    // That should allow `1.2.3-pr.2` to pass.\n    // However, `1.2.4-alpha.notready` should NOT be allowed,\n    // even though it's within the range set by the comparators.\n    for (let i = 0; i < set.length; i++) {\n      debug(set[i].semver)\n      if (set[i].semver === Comparator.ANY) {\n        continue\n      }\n\n      if (set[i].semver.prerelease.length > 0) {\n        const allowed = set[i].semver\n        if (allowed.major === version.major &&\n            allowed.minor === version.minor &&\n            allowed.patch === version.patch) {\n          return true\n        }\n      }\n    }\n\n    // Version has a -pre, but it's not one of the ones we like.\n    return false\n  }\n\n  return true\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/classes/range.js?");

/***/ }),

/***/ "./node_modules/semver/classes/semver.js":
/*!***********************************************!*\
  !*** ./node_modules/semver/classes/semver.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const debug = __webpack_require__(/*! ../internal/debug */ \"./node_modules/semver/internal/debug.js\")\nconst { MAX_LENGTH, MAX_SAFE_INTEGER } = __webpack_require__(/*! ../internal/constants */ \"./node_modules/semver/internal/constants.js\")\nconst { safeRe: re, t } = __webpack_require__(/*! ../internal/re */ \"./node_modules/semver/internal/re.js\")\n\nconst parseOptions = __webpack_require__(/*! ../internal/parse-options */ \"./node_modules/semver/internal/parse-options.js\")\nconst { compareIdentifiers } = __webpack_require__(/*! ../internal/identifiers */ \"./node_modules/semver/internal/identifiers.js\")\nclass SemVer {\n  constructor (version, options) {\n    options = parseOptions(options)\n\n    if (version instanceof SemVer) {\n      if (version.loose === !!options.loose &&\n          version.includePrerelease === !!options.includePrerelease) {\n        return version\n      } else {\n        version = version.version\n      }\n    } else if (typeof version !== 'string') {\n      throw new TypeError(`Invalid version. Must be a string. Got type \"${typeof version}\".`)\n    }\n\n    if (version.length > MAX_LENGTH) {\n      throw new TypeError(\n        `version is longer than ${MAX_LENGTH} characters`\n      )\n    }\n\n    debug('SemVer', version, options)\n    this.options = options\n    this.loose = !!options.loose\n    // this isn't actually relevant for versions, but keep it so that we\n    // don't run into trouble passing this.options around.\n    this.includePrerelease = !!options.includePrerelease\n\n    const m = version.trim().match(options.loose ? re[t.LOOSE] : re[t.FULL])\n\n    if (!m) {\n      throw new TypeError(`Invalid Version: ${version}`)\n    }\n\n    this.raw = version\n\n    // these are actually numbers\n    this.major = +m[1]\n    this.minor = +m[2]\n    this.patch = +m[3]\n\n    if (this.major > MAX_SAFE_INTEGER || this.major < 0) {\n      throw new TypeError('Invalid major version')\n    }\n\n    if (this.minor > MAX_SAFE_INTEGER || this.minor < 0) {\n      throw new TypeError('Invalid minor version')\n    }\n\n    if (this.patch > MAX_SAFE_INTEGER || this.patch < 0) {\n      throw new TypeError('Invalid patch version')\n    }\n\n    // numberify any prerelease numeric ids\n    if (!m[4]) {\n      this.prerelease = []\n    } else {\n      this.prerelease = m[4].split('.').map((id) => {\n        if (/^[0-9]+$/.test(id)) {\n          const num = +id\n          if (num >= 0 && num < MAX_SAFE_INTEGER) {\n            return num\n          }\n        }\n        return id\n      })\n    }\n\n    this.build = m[5] ? m[5].split('.') : []\n    this.format()\n  }\n\n  format () {\n    this.version = `${this.major}.${this.minor}.${this.patch}`\n    if (this.prerelease.length) {\n      this.version += `-${this.prerelease.join('.')}`\n    }\n    return this.version\n  }\n\n  toString () {\n    return this.version\n  }\n\n  compare (other) {\n    debug('SemVer.compare', this.version, this.options, other)\n    if (!(other instanceof SemVer)) {\n      if (typeof other === 'string' && other === this.version) {\n        return 0\n      }\n      other = new SemVer(other, this.options)\n    }\n\n    if (other.version === this.version) {\n      return 0\n    }\n\n    return this.compareMain(other) || this.comparePre(other)\n  }\n\n  compareMain (other) {\n    if (!(other instanceof SemVer)) {\n      other = new SemVer(other, this.options)\n    }\n\n    return (\n      compareIdentifiers(this.major, other.major) ||\n      compareIdentifiers(this.minor, other.minor) ||\n      compareIdentifiers(this.patch, other.patch)\n    )\n  }\n\n  comparePre (other) {\n    if (!(other instanceof SemVer)) {\n      other = new SemVer(other, this.options)\n    }\n\n    // NOT having a prerelease is > having one\n    if (this.prerelease.length && !other.prerelease.length) {\n      return -1\n    } else if (!this.prerelease.length && other.prerelease.length) {\n      return 1\n    } else if (!this.prerelease.length && !other.prerelease.length) {\n      return 0\n    }\n\n    let i = 0\n    do {\n      const a = this.prerelease[i]\n      const b = other.prerelease[i]\n      debug('prerelease compare', i, a, b)\n      if (a === undefined && b === undefined) {\n        return 0\n      } else if (b === undefined) {\n        return 1\n      } else if (a === undefined) {\n        return -1\n      } else if (a === b) {\n        continue\n      } else {\n        return compareIdentifiers(a, b)\n      }\n    } while (++i)\n  }\n\n  compareBuild (other) {\n    if (!(other instanceof SemVer)) {\n      other = new SemVer(other, this.options)\n    }\n\n    let i = 0\n    do {\n      const a = this.build[i]\n      const b = other.build[i]\n      debug('prerelease compare', i, a, b)\n      if (a === undefined && b === undefined) {\n        return 0\n      } else if (b === undefined) {\n        return 1\n      } else if (a === undefined) {\n        return -1\n      } else if (a === b) {\n        continue\n      } else {\n        return compareIdentifiers(a, b)\n      }\n    } while (++i)\n  }\n\n  // preminor will bump the version up to the next minor release, and immediately\n  // down to pre-release. premajor and prepatch work the same way.\n  inc (release, identifier, identifierBase) {\n    switch (release) {\n      case 'premajor':\n        this.prerelease.length = 0\n        this.patch = 0\n        this.minor = 0\n        this.major++\n        this.inc('pre', identifier, identifierBase)\n        break\n      case 'preminor':\n        this.prerelease.length = 0\n        this.patch = 0\n        this.minor++\n        this.inc('pre', identifier, identifierBase)\n        break\n      case 'prepatch':\n        // If this is already a prerelease, it will bump to the next version\n        // drop any prereleases that might already exist, since they are not\n        // relevant at this point.\n        this.prerelease.length = 0\n        this.inc('patch', identifier, identifierBase)\n        this.inc('pre', identifier, identifierBase)\n        break\n      // If the input is a non-prerelease version, this acts the same as\n      // prepatch.\n      case 'prerelease':\n        if (this.prerelease.length === 0) {\n          this.inc('patch', identifier, identifierBase)\n        }\n        this.inc('pre', identifier, identifierBase)\n        break\n\n      case 'major':\n        // If this is a pre-major version, bump up to the same major version.\n        // Otherwise increment major.\n        // 1.0.0-5 bumps to 1.0.0\n        // 1.1.0 bumps to 2.0.0\n        if (\n          this.minor !== 0 ||\n          this.patch !== 0 ||\n          this.prerelease.length === 0\n        ) {\n          this.major++\n        }\n        this.minor = 0\n        this.patch = 0\n        this.prerelease = []\n        break\n      case 'minor':\n        // If this is a pre-minor version, bump up to the same minor version.\n        // Otherwise increment minor.\n        // 1.2.0-5 bumps to 1.2.0\n        // 1.2.1 bumps to 1.3.0\n        if (this.patch !== 0 || this.prerelease.length === 0) {\n          this.minor++\n        }\n        this.patch = 0\n        this.prerelease = []\n        break\n      case 'patch':\n        // If this is not a pre-release version, it will increment the patch.\n        // If it is a pre-release it will bump up to the same patch version.\n        // 1.2.0-5 patches to 1.2.0\n        // 1.2.0 patches to 1.2.1\n        if (this.prerelease.length === 0) {\n          this.patch++\n        }\n        this.prerelease = []\n        break\n      // This probably shouldn't be used publicly.\n      // 1.0.0 'pre' would become 1.0.0-0 which is the wrong direction.\n      case 'pre': {\n        const base = Number(identifierBase) ? 1 : 0\n\n        if (!identifier && identifierBase === false) {\n          throw new Error('invalid increment argument: identifier is empty')\n        }\n\n        if (this.prerelease.length === 0) {\n          this.prerelease = [base]\n        } else {\n          let i = this.prerelease.length\n          while (--i >= 0) {\n            if (typeof this.prerelease[i] === 'number') {\n              this.prerelease[i]++\n              i = -2\n            }\n          }\n          if (i === -1) {\n            // didn't increment anything\n            if (identifier === this.prerelease.join('.') && identifierBase === false) {\n              throw new Error('invalid increment argument: identifier already exists')\n            }\n            this.prerelease.push(base)\n          }\n        }\n        if (identifier) {\n          // 1.2.0-beta.1 bumps to 1.2.0-beta.2,\n          // 1.2.0-beta.fooblz or 1.2.0-beta bumps to 1.2.0-beta.0\n          let prerelease = [identifier, base]\n          if (identifierBase === false) {\n            prerelease = [identifier]\n          }\n          if (compareIdentifiers(this.prerelease[0], identifier) === 0) {\n            if (isNaN(this.prerelease[1])) {\n              this.prerelease = prerelease\n            }\n          } else {\n            this.prerelease = prerelease\n          }\n        }\n        break\n      }\n      default:\n        throw new Error(`invalid increment argument: ${release}`)\n    }\n    this.raw = this.format()\n    if (this.build.length) {\n      this.raw += `+${this.build.join('.')}`\n    }\n    return this\n  }\n}\n\nmodule.exports = SemVer\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/classes/semver.js?");

/***/ }),

/***/ "./node_modules/semver/functions/clean.js":
/*!************************************************!*\
  !*** ./node_modules/semver/functions/clean.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const parse = __webpack_require__(/*! ./parse */ \"./node_modules/semver/functions/parse.js\")\nconst clean = (version, options) => {\n  const s = parse(version.trim().replace(/^[=v]+/, ''), options)\n  return s ? s.version : null\n}\nmodule.exports = clean\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/functions/clean.js?");

/***/ }),

/***/ "./node_modules/semver/functions/cmp.js":
/*!**********************************************!*\
  !*** ./node_modules/semver/functions/cmp.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const eq = __webpack_require__(/*! ./eq */ \"./node_modules/semver/functions/eq.js\")\nconst neq = __webpack_require__(/*! ./neq */ \"./node_modules/semver/functions/neq.js\")\nconst gt = __webpack_require__(/*! ./gt */ \"./node_modules/semver/functions/gt.js\")\nconst gte = __webpack_require__(/*! ./gte */ \"./node_modules/semver/functions/gte.js\")\nconst lt = __webpack_require__(/*! ./lt */ \"./node_modules/semver/functions/lt.js\")\nconst lte = __webpack_require__(/*! ./lte */ \"./node_modules/semver/functions/lte.js\")\n\nconst cmp = (a, op, b, loose) => {\n  switch (op) {\n    case '===':\n      if (typeof a === 'object') {\n        a = a.version\n      }\n      if (typeof b === 'object') {\n        b = b.version\n      }\n      return a === b\n\n    case '!==':\n      if (typeof a === 'object') {\n        a = a.version\n      }\n      if (typeof b === 'object') {\n        b = b.version\n      }\n      return a !== b\n\n    case '':\n    case '=':\n    case '==':\n      return eq(a, b, loose)\n\n    case '!=':\n      return neq(a, b, loose)\n\n    case '>':\n      return gt(a, b, loose)\n\n    case '>=':\n      return gte(a, b, loose)\n\n    case '<':\n      return lt(a, b, loose)\n\n    case '<=':\n      return lte(a, b, loose)\n\n    default:\n      throw new TypeError(`Invalid operator: ${op}`)\n  }\n}\nmodule.exports = cmp\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/functions/cmp.js?");

/***/ }),

/***/ "./node_modules/semver/functions/coerce.js":
/*!*************************************************!*\
  !*** ./node_modules/semver/functions/coerce.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SemVer = __webpack_require__(/*! ../classes/semver */ \"./node_modules/semver/classes/semver.js\")\nconst parse = __webpack_require__(/*! ./parse */ \"./node_modules/semver/functions/parse.js\")\nconst { safeRe: re, t } = __webpack_require__(/*! ../internal/re */ \"./node_modules/semver/internal/re.js\")\n\nconst coerce = (version, options) => {\n  if (version instanceof SemVer) {\n    return version\n  }\n\n  if (typeof version === 'number') {\n    version = String(version)\n  }\n\n  if (typeof version !== 'string') {\n    return null\n  }\n\n  options = options || {}\n\n  let match = null\n  if (!options.rtl) {\n    match = version.match(re[t.COERCE])\n  } else {\n    // Find the right-most coercible string that does not share\n    // a terminus with a more left-ward coercible string.\n    // Eg, '1.2.3.4' wants to coerce '2.3.4', not '3.4' or '4'\n    //\n    // Walk through the string checking with a /g regexp\n    // Manually set the index so as to pick up overlapping matches.\n    // Stop when we get a match that ends at the string end, since no\n    // coercible string can be more right-ward without the same terminus.\n    let next\n    while ((next = re[t.COERCERTL].exec(version)) &&\n        (!match || match.index + match[0].length !== version.length)\n    ) {\n      if (!match ||\n            next.index + next[0].length !== match.index + match[0].length) {\n        match = next\n      }\n      re[t.COERCERTL].lastIndex = next.index + next[1].length + next[2].length\n    }\n    // leave it in a clean state\n    re[t.COERCERTL].lastIndex = -1\n  }\n\n  if (match === null) {\n    return null\n  }\n\n  return parse(`${match[2]}.${match[3] || '0'}.${match[4] || '0'}`, options)\n}\nmodule.exports = coerce\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/functions/coerce.js?");

/***/ }),

/***/ "./node_modules/semver/functions/compare-build.js":
/*!********************************************************!*\
  !*** ./node_modules/semver/functions/compare-build.js ***!
  \********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SemVer = __webpack_require__(/*! ../classes/semver */ \"./node_modules/semver/classes/semver.js\")\nconst compareBuild = (a, b, loose) => {\n  const versionA = new SemVer(a, loose)\n  const versionB = new SemVer(b, loose)\n  return versionA.compare(versionB) || versionA.compareBuild(versionB)\n}\nmodule.exports = compareBuild\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/functions/compare-build.js?");

/***/ }),

/***/ "./node_modules/semver/functions/compare-loose.js":
/*!********************************************************!*\
  !*** ./node_modules/semver/functions/compare-loose.js ***!
  \********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const compare = __webpack_require__(/*! ./compare */ \"./node_modules/semver/functions/compare.js\")\nconst compareLoose = (a, b) => compare(a, b, true)\nmodule.exports = compareLoose\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/functions/compare-loose.js?");

/***/ }),

/***/ "./node_modules/semver/functions/compare.js":
/*!**************************************************!*\
  !*** ./node_modules/semver/functions/compare.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SemVer = __webpack_require__(/*! ../classes/semver */ \"./node_modules/semver/classes/semver.js\")\nconst compare = (a, b, loose) =>\n  new SemVer(a, loose).compare(new SemVer(b, loose))\n\nmodule.exports = compare\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/functions/compare.js?");

/***/ }),

/***/ "./node_modules/semver/functions/diff.js":
/*!***********************************************!*\
  !*** ./node_modules/semver/functions/diff.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const parse = __webpack_require__(/*! ./parse.js */ \"./node_modules/semver/functions/parse.js\")\n\nconst diff = (version1, version2) => {\n  const v1 = parse(version1, null, true)\n  const v2 = parse(version2, null, true)\n  const comparison = v1.compare(v2)\n\n  if (comparison === 0) {\n    return null\n  }\n\n  const v1Higher = comparison > 0\n  const highVersion = v1Higher ? v1 : v2\n  const lowVersion = v1Higher ? v2 : v1\n  const highHasPre = !!highVersion.prerelease.length\n  const lowHasPre = !!lowVersion.prerelease.length\n\n  if (lowHasPre && !highHasPre) {\n    // Going from prerelease -> no prerelease requires some special casing\n\n    // If the low version has only a major, then it will always be a major\n    // Some examples:\n    // 1.0.0-1 -> 1.0.0\n    // 1.0.0-1 -> 1.1.1\n    // 1.0.0-1 -> 2.0.0\n    if (!lowVersion.patch && !lowVersion.minor) {\n      return 'major'\n    }\n\n    // Otherwise it can be determined by checking the high version\n\n    if (highVersion.patch) {\n      // anything higher than a patch bump would result in the wrong version\n      return 'patch'\n    }\n\n    if (highVersion.minor) {\n      // anything higher than a minor bump would result in the wrong version\n      return 'minor'\n    }\n\n    // bumping major/minor/patch all have same result\n    return 'major'\n  }\n\n  // add the `pre` prefix if we are going to a prerelease version\n  const prefix = highHasPre ? 'pre' : ''\n\n  if (v1.major !== v2.major) {\n    return prefix + 'major'\n  }\n\n  if (v1.minor !== v2.minor) {\n    return prefix + 'minor'\n  }\n\n  if (v1.patch !== v2.patch) {\n    return prefix + 'patch'\n  }\n\n  // high and low are preleases\n  return 'prerelease'\n}\n\nmodule.exports = diff\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/functions/diff.js?");

/***/ }),

/***/ "./node_modules/semver/functions/eq.js":
/*!*********************************************!*\
  !*** ./node_modules/semver/functions/eq.js ***!
  \*********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const compare = __webpack_require__(/*! ./compare */ \"./node_modules/semver/functions/compare.js\")\nconst eq = (a, b, loose) => compare(a, b, loose) === 0\nmodule.exports = eq\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/functions/eq.js?");

/***/ }),

/***/ "./node_modules/semver/functions/gt.js":
/*!*********************************************!*\
  !*** ./node_modules/semver/functions/gt.js ***!
  \*********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const compare = __webpack_require__(/*! ./compare */ \"./node_modules/semver/functions/compare.js\")\nconst gt = (a, b, loose) => compare(a, b, loose) > 0\nmodule.exports = gt\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/functions/gt.js?");

/***/ }),

/***/ "./node_modules/semver/functions/gte.js":
/*!**********************************************!*\
  !*** ./node_modules/semver/functions/gte.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const compare = __webpack_require__(/*! ./compare */ \"./node_modules/semver/functions/compare.js\")\nconst gte = (a, b, loose) => compare(a, b, loose) >= 0\nmodule.exports = gte\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/functions/gte.js?");

/***/ }),

/***/ "./node_modules/semver/functions/inc.js":
/*!**********************************************!*\
  !*** ./node_modules/semver/functions/inc.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SemVer = __webpack_require__(/*! ../classes/semver */ \"./node_modules/semver/classes/semver.js\")\n\nconst inc = (version, release, options, identifier, identifierBase) => {\n  if (typeof (options) === 'string') {\n    identifierBase = identifier\n    identifier = options\n    options = undefined\n  }\n\n  try {\n    return new SemVer(\n      version instanceof SemVer ? version.version : version,\n      options\n    ).inc(release, identifier, identifierBase).version\n  } catch (er) {\n    return null\n  }\n}\nmodule.exports = inc\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/functions/inc.js?");

/***/ }),

/***/ "./node_modules/semver/functions/lt.js":
/*!*********************************************!*\
  !*** ./node_modules/semver/functions/lt.js ***!
  \*********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const compare = __webpack_require__(/*! ./compare */ \"./node_modules/semver/functions/compare.js\")\nconst lt = (a, b, loose) => compare(a, b, loose) < 0\nmodule.exports = lt\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/functions/lt.js?");

/***/ }),

/***/ "./node_modules/semver/functions/lte.js":
/*!**********************************************!*\
  !*** ./node_modules/semver/functions/lte.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const compare = __webpack_require__(/*! ./compare */ \"./node_modules/semver/functions/compare.js\")\nconst lte = (a, b, loose) => compare(a, b, loose) <= 0\nmodule.exports = lte\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/functions/lte.js?");

/***/ }),

/***/ "./node_modules/semver/functions/major.js":
/*!************************************************!*\
  !*** ./node_modules/semver/functions/major.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SemVer = __webpack_require__(/*! ../classes/semver */ \"./node_modules/semver/classes/semver.js\")\nconst major = (a, loose) => new SemVer(a, loose).major\nmodule.exports = major\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/functions/major.js?");

/***/ }),

/***/ "./node_modules/semver/functions/minor.js":
/*!************************************************!*\
  !*** ./node_modules/semver/functions/minor.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SemVer = __webpack_require__(/*! ../classes/semver */ \"./node_modules/semver/classes/semver.js\")\nconst minor = (a, loose) => new SemVer(a, loose).minor\nmodule.exports = minor\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/functions/minor.js?");

/***/ }),

/***/ "./node_modules/semver/functions/neq.js":
/*!**********************************************!*\
  !*** ./node_modules/semver/functions/neq.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const compare = __webpack_require__(/*! ./compare */ \"./node_modules/semver/functions/compare.js\")\nconst neq = (a, b, loose) => compare(a, b, loose) !== 0\nmodule.exports = neq\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/functions/neq.js?");

/***/ }),

/***/ "./node_modules/semver/functions/parse.js":
/*!************************************************!*\
  !*** ./node_modules/semver/functions/parse.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SemVer = __webpack_require__(/*! ../classes/semver */ \"./node_modules/semver/classes/semver.js\")\nconst parse = (version, options, throwErrors = false) => {\n  if (version instanceof SemVer) {\n    return version\n  }\n  try {\n    return new SemVer(version, options)\n  } catch (er) {\n    if (!throwErrors) {\n      return null\n    }\n    throw er\n  }\n}\n\nmodule.exports = parse\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/functions/parse.js?");

/***/ }),

/***/ "./node_modules/semver/functions/patch.js":
/*!************************************************!*\
  !*** ./node_modules/semver/functions/patch.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SemVer = __webpack_require__(/*! ../classes/semver */ \"./node_modules/semver/classes/semver.js\")\nconst patch = (a, loose) => new SemVer(a, loose).patch\nmodule.exports = patch\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/functions/patch.js?");

/***/ }),

/***/ "./node_modules/semver/functions/prerelease.js":
/*!*****************************************************!*\
  !*** ./node_modules/semver/functions/prerelease.js ***!
  \*****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const parse = __webpack_require__(/*! ./parse */ \"./node_modules/semver/functions/parse.js\")\nconst prerelease = (version, options) => {\n  const parsed = parse(version, options)\n  return (parsed && parsed.prerelease.length) ? parsed.prerelease : null\n}\nmodule.exports = prerelease\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/functions/prerelease.js?");

/***/ }),

/***/ "./node_modules/semver/functions/rcompare.js":
/*!***************************************************!*\
  !*** ./node_modules/semver/functions/rcompare.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const compare = __webpack_require__(/*! ./compare */ \"./node_modules/semver/functions/compare.js\")\nconst rcompare = (a, b, loose) => compare(b, a, loose)\nmodule.exports = rcompare\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/functions/rcompare.js?");

/***/ }),

/***/ "./node_modules/semver/functions/rsort.js":
/*!************************************************!*\
  !*** ./node_modules/semver/functions/rsort.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const compareBuild = __webpack_require__(/*! ./compare-build */ \"./node_modules/semver/functions/compare-build.js\")\nconst rsort = (list, loose) => list.sort((a, b) => compareBuild(b, a, loose))\nmodule.exports = rsort\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/functions/rsort.js?");

/***/ }),

/***/ "./node_modules/semver/functions/satisfies.js":
/*!****************************************************!*\
  !*** ./node_modules/semver/functions/satisfies.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const Range = __webpack_require__(/*! ../classes/range */ \"./node_modules/semver/classes/range.js\")\nconst satisfies = (version, range, options) => {\n  try {\n    range = new Range(range, options)\n  } catch (er) {\n    return false\n  }\n  return range.test(version)\n}\nmodule.exports = satisfies\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/functions/satisfies.js?");

/***/ }),

/***/ "./node_modules/semver/functions/sort.js":
/*!***********************************************!*\
  !*** ./node_modules/semver/functions/sort.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const compareBuild = __webpack_require__(/*! ./compare-build */ \"./node_modules/semver/functions/compare-build.js\")\nconst sort = (list, loose) => list.sort((a, b) => compareBuild(a, b, loose))\nmodule.exports = sort\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/functions/sort.js?");

/***/ }),

/***/ "./node_modules/semver/functions/valid.js":
/*!************************************************!*\
  !*** ./node_modules/semver/functions/valid.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const parse = __webpack_require__(/*! ./parse */ \"./node_modules/semver/functions/parse.js\")\nconst valid = (version, options) => {\n  const v = parse(version, options)\n  return v ? v.version : null\n}\nmodule.exports = valid\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/functions/valid.js?");

/***/ }),

/***/ "./node_modules/semver/index.js":
/*!**************************************!*\
  !*** ./node_modules/semver/index.js ***!
  \**************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("// just pre-load all the stuff that index.js lazily exports\nconst internalRe = __webpack_require__(/*! ./internal/re */ \"./node_modules/semver/internal/re.js\")\nconst constants = __webpack_require__(/*! ./internal/constants */ \"./node_modules/semver/internal/constants.js\")\nconst SemVer = __webpack_require__(/*! ./classes/semver */ \"./node_modules/semver/classes/semver.js\")\nconst identifiers = __webpack_require__(/*! ./internal/identifiers */ \"./node_modules/semver/internal/identifiers.js\")\nconst parse = __webpack_require__(/*! ./functions/parse */ \"./node_modules/semver/functions/parse.js\")\nconst valid = __webpack_require__(/*! ./functions/valid */ \"./node_modules/semver/functions/valid.js\")\nconst clean = __webpack_require__(/*! ./functions/clean */ \"./node_modules/semver/functions/clean.js\")\nconst inc = __webpack_require__(/*! ./functions/inc */ \"./node_modules/semver/functions/inc.js\")\nconst diff = __webpack_require__(/*! ./functions/diff */ \"./node_modules/semver/functions/diff.js\")\nconst major = __webpack_require__(/*! ./functions/major */ \"./node_modules/semver/functions/major.js\")\nconst minor = __webpack_require__(/*! ./functions/minor */ \"./node_modules/semver/functions/minor.js\")\nconst patch = __webpack_require__(/*! ./functions/patch */ \"./node_modules/semver/functions/patch.js\")\nconst prerelease = __webpack_require__(/*! ./functions/prerelease */ \"./node_modules/semver/functions/prerelease.js\")\nconst compare = __webpack_require__(/*! ./functions/compare */ \"./node_modules/semver/functions/compare.js\")\nconst rcompare = __webpack_require__(/*! ./functions/rcompare */ \"./node_modules/semver/functions/rcompare.js\")\nconst compareLoose = __webpack_require__(/*! ./functions/compare-loose */ \"./node_modules/semver/functions/compare-loose.js\")\nconst compareBuild = __webpack_require__(/*! ./functions/compare-build */ \"./node_modules/semver/functions/compare-build.js\")\nconst sort = __webpack_require__(/*! ./functions/sort */ \"./node_modules/semver/functions/sort.js\")\nconst rsort = __webpack_require__(/*! ./functions/rsort */ \"./node_modules/semver/functions/rsort.js\")\nconst gt = __webpack_require__(/*! ./functions/gt */ \"./node_modules/semver/functions/gt.js\")\nconst lt = __webpack_require__(/*! ./functions/lt */ \"./node_modules/semver/functions/lt.js\")\nconst eq = __webpack_require__(/*! ./functions/eq */ \"./node_modules/semver/functions/eq.js\")\nconst neq = __webpack_require__(/*! ./functions/neq */ \"./node_modules/semver/functions/neq.js\")\nconst gte = __webpack_require__(/*! ./functions/gte */ \"./node_modules/semver/functions/gte.js\")\nconst lte = __webpack_require__(/*! ./functions/lte */ \"./node_modules/semver/functions/lte.js\")\nconst cmp = __webpack_require__(/*! ./functions/cmp */ \"./node_modules/semver/functions/cmp.js\")\nconst coerce = __webpack_require__(/*! ./functions/coerce */ \"./node_modules/semver/functions/coerce.js\")\nconst Comparator = __webpack_require__(/*! ./classes/comparator */ \"./node_modules/semver/classes/comparator.js\")\nconst Range = __webpack_require__(/*! ./classes/range */ \"./node_modules/semver/classes/range.js\")\nconst satisfies = __webpack_require__(/*! ./functions/satisfies */ \"./node_modules/semver/functions/satisfies.js\")\nconst toComparators = __webpack_require__(/*! ./ranges/to-comparators */ \"./node_modules/semver/ranges/to-comparators.js\")\nconst maxSatisfying = __webpack_require__(/*! ./ranges/max-satisfying */ \"./node_modules/semver/ranges/max-satisfying.js\")\nconst minSatisfying = __webpack_require__(/*! ./ranges/min-satisfying */ \"./node_modules/semver/ranges/min-satisfying.js\")\nconst minVersion = __webpack_require__(/*! ./ranges/min-version */ \"./node_modules/semver/ranges/min-version.js\")\nconst validRange = __webpack_require__(/*! ./ranges/valid */ \"./node_modules/semver/ranges/valid.js\")\nconst outside = __webpack_require__(/*! ./ranges/outside */ \"./node_modules/semver/ranges/outside.js\")\nconst gtr = __webpack_require__(/*! ./ranges/gtr */ \"./node_modules/semver/ranges/gtr.js\")\nconst ltr = __webpack_require__(/*! ./ranges/ltr */ \"./node_modules/semver/ranges/ltr.js\")\nconst intersects = __webpack_require__(/*! ./ranges/intersects */ \"./node_modules/semver/ranges/intersects.js\")\nconst simplifyRange = __webpack_require__(/*! ./ranges/simplify */ \"./node_modules/semver/ranges/simplify.js\")\nconst subset = __webpack_require__(/*! ./ranges/subset */ \"./node_modules/semver/ranges/subset.js\")\nmodule.exports = {\n  parse,\n  valid,\n  clean,\n  inc,\n  diff,\n  major,\n  minor,\n  patch,\n  prerelease,\n  compare,\n  rcompare,\n  compareLoose,\n  compareBuild,\n  sort,\n  rsort,\n  gt,\n  lt,\n  eq,\n  neq,\n  gte,\n  lte,\n  cmp,\n  coerce,\n  Comparator,\n  Range,\n  satisfies,\n  toComparators,\n  maxSatisfying,\n  minSatisfying,\n  minVersion,\n  validRange,\n  outside,\n  gtr,\n  ltr,\n  intersects,\n  simplifyRange,\n  subset,\n  SemVer,\n  re: internalRe.re,\n  src: internalRe.src,\n  tokens: internalRe.t,\n  SEMVER_SPEC_VERSION: constants.SEMVER_SPEC_VERSION,\n  RELEASE_TYPES: constants.RELEASE_TYPES,\n  compareIdentifiers: identifiers.compareIdentifiers,\n  rcompareIdentifiers: identifiers.rcompareIdentifiers,\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/index.js?");

/***/ }),

/***/ "./node_modules/semver/internal/constants.js":
/*!***************************************************!*\
  !*** ./node_modules/semver/internal/constants.js ***!
  \***************************************************/
/***/ ((module) => {

eval("// Note: this is the semver.org version of the spec that it implements\n// Not necessarily the package version of this code.\nconst SEMVER_SPEC_VERSION = '2.0.0'\n\nconst MAX_LENGTH = 256\nconst MAX_SAFE_INTEGER = Number.MAX_SAFE_INTEGER ||\n/* istanbul ignore next */ 9007199254740991\n\n// Max safe segment length for coercion.\nconst MAX_SAFE_COMPONENT_LENGTH = 16\n\n// Max safe length for a build identifier. The max length minus 6 characters for\n// the shortest version with a build 0.0.0+BUILD.\nconst MAX_SAFE_BUILD_LENGTH = MAX_LENGTH - 6\n\nconst RELEASE_TYPES = [\n  'major',\n  'premajor',\n  'minor',\n  'preminor',\n  'patch',\n  'prepatch',\n  'prerelease',\n]\n\nmodule.exports = {\n  MAX_LENGTH,\n  MAX_SAFE_COMPONENT_LENGTH,\n  MAX_SAFE_BUILD_LENGTH,\n  MAX_SAFE_INTEGER,\n  RELEASE_TYPES,\n  SEMVER_SPEC_VERSION,\n  FLAG_INCLUDE_PRERELEASE: 0b001,\n  FLAG_LOOSE: 0b010,\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/internal/constants.js?");

/***/ }),

/***/ "./node_modules/semver/internal/debug.js":
/*!***********************************************!*\
  !*** ./node_modules/semver/internal/debug.js ***!
  \***********************************************/
/***/ ((module) => {

eval("const debug = (\n  typeof process === 'object' &&\n  process.env &&\n  process.env.NODE_DEBUG &&\n  /\\bsemver\\b/i.test(process.env.NODE_DEBUG)\n) ? (...args) => console.error('SEMVER', ...args)\n  : () => {}\n\nmodule.exports = debug\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/internal/debug.js?");

/***/ }),

/***/ "./node_modules/semver/internal/identifiers.js":
/*!*****************************************************!*\
  !*** ./node_modules/semver/internal/identifiers.js ***!
  \*****************************************************/
/***/ ((module) => {

eval("const numeric = /^[0-9]+$/\nconst compareIdentifiers = (a, b) => {\n  const anum = numeric.test(a)\n  const bnum = numeric.test(b)\n\n  if (anum && bnum) {\n    a = +a\n    b = +b\n  }\n\n  return a === b ? 0\n    : (anum && !bnum) ? -1\n    : (bnum && !anum) ? 1\n    : a < b ? -1\n    : 1\n}\n\nconst rcompareIdentifiers = (a, b) => compareIdentifiers(b, a)\n\nmodule.exports = {\n  compareIdentifiers,\n  rcompareIdentifiers,\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/internal/identifiers.js?");

/***/ }),

/***/ "./node_modules/semver/internal/parse-options.js":
/*!*******************************************************!*\
  !*** ./node_modules/semver/internal/parse-options.js ***!
  \*******************************************************/
/***/ ((module) => {

eval("// parse out just the options we care about\nconst looseOption = Object.freeze({ loose: true })\nconst emptyOpts = Object.freeze({ })\nconst parseOptions = options => {\n  if (!options) {\n    return emptyOpts\n  }\n\n  if (typeof options !== 'object') {\n    return looseOption\n  }\n\n  return options\n}\nmodule.exports = parseOptions\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/internal/parse-options.js?");

/***/ }),

/***/ "./node_modules/semver/internal/re.js":
/*!********************************************!*\
  !*** ./node_modules/semver/internal/re.js ***!
  \********************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("const {\n  MAX_SAFE_COMPONENT_LENGTH,\n  MAX_SAFE_BUILD_LENGTH,\n  MAX_LENGTH,\n} = __webpack_require__(/*! ./constants */ \"./node_modules/semver/internal/constants.js\")\nconst debug = __webpack_require__(/*! ./debug */ \"./node_modules/semver/internal/debug.js\")\nexports = module.exports = {}\n\n// The actual regexps go on exports.re\nconst re = exports.re = []\nconst safeRe = exports.safeRe = []\nconst src = exports.src = []\nconst t = exports.t = {}\nlet R = 0\n\nconst LETTERDASHNUMBER = '[a-zA-Z0-9-]'\n\n// Replace some greedy regex tokens to prevent regex dos issues. These regex are\n// used internally via the safeRe object since all inputs in this library get\n// normalized first to trim and collapse all extra whitespace. The original\n// regexes are exported for userland consumption and lower level usage. A\n// future breaking change could export the safer regex only with a note that\n// all input should have extra whitespace removed.\nconst safeRegexReplacements = [\n  ['\\\\s', 1],\n  ['\\\\d', MAX_LENGTH],\n  [LETTERDASHNUMBER, MAX_SAFE_BUILD_LENGTH],\n]\n\nconst makeSafeRegex = (value) => {\n  for (const [token, max] of safeRegexReplacements) {\n    value = value\n      .split(`${token}*`).join(`${token}{0,${max}}`)\n      .split(`${token}+`).join(`${token}{1,${max}}`)\n  }\n  return value\n}\n\nconst createToken = (name, value, isGlobal) => {\n  const safe = makeSafeRegex(value)\n  const index = R++\n  debug(name, index, value)\n  t[name] = index\n  src[index] = value\n  re[index] = new RegExp(value, isGlobal ? 'g' : undefined)\n  safeRe[index] = new RegExp(safe, isGlobal ? 'g' : undefined)\n}\n\n// The following Regular Expressions can be used for tokenizing,\n// validating, and parsing SemVer version strings.\n\n// ## Numeric Identifier\n// A single `0`, or a non-zero digit followed by zero or more digits.\n\ncreateToken('NUMERICIDENTIFIER', '0|[1-9]\\\\d*')\ncreateToken('NUMERICIDENTIFIERLOOSE', '\\\\d+')\n\n// ## Non-numeric Identifier\n// Zero or more digits, followed by a letter or hyphen, and then zero or\n// more letters, digits, or hyphens.\n\ncreateToken('NONNUMERICIDENTIFIER', `\\\\d*[a-zA-Z-]${LETTERDASHNUMBER}*`)\n\n// ## Main Version\n// Three dot-separated numeric identifiers.\n\ncreateToken('MAINVERSION', `(${src[t.NUMERICIDENTIFIER]})\\\\.` +\n                   `(${src[t.NUMERICIDENTIFIER]})\\\\.` +\n                   `(${src[t.NUMERICIDENTIFIER]})`)\n\ncreateToken('MAINVERSIONLOOSE', `(${src[t.NUMERICIDENTIFIERLOOSE]})\\\\.` +\n                        `(${src[t.NUMERICIDENTIFIERLOOSE]})\\\\.` +\n                        `(${src[t.NUMERICIDENTIFIERLOOSE]})`)\n\n// ## Pre-release Version Identifier\n// A numeric identifier, or a non-numeric identifier.\n\ncreateToken('PRERELEASEIDENTIFIER', `(?:${src[t.NUMERICIDENTIFIER]\n}|${src[t.NONNUMERICIDENTIFIER]})`)\n\ncreateToken('PRERELEASEIDENTIFIERLOOSE', `(?:${src[t.NUMERICIDENTIFIERLOOSE]\n}|${src[t.NONNUMERICIDENTIFIER]})`)\n\n// ## Pre-release Version\n// Hyphen, followed by one or more dot-separated pre-release version\n// identifiers.\n\ncreateToken('PRERELEASE', `(?:-(${src[t.PRERELEASEIDENTIFIER]\n}(?:\\\\.${src[t.PRERELEASEIDENTIFIER]})*))`)\n\ncreateToken('PRERELEASELOOSE', `(?:-?(${src[t.PRERELEASEIDENTIFIERLOOSE]\n}(?:\\\\.${src[t.PRERELEASEIDENTIFIERLOOSE]})*))`)\n\n// ## Build Metadata Identifier\n// Any combination of digits, letters, or hyphens.\n\ncreateToken('BUILDIDENTIFIER', `${LETTERDASHNUMBER}+`)\n\n// ## Build Metadata\n// Plus sign, followed by one or more period-separated build metadata\n// identifiers.\n\ncreateToken('BUILD', `(?:\\\\+(${src[t.BUILDIDENTIFIER]\n}(?:\\\\.${src[t.BUILDIDENTIFIER]})*))`)\n\n// ## Full Version String\n// A main version, followed optionally by a pre-release version and\n// build metadata.\n\n// Note that the only major, minor, patch, and pre-release sections of\n// the version string are capturing groups.  The build metadata is not a\n// capturing group, because it should not ever be used in version\n// comparison.\n\ncreateToken('FULLPLAIN', `v?${src[t.MAINVERSION]\n}${src[t.PRERELEASE]}?${\n  src[t.BUILD]}?`)\n\ncreateToken('FULL', `^${src[t.FULLPLAIN]}$`)\n\n// like full, but allows v1.2.3 and =1.2.3, which people do sometimes.\n// also, 1.0.0alpha1 (prerelease without the hyphen) which is pretty\n// common in the npm registry.\ncreateToken('LOOSEPLAIN', `[v=\\\\s]*${src[t.MAINVERSIONLOOSE]\n}${src[t.PRERELEASELOOSE]}?${\n  src[t.BUILD]}?`)\n\ncreateToken('LOOSE', `^${src[t.LOOSEPLAIN]}$`)\n\ncreateToken('GTLT', '((?:<|>)?=?)')\n\n// Something like \"2.*\" or \"1.2.x\".\n// Note that \"x.x\" is a valid xRange identifer, meaning \"any version\"\n// Only the first item is strictly required.\ncreateToken('XRANGEIDENTIFIERLOOSE', `${src[t.NUMERICIDENTIFIERLOOSE]}|x|X|\\\\*`)\ncreateToken('XRANGEIDENTIFIER', `${src[t.NUMERICIDENTIFIER]}|x|X|\\\\*`)\n\ncreateToken('XRANGEPLAIN', `[v=\\\\s]*(${src[t.XRANGEIDENTIFIER]})` +\n                   `(?:\\\\.(${src[t.XRANGEIDENTIFIER]})` +\n                   `(?:\\\\.(${src[t.XRANGEIDENTIFIER]})` +\n                   `(?:${src[t.PRERELEASE]})?${\n                     src[t.BUILD]}?` +\n                   `)?)?`)\n\ncreateToken('XRANGEPLAINLOOSE', `[v=\\\\s]*(${src[t.XRANGEIDENTIFIERLOOSE]})` +\n                        `(?:\\\\.(${src[t.XRANGEIDENTIFIERLOOSE]})` +\n                        `(?:\\\\.(${src[t.XRANGEIDENTIFIERLOOSE]})` +\n                        `(?:${src[t.PRERELEASELOOSE]})?${\n                          src[t.BUILD]}?` +\n                        `)?)?`)\n\ncreateToken('XRANGE', `^${src[t.GTLT]}\\\\s*${src[t.XRANGEPLAIN]}$`)\ncreateToken('XRANGELOOSE', `^${src[t.GTLT]}\\\\s*${src[t.XRANGEPLAINLOOSE]}$`)\n\n// Coercion.\n// Extract anything that could conceivably be a part of a valid semver\ncreateToken('COERCE', `${'(^|[^\\\\d])' +\n              '(\\\\d{1,'}${MAX_SAFE_COMPONENT_LENGTH}})` +\n              `(?:\\\\.(\\\\d{1,${MAX_SAFE_COMPONENT_LENGTH}}))?` +\n              `(?:\\\\.(\\\\d{1,${MAX_SAFE_COMPONENT_LENGTH}}))?` +\n              `(?:$|[^\\\\d])`)\ncreateToken('COERCERTL', src[t.COERCE], true)\n\n// Tilde ranges.\n// Meaning is \"reasonably at or greater than\"\ncreateToken('LONETILDE', '(?:~>?)')\n\ncreateToken('TILDETRIM', `(\\\\s*)${src[t.LONETILDE]}\\\\s+`, true)\nexports.tildeTrimReplace = '$1~'\n\ncreateToken('TILDE', `^${src[t.LONETILDE]}${src[t.XRANGEPLAIN]}$`)\ncreateToken('TILDELOOSE', `^${src[t.LONETILDE]}${src[t.XRANGEPLAINLOOSE]}$`)\n\n// Caret ranges.\n// Meaning is \"at least and backwards compatible with\"\ncreateToken('LONECARET', '(?:\\\\^)')\n\ncreateToken('CARETTRIM', `(\\\\s*)${src[t.LONECARET]}\\\\s+`, true)\nexports.caretTrimReplace = '$1^'\n\ncreateToken('CARET', `^${src[t.LONECARET]}${src[t.XRANGEPLAIN]}$`)\ncreateToken('CARETLOOSE', `^${src[t.LONECARET]}${src[t.XRANGEPLAINLOOSE]}$`)\n\n// A simple gt/lt/eq thing, or just \"\" to indicate \"any version\"\ncreateToken('COMPARATORLOOSE', `^${src[t.GTLT]}\\\\s*(${src[t.LOOSEPLAIN]})$|^$`)\ncreateToken('COMPARATOR', `^${src[t.GTLT]}\\\\s*(${src[t.FULLPLAIN]})$|^$`)\n\n// An expression to strip any whitespace between the gtlt and the thing\n// it modifies, so that `> 1.2.3` ==> `>1.2.3`\ncreateToken('COMPARATORTRIM', `(\\\\s*)${src[t.GTLT]\n}\\\\s*(${src[t.LOOSEPLAIN]}|${src[t.XRANGEPLAIN]})`, true)\nexports.comparatorTrimReplace = '$1$2$3'\n\n// Something like `1.2.3 - 1.2.4`\n// Note that these all use the loose form, because they'll be\n// checked against either the strict or loose comparator form\n// later.\ncreateToken('HYPHENRANGE', `^\\\\s*(${src[t.XRANGEPLAIN]})` +\n                   `\\\\s+-\\\\s+` +\n                   `(${src[t.XRANGEPLAIN]})` +\n                   `\\\\s*$`)\n\ncreateToken('HYPHENRANGELOOSE', `^\\\\s*(${src[t.XRANGEPLAINLOOSE]})` +\n                        `\\\\s+-\\\\s+` +\n                        `(${src[t.XRANGEPLAINLOOSE]})` +\n                        `\\\\s*$`)\n\n// Star ranges basically just allow anything at all.\ncreateToken('STAR', '(<|>)?=?\\\\s*\\\\*')\n// >=0.0.0 is like a star\ncreateToken('GTE0', '^\\\\s*>=\\\\s*0\\\\.0\\\\.0\\\\s*$')\ncreateToken('GTE0PRE', '^\\\\s*>=\\\\s*0\\\\.0\\\\.0-0\\\\s*$')\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/internal/re.js?");

/***/ }),

/***/ "./node_modules/semver/node_modules/lru-cache/index.js":
/*!*************************************************************!*\
  !*** ./node_modules/semver/node_modules/lru-cache/index.js ***!
  \*************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n// A linked list to keep track of recently-used-ness\nconst Yallist = __webpack_require__(/*! yallist */ \"./node_modules/semver/node_modules/yallist/yallist.js\")\n\nconst MAX = Symbol('max')\nconst LENGTH = Symbol('length')\nconst LENGTH_CALCULATOR = Symbol('lengthCalculator')\nconst ALLOW_STALE = Symbol('allowStale')\nconst MAX_AGE = Symbol('maxAge')\nconst DISPOSE = Symbol('dispose')\nconst NO_DISPOSE_ON_SET = Symbol('noDisposeOnSet')\nconst LRU_LIST = Symbol('lruList')\nconst CACHE = Symbol('cache')\nconst UPDATE_AGE_ON_GET = Symbol('updateAgeOnGet')\n\nconst naiveLength = () => 1\n\n// lruList is a yallist where the head is the youngest\n// item, and the tail is the oldest.  the list contains the Hit\n// objects as the entries.\n// Each Hit object has a reference to its Yallist.Node.  This\n// never changes.\n//\n// cache is a Map (or PseudoMap) that matches the keys to\n// the Yallist.Node object.\nclass LRUCache {\n  constructor (options) {\n    if (typeof options === 'number')\n      options = { max: options }\n\n    if (!options)\n      options = {}\n\n    if (options.max && (typeof options.max !== 'number' || options.max < 0))\n      throw new TypeError('max must be a non-negative number')\n    // Kind of weird to have a default max of Infinity, but oh well.\n    const max = this[MAX] = options.max || Infinity\n\n    const lc = options.length || naiveLength\n    this[LENGTH_CALCULATOR] = (typeof lc !== 'function') ? naiveLength : lc\n    this[ALLOW_STALE] = options.stale || false\n    if (options.maxAge && typeof options.maxAge !== 'number')\n      throw new TypeError('maxAge must be a number')\n    this[MAX_AGE] = options.maxAge || 0\n    this[DISPOSE] = options.dispose\n    this[NO_DISPOSE_ON_SET] = options.noDisposeOnSet || false\n    this[UPDATE_AGE_ON_GET] = options.updateAgeOnGet || false\n    this.reset()\n  }\n\n  // resize the cache when the max changes.\n  set max (mL) {\n    if (typeof mL !== 'number' || mL < 0)\n      throw new TypeError('max must be a non-negative number')\n\n    this[MAX] = mL || Infinity\n    trim(this)\n  }\n  get max () {\n    return this[MAX]\n  }\n\n  set allowStale (allowStale) {\n    this[ALLOW_STALE] = !!allowStale\n  }\n  get allowStale () {\n    return this[ALLOW_STALE]\n  }\n\n  set maxAge (mA) {\n    if (typeof mA !== 'number')\n      throw new TypeError('maxAge must be a non-negative number')\n\n    this[MAX_AGE] = mA\n    trim(this)\n  }\n  get maxAge () {\n    return this[MAX_AGE]\n  }\n\n  // resize the cache when the lengthCalculator changes.\n  set lengthCalculator (lC) {\n    if (typeof lC !== 'function')\n      lC = naiveLength\n\n    if (lC !== this[LENGTH_CALCULATOR]) {\n      this[LENGTH_CALCULATOR] = lC\n      this[LENGTH] = 0\n      this[LRU_LIST].forEach(hit => {\n        hit.length = this[LENGTH_CALCULATOR](hit.value, hit.key)\n        this[LENGTH] += hit.length\n      })\n    }\n    trim(this)\n  }\n  get lengthCalculator () { return this[LENGTH_CALCULATOR] }\n\n  get length () { return this[LENGTH] }\n  get itemCount () { return this[LRU_LIST].length }\n\n  rforEach (fn, thisp) {\n    thisp = thisp || this\n    for (let walker = this[LRU_LIST].tail; walker !== null;) {\n      const prev = walker.prev\n      forEachStep(this, fn, walker, thisp)\n      walker = prev\n    }\n  }\n\n  forEach (fn, thisp) {\n    thisp = thisp || this\n    for (let walker = this[LRU_LIST].head; walker !== null;) {\n      const next = walker.next\n      forEachStep(this, fn, walker, thisp)\n      walker = next\n    }\n  }\n\n  keys () {\n    return this[LRU_LIST].toArray().map(k => k.key)\n  }\n\n  values () {\n    return this[LRU_LIST].toArray().map(k => k.value)\n  }\n\n  reset () {\n    if (this[DISPOSE] &&\n        this[LRU_LIST] &&\n        this[LRU_LIST].length) {\n      this[LRU_LIST].forEach(hit => this[DISPOSE](hit.key, hit.value))\n    }\n\n    this[CACHE] = new Map() // hash of items by key\n    this[LRU_LIST] = new Yallist() // list of items in order of use recency\n    this[LENGTH] = 0 // length of items in the list\n  }\n\n  dump () {\n    return this[LRU_LIST].map(hit =>\n      isStale(this, hit) ? false : {\n        k: hit.key,\n        v: hit.value,\n        e: hit.now + (hit.maxAge || 0)\n      }).toArray().filter(h => h)\n  }\n\n  dumpLru () {\n    return this[LRU_LIST]\n  }\n\n  set (key, value, maxAge) {\n    maxAge = maxAge || this[MAX_AGE]\n\n    if (maxAge && typeof maxAge !== 'number')\n      throw new TypeError('maxAge must be a number')\n\n    const now = maxAge ? Date.now() : 0\n    const len = this[LENGTH_CALCULATOR](value, key)\n\n    if (this[CACHE].has(key)) {\n      if (len > this[MAX]) {\n        del(this, this[CACHE].get(key))\n        return false\n      }\n\n      const node = this[CACHE].get(key)\n      const item = node.value\n\n      // dispose of the old one before overwriting\n      // split out into 2 ifs for better coverage tracking\n      if (this[DISPOSE]) {\n        if (!this[NO_DISPOSE_ON_SET])\n          this[DISPOSE](key, item.value)\n      }\n\n      item.now = now\n      item.maxAge = maxAge\n      item.value = value\n      this[LENGTH] += len - item.length\n      item.length = len\n      this.get(key)\n      trim(this)\n      return true\n    }\n\n    const hit = new Entry(key, value, len, now, maxAge)\n\n    // oversized objects fall out of cache automatically.\n    if (hit.length > this[MAX]) {\n      if (this[DISPOSE])\n        this[DISPOSE](key, value)\n\n      return false\n    }\n\n    this[LENGTH] += hit.length\n    this[LRU_LIST].unshift(hit)\n    this[CACHE].set(key, this[LRU_LIST].head)\n    trim(this)\n    return true\n  }\n\n  has (key) {\n    if (!this[CACHE].has(key)) return false\n    const hit = this[CACHE].get(key).value\n    return !isStale(this, hit)\n  }\n\n  get (key) {\n    return get(this, key, true)\n  }\n\n  peek (key) {\n    return get(this, key, false)\n  }\n\n  pop () {\n    const node = this[LRU_LIST].tail\n    if (!node)\n      return null\n\n    del(this, node)\n    return node.value\n  }\n\n  del (key) {\n    del(this, this[CACHE].get(key))\n  }\n\n  load (arr) {\n    // reset the cache\n    this.reset()\n\n    const now = Date.now()\n    // A previous serialized cache has the most recent items first\n    for (let l = arr.length - 1; l >= 0; l--) {\n      const hit = arr[l]\n      const expiresAt = hit.e || 0\n      if (expiresAt === 0)\n        // the item was created without expiration in a non aged cache\n        this.set(hit.k, hit.v)\n      else {\n        const maxAge = expiresAt - now\n        // dont add already expired items\n        if (maxAge > 0) {\n          this.set(hit.k, hit.v, maxAge)\n        }\n      }\n    }\n  }\n\n  prune () {\n    this[CACHE].forEach((value, key) => get(this, key, false))\n  }\n}\n\nconst get = (self, key, doUse) => {\n  const node = self[CACHE].get(key)\n  if (node) {\n    const hit = node.value\n    if (isStale(self, hit)) {\n      del(self, node)\n      if (!self[ALLOW_STALE])\n        return undefined\n    } else {\n      if (doUse) {\n        if (self[UPDATE_AGE_ON_GET])\n          node.value.now = Date.now()\n        self[LRU_LIST].unshiftNode(node)\n      }\n    }\n    return hit.value\n  }\n}\n\nconst isStale = (self, hit) => {\n  if (!hit || (!hit.maxAge && !self[MAX_AGE]))\n    return false\n\n  const diff = Date.now() - hit.now\n  return hit.maxAge ? diff > hit.maxAge\n    : self[MAX_AGE] && (diff > self[MAX_AGE])\n}\n\nconst trim = self => {\n  if (self[LENGTH] > self[MAX]) {\n    for (let walker = self[LRU_LIST].tail;\n      self[LENGTH] > self[MAX] && walker !== null;) {\n      // We know that we're about to delete this one, and also\n      // what the next least recently used key will be, so just\n      // go ahead and set it now.\n      const prev = walker.prev\n      del(self, walker)\n      walker = prev\n    }\n  }\n}\n\nconst del = (self, node) => {\n  if (node) {\n    const hit = node.value\n    if (self[DISPOSE])\n      self[DISPOSE](hit.key, hit.value)\n\n    self[LENGTH] -= hit.length\n    self[CACHE].delete(hit.key)\n    self[LRU_LIST].removeNode(node)\n  }\n}\n\nclass Entry {\n  constructor (key, value, length, now, maxAge) {\n    this.key = key\n    this.value = value\n    this.length = length\n    this.now = now\n    this.maxAge = maxAge || 0\n  }\n}\n\nconst forEachStep = (self, fn, node, thisp) => {\n  let hit = node.value\n  if (isStale(self, hit)) {\n    del(self, node)\n    if (!self[ALLOW_STALE])\n      hit = undefined\n  }\n  if (hit)\n    fn.call(thisp, hit.value, hit.key, self)\n}\n\nmodule.exports = LRUCache\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/node_modules/lru-cache/index.js?");

/***/ }),

/***/ "./node_modules/semver/node_modules/yallist/iterator.js":
/*!**************************************************************!*\
  !*** ./node_modules/semver/node_modules/yallist/iterator.js ***!
  \**************************************************************/
/***/ ((module) => {

"use strict";
eval("\nmodule.exports = function (Yallist) {\n  Yallist.prototype[Symbol.iterator] = function* () {\n    for (let walker = this.head; walker; walker = walker.next) {\n      yield walker.value\n    }\n  }\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/node_modules/yallist/iterator.js?");

/***/ }),

/***/ "./node_modules/semver/node_modules/yallist/yallist.js":
/*!*************************************************************!*\
  !*** ./node_modules/semver/node_modules/yallist/yallist.js ***!
  \*************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nmodule.exports = Yallist\n\nYallist.Node = Node\nYallist.create = Yallist\n\nfunction Yallist (list) {\n  var self = this\n  if (!(self instanceof Yallist)) {\n    self = new Yallist()\n  }\n\n  self.tail = null\n  self.head = null\n  self.length = 0\n\n  if (list && typeof list.forEach === 'function') {\n    list.forEach(function (item) {\n      self.push(item)\n    })\n  } else if (arguments.length > 0) {\n    for (var i = 0, l = arguments.length; i < l; i++) {\n      self.push(arguments[i])\n    }\n  }\n\n  return self\n}\n\nYallist.prototype.removeNode = function (node) {\n  if (node.list !== this) {\n    throw new Error('removing node which does not belong to this list')\n  }\n\n  var next = node.next\n  var prev = node.prev\n\n  if (next) {\n    next.prev = prev\n  }\n\n  if (prev) {\n    prev.next = next\n  }\n\n  if (node === this.head) {\n    this.head = next\n  }\n  if (node === this.tail) {\n    this.tail = prev\n  }\n\n  node.list.length--\n  node.next = null\n  node.prev = null\n  node.list = null\n\n  return next\n}\n\nYallist.prototype.unshiftNode = function (node) {\n  if (node === this.head) {\n    return\n  }\n\n  if (node.list) {\n    node.list.removeNode(node)\n  }\n\n  var head = this.head\n  node.list = this\n  node.next = head\n  if (head) {\n    head.prev = node\n  }\n\n  this.head = node\n  if (!this.tail) {\n    this.tail = node\n  }\n  this.length++\n}\n\nYallist.prototype.pushNode = function (node) {\n  if (node === this.tail) {\n    return\n  }\n\n  if (node.list) {\n    node.list.removeNode(node)\n  }\n\n  var tail = this.tail\n  node.list = this\n  node.prev = tail\n  if (tail) {\n    tail.next = node\n  }\n\n  this.tail = node\n  if (!this.head) {\n    this.head = node\n  }\n  this.length++\n}\n\nYallist.prototype.push = function () {\n  for (var i = 0, l = arguments.length; i < l; i++) {\n    push(this, arguments[i])\n  }\n  return this.length\n}\n\nYallist.prototype.unshift = function () {\n  for (var i = 0, l = arguments.length; i < l; i++) {\n    unshift(this, arguments[i])\n  }\n  return this.length\n}\n\nYallist.prototype.pop = function () {\n  if (!this.tail) {\n    return undefined\n  }\n\n  var res = this.tail.value\n  this.tail = this.tail.prev\n  if (this.tail) {\n    this.tail.next = null\n  } else {\n    this.head = null\n  }\n  this.length--\n  return res\n}\n\nYallist.prototype.shift = function () {\n  if (!this.head) {\n    return undefined\n  }\n\n  var res = this.head.value\n  this.head = this.head.next\n  if (this.head) {\n    this.head.prev = null\n  } else {\n    this.tail = null\n  }\n  this.length--\n  return res\n}\n\nYallist.prototype.forEach = function (fn, thisp) {\n  thisp = thisp || this\n  for (var walker = this.head, i = 0; walker !== null; i++) {\n    fn.call(thisp, walker.value, i, this)\n    walker = walker.next\n  }\n}\n\nYallist.prototype.forEachReverse = function (fn, thisp) {\n  thisp = thisp || this\n  for (var walker = this.tail, i = this.length - 1; walker !== null; i--) {\n    fn.call(thisp, walker.value, i, this)\n    walker = walker.prev\n  }\n}\n\nYallist.prototype.get = function (n) {\n  for (var i = 0, walker = this.head; walker !== null && i < n; i++) {\n    // abort out of the list early if we hit a cycle\n    walker = walker.next\n  }\n  if (i === n && walker !== null) {\n    return walker.value\n  }\n}\n\nYallist.prototype.getReverse = function (n) {\n  for (var i = 0, walker = this.tail; walker !== null && i < n; i++) {\n    // abort out of the list early if we hit a cycle\n    walker = walker.prev\n  }\n  if (i === n && walker !== null) {\n    return walker.value\n  }\n}\n\nYallist.prototype.map = function (fn, thisp) {\n  thisp = thisp || this\n  var res = new Yallist()\n  for (var walker = this.head; walker !== null;) {\n    res.push(fn.call(thisp, walker.value, this))\n    walker = walker.next\n  }\n  return res\n}\n\nYallist.prototype.mapReverse = function (fn, thisp) {\n  thisp = thisp || this\n  var res = new Yallist()\n  for (var walker = this.tail; walker !== null;) {\n    res.push(fn.call(thisp, walker.value, this))\n    walker = walker.prev\n  }\n  return res\n}\n\nYallist.prototype.reduce = function (fn, initial) {\n  var acc\n  var walker = this.head\n  if (arguments.length > 1) {\n    acc = initial\n  } else if (this.head) {\n    walker = this.head.next\n    acc = this.head.value\n  } else {\n    throw new TypeError('Reduce of empty list with no initial value')\n  }\n\n  for (var i = 0; walker !== null; i++) {\n    acc = fn(acc, walker.value, i)\n    walker = walker.next\n  }\n\n  return acc\n}\n\nYallist.prototype.reduceReverse = function (fn, initial) {\n  var acc\n  var walker = this.tail\n  if (arguments.length > 1) {\n    acc = initial\n  } else if (this.tail) {\n    walker = this.tail.prev\n    acc = this.tail.value\n  } else {\n    throw new TypeError('Reduce of empty list with no initial value')\n  }\n\n  for (var i = this.length - 1; walker !== null; i--) {\n    acc = fn(acc, walker.value, i)\n    walker = walker.prev\n  }\n\n  return acc\n}\n\nYallist.prototype.toArray = function () {\n  var arr = new Array(this.length)\n  for (var i = 0, walker = this.head; walker !== null; i++) {\n    arr[i] = walker.value\n    walker = walker.next\n  }\n  return arr\n}\n\nYallist.prototype.toArrayReverse = function () {\n  var arr = new Array(this.length)\n  for (var i = 0, walker = this.tail; walker !== null; i++) {\n    arr[i] = walker.value\n    walker = walker.prev\n  }\n  return arr\n}\n\nYallist.prototype.slice = function (from, to) {\n  to = to || this.length\n  if (to < 0) {\n    to += this.length\n  }\n  from = from || 0\n  if (from < 0) {\n    from += this.length\n  }\n  var ret = new Yallist()\n  if (to < from || to < 0) {\n    return ret\n  }\n  if (from < 0) {\n    from = 0\n  }\n  if (to > this.length) {\n    to = this.length\n  }\n  for (var i = 0, walker = this.head; walker !== null && i < from; i++) {\n    walker = walker.next\n  }\n  for (; walker !== null && i < to; i++, walker = walker.next) {\n    ret.push(walker.value)\n  }\n  return ret\n}\n\nYallist.prototype.sliceReverse = function (from, to) {\n  to = to || this.length\n  if (to < 0) {\n    to += this.length\n  }\n  from = from || 0\n  if (from < 0) {\n    from += this.length\n  }\n  var ret = new Yallist()\n  if (to < from || to < 0) {\n    return ret\n  }\n  if (from < 0) {\n    from = 0\n  }\n  if (to > this.length) {\n    to = this.length\n  }\n  for (var i = this.length, walker = this.tail; walker !== null && i > to; i--) {\n    walker = walker.prev\n  }\n  for (; walker !== null && i > from; i--, walker = walker.prev) {\n    ret.push(walker.value)\n  }\n  return ret\n}\n\nYallist.prototype.splice = function (start, deleteCount, ...nodes) {\n  if (start > this.length) {\n    start = this.length - 1\n  }\n  if (start < 0) {\n    start = this.length + start;\n  }\n\n  for (var i = 0, walker = this.head; walker !== null && i < start; i++) {\n    walker = walker.next\n  }\n\n  var ret = []\n  for (var i = 0; walker && i < deleteCount; i++) {\n    ret.push(walker.value)\n    walker = this.removeNode(walker)\n  }\n  if (walker === null) {\n    walker = this.tail\n  }\n\n  if (walker !== this.head && walker !== this.tail) {\n    walker = walker.prev\n  }\n\n  for (var i = 0; i < nodes.length; i++) {\n    walker = insert(this, walker, nodes[i])\n  }\n  return ret;\n}\n\nYallist.prototype.reverse = function () {\n  var head = this.head\n  var tail = this.tail\n  for (var walker = head; walker !== null; walker = walker.prev) {\n    var p = walker.prev\n    walker.prev = walker.next\n    walker.next = p\n  }\n  this.head = tail\n  this.tail = head\n  return this\n}\n\nfunction insert (self, node, value) {\n  var inserted = node === self.head ?\n    new Node(value, null, node, self) :\n    new Node(value, node, node.next, self)\n\n  if (inserted.next === null) {\n    self.tail = inserted\n  }\n  if (inserted.prev === null) {\n    self.head = inserted\n  }\n\n  self.length++\n\n  return inserted\n}\n\nfunction push (self, item) {\n  self.tail = new Node(item, self.tail, null, self)\n  if (!self.head) {\n    self.head = self.tail\n  }\n  self.length++\n}\n\nfunction unshift (self, item) {\n  self.head = new Node(item, null, self.head, self)\n  if (!self.tail) {\n    self.tail = self.head\n  }\n  self.length++\n}\n\nfunction Node (value, prev, next, list) {\n  if (!(this instanceof Node)) {\n    return new Node(value, prev, next, list)\n  }\n\n  this.list = list\n  this.value = value\n\n  if (prev) {\n    prev.next = this\n    this.prev = prev\n  } else {\n    this.prev = null\n  }\n\n  if (next) {\n    next.prev = this\n    this.next = next\n  } else {\n    this.next = null\n  }\n}\n\ntry {\n  // add if support for Symbol.iterator is present\n  __webpack_require__(/*! ./iterator.js */ \"./node_modules/semver/node_modules/yallist/iterator.js\")(Yallist)\n} catch (er) {}\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/node_modules/yallist/yallist.js?");

/***/ }),

/***/ "./node_modules/semver/ranges/gtr.js":
/*!*******************************************!*\
  !*** ./node_modules/semver/ranges/gtr.js ***!
  \*******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("// Determine if version is greater than all the versions possible in the range.\nconst outside = __webpack_require__(/*! ./outside */ \"./node_modules/semver/ranges/outside.js\")\nconst gtr = (version, range, options) => outside(version, range, '>', options)\nmodule.exports = gtr\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/ranges/gtr.js?");

/***/ }),

/***/ "./node_modules/semver/ranges/intersects.js":
/*!**************************************************!*\
  !*** ./node_modules/semver/ranges/intersects.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const Range = __webpack_require__(/*! ../classes/range */ \"./node_modules/semver/classes/range.js\")\nconst intersects = (r1, r2, options) => {\n  r1 = new Range(r1, options)\n  r2 = new Range(r2, options)\n  return r1.intersects(r2, options)\n}\nmodule.exports = intersects\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/ranges/intersects.js?");

/***/ }),

/***/ "./node_modules/semver/ranges/ltr.js":
/*!*******************************************!*\
  !*** ./node_modules/semver/ranges/ltr.js ***!
  \*******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const outside = __webpack_require__(/*! ./outside */ \"./node_modules/semver/ranges/outside.js\")\n// Determine if version is less than all the versions possible in the range\nconst ltr = (version, range, options) => outside(version, range, '<', options)\nmodule.exports = ltr\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/ranges/ltr.js?");

/***/ }),

/***/ "./node_modules/semver/ranges/max-satisfying.js":
/*!******************************************************!*\
  !*** ./node_modules/semver/ranges/max-satisfying.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SemVer = __webpack_require__(/*! ../classes/semver */ \"./node_modules/semver/classes/semver.js\")\nconst Range = __webpack_require__(/*! ../classes/range */ \"./node_modules/semver/classes/range.js\")\n\nconst maxSatisfying = (versions, range, options) => {\n  let max = null\n  let maxSV = null\n  let rangeObj = null\n  try {\n    rangeObj = new Range(range, options)\n  } catch (er) {\n    return null\n  }\n  versions.forEach((v) => {\n    if (rangeObj.test(v)) {\n      // satisfies(v, range, options)\n      if (!max || maxSV.compare(v) === -1) {\n        // compare(max, v, true)\n        max = v\n        maxSV = new SemVer(max, options)\n      }\n    }\n  })\n  return max\n}\nmodule.exports = maxSatisfying\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/ranges/max-satisfying.js?");

/***/ }),

/***/ "./node_modules/semver/ranges/min-satisfying.js":
/*!******************************************************!*\
  !*** ./node_modules/semver/ranges/min-satisfying.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SemVer = __webpack_require__(/*! ../classes/semver */ \"./node_modules/semver/classes/semver.js\")\nconst Range = __webpack_require__(/*! ../classes/range */ \"./node_modules/semver/classes/range.js\")\nconst minSatisfying = (versions, range, options) => {\n  let min = null\n  let minSV = null\n  let rangeObj = null\n  try {\n    rangeObj = new Range(range, options)\n  } catch (er) {\n    return null\n  }\n  versions.forEach((v) => {\n    if (rangeObj.test(v)) {\n      // satisfies(v, range, options)\n      if (!min || minSV.compare(v) === 1) {\n        // compare(min, v, true)\n        min = v\n        minSV = new SemVer(min, options)\n      }\n    }\n  })\n  return min\n}\nmodule.exports = minSatisfying\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/ranges/min-satisfying.js?");

/***/ }),

/***/ "./node_modules/semver/ranges/min-version.js":
/*!***************************************************!*\
  !*** ./node_modules/semver/ranges/min-version.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SemVer = __webpack_require__(/*! ../classes/semver */ \"./node_modules/semver/classes/semver.js\")\nconst Range = __webpack_require__(/*! ../classes/range */ \"./node_modules/semver/classes/range.js\")\nconst gt = __webpack_require__(/*! ../functions/gt */ \"./node_modules/semver/functions/gt.js\")\n\nconst minVersion = (range, loose) => {\n  range = new Range(range, loose)\n\n  let minver = new SemVer('0.0.0')\n  if (range.test(minver)) {\n    return minver\n  }\n\n  minver = new SemVer('0.0.0-0')\n  if (range.test(minver)) {\n    return minver\n  }\n\n  minver = null\n  for (let i = 0; i < range.set.length; ++i) {\n    const comparators = range.set[i]\n\n    let setMin = null\n    comparators.forEach((comparator) => {\n      // Clone to avoid manipulating the comparator's semver object.\n      const compver = new SemVer(comparator.semver.version)\n      switch (comparator.operator) {\n        case '>':\n          if (compver.prerelease.length === 0) {\n            compver.patch++\n          } else {\n            compver.prerelease.push(0)\n          }\n          compver.raw = compver.format()\n          /* fallthrough */\n        case '':\n        case '>=':\n          if (!setMin || gt(compver, setMin)) {\n            setMin = compver\n          }\n          break\n        case '<':\n        case '<=':\n          /* Ignore maximum versions */\n          break\n        /* istanbul ignore next */\n        default:\n          throw new Error(`Unexpected operation: ${comparator.operator}`)\n      }\n    })\n    if (setMin && (!minver || gt(minver, setMin))) {\n      minver = setMin\n    }\n  }\n\n  if (minver && range.test(minver)) {\n    return minver\n  }\n\n  return null\n}\nmodule.exports = minVersion\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/ranges/min-version.js?");

/***/ }),

/***/ "./node_modules/semver/ranges/outside.js":
/*!***********************************************!*\
  !*** ./node_modules/semver/ranges/outside.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SemVer = __webpack_require__(/*! ../classes/semver */ \"./node_modules/semver/classes/semver.js\")\nconst Comparator = __webpack_require__(/*! ../classes/comparator */ \"./node_modules/semver/classes/comparator.js\")\nconst { ANY } = Comparator\nconst Range = __webpack_require__(/*! ../classes/range */ \"./node_modules/semver/classes/range.js\")\nconst satisfies = __webpack_require__(/*! ../functions/satisfies */ \"./node_modules/semver/functions/satisfies.js\")\nconst gt = __webpack_require__(/*! ../functions/gt */ \"./node_modules/semver/functions/gt.js\")\nconst lt = __webpack_require__(/*! ../functions/lt */ \"./node_modules/semver/functions/lt.js\")\nconst lte = __webpack_require__(/*! ../functions/lte */ \"./node_modules/semver/functions/lte.js\")\nconst gte = __webpack_require__(/*! ../functions/gte */ \"./node_modules/semver/functions/gte.js\")\n\nconst outside = (version, range, hilo, options) => {\n  version = new SemVer(version, options)\n  range = new Range(range, options)\n\n  let gtfn, ltefn, ltfn, comp, ecomp\n  switch (hilo) {\n    case '>':\n      gtfn = gt\n      ltefn = lte\n      ltfn = lt\n      comp = '>'\n      ecomp = '>='\n      break\n    case '<':\n      gtfn = lt\n      ltefn = gte\n      ltfn = gt\n      comp = '<'\n      ecomp = '<='\n      break\n    default:\n      throw new TypeError('Must provide a hilo val of \"<\" or \">\"')\n  }\n\n  // If it satisfies the range it is not outside\n  if (satisfies(version, range, options)) {\n    return false\n  }\n\n  // From now on, variable terms are as if we're in \"gtr\" mode.\n  // but note that everything is flipped for the \"ltr\" function.\n\n  for (let i = 0; i < range.set.length; ++i) {\n    const comparators = range.set[i]\n\n    let high = null\n    let low = null\n\n    comparators.forEach((comparator) => {\n      if (comparator.semver === ANY) {\n        comparator = new Comparator('>=0.0.0')\n      }\n      high = high || comparator\n      low = low || comparator\n      if (gtfn(comparator.semver, high.semver, options)) {\n        high = comparator\n      } else if (ltfn(comparator.semver, low.semver, options)) {\n        low = comparator\n      }\n    })\n\n    // If the edge version comparator has a operator then our version\n    // isn't outside it\n    if (high.operator === comp || high.operator === ecomp) {\n      return false\n    }\n\n    // If the lowest version comparator has an operator and our version\n    // is less than it then it isn't higher than the range\n    if ((!low.operator || low.operator === comp) &&\n        ltefn(version, low.semver)) {\n      return false\n    } else if (low.operator === ecomp && ltfn(version, low.semver)) {\n      return false\n    }\n  }\n  return true\n}\n\nmodule.exports = outside\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/ranges/outside.js?");

/***/ }),

/***/ "./node_modules/semver/ranges/simplify.js":
/*!************************************************!*\
  !*** ./node_modules/semver/ranges/simplify.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("// given a set of versions and a range, create a \"simplified\" range\n// that includes the same versions that the original range does\n// If the original range is shorter than the simplified one, return that.\nconst satisfies = __webpack_require__(/*! ../functions/satisfies.js */ \"./node_modules/semver/functions/satisfies.js\")\nconst compare = __webpack_require__(/*! ../functions/compare.js */ \"./node_modules/semver/functions/compare.js\")\nmodule.exports = (versions, range, options) => {\n  const set = []\n  let first = null\n  let prev = null\n  const v = versions.sort((a, b) => compare(a, b, options))\n  for (const version of v) {\n    const included = satisfies(version, range, options)\n    if (included) {\n      prev = version\n      if (!first) {\n        first = version\n      }\n    } else {\n      if (prev) {\n        set.push([first, prev])\n      }\n      prev = null\n      first = null\n    }\n  }\n  if (first) {\n    set.push([first, null])\n  }\n\n  const ranges = []\n  for (const [min, max] of set) {\n    if (min === max) {\n      ranges.push(min)\n    } else if (!max && min === v[0]) {\n      ranges.push('*')\n    } else if (!max) {\n      ranges.push(`>=${min}`)\n    } else if (min === v[0]) {\n      ranges.push(`<=${max}`)\n    } else {\n      ranges.push(`${min} - ${max}`)\n    }\n  }\n  const simplified = ranges.join(' || ')\n  const original = typeof range.raw === 'string' ? range.raw : String(range)\n  return simplified.length < original.length ? simplified : range\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/ranges/simplify.js?");

/***/ }),

/***/ "./node_modules/semver/ranges/subset.js":
/*!**********************************************!*\
  !*** ./node_modules/semver/ranges/subset.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const Range = __webpack_require__(/*! ../classes/range.js */ \"./node_modules/semver/classes/range.js\")\nconst Comparator = __webpack_require__(/*! ../classes/comparator.js */ \"./node_modules/semver/classes/comparator.js\")\nconst { ANY } = Comparator\nconst satisfies = __webpack_require__(/*! ../functions/satisfies.js */ \"./node_modules/semver/functions/satisfies.js\")\nconst compare = __webpack_require__(/*! ../functions/compare.js */ \"./node_modules/semver/functions/compare.js\")\n\n// Complex range `r1 || r2 || ...` is a subset of `R1 || R2 || ...` iff:\n// - Every simple range `r1, r2, ...` is a null set, OR\n// - Every simple range `r1, r2, ...` which is not a null set is a subset of\n//   some `R1, R2, ...`\n//\n// Simple range `c1 c2 ...` is a subset of simple range `C1 C2 ...` iff:\n// - If c is only the ANY comparator\n//   - If C is only the ANY comparator, return true\n//   - Else if in prerelease mode, return false\n//   - else replace c with `[>=0.0.0]`\n// - If C is only the ANY comparator\n//   - if in prerelease mode, return true\n//   - else replace C with `[>=0.0.0]`\n// - Let EQ be the set of = comparators in c\n// - If EQ is more than one, return true (null set)\n// - Let GT be the highest > or >= comparator in c\n// - Let LT be the lowest < or <= comparator in c\n// - If GT and LT, and GT.semver > LT.semver, return true (null set)\n// - If any C is a = range, and GT or LT are set, return false\n// - If EQ\n//   - If GT, and EQ does not satisfy GT, return true (null set)\n//   - If LT, and EQ does not satisfy LT, return true (null set)\n//   - If EQ satisfies every C, return true\n//   - Else return false\n// - If GT\n//   - If GT.semver is lower than any > or >= comp in C, return false\n//   - If GT is >=, and GT.semver does not satisfy every C, return false\n//   - If GT.semver has a prerelease, and not in prerelease mode\n//     - If no C has a prerelease and the GT.semver tuple, return false\n// - If LT\n//   - If LT.semver is greater than any < or <= comp in C, return false\n//   - If LT is <=, and LT.semver does not satisfy every C, return false\n//   - If GT.semver has a prerelease, and not in prerelease mode\n//     - If no C has a prerelease and the LT.semver tuple, return false\n// - Else return true\n\nconst subset = (sub, dom, options = {}) => {\n  if (sub === dom) {\n    return true\n  }\n\n  sub = new Range(sub, options)\n  dom = new Range(dom, options)\n  let sawNonNull = false\n\n  OUTER: for (const simpleSub of sub.set) {\n    for (const simpleDom of dom.set) {\n      const isSub = simpleSubset(simpleSub, simpleDom, options)\n      sawNonNull = sawNonNull || isSub !== null\n      if (isSub) {\n        continue OUTER\n      }\n    }\n    // the null set is a subset of everything, but null simple ranges in\n    // a complex range should be ignored.  so if we saw a non-null range,\n    // then we know this isn't a subset, but if EVERY simple range was null,\n    // then it is a subset.\n    if (sawNonNull) {\n      return false\n    }\n  }\n  return true\n}\n\nconst minimumVersionWithPreRelease = [new Comparator('>=0.0.0-0')]\nconst minimumVersion = [new Comparator('>=0.0.0')]\n\nconst simpleSubset = (sub, dom, options) => {\n  if (sub === dom) {\n    return true\n  }\n\n  if (sub.length === 1 && sub[0].semver === ANY) {\n    if (dom.length === 1 && dom[0].semver === ANY) {\n      return true\n    } else if (options.includePrerelease) {\n      sub = minimumVersionWithPreRelease\n    } else {\n      sub = minimumVersion\n    }\n  }\n\n  if (dom.length === 1 && dom[0].semver === ANY) {\n    if (options.includePrerelease) {\n      return true\n    } else {\n      dom = minimumVersion\n    }\n  }\n\n  const eqSet = new Set()\n  let gt, lt\n  for (const c of sub) {\n    if (c.operator === '>' || c.operator === '>=') {\n      gt = higherGT(gt, c, options)\n    } else if (c.operator === '<' || c.operator === '<=') {\n      lt = lowerLT(lt, c, options)\n    } else {\n      eqSet.add(c.semver)\n    }\n  }\n\n  if (eqSet.size > 1) {\n    return null\n  }\n\n  let gtltComp\n  if (gt && lt) {\n    gtltComp = compare(gt.semver, lt.semver, options)\n    if (gtltComp > 0) {\n      return null\n    } else if (gtltComp === 0 && (gt.operator !== '>=' || lt.operator !== '<=')) {\n      return null\n    }\n  }\n\n  // will iterate one or zero times\n  for (const eq of eqSet) {\n    if (gt && !satisfies(eq, String(gt), options)) {\n      return null\n    }\n\n    if (lt && !satisfies(eq, String(lt), options)) {\n      return null\n    }\n\n    for (const c of dom) {\n      if (!satisfies(eq, String(c), options)) {\n        return false\n      }\n    }\n\n    return true\n  }\n\n  let higher, lower\n  let hasDomLT, hasDomGT\n  // if the subset has a prerelease, we need a comparator in the superset\n  // with the same tuple and a prerelease, or it's not a subset\n  let needDomLTPre = lt &&\n    !options.includePrerelease &&\n    lt.semver.prerelease.length ? lt.semver : false\n  let needDomGTPre = gt &&\n    !options.includePrerelease &&\n    gt.semver.prerelease.length ? gt.semver : false\n  // exception: <1.2.3-0 is the same as <1.2.3\n  if (needDomLTPre && needDomLTPre.prerelease.length === 1 &&\n      lt.operator === '<' && needDomLTPre.prerelease[0] === 0) {\n    needDomLTPre = false\n  }\n\n  for (const c of dom) {\n    hasDomGT = hasDomGT || c.operator === '>' || c.operator === '>='\n    hasDomLT = hasDomLT || c.operator === '<' || c.operator === '<='\n    if (gt) {\n      if (needDomGTPre) {\n        if (c.semver.prerelease && c.semver.prerelease.length &&\n            c.semver.major === needDomGTPre.major &&\n            c.semver.minor === needDomGTPre.minor &&\n            c.semver.patch === needDomGTPre.patch) {\n          needDomGTPre = false\n        }\n      }\n      if (c.operator === '>' || c.operator === '>=') {\n        higher = higherGT(gt, c, options)\n        if (higher === c && higher !== gt) {\n          return false\n        }\n      } else if (gt.operator === '>=' && !satisfies(gt.semver, String(c), options)) {\n        return false\n      }\n    }\n    if (lt) {\n      if (needDomLTPre) {\n        if (c.semver.prerelease && c.semver.prerelease.length &&\n            c.semver.major === needDomLTPre.major &&\n            c.semver.minor === needDomLTPre.minor &&\n            c.semver.patch === needDomLTPre.patch) {\n          needDomLTPre = false\n        }\n      }\n      if (c.operator === '<' || c.operator === '<=') {\n        lower = lowerLT(lt, c, options)\n        if (lower === c && lower !== lt) {\n          return false\n        }\n      } else if (lt.operator === '<=' && !satisfies(lt.semver, String(c), options)) {\n        return false\n      }\n    }\n    if (!c.operator && (lt || gt) && gtltComp !== 0) {\n      return false\n    }\n  }\n\n  // if there was a < or >, and nothing in the dom, then must be false\n  // UNLESS it was limited by another range in the other direction.\n  // Eg, >1.0.0 <1.0.1 is still a subset of <2.0.0\n  if (gt && hasDomLT && !lt && gtltComp !== 0) {\n    return false\n  }\n\n  if (lt && hasDomGT && !gt && gtltComp !== 0) {\n    return false\n  }\n\n  // we needed a prerelease range in a specific tuple, but didn't get one\n  // then this isn't a subset.  eg >=1.2.3-pre is not a subset of >=1.0.0,\n  // because it includes prereleases in the 1.2.3 tuple\n  if (needDomGTPre || needDomLTPre) {\n    return false\n  }\n\n  return true\n}\n\n// >=1.2.3 is lower than >1.2.3\nconst higherGT = (a, b, options) => {\n  if (!a) {\n    return b\n  }\n  const comp = compare(a.semver, b.semver, options)\n  return comp > 0 ? a\n    : comp < 0 ? b\n    : b.operator === '>' && a.operator === '>=' ? b\n    : a\n}\n\n// <=1.2.3 is higher than <1.2.3\nconst lowerLT = (a, b, options) => {\n  if (!a) {\n    return b\n  }\n  const comp = compare(a.semver, b.semver, options)\n  return comp < 0 ? a\n    : comp > 0 ? b\n    : b.operator === '<' && a.operator === '<=' ? b\n    : a\n}\n\nmodule.exports = subset\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/ranges/subset.js?");

/***/ }),

/***/ "./node_modules/semver/ranges/to-comparators.js":
/*!******************************************************!*\
  !*** ./node_modules/semver/ranges/to-comparators.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const Range = __webpack_require__(/*! ../classes/range */ \"./node_modules/semver/classes/range.js\")\n\n// Mostly just for testing and legacy API reasons\nconst toComparators = (range, options) =>\n  new Range(range, options).set\n    .map(comp => comp.map(c => c.value).join(' ').trim().split(' '))\n\nmodule.exports = toComparators\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/ranges/to-comparators.js?");

/***/ }),

/***/ "./node_modules/semver/ranges/valid.js":
/*!*********************************************!*\
  !*** ./node_modules/semver/ranges/valid.js ***!
  \*********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const Range = __webpack_require__(/*! ../classes/range */ \"./node_modules/semver/classes/range.js\")\nconst validRange = (range, options) => {\n  try {\n    // Return '*' instead of '' so that truthiness works.\n    // This will throw if it's invalid anyway\n    return new Range(range, options).range || '*'\n  } catch (er) {\n    return null\n  }\n}\nmodule.exports = validRange\n\n\n//# sourceURL=webpack://renderer/./node_modules/semver/ranges/valid.js?");

/***/ }),

/***/ "./node_modules/smart-buffer/build/smartbuffer.js":
/*!********************************************************!*\
  !*** ./node_modules/smart-buffer/build/smartbuffer.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/smart-buffer/build/utils.js\");\n// The default Buffer size if one is not provided.\nconst DEFAULT_SMARTBUFFER_SIZE = 4096;\n// The default string encoding to use for reading/writing strings.\nconst DEFAULT_SMARTBUFFER_ENCODING = 'utf8';\nclass SmartBuffer {\n    /**\n     * Creates a new SmartBuffer instance.\n     *\n     * @param options { SmartBufferOptions } The SmartBufferOptions to apply to this instance.\n     */\n    constructor(options) {\n        this.length = 0;\n        this._encoding = DEFAULT_SMARTBUFFER_ENCODING;\n        this._writeOffset = 0;\n        this._readOffset = 0;\n        if (SmartBuffer.isSmartBufferOptions(options)) {\n            // Checks for encoding\n            if (options.encoding) {\n                utils_1.checkEncoding(options.encoding);\n                this._encoding = options.encoding;\n            }\n            // Checks for initial size length\n            if (options.size) {\n                if (utils_1.isFiniteInteger(options.size) && options.size > 0) {\n                    this._buff = Buffer.allocUnsafe(options.size);\n                }\n                else {\n                    throw new Error(utils_1.ERRORS.INVALID_SMARTBUFFER_SIZE);\n                }\n                // Check for initial Buffer\n            }\n            else if (options.buff) {\n                if (Buffer.isBuffer(options.buff)) {\n                    this._buff = options.buff;\n                    this.length = options.buff.length;\n                }\n                else {\n                    throw new Error(utils_1.ERRORS.INVALID_SMARTBUFFER_BUFFER);\n                }\n            }\n            else {\n                this._buff = Buffer.allocUnsafe(DEFAULT_SMARTBUFFER_SIZE);\n            }\n        }\n        else {\n            // If something was passed but it's not a SmartBufferOptions object\n            if (typeof options !== 'undefined') {\n                throw new Error(utils_1.ERRORS.INVALID_SMARTBUFFER_OBJECT);\n            }\n            // Otherwise default to sane options\n            this._buff = Buffer.allocUnsafe(DEFAULT_SMARTBUFFER_SIZE);\n        }\n    }\n    /**\n     * Creates a new SmartBuffer instance with the provided internal Buffer size and optional encoding.\n     *\n     * @param size { Number } The size of the internal Buffer.\n     * @param encoding { String } The BufferEncoding to use for strings.\n     *\n     * @return { SmartBuffer }\n     */\n    static fromSize(size, encoding) {\n        return new this({\n            size: size,\n            encoding: encoding\n        });\n    }\n    /**\n     * Creates a new SmartBuffer instance with the provided Buffer and optional encoding.\n     *\n     * @param buffer { Buffer } The Buffer to use as the internal Buffer value.\n     * @param encoding { String } The BufferEncoding to use for strings.\n     *\n     * @return { SmartBuffer }\n     */\n    static fromBuffer(buff, encoding) {\n        return new this({\n            buff: buff,\n            encoding: encoding\n        });\n    }\n    /**\n     * Creates a new SmartBuffer instance with the provided SmartBufferOptions options.\n     *\n     * @param options { SmartBufferOptions } The options to use when creating the SmartBuffer instance.\n     */\n    static fromOptions(options) {\n        return new this(options);\n    }\n    /**\n     * Type checking function that determines if an object is a SmartBufferOptions object.\n     */\n    static isSmartBufferOptions(options) {\n        const castOptions = options;\n        return (castOptions &&\n            (castOptions.encoding !== undefined || castOptions.size !== undefined || castOptions.buff !== undefined));\n    }\n    // Signed integers\n    /**\n     * Reads an Int8 value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readInt8(offset) {\n        return this._readNumberValue(Buffer.prototype.readInt8, 1, offset);\n    }\n    /**\n     * Reads an Int16BE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readInt16BE(offset) {\n        return this._readNumberValue(Buffer.prototype.readInt16BE, 2, offset);\n    }\n    /**\n     * Reads an Int16LE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readInt16LE(offset) {\n        return this._readNumberValue(Buffer.prototype.readInt16LE, 2, offset);\n    }\n    /**\n     * Reads an Int32BE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readInt32BE(offset) {\n        return this._readNumberValue(Buffer.prototype.readInt32BE, 4, offset);\n    }\n    /**\n     * Reads an Int32LE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readInt32LE(offset) {\n        return this._readNumberValue(Buffer.prototype.readInt32LE, 4, offset);\n    }\n    /**\n     * Reads a BigInt64BE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { BigInt }\n     */\n    readBigInt64BE(offset) {\n        utils_1.bigIntAndBufferInt64Check('readBigInt64BE');\n        return this._readNumberValue(Buffer.prototype.readBigInt64BE, 8, offset);\n    }\n    /**\n     * Reads a BigInt64LE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { BigInt }\n     */\n    readBigInt64LE(offset) {\n        utils_1.bigIntAndBufferInt64Check('readBigInt64LE');\n        return this._readNumberValue(Buffer.prototype.readBigInt64LE, 8, offset);\n    }\n    /**\n     * Writes an Int8 value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeInt8(value, offset) {\n        this._writeNumberValue(Buffer.prototype.writeInt8, 1, value, offset);\n        return this;\n    }\n    /**\n     * Inserts an Int8 value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertInt8(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeInt8, 1, value, offset);\n    }\n    /**\n     * Writes an Int16BE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeInt16BE(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeInt16BE, 2, value, offset);\n    }\n    /**\n     * Inserts an Int16BE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertInt16BE(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeInt16BE, 2, value, offset);\n    }\n    /**\n     * Writes an Int16LE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeInt16LE(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeInt16LE, 2, value, offset);\n    }\n    /**\n     * Inserts an Int16LE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertInt16LE(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeInt16LE, 2, value, offset);\n    }\n    /**\n     * Writes an Int32BE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeInt32BE(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeInt32BE, 4, value, offset);\n    }\n    /**\n     * Inserts an Int32BE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertInt32BE(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeInt32BE, 4, value, offset);\n    }\n    /**\n     * Writes an Int32LE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeInt32LE(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeInt32LE, 4, value, offset);\n    }\n    /**\n     * Inserts an Int32LE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertInt32LE(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeInt32LE, 4, value, offset);\n    }\n    /**\n     * Writes a BigInt64BE value to the current write position (or at optional offset).\n     *\n     * @param value { BigInt } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeBigInt64BE(value, offset) {\n        utils_1.bigIntAndBufferInt64Check('writeBigInt64BE');\n        return this._writeNumberValue(Buffer.prototype.writeBigInt64BE, 8, value, offset);\n    }\n    /**\n     * Inserts a BigInt64BE value at the given offset value.\n     *\n     * @param value { BigInt } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertBigInt64BE(value, offset) {\n        utils_1.bigIntAndBufferInt64Check('writeBigInt64BE');\n        return this._insertNumberValue(Buffer.prototype.writeBigInt64BE, 8, value, offset);\n    }\n    /**\n     * Writes a BigInt64LE value to the current write position (or at optional offset).\n     *\n     * @param value { BigInt } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeBigInt64LE(value, offset) {\n        utils_1.bigIntAndBufferInt64Check('writeBigInt64LE');\n        return this._writeNumberValue(Buffer.prototype.writeBigInt64LE, 8, value, offset);\n    }\n    /**\n     * Inserts a Int64LE value at the given offset value.\n     *\n     * @param value { BigInt } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertBigInt64LE(value, offset) {\n        utils_1.bigIntAndBufferInt64Check('writeBigInt64LE');\n        return this._insertNumberValue(Buffer.prototype.writeBigInt64LE, 8, value, offset);\n    }\n    // Unsigned Integers\n    /**\n     * Reads an UInt8 value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readUInt8(offset) {\n        return this._readNumberValue(Buffer.prototype.readUInt8, 1, offset);\n    }\n    /**\n     * Reads an UInt16BE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readUInt16BE(offset) {\n        return this._readNumberValue(Buffer.prototype.readUInt16BE, 2, offset);\n    }\n    /**\n     * Reads an UInt16LE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readUInt16LE(offset) {\n        return this._readNumberValue(Buffer.prototype.readUInt16LE, 2, offset);\n    }\n    /**\n     * Reads an UInt32BE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readUInt32BE(offset) {\n        return this._readNumberValue(Buffer.prototype.readUInt32BE, 4, offset);\n    }\n    /**\n     * Reads an UInt32LE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readUInt32LE(offset) {\n        return this._readNumberValue(Buffer.prototype.readUInt32LE, 4, offset);\n    }\n    /**\n     * Reads a BigUInt64BE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { BigInt }\n     */\n    readBigUInt64BE(offset) {\n        utils_1.bigIntAndBufferInt64Check('readBigUInt64BE');\n        return this._readNumberValue(Buffer.prototype.readBigUInt64BE, 8, offset);\n    }\n    /**\n     * Reads a BigUInt64LE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { BigInt }\n     */\n    readBigUInt64LE(offset) {\n        utils_1.bigIntAndBufferInt64Check('readBigUInt64LE');\n        return this._readNumberValue(Buffer.prototype.readBigUInt64LE, 8, offset);\n    }\n    /**\n     * Writes an UInt8 value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeUInt8(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeUInt8, 1, value, offset);\n    }\n    /**\n     * Inserts an UInt8 value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertUInt8(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeUInt8, 1, value, offset);\n    }\n    /**\n     * Writes an UInt16BE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeUInt16BE(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeUInt16BE, 2, value, offset);\n    }\n    /**\n     * Inserts an UInt16BE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertUInt16BE(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeUInt16BE, 2, value, offset);\n    }\n    /**\n     * Writes an UInt16LE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeUInt16LE(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeUInt16LE, 2, value, offset);\n    }\n    /**\n     * Inserts an UInt16LE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertUInt16LE(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeUInt16LE, 2, value, offset);\n    }\n    /**\n     * Writes an UInt32BE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeUInt32BE(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeUInt32BE, 4, value, offset);\n    }\n    /**\n     * Inserts an UInt32BE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertUInt32BE(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeUInt32BE, 4, value, offset);\n    }\n    /**\n     * Writes an UInt32LE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeUInt32LE(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeUInt32LE, 4, value, offset);\n    }\n    /**\n     * Inserts an UInt32LE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertUInt32LE(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeUInt32LE, 4, value, offset);\n    }\n    /**\n     * Writes a BigUInt64BE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeBigUInt64BE(value, offset) {\n        utils_1.bigIntAndBufferInt64Check('writeBigUInt64BE');\n        return this._writeNumberValue(Buffer.prototype.writeBigUInt64BE, 8, value, offset);\n    }\n    /**\n     * Inserts a BigUInt64BE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertBigUInt64BE(value, offset) {\n        utils_1.bigIntAndBufferInt64Check('writeBigUInt64BE');\n        return this._insertNumberValue(Buffer.prototype.writeBigUInt64BE, 8, value, offset);\n    }\n    /**\n     * Writes a BigUInt64LE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeBigUInt64LE(value, offset) {\n        utils_1.bigIntAndBufferInt64Check('writeBigUInt64LE');\n        return this._writeNumberValue(Buffer.prototype.writeBigUInt64LE, 8, value, offset);\n    }\n    /**\n     * Inserts a BigUInt64LE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertBigUInt64LE(value, offset) {\n        utils_1.bigIntAndBufferInt64Check('writeBigUInt64LE');\n        return this._insertNumberValue(Buffer.prototype.writeBigUInt64LE, 8, value, offset);\n    }\n    // Floating Point\n    /**\n     * Reads an FloatBE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readFloatBE(offset) {\n        return this._readNumberValue(Buffer.prototype.readFloatBE, 4, offset);\n    }\n    /**\n     * Reads an FloatLE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readFloatLE(offset) {\n        return this._readNumberValue(Buffer.prototype.readFloatLE, 4, offset);\n    }\n    /**\n     * Writes a FloatBE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeFloatBE(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeFloatBE, 4, value, offset);\n    }\n    /**\n     * Inserts a FloatBE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertFloatBE(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeFloatBE, 4, value, offset);\n    }\n    /**\n     * Writes a FloatLE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeFloatLE(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeFloatLE, 4, value, offset);\n    }\n    /**\n     * Inserts a FloatLE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertFloatLE(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeFloatLE, 4, value, offset);\n    }\n    // Double Floating Point\n    /**\n     * Reads an DoublEBE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readDoubleBE(offset) {\n        return this._readNumberValue(Buffer.prototype.readDoubleBE, 8, offset);\n    }\n    /**\n     * Reads an DoubleLE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readDoubleLE(offset) {\n        return this._readNumberValue(Buffer.prototype.readDoubleLE, 8, offset);\n    }\n    /**\n     * Writes a DoubleBE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeDoubleBE(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeDoubleBE, 8, value, offset);\n    }\n    /**\n     * Inserts a DoubleBE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertDoubleBE(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeDoubleBE, 8, value, offset);\n    }\n    /**\n     * Writes a DoubleLE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeDoubleLE(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeDoubleLE, 8, value, offset);\n    }\n    /**\n     * Inserts a DoubleLE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertDoubleLE(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeDoubleLE, 8, value, offset);\n    }\n    // Strings\n    /**\n     * Reads a String from the current read position.\n     *\n     * @param arg1 { Number | String } The number of bytes to read as a String, or the BufferEncoding to use for\n     *             the string (Defaults to instance level encoding).\n     * @param encoding { String } The BufferEncoding to use for the string (Defaults to instance level encoding).\n     *\n     * @return { String }\n     */\n    readString(arg1, encoding) {\n        let lengthVal;\n        // Length provided\n        if (typeof arg1 === 'number') {\n            utils_1.checkLengthValue(arg1);\n            lengthVal = Math.min(arg1, this.length - this._readOffset);\n        }\n        else {\n            encoding = arg1;\n            lengthVal = this.length - this._readOffset;\n        }\n        // Check encoding\n        if (typeof encoding !== 'undefined') {\n            utils_1.checkEncoding(encoding);\n        }\n        const value = this._buff.slice(this._readOffset, this._readOffset + lengthVal).toString(encoding || this._encoding);\n        this._readOffset += lengthVal;\n        return value;\n    }\n    /**\n     * Inserts a String\n     *\n     * @param value { String } The String value to insert.\n     * @param offset { Number } The offset to insert the string at.\n     * @param encoding { String } The BufferEncoding to use for writing strings (defaults to instance encoding).\n     *\n     * @return this\n     */\n    insertString(value, offset, encoding) {\n        utils_1.checkOffsetValue(offset);\n        return this._handleString(value, true, offset, encoding);\n    }\n    /**\n     * Writes a String\n     *\n     * @param value { String } The String value to write.\n     * @param arg2 { Number | String } The offset to write the string at, or the BufferEncoding to use.\n     * @param encoding { String } The BufferEncoding to use for writing strings (defaults to instance encoding).\n     *\n     * @return this\n     */\n    writeString(value, arg2, encoding) {\n        return this._handleString(value, false, arg2, encoding);\n    }\n    /**\n     * Reads a null-terminated String from the current read position.\n     *\n     * @param encoding { String } The BufferEncoding to use for the string (Defaults to instance level encoding).\n     *\n     * @return { String }\n     */\n    readStringNT(encoding) {\n        if (typeof encoding !== 'undefined') {\n            utils_1.checkEncoding(encoding);\n        }\n        // Set null character position to the end SmartBuffer instance.\n        let nullPos = this.length;\n        // Find next null character (if one is not found, default from above is used)\n        for (let i = this._readOffset; i < this.length; i++) {\n            if (this._buff[i] === 0x00) {\n                nullPos = i;\n                break;\n            }\n        }\n        // Read string value\n        const value = this._buff.slice(this._readOffset, nullPos);\n        // Increment internal Buffer read offset\n        this._readOffset = nullPos + 1;\n        return value.toString(encoding || this._encoding);\n    }\n    /**\n     * Inserts a null-terminated String.\n     *\n     * @param value { String } The String value to write.\n     * @param arg2 { Number | String } The offset to write the string to, or the BufferEncoding to use.\n     * @param encoding { String } The BufferEncoding to use for writing strings (defaults to instance encoding).\n     *\n     * @return this\n     */\n    insertStringNT(value, offset, encoding) {\n        utils_1.checkOffsetValue(offset);\n        // Write Values\n        this.insertString(value, offset, encoding);\n        this.insertUInt8(0x00, offset + value.length);\n        return this;\n    }\n    /**\n     * Writes a null-terminated String.\n     *\n     * @param value { String } The String value to write.\n     * @param arg2 { Number | String } The offset to write the string to, or the BufferEncoding to use.\n     * @param encoding { String } The BufferEncoding to use for writing strings (defaults to instance encoding).\n     *\n     * @return this\n     */\n    writeStringNT(value, arg2, encoding) {\n        // Write Values\n        this.writeString(value, arg2, encoding);\n        this.writeUInt8(0x00, typeof arg2 === 'number' ? arg2 + value.length : this.writeOffset);\n        return this;\n    }\n    // Buffers\n    /**\n     * Reads a Buffer from the internal read position.\n     *\n     * @param length { Number } The length of data to read as a Buffer.\n     *\n     * @return { Buffer }\n     */\n    readBuffer(length) {\n        if (typeof length !== 'undefined') {\n            utils_1.checkLengthValue(length);\n        }\n        const lengthVal = typeof length === 'number' ? length : this.length;\n        const endPoint = Math.min(this.length, this._readOffset + lengthVal);\n        // Read buffer value\n        const value = this._buff.slice(this._readOffset, endPoint);\n        // Increment internal Buffer read offset\n        this._readOffset = endPoint;\n        return value;\n    }\n    /**\n     * Writes a Buffer to the current write position.\n     *\n     * @param value { Buffer } The Buffer to write.\n     * @param offset { Number } The offset to write the Buffer to.\n     *\n     * @return this\n     */\n    insertBuffer(value, offset) {\n        utils_1.checkOffsetValue(offset);\n        return this._handleBuffer(value, true, offset);\n    }\n    /**\n     * Writes a Buffer to the current write position.\n     *\n     * @param value { Buffer } The Buffer to write.\n     * @param offset { Number } The offset to write the Buffer to.\n     *\n     * @return this\n     */\n    writeBuffer(value, offset) {\n        return this._handleBuffer(value, false, offset);\n    }\n    /**\n     * Reads a null-terminated Buffer from the current read poisiton.\n     *\n     * @return { Buffer }\n     */\n    readBufferNT() {\n        // Set null character position to the end SmartBuffer instance.\n        let nullPos = this.length;\n        // Find next null character (if one is not found, default from above is used)\n        for (let i = this._readOffset; i < this.length; i++) {\n            if (this._buff[i] === 0x00) {\n                nullPos = i;\n                break;\n            }\n        }\n        // Read value\n        const value = this._buff.slice(this._readOffset, nullPos);\n        // Increment internal Buffer read offset\n        this._readOffset = nullPos + 1;\n        return value;\n    }\n    /**\n     * Inserts a null-terminated Buffer.\n     *\n     * @param value { Buffer } The Buffer to write.\n     * @param offset { Number } The offset to write the Buffer to.\n     *\n     * @return this\n     */\n    insertBufferNT(value, offset) {\n        utils_1.checkOffsetValue(offset);\n        // Write Values\n        this.insertBuffer(value, offset);\n        this.insertUInt8(0x00, offset + value.length);\n        return this;\n    }\n    /**\n     * Writes a null-terminated Buffer.\n     *\n     * @param value { Buffer } The Buffer to write.\n     * @param offset { Number } The offset to write the Buffer to.\n     *\n     * @return this\n     */\n    writeBufferNT(value, offset) {\n        // Checks for valid numberic value;\n        if (typeof offset !== 'undefined') {\n            utils_1.checkOffsetValue(offset);\n        }\n        // Write Values\n        this.writeBuffer(value, offset);\n        this.writeUInt8(0x00, typeof offset === 'number' ? offset + value.length : this._writeOffset);\n        return this;\n    }\n    /**\n     * Clears the SmartBuffer instance to its original empty state.\n     */\n    clear() {\n        this._writeOffset = 0;\n        this._readOffset = 0;\n        this.length = 0;\n        return this;\n    }\n    /**\n     * Gets the remaining data left to be read from the SmartBuffer instance.\n     *\n     * @return { Number }\n     */\n    remaining() {\n        return this.length - this._readOffset;\n    }\n    /**\n     * Gets the current read offset value of the SmartBuffer instance.\n     *\n     * @return { Number }\n     */\n    get readOffset() {\n        return this._readOffset;\n    }\n    /**\n     * Sets the read offset value of the SmartBuffer instance.\n     *\n     * @param offset { Number } - The offset value to set.\n     */\n    set readOffset(offset) {\n        utils_1.checkOffsetValue(offset);\n        // Check for bounds.\n        utils_1.checkTargetOffset(offset, this);\n        this._readOffset = offset;\n    }\n    /**\n     * Gets the current write offset value of the SmartBuffer instance.\n     *\n     * @return { Number }\n     */\n    get writeOffset() {\n        return this._writeOffset;\n    }\n    /**\n     * Sets the write offset value of the SmartBuffer instance.\n     *\n     * @param offset { Number } - The offset value to set.\n     */\n    set writeOffset(offset) {\n        utils_1.checkOffsetValue(offset);\n        // Check for bounds.\n        utils_1.checkTargetOffset(offset, this);\n        this._writeOffset = offset;\n    }\n    /**\n     * Gets the currently set string encoding of the SmartBuffer instance.\n     *\n     * @return { BufferEncoding } The string Buffer encoding currently set.\n     */\n    get encoding() {\n        return this._encoding;\n    }\n    /**\n     * Sets the string encoding of the SmartBuffer instance.\n     *\n     * @param encoding { BufferEncoding } The string Buffer encoding to set.\n     */\n    set encoding(encoding) {\n        utils_1.checkEncoding(encoding);\n        this._encoding = encoding;\n    }\n    /**\n     * Gets the underlying internal Buffer. (This includes unmanaged data in the Buffer)\n     *\n     * @return { Buffer } The Buffer value.\n     */\n    get internalBuffer() {\n        return this._buff;\n    }\n    /**\n     * Gets the value of the internal managed Buffer (Includes managed data only)\n     *\n     * @param { Buffer }\n     */\n    toBuffer() {\n        return this._buff.slice(0, this.length);\n    }\n    /**\n     * Gets the String value of the internal managed Buffer\n     *\n     * @param encoding { String } The BufferEncoding to display the Buffer as (defaults to instance level encoding).\n     */\n    toString(encoding) {\n        const encodingVal = typeof encoding === 'string' ? encoding : this._encoding;\n        // Check for invalid encoding.\n        utils_1.checkEncoding(encodingVal);\n        return this._buff.toString(encodingVal, 0, this.length);\n    }\n    /**\n     * Destroys the SmartBuffer instance.\n     */\n    destroy() {\n        this.clear();\n        return this;\n    }\n    /**\n     * Handles inserting and writing strings.\n     *\n     * @param value { String } The String value to insert.\n     * @param isInsert { Boolean } True if inserting a string, false if writing.\n     * @param arg2 { Number | String } The offset to insert the string at, or the BufferEncoding to use.\n     * @param encoding { String } The BufferEncoding to use for writing strings (defaults to instance encoding).\n     */\n    _handleString(value, isInsert, arg3, encoding) {\n        let offsetVal = this._writeOffset;\n        let encodingVal = this._encoding;\n        // Check for offset\n        if (typeof arg3 === 'number') {\n            offsetVal = arg3;\n            // Check for encoding\n        }\n        else if (typeof arg3 === 'string') {\n            utils_1.checkEncoding(arg3);\n            encodingVal = arg3;\n        }\n        // Check for encoding (third param)\n        if (typeof encoding === 'string') {\n            utils_1.checkEncoding(encoding);\n            encodingVal = encoding;\n        }\n        // Calculate bytelength of string.\n        const byteLength = Buffer.byteLength(value, encodingVal);\n        // Ensure there is enough internal Buffer capacity.\n        if (isInsert) {\n            this.ensureInsertable(byteLength, offsetVal);\n        }\n        else {\n            this._ensureWriteable(byteLength, offsetVal);\n        }\n        // Write value\n        this._buff.write(value, offsetVal, byteLength, encodingVal);\n        // Increment internal Buffer write offset;\n        if (isInsert) {\n            this._writeOffset += byteLength;\n        }\n        else {\n            // If an offset was given, check to see if we wrote beyond the current writeOffset.\n            if (typeof arg3 === 'number') {\n                this._writeOffset = Math.max(this._writeOffset, offsetVal + byteLength);\n            }\n            else {\n                // If no offset was given, we wrote to the end of the SmartBuffer so increment writeOffset.\n                this._writeOffset += byteLength;\n            }\n        }\n        return this;\n    }\n    /**\n     * Handles writing or insert of a Buffer.\n     *\n     * @param value { Buffer } The Buffer to write.\n     * @param offset { Number } The offset to write the Buffer to.\n     */\n    _handleBuffer(value, isInsert, offset) {\n        const offsetVal = typeof offset === 'number' ? offset : this._writeOffset;\n        // Ensure there is enough internal Buffer capacity.\n        if (isInsert) {\n            this.ensureInsertable(value.length, offsetVal);\n        }\n        else {\n            this._ensureWriteable(value.length, offsetVal);\n        }\n        // Write buffer value\n        value.copy(this._buff, offsetVal);\n        // Increment internal Buffer write offset;\n        if (isInsert) {\n            this._writeOffset += value.length;\n        }\n        else {\n            // If an offset was given, check to see if we wrote beyond the current writeOffset.\n            if (typeof offset === 'number') {\n                this._writeOffset = Math.max(this._writeOffset, offsetVal + value.length);\n            }\n            else {\n                // If no offset was given, we wrote to the end of the SmartBuffer so increment writeOffset.\n                this._writeOffset += value.length;\n            }\n        }\n        return this;\n    }\n    /**\n     * Ensures that the internal Buffer is large enough to read data.\n     *\n     * @param length { Number } The length of the data that needs to be read.\n     * @param offset { Number } The offset of the data that needs to be read.\n     */\n    ensureReadable(length, offset) {\n        // Offset value defaults to managed read offset.\n        let offsetVal = this._readOffset;\n        // If an offset was provided, use it.\n        if (typeof offset !== 'undefined') {\n            // Checks for valid numberic value;\n            utils_1.checkOffsetValue(offset);\n            // Overide with custom offset.\n            offsetVal = offset;\n        }\n        // Checks if offset is below zero, or the offset+length offset is beyond the total length of the managed data.\n        if (offsetVal < 0 || offsetVal + length > this.length) {\n            throw new Error(utils_1.ERRORS.INVALID_READ_BEYOND_BOUNDS);\n        }\n    }\n    /**\n     * Ensures that the internal Buffer is large enough to insert data.\n     *\n     * @param dataLength { Number } The length of the data that needs to be written.\n     * @param offset { Number } The offset of the data to be written.\n     */\n    ensureInsertable(dataLength, offset) {\n        // Checks for valid numberic value;\n        utils_1.checkOffsetValue(offset);\n        // Ensure there is enough internal Buffer capacity.\n        this._ensureCapacity(this.length + dataLength);\n        // If an offset was provided and its not the very end of the buffer, copy data into appropriate location in regards to the offset.\n        if (offset < this.length) {\n            this._buff.copy(this._buff, offset + dataLength, offset, this._buff.length);\n        }\n        // Adjust tracked smart buffer length\n        if (offset + dataLength > this.length) {\n            this.length = offset + dataLength;\n        }\n        else {\n            this.length += dataLength;\n        }\n    }\n    /**\n     * Ensures that the internal Buffer is large enough to write data.\n     *\n     * @param dataLength { Number } The length of the data that needs to be written.\n     * @param offset { Number } The offset of the data to be written (defaults to writeOffset).\n     */\n    _ensureWriteable(dataLength, offset) {\n        const offsetVal = typeof offset === 'number' ? offset : this._writeOffset;\n        // Ensure enough capacity to write data.\n        this._ensureCapacity(offsetVal + dataLength);\n        // Adjust SmartBuffer length (if offset + length is larger than managed length, adjust length)\n        if (offsetVal + dataLength > this.length) {\n            this.length = offsetVal + dataLength;\n        }\n    }\n    /**\n     * Ensures that the internal Buffer is large enough to write at least the given amount of data.\n     *\n     * @param minLength { Number } The minimum length of the data needs to be written.\n     */\n    _ensureCapacity(minLength) {\n        const oldLength = this._buff.length;\n        if (minLength > oldLength) {\n            let data = this._buff;\n            let newLength = (oldLength * 3) / 2 + 1;\n            if (newLength < minLength) {\n                newLength = minLength;\n            }\n            this._buff = Buffer.allocUnsafe(newLength);\n            data.copy(this._buff, 0, 0, oldLength);\n        }\n    }\n    /**\n     * Reads a numeric number value using the provided function.\n     *\n     * @typeparam T { number | bigint } The type of the value to be read\n     *\n     * @param func { Function(offset: number) => number } The function to read data on the internal Buffer with.\n     * @param byteSize { Number } The number of bytes read.\n     * @param offset { Number } The offset to read from (optional). When this is not provided, the managed readOffset is used instead.\n     *\n     * @returns { T } the number value\n     */\n    _readNumberValue(func, byteSize, offset) {\n        this.ensureReadable(byteSize, offset);\n        // Call Buffer.readXXXX();\n        const value = func.call(this._buff, typeof offset === 'number' ? offset : this._readOffset);\n        // Adjust internal read offset if an optional read offset was not provided.\n        if (typeof offset === 'undefined') {\n            this._readOffset += byteSize;\n        }\n        return value;\n    }\n    /**\n     * Inserts a numeric number value based on the given offset and value.\n     *\n     * @typeparam T { number | bigint } The type of the value to be written\n     *\n     * @param func { Function(offset: T, offset?) => number} The function to write data on the internal Buffer with.\n     * @param byteSize { Number } The number of bytes written.\n     * @param value { T } The number value to write.\n     * @param offset { Number } the offset to write the number at (REQUIRED).\n     *\n     * @returns SmartBuffer this buffer\n     */\n    _insertNumberValue(func, byteSize, value, offset) {\n        // Check for invalid offset values.\n        utils_1.checkOffsetValue(offset);\n        // Ensure there is enough internal Buffer capacity. (raw offset is passed)\n        this.ensureInsertable(byteSize, offset);\n        // Call buffer.writeXXXX();\n        func.call(this._buff, value, offset);\n        // Adjusts internally managed write offset.\n        this._writeOffset += byteSize;\n        return this;\n    }\n    /**\n     * Writes a numeric number value based on the given offset and value.\n     *\n     * @typeparam T { number | bigint } The type of the value to be written\n     *\n     * @param func { Function(offset: T, offset?) => number} The function to write data on the internal Buffer with.\n     * @param byteSize { Number } The number of bytes written.\n     * @param value { T } The number value to write.\n     * @param offset { Number } the offset to write the number at (REQUIRED).\n     *\n     * @returns SmartBuffer this buffer\n     */\n    _writeNumberValue(func, byteSize, value, offset) {\n        // If an offset was provided, validate it.\n        if (typeof offset === 'number') {\n            // Check if we're writing beyond the bounds of the managed data.\n            if (offset < 0) {\n                throw new Error(utils_1.ERRORS.INVALID_WRITE_BEYOND_BOUNDS);\n            }\n            utils_1.checkOffsetValue(offset);\n        }\n        // Default to writeOffset if no offset value was given.\n        const offsetVal = typeof offset === 'number' ? offset : this._writeOffset;\n        // Ensure there is enough internal Buffer capacity. (raw offset is passed)\n        this._ensureWriteable(byteSize, offsetVal);\n        func.call(this._buff, value, offsetVal);\n        // If an offset was given, check to see if we wrote beyond the current writeOffset.\n        if (typeof offset === 'number') {\n            this._writeOffset = Math.max(this._writeOffset, offsetVal + byteSize);\n        }\n        else {\n            // If no numeric offset was given, we wrote to the end of the SmartBuffer so increment writeOffset.\n            this._writeOffset += byteSize;\n        }\n        return this;\n    }\n}\nexports.SmartBuffer = SmartBuffer;\n//# sourceMappingURL=smartbuffer.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/smart-buffer/build/smartbuffer.js?");

/***/ }),

/***/ "./node_modules/smart-buffer/build/utils.js":
/*!**************************************************!*\
  !*** ./node_modules/smart-buffer/build/utils.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nconst buffer_1 = __webpack_require__(/*! buffer */ \"buffer\");\n/**\n * Error strings\n */\nconst ERRORS = {\n    INVALID_ENCODING: 'Invalid encoding provided. Please specify a valid encoding the internal Node.js Buffer supports.',\n    INVALID_SMARTBUFFER_SIZE: 'Invalid size provided. Size must be a valid integer greater than zero.',\n    INVALID_SMARTBUFFER_BUFFER: 'Invalid Buffer provided in SmartBufferOptions.',\n    INVALID_SMARTBUFFER_OBJECT: 'Invalid SmartBufferOptions object supplied to SmartBuffer constructor or factory methods.',\n    INVALID_OFFSET: 'An invalid offset value was provided.',\n    INVALID_OFFSET_NON_NUMBER: 'An invalid offset value was provided. A numeric value is required.',\n    INVALID_LENGTH: 'An invalid length value was provided.',\n    INVALID_LENGTH_NON_NUMBER: 'An invalid length value was provived. A numeric value is required.',\n    INVALID_TARGET_OFFSET: 'Target offset is beyond the bounds of the internal SmartBuffer data.',\n    INVALID_TARGET_LENGTH: 'Specified length value moves cursor beyong the bounds of the internal SmartBuffer data.',\n    INVALID_READ_BEYOND_BOUNDS: 'Attempted to read beyond the bounds of the managed data.',\n    INVALID_WRITE_BEYOND_BOUNDS: 'Attempted to write beyond the bounds of the managed data.'\n};\nexports.ERRORS = ERRORS;\n/**\n * Checks if a given encoding is a valid Buffer encoding. (Throws an exception if check fails)\n *\n * @param { String } encoding The encoding string to check.\n */\nfunction checkEncoding(encoding) {\n    if (!buffer_1.Buffer.isEncoding(encoding)) {\n        throw new Error(ERRORS.INVALID_ENCODING);\n    }\n}\nexports.checkEncoding = checkEncoding;\n/**\n * Checks if a given number is a finite integer. (Throws an exception if check fails)\n *\n * @param { Number } value The number value to check.\n */\nfunction isFiniteInteger(value) {\n    return typeof value === 'number' && isFinite(value) && isInteger(value);\n}\nexports.isFiniteInteger = isFiniteInteger;\n/**\n * Checks if an offset/length value is valid. (Throws an exception if check fails)\n *\n * @param value The value to check.\n * @param offset True if checking an offset, false if checking a length.\n */\nfunction checkOffsetOrLengthValue(value, offset) {\n    if (typeof value === 'number') {\n        // Check for non finite/non integers\n        if (!isFiniteInteger(value) || value < 0) {\n            throw new Error(offset ? ERRORS.INVALID_OFFSET : ERRORS.INVALID_LENGTH);\n        }\n    }\n    else {\n        throw new Error(offset ? ERRORS.INVALID_OFFSET_NON_NUMBER : ERRORS.INVALID_LENGTH_NON_NUMBER);\n    }\n}\n/**\n * Checks if a length value is valid. (Throws an exception if check fails)\n *\n * @param { Number } length The value to check.\n */\nfunction checkLengthValue(length) {\n    checkOffsetOrLengthValue(length, false);\n}\nexports.checkLengthValue = checkLengthValue;\n/**\n * Checks if a offset value is valid. (Throws an exception if check fails)\n *\n * @param { Number } offset The value to check.\n */\nfunction checkOffsetValue(offset) {\n    checkOffsetOrLengthValue(offset, true);\n}\nexports.checkOffsetValue = checkOffsetValue;\n/**\n * Checks if a target offset value is out of bounds. (Throws an exception if check fails)\n *\n * @param { Number } offset The offset value to check.\n * @param { SmartBuffer } buff The SmartBuffer instance to check against.\n */\nfunction checkTargetOffset(offset, buff) {\n    if (offset < 0 || offset > buff.length) {\n        throw new Error(ERRORS.INVALID_TARGET_OFFSET);\n    }\n}\nexports.checkTargetOffset = checkTargetOffset;\n/**\n * Determines whether a given number is a integer.\n * @param value The number to check.\n */\nfunction isInteger(value) {\n    return typeof value === 'number' && isFinite(value) && Math.floor(value) === value;\n}\n/**\n * Throws if Node.js version is too low to support bigint\n */\nfunction bigIntAndBufferInt64Check(bufferMethod) {\n    if (typeof BigInt === 'undefined') {\n        throw new Error('Platform does not support JS BigInt type.');\n    }\n    if (typeof buffer_1.Buffer.prototype[bufferMethod] === 'undefined') {\n        throw new Error(`Platform does not support Buffer.prototype.${bufferMethod}.`);\n    }\n}\nexports.bigIntAndBufferInt64Check = bigIntAndBufferInt64Check;\n//# sourceMappingURL=utils.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/smart-buffer/build/utils.js?");

/***/ }),

/***/ "./node_modules/socks/build/client/socksclient.js":
/*!********************************************************!*\
  !*** ./node_modules/socks/build/client/socksclient.js ***!
  \********************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SocksClientError = exports.SocksClient = void 0;\nconst events_1 = __webpack_require__(/*! events */ \"events\");\nconst net = __webpack_require__(/*! net */ \"net\");\nconst ip = __webpack_require__(/*! ip */ \"./node_modules/ip/lib/ip.js\");\nconst smart_buffer_1 = __webpack_require__(/*! smart-buffer */ \"./node_modules/smart-buffer/build/smartbuffer.js\");\nconst constants_1 = __webpack_require__(/*! ../common/constants */ \"./node_modules/socks/build/common/constants.js\");\nconst helpers_1 = __webpack_require__(/*! ../common/helpers */ \"./node_modules/socks/build/common/helpers.js\");\nconst receivebuffer_1 = __webpack_require__(/*! ../common/receivebuffer */ \"./node_modules/socks/build/common/receivebuffer.js\");\nconst util_1 = __webpack_require__(/*! ../common/util */ \"./node_modules/socks/build/common/util.js\");\nObject.defineProperty(exports, \"SocksClientError\", ({ enumerable: true, get: function () { return util_1.SocksClientError; } }));\nclass SocksClient extends events_1.EventEmitter {\n    constructor(options) {\n        super();\n        this.options = Object.assign({}, options);\n        // Validate SocksClientOptions\n        (0, helpers_1.validateSocksClientOptions)(options);\n        // Default state\n        this.setState(constants_1.SocksClientState.Created);\n    }\n    /**\n     * Creates a new SOCKS connection.\n     *\n     * Note: Supports callbacks and promises. Only supports the connect command.\n     * @param options { SocksClientOptions } Options.\n     * @param callback { Function } An optional callback function.\n     * @returns { Promise }\n     */\n    static createConnection(options, callback) {\n        return new Promise((resolve, reject) => {\n            // Validate SocksClientOptions\n            try {\n                (0, helpers_1.validateSocksClientOptions)(options, ['connect']);\n            }\n            catch (err) {\n                if (typeof callback === 'function') {\n                    callback(err);\n                    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n                    return resolve(err); // Resolves pending promise (prevents memory leaks).\n                }\n                else {\n                    return reject(err);\n                }\n            }\n            const client = new SocksClient(options);\n            client.connect(options.existing_socket);\n            client.once('established', (info) => {\n                client.removeAllListeners();\n                if (typeof callback === 'function') {\n                    callback(null, info);\n                    resolve(info); // Resolves pending promise (prevents memory leaks).\n                }\n                else {\n                    resolve(info);\n                }\n            });\n            // Error occurred, failed to establish connection.\n            client.once('error', (err) => {\n                client.removeAllListeners();\n                if (typeof callback === 'function') {\n                    callback(err);\n                    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n                    resolve(err); // Resolves pending promise (prevents memory leaks).\n                }\n                else {\n                    reject(err);\n                }\n            });\n        });\n    }\n    /**\n     * Creates a new SOCKS connection chain to a destination host through 2 or more SOCKS proxies.\n     *\n     * Note: Supports callbacks and promises. Only supports the connect method.\n     * Note: Implemented via createConnection() factory function.\n     * @param options { SocksClientChainOptions } Options\n     * @param callback { Function } An optional callback function.\n     * @returns { Promise }\n     */\n    static createConnectionChain(options, callback) {\n        // eslint-disable-next-line no-async-promise-executor\n        return new Promise((resolve, reject) => __awaiter(this, void 0, void 0, function* () {\n            // Validate SocksClientChainOptions\n            try {\n                (0, helpers_1.validateSocksClientChainOptions)(options);\n            }\n            catch (err) {\n                if (typeof callback === 'function') {\n                    callback(err);\n                    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n                    return resolve(err); // Resolves pending promise (prevents memory leaks).\n                }\n                else {\n                    return reject(err);\n                }\n            }\n            // Shuffle proxies\n            if (options.randomizeChain) {\n                (0, util_1.shuffleArray)(options.proxies);\n            }\n            try {\n                let sock;\n                for (let i = 0; i < options.proxies.length; i++) {\n                    const nextProxy = options.proxies[i];\n                    // If we've reached the last proxy in the chain, the destination is the actual destination, otherwise it's the next proxy.\n                    const nextDestination = i === options.proxies.length - 1\n                        ? options.destination\n                        : {\n                            host: options.proxies[i + 1].host ||\n                                options.proxies[i + 1].ipaddress,\n                            port: options.proxies[i + 1].port,\n                        };\n                    // Creates the next connection in the chain.\n                    const result = yield SocksClient.createConnection({\n                        command: 'connect',\n                        proxy: nextProxy,\n                        destination: nextDestination,\n                        existing_socket: sock,\n                    });\n                    // If sock is undefined, assign it here.\n                    sock = sock || result.socket;\n                }\n                if (typeof callback === 'function') {\n                    callback(null, { socket: sock });\n                    resolve({ socket: sock }); // Resolves pending promise (prevents memory leaks).\n                }\n                else {\n                    resolve({ socket: sock });\n                }\n            }\n            catch (err) {\n                if (typeof callback === 'function') {\n                    callback(err);\n                    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n                    resolve(err); // Resolves pending promise (prevents memory leaks).\n                }\n                else {\n                    reject(err);\n                }\n            }\n        }));\n    }\n    /**\n     * Creates a SOCKS UDP Frame.\n     * @param options\n     */\n    static createUDPFrame(options) {\n        const buff = new smart_buffer_1.SmartBuffer();\n        buff.writeUInt16BE(0);\n        buff.writeUInt8(options.frameNumber || 0);\n        // IPv4/IPv6/Hostname\n        if (net.isIPv4(options.remoteHost.host)) {\n            buff.writeUInt8(constants_1.Socks5HostType.IPv4);\n            buff.writeUInt32BE(ip.toLong(options.remoteHost.host));\n        }\n        else if (net.isIPv6(options.remoteHost.host)) {\n            buff.writeUInt8(constants_1.Socks5HostType.IPv6);\n            buff.writeBuffer(ip.toBuffer(options.remoteHost.host));\n        }\n        else {\n            buff.writeUInt8(constants_1.Socks5HostType.Hostname);\n            buff.writeUInt8(Buffer.byteLength(options.remoteHost.host));\n            buff.writeString(options.remoteHost.host);\n        }\n        // Port\n        buff.writeUInt16BE(options.remoteHost.port);\n        // Data\n        buff.writeBuffer(options.data);\n        return buff.toBuffer();\n    }\n    /**\n     * Parses a SOCKS UDP frame.\n     * @param data\n     */\n    static parseUDPFrame(data) {\n        const buff = smart_buffer_1.SmartBuffer.fromBuffer(data);\n        buff.readOffset = 2;\n        const frameNumber = buff.readUInt8();\n        const hostType = buff.readUInt8();\n        let remoteHost;\n        if (hostType === constants_1.Socks5HostType.IPv4) {\n            remoteHost = ip.fromLong(buff.readUInt32BE());\n        }\n        else if (hostType === constants_1.Socks5HostType.IPv6) {\n            remoteHost = ip.toString(buff.readBuffer(16));\n        }\n        else {\n            remoteHost = buff.readString(buff.readUInt8());\n        }\n        const remotePort = buff.readUInt16BE();\n        return {\n            frameNumber,\n            remoteHost: {\n                host: remoteHost,\n                port: remotePort,\n            },\n            data: buff.readBuffer(),\n        };\n    }\n    /**\n     * Internal state setter. If the SocksClient is in an error state, it cannot be changed to a non error state.\n     */\n    setState(newState) {\n        if (this.state !== constants_1.SocksClientState.Error) {\n            this.state = newState;\n        }\n    }\n    /**\n     * Starts the connection establishment to the proxy and destination.\n     * @param existingSocket Connected socket to use instead of creating a new one (internal use).\n     */\n    connect(existingSocket) {\n        this.onDataReceived = (data) => this.onDataReceivedHandler(data);\n        this.onClose = () => this.onCloseHandler();\n        this.onError = (err) => this.onErrorHandler(err);\n        this.onConnect = () => this.onConnectHandler();\n        // Start timeout timer (defaults to 30 seconds)\n        const timer = setTimeout(() => this.onEstablishedTimeout(), this.options.timeout || constants_1.DEFAULT_TIMEOUT);\n        // check whether unref is available as it differs from browser to NodeJS (#33)\n        if (timer.unref && typeof timer.unref === 'function') {\n            timer.unref();\n        }\n        // If an existing socket is provided, use it to negotiate SOCKS handshake. Otherwise create a new Socket.\n        if (existingSocket) {\n            this.socket = existingSocket;\n        }\n        else {\n            this.socket = new net.Socket();\n        }\n        // Attach Socket error handlers.\n        this.socket.once('close', this.onClose);\n        this.socket.once('error', this.onError);\n        this.socket.once('connect', this.onConnect);\n        this.socket.on('data', this.onDataReceived);\n        this.setState(constants_1.SocksClientState.Connecting);\n        this.receiveBuffer = new receivebuffer_1.ReceiveBuffer();\n        if (existingSocket) {\n            this.socket.emit('connect');\n        }\n        else {\n            this.socket.connect(this.getSocketOptions());\n            if (this.options.set_tcp_nodelay !== undefined &&\n                this.options.set_tcp_nodelay !== null) {\n                this.socket.setNoDelay(!!this.options.set_tcp_nodelay);\n            }\n        }\n        // Listen for established event so we can re-emit any excess data received during handshakes.\n        this.prependOnceListener('established', (info) => {\n            setImmediate(() => {\n                if (this.receiveBuffer.length > 0) {\n                    const excessData = this.receiveBuffer.get(this.receiveBuffer.length);\n                    info.socket.emit('data', excessData);\n                }\n                info.socket.resume();\n            });\n        });\n    }\n    // Socket options (defaults host/port to options.proxy.host/options.proxy.port)\n    getSocketOptions() {\n        return Object.assign(Object.assign({}, this.options.socket_options), { host: this.options.proxy.host || this.options.proxy.ipaddress, port: this.options.proxy.port });\n    }\n    /**\n     * Handles internal Socks timeout callback.\n     * Note: If the Socks client is not BoundWaitingForConnection or Established, the connection will be closed.\n     */\n    onEstablishedTimeout() {\n        if (this.state !== constants_1.SocksClientState.Established &&\n            this.state !== constants_1.SocksClientState.BoundWaitingForConnection) {\n            this.closeSocket(constants_1.ERRORS.ProxyConnectionTimedOut);\n        }\n    }\n    /**\n     * Handles Socket connect event.\n     */\n    onConnectHandler() {\n        this.setState(constants_1.SocksClientState.Connected);\n        // Send initial handshake.\n        if (this.options.proxy.type === 4) {\n            this.sendSocks4InitialHandshake();\n        }\n        else {\n            this.sendSocks5InitialHandshake();\n        }\n        this.setState(constants_1.SocksClientState.SentInitialHandshake);\n    }\n    /**\n     * Handles Socket data event.\n     * @param data\n     */\n    onDataReceivedHandler(data) {\n        /*\n          All received data is appended to a ReceiveBuffer.\n          This makes sure that all the data we need is received before we attempt to process it.\n        */\n        this.receiveBuffer.append(data);\n        // Process data that we have.\n        this.processData();\n    }\n    /**\n     * Handles processing of the data we have received.\n     */\n    processData() {\n        // If we have enough data to process the next step in the SOCKS handshake, proceed.\n        while (this.state !== constants_1.SocksClientState.Established &&\n            this.state !== constants_1.SocksClientState.Error &&\n            this.receiveBuffer.length >= this.nextRequiredPacketBufferSize) {\n            // Sent initial handshake, waiting for response.\n            if (this.state === constants_1.SocksClientState.SentInitialHandshake) {\n                if (this.options.proxy.type === 4) {\n                    // Socks v4 only has one handshake response.\n                    this.handleSocks4FinalHandshakeResponse();\n                }\n                else {\n                    // Socks v5 has two handshakes, handle initial one here.\n                    this.handleInitialSocks5HandshakeResponse();\n                }\n                // Sent auth request for Socks v5, waiting for response.\n            }\n            else if (this.state === constants_1.SocksClientState.SentAuthentication) {\n                this.handleInitialSocks5AuthenticationHandshakeResponse();\n                // Sent final Socks v5 handshake, waiting for final response.\n            }\n            else if (this.state === constants_1.SocksClientState.SentFinalHandshake) {\n                this.handleSocks5FinalHandshakeResponse();\n                // Socks BIND established. Waiting for remote connection via proxy.\n            }\n            else if (this.state === constants_1.SocksClientState.BoundWaitingForConnection) {\n                if (this.options.proxy.type === 4) {\n                    this.handleSocks4IncomingConnectionResponse();\n                }\n                else {\n                    this.handleSocks5IncomingConnectionResponse();\n                }\n            }\n            else {\n                this.closeSocket(constants_1.ERRORS.InternalError);\n                break;\n            }\n        }\n    }\n    /**\n     * Handles Socket close event.\n     * @param had_error\n     */\n    onCloseHandler() {\n        this.closeSocket(constants_1.ERRORS.SocketClosed);\n    }\n    /**\n     * Handles Socket error event.\n     * @param err\n     */\n    onErrorHandler(err) {\n        this.closeSocket(err.message);\n    }\n    /**\n     * Removes internal event listeners on the underlying Socket.\n     */\n    removeInternalSocketHandlers() {\n        // Pauses data flow of the socket (this is internally resumed after 'established' is emitted)\n        this.socket.pause();\n        this.socket.removeListener('data', this.onDataReceived);\n        this.socket.removeListener('close', this.onClose);\n        this.socket.removeListener('error', this.onError);\n        this.socket.removeListener('connect', this.onConnect);\n    }\n    /**\n     * Closes and destroys the underlying Socket. Emits an error event.\n     * @param err { String } An error string to include in error event.\n     */\n    closeSocket(err) {\n        // Make sure only one 'error' event is fired for the lifetime of this SocksClient instance.\n        if (this.state !== constants_1.SocksClientState.Error) {\n            // Set internal state to Error.\n            this.setState(constants_1.SocksClientState.Error);\n            // Destroy Socket\n            this.socket.destroy();\n            // Remove internal listeners\n            this.removeInternalSocketHandlers();\n            // Fire 'error' event.\n            this.emit('error', new util_1.SocksClientError(err, this.options));\n        }\n    }\n    /**\n     * Sends initial Socks v4 handshake request.\n     */\n    sendSocks4InitialHandshake() {\n        const userId = this.options.proxy.userId || '';\n        const buff = new smart_buffer_1.SmartBuffer();\n        buff.writeUInt8(0x04);\n        buff.writeUInt8(constants_1.SocksCommand[this.options.command]);\n        buff.writeUInt16BE(this.options.destination.port);\n        // Socks 4 (IPv4)\n        if (net.isIPv4(this.options.destination.host)) {\n            buff.writeBuffer(ip.toBuffer(this.options.destination.host));\n            buff.writeStringNT(userId);\n            // Socks 4a (hostname)\n        }\n        else {\n            buff.writeUInt8(0x00);\n            buff.writeUInt8(0x00);\n            buff.writeUInt8(0x00);\n            buff.writeUInt8(0x01);\n            buff.writeStringNT(userId);\n            buff.writeStringNT(this.options.destination.host);\n        }\n        this.nextRequiredPacketBufferSize =\n            constants_1.SOCKS_INCOMING_PACKET_SIZES.Socks4Response;\n        this.socket.write(buff.toBuffer());\n    }\n    /**\n     * Handles Socks v4 handshake response.\n     * @param data\n     */\n    handleSocks4FinalHandshakeResponse() {\n        const data = this.receiveBuffer.get(8);\n        if (data[1] !== constants_1.Socks4Response.Granted) {\n            this.closeSocket(`${constants_1.ERRORS.Socks4ProxyRejectedConnection} - (${constants_1.Socks4Response[data[1]]})`);\n        }\n        else {\n            // Bind response\n            if (constants_1.SocksCommand[this.options.command] === constants_1.SocksCommand.bind) {\n                const buff = smart_buffer_1.SmartBuffer.fromBuffer(data);\n                buff.readOffset = 2;\n                const remoteHost = {\n                    port: buff.readUInt16BE(),\n                    host: ip.fromLong(buff.readUInt32BE()),\n                };\n                // If host is 0.0.0.0, set to proxy host.\n                if (remoteHost.host === '0.0.0.0') {\n                    remoteHost.host = this.options.proxy.ipaddress;\n                }\n                this.setState(constants_1.SocksClientState.BoundWaitingForConnection);\n                this.emit('bound', { remoteHost, socket: this.socket });\n                // Connect response\n            }\n            else {\n                this.setState(constants_1.SocksClientState.Established);\n                this.removeInternalSocketHandlers();\n                this.emit('established', { socket: this.socket });\n            }\n        }\n    }\n    /**\n     * Handles Socks v4 incoming connection request (BIND)\n     * @param data\n     */\n    handleSocks4IncomingConnectionResponse() {\n        const data = this.receiveBuffer.get(8);\n        if (data[1] !== constants_1.Socks4Response.Granted) {\n            this.closeSocket(`${constants_1.ERRORS.Socks4ProxyRejectedIncomingBoundConnection} - (${constants_1.Socks4Response[data[1]]})`);\n        }\n        else {\n            const buff = smart_buffer_1.SmartBuffer.fromBuffer(data);\n            buff.readOffset = 2;\n            const remoteHost = {\n                port: buff.readUInt16BE(),\n                host: ip.fromLong(buff.readUInt32BE()),\n            };\n            this.setState(constants_1.SocksClientState.Established);\n            this.removeInternalSocketHandlers();\n            this.emit('established', { remoteHost, socket: this.socket });\n        }\n    }\n    /**\n     * Sends initial Socks v5 handshake request.\n     */\n    sendSocks5InitialHandshake() {\n        const buff = new smart_buffer_1.SmartBuffer();\n        // By default we always support no auth.\n        const supportedAuthMethods = [constants_1.Socks5Auth.NoAuth];\n        // We should only tell the proxy we support user/pass auth if auth info is actually provided.\n        // Note: As of Tor v0.3.5.7+, if user/pass auth is an option from the client, by default it will always take priority.\n        if (this.options.proxy.userId || this.options.proxy.password) {\n            supportedAuthMethods.push(constants_1.Socks5Auth.UserPass);\n        }\n        // Custom auth method?\n        if (this.options.proxy.custom_auth_method !== undefined) {\n            supportedAuthMethods.push(this.options.proxy.custom_auth_method);\n        }\n        // Build handshake packet\n        buff.writeUInt8(0x05);\n        buff.writeUInt8(supportedAuthMethods.length);\n        for (const authMethod of supportedAuthMethods) {\n            buff.writeUInt8(authMethod);\n        }\n        this.nextRequiredPacketBufferSize =\n            constants_1.SOCKS_INCOMING_PACKET_SIZES.Socks5InitialHandshakeResponse;\n        this.socket.write(buff.toBuffer());\n        this.setState(constants_1.SocksClientState.SentInitialHandshake);\n    }\n    /**\n     * Handles initial Socks v5 handshake response.\n     * @param data\n     */\n    handleInitialSocks5HandshakeResponse() {\n        const data = this.receiveBuffer.get(2);\n        if (data[0] !== 0x05) {\n            this.closeSocket(constants_1.ERRORS.InvalidSocks5IntiailHandshakeSocksVersion);\n        }\n        else if (data[1] === constants_1.SOCKS5_NO_ACCEPTABLE_AUTH) {\n            this.closeSocket(constants_1.ERRORS.InvalidSocks5InitialHandshakeNoAcceptedAuthType);\n        }\n        else {\n            // If selected Socks v5 auth method is no auth, send final handshake request.\n            if (data[1] === constants_1.Socks5Auth.NoAuth) {\n                this.socks5ChosenAuthType = constants_1.Socks5Auth.NoAuth;\n                this.sendSocks5CommandRequest();\n                // If selected Socks v5 auth method is user/password, send auth handshake.\n            }\n            else if (data[1] === constants_1.Socks5Auth.UserPass) {\n                this.socks5ChosenAuthType = constants_1.Socks5Auth.UserPass;\n                this.sendSocks5UserPassAuthentication();\n                // If selected Socks v5 auth method is the custom_auth_method, send custom handshake.\n            }\n            else if (data[1] === this.options.proxy.custom_auth_method) {\n                this.socks5ChosenAuthType = this.options.proxy.custom_auth_method;\n                this.sendSocks5CustomAuthentication();\n            }\n            else {\n                this.closeSocket(constants_1.ERRORS.InvalidSocks5InitialHandshakeUnknownAuthType);\n            }\n        }\n    }\n    /**\n     * Sends Socks v5 user & password auth handshake.\n     *\n     * Note: No auth and user/pass are currently supported.\n     */\n    sendSocks5UserPassAuthentication() {\n        const userId = this.options.proxy.userId || '';\n        const password = this.options.proxy.password || '';\n        const buff = new smart_buffer_1.SmartBuffer();\n        buff.writeUInt8(0x01);\n        buff.writeUInt8(Buffer.byteLength(userId));\n        buff.writeString(userId);\n        buff.writeUInt8(Buffer.byteLength(password));\n        buff.writeString(password);\n        this.nextRequiredPacketBufferSize =\n            constants_1.SOCKS_INCOMING_PACKET_SIZES.Socks5UserPassAuthenticationResponse;\n        this.socket.write(buff.toBuffer());\n        this.setState(constants_1.SocksClientState.SentAuthentication);\n    }\n    sendSocks5CustomAuthentication() {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.nextRequiredPacketBufferSize =\n                this.options.proxy.custom_auth_response_size;\n            this.socket.write(yield this.options.proxy.custom_auth_request_handler());\n            this.setState(constants_1.SocksClientState.SentAuthentication);\n        });\n    }\n    handleSocks5CustomAuthHandshakeResponse(data) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return yield this.options.proxy.custom_auth_response_handler(data);\n        });\n    }\n    handleSocks5AuthenticationNoAuthHandshakeResponse(data) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return data[1] === 0x00;\n        });\n    }\n    handleSocks5AuthenticationUserPassHandshakeResponse(data) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return data[1] === 0x00;\n        });\n    }\n    /**\n     * Handles Socks v5 auth handshake response.\n     * @param data\n     */\n    handleInitialSocks5AuthenticationHandshakeResponse() {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.setState(constants_1.SocksClientState.ReceivedAuthenticationResponse);\n            let authResult = false;\n            if (this.socks5ChosenAuthType === constants_1.Socks5Auth.NoAuth) {\n                authResult = yield this.handleSocks5AuthenticationNoAuthHandshakeResponse(this.receiveBuffer.get(2));\n            }\n            else if (this.socks5ChosenAuthType === constants_1.Socks5Auth.UserPass) {\n                authResult =\n                    yield this.handleSocks5AuthenticationUserPassHandshakeResponse(this.receiveBuffer.get(2));\n            }\n            else if (this.socks5ChosenAuthType === this.options.proxy.custom_auth_method) {\n                authResult = yield this.handleSocks5CustomAuthHandshakeResponse(this.receiveBuffer.get(this.options.proxy.custom_auth_response_size));\n            }\n            if (!authResult) {\n                this.closeSocket(constants_1.ERRORS.Socks5AuthenticationFailed);\n            }\n            else {\n                this.sendSocks5CommandRequest();\n            }\n        });\n    }\n    /**\n     * Sends Socks v5 final handshake request.\n     */\n    sendSocks5CommandRequest() {\n        const buff = new smart_buffer_1.SmartBuffer();\n        buff.writeUInt8(0x05);\n        buff.writeUInt8(constants_1.SocksCommand[this.options.command]);\n        buff.writeUInt8(0x00);\n        // ipv4, ipv6, domain?\n        if (net.isIPv4(this.options.destination.host)) {\n            buff.writeUInt8(constants_1.Socks5HostType.IPv4);\n            buff.writeBuffer(ip.toBuffer(this.options.destination.host));\n        }\n        else if (net.isIPv6(this.options.destination.host)) {\n            buff.writeUInt8(constants_1.Socks5HostType.IPv6);\n            buff.writeBuffer(ip.toBuffer(this.options.destination.host));\n        }\n        else {\n            buff.writeUInt8(constants_1.Socks5HostType.Hostname);\n            buff.writeUInt8(this.options.destination.host.length);\n            buff.writeString(this.options.destination.host);\n        }\n        buff.writeUInt16BE(this.options.destination.port);\n        this.nextRequiredPacketBufferSize =\n            constants_1.SOCKS_INCOMING_PACKET_SIZES.Socks5ResponseHeader;\n        this.socket.write(buff.toBuffer());\n        this.setState(constants_1.SocksClientState.SentFinalHandshake);\n    }\n    /**\n     * Handles Socks v5 final handshake response.\n     * @param data\n     */\n    handleSocks5FinalHandshakeResponse() {\n        // Peek at available data (we need at least 5 bytes to get the hostname length)\n        const header = this.receiveBuffer.peek(5);\n        if (header[0] !== 0x05 || header[1] !== constants_1.Socks5Response.Granted) {\n            this.closeSocket(`${constants_1.ERRORS.InvalidSocks5FinalHandshakeRejected} - ${constants_1.Socks5Response[header[1]]}`);\n        }\n        else {\n            // Read address type\n            const addressType = header[3];\n            let remoteHost;\n            let buff;\n            // IPv4\n            if (addressType === constants_1.Socks5HostType.IPv4) {\n                // Check if data is available.\n                const dataNeeded = constants_1.SOCKS_INCOMING_PACKET_SIZES.Socks5ResponseIPv4;\n                if (this.receiveBuffer.length < dataNeeded) {\n                    this.nextRequiredPacketBufferSize = dataNeeded;\n                    return;\n                }\n                buff = smart_buffer_1.SmartBuffer.fromBuffer(this.receiveBuffer.get(dataNeeded).slice(4));\n                remoteHost = {\n                    host: ip.fromLong(buff.readUInt32BE()),\n                    port: buff.readUInt16BE(),\n                };\n                // If given host is 0.0.0.0, assume remote proxy ip instead.\n                if (remoteHost.host === '0.0.0.0') {\n                    remoteHost.host = this.options.proxy.ipaddress;\n                }\n                // Hostname\n            }\n            else if (addressType === constants_1.Socks5HostType.Hostname) {\n                const hostLength = header[4];\n                const dataNeeded = constants_1.SOCKS_INCOMING_PACKET_SIZES.Socks5ResponseHostname(hostLength); // header + host length + host + port\n                // Check if data is available.\n                if (this.receiveBuffer.length < dataNeeded) {\n                    this.nextRequiredPacketBufferSize = dataNeeded;\n                    return;\n                }\n                buff = smart_buffer_1.SmartBuffer.fromBuffer(this.receiveBuffer.get(dataNeeded).slice(5));\n                remoteHost = {\n                    host: buff.readString(hostLength),\n                    port: buff.readUInt16BE(),\n                };\n                // IPv6\n            }\n            else if (addressType === constants_1.Socks5HostType.IPv6) {\n                // Check if data is available.\n                const dataNeeded = constants_1.SOCKS_INCOMING_PACKET_SIZES.Socks5ResponseIPv6;\n                if (this.receiveBuffer.length < dataNeeded) {\n                    this.nextRequiredPacketBufferSize = dataNeeded;\n                    return;\n                }\n                buff = smart_buffer_1.SmartBuffer.fromBuffer(this.receiveBuffer.get(dataNeeded).slice(4));\n                remoteHost = {\n                    host: ip.toString(buff.readBuffer(16)),\n                    port: buff.readUInt16BE(),\n                };\n            }\n            // We have everything we need\n            this.setState(constants_1.SocksClientState.ReceivedFinalResponse);\n            // If using CONNECT, the client is now in the established state.\n            if (constants_1.SocksCommand[this.options.command] === constants_1.SocksCommand.connect) {\n                this.setState(constants_1.SocksClientState.Established);\n                this.removeInternalSocketHandlers();\n                this.emit('established', { remoteHost, socket: this.socket });\n            }\n            else if (constants_1.SocksCommand[this.options.command] === constants_1.SocksCommand.bind) {\n                /* If using BIND, the Socks client is now in BoundWaitingForConnection state.\n                   This means that the remote proxy server is waiting for a remote connection to the bound port. */\n                this.setState(constants_1.SocksClientState.BoundWaitingForConnection);\n                this.nextRequiredPacketBufferSize =\n                    constants_1.SOCKS_INCOMING_PACKET_SIZES.Socks5ResponseHeader;\n                this.emit('bound', { remoteHost, socket: this.socket });\n                /*\n                  If using Associate, the Socks client is now Established. And the proxy server is now accepting UDP packets at the\n                  given bound port. This initial Socks TCP connection must remain open for the UDP relay to continue to work.\n                */\n            }\n            else if (constants_1.SocksCommand[this.options.command] === constants_1.SocksCommand.associate) {\n                this.setState(constants_1.SocksClientState.Established);\n                this.removeInternalSocketHandlers();\n                this.emit('established', {\n                    remoteHost,\n                    socket: this.socket,\n                });\n            }\n        }\n    }\n    /**\n     * Handles Socks v5 incoming connection request (BIND).\n     */\n    handleSocks5IncomingConnectionResponse() {\n        // Peek at available data (we need at least 5 bytes to get the hostname length)\n        const header = this.receiveBuffer.peek(5);\n        if (header[0] !== 0x05 || header[1] !== constants_1.Socks5Response.Granted) {\n            this.closeSocket(`${constants_1.ERRORS.Socks5ProxyRejectedIncomingBoundConnection} - ${constants_1.Socks5Response[header[1]]}`);\n        }\n        else {\n            // Read address type\n            const addressType = header[3];\n            let remoteHost;\n            let buff;\n            // IPv4\n            if (addressType === constants_1.Socks5HostType.IPv4) {\n                // Check if data is available.\n                const dataNeeded = constants_1.SOCKS_INCOMING_PACKET_SIZES.Socks5ResponseIPv4;\n                if (this.receiveBuffer.length < dataNeeded) {\n                    this.nextRequiredPacketBufferSize = dataNeeded;\n                    return;\n                }\n                buff = smart_buffer_1.SmartBuffer.fromBuffer(this.receiveBuffer.get(dataNeeded).slice(4));\n                remoteHost = {\n                    host: ip.fromLong(buff.readUInt32BE()),\n                    port: buff.readUInt16BE(),\n                };\n                // If given host is 0.0.0.0, assume remote proxy ip instead.\n                if (remoteHost.host === '0.0.0.0') {\n                    remoteHost.host = this.options.proxy.ipaddress;\n                }\n                // Hostname\n            }\n            else if (addressType === constants_1.Socks5HostType.Hostname) {\n                const hostLength = header[4];\n                const dataNeeded = constants_1.SOCKS_INCOMING_PACKET_SIZES.Socks5ResponseHostname(hostLength); // header + host length + port\n                // Check if data is available.\n                if (this.receiveBuffer.length < dataNeeded) {\n                    this.nextRequiredPacketBufferSize = dataNeeded;\n                    return;\n                }\n                buff = smart_buffer_1.SmartBuffer.fromBuffer(this.receiveBuffer.get(dataNeeded).slice(5));\n                remoteHost = {\n                    host: buff.readString(hostLength),\n                    port: buff.readUInt16BE(),\n                };\n                // IPv6\n            }\n            else if (addressType === constants_1.Socks5HostType.IPv6) {\n                // Check if data is available.\n                const dataNeeded = constants_1.SOCKS_INCOMING_PACKET_SIZES.Socks5ResponseIPv6;\n                if (this.receiveBuffer.length < dataNeeded) {\n                    this.nextRequiredPacketBufferSize = dataNeeded;\n                    return;\n                }\n                buff = smart_buffer_1.SmartBuffer.fromBuffer(this.receiveBuffer.get(dataNeeded).slice(4));\n                remoteHost = {\n                    host: ip.toString(buff.readBuffer(16)),\n                    port: buff.readUInt16BE(),\n                };\n            }\n            this.setState(constants_1.SocksClientState.Established);\n            this.removeInternalSocketHandlers();\n            this.emit('established', { remoteHost, socket: this.socket });\n        }\n    }\n    get socksClientOptions() {\n        return Object.assign({}, this.options);\n    }\n}\nexports.SocksClient = SocksClient;\n//# sourceMappingURL=socksclient.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/socks/build/client/socksclient.js?");

/***/ }),

/***/ "./node_modules/socks/build/common/constants.js":
/*!******************************************************!*\
  !*** ./node_modules/socks/build/common/constants.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SOCKS5_NO_ACCEPTABLE_AUTH = exports.SOCKS5_CUSTOM_AUTH_END = exports.SOCKS5_CUSTOM_AUTH_START = exports.SOCKS_INCOMING_PACKET_SIZES = exports.SocksClientState = exports.Socks5Response = exports.Socks5HostType = exports.Socks5Auth = exports.Socks4Response = exports.SocksCommand = exports.ERRORS = exports.DEFAULT_TIMEOUT = void 0;\nconst DEFAULT_TIMEOUT = 30000;\nexports.DEFAULT_TIMEOUT = DEFAULT_TIMEOUT;\n// prettier-ignore\nconst ERRORS = {\n    InvalidSocksCommand: 'An invalid SOCKS command was provided. Valid options are connect, bind, and associate.',\n    InvalidSocksCommandForOperation: 'An invalid SOCKS command was provided. Only a subset of commands are supported for this operation.',\n    InvalidSocksCommandChain: 'An invalid SOCKS command was provided. Chaining currently only supports the connect command.',\n    InvalidSocksClientOptionsDestination: 'An invalid destination host was provided.',\n    InvalidSocksClientOptionsExistingSocket: 'An invalid existing socket was provided. This should be an instance of stream.Duplex.',\n    InvalidSocksClientOptionsProxy: 'Invalid SOCKS proxy details were provided.',\n    InvalidSocksClientOptionsTimeout: 'An invalid timeout value was provided. Please enter a value above 0 (in ms).',\n    InvalidSocksClientOptionsProxiesLength: 'At least two socks proxies must be provided for chaining.',\n    InvalidSocksClientOptionsCustomAuthRange: 'Custom auth must be a value between 0x80 and 0xFE.',\n    InvalidSocksClientOptionsCustomAuthOptions: 'When a custom_auth_method is provided, custom_auth_request_handler, custom_auth_response_size, and custom_auth_response_handler must also be provided and valid.',\n    NegotiationError: 'Negotiation error',\n    SocketClosed: 'Socket closed',\n    ProxyConnectionTimedOut: 'Proxy connection timed out',\n    InternalError: 'SocksClient internal error (this should not happen)',\n    InvalidSocks4HandshakeResponse: 'Received invalid Socks4 handshake response',\n    Socks4ProxyRejectedConnection: 'Socks4 Proxy rejected connection',\n    InvalidSocks4IncomingConnectionResponse: 'Socks4 invalid incoming connection response',\n    Socks4ProxyRejectedIncomingBoundConnection: 'Socks4 Proxy rejected incoming bound connection',\n    InvalidSocks5InitialHandshakeResponse: 'Received invalid Socks5 initial handshake response',\n    InvalidSocks5IntiailHandshakeSocksVersion: 'Received invalid Socks5 initial handshake (invalid socks version)',\n    InvalidSocks5InitialHandshakeNoAcceptedAuthType: 'Received invalid Socks5 initial handshake (no accepted authentication type)',\n    InvalidSocks5InitialHandshakeUnknownAuthType: 'Received invalid Socks5 initial handshake (unknown authentication type)',\n    Socks5AuthenticationFailed: 'Socks5 Authentication failed',\n    InvalidSocks5FinalHandshake: 'Received invalid Socks5 final handshake response',\n    InvalidSocks5FinalHandshakeRejected: 'Socks5 proxy rejected connection',\n    InvalidSocks5IncomingConnectionResponse: 'Received invalid Socks5 incoming connection response',\n    Socks5ProxyRejectedIncomingBoundConnection: 'Socks5 Proxy rejected incoming bound connection',\n};\nexports.ERRORS = ERRORS;\nconst SOCKS_INCOMING_PACKET_SIZES = {\n    Socks5InitialHandshakeResponse: 2,\n    Socks5UserPassAuthenticationResponse: 2,\n    // Command response + incoming connection (bind)\n    Socks5ResponseHeader: 5,\n    Socks5ResponseIPv4: 10,\n    Socks5ResponseIPv6: 22,\n    Socks5ResponseHostname: (hostNameLength) => hostNameLength + 7,\n    // Command response + incoming connection (bind)\n    Socks4Response: 8, // 2 header + 2 port + 4 ip\n};\nexports.SOCKS_INCOMING_PACKET_SIZES = SOCKS_INCOMING_PACKET_SIZES;\nvar SocksCommand;\n(function (SocksCommand) {\n    SocksCommand[SocksCommand[\"connect\"] = 1] = \"connect\";\n    SocksCommand[SocksCommand[\"bind\"] = 2] = \"bind\";\n    SocksCommand[SocksCommand[\"associate\"] = 3] = \"associate\";\n})(SocksCommand || (SocksCommand = {}));\nexports.SocksCommand = SocksCommand;\nvar Socks4Response;\n(function (Socks4Response) {\n    Socks4Response[Socks4Response[\"Granted\"] = 90] = \"Granted\";\n    Socks4Response[Socks4Response[\"Failed\"] = 91] = \"Failed\";\n    Socks4Response[Socks4Response[\"Rejected\"] = 92] = \"Rejected\";\n    Socks4Response[Socks4Response[\"RejectedIdent\"] = 93] = \"RejectedIdent\";\n})(Socks4Response || (Socks4Response = {}));\nexports.Socks4Response = Socks4Response;\nvar Socks5Auth;\n(function (Socks5Auth) {\n    Socks5Auth[Socks5Auth[\"NoAuth\"] = 0] = \"NoAuth\";\n    Socks5Auth[Socks5Auth[\"GSSApi\"] = 1] = \"GSSApi\";\n    Socks5Auth[Socks5Auth[\"UserPass\"] = 2] = \"UserPass\";\n})(Socks5Auth || (Socks5Auth = {}));\nexports.Socks5Auth = Socks5Auth;\nconst SOCKS5_CUSTOM_AUTH_START = 0x80;\nexports.SOCKS5_CUSTOM_AUTH_START = SOCKS5_CUSTOM_AUTH_START;\nconst SOCKS5_CUSTOM_AUTH_END = 0xfe;\nexports.SOCKS5_CUSTOM_AUTH_END = SOCKS5_CUSTOM_AUTH_END;\nconst SOCKS5_NO_ACCEPTABLE_AUTH = 0xff;\nexports.SOCKS5_NO_ACCEPTABLE_AUTH = SOCKS5_NO_ACCEPTABLE_AUTH;\nvar Socks5Response;\n(function (Socks5Response) {\n    Socks5Response[Socks5Response[\"Granted\"] = 0] = \"Granted\";\n    Socks5Response[Socks5Response[\"Failure\"] = 1] = \"Failure\";\n    Socks5Response[Socks5Response[\"NotAllowed\"] = 2] = \"NotAllowed\";\n    Socks5Response[Socks5Response[\"NetworkUnreachable\"] = 3] = \"NetworkUnreachable\";\n    Socks5Response[Socks5Response[\"HostUnreachable\"] = 4] = \"HostUnreachable\";\n    Socks5Response[Socks5Response[\"ConnectionRefused\"] = 5] = \"ConnectionRefused\";\n    Socks5Response[Socks5Response[\"TTLExpired\"] = 6] = \"TTLExpired\";\n    Socks5Response[Socks5Response[\"CommandNotSupported\"] = 7] = \"CommandNotSupported\";\n    Socks5Response[Socks5Response[\"AddressNotSupported\"] = 8] = \"AddressNotSupported\";\n})(Socks5Response || (Socks5Response = {}));\nexports.Socks5Response = Socks5Response;\nvar Socks5HostType;\n(function (Socks5HostType) {\n    Socks5HostType[Socks5HostType[\"IPv4\"] = 1] = \"IPv4\";\n    Socks5HostType[Socks5HostType[\"Hostname\"] = 3] = \"Hostname\";\n    Socks5HostType[Socks5HostType[\"IPv6\"] = 4] = \"IPv6\";\n})(Socks5HostType || (Socks5HostType = {}));\nexports.Socks5HostType = Socks5HostType;\nvar SocksClientState;\n(function (SocksClientState) {\n    SocksClientState[SocksClientState[\"Created\"] = 0] = \"Created\";\n    SocksClientState[SocksClientState[\"Connecting\"] = 1] = \"Connecting\";\n    SocksClientState[SocksClientState[\"Connected\"] = 2] = \"Connected\";\n    SocksClientState[SocksClientState[\"SentInitialHandshake\"] = 3] = \"SentInitialHandshake\";\n    SocksClientState[SocksClientState[\"ReceivedInitialHandshakeResponse\"] = 4] = \"ReceivedInitialHandshakeResponse\";\n    SocksClientState[SocksClientState[\"SentAuthentication\"] = 5] = \"SentAuthentication\";\n    SocksClientState[SocksClientState[\"ReceivedAuthenticationResponse\"] = 6] = \"ReceivedAuthenticationResponse\";\n    SocksClientState[SocksClientState[\"SentFinalHandshake\"] = 7] = \"SentFinalHandshake\";\n    SocksClientState[SocksClientState[\"ReceivedFinalResponse\"] = 8] = \"ReceivedFinalResponse\";\n    SocksClientState[SocksClientState[\"BoundWaitingForConnection\"] = 9] = \"BoundWaitingForConnection\";\n    SocksClientState[SocksClientState[\"Established\"] = 10] = \"Established\";\n    SocksClientState[SocksClientState[\"Disconnected\"] = 11] = \"Disconnected\";\n    SocksClientState[SocksClientState[\"Error\"] = 99] = \"Error\";\n})(SocksClientState || (SocksClientState = {}));\nexports.SocksClientState = SocksClientState;\n//# sourceMappingURL=constants.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/socks/build/common/constants.js?");

/***/ }),

/***/ "./node_modules/socks/build/common/helpers.js":
/*!****************************************************!*\
  !*** ./node_modules/socks/build/common/helpers.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.validateSocksClientChainOptions = exports.validateSocksClientOptions = void 0;\nconst util_1 = __webpack_require__(/*! ./util */ \"./node_modules/socks/build/common/util.js\");\nconst constants_1 = __webpack_require__(/*! ./constants */ \"./node_modules/socks/build/common/constants.js\");\nconst stream = __webpack_require__(/*! stream */ \"stream\");\n/**\n * Validates the provided SocksClientOptions\n * @param options { SocksClientOptions }\n * @param acceptedCommands { string[] } A list of accepted SocksProxy commands.\n */\nfunction validateSocksClientOptions(options, acceptedCommands = ['connect', 'bind', 'associate']) {\n    // Check SOCKs command option.\n    if (!constants_1.SocksCommand[options.command]) {\n        throw new util_1.SocksClientError(constants_1.ERRORS.InvalidSocksCommand, options);\n    }\n    // Check SocksCommand for acceptable command.\n    if (acceptedCommands.indexOf(options.command) === -1) {\n        throw new util_1.SocksClientError(constants_1.ERRORS.InvalidSocksCommandForOperation, options);\n    }\n    // Check destination\n    if (!isValidSocksRemoteHost(options.destination)) {\n        throw new util_1.SocksClientError(constants_1.ERRORS.InvalidSocksClientOptionsDestination, options);\n    }\n    // Check SOCKS proxy to use\n    if (!isValidSocksProxy(options.proxy)) {\n        throw new util_1.SocksClientError(constants_1.ERRORS.InvalidSocksClientOptionsProxy, options);\n    }\n    // Validate custom auth (if set)\n    validateCustomProxyAuth(options.proxy, options);\n    // Check timeout\n    if (options.timeout && !isValidTimeoutValue(options.timeout)) {\n        throw new util_1.SocksClientError(constants_1.ERRORS.InvalidSocksClientOptionsTimeout, options);\n    }\n    // Check existing_socket (if provided)\n    if (options.existing_socket &&\n        !(options.existing_socket instanceof stream.Duplex)) {\n        throw new util_1.SocksClientError(constants_1.ERRORS.InvalidSocksClientOptionsExistingSocket, options);\n    }\n}\nexports.validateSocksClientOptions = validateSocksClientOptions;\n/**\n * Validates the SocksClientChainOptions\n * @param options { SocksClientChainOptions }\n */\nfunction validateSocksClientChainOptions(options) {\n    // Only connect is supported when chaining.\n    if (options.command !== 'connect') {\n        throw new util_1.SocksClientError(constants_1.ERRORS.InvalidSocksCommandChain, options);\n    }\n    // Check destination\n    if (!isValidSocksRemoteHost(options.destination)) {\n        throw new util_1.SocksClientError(constants_1.ERRORS.InvalidSocksClientOptionsDestination, options);\n    }\n    // Validate proxies (length)\n    if (!(options.proxies &&\n        Array.isArray(options.proxies) &&\n        options.proxies.length >= 2)) {\n        throw new util_1.SocksClientError(constants_1.ERRORS.InvalidSocksClientOptionsProxiesLength, options);\n    }\n    // Validate proxies\n    options.proxies.forEach((proxy) => {\n        if (!isValidSocksProxy(proxy)) {\n            throw new util_1.SocksClientError(constants_1.ERRORS.InvalidSocksClientOptionsProxy, options);\n        }\n        // Validate custom auth (if set)\n        validateCustomProxyAuth(proxy, options);\n    });\n    // Check timeout\n    if (options.timeout && !isValidTimeoutValue(options.timeout)) {\n        throw new util_1.SocksClientError(constants_1.ERRORS.InvalidSocksClientOptionsTimeout, options);\n    }\n}\nexports.validateSocksClientChainOptions = validateSocksClientChainOptions;\nfunction validateCustomProxyAuth(proxy, options) {\n    if (proxy.custom_auth_method !== undefined) {\n        // Invalid auth method range\n        if (proxy.custom_auth_method < constants_1.SOCKS5_CUSTOM_AUTH_START ||\n            proxy.custom_auth_method > constants_1.SOCKS5_CUSTOM_AUTH_END) {\n            throw new util_1.SocksClientError(constants_1.ERRORS.InvalidSocksClientOptionsCustomAuthRange, options);\n        }\n        // Missing custom_auth_request_handler\n        if (proxy.custom_auth_request_handler === undefined ||\n            typeof proxy.custom_auth_request_handler !== 'function') {\n            throw new util_1.SocksClientError(constants_1.ERRORS.InvalidSocksClientOptionsCustomAuthOptions, options);\n        }\n        // Missing custom_auth_response_size\n        if (proxy.custom_auth_response_size === undefined) {\n            throw new util_1.SocksClientError(constants_1.ERRORS.InvalidSocksClientOptionsCustomAuthOptions, options);\n        }\n        // Missing/invalid custom_auth_response_handler\n        if (proxy.custom_auth_response_handler === undefined ||\n            typeof proxy.custom_auth_response_handler !== 'function') {\n            throw new util_1.SocksClientError(constants_1.ERRORS.InvalidSocksClientOptionsCustomAuthOptions, options);\n        }\n    }\n}\n/**\n * Validates a SocksRemoteHost\n * @param remoteHost { SocksRemoteHost }\n */\nfunction isValidSocksRemoteHost(remoteHost) {\n    return (remoteHost &&\n        typeof remoteHost.host === 'string' &&\n        typeof remoteHost.port === 'number' &&\n        remoteHost.port >= 0 &&\n        remoteHost.port <= 65535);\n}\n/**\n * Validates a SocksProxy\n * @param proxy { SocksProxy }\n */\nfunction isValidSocksProxy(proxy) {\n    return (proxy &&\n        (typeof proxy.host === 'string' || typeof proxy.ipaddress === 'string') &&\n        typeof proxy.port === 'number' &&\n        proxy.port >= 0 &&\n        proxy.port <= 65535 &&\n        (proxy.type === 4 || proxy.type === 5));\n}\n/**\n * Validates a timeout value.\n * @param value { Number }\n */\nfunction isValidTimeoutValue(value) {\n    return typeof value === 'number' && value > 0;\n}\n//# sourceMappingURL=helpers.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/socks/build/common/helpers.js?");

/***/ }),

/***/ "./node_modules/socks/build/common/receivebuffer.js":
/*!**********************************************************!*\
  !*** ./node_modules/socks/build/common/receivebuffer.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ReceiveBuffer = void 0;\nclass ReceiveBuffer {\n    constructor(size = 4096) {\n        this.buffer = Buffer.allocUnsafe(size);\n        this.offset = 0;\n        this.originalSize = size;\n    }\n    get length() {\n        return this.offset;\n    }\n    append(data) {\n        if (!Buffer.isBuffer(data)) {\n            throw new Error('Attempted to append a non-buffer instance to ReceiveBuffer.');\n        }\n        if (this.offset + data.length >= this.buffer.length) {\n            const tmp = this.buffer;\n            this.buffer = Buffer.allocUnsafe(Math.max(this.buffer.length + this.originalSize, this.buffer.length + data.length));\n            tmp.copy(this.buffer);\n        }\n        data.copy(this.buffer, this.offset);\n        return (this.offset += data.length);\n    }\n    peek(length) {\n        if (length > this.offset) {\n            throw new Error('Attempted to read beyond the bounds of the managed internal data.');\n        }\n        return this.buffer.slice(0, length);\n    }\n    get(length) {\n        if (length > this.offset) {\n            throw new Error('Attempted to read beyond the bounds of the managed internal data.');\n        }\n        const value = Buffer.allocUnsafe(length);\n        this.buffer.slice(0, length).copy(value);\n        this.buffer.copyWithin(0, length, length + this.offset - length);\n        this.offset -= length;\n        return value;\n    }\n}\nexports.ReceiveBuffer = ReceiveBuffer;\n//# sourceMappingURL=receivebuffer.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/socks/build/common/receivebuffer.js?");

/***/ }),

/***/ "./node_modules/socks/build/common/util.js":
/*!*************************************************!*\
  !*** ./node_modules/socks/build/common/util.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.shuffleArray = exports.SocksClientError = void 0;\n/**\n * Error wrapper for SocksClient\n */\nclass SocksClientError extends Error {\n    constructor(message, options) {\n        super(message);\n        this.options = options;\n    }\n}\nexports.SocksClientError = SocksClientError;\n/**\n * Shuffles a given array.\n * @param array The array to shuffle.\n */\nfunction shuffleArray(array) {\n    for (let i = array.length - 1; i > 0; i--) {\n        const j = Math.floor(Math.random() * (i + 1));\n        [array[i], array[j]] = [array[j], array[i]];\n    }\n}\nexports.shuffleArray = shuffleArray;\n//# sourceMappingURL=util.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/socks/build/common/util.js?");

/***/ }),

/***/ "./node_modules/socks/build/index.js":
/*!*******************************************!*\
  !*** ./node_modules/socks/build/index.js ***!
  \*******************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n__exportStar(__webpack_require__(/*! ./client/socksclient */ \"./node_modules/socks/build/client/socksclient.js\"), exports);\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://renderer/./node_modules/socks/build/index.js?");

/***/ }),

/***/ "./node_modules/sparse-bitfield/index.js":
/*!***********************************************!*\
  !*** ./node_modules/sparse-bitfield/index.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var pager = __webpack_require__(/*! memory-pager */ \"./node_modules/memory-pager/index.js\")\n\nmodule.exports = Bitfield\n\nfunction Bitfield (opts) {\n  if (!(this instanceof Bitfield)) return new Bitfield(opts)\n  if (!opts) opts = {}\n  if (Buffer.isBuffer(opts)) opts = {buffer: opts}\n\n  this.pageOffset = opts.pageOffset || 0\n  this.pageSize = opts.pageSize || 1024\n  this.pages = opts.pages || pager(this.pageSize)\n\n  this.byteLength = this.pages.length * this.pageSize\n  this.length = 8 * this.byteLength\n\n  if (!powerOfTwo(this.pageSize)) throw new Error('The page size should be a power of two')\n\n  this._trackUpdates = !!opts.trackUpdates\n  this._pageMask = this.pageSize - 1\n\n  if (opts.buffer) {\n    for (var i = 0; i < opts.buffer.length; i += this.pageSize) {\n      this.pages.set(i / this.pageSize, opts.buffer.slice(i, i + this.pageSize))\n    }\n    this.byteLength = opts.buffer.length\n    this.length = 8 * this.byteLength\n  }\n}\n\nBitfield.prototype.get = function (i) {\n  var o = i & 7\n  var j = (i - o) / 8\n\n  return !!(this.getByte(j) & (128 >> o))\n}\n\nBitfield.prototype.getByte = function (i) {\n  var o = i & this._pageMask\n  var j = (i - o) / this.pageSize\n  var page = this.pages.get(j, true)\n\n  return page ? page.buffer[o + this.pageOffset] : 0\n}\n\nBitfield.prototype.set = function (i, v) {\n  var o = i & 7\n  var j = (i - o) / 8\n  var b = this.getByte(j)\n\n  return this.setByte(j, v ? b | (128 >> o) : b & (255 ^ (128 >> o)))\n}\n\nBitfield.prototype.toBuffer = function () {\n  var all = alloc(this.pages.length * this.pageSize)\n\n  for (var i = 0; i < this.pages.length; i++) {\n    var next = this.pages.get(i, true)\n    var allOffset = i * this.pageSize\n    if (next) next.buffer.copy(all, allOffset, this.pageOffset, this.pageOffset + this.pageSize)\n  }\n\n  return all\n}\n\nBitfield.prototype.setByte = function (i, b) {\n  var o = i & this._pageMask\n  var j = (i - o) / this.pageSize\n  var page = this.pages.get(j, false)\n\n  o += this.pageOffset\n\n  if (page.buffer[o] === b) return false\n  page.buffer[o] = b\n\n  if (i >= this.byteLength) {\n    this.byteLength = i + 1\n    this.length = this.byteLength * 8\n  }\n\n  if (this._trackUpdates) this.pages.updated(page)\n\n  return true\n}\n\nfunction alloc (n) {\n  if (Buffer.alloc) return Buffer.alloc(n)\n  var b = new Buffer(n)\n  b.fill(0)\n  return b\n}\n\nfunction powerOfTwo (x) {\n  return !(x & (x - 1))\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/sparse-bitfield/index.js?");

/***/ }),

/***/ "./node_modules/universalify/index.js":
/*!********************************************!*\
  !*** ./node_modules/universalify/index.js ***!
  \********************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nexports.fromCallback = function (fn) {\n  return Object.defineProperty(function (...args) {\n    if (typeof args[args.length - 1] === 'function') fn.apply(this, args)\n    else {\n      return new Promise((resolve, reject) => {\n        fn.call(\n          this,\n          ...args,\n          (err, res) => (err != null) ? reject(err) : resolve(res)\n        )\n      })\n    }\n  }, 'name', { value: fn.name })\n}\n\nexports.fromPromise = function (fn) {\n  return Object.defineProperty(function (...args) {\n    const cb = args[args.length - 1]\n    if (typeof cb !== 'function') return fn.apply(this, args)\n    else fn.apply(this, args.slice(0, -1)).then(r => cb(null, r), cb)\n  }, 'name', { value: fn.name })\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/universalify/index.js?");

/***/ }),

/***/ "./node_modules/use-sync-external-store/cjs/use-sync-external-store-shim.development.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/use-sync-external-store/cjs/use-sync-external-store-shim.development.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("/**\n * @license React\n * use-sync-external-store-shim.development.js\n *\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n\n\nif (true) {\n  (function() {\n\n          'use strict';\n\n/* global __REACT_DEVTOOLS_GLOBAL_HOOK__ */\nif (\n  typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ !== 'undefined' &&\n  typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStart ===\n    'function'\n) {\n  __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStart(new Error());\n}\n          var React = __webpack_require__(/*! react */ \"./node_modules/react/index.js\");\n\nvar ReactSharedInternals = React.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED;\n\nfunction error(format) {\n  {\n    {\n      for (var _len2 = arguments.length, args = new Array(_len2 > 1 ? _len2 - 1 : 0), _key2 = 1; _key2 < _len2; _key2++) {\n        args[_key2 - 1] = arguments[_key2];\n      }\n\n      printWarning('error', format, args);\n    }\n  }\n}\n\nfunction printWarning(level, format, args) {\n  // When changing this logic, you might want to also\n  // update consoleWithStackDev.www.js as well.\n  {\n    var ReactDebugCurrentFrame = ReactSharedInternals.ReactDebugCurrentFrame;\n    var stack = ReactDebugCurrentFrame.getStackAddendum();\n\n    if (stack !== '') {\n      format += '%s';\n      args = args.concat([stack]);\n    } // eslint-disable-next-line react-internal/safe-string-coercion\n\n\n    var argsWithFormat = args.map(function (item) {\n      return String(item);\n    }); // Careful: RN currently depends on this prefix\n\n    argsWithFormat.unshift('Warning: ' + format); // We intentionally don't use spread (or .apply) directly because it\n    // breaks IE9: https://github.com/facebook/react/issues/13610\n    // eslint-disable-next-line react-internal/no-production-logging\n\n    Function.prototype.apply.call(console[level], console, argsWithFormat);\n  }\n}\n\n/**\n * inlined Object.is polyfill to avoid requiring consumers ship their own\n * https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/is\n */\nfunction is(x, y) {\n  return x === y && (x !== 0 || 1 / x === 1 / y) || x !== x && y !== y // eslint-disable-line no-self-compare\n  ;\n}\n\nvar objectIs = typeof Object.is === 'function' ? Object.is : is;\n\n// dispatch for CommonJS interop named imports.\n\nvar useState = React.useState,\n    useEffect = React.useEffect,\n    useLayoutEffect = React.useLayoutEffect,\n    useDebugValue = React.useDebugValue;\nvar didWarnOld18Alpha = false;\nvar didWarnUncachedGetSnapshot = false; // Disclaimer: This shim breaks many of the rules of React, and only works\n// because of a very particular set of implementation details and assumptions\n// -- change any one of them and it will break. The most important assumption\n// is that updates are always synchronous, because concurrent rendering is\n// only available in versions of React that also have a built-in\n// useSyncExternalStore API. And we only use this shim when the built-in API\n// does not exist.\n//\n// Do not assume that the clever hacks used by this hook also work in general.\n// The point of this shim is to replace the need for hacks by other libraries.\n\nfunction useSyncExternalStore(subscribe, getSnapshot, // Note: The shim does not use getServerSnapshot, because pre-18 versions of\n// React do not expose a way to check if we're hydrating. So users of the shim\n// will need to track that themselves and return the correct value\n// from `getSnapshot`.\ngetServerSnapshot) {\n  {\n    if (!didWarnOld18Alpha) {\n      if (React.startTransition !== undefined) {\n        didWarnOld18Alpha = true;\n\n        error('You are using an outdated, pre-release alpha of React 18 that ' + 'does not support useSyncExternalStore. The ' + 'use-sync-external-store shim will not work correctly. Upgrade ' + 'to a newer pre-release.');\n      }\n    }\n  } // Read the current snapshot from the store on every render. Again, this\n  // breaks the rules of React, and only works here because of specific\n  // implementation details, most importantly that updates are\n  // always synchronous.\n\n\n  var value = getSnapshot();\n\n  {\n    if (!didWarnUncachedGetSnapshot) {\n      var cachedValue = getSnapshot();\n\n      if (!objectIs(value, cachedValue)) {\n        error('The result of getSnapshot should be cached to avoid an infinite loop');\n\n        didWarnUncachedGetSnapshot = true;\n      }\n    }\n  } // Because updates are synchronous, we don't queue them. Instead we force a\n  // re-render whenever the subscribed state changes by updating an some\n  // arbitrary useState hook. Then, during render, we call getSnapshot to read\n  // the current value.\n  //\n  // Because we don't actually use the state returned by the useState hook, we\n  // can save a bit of memory by storing other stuff in that slot.\n  //\n  // To implement the early bailout, we need to track some things on a mutable\n  // object. Usually, we would put that in a useRef hook, but we can stash it in\n  // our useState hook instead.\n  //\n  // To force a re-render, we call forceUpdate({inst}). That works because the\n  // new object always fails an equality check.\n\n\n  var _useState = useState({\n    inst: {\n      value: value,\n      getSnapshot: getSnapshot\n    }\n  }),\n      inst = _useState[0].inst,\n      forceUpdate = _useState[1]; // Track the latest getSnapshot function with a ref. This needs to be updated\n  // in the layout phase so we can access it during the tearing check that\n  // happens on subscribe.\n\n\n  useLayoutEffect(function () {\n    inst.value = value;\n    inst.getSnapshot = getSnapshot; // Whenever getSnapshot or subscribe changes, we need to check in the\n    // commit phase if there was an interleaved mutation. In concurrent mode\n    // this can happen all the time, but even in synchronous mode, an earlier\n    // effect may have mutated the store.\n\n    if (checkIfSnapshotChanged(inst)) {\n      // Force a re-render.\n      forceUpdate({\n        inst: inst\n      });\n    }\n  }, [subscribe, value, getSnapshot]);\n  useEffect(function () {\n    // Check for changes right before subscribing. Subsequent changes will be\n    // detected in the subscription handler.\n    if (checkIfSnapshotChanged(inst)) {\n      // Force a re-render.\n      forceUpdate({\n        inst: inst\n      });\n    }\n\n    var handleStoreChange = function () {\n      // TODO: Because there is no cross-renderer API for batching updates, it's\n      // up to the consumer of this library to wrap their subscription event\n      // with unstable_batchedUpdates. Should we try to detect when this isn't\n      // the case and print a warning in development?\n      // The store changed. Check if the snapshot changed since the last time we\n      // read from the store.\n      if (checkIfSnapshotChanged(inst)) {\n        // Force a re-render.\n        forceUpdate({\n          inst: inst\n        });\n      }\n    }; // Subscribe to the store and return a clean-up function.\n\n\n    return subscribe(handleStoreChange);\n  }, [subscribe]);\n  useDebugValue(value);\n  return value;\n}\n\nfunction checkIfSnapshotChanged(inst) {\n  var latestGetSnapshot = inst.getSnapshot;\n  var prevValue = inst.value;\n\n  try {\n    var nextValue = latestGetSnapshot();\n    return !objectIs(prevValue, nextValue);\n  } catch (error) {\n    return true;\n  }\n}\n\nfunction useSyncExternalStore$1(subscribe, getSnapshot, getServerSnapshot) {\n  // Note: The shim does not use getServerSnapshot, because pre-18 versions of\n  // React do not expose a way to check if we're hydrating. So users of the shim\n  // will need to track that themselves and return the correct value\n  // from `getSnapshot`.\n  return getSnapshot();\n}\n\nvar canUseDOM = !!(typeof window !== 'undefined' && typeof window.document !== 'undefined' && typeof window.document.createElement !== 'undefined');\n\nvar isServerEnvironment = !canUseDOM;\n\nvar shim = isServerEnvironment ? useSyncExternalStore$1 : useSyncExternalStore;\nvar useSyncExternalStore$2 = React.useSyncExternalStore !== undefined ? React.useSyncExternalStore : shim;\n\nexports.useSyncExternalStore = useSyncExternalStore$2;\n          /* global __REACT_DEVTOOLS_GLOBAL_HOOK__ */\nif (\n  typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ !== 'undefined' &&\n  typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStop ===\n    'function'\n) {\n  __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStop(new Error());\n}\n        \n  })();\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/use-sync-external-store/cjs/use-sync-external-store-shim.development.js?");

/***/ }),

/***/ "./node_modules/use-sync-external-store/cjs/use-sync-external-store-shim/with-selector.development.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/use-sync-external-store/cjs/use-sync-external-store-shim/with-selector.development.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("/**\n * @license React\n * use-sync-external-store-shim/with-selector.development.js\n *\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n\n\nif (true) {\n  (function() {\n\n          'use strict';\n\n/* global __REACT_DEVTOOLS_GLOBAL_HOOK__ */\nif (\n  typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ !== 'undefined' &&\n  typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStart ===\n    'function'\n) {\n  __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStart(new Error());\n}\n          var React = __webpack_require__(/*! react */ \"./node_modules/react/index.js\");\nvar shim = __webpack_require__(/*! use-sync-external-store/shim */ \"./node_modules/use-sync-external-store/shim/index.js\");\n\n/**\n * inlined Object.is polyfill to avoid requiring consumers ship their own\n * https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/is\n */\nfunction is(x, y) {\n  return x === y && (x !== 0 || 1 / x === 1 / y) || x !== x && y !== y // eslint-disable-line no-self-compare\n  ;\n}\n\nvar objectIs = typeof Object.is === 'function' ? Object.is : is;\n\nvar useSyncExternalStore = shim.useSyncExternalStore;\n\n// for CommonJS interop.\n\nvar useRef = React.useRef,\n    useEffect = React.useEffect,\n    useMemo = React.useMemo,\n    useDebugValue = React.useDebugValue; // Same as useSyncExternalStore, but supports selector and isEqual arguments.\n\nfunction useSyncExternalStoreWithSelector(subscribe, getSnapshot, getServerSnapshot, selector, isEqual) {\n  // Use this to track the rendered snapshot.\n  var instRef = useRef(null);\n  var inst;\n\n  if (instRef.current === null) {\n    inst = {\n      hasValue: false,\n      value: null\n    };\n    instRef.current = inst;\n  } else {\n    inst = instRef.current;\n  }\n\n  var _useMemo = useMemo(function () {\n    // Track the memoized state using closure variables that are local to this\n    // memoized instance of a getSnapshot function. Intentionally not using a\n    // useRef hook, because that state would be shared across all concurrent\n    // copies of the hook/component.\n    var hasMemo = false;\n    var memoizedSnapshot;\n    var memoizedSelection;\n\n    var memoizedSelector = function (nextSnapshot) {\n      if (!hasMemo) {\n        // The first time the hook is called, there is no memoized result.\n        hasMemo = true;\n        memoizedSnapshot = nextSnapshot;\n\n        var _nextSelection = selector(nextSnapshot);\n\n        if (isEqual !== undefined) {\n          // Even if the selector has changed, the currently rendered selection\n          // may be equal to the new selection. We should attempt to reuse the\n          // current value if possible, to preserve downstream memoizations.\n          if (inst.hasValue) {\n            var currentSelection = inst.value;\n\n            if (isEqual(currentSelection, _nextSelection)) {\n              memoizedSelection = currentSelection;\n              return currentSelection;\n            }\n          }\n        }\n\n        memoizedSelection = _nextSelection;\n        return _nextSelection;\n      } // We may be able to reuse the previous invocation's result.\n\n\n      // We may be able to reuse the previous invocation's result.\n      var prevSnapshot = memoizedSnapshot;\n      var prevSelection = memoizedSelection;\n\n      if (objectIs(prevSnapshot, nextSnapshot)) {\n        // The snapshot is the same as last time. Reuse the previous selection.\n        return prevSelection;\n      } // The snapshot has changed, so we need to compute a new selection.\n\n\n      // The snapshot has changed, so we need to compute a new selection.\n      var nextSelection = selector(nextSnapshot); // If a custom isEqual function is provided, use that to check if the data\n      // has changed. If it hasn't, return the previous selection. That signals\n      // to React that the selections are conceptually equal, and we can bail\n      // out of rendering.\n\n      // If a custom isEqual function is provided, use that to check if the data\n      // has changed. If it hasn't, return the previous selection. That signals\n      // to React that the selections are conceptually equal, and we can bail\n      // out of rendering.\n      if (isEqual !== undefined && isEqual(prevSelection, nextSelection)) {\n        return prevSelection;\n      }\n\n      memoizedSnapshot = nextSnapshot;\n      memoizedSelection = nextSelection;\n      return nextSelection;\n    }; // Assigning this to a constant so that Flow knows it can't change.\n\n\n    // Assigning this to a constant so that Flow knows it can't change.\n    var maybeGetServerSnapshot = getServerSnapshot === undefined ? null : getServerSnapshot;\n\n    var getSnapshotWithSelector = function () {\n      return memoizedSelector(getSnapshot());\n    };\n\n    var getServerSnapshotWithSelector = maybeGetServerSnapshot === null ? undefined : function () {\n      return memoizedSelector(maybeGetServerSnapshot());\n    };\n    return [getSnapshotWithSelector, getServerSnapshotWithSelector];\n  }, [getSnapshot, getServerSnapshot, selector, isEqual]),\n      getSelection = _useMemo[0],\n      getServerSelection = _useMemo[1];\n\n  var value = useSyncExternalStore(subscribe, getSelection, getServerSelection);\n  useEffect(function () {\n    inst.hasValue = true;\n    inst.value = value;\n  }, [value]);\n  useDebugValue(value);\n  return value;\n}\n\nexports.useSyncExternalStoreWithSelector = useSyncExternalStoreWithSelector;\n          /* global __REACT_DEVTOOLS_GLOBAL_HOOK__ */\nif (\n  typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ !== 'undefined' &&\n  typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStop ===\n    'function'\n) {\n  __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStop(new Error());\n}\n        \n  })();\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/use-sync-external-store/cjs/use-sync-external-store-shim/with-selector.development.js?");

/***/ }),

/***/ "./node_modules/use-sync-external-store/shim/index.js":
/*!************************************************************!*\
  !*** ./node_modules/use-sync-external-store/shim/index.js ***!
  \************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nif (false) {} else {\n  module.exports = __webpack_require__(/*! ../cjs/use-sync-external-store-shim.development.js */ \"./node_modules/use-sync-external-store/cjs/use-sync-external-store-shim.development.js\");\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/use-sync-external-store/shim/index.js?");

/***/ }),

/***/ "./node_modules/use-sync-external-store/shim/with-selector.js":
/*!********************************************************************!*\
  !*** ./node_modules/use-sync-external-store/shim/with-selector.js ***!
  \********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nif (false) {} else {\n  module.exports = __webpack_require__(/*! ../cjs/use-sync-external-store-shim/with-selector.development.js */ \"./node_modules/use-sync-external-store/cjs/use-sync-external-store-shim/with-selector.development.js\");\n}\n\n\n//# sourceURL=webpack://renderer/./node_modules/use-sync-external-store/shim/with-selector.js?");

/***/ }),

/***/ "./node_modules/webidl-conversions/lib/index.js":
/*!******************************************************!*\
  !*** ./node_modules/webidl-conversions/lib/index.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nfunction makeException(ErrorType, message, options) {\n  if (options.globals) {\n    ErrorType = options.globals[ErrorType.name];\n  }\n  return new ErrorType(`${options.context ? options.context : \"Value\"} ${message}.`);\n}\n\nfunction toNumber(value, options) {\n  if (typeof value === \"bigint\") {\n    throw makeException(TypeError, \"is a BigInt which cannot be converted to a number\", options);\n  }\n  if (!options.globals) {\n    return Number(value);\n  }\n  return options.globals.Number(value);\n}\n\n// Round x to the nearest integer, choosing the even integer if it lies halfway between two.\nfunction evenRound(x) {\n  // There are four cases for numbers with fractional part being .5:\n  //\n  // case |     x     | floor(x) | round(x) | expected | x <> 0 | x % 1 | x & 1 |   example\n  //   1  |  2n + 0.5 |  2n      |  2n + 1  |  2n      |   >    |  0.5  |   0   |  0.5 ->  0\n  //   2  |  2n + 1.5 |  2n + 1  |  2n + 2  |  2n + 2  |   >    |  0.5  |   1   |  1.5 ->  2\n  //   3  | -2n - 0.5 | -2n - 1  | -2n      | -2n      |   <    | -0.5  |   0   | -0.5 ->  0\n  //   4  | -2n - 1.5 | -2n - 2  | -2n - 1  | -2n - 2  |   <    | -0.5  |   1   | -1.5 -> -2\n  // (where n is a non-negative integer)\n  //\n  // Branch here for cases 1 and 4\n  if ((x > 0 && (x % 1) === +0.5 && (x & 1) === 0) ||\n        (x < 0 && (x % 1) === -0.5 && (x & 1) === 1)) {\n    return censorNegativeZero(Math.floor(x));\n  }\n\n  return censorNegativeZero(Math.round(x));\n}\n\nfunction integerPart(n) {\n  return censorNegativeZero(Math.trunc(n));\n}\n\nfunction sign(x) {\n  return x < 0 ? -1 : 1;\n}\n\nfunction modulo(x, y) {\n  // https://tc39.github.io/ecma262/#eqn-modulo\n  // Note that http://stackoverflow.com/a/4467559/3191 does NOT work for large modulos\n  const signMightNotMatch = x % y;\n  if (sign(y) !== sign(signMightNotMatch)) {\n    return signMightNotMatch + y;\n  }\n  return signMightNotMatch;\n}\n\nfunction censorNegativeZero(x) {\n  return x === 0 ? 0 : x;\n}\n\nfunction createIntegerConversion(bitLength, { unsigned }) {\n  let lowerBound, upperBound;\n  if (unsigned) {\n    lowerBound = 0;\n    upperBound = 2 ** bitLength - 1;\n  } else {\n    lowerBound = -(2 ** (bitLength - 1));\n    upperBound = 2 ** (bitLength - 1) - 1;\n  }\n\n  const twoToTheBitLength = 2 ** bitLength;\n  const twoToOneLessThanTheBitLength = 2 ** (bitLength - 1);\n\n  return (value, options = {}) => {\n    let x = toNumber(value, options);\n    x = censorNegativeZero(x);\n\n    if (options.enforceRange) {\n      if (!Number.isFinite(x)) {\n        throw makeException(TypeError, \"is not a finite number\", options);\n      }\n\n      x = integerPart(x);\n\n      if (x < lowerBound || x > upperBound) {\n        throw makeException(\n          TypeError,\n          `is outside the accepted range of ${lowerBound} to ${upperBound}, inclusive`,\n          options\n        );\n      }\n\n      return x;\n    }\n\n    if (!Number.isNaN(x) && options.clamp) {\n      x = Math.min(Math.max(x, lowerBound), upperBound);\n      x = evenRound(x);\n      return x;\n    }\n\n    if (!Number.isFinite(x) || x === 0) {\n      return 0;\n    }\n    x = integerPart(x);\n\n    // Math.pow(2, 64) is not accurately representable in JavaScript, so try to avoid these per-spec operations if\n    // possible. Hopefully it's an optimization for the non-64-bitLength cases too.\n    if (x >= lowerBound && x <= upperBound) {\n      return x;\n    }\n\n    // These will not work great for bitLength of 64, but oh well. See the README for more details.\n    x = modulo(x, twoToTheBitLength);\n    if (!unsigned && x >= twoToOneLessThanTheBitLength) {\n      return x - twoToTheBitLength;\n    }\n    return x;\n  };\n}\n\nfunction createLongLongConversion(bitLength, { unsigned }) {\n  const upperBound = Number.MAX_SAFE_INTEGER;\n  const lowerBound = unsigned ? 0 : Number.MIN_SAFE_INTEGER;\n  const asBigIntN = unsigned ? BigInt.asUintN : BigInt.asIntN;\n\n  return (value, options = {}) => {\n    let x = toNumber(value, options);\n    x = censorNegativeZero(x);\n\n    if (options.enforceRange) {\n      if (!Number.isFinite(x)) {\n        throw makeException(TypeError, \"is not a finite number\", options);\n      }\n\n      x = integerPart(x);\n\n      if (x < lowerBound || x > upperBound) {\n        throw makeException(\n          TypeError,\n          `is outside the accepted range of ${lowerBound} to ${upperBound}, inclusive`,\n          options\n        );\n      }\n\n      return x;\n    }\n\n    if (!Number.isNaN(x) && options.clamp) {\n      x = Math.min(Math.max(x, lowerBound), upperBound);\n      x = evenRound(x);\n      return x;\n    }\n\n    if (!Number.isFinite(x) || x === 0) {\n      return 0;\n    }\n\n    let xBigInt = BigInt(integerPart(x));\n    xBigInt = asBigIntN(bitLength, xBigInt);\n    return Number(xBigInt);\n  };\n}\n\nexports.any = value => {\n  return value;\n};\n\nexports.undefined = () => {\n  return undefined;\n};\n\nexports.boolean = value => {\n  return Boolean(value);\n};\n\nexports.byte = createIntegerConversion(8, { unsigned: false });\nexports.octet = createIntegerConversion(8, { unsigned: true });\n\nexports.short = createIntegerConversion(16, { unsigned: false });\nexports[\"unsigned short\"] = createIntegerConversion(16, { unsigned: true });\n\nexports.long = createIntegerConversion(32, { unsigned: false });\nexports[\"unsigned long\"] = createIntegerConversion(32, { unsigned: true });\n\nexports[\"long long\"] = createLongLongConversion(64, { unsigned: false });\nexports[\"unsigned long long\"] = createLongLongConversion(64, { unsigned: true });\n\nexports.double = (value, options = {}) => {\n  const x = toNumber(value, options);\n\n  if (!Number.isFinite(x)) {\n    throw makeException(TypeError, \"is not a finite floating-point value\", options);\n  }\n\n  return x;\n};\n\nexports[\"unrestricted double\"] = (value, options = {}) => {\n  const x = toNumber(value, options);\n\n  return x;\n};\n\nexports.float = (value, options = {}) => {\n  const x = toNumber(value, options);\n\n  if (!Number.isFinite(x)) {\n    throw makeException(TypeError, \"is not a finite floating-point value\", options);\n  }\n\n  if (Object.is(x, -0)) {\n    return x;\n  }\n\n  const y = Math.fround(x);\n\n  if (!Number.isFinite(y)) {\n    throw makeException(TypeError, \"is outside the range of a single-precision floating-point value\", options);\n  }\n\n  return y;\n};\n\nexports[\"unrestricted float\"] = (value, options = {}) => {\n  const x = toNumber(value, options);\n\n  if (isNaN(x)) {\n    return x;\n  }\n\n  if (Object.is(x, -0)) {\n    return x;\n  }\n\n  return Math.fround(x);\n};\n\nexports.DOMString = (value, options = {}) => {\n  if (options.treatNullAsEmptyString && value === null) {\n    return \"\";\n  }\n\n  if (typeof value === \"symbol\") {\n    throw makeException(TypeError, \"is a symbol, which cannot be converted to a string\", options);\n  }\n\n  const StringCtor = options.globals ? options.globals.String : String;\n  return StringCtor(value);\n};\n\nexports.ByteString = (value, options = {}) => {\n  const x = exports.DOMString(value, options);\n  let c;\n  for (let i = 0; (c = x.codePointAt(i)) !== undefined; ++i) {\n    if (c > 255) {\n      throw makeException(TypeError, \"is not a valid ByteString\", options);\n    }\n  }\n\n  return x;\n};\n\nexports.USVString = (value, options = {}) => {\n  const S = exports.DOMString(value, options);\n  const n = S.length;\n  const U = [];\n  for (let i = 0; i < n; ++i) {\n    const c = S.charCodeAt(i);\n    if (c < 0xD800 || c > 0xDFFF) {\n      U.push(String.fromCodePoint(c));\n    } else if (0xDC00 <= c && c <= 0xDFFF) {\n      U.push(String.fromCodePoint(0xFFFD));\n    } else if (i === n - 1) {\n      U.push(String.fromCodePoint(0xFFFD));\n    } else {\n      const d = S.charCodeAt(i + 1);\n      if (0xDC00 <= d && d <= 0xDFFF) {\n        const a = c & 0x3FF;\n        const b = d & 0x3FF;\n        U.push(String.fromCodePoint((2 << 15) + ((2 << 9) * a) + b));\n        ++i;\n      } else {\n        U.push(String.fromCodePoint(0xFFFD));\n      }\n    }\n  }\n\n  return U.join(\"\");\n};\n\nexports.object = (value, options = {}) => {\n  if (value === null || (typeof value !== \"object\" && typeof value !== \"function\")) {\n    throw makeException(TypeError, \"is not an object\", options);\n  }\n\n  return value;\n};\n\nconst abByteLengthGetter =\n    Object.getOwnPropertyDescriptor(ArrayBuffer.prototype, \"byteLength\").get;\nconst sabByteLengthGetter =\n    typeof SharedArrayBuffer === \"function\" ?\n      Object.getOwnPropertyDescriptor(SharedArrayBuffer.prototype, \"byteLength\").get :\n      null;\n\nfunction isNonSharedArrayBuffer(value) {\n  try {\n    // This will throw on SharedArrayBuffers, but not detached ArrayBuffers.\n    // (The spec says it should throw, but the spec conflicts with implementations: https://github.com/tc39/ecma262/issues/678)\n    abByteLengthGetter.call(value);\n\n    return true;\n  } catch {\n    return false;\n  }\n}\n\nfunction isSharedArrayBuffer(value) {\n  try {\n    sabByteLengthGetter.call(value);\n    return true;\n  } catch {\n    return false;\n  }\n}\n\nfunction isArrayBufferDetached(value) {\n  try {\n    // eslint-disable-next-line no-new\n    new Uint8Array(value);\n    return false;\n  } catch {\n    return true;\n  }\n}\n\nexports.ArrayBuffer = (value, options = {}) => {\n  if (!isNonSharedArrayBuffer(value)) {\n    if (options.allowShared && !isSharedArrayBuffer(value)) {\n      throw makeException(TypeError, \"is not an ArrayBuffer or SharedArrayBuffer\", options);\n    }\n    throw makeException(TypeError, \"is not an ArrayBuffer\", options);\n  }\n  if (isArrayBufferDetached(value)) {\n    throw makeException(TypeError, \"is a detached ArrayBuffer\", options);\n  }\n\n  return value;\n};\n\nconst dvByteLengthGetter =\n    Object.getOwnPropertyDescriptor(DataView.prototype, \"byteLength\").get;\nexports.DataView = (value, options = {}) => {\n  try {\n    dvByteLengthGetter.call(value);\n  } catch (e) {\n    throw makeException(TypeError, \"is not a DataView\", options);\n  }\n\n  if (!options.allowShared && isSharedArrayBuffer(value.buffer)) {\n    throw makeException(TypeError, \"is backed by a SharedArrayBuffer, which is not allowed\", options);\n  }\n  if (isArrayBufferDetached(value.buffer)) {\n    throw makeException(TypeError, \"is backed by a detached ArrayBuffer\", options);\n  }\n\n  return value;\n};\n\n// Returns the unforgeable `TypedArray` constructor name or `undefined`,\n// if the `this` value isn't a valid `TypedArray` object.\n//\n// https://tc39.es/ecma262/#sec-get-%typedarray%.prototype-@@tostringtag\nconst typedArrayNameGetter = Object.getOwnPropertyDescriptor(\n  Object.getPrototypeOf(Uint8Array).prototype,\n  Symbol.toStringTag\n).get;\n[\n  Int8Array,\n  Int16Array,\n  Int32Array,\n  Uint8Array,\n  Uint16Array,\n  Uint32Array,\n  Uint8ClampedArray,\n  Float32Array,\n  Float64Array\n].forEach(func => {\n  const { name } = func;\n  const article = /^[AEIOU]/u.test(name) ? \"an\" : \"a\";\n  exports[name] = (value, options = {}) => {\n    if (!ArrayBuffer.isView(value) || typedArrayNameGetter.call(value) !== name) {\n      throw makeException(TypeError, `is not ${article} ${name} object`, options);\n    }\n    if (!options.allowShared && isSharedArrayBuffer(value.buffer)) {\n      throw makeException(TypeError, \"is a view on a SharedArrayBuffer, which is not allowed\", options);\n    }\n    if (isArrayBufferDetached(value.buffer)) {\n      throw makeException(TypeError, \"is a view on a detached ArrayBuffer\", options);\n    }\n\n    return value;\n  };\n});\n\n// Common definitions\n\nexports.ArrayBufferView = (value, options = {}) => {\n  if (!ArrayBuffer.isView(value)) {\n    throw makeException(TypeError, \"is not a view on an ArrayBuffer or SharedArrayBuffer\", options);\n  }\n\n  if (!options.allowShared && isSharedArrayBuffer(value.buffer)) {\n    throw makeException(TypeError, \"is a view on a SharedArrayBuffer, which is not allowed\", options);\n  }\n\n  if (isArrayBufferDetached(value.buffer)) {\n    throw makeException(TypeError, \"is a view on a detached ArrayBuffer\", options);\n  }\n  return value;\n};\n\nexports.BufferSource = (value, options = {}) => {\n  if (ArrayBuffer.isView(value)) {\n    if (!options.allowShared && isSharedArrayBuffer(value.buffer)) {\n      throw makeException(TypeError, \"is a view on a SharedArrayBuffer, which is not allowed\", options);\n    }\n\n    if (isArrayBufferDetached(value.buffer)) {\n      throw makeException(TypeError, \"is a view on a detached ArrayBuffer\", options);\n    }\n    return value;\n  }\n\n  if (!options.allowShared && !isNonSharedArrayBuffer(value)) {\n    throw makeException(TypeError, \"is not an ArrayBuffer or a view on one\", options);\n  }\n  if (options.allowShared && !isSharedArrayBuffer(value) && !isNonSharedArrayBuffer(value)) {\n    throw makeException(TypeError, \"is not an ArrayBuffer, SharedArrayBuffer, or a view on one\", options);\n  }\n  if (isArrayBufferDetached(value)) {\n    throw makeException(TypeError, \"is a detached ArrayBuffer\", options);\n  }\n\n  return value;\n};\n\nexports.DOMTimeStamp = exports[\"unsigned long long\"];\n\n\n//# sourceURL=webpack://renderer/./node_modules/webidl-conversions/lib/index.js?");

/***/ }),

/***/ "?5938":
/*!********************!*\
  !*** dll renderer ***!
  \********************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("module.exports = __webpack_require__;\n\n//# sourceURL=webpack://renderer/dll_renderer?");

/***/ }),

/***/ "assert":
/*!*************************!*\
  !*** external "assert" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("assert");

/***/ }),

/***/ "buffer":
/*!*************************!*\
  !*** external "buffer" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("buffer");

/***/ }),

/***/ "child_process":
/*!********************************!*\
  !*** external "child_process" ***!
  \********************************/
/***/ ((module) => {

"use strict";
module.exports = require("child_process");

/***/ }),

/***/ "constants":
/*!****************************!*\
  !*** external "constants" ***!
  \****************************/
/***/ ((module) => {

"use strict";
module.exports = require("constants");

/***/ }),

/***/ "crypto":
/*!*************************!*\
  !*** external "crypto" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("crypto");

/***/ }),

/***/ "dns":
/*!**********************!*\
  !*** external "dns" ***!
  \**********************/
/***/ ((module) => {

"use strict";
module.exports = require("dns");

/***/ }),

/***/ "electron":
/*!***************************!*\
  !*** external "electron" ***!
  \***************************/
/***/ ((module) => {

"use strict";
module.exports = require("electron");

/***/ }),

/***/ "events":
/*!*************************!*\
  !*** external "events" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("events");

/***/ }),

/***/ "fs":
/*!*********************!*\
  !*** external "fs" ***!
  \*********************/
/***/ ((module) => {

"use strict";
module.exports = require("fs");

/***/ }),

/***/ "fs/promises":
/*!******************************!*\
  !*** external "fs/promises" ***!
  \******************************/
/***/ ((module) => {

"use strict";
module.exports = require("fs/promises");

/***/ }),

/***/ "http":
/*!***********************!*\
  !*** external "http" ***!
  \***********************/
/***/ ((module) => {

"use strict";
module.exports = require("http");

/***/ }),

/***/ "https":
/*!************************!*\
  !*** external "https" ***!
  \************************/
/***/ ((module) => {

"use strict";
module.exports = require("https");

/***/ }),

/***/ "net":
/*!**********************!*\
  !*** external "net" ***!
  \**********************/
/***/ ((module) => {

"use strict";
module.exports = require("net");

/***/ }),

/***/ "os":
/*!*********************!*\
  !*** external "os" ***!
  \*********************/
/***/ ((module) => {

"use strict";
module.exports = require("os");

/***/ }),

/***/ "path":
/*!***********************!*\
  !*** external "path" ***!
  \***********************/
/***/ ((module) => {

"use strict";
module.exports = require("path");

/***/ }),

/***/ "process":
/*!**************************!*\
  !*** external "process" ***!
  \**************************/
/***/ ((module) => {

"use strict";
module.exports = require("process");

/***/ }),

/***/ "querystring":
/*!******************************!*\
  !*** external "querystring" ***!
  \******************************/
/***/ ((module) => {

"use strict";
module.exports = require("querystring");

/***/ }),

/***/ "stream":
/*!*************************!*\
  !*** external "stream" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("stream");

/***/ }),

/***/ "string_decoder":
/*!*********************************!*\
  !*** external "string_decoder" ***!
  \*********************************/
/***/ ((module) => {

"use strict";
module.exports = require("string_decoder");

/***/ }),

/***/ "timers":
/*!*************************!*\
  !*** external "timers" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("timers");

/***/ }),

/***/ "tls":
/*!**********************!*\
  !*** external "tls" ***!
  \**********************/
/***/ ((module) => {

"use strict";
module.exports = require("tls");

/***/ }),

/***/ "url":
/*!**********************!*\
  !*** external "url" ***!
  \**********************/
/***/ ((module) => {

"use strict";
module.exports = require("url");

/***/ }),

/***/ "util":
/*!***********************!*\
  !*** external "util" ***!
  \***********************/
/***/ ((module) => {

"use strict";
module.exports = require("util");

/***/ }),

/***/ "zlib":
/*!***********************!*\
  !*** external "zlib" ***!
  \***********************/
/***/ ((module) => {

"use strict";
module.exports = require("zlib");

/***/ }),

/***/ "./node_modules/bson/lib/bson.cjs":
/*!****************************************!*\
  !*** ./node_modules/bson/lib/bson.cjs ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nfunction isAnyArrayBuffer(value) {\n    return ['[object ArrayBuffer]', '[object SharedArrayBuffer]'].includes(Object.prototype.toString.call(value));\n}\nfunction isUint8Array(value) {\n    return Object.prototype.toString.call(value) === '[object Uint8Array]';\n}\nfunction isRegExp(d) {\n    return Object.prototype.toString.call(d) === '[object RegExp]';\n}\nfunction isMap(d) {\n    return Object.prototype.toString.call(d) === '[object Map]';\n}\nfunction isDate(d) {\n    return Object.prototype.toString.call(d) === '[object Date]';\n}\nfunction defaultInspect(x, _options) {\n    return JSON.stringify(x, (k, v) => {\n        if (typeof v === 'bigint') {\n            return { $numberLong: `${v}` };\n        }\n        else if (isMap(v)) {\n            return Object.fromEntries(v);\n        }\n        return v;\n    });\n}\nfunction getStylizeFunction(options) {\n    const stylizeExists = options != null &&\n        typeof options === 'object' &&\n        'stylize' in options &&\n        typeof options.stylize === 'function';\n    if (stylizeExists) {\n        return options.stylize;\n    }\n}\n\nconst BSON_MAJOR_VERSION = 6;\nconst BSON_INT32_MAX = 0x7fffffff;\nconst BSON_INT32_MIN = -0x80000000;\nconst BSON_INT64_MAX = Math.pow(2, 63) - 1;\nconst BSON_INT64_MIN = -Math.pow(2, 63);\nconst JS_INT_MAX = Math.pow(2, 53);\nconst JS_INT_MIN = -Math.pow(2, 53);\nconst BSON_DATA_NUMBER = 1;\nconst BSON_DATA_STRING = 2;\nconst BSON_DATA_OBJECT = 3;\nconst BSON_DATA_ARRAY = 4;\nconst BSON_DATA_BINARY = 5;\nconst BSON_DATA_UNDEFINED = 6;\nconst BSON_DATA_OID = 7;\nconst BSON_DATA_BOOLEAN = 8;\nconst BSON_DATA_DATE = 9;\nconst BSON_DATA_NULL = 10;\nconst BSON_DATA_REGEXP = 11;\nconst BSON_DATA_DBPOINTER = 12;\nconst BSON_DATA_CODE = 13;\nconst BSON_DATA_SYMBOL = 14;\nconst BSON_DATA_CODE_W_SCOPE = 15;\nconst BSON_DATA_INT = 16;\nconst BSON_DATA_TIMESTAMP = 17;\nconst BSON_DATA_LONG = 18;\nconst BSON_DATA_DECIMAL128 = 19;\nconst BSON_DATA_MIN_KEY = 0xff;\nconst BSON_DATA_MAX_KEY = 0x7f;\nconst BSON_BINARY_SUBTYPE_DEFAULT = 0;\nconst BSON_BINARY_SUBTYPE_UUID_NEW = 4;\nconst BSONType = Object.freeze({\n    double: 1,\n    string: 2,\n    object: 3,\n    array: 4,\n    binData: 5,\n    undefined: 6,\n    objectId: 7,\n    bool: 8,\n    date: 9,\n    null: 10,\n    regex: 11,\n    dbPointer: 12,\n    javascript: 13,\n    symbol: 14,\n    javascriptWithScope: 15,\n    int: 16,\n    timestamp: 17,\n    long: 18,\n    decimal: 19,\n    minKey: -1,\n    maxKey: 127\n});\n\nclass BSONError extends Error {\n    get bsonError() {\n        return true;\n    }\n    get name() {\n        return 'BSONError';\n    }\n    constructor(message) {\n        super(message);\n    }\n    static isBSONError(value) {\n        return (value != null &&\n            typeof value === 'object' &&\n            'bsonError' in value &&\n            value.bsonError === true &&\n            'name' in value &&\n            'message' in value &&\n            'stack' in value);\n    }\n}\nclass BSONVersionError extends BSONError {\n    get name() {\n        return 'BSONVersionError';\n    }\n    constructor() {\n        super(`Unsupported BSON version, bson types must be from bson ${BSON_MAJOR_VERSION}.x.x`);\n    }\n}\nclass BSONRuntimeError extends BSONError {\n    get name() {\n        return 'BSONRuntimeError';\n    }\n    constructor(message) {\n        super(message);\n    }\n}\n\nfunction nodejsMathRandomBytes(byteLength) {\n    return nodeJsByteUtils.fromNumberArray(Array.from({ length: byteLength }, () => Math.floor(Math.random() * 256)));\n}\nconst nodejsRandomBytes = (() => {\n    try {\n        return (__webpack_require__(/*! crypto */ \"crypto\").randomBytes);\n    }\n    catch {\n        return nodejsMathRandomBytes;\n    }\n})();\nconst nodeJsByteUtils = {\n    toLocalBufferType(potentialBuffer) {\n        if (Buffer.isBuffer(potentialBuffer)) {\n            return potentialBuffer;\n        }\n        if (ArrayBuffer.isView(potentialBuffer)) {\n            return Buffer.from(potentialBuffer.buffer, potentialBuffer.byteOffset, potentialBuffer.byteLength);\n        }\n        const stringTag = potentialBuffer?.[Symbol.toStringTag] ?? Object.prototype.toString.call(potentialBuffer);\n        if (stringTag === 'ArrayBuffer' ||\n            stringTag === 'SharedArrayBuffer' ||\n            stringTag === '[object ArrayBuffer]' ||\n            stringTag === '[object SharedArrayBuffer]') {\n            return Buffer.from(potentialBuffer);\n        }\n        throw new BSONError(`Cannot create Buffer from ${String(potentialBuffer)}`);\n    },\n    allocate(size) {\n        return Buffer.alloc(size);\n    },\n    equals(a, b) {\n        return nodeJsByteUtils.toLocalBufferType(a).equals(b);\n    },\n    fromNumberArray(array) {\n        return Buffer.from(array);\n    },\n    fromBase64(base64) {\n        return Buffer.from(base64, 'base64');\n    },\n    toBase64(buffer) {\n        return nodeJsByteUtils.toLocalBufferType(buffer).toString('base64');\n    },\n    fromISO88591(codePoints) {\n        return Buffer.from(codePoints, 'binary');\n    },\n    toISO88591(buffer) {\n        return nodeJsByteUtils.toLocalBufferType(buffer).toString('binary');\n    },\n    fromHex(hex) {\n        return Buffer.from(hex, 'hex');\n    },\n    toHex(buffer) {\n        return nodeJsByteUtils.toLocalBufferType(buffer).toString('hex');\n    },\n    fromUTF8(text) {\n        return Buffer.from(text, 'utf8');\n    },\n    toUTF8(buffer, start, end) {\n        return nodeJsByteUtils.toLocalBufferType(buffer).toString('utf8', start, end);\n    },\n    utf8ByteLength(input) {\n        return Buffer.byteLength(input, 'utf8');\n    },\n    encodeUTF8Into(buffer, source, byteOffset) {\n        return nodeJsByteUtils.toLocalBufferType(buffer).write(source, byteOffset, undefined, 'utf8');\n    },\n    randomBytes: nodejsRandomBytes\n};\n\nfunction isReactNative() {\n    const { navigator } = globalThis;\n    return typeof navigator === 'object' && navigator.product === 'ReactNative';\n}\nfunction webMathRandomBytes(byteLength) {\n    if (byteLength < 0) {\n        throw new RangeError(`The argument 'byteLength' is invalid. Received ${byteLength}`);\n    }\n    return webByteUtils.fromNumberArray(Array.from({ length: byteLength }, () => Math.floor(Math.random() * 256)));\n}\nconst webRandomBytes = (() => {\n    const { crypto } = globalThis;\n    if (crypto != null && typeof crypto.getRandomValues === 'function') {\n        return (byteLength) => {\n            return crypto.getRandomValues(webByteUtils.allocate(byteLength));\n        };\n    }\n    else {\n        if (isReactNative()) {\n            const { console } = globalThis;\n            console?.warn?.('BSON: For React Native please polyfill crypto.getRandomValues, e.g. using: https://www.npmjs.com/package/react-native-get-random-values.');\n        }\n        return webMathRandomBytes;\n    }\n})();\nconst HEX_DIGIT = /(\\d|[a-f])/i;\nconst webByteUtils = {\n    toLocalBufferType(potentialUint8array) {\n        const stringTag = potentialUint8array?.[Symbol.toStringTag] ??\n            Object.prototype.toString.call(potentialUint8array);\n        if (stringTag === 'Uint8Array') {\n            return potentialUint8array;\n        }\n        if (ArrayBuffer.isView(potentialUint8array)) {\n            return new Uint8Array(potentialUint8array.buffer.slice(potentialUint8array.byteOffset, potentialUint8array.byteOffset + potentialUint8array.byteLength));\n        }\n        if (stringTag === 'ArrayBuffer' ||\n            stringTag === 'SharedArrayBuffer' ||\n            stringTag === '[object ArrayBuffer]' ||\n            stringTag === '[object SharedArrayBuffer]') {\n            return new Uint8Array(potentialUint8array);\n        }\n        throw new BSONError(`Cannot make a Uint8Array from ${String(potentialUint8array)}`);\n    },\n    allocate(size) {\n        if (typeof size !== 'number') {\n            throw new TypeError(`The \"size\" argument must be of type number. Received ${String(size)}`);\n        }\n        return new Uint8Array(size);\n    },\n    equals(a, b) {\n        if (a.byteLength !== b.byteLength) {\n            return false;\n        }\n        for (let i = 0; i < a.byteLength; i++) {\n            if (a[i] !== b[i]) {\n                return false;\n            }\n        }\n        return true;\n    },\n    fromNumberArray(array) {\n        return Uint8Array.from(array);\n    },\n    fromBase64(base64) {\n        return Uint8Array.from(atob(base64), c => c.charCodeAt(0));\n    },\n    toBase64(uint8array) {\n        return btoa(webByteUtils.toISO88591(uint8array));\n    },\n    fromISO88591(codePoints) {\n        return Uint8Array.from(codePoints, c => c.charCodeAt(0) & 0xff);\n    },\n    toISO88591(uint8array) {\n        return Array.from(Uint16Array.from(uint8array), b => String.fromCharCode(b)).join('');\n    },\n    fromHex(hex) {\n        const evenLengthHex = hex.length % 2 === 0 ? hex : hex.slice(0, hex.length - 1);\n        const buffer = [];\n        for (let i = 0; i < evenLengthHex.length; i += 2) {\n            const firstDigit = evenLengthHex[i];\n            const secondDigit = evenLengthHex[i + 1];\n            if (!HEX_DIGIT.test(firstDigit)) {\n                break;\n            }\n            if (!HEX_DIGIT.test(secondDigit)) {\n                break;\n            }\n            const hexDigit = Number.parseInt(`${firstDigit}${secondDigit}`, 16);\n            buffer.push(hexDigit);\n        }\n        return Uint8Array.from(buffer);\n    },\n    toHex(uint8array) {\n        return Array.from(uint8array, byte => byte.toString(16).padStart(2, '0')).join('');\n    },\n    fromUTF8(text) {\n        return new TextEncoder().encode(text);\n    },\n    toUTF8(uint8array, start, end) {\n        return new TextDecoder('utf8', { fatal: false }).decode(uint8array.slice(start, end));\n    },\n    utf8ByteLength(input) {\n        return webByteUtils.fromUTF8(input).byteLength;\n    },\n    encodeUTF8Into(buffer, source, byteOffset) {\n        const bytes = webByteUtils.fromUTF8(source);\n        buffer.set(bytes, byteOffset);\n        return bytes.byteLength;\n    },\n    randomBytes: webRandomBytes\n};\n\nconst hasGlobalBuffer = typeof Buffer === 'function' && Buffer.prototype?._isBuffer !== true;\nconst ByteUtils = hasGlobalBuffer ? nodeJsByteUtils : webByteUtils;\nclass BSONDataView extends DataView {\n    static fromUint8Array(input) {\n        return new DataView(input.buffer, input.byteOffset, input.byteLength);\n    }\n}\n\nclass BSONValue {\n    get [Symbol.for('@@mdb.bson.version')]() {\n        return BSON_MAJOR_VERSION;\n    }\n    [Symbol.for('nodejs.util.inspect.custom')](depth, options, inspect) {\n        return this.inspect(depth, options, inspect);\n    }\n}\n\nclass Binary extends BSONValue {\n    get _bsontype() {\n        return 'Binary';\n    }\n    constructor(buffer, subType) {\n        super();\n        if (!(buffer == null) &&\n            typeof buffer === 'string' &&\n            !ArrayBuffer.isView(buffer) &&\n            !isAnyArrayBuffer(buffer) &&\n            !Array.isArray(buffer)) {\n            throw new BSONError('Binary can only be constructed from Uint8Array or number[]');\n        }\n        this.sub_type = subType ?? Binary.BSON_BINARY_SUBTYPE_DEFAULT;\n        if (buffer == null) {\n            this.buffer = ByteUtils.allocate(Binary.BUFFER_SIZE);\n            this.position = 0;\n        }\n        else {\n            this.buffer = Array.isArray(buffer)\n                ? ByteUtils.fromNumberArray(buffer)\n                : ByteUtils.toLocalBufferType(buffer);\n            this.position = this.buffer.byteLength;\n        }\n    }\n    put(byteValue) {\n        if (typeof byteValue === 'string' && byteValue.length !== 1) {\n            throw new BSONError('only accepts single character String');\n        }\n        else if (typeof byteValue !== 'number' && byteValue.length !== 1)\n            throw new BSONError('only accepts single character Uint8Array or Array');\n        let decodedByte;\n        if (typeof byteValue === 'string') {\n            decodedByte = byteValue.charCodeAt(0);\n        }\n        else if (typeof byteValue === 'number') {\n            decodedByte = byteValue;\n        }\n        else {\n            decodedByte = byteValue[0];\n        }\n        if (decodedByte < 0 || decodedByte > 255) {\n            throw new BSONError('only accepts number in a valid unsigned byte range 0-255');\n        }\n        if (this.buffer.byteLength > this.position) {\n            this.buffer[this.position++] = decodedByte;\n        }\n        else {\n            const newSpace = ByteUtils.allocate(Binary.BUFFER_SIZE + this.buffer.length);\n            newSpace.set(this.buffer, 0);\n            this.buffer = newSpace;\n            this.buffer[this.position++] = decodedByte;\n        }\n    }\n    write(sequence, offset) {\n        offset = typeof offset === 'number' ? offset : this.position;\n        if (this.buffer.byteLength < offset + sequence.length) {\n            const newSpace = ByteUtils.allocate(this.buffer.byteLength + sequence.length);\n            newSpace.set(this.buffer, 0);\n            this.buffer = newSpace;\n        }\n        if (ArrayBuffer.isView(sequence)) {\n            this.buffer.set(ByteUtils.toLocalBufferType(sequence), offset);\n            this.position =\n                offset + sequence.byteLength > this.position ? offset + sequence.length : this.position;\n        }\n        else if (typeof sequence === 'string') {\n            throw new BSONError('input cannot be string');\n        }\n    }\n    read(position, length) {\n        length = length && length > 0 ? length : this.position;\n        return this.buffer.slice(position, position + length);\n    }\n    value() {\n        return this.buffer.length === this.position\n            ? this.buffer\n            : this.buffer.subarray(0, this.position);\n    }\n    length() {\n        return this.position;\n    }\n    toJSON() {\n        return ByteUtils.toBase64(this.buffer);\n    }\n    toString(encoding) {\n        if (encoding === 'hex')\n            return ByteUtils.toHex(this.buffer);\n        if (encoding === 'base64')\n            return ByteUtils.toBase64(this.buffer);\n        if (encoding === 'utf8' || encoding === 'utf-8')\n            return ByteUtils.toUTF8(this.buffer, 0, this.buffer.byteLength);\n        return ByteUtils.toUTF8(this.buffer, 0, this.buffer.byteLength);\n    }\n    toExtendedJSON(options) {\n        options = options || {};\n        const base64String = ByteUtils.toBase64(this.buffer);\n        const subType = Number(this.sub_type).toString(16);\n        if (options.legacy) {\n            return {\n                $binary: base64String,\n                $type: subType.length === 1 ? '0' + subType : subType\n            };\n        }\n        return {\n            $binary: {\n                base64: base64String,\n                subType: subType.length === 1 ? '0' + subType : subType\n            }\n        };\n    }\n    toUUID() {\n        if (this.sub_type === Binary.SUBTYPE_UUID) {\n            return new UUID(this.buffer.slice(0, this.position));\n        }\n        throw new BSONError(`Binary sub_type \"${this.sub_type}\" is not supported for converting to UUID. Only \"${Binary.SUBTYPE_UUID}\" is currently supported.`);\n    }\n    static createFromHexString(hex, subType) {\n        return new Binary(ByteUtils.fromHex(hex), subType);\n    }\n    static createFromBase64(base64, subType) {\n        return new Binary(ByteUtils.fromBase64(base64), subType);\n    }\n    static fromExtendedJSON(doc, options) {\n        options = options || {};\n        let data;\n        let type;\n        if ('$binary' in doc) {\n            if (options.legacy && typeof doc.$binary === 'string' && '$type' in doc) {\n                type = doc.$type ? parseInt(doc.$type, 16) : 0;\n                data = ByteUtils.fromBase64(doc.$binary);\n            }\n            else {\n                if (typeof doc.$binary !== 'string') {\n                    type = doc.$binary.subType ? parseInt(doc.$binary.subType, 16) : 0;\n                    data = ByteUtils.fromBase64(doc.$binary.base64);\n                }\n            }\n        }\n        else if ('$uuid' in doc) {\n            type = 4;\n            data = UUID.bytesFromString(doc.$uuid);\n        }\n        if (!data) {\n            throw new BSONError(`Unexpected Binary Extended JSON format ${JSON.stringify(doc)}`);\n        }\n        return type === BSON_BINARY_SUBTYPE_UUID_NEW ? new UUID(data) : new Binary(data, type);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        const base64 = ByteUtils.toBase64(this.buffer.subarray(0, this.position));\n        const base64Arg = inspect(base64, options);\n        const subTypeArg = inspect(this.sub_type, options);\n        return `Binary.createFromBase64(${base64Arg}, ${subTypeArg})`;\n    }\n}\nBinary.BSON_BINARY_SUBTYPE_DEFAULT = 0;\nBinary.BUFFER_SIZE = 256;\nBinary.SUBTYPE_DEFAULT = 0;\nBinary.SUBTYPE_FUNCTION = 1;\nBinary.SUBTYPE_BYTE_ARRAY = 2;\nBinary.SUBTYPE_UUID_OLD = 3;\nBinary.SUBTYPE_UUID = 4;\nBinary.SUBTYPE_MD5 = 5;\nBinary.SUBTYPE_ENCRYPTED = 6;\nBinary.SUBTYPE_COLUMN = 7;\nBinary.SUBTYPE_USER_DEFINED = 128;\nconst UUID_BYTE_LENGTH = 16;\nconst UUID_WITHOUT_DASHES = /^[0-9A-F]{32}$/i;\nconst UUID_WITH_DASHES = /^[0-9A-F]{8}-[0-9A-F]{4}-[0-9A-F]{4}-[0-9A-F]{4}-[0-9A-F]{12}$/i;\nclass UUID extends Binary {\n    constructor(input) {\n        let bytes;\n        if (input == null) {\n            bytes = UUID.generate();\n        }\n        else if (input instanceof UUID) {\n            bytes = ByteUtils.toLocalBufferType(new Uint8Array(input.buffer));\n        }\n        else if (ArrayBuffer.isView(input) && input.byteLength === UUID_BYTE_LENGTH) {\n            bytes = ByteUtils.toLocalBufferType(input);\n        }\n        else if (typeof input === 'string') {\n            bytes = UUID.bytesFromString(input);\n        }\n        else {\n            throw new BSONError('Argument passed in UUID constructor must be a UUID, a 16 byte Buffer or a 32/36 character hex string (dashes excluded/included, format: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx).');\n        }\n        super(bytes, BSON_BINARY_SUBTYPE_UUID_NEW);\n    }\n    get id() {\n        return this.buffer;\n    }\n    set id(value) {\n        this.buffer = value;\n    }\n    toHexString(includeDashes = true) {\n        if (includeDashes) {\n            return [\n                ByteUtils.toHex(this.buffer.subarray(0, 4)),\n                ByteUtils.toHex(this.buffer.subarray(4, 6)),\n                ByteUtils.toHex(this.buffer.subarray(6, 8)),\n                ByteUtils.toHex(this.buffer.subarray(8, 10)),\n                ByteUtils.toHex(this.buffer.subarray(10, 16))\n            ].join('-');\n        }\n        return ByteUtils.toHex(this.buffer);\n    }\n    toString(encoding) {\n        if (encoding === 'hex')\n            return ByteUtils.toHex(this.id);\n        if (encoding === 'base64')\n            return ByteUtils.toBase64(this.id);\n        return this.toHexString();\n    }\n    toJSON() {\n        return this.toHexString();\n    }\n    equals(otherId) {\n        if (!otherId) {\n            return false;\n        }\n        if (otherId instanceof UUID) {\n            return ByteUtils.equals(otherId.id, this.id);\n        }\n        try {\n            return ByteUtils.equals(new UUID(otherId).id, this.id);\n        }\n        catch {\n            return false;\n        }\n    }\n    toBinary() {\n        return new Binary(this.id, Binary.SUBTYPE_UUID);\n    }\n    static generate() {\n        const bytes = ByteUtils.randomBytes(UUID_BYTE_LENGTH);\n        bytes[6] = (bytes[6] & 0x0f) | 0x40;\n        bytes[8] = (bytes[8] & 0x3f) | 0x80;\n        return bytes;\n    }\n    static isValid(input) {\n        if (!input) {\n            return false;\n        }\n        if (typeof input === 'string') {\n            return UUID.isValidUUIDString(input);\n        }\n        if (isUint8Array(input)) {\n            return input.byteLength === UUID_BYTE_LENGTH;\n        }\n        return (input._bsontype === 'Binary' &&\n            input.sub_type === this.SUBTYPE_UUID &&\n            input.buffer.byteLength === 16);\n    }\n    static createFromHexString(hexString) {\n        const buffer = UUID.bytesFromString(hexString);\n        return new UUID(buffer);\n    }\n    static createFromBase64(base64) {\n        return new UUID(ByteUtils.fromBase64(base64));\n    }\n    static bytesFromString(representation) {\n        if (!UUID.isValidUUIDString(representation)) {\n            throw new BSONError('UUID string representation must be 32 hex digits or canonical hyphenated representation');\n        }\n        return ByteUtils.fromHex(representation.replace(/-/g, ''));\n    }\n    static isValidUUIDString(representation) {\n        return UUID_WITHOUT_DASHES.test(representation) || UUID_WITH_DASHES.test(representation);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        return `new UUID(${inspect(this.toHexString(), options)})`;\n    }\n}\n\nclass Code extends BSONValue {\n    get _bsontype() {\n        return 'Code';\n    }\n    constructor(code, scope) {\n        super();\n        this.code = code.toString();\n        this.scope = scope ?? null;\n    }\n    toJSON() {\n        if (this.scope != null) {\n            return { code: this.code, scope: this.scope };\n        }\n        return { code: this.code };\n    }\n    toExtendedJSON() {\n        if (this.scope) {\n            return { $code: this.code, $scope: this.scope };\n        }\n        return { $code: this.code };\n    }\n    static fromExtendedJSON(doc) {\n        return new Code(doc.$code, doc.$scope);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        let parametersString = inspect(this.code, options);\n        const multiLineFn = parametersString.includes('\\n');\n        if (this.scope != null) {\n            parametersString += `,${multiLineFn ? '\\n' : ' '}${inspect(this.scope, options)}`;\n        }\n        const endingNewline = multiLineFn && this.scope === null;\n        return `new Code(${multiLineFn ? '\\n' : ''}${parametersString}${endingNewline ? '\\n' : ''})`;\n    }\n}\n\nfunction isDBRefLike(value) {\n    return (value != null &&\n        typeof value === 'object' &&\n        '$id' in value &&\n        value.$id != null &&\n        '$ref' in value &&\n        typeof value.$ref === 'string' &&\n        (!('$db' in value) || ('$db' in value && typeof value.$db === 'string')));\n}\nclass DBRef extends BSONValue {\n    get _bsontype() {\n        return 'DBRef';\n    }\n    constructor(collection, oid, db, fields) {\n        super();\n        const parts = collection.split('.');\n        if (parts.length === 2) {\n            db = parts.shift();\n            collection = parts.shift();\n        }\n        this.collection = collection;\n        this.oid = oid;\n        this.db = db;\n        this.fields = fields || {};\n    }\n    get namespace() {\n        return this.collection;\n    }\n    set namespace(value) {\n        this.collection = value;\n    }\n    toJSON() {\n        const o = Object.assign({\n            $ref: this.collection,\n            $id: this.oid\n        }, this.fields);\n        if (this.db != null)\n            o.$db = this.db;\n        return o;\n    }\n    toExtendedJSON(options) {\n        options = options || {};\n        let o = {\n            $ref: this.collection,\n            $id: this.oid\n        };\n        if (options.legacy) {\n            return o;\n        }\n        if (this.db)\n            o.$db = this.db;\n        o = Object.assign(o, this.fields);\n        return o;\n    }\n    static fromExtendedJSON(doc) {\n        const copy = Object.assign({}, doc);\n        delete copy.$ref;\n        delete copy.$id;\n        delete copy.$db;\n        return new DBRef(doc.$ref, doc.$id, doc.$db, copy);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        const args = [\n            inspect(this.namespace, options),\n            inspect(this.oid, options),\n            ...(this.db ? [inspect(this.db, options)] : []),\n            ...(Object.keys(this.fields).length > 0 ? [inspect(this.fields, options)] : [])\n        ];\n        args[1] = inspect === defaultInspect ? `new ObjectId(${args[1]})` : args[1];\n        return `new DBRef(${args.join(', ')})`;\n    }\n}\n\nlet wasm = undefined;\ntry {\n    wasm = new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 13, 2, 96, 0, 1, 127, 96, 4, 127, 127, 127, 127, 1, 127, 3, 7, 6, 0, 1, 1, 1, 1, 1, 6, 6, 1, 127, 1, 65, 0, 11, 7, 50, 6, 3, 109, 117, 108, 0, 1, 5, 100, 105, 118, 95, 115, 0, 2, 5, 100, 105, 118, 95, 117, 0, 3, 5, 114, 101, 109, 95, 115, 0, 4, 5, 114, 101, 109, 95, 117, 0, 5, 8, 103, 101, 116, 95, 104, 105, 103, 104, 0, 0, 10, 191, 1, 6, 4, 0, 35, 0, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 126, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 127, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 128, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 129, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 130, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11])), {}).exports;\n}\ncatch {\n}\nconst TWO_PWR_16_DBL = 1 << 16;\nconst TWO_PWR_24_DBL = 1 << 24;\nconst TWO_PWR_32_DBL = TWO_PWR_16_DBL * TWO_PWR_16_DBL;\nconst TWO_PWR_64_DBL = TWO_PWR_32_DBL * TWO_PWR_32_DBL;\nconst TWO_PWR_63_DBL = TWO_PWR_64_DBL / 2;\nconst INT_CACHE = {};\nconst UINT_CACHE = {};\nconst MAX_INT64_STRING_LENGTH = 20;\nconst DECIMAL_REG_EX = /^(\\+?0|(\\+|-)?[1-9][0-9]*)$/;\nclass Long extends BSONValue {\n    get _bsontype() {\n        return 'Long';\n    }\n    get __isLong__() {\n        return true;\n    }\n    constructor(low = 0, high, unsigned) {\n        super();\n        if (typeof low === 'bigint') {\n            Object.assign(this, Long.fromBigInt(low, !!high));\n        }\n        else if (typeof low === 'string') {\n            Object.assign(this, Long.fromString(low, !!high));\n        }\n        else {\n            this.low = low | 0;\n            this.high = high | 0;\n            this.unsigned = !!unsigned;\n        }\n    }\n    static fromBits(lowBits, highBits, unsigned) {\n        return new Long(lowBits, highBits, unsigned);\n    }\n    static fromInt(value, unsigned) {\n        let obj, cachedObj, cache;\n        if (unsigned) {\n            value >>>= 0;\n            if ((cache = 0 <= value && value < 256)) {\n                cachedObj = UINT_CACHE[value];\n                if (cachedObj)\n                    return cachedObj;\n            }\n            obj = Long.fromBits(value, (value | 0) < 0 ? -1 : 0, true);\n            if (cache)\n                UINT_CACHE[value] = obj;\n            return obj;\n        }\n        else {\n            value |= 0;\n            if ((cache = -128 <= value && value < 128)) {\n                cachedObj = INT_CACHE[value];\n                if (cachedObj)\n                    return cachedObj;\n            }\n            obj = Long.fromBits(value, value < 0 ? -1 : 0, false);\n            if (cache)\n                INT_CACHE[value] = obj;\n            return obj;\n        }\n    }\n    static fromNumber(value, unsigned) {\n        if (isNaN(value))\n            return unsigned ? Long.UZERO : Long.ZERO;\n        if (unsigned) {\n            if (value < 0)\n                return Long.UZERO;\n            if (value >= TWO_PWR_64_DBL)\n                return Long.MAX_UNSIGNED_VALUE;\n        }\n        else {\n            if (value <= -TWO_PWR_63_DBL)\n                return Long.MIN_VALUE;\n            if (value + 1 >= TWO_PWR_63_DBL)\n                return Long.MAX_VALUE;\n        }\n        if (value < 0)\n            return Long.fromNumber(-value, unsigned).neg();\n        return Long.fromBits(value % TWO_PWR_32_DBL | 0, (value / TWO_PWR_32_DBL) | 0, unsigned);\n    }\n    static fromBigInt(value, unsigned) {\n        return Long.fromString(value.toString(), unsigned);\n    }\n    static fromString(str, unsigned, radix) {\n        if (str.length === 0)\n            throw new BSONError('empty string');\n        if (str === 'NaN' || str === 'Infinity' || str === '+Infinity' || str === '-Infinity')\n            return Long.ZERO;\n        if (typeof unsigned === 'number') {\n            (radix = unsigned), (unsigned = false);\n        }\n        else {\n            unsigned = !!unsigned;\n        }\n        radix = radix || 10;\n        if (radix < 2 || 36 < radix)\n            throw new BSONError('radix');\n        let p;\n        if ((p = str.indexOf('-')) > 0)\n            throw new BSONError('interior hyphen');\n        else if (p === 0) {\n            return Long.fromString(str.substring(1), unsigned, radix).neg();\n        }\n        const radixToPower = Long.fromNumber(Math.pow(radix, 8));\n        let result = Long.ZERO;\n        for (let i = 0; i < str.length; i += 8) {\n            const size = Math.min(8, str.length - i), value = parseInt(str.substring(i, i + size), radix);\n            if (size < 8) {\n                const power = Long.fromNumber(Math.pow(radix, size));\n                result = result.mul(power).add(Long.fromNumber(value));\n            }\n            else {\n                result = result.mul(radixToPower);\n                result = result.add(Long.fromNumber(value));\n            }\n        }\n        result.unsigned = unsigned;\n        return result;\n    }\n    static fromBytes(bytes, unsigned, le) {\n        return le ? Long.fromBytesLE(bytes, unsigned) : Long.fromBytesBE(bytes, unsigned);\n    }\n    static fromBytesLE(bytes, unsigned) {\n        return new Long(bytes[0] | (bytes[1] << 8) | (bytes[2] << 16) | (bytes[3] << 24), bytes[4] | (bytes[5] << 8) | (bytes[6] << 16) | (bytes[7] << 24), unsigned);\n    }\n    static fromBytesBE(bytes, unsigned) {\n        return new Long((bytes[4] << 24) | (bytes[5] << 16) | (bytes[6] << 8) | bytes[7], (bytes[0] << 24) | (bytes[1] << 16) | (bytes[2] << 8) | bytes[3], unsigned);\n    }\n    static isLong(value) {\n        return (value != null &&\n            typeof value === 'object' &&\n            '__isLong__' in value &&\n            value.__isLong__ === true);\n    }\n    static fromValue(val, unsigned) {\n        if (typeof val === 'number')\n            return Long.fromNumber(val, unsigned);\n        if (typeof val === 'string')\n            return Long.fromString(val, unsigned);\n        return Long.fromBits(val.low, val.high, typeof unsigned === 'boolean' ? unsigned : val.unsigned);\n    }\n    add(addend) {\n        if (!Long.isLong(addend))\n            addend = Long.fromValue(addend);\n        const a48 = this.high >>> 16;\n        const a32 = this.high & 0xffff;\n        const a16 = this.low >>> 16;\n        const a00 = this.low & 0xffff;\n        const b48 = addend.high >>> 16;\n        const b32 = addend.high & 0xffff;\n        const b16 = addend.low >>> 16;\n        const b00 = addend.low & 0xffff;\n        let c48 = 0, c32 = 0, c16 = 0, c00 = 0;\n        c00 += a00 + b00;\n        c16 += c00 >>> 16;\n        c00 &= 0xffff;\n        c16 += a16 + b16;\n        c32 += c16 >>> 16;\n        c16 &= 0xffff;\n        c32 += a32 + b32;\n        c48 += c32 >>> 16;\n        c32 &= 0xffff;\n        c48 += a48 + b48;\n        c48 &= 0xffff;\n        return Long.fromBits((c16 << 16) | c00, (c48 << 16) | c32, this.unsigned);\n    }\n    and(other) {\n        if (!Long.isLong(other))\n            other = Long.fromValue(other);\n        return Long.fromBits(this.low & other.low, this.high & other.high, this.unsigned);\n    }\n    compare(other) {\n        if (!Long.isLong(other))\n            other = Long.fromValue(other);\n        if (this.eq(other))\n            return 0;\n        const thisNeg = this.isNegative(), otherNeg = other.isNegative();\n        if (thisNeg && !otherNeg)\n            return -1;\n        if (!thisNeg && otherNeg)\n            return 1;\n        if (!this.unsigned)\n            return this.sub(other).isNegative() ? -1 : 1;\n        return other.high >>> 0 > this.high >>> 0 ||\n            (other.high === this.high && other.low >>> 0 > this.low >>> 0)\n            ? -1\n            : 1;\n    }\n    comp(other) {\n        return this.compare(other);\n    }\n    divide(divisor) {\n        if (!Long.isLong(divisor))\n            divisor = Long.fromValue(divisor);\n        if (divisor.isZero())\n            throw new BSONError('division by zero');\n        if (wasm) {\n            if (!this.unsigned &&\n                this.high === -0x80000000 &&\n                divisor.low === -1 &&\n                divisor.high === -1) {\n                return this;\n            }\n            const low = (this.unsigned ? wasm.div_u : wasm.div_s)(this.low, this.high, divisor.low, divisor.high);\n            return Long.fromBits(low, wasm.get_high(), this.unsigned);\n        }\n        if (this.isZero())\n            return this.unsigned ? Long.UZERO : Long.ZERO;\n        let approx, rem, res;\n        if (!this.unsigned) {\n            if (this.eq(Long.MIN_VALUE)) {\n                if (divisor.eq(Long.ONE) || divisor.eq(Long.NEG_ONE))\n                    return Long.MIN_VALUE;\n                else if (divisor.eq(Long.MIN_VALUE))\n                    return Long.ONE;\n                else {\n                    const halfThis = this.shr(1);\n                    approx = halfThis.div(divisor).shl(1);\n                    if (approx.eq(Long.ZERO)) {\n                        return divisor.isNegative() ? Long.ONE : Long.NEG_ONE;\n                    }\n                    else {\n                        rem = this.sub(divisor.mul(approx));\n                        res = approx.add(rem.div(divisor));\n                        return res;\n                    }\n                }\n            }\n            else if (divisor.eq(Long.MIN_VALUE))\n                return this.unsigned ? Long.UZERO : Long.ZERO;\n            if (this.isNegative()) {\n                if (divisor.isNegative())\n                    return this.neg().div(divisor.neg());\n                return this.neg().div(divisor).neg();\n            }\n            else if (divisor.isNegative())\n                return this.div(divisor.neg()).neg();\n            res = Long.ZERO;\n        }\n        else {\n            if (!divisor.unsigned)\n                divisor = divisor.toUnsigned();\n            if (divisor.gt(this))\n                return Long.UZERO;\n            if (divisor.gt(this.shru(1)))\n                return Long.UONE;\n            res = Long.UZERO;\n        }\n        rem = this;\n        while (rem.gte(divisor)) {\n            approx = Math.max(1, Math.floor(rem.toNumber() / divisor.toNumber()));\n            const log2 = Math.ceil(Math.log(approx) / Math.LN2);\n            const delta = log2 <= 48 ? 1 : Math.pow(2, log2 - 48);\n            let approxRes = Long.fromNumber(approx);\n            let approxRem = approxRes.mul(divisor);\n            while (approxRem.isNegative() || approxRem.gt(rem)) {\n                approx -= delta;\n                approxRes = Long.fromNumber(approx, this.unsigned);\n                approxRem = approxRes.mul(divisor);\n            }\n            if (approxRes.isZero())\n                approxRes = Long.ONE;\n            res = res.add(approxRes);\n            rem = rem.sub(approxRem);\n        }\n        return res;\n    }\n    div(divisor) {\n        return this.divide(divisor);\n    }\n    equals(other) {\n        if (!Long.isLong(other))\n            other = Long.fromValue(other);\n        if (this.unsigned !== other.unsigned && this.high >>> 31 === 1 && other.high >>> 31 === 1)\n            return false;\n        return this.high === other.high && this.low === other.low;\n    }\n    eq(other) {\n        return this.equals(other);\n    }\n    getHighBits() {\n        return this.high;\n    }\n    getHighBitsUnsigned() {\n        return this.high >>> 0;\n    }\n    getLowBits() {\n        return this.low;\n    }\n    getLowBitsUnsigned() {\n        return this.low >>> 0;\n    }\n    getNumBitsAbs() {\n        if (this.isNegative()) {\n            return this.eq(Long.MIN_VALUE) ? 64 : this.neg().getNumBitsAbs();\n        }\n        const val = this.high !== 0 ? this.high : this.low;\n        let bit;\n        for (bit = 31; bit > 0; bit--)\n            if ((val & (1 << bit)) !== 0)\n                break;\n        return this.high !== 0 ? bit + 33 : bit + 1;\n    }\n    greaterThan(other) {\n        return this.comp(other) > 0;\n    }\n    gt(other) {\n        return this.greaterThan(other);\n    }\n    greaterThanOrEqual(other) {\n        return this.comp(other) >= 0;\n    }\n    gte(other) {\n        return this.greaterThanOrEqual(other);\n    }\n    ge(other) {\n        return this.greaterThanOrEqual(other);\n    }\n    isEven() {\n        return (this.low & 1) === 0;\n    }\n    isNegative() {\n        return !this.unsigned && this.high < 0;\n    }\n    isOdd() {\n        return (this.low & 1) === 1;\n    }\n    isPositive() {\n        return this.unsigned || this.high >= 0;\n    }\n    isZero() {\n        return this.high === 0 && this.low === 0;\n    }\n    lessThan(other) {\n        return this.comp(other) < 0;\n    }\n    lt(other) {\n        return this.lessThan(other);\n    }\n    lessThanOrEqual(other) {\n        return this.comp(other) <= 0;\n    }\n    lte(other) {\n        return this.lessThanOrEqual(other);\n    }\n    modulo(divisor) {\n        if (!Long.isLong(divisor))\n            divisor = Long.fromValue(divisor);\n        if (wasm) {\n            const low = (this.unsigned ? wasm.rem_u : wasm.rem_s)(this.low, this.high, divisor.low, divisor.high);\n            return Long.fromBits(low, wasm.get_high(), this.unsigned);\n        }\n        return this.sub(this.div(divisor).mul(divisor));\n    }\n    mod(divisor) {\n        return this.modulo(divisor);\n    }\n    rem(divisor) {\n        return this.modulo(divisor);\n    }\n    multiply(multiplier) {\n        if (this.isZero())\n            return Long.ZERO;\n        if (!Long.isLong(multiplier))\n            multiplier = Long.fromValue(multiplier);\n        if (wasm) {\n            const low = wasm.mul(this.low, this.high, multiplier.low, multiplier.high);\n            return Long.fromBits(low, wasm.get_high(), this.unsigned);\n        }\n        if (multiplier.isZero())\n            return Long.ZERO;\n        if (this.eq(Long.MIN_VALUE))\n            return multiplier.isOdd() ? Long.MIN_VALUE : Long.ZERO;\n        if (multiplier.eq(Long.MIN_VALUE))\n            return this.isOdd() ? Long.MIN_VALUE : Long.ZERO;\n        if (this.isNegative()) {\n            if (multiplier.isNegative())\n                return this.neg().mul(multiplier.neg());\n            else\n                return this.neg().mul(multiplier).neg();\n        }\n        else if (multiplier.isNegative())\n            return this.mul(multiplier.neg()).neg();\n        if (this.lt(Long.TWO_PWR_24) && multiplier.lt(Long.TWO_PWR_24))\n            return Long.fromNumber(this.toNumber() * multiplier.toNumber(), this.unsigned);\n        const a48 = this.high >>> 16;\n        const a32 = this.high & 0xffff;\n        const a16 = this.low >>> 16;\n        const a00 = this.low & 0xffff;\n        const b48 = multiplier.high >>> 16;\n        const b32 = multiplier.high & 0xffff;\n        const b16 = multiplier.low >>> 16;\n        const b00 = multiplier.low & 0xffff;\n        let c48 = 0, c32 = 0, c16 = 0, c00 = 0;\n        c00 += a00 * b00;\n        c16 += c00 >>> 16;\n        c00 &= 0xffff;\n        c16 += a16 * b00;\n        c32 += c16 >>> 16;\n        c16 &= 0xffff;\n        c16 += a00 * b16;\n        c32 += c16 >>> 16;\n        c16 &= 0xffff;\n        c32 += a32 * b00;\n        c48 += c32 >>> 16;\n        c32 &= 0xffff;\n        c32 += a16 * b16;\n        c48 += c32 >>> 16;\n        c32 &= 0xffff;\n        c32 += a00 * b32;\n        c48 += c32 >>> 16;\n        c32 &= 0xffff;\n        c48 += a48 * b00 + a32 * b16 + a16 * b32 + a00 * b48;\n        c48 &= 0xffff;\n        return Long.fromBits((c16 << 16) | c00, (c48 << 16) | c32, this.unsigned);\n    }\n    mul(multiplier) {\n        return this.multiply(multiplier);\n    }\n    negate() {\n        if (!this.unsigned && this.eq(Long.MIN_VALUE))\n            return Long.MIN_VALUE;\n        return this.not().add(Long.ONE);\n    }\n    neg() {\n        return this.negate();\n    }\n    not() {\n        return Long.fromBits(~this.low, ~this.high, this.unsigned);\n    }\n    notEquals(other) {\n        return !this.equals(other);\n    }\n    neq(other) {\n        return this.notEquals(other);\n    }\n    ne(other) {\n        return this.notEquals(other);\n    }\n    or(other) {\n        if (!Long.isLong(other))\n            other = Long.fromValue(other);\n        return Long.fromBits(this.low | other.low, this.high | other.high, this.unsigned);\n    }\n    shiftLeft(numBits) {\n        if (Long.isLong(numBits))\n            numBits = numBits.toInt();\n        if ((numBits &= 63) === 0)\n            return this;\n        else if (numBits < 32)\n            return Long.fromBits(this.low << numBits, (this.high << numBits) | (this.low >>> (32 - numBits)), this.unsigned);\n        else\n            return Long.fromBits(0, this.low << (numBits - 32), this.unsigned);\n    }\n    shl(numBits) {\n        return this.shiftLeft(numBits);\n    }\n    shiftRight(numBits) {\n        if (Long.isLong(numBits))\n            numBits = numBits.toInt();\n        if ((numBits &= 63) === 0)\n            return this;\n        else if (numBits < 32)\n            return Long.fromBits((this.low >>> numBits) | (this.high << (32 - numBits)), this.high >> numBits, this.unsigned);\n        else\n            return Long.fromBits(this.high >> (numBits - 32), this.high >= 0 ? 0 : -1, this.unsigned);\n    }\n    shr(numBits) {\n        return this.shiftRight(numBits);\n    }\n    shiftRightUnsigned(numBits) {\n        if (Long.isLong(numBits))\n            numBits = numBits.toInt();\n        numBits &= 63;\n        if (numBits === 0)\n            return this;\n        else {\n            const high = this.high;\n            if (numBits < 32) {\n                const low = this.low;\n                return Long.fromBits((low >>> numBits) | (high << (32 - numBits)), high >>> numBits, this.unsigned);\n            }\n            else if (numBits === 32)\n                return Long.fromBits(high, 0, this.unsigned);\n            else\n                return Long.fromBits(high >>> (numBits - 32), 0, this.unsigned);\n        }\n    }\n    shr_u(numBits) {\n        return this.shiftRightUnsigned(numBits);\n    }\n    shru(numBits) {\n        return this.shiftRightUnsigned(numBits);\n    }\n    subtract(subtrahend) {\n        if (!Long.isLong(subtrahend))\n            subtrahend = Long.fromValue(subtrahend);\n        return this.add(subtrahend.neg());\n    }\n    sub(subtrahend) {\n        return this.subtract(subtrahend);\n    }\n    toInt() {\n        return this.unsigned ? this.low >>> 0 : this.low;\n    }\n    toNumber() {\n        if (this.unsigned)\n            return (this.high >>> 0) * TWO_PWR_32_DBL + (this.low >>> 0);\n        return this.high * TWO_PWR_32_DBL + (this.low >>> 0);\n    }\n    toBigInt() {\n        return BigInt(this.toString());\n    }\n    toBytes(le) {\n        return le ? this.toBytesLE() : this.toBytesBE();\n    }\n    toBytesLE() {\n        const hi = this.high, lo = this.low;\n        return [\n            lo & 0xff,\n            (lo >>> 8) & 0xff,\n            (lo >>> 16) & 0xff,\n            lo >>> 24,\n            hi & 0xff,\n            (hi >>> 8) & 0xff,\n            (hi >>> 16) & 0xff,\n            hi >>> 24\n        ];\n    }\n    toBytesBE() {\n        const hi = this.high, lo = this.low;\n        return [\n            hi >>> 24,\n            (hi >>> 16) & 0xff,\n            (hi >>> 8) & 0xff,\n            hi & 0xff,\n            lo >>> 24,\n            (lo >>> 16) & 0xff,\n            (lo >>> 8) & 0xff,\n            lo & 0xff\n        ];\n    }\n    toSigned() {\n        if (!this.unsigned)\n            return this;\n        return Long.fromBits(this.low, this.high, false);\n    }\n    toString(radix) {\n        radix = radix || 10;\n        if (radix < 2 || 36 < radix)\n            throw new BSONError('radix');\n        if (this.isZero())\n            return '0';\n        if (this.isNegative()) {\n            if (this.eq(Long.MIN_VALUE)) {\n                const radixLong = Long.fromNumber(radix), div = this.div(radixLong), rem1 = div.mul(radixLong).sub(this);\n                return div.toString(radix) + rem1.toInt().toString(radix);\n            }\n            else\n                return '-' + this.neg().toString(radix);\n        }\n        const radixToPower = Long.fromNumber(Math.pow(radix, 6), this.unsigned);\n        let rem = this;\n        let result = '';\n        while (true) {\n            const remDiv = rem.div(radixToPower);\n            const intval = rem.sub(remDiv.mul(radixToPower)).toInt() >>> 0;\n            let digits = intval.toString(radix);\n            rem = remDiv;\n            if (rem.isZero()) {\n                return digits + result;\n            }\n            else {\n                while (digits.length < 6)\n                    digits = '0' + digits;\n                result = '' + digits + result;\n            }\n        }\n    }\n    toUnsigned() {\n        if (this.unsigned)\n            return this;\n        return Long.fromBits(this.low, this.high, true);\n    }\n    xor(other) {\n        if (!Long.isLong(other))\n            other = Long.fromValue(other);\n        return Long.fromBits(this.low ^ other.low, this.high ^ other.high, this.unsigned);\n    }\n    eqz() {\n        return this.isZero();\n    }\n    le(other) {\n        return this.lessThanOrEqual(other);\n    }\n    toExtendedJSON(options) {\n        if (options && options.relaxed)\n            return this.toNumber();\n        return { $numberLong: this.toString() };\n    }\n    static fromExtendedJSON(doc, options) {\n        const { useBigInt64 = false, relaxed = true } = { ...options };\n        if (doc.$numberLong.length > MAX_INT64_STRING_LENGTH) {\n            throw new BSONError('$numberLong string is too long');\n        }\n        if (!DECIMAL_REG_EX.test(doc.$numberLong)) {\n            throw new BSONError(`$numberLong string \"${doc.$numberLong}\" is in an invalid format`);\n        }\n        if (useBigInt64) {\n            const bigIntResult = BigInt(doc.$numberLong);\n            return BigInt.asIntN(64, bigIntResult);\n        }\n        const longResult = Long.fromString(doc.$numberLong);\n        if (relaxed) {\n            return longResult.toNumber();\n        }\n        return longResult;\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        const longVal = inspect(this.toString(), options);\n        const unsignedVal = this.unsigned ? `, ${inspect(this.unsigned, options)}` : '';\n        return `new Long(${longVal}${unsignedVal})`;\n    }\n}\nLong.TWO_PWR_24 = Long.fromInt(TWO_PWR_24_DBL);\nLong.MAX_UNSIGNED_VALUE = Long.fromBits(0xffffffff | 0, 0xffffffff | 0, true);\nLong.ZERO = Long.fromInt(0);\nLong.UZERO = Long.fromInt(0, true);\nLong.ONE = Long.fromInt(1);\nLong.UONE = Long.fromInt(1, true);\nLong.NEG_ONE = Long.fromInt(-1);\nLong.MAX_VALUE = Long.fromBits(0xffffffff | 0, 0x7fffffff | 0, false);\nLong.MIN_VALUE = Long.fromBits(0, 0x80000000 | 0, false);\n\nconst PARSE_STRING_REGEXP = /^(\\+|-)?(\\d+|(\\d*\\.\\d*))?(E|e)?([-+])?(\\d+)?$/;\nconst PARSE_INF_REGEXP = /^(\\+|-)?(Infinity|inf)$/i;\nconst PARSE_NAN_REGEXP = /^(\\+|-)?NaN$/i;\nconst EXPONENT_MAX = 6111;\nconst EXPONENT_MIN = -6176;\nconst EXPONENT_BIAS = 6176;\nconst MAX_DIGITS = 34;\nconst NAN_BUFFER = ByteUtils.fromNumberArray([\n    0x7c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00\n].reverse());\nconst INF_NEGATIVE_BUFFER = ByteUtils.fromNumberArray([\n    0xf8, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00\n].reverse());\nconst INF_POSITIVE_BUFFER = ByteUtils.fromNumberArray([\n    0x78, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00\n].reverse());\nconst EXPONENT_REGEX = /^([-+])?(\\d+)?$/;\nconst COMBINATION_MASK = 0x1f;\nconst EXPONENT_MASK = 0x3fff;\nconst COMBINATION_INFINITY = 30;\nconst COMBINATION_NAN = 31;\nfunction isDigit(value) {\n    return !isNaN(parseInt(value, 10));\n}\nfunction divideu128(value) {\n    const DIVISOR = Long.fromNumber(1000 * 1000 * 1000);\n    let _rem = Long.fromNumber(0);\n    if (!value.parts[0] && !value.parts[1] && !value.parts[2] && !value.parts[3]) {\n        return { quotient: value, rem: _rem };\n    }\n    for (let i = 0; i <= 3; i++) {\n        _rem = _rem.shiftLeft(32);\n        _rem = _rem.add(new Long(value.parts[i], 0));\n        value.parts[i] = _rem.div(DIVISOR).low;\n        _rem = _rem.modulo(DIVISOR);\n    }\n    return { quotient: value, rem: _rem };\n}\nfunction multiply64x2(left, right) {\n    if (!left && !right) {\n        return { high: Long.fromNumber(0), low: Long.fromNumber(0) };\n    }\n    const leftHigh = left.shiftRightUnsigned(32);\n    const leftLow = new Long(left.getLowBits(), 0);\n    const rightHigh = right.shiftRightUnsigned(32);\n    const rightLow = new Long(right.getLowBits(), 0);\n    let productHigh = leftHigh.multiply(rightHigh);\n    let productMid = leftHigh.multiply(rightLow);\n    const productMid2 = leftLow.multiply(rightHigh);\n    let productLow = leftLow.multiply(rightLow);\n    productHigh = productHigh.add(productMid.shiftRightUnsigned(32));\n    productMid = new Long(productMid.getLowBits(), 0)\n        .add(productMid2)\n        .add(productLow.shiftRightUnsigned(32));\n    productHigh = productHigh.add(productMid.shiftRightUnsigned(32));\n    productLow = productMid.shiftLeft(32).add(new Long(productLow.getLowBits(), 0));\n    return { high: productHigh, low: productLow };\n}\nfunction lessThan(left, right) {\n    const uhleft = left.high >>> 0;\n    const uhright = right.high >>> 0;\n    if (uhleft < uhright) {\n        return true;\n    }\n    else if (uhleft === uhright) {\n        const ulleft = left.low >>> 0;\n        const ulright = right.low >>> 0;\n        if (ulleft < ulright)\n            return true;\n    }\n    return false;\n}\nfunction invalidErr(string, message) {\n    throw new BSONError(`\"${string}\" is not a valid Decimal128 string - ${message}`);\n}\nclass Decimal128 extends BSONValue {\n    get _bsontype() {\n        return 'Decimal128';\n    }\n    constructor(bytes) {\n        super();\n        if (typeof bytes === 'string') {\n            this.bytes = Decimal128.fromString(bytes).bytes;\n        }\n        else if (isUint8Array(bytes)) {\n            if (bytes.byteLength !== 16) {\n                throw new BSONError('Decimal128 must take a Buffer of 16 bytes');\n            }\n            this.bytes = bytes;\n        }\n        else {\n            throw new BSONError('Decimal128 must take a Buffer or string');\n        }\n    }\n    static fromString(representation) {\n        return Decimal128._fromString(representation, { allowRounding: false });\n    }\n    static fromStringWithRounding(representation) {\n        return Decimal128._fromString(representation, { allowRounding: true });\n    }\n    static _fromString(representation, options) {\n        let isNegative = false;\n        let sawSign = false;\n        let sawRadix = false;\n        let foundNonZero = false;\n        let significantDigits = 0;\n        let nDigitsRead = 0;\n        let nDigits = 0;\n        let radixPosition = 0;\n        let firstNonZero = 0;\n        const digits = [0];\n        let nDigitsStored = 0;\n        let digitsInsert = 0;\n        let lastDigit = 0;\n        let exponent = 0;\n        let significandHigh = new Long(0, 0);\n        let significandLow = new Long(0, 0);\n        let biasedExponent = 0;\n        let index = 0;\n        if (representation.length >= 7000) {\n            throw new BSONError('' + representation + ' not a valid Decimal128 string');\n        }\n        const stringMatch = representation.match(PARSE_STRING_REGEXP);\n        const infMatch = representation.match(PARSE_INF_REGEXP);\n        const nanMatch = representation.match(PARSE_NAN_REGEXP);\n        if ((!stringMatch && !infMatch && !nanMatch) || representation.length === 0) {\n            throw new BSONError('' + representation + ' not a valid Decimal128 string');\n        }\n        if (stringMatch) {\n            const unsignedNumber = stringMatch[2];\n            const e = stringMatch[4];\n            const expSign = stringMatch[5];\n            const expNumber = stringMatch[6];\n            if (e && expNumber === undefined)\n                invalidErr(representation, 'missing exponent power');\n            if (e && unsignedNumber === undefined)\n                invalidErr(representation, 'missing exponent base');\n            if (e === undefined && (expSign || expNumber)) {\n                invalidErr(representation, 'missing e before exponent');\n            }\n        }\n        if (representation[index] === '+' || representation[index] === '-') {\n            sawSign = true;\n            isNegative = representation[index++] === '-';\n        }\n        if (!isDigit(representation[index]) && representation[index] !== '.') {\n            if (representation[index] === 'i' || representation[index] === 'I') {\n                return new Decimal128(isNegative ? INF_NEGATIVE_BUFFER : INF_POSITIVE_BUFFER);\n            }\n            else if (representation[index] === 'N') {\n                return new Decimal128(NAN_BUFFER);\n            }\n        }\n        while (isDigit(representation[index]) || representation[index] === '.') {\n            if (representation[index] === '.') {\n                if (sawRadix)\n                    invalidErr(representation, 'contains multiple periods');\n                sawRadix = true;\n                index = index + 1;\n                continue;\n            }\n            if (nDigitsStored < MAX_DIGITS) {\n                if (representation[index] !== '0' || foundNonZero) {\n                    if (!foundNonZero) {\n                        firstNonZero = nDigitsRead;\n                    }\n                    foundNonZero = true;\n                    digits[digitsInsert++] = parseInt(representation[index], 10);\n                    nDigitsStored = nDigitsStored + 1;\n                }\n            }\n            if (foundNonZero)\n                nDigits = nDigits + 1;\n            if (sawRadix)\n                radixPosition = radixPosition + 1;\n            nDigitsRead = nDigitsRead + 1;\n            index = index + 1;\n        }\n        if (sawRadix && !nDigitsRead)\n            throw new BSONError('' + representation + ' not a valid Decimal128 string');\n        if (representation[index] === 'e' || representation[index] === 'E') {\n            const match = representation.substr(++index).match(EXPONENT_REGEX);\n            if (!match || !match[2])\n                return new Decimal128(NAN_BUFFER);\n            exponent = parseInt(match[0], 10);\n            index = index + match[0].length;\n        }\n        if (representation[index])\n            return new Decimal128(NAN_BUFFER);\n        if (!nDigitsStored) {\n            digits[0] = 0;\n            nDigits = 1;\n            nDigitsStored = 1;\n            significantDigits = 0;\n        }\n        else {\n            lastDigit = nDigitsStored - 1;\n            significantDigits = nDigits;\n            if (significantDigits !== 1) {\n                while (representation[firstNonZero + significantDigits - 1 + Number(sawSign) + Number(sawRadix)] === '0') {\n                    significantDigits = significantDigits - 1;\n                }\n            }\n        }\n        if (exponent <= radixPosition && radixPosition > exponent + (1 << 14)) {\n            exponent = EXPONENT_MIN;\n        }\n        else {\n            exponent = exponent - radixPosition;\n        }\n        while (exponent > EXPONENT_MAX) {\n            lastDigit = lastDigit + 1;\n            if (lastDigit >= MAX_DIGITS) {\n                if (significantDigits === 0) {\n                    exponent = EXPONENT_MAX;\n                    break;\n                }\n                invalidErr(representation, 'overflow');\n            }\n            exponent = exponent - 1;\n        }\n        if (options.allowRounding) {\n            while (exponent < EXPONENT_MIN || nDigitsStored < nDigits) {\n                if (lastDigit === 0 && significantDigits < nDigitsStored) {\n                    exponent = EXPONENT_MIN;\n                    significantDigits = 0;\n                    break;\n                }\n                if (nDigitsStored < nDigits) {\n                    nDigits = nDigits - 1;\n                }\n                else {\n                    lastDigit = lastDigit - 1;\n                }\n                if (exponent < EXPONENT_MAX) {\n                    exponent = exponent + 1;\n                }\n                else {\n                    const digitsString = digits.join('');\n                    if (digitsString.match(/^0+$/)) {\n                        exponent = EXPONENT_MAX;\n                        break;\n                    }\n                    invalidErr(representation, 'overflow');\n                }\n            }\n            if (lastDigit + 1 < significantDigits) {\n                let endOfString = nDigitsRead;\n                if (sawRadix) {\n                    firstNonZero = firstNonZero + 1;\n                    endOfString = endOfString + 1;\n                }\n                if (sawSign) {\n                    firstNonZero = firstNonZero + 1;\n                    endOfString = endOfString + 1;\n                }\n                const roundDigit = parseInt(representation[firstNonZero + lastDigit + 1], 10);\n                let roundBit = 0;\n                if (roundDigit >= 5) {\n                    roundBit = 1;\n                    if (roundDigit === 5) {\n                        roundBit = digits[lastDigit] % 2 === 1 ? 1 : 0;\n                        for (let i = firstNonZero + lastDigit + 2; i < endOfString; i++) {\n                            if (parseInt(representation[i], 10)) {\n                                roundBit = 1;\n                                break;\n                            }\n                        }\n                    }\n                }\n                if (roundBit) {\n                    let dIdx = lastDigit;\n                    for (; dIdx >= 0; dIdx--) {\n                        if (++digits[dIdx] > 9) {\n                            digits[dIdx] = 0;\n                            if (dIdx === 0) {\n                                if (exponent < EXPONENT_MAX) {\n                                    exponent = exponent + 1;\n                                    digits[dIdx] = 1;\n                                }\n                                else {\n                                    return new Decimal128(isNegative ? INF_NEGATIVE_BUFFER : INF_POSITIVE_BUFFER);\n                                }\n                            }\n                        }\n                        else {\n                            break;\n                        }\n                    }\n                }\n            }\n        }\n        else {\n            while (exponent < EXPONENT_MIN || nDigitsStored < nDigits) {\n                if (lastDigit === 0) {\n                    if (significantDigits === 0) {\n                        exponent = EXPONENT_MIN;\n                        break;\n                    }\n                    invalidErr(representation, 'exponent underflow');\n                }\n                if (nDigitsStored < nDigits) {\n                    if (representation[nDigits - 1 + Number(sawSign) + Number(sawRadix)] !== '0' &&\n                        significantDigits !== 0) {\n                        invalidErr(representation, 'inexact rounding');\n                    }\n                    nDigits = nDigits - 1;\n                }\n                else {\n                    if (digits[lastDigit] !== 0) {\n                        invalidErr(representation, 'inexact rounding');\n                    }\n                    lastDigit = lastDigit - 1;\n                }\n                if (exponent < EXPONENT_MAX) {\n                    exponent = exponent + 1;\n                }\n                else {\n                    invalidErr(representation, 'overflow');\n                }\n            }\n            if (lastDigit + 1 < significantDigits) {\n                if (sawRadix) {\n                    firstNonZero = firstNonZero + 1;\n                }\n                if (sawSign) {\n                    firstNonZero = firstNonZero + 1;\n                }\n                const roundDigit = parseInt(representation[firstNonZero + lastDigit + 1], 10);\n                if (roundDigit !== 0) {\n                    invalidErr(representation, 'inexact rounding');\n                }\n            }\n        }\n        significandHigh = Long.fromNumber(0);\n        significandLow = Long.fromNumber(0);\n        if (significantDigits === 0) {\n            significandHigh = Long.fromNumber(0);\n            significandLow = Long.fromNumber(0);\n        }\n        else if (lastDigit < 17) {\n            let dIdx = 0;\n            significandLow = Long.fromNumber(digits[dIdx++]);\n            significandHigh = new Long(0, 0);\n            for (; dIdx <= lastDigit; dIdx++) {\n                significandLow = significandLow.multiply(Long.fromNumber(10));\n                significandLow = significandLow.add(Long.fromNumber(digits[dIdx]));\n            }\n        }\n        else {\n            let dIdx = 0;\n            significandHigh = Long.fromNumber(digits[dIdx++]);\n            for (; dIdx <= lastDigit - 17; dIdx++) {\n                significandHigh = significandHigh.multiply(Long.fromNumber(10));\n                significandHigh = significandHigh.add(Long.fromNumber(digits[dIdx]));\n            }\n            significandLow = Long.fromNumber(digits[dIdx++]);\n            for (; dIdx <= lastDigit; dIdx++) {\n                significandLow = significandLow.multiply(Long.fromNumber(10));\n                significandLow = significandLow.add(Long.fromNumber(digits[dIdx]));\n            }\n        }\n        const significand = multiply64x2(significandHigh, Long.fromString('100000000000000000'));\n        significand.low = significand.low.add(significandLow);\n        if (lessThan(significand.low, significandLow)) {\n            significand.high = significand.high.add(Long.fromNumber(1));\n        }\n        biasedExponent = exponent + EXPONENT_BIAS;\n        const dec = { low: Long.fromNumber(0), high: Long.fromNumber(0) };\n        if (significand.high.shiftRightUnsigned(49).and(Long.fromNumber(1)).equals(Long.fromNumber(1))) {\n            dec.high = dec.high.or(Long.fromNumber(0x3).shiftLeft(61));\n            dec.high = dec.high.or(Long.fromNumber(biasedExponent).and(Long.fromNumber(0x3fff).shiftLeft(47)));\n            dec.high = dec.high.or(significand.high.and(Long.fromNumber(0x7fffffffffff)));\n        }\n        else {\n            dec.high = dec.high.or(Long.fromNumber(biasedExponent & 0x3fff).shiftLeft(49));\n            dec.high = dec.high.or(significand.high.and(Long.fromNumber(0x1ffffffffffff)));\n        }\n        dec.low = significand.low;\n        if (isNegative) {\n            dec.high = dec.high.or(Long.fromString('9223372036854775808'));\n        }\n        const buffer = ByteUtils.allocate(16);\n        index = 0;\n        buffer[index++] = dec.low.low & 0xff;\n        buffer[index++] = (dec.low.low >> 8) & 0xff;\n        buffer[index++] = (dec.low.low >> 16) & 0xff;\n        buffer[index++] = (dec.low.low >> 24) & 0xff;\n        buffer[index++] = dec.low.high & 0xff;\n        buffer[index++] = (dec.low.high >> 8) & 0xff;\n        buffer[index++] = (dec.low.high >> 16) & 0xff;\n        buffer[index++] = (dec.low.high >> 24) & 0xff;\n        buffer[index++] = dec.high.low & 0xff;\n        buffer[index++] = (dec.high.low >> 8) & 0xff;\n        buffer[index++] = (dec.high.low >> 16) & 0xff;\n        buffer[index++] = (dec.high.low >> 24) & 0xff;\n        buffer[index++] = dec.high.high & 0xff;\n        buffer[index++] = (dec.high.high >> 8) & 0xff;\n        buffer[index++] = (dec.high.high >> 16) & 0xff;\n        buffer[index++] = (dec.high.high >> 24) & 0xff;\n        return new Decimal128(buffer);\n    }\n    toString() {\n        let biased_exponent;\n        let significand_digits = 0;\n        const significand = new Array(36);\n        for (let i = 0; i < significand.length; i++)\n            significand[i] = 0;\n        let index = 0;\n        let is_zero = false;\n        let significand_msb;\n        let significand128 = { parts: [0, 0, 0, 0] };\n        let j, k;\n        const string = [];\n        index = 0;\n        const buffer = this.bytes;\n        const low = buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24);\n        const midl = buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24);\n        const midh = buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24);\n        const high = buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24);\n        index = 0;\n        const dec = {\n            low: new Long(low, midl),\n            high: new Long(midh, high)\n        };\n        if (dec.high.lessThan(Long.ZERO)) {\n            string.push('-');\n        }\n        const combination = (high >> 26) & COMBINATION_MASK;\n        if (combination >> 3 === 3) {\n            if (combination === COMBINATION_INFINITY) {\n                return string.join('') + 'Infinity';\n            }\n            else if (combination === COMBINATION_NAN) {\n                return 'NaN';\n            }\n            else {\n                biased_exponent = (high >> 15) & EXPONENT_MASK;\n                significand_msb = 0x08 + ((high >> 14) & 0x01);\n            }\n        }\n        else {\n            significand_msb = (high >> 14) & 0x07;\n            biased_exponent = (high >> 17) & EXPONENT_MASK;\n        }\n        const exponent = biased_exponent - EXPONENT_BIAS;\n        significand128.parts[0] = (high & 0x3fff) + ((significand_msb & 0xf) << 14);\n        significand128.parts[1] = midh;\n        significand128.parts[2] = midl;\n        significand128.parts[3] = low;\n        if (significand128.parts[0] === 0 &&\n            significand128.parts[1] === 0 &&\n            significand128.parts[2] === 0 &&\n            significand128.parts[3] === 0) {\n            is_zero = true;\n        }\n        else {\n            for (k = 3; k >= 0; k--) {\n                let least_digits = 0;\n                const result = divideu128(significand128);\n                significand128 = result.quotient;\n                least_digits = result.rem.low;\n                if (!least_digits)\n                    continue;\n                for (j = 8; j >= 0; j--) {\n                    significand[k * 9 + j] = least_digits % 10;\n                    least_digits = Math.floor(least_digits / 10);\n                }\n            }\n        }\n        if (is_zero) {\n            significand_digits = 1;\n            significand[index] = 0;\n        }\n        else {\n            significand_digits = 36;\n            while (!significand[index]) {\n                significand_digits = significand_digits - 1;\n                index = index + 1;\n            }\n        }\n        const scientific_exponent = significand_digits - 1 + exponent;\n        if (scientific_exponent >= 34 || scientific_exponent <= -7 || exponent > 0) {\n            if (significand_digits > 34) {\n                string.push(`${0}`);\n                if (exponent > 0)\n                    string.push(`E+${exponent}`);\n                else if (exponent < 0)\n                    string.push(`E${exponent}`);\n                return string.join('');\n            }\n            string.push(`${significand[index++]}`);\n            significand_digits = significand_digits - 1;\n            if (significand_digits) {\n                string.push('.');\n            }\n            for (let i = 0; i < significand_digits; i++) {\n                string.push(`${significand[index++]}`);\n            }\n            string.push('E');\n            if (scientific_exponent > 0) {\n                string.push(`+${scientific_exponent}`);\n            }\n            else {\n                string.push(`${scientific_exponent}`);\n            }\n        }\n        else {\n            if (exponent >= 0) {\n                for (let i = 0; i < significand_digits; i++) {\n                    string.push(`${significand[index++]}`);\n                }\n            }\n            else {\n                let radix_position = significand_digits + exponent;\n                if (radix_position > 0) {\n                    for (let i = 0; i < radix_position; i++) {\n                        string.push(`${significand[index++]}`);\n                    }\n                }\n                else {\n                    string.push('0');\n                }\n                string.push('.');\n                while (radix_position++ < 0) {\n                    string.push('0');\n                }\n                for (let i = 0; i < significand_digits - Math.max(radix_position - 1, 0); i++) {\n                    string.push(`${significand[index++]}`);\n                }\n            }\n        }\n        return string.join('');\n    }\n    toJSON() {\n        return { $numberDecimal: this.toString() };\n    }\n    toExtendedJSON() {\n        return { $numberDecimal: this.toString() };\n    }\n    static fromExtendedJSON(doc) {\n        return Decimal128.fromString(doc.$numberDecimal);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        const d128string = inspect(this.toString(), options);\n        return `new Decimal128(${d128string})`;\n    }\n}\n\nclass Double extends BSONValue {\n    get _bsontype() {\n        return 'Double';\n    }\n    constructor(value) {\n        super();\n        if (value instanceof Number) {\n            value = value.valueOf();\n        }\n        this.value = +value;\n    }\n    valueOf() {\n        return this.value;\n    }\n    toJSON() {\n        return this.value;\n    }\n    toString(radix) {\n        return this.value.toString(radix);\n    }\n    toExtendedJSON(options) {\n        if (options && (options.legacy || (options.relaxed && isFinite(this.value)))) {\n            return this.value;\n        }\n        if (Object.is(Math.sign(this.value), -0)) {\n            return { $numberDouble: '-0.0' };\n        }\n        return {\n            $numberDouble: Number.isInteger(this.value) ? this.value.toFixed(1) : this.value.toString()\n        };\n    }\n    static fromExtendedJSON(doc, options) {\n        const doubleValue = parseFloat(doc.$numberDouble);\n        return options && options.relaxed ? doubleValue : new Double(doubleValue);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        return `new Double(${inspect(this.value, options)})`;\n    }\n}\n\nclass Int32 extends BSONValue {\n    get _bsontype() {\n        return 'Int32';\n    }\n    constructor(value) {\n        super();\n        if (value instanceof Number) {\n            value = value.valueOf();\n        }\n        this.value = +value | 0;\n    }\n    valueOf() {\n        return this.value;\n    }\n    toString(radix) {\n        return this.value.toString(radix);\n    }\n    toJSON() {\n        return this.value;\n    }\n    toExtendedJSON(options) {\n        if (options && (options.relaxed || options.legacy))\n            return this.value;\n        return { $numberInt: this.value.toString() };\n    }\n    static fromExtendedJSON(doc, options) {\n        return options && options.relaxed ? parseInt(doc.$numberInt, 10) : new Int32(doc.$numberInt);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        return `new Int32(${inspect(this.value, options)})`;\n    }\n}\n\nclass MaxKey extends BSONValue {\n    get _bsontype() {\n        return 'MaxKey';\n    }\n    toExtendedJSON() {\n        return { $maxKey: 1 };\n    }\n    static fromExtendedJSON() {\n        return new MaxKey();\n    }\n    inspect() {\n        return 'new MaxKey()';\n    }\n}\n\nclass MinKey extends BSONValue {\n    get _bsontype() {\n        return 'MinKey';\n    }\n    toExtendedJSON() {\n        return { $minKey: 1 };\n    }\n    static fromExtendedJSON() {\n        return new MinKey();\n    }\n    inspect() {\n        return 'new MinKey()';\n    }\n}\n\nconst checkForHexRegExp = new RegExp('^[0-9a-fA-F]{24}$');\nlet PROCESS_UNIQUE = null;\nconst kId = Symbol('id');\nclass ObjectId extends BSONValue {\n    get _bsontype() {\n        return 'ObjectId';\n    }\n    constructor(inputId) {\n        super();\n        let workingId;\n        if (typeof inputId === 'object' && inputId && 'id' in inputId) {\n            if (typeof inputId.id !== 'string' && !ArrayBuffer.isView(inputId.id)) {\n                throw new BSONError('Argument passed in must have an id that is of type string or Buffer');\n            }\n            if ('toHexString' in inputId && typeof inputId.toHexString === 'function') {\n                workingId = ByteUtils.fromHex(inputId.toHexString());\n            }\n            else {\n                workingId = inputId.id;\n            }\n        }\n        else {\n            workingId = inputId;\n        }\n        if (workingId == null || typeof workingId === 'number') {\n            this[kId] = ObjectId.generate(typeof workingId === 'number' ? workingId : undefined);\n        }\n        else if (ArrayBuffer.isView(workingId) && workingId.byteLength === 12) {\n            this[kId] = ByteUtils.toLocalBufferType(workingId);\n        }\n        else if (typeof workingId === 'string') {\n            if (workingId.length === 24 && checkForHexRegExp.test(workingId)) {\n                this[kId] = ByteUtils.fromHex(workingId);\n            }\n            else {\n                throw new BSONError('input must be a 24 character hex string, 12 byte Uint8Array, or an integer');\n            }\n        }\n        else {\n            throw new BSONError('Argument passed in does not match the accepted types');\n        }\n        if (ObjectId.cacheHexString) {\n            this.__id = ByteUtils.toHex(this.id);\n        }\n    }\n    get id() {\n        return this[kId];\n    }\n    set id(value) {\n        this[kId] = value;\n        if (ObjectId.cacheHexString) {\n            this.__id = ByteUtils.toHex(value);\n        }\n    }\n    toHexString() {\n        if (ObjectId.cacheHexString && this.__id) {\n            return this.__id;\n        }\n        const hexString = ByteUtils.toHex(this.id);\n        if (ObjectId.cacheHexString && !this.__id) {\n            this.__id = hexString;\n        }\n        return hexString;\n    }\n    static getInc() {\n        return (ObjectId.index = (ObjectId.index + 1) % 0xffffff);\n    }\n    static generate(time) {\n        if ('number' !== typeof time) {\n            time = Math.floor(Date.now() / 1000);\n        }\n        const inc = ObjectId.getInc();\n        const buffer = ByteUtils.allocate(12);\n        BSONDataView.fromUint8Array(buffer).setUint32(0, time, false);\n        if (PROCESS_UNIQUE === null) {\n            PROCESS_UNIQUE = ByteUtils.randomBytes(5);\n        }\n        buffer[4] = PROCESS_UNIQUE[0];\n        buffer[5] = PROCESS_UNIQUE[1];\n        buffer[6] = PROCESS_UNIQUE[2];\n        buffer[7] = PROCESS_UNIQUE[3];\n        buffer[8] = PROCESS_UNIQUE[4];\n        buffer[11] = inc & 0xff;\n        buffer[10] = (inc >> 8) & 0xff;\n        buffer[9] = (inc >> 16) & 0xff;\n        return buffer;\n    }\n    toString(encoding) {\n        if (encoding === 'base64')\n            return ByteUtils.toBase64(this.id);\n        if (encoding === 'hex')\n            return this.toHexString();\n        return this.toHexString();\n    }\n    toJSON() {\n        return this.toHexString();\n    }\n    static is(variable) {\n        return (variable != null &&\n            typeof variable === 'object' &&\n            '_bsontype' in variable &&\n            variable._bsontype === 'ObjectId');\n    }\n    equals(otherId) {\n        if (otherId === undefined || otherId === null) {\n            return false;\n        }\n        if (ObjectId.is(otherId)) {\n            return this[kId][11] === otherId[kId][11] && ByteUtils.equals(this[kId], otherId[kId]);\n        }\n        if (typeof otherId === 'string') {\n            return otherId.toLowerCase() === this.toHexString();\n        }\n        if (typeof otherId === 'object' && typeof otherId.toHexString === 'function') {\n            const otherIdString = otherId.toHexString();\n            const thisIdString = this.toHexString();\n            return typeof otherIdString === 'string' && otherIdString.toLowerCase() === thisIdString;\n        }\n        return false;\n    }\n    getTimestamp() {\n        const timestamp = new Date();\n        const time = BSONDataView.fromUint8Array(this.id).getUint32(0, false);\n        timestamp.setTime(Math.floor(time) * 1000);\n        return timestamp;\n    }\n    static createPk() {\n        return new ObjectId();\n    }\n    static createFromTime(time) {\n        const buffer = ByteUtils.fromNumberArray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]);\n        BSONDataView.fromUint8Array(buffer).setUint32(0, time, false);\n        return new ObjectId(buffer);\n    }\n    static createFromHexString(hexString) {\n        if (hexString?.length !== 24) {\n            throw new BSONError('hex string must be 24 characters');\n        }\n        return new ObjectId(ByteUtils.fromHex(hexString));\n    }\n    static createFromBase64(base64) {\n        if (base64?.length !== 16) {\n            throw new BSONError('base64 string must be 16 characters');\n        }\n        return new ObjectId(ByteUtils.fromBase64(base64));\n    }\n    static isValid(id) {\n        if (id == null)\n            return false;\n        try {\n            new ObjectId(id);\n            return true;\n        }\n        catch {\n            return false;\n        }\n    }\n    toExtendedJSON() {\n        if (this.toHexString)\n            return { $oid: this.toHexString() };\n        return { $oid: this.toString('hex') };\n    }\n    static fromExtendedJSON(doc) {\n        return new ObjectId(doc.$oid);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        return `new ObjectId(${inspect(this.toHexString(), options)})`;\n    }\n}\nObjectId.index = Math.floor(Math.random() * 0xffffff);\n\nfunction internalCalculateObjectSize(object, serializeFunctions, ignoreUndefined) {\n    let totalLength = 4 + 1;\n    if (Array.isArray(object)) {\n        for (let i = 0; i < object.length; i++) {\n            totalLength += calculateElement(i.toString(), object[i], serializeFunctions, true, ignoreUndefined);\n        }\n    }\n    else {\n        if (typeof object?.toBSON === 'function') {\n            object = object.toBSON();\n        }\n        for (const key of Object.keys(object)) {\n            totalLength += calculateElement(key, object[key], serializeFunctions, false, ignoreUndefined);\n        }\n    }\n    return totalLength;\n}\nfunction calculateElement(name, value, serializeFunctions = false, isArray = false, ignoreUndefined = false) {\n    if (typeof value?.toBSON === 'function') {\n        value = value.toBSON();\n    }\n    switch (typeof value) {\n        case 'string':\n            return 1 + ByteUtils.utf8ByteLength(name) + 1 + 4 + ByteUtils.utf8ByteLength(value) + 1;\n        case 'number':\n            if (Math.floor(value) === value &&\n                value >= JS_INT_MIN &&\n                value <= JS_INT_MAX) {\n                if (value >= BSON_INT32_MIN && value <= BSON_INT32_MAX) {\n                    return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (4 + 1);\n                }\n                else {\n                    return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (8 + 1);\n                }\n            }\n            else {\n                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (8 + 1);\n            }\n        case 'undefined':\n            if (isArray || !ignoreUndefined)\n                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + 1;\n            return 0;\n        case 'boolean':\n            return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (1 + 1);\n        case 'object':\n            if (value != null &&\n                typeof value._bsontype === 'string' &&\n                value[Symbol.for('@@mdb.bson.version')] !== BSON_MAJOR_VERSION) {\n                throw new BSONVersionError();\n            }\n            else if (value == null || value._bsontype === 'MinKey' || value._bsontype === 'MaxKey') {\n                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + 1;\n            }\n            else if (value._bsontype === 'ObjectId') {\n                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (12 + 1);\n            }\n            else if (value instanceof Date || isDate(value)) {\n                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (8 + 1);\n            }\n            else if (ArrayBuffer.isView(value) ||\n                value instanceof ArrayBuffer ||\n                isAnyArrayBuffer(value)) {\n                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (1 + 4 + 1) + value.byteLength);\n            }\n            else if (value._bsontype === 'Long' ||\n                value._bsontype === 'Double' ||\n                value._bsontype === 'Timestamp') {\n                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (8 + 1);\n            }\n            else if (value._bsontype === 'Decimal128') {\n                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (16 + 1);\n            }\n            else if (value._bsontype === 'Code') {\n                if (value.scope != null && Object.keys(value.scope).length > 0) {\n                    return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                        1 +\n                        4 +\n                        4 +\n                        ByteUtils.utf8ByteLength(value.code.toString()) +\n                        1 +\n                        internalCalculateObjectSize(value.scope, serializeFunctions, ignoreUndefined));\n                }\n                else {\n                    return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                        1 +\n                        4 +\n                        ByteUtils.utf8ByteLength(value.code.toString()) +\n                        1);\n                }\n            }\n            else if (value._bsontype === 'Binary') {\n                const binary = value;\n                if (binary.sub_type === Binary.SUBTYPE_BYTE_ARRAY) {\n                    return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                        (binary.position + 1 + 4 + 1 + 4));\n                }\n                else {\n                    return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (binary.position + 1 + 4 + 1));\n                }\n            }\n            else if (value._bsontype === 'Symbol') {\n                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                    ByteUtils.utf8ByteLength(value.value) +\n                    4 +\n                    1 +\n                    1);\n            }\n            else if (value._bsontype === 'DBRef') {\n                const ordered_values = Object.assign({\n                    $ref: value.collection,\n                    $id: value.oid\n                }, value.fields);\n                if (value.db != null) {\n                    ordered_values['$db'] = value.db;\n                }\n                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                    1 +\n                    internalCalculateObjectSize(ordered_values, serializeFunctions, ignoreUndefined));\n            }\n            else if (value instanceof RegExp || isRegExp(value)) {\n                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                    1 +\n                    ByteUtils.utf8ByteLength(value.source) +\n                    1 +\n                    (value.global ? 1 : 0) +\n                    (value.ignoreCase ? 1 : 0) +\n                    (value.multiline ? 1 : 0) +\n                    1);\n            }\n            else if (value._bsontype === 'BSONRegExp') {\n                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                    1 +\n                    ByteUtils.utf8ByteLength(value.pattern) +\n                    1 +\n                    ByteUtils.utf8ByteLength(value.options) +\n                    1);\n            }\n            else {\n                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                    internalCalculateObjectSize(value, serializeFunctions, ignoreUndefined) +\n                    1);\n            }\n        case 'function':\n            if (serializeFunctions) {\n                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                    1 +\n                    4 +\n                    ByteUtils.utf8ByteLength(value.toString()) +\n                    1);\n            }\n    }\n    return 0;\n}\n\nfunction alphabetize(str) {\n    return str.split('').sort().join('');\n}\nclass BSONRegExp extends BSONValue {\n    get _bsontype() {\n        return 'BSONRegExp';\n    }\n    constructor(pattern, options) {\n        super();\n        this.pattern = pattern;\n        this.options = alphabetize(options ?? '');\n        if (this.pattern.indexOf('\\x00') !== -1) {\n            throw new BSONError(`BSON Regex patterns cannot contain null bytes, found: ${JSON.stringify(this.pattern)}`);\n        }\n        if (this.options.indexOf('\\x00') !== -1) {\n            throw new BSONError(`BSON Regex options cannot contain null bytes, found: ${JSON.stringify(this.options)}`);\n        }\n        for (let i = 0; i < this.options.length; i++) {\n            if (!(this.options[i] === 'i' ||\n                this.options[i] === 'm' ||\n                this.options[i] === 'x' ||\n                this.options[i] === 'l' ||\n                this.options[i] === 's' ||\n                this.options[i] === 'u')) {\n                throw new BSONError(`The regular expression option [${this.options[i]}] is not supported`);\n            }\n        }\n    }\n    static parseOptions(options) {\n        return options ? options.split('').sort().join('') : '';\n    }\n    toExtendedJSON(options) {\n        options = options || {};\n        if (options.legacy) {\n            return { $regex: this.pattern, $options: this.options };\n        }\n        return { $regularExpression: { pattern: this.pattern, options: this.options } };\n    }\n    static fromExtendedJSON(doc) {\n        if ('$regex' in doc) {\n            if (typeof doc.$regex !== 'string') {\n                if (doc.$regex._bsontype === 'BSONRegExp') {\n                    return doc;\n                }\n            }\n            else {\n                return new BSONRegExp(doc.$regex, BSONRegExp.parseOptions(doc.$options));\n            }\n        }\n        if ('$regularExpression' in doc) {\n            return new BSONRegExp(doc.$regularExpression.pattern, BSONRegExp.parseOptions(doc.$regularExpression.options));\n        }\n        throw new BSONError(`Unexpected BSONRegExp EJSON object form: ${JSON.stringify(doc)}`);\n    }\n    inspect(depth, options, inspect) {\n        const stylize = getStylizeFunction(options) ?? (v => v);\n        inspect ??= defaultInspect;\n        const pattern = stylize(inspect(this.pattern), 'regexp');\n        const flags = stylize(inspect(this.options), 'regexp');\n        return `new BSONRegExp(${pattern}, ${flags})`;\n    }\n}\n\nclass BSONSymbol extends BSONValue {\n    get _bsontype() {\n        return 'BSONSymbol';\n    }\n    constructor(value) {\n        super();\n        this.value = value;\n    }\n    valueOf() {\n        return this.value;\n    }\n    toString() {\n        return this.value;\n    }\n    toJSON() {\n        return this.value;\n    }\n    toExtendedJSON() {\n        return { $symbol: this.value };\n    }\n    static fromExtendedJSON(doc) {\n        return new BSONSymbol(doc.$symbol);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        return `new BSONSymbol(${inspect(this.value, options)})`;\n    }\n}\n\nconst LongWithoutOverridesClass = Long;\nclass Timestamp extends LongWithoutOverridesClass {\n    get _bsontype() {\n        return 'Timestamp';\n    }\n    constructor(low) {\n        if (low == null) {\n            super(0, 0, true);\n        }\n        else if (typeof low === 'bigint') {\n            super(low, true);\n        }\n        else if (Long.isLong(low)) {\n            super(low.low, low.high, true);\n        }\n        else if (typeof low === 'object' && 't' in low && 'i' in low) {\n            if (typeof low.t !== 'number' && (typeof low.t !== 'object' || low.t._bsontype !== 'Int32')) {\n                throw new BSONError('Timestamp constructed from { t, i } must provide t as a number');\n            }\n            if (typeof low.i !== 'number' && (typeof low.i !== 'object' || low.i._bsontype !== 'Int32')) {\n                throw new BSONError('Timestamp constructed from { t, i } must provide i as a number');\n            }\n            const t = Number(low.t);\n            const i = Number(low.i);\n            if (t < 0 || Number.isNaN(t)) {\n                throw new BSONError('Timestamp constructed from { t, i } must provide a positive t');\n            }\n            if (i < 0 || Number.isNaN(i)) {\n                throw new BSONError('Timestamp constructed from { t, i } must provide a positive i');\n            }\n            if (t > 4294967295) {\n                throw new BSONError('Timestamp constructed from { t, i } must provide t equal or less than uint32 max');\n            }\n            if (i > 4294967295) {\n                throw new BSONError('Timestamp constructed from { t, i } must provide i equal or less than uint32 max');\n            }\n            super(i, t, true);\n        }\n        else {\n            throw new BSONError('A Timestamp can only be constructed with: bigint, Long, or { t: number; i: number }');\n        }\n    }\n    toJSON() {\n        return {\n            $timestamp: this.toString()\n        };\n    }\n    static fromInt(value) {\n        return new Timestamp(Long.fromInt(value, true));\n    }\n    static fromNumber(value) {\n        return new Timestamp(Long.fromNumber(value, true));\n    }\n    static fromBits(lowBits, highBits) {\n        return new Timestamp({ i: lowBits, t: highBits });\n    }\n    static fromString(str, optRadix) {\n        return new Timestamp(Long.fromString(str, true, optRadix));\n    }\n    toExtendedJSON() {\n        return { $timestamp: { t: this.high >>> 0, i: this.low >>> 0 } };\n    }\n    static fromExtendedJSON(doc) {\n        const i = Long.isLong(doc.$timestamp.i)\n            ? doc.$timestamp.i.getLowBitsUnsigned()\n            : doc.$timestamp.i;\n        const t = Long.isLong(doc.$timestamp.t)\n            ? doc.$timestamp.t.getLowBitsUnsigned()\n            : doc.$timestamp.t;\n        return new Timestamp({ t, i });\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        const t = inspect(this.high >>> 0, options);\n        const i = inspect(this.low >>> 0, options);\n        return `new Timestamp({ t: ${t}, i: ${i} })`;\n    }\n}\nTimestamp.MAX_VALUE = Long.MAX_UNSIGNED_VALUE;\n\nconst FIRST_BIT = 0x80;\nconst FIRST_TWO_BITS = 0xc0;\nconst FIRST_THREE_BITS = 0xe0;\nconst FIRST_FOUR_BITS = 0xf0;\nconst FIRST_FIVE_BITS = 0xf8;\nconst TWO_BIT_CHAR = 0xc0;\nconst THREE_BIT_CHAR = 0xe0;\nconst FOUR_BIT_CHAR = 0xf0;\nconst CONTINUING_CHAR = 0x80;\nfunction validateUtf8(bytes, start, end) {\n    let continuation = 0;\n    for (let i = start; i < end; i += 1) {\n        const byte = bytes[i];\n        if (continuation) {\n            if ((byte & FIRST_TWO_BITS) !== CONTINUING_CHAR) {\n                return false;\n            }\n            continuation -= 1;\n        }\n        else if (byte & FIRST_BIT) {\n            if ((byte & FIRST_THREE_BITS) === TWO_BIT_CHAR) {\n                continuation = 1;\n            }\n            else if ((byte & FIRST_FOUR_BITS) === THREE_BIT_CHAR) {\n                continuation = 2;\n            }\n            else if ((byte & FIRST_FIVE_BITS) === FOUR_BIT_CHAR) {\n                continuation = 3;\n            }\n            else {\n                return false;\n            }\n        }\n    }\n    return !continuation;\n}\n\nconst JS_INT_MAX_LONG = Long.fromNumber(JS_INT_MAX);\nconst JS_INT_MIN_LONG = Long.fromNumber(JS_INT_MIN);\nfunction internalDeserialize(buffer, options, isArray) {\n    options = options == null ? {} : options;\n    const index = options && options.index ? options.index : 0;\n    const size = buffer[index] |\n        (buffer[index + 1] << 8) |\n        (buffer[index + 2] << 16) |\n        (buffer[index + 3] << 24);\n    if (size < 5) {\n        throw new BSONError(`bson size must be >= 5, is ${size}`);\n    }\n    if (options.allowObjectSmallerThanBufferSize && buffer.length < size) {\n        throw new BSONError(`buffer length ${buffer.length} must be >= bson size ${size}`);\n    }\n    if (!options.allowObjectSmallerThanBufferSize && buffer.length !== size) {\n        throw new BSONError(`buffer length ${buffer.length} must === bson size ${size}`);\n    }\n    if (size + index > buffer.byteLength) {\n        throw new BSONError(`(bson size ${size} + options.index ${index} must be <= buffer length ${buffer.byteLength})`);\n    }\n    if (buffer[index + size - 1] !== 0) {\n        throw new BSONError(\"One object, sized correctly, with a spot for an EOO, but the EOO isn't 0x00\");\n    }\n    return deserializeObject(buffer, index, options, isArray);\n}\nconst allowedDBRefKeys = /^\\$ref$|^\\$id$|^\\$db$/;\nfunction deserializeObject(buffer, index, options, isArray = false) {\n    const fieldsAsRaw = options['fieldsAsRaw'] == null ? null : options['fieldsAsRaw'];\n    const raw = options['raw'] == null ? false : options['raw'];\n    const bsonRegExp = typeof options['bsonRegExp'] === 'boolean' ? options['bsonRegExp'] : false;\n    const promoteBuffers = options.promoteBuffers ?? false;\n    const promoteLongs = options.promoteLongs ?? true;\n    const promoteValues = options.promoteValues ?? true;\n    const useBigInt64 = options.useBigInt64 ?? false;\n    if (useBigInt64 && !promoteValues) {\n        throw new BSONError('Must either request bigint or Long for int64 deserialization');\n    }\n    if (useBigInt64 && !promoteLongs) {\n        throw new BSONError('Must either request bigint or Long for int64 deserialization');\n    }\n    const validation = options.validation == null ? { utf8: true } : options.validation;\n    let globalUTFValidation = true;\n    let validationSetting;\n    const utf8KeysSet = new Set();\n    const utf8ValidatedKeys = validation.utf8;\n    if (typeof utf8ValidatedKeys === 'boolean') {\n        validationSetting = utf8ValidatedKeys;\n    }\n    else {\n        globalUTFValidation = false;\n        const utf8ValidationValues = Object.keys(utf8ValidatedKeys).map(function (key) {\n            return utf8ValidatedKeys[key];\n        });\n        if (utf8ValidationValues.length === 0) {\n            throw new BSONError('UTF-8 validation setting cannot be empty');\n        }\n        if (typeof utf8ValidationValues[0] !== 'boolean') {\n            throw new BSONError('Invalid UTF-8 validation option, must specify boolean values');\n        }\n        validationSetting = utf8ValidationValues[0];\n        if (!utf8ValidationValues.every(item => item === validationSetting)) {\n            throw new BSONError('Invalid UTF-8 validation option - keys must be all true or all false');\n        }\n    }\n    if (!globalUTFValidation) {\n        for (const key of Object.keys(utf8ValidatedKeys)) {\n            utf8KeysSet.add(key);\n        }\n    }\n    const startIndex = index;\n    if (buffer.length < 5)\n        throw new BSONError('corrupt bson message < 5 bytes long');\n    const size = buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24);\n    if (size < 5 || size > buffer.length)\n        throw new BSONError('corrupt bson message');\n    const object = isArray ? [] : {};\n    let arrayIndex = 0;\n    const done = false;\n    let isPossibleDBRef = isArray ? false : null;\n    const dataview = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength);\n    while (!done) {\n        const elementType = buffer[index++];\n        if (elementType === 0)\n            break;\n        let i = index;\n        while (buffer[i] !== 0x00 && i < buffer.length) {\n            i++;\n        }\n        if (i >= buffer.byteLength)\n            throw new BSONError('Bad BSON Document: illegal CString');\n        const name = isArray ? arrayIndex++ : ByteUtils.toUTF8(buffer, index, i);\n        let shouldValidateKey = true;\n        if (globalUTFValidation || utf8KeysSet.has(name)) {\n            shouldValidateKey = validationSetting;\n        }\n        else {\n            shouldValidateKey = !validationSetting;\n        }\n        if (isPossibleDBRef !== false && name[0] === '$') {\n            isPossibleDBRef = allowedDBRefKeys.test(name);\n        }\n        let value;\n        index = i + 1;\n        if (elementType === BSON_DATA_STRING) {\n            const stringSize = buffer[index++] |\n                (buffer[index++] << 8) |\n                (buffer[index++] << 16) |\n                (buffer[index++] << 24);\n            if (stringSize <= 0 ||\n                stringSize > buffer.length - index ||\n                buffer[index + stringSize - 1] !== 0) {\n                throw new BSONError('bad string length in bson');\n            }\n            value = getValidatedString(buffer, index, index + stringSize - 1, shouldValidateKey);\n            index = index + stringSize;\n        }\n        else if (elementType === BSON_DATA_OID) {\n            const oid = ByteUtils.allocate(12);\n            oid.set(buffer.subarray(index, index + 12));\n            value = new ObjectId(oid);\n            index = index + 12;\n        }\n        else if (elementType === BSON_DATA_INT && promoteValues === false) {\n            value = new Int32(buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24));\n        }\n        else if (elementType === BSON_DATA_INT) {\n            value =\n                buffer[index++] |\n                    (buffer[index++] << 8) |\n                    (buffer[index++] << 16) |\n                    (buffer[index++] << 24);\n        }\n        else if (elementType === BSON_DATA_NUMBER && promoteValues === false) {\n            value = new Double(dataview.getFloat64(index, true));\n            index = index + 8;\n        }\n        else if (elementType === BSON_DATA_NUMBER) {\n            value = dataview.getFloat64(index, true);\n            index = index + 8;\n        }\n        else if (elementType === BSON_DATA_DATE) {\n            const lowBits = buffer[index++] |\n                (buffer[index++] << 8) |\n                (buffer[index++] << 16) |\n                (buffer[index++] << 24);\n            const highBits = buffer[index++] |\n                (buffer[index++] << 8) |\n                (buffer[index++] << 16) |\n                (buffer[index++] << 24);\n            value = new Date(new Long(lowBits, highBits).toNumber());\n        }\n        else if (elementType === BSON_DATA_BOOLEAN) {\n            if (buffer[index] !== 0 && buffer[index] !== 1)\n                throw new BSONError('illegal boolean type value');\n            value = buffer[index++] === 1;\n        }\n        else if (elementType === BSON_DATA_OBJECT) {\n            const _index = index;\n            const objectSize = buffer[index] |\n                (buffer[index + 1] << 8) |\n                (buffer[index + 2] << 16) |\n                (buffer[index + 3] << 24);\n            if (objectSize <= 0 || objectSize > buffer.length - index)\n                throw new BSONError('bad embedded document length in bson');\n            if (raw) {\n                value = buffer.slice(index, index + objectSize);\n            }\n            else {\n                let objectOptions = options;\n                if (!globalUTFValidation) {\n                    objectOptions = { ...options, validation: { utf8: shouldValidateKey } };\n                }\n                value = deserializeObject(buffer, _index, objectOptions, false);\n            }\n            index = index + objectSize;\n        }\n        else if (elementType === BSON_DATA_ARRAY) {\n            const _index = index;\n            const objectSize = buffer[index] |\n                (buffer[index + 1] << 8) |\n                (buffer[index + 2] << 16) |\n                (buffer[index + 3] << 24);\n            let arrayOptions = options;\n            const stopIndex = index + objectSize;\n            if (fieldsAsRaw && fieldsAsRaw[name]) {\n                arrayOptions = { ...options, raw: true };\n            }\n            if (!globalUTFValidation) {\n                arrayOptions = { ...arrayOptions, validation: { utf8: shouldValidateKey } };\n            }\n            value = deserializeObject(buffer, _index, arrayOptions, true);\n            index = index + objectSize;\n            if (buffer[index - 1] !== 0)\n                throw new BSONError('invalid array terminator byte');\n            if (index !== stopIndex)\n                throw new BSONError('corrupted array bson');\n        }\n        else if (elementType === BSON_DATA_UNDEFINED) {\n            value = undefined;\n        }\n        else if (elementType === BSON_DATA_NULL) {\n            value = null;\n        }\n        else if (elementType === BSON_DATA_LONG) {\n            const dataview = BSONDataView.fromUint8Array(buffer.subarray(index, index + 8));\n            const lowBits = buffer[index++] |\n                (buffer[index++] << 8) |\n                (buffer[index++] << 16) |\n                (buffer[index++] << 24);\n            const highBits = buffer[index++] |\n                (buffer[index++] << 8) |\n                (buffer[index++] << 16) |\n                (buffer[index++] << 24);\n            const long = new Long(lowBits, highBits);\n            if (useBigInt64) {\n                value = dataview.getBigInt64(0, true);\n            }\n            else if (promoteLongs && promoteValues === true) {\n                value =\n                    long.lessThanOrEqual(JS_INT_MAX_LONG) && long.greaterThanOrEqual(JS_INT_MIN_LONG)\n                        ? long.toNumber()\n                        : long;\n            }\n            else {\n                value = long;\n            }\n        }\n        else if (elementType === BSON_DATA_DECIMAL128) {\n            const bytes = ByteUtils.allocate(16);\n            bytes.set(buffer.subarray(index, index + 16), 0);\n            index = index + 16;\n            value = new Decimal128(bytes);\n        }\n        else if (elementType === BSON_DATA_BINARY) {\n            let binarySize = buffer[index++] |\n                (buffer[index++] << 8) |\n                (buffer[index++] << 16) |\n                (buffer[index++] << 24);\n            const totalBinarySize = binarySize;\n            const subType = buffer[index++];\n            if (binarySize < 0)\n                throw new BSONError('Negative binary type element size found');\n            if (binarySize > buffer.byteLength)\n                throw new BSONError('Binary type size larger than document size');\n            if (buffer['slice'] != null) {\n                if (subType === Binary.SUBTYPE_BYTE_ARRAY) {\n                    binarySize =\n                        buffer[index++] |\n                            (buffer[index++] << 8) |\n                            (buffer[index++] << 16) |\n                            (buffer[index++] << 24);\n                    if (binarySize < 0)\n                        throw new BSONError('Negative binary type element size found for subtype 0x02');\n                    if (binarySize > totalBinarySize - 4)\n                        throw new BSONError('Binary type with subtype 0x02 contains too long binary size');\n                    if (binarySize < totalBinarySize - 4)\n                        throw new BSONError('Binary type with subtype 0x02 contains too short binary size');\n                }\n                if (promoteBuffers && promoteValues) {\n                    value = ByteUtils.toLocalBufferType(buffer.slice(index, index + binarySize));\n                }\n                else {\n                    value = new Binary(buffer.slice(index, index + binarySize), subType);\n                    if (subType === BSON_BINARY_SUBTYPE_UUID_NEW && UUID.isValid(value)) {\n                        value = value.toUUID();\n                    }\n                }\n            }\n            else {\n                const _buffer = ByteUtils.allocate(binarySize);\n                if (subType === Binary.SUBTYPE_BYTE_ARRAY) {\n                    binarySize =\n                        buffer[index++] |\n                            (buffer[index++] << 8) |\n                            (buffer[index++] << 16) |\n                            (buffer[index++] << 24);\n                    if (binarySize < 0)\n                        throw new BSONError('Negative binary type element size found for subtype 0x02');\n                    if (binarySize > totalBinarySize - 4)\n                        throw new BSONError('Binary type with subtype 0x02 contains too long binary size');\n                    if (binarySize < totalBinarySize - 4)\n                        throw new BSONError('Binary type with subtype 0x02 contains too short binary size');\n                }\n                for (i = 0; i < binarySize; i++) {\n                    _buffer[i] = buffer[index + i];\n                }\n                if (promoteBuffers && promoteValues) {\n                    value = _buffer;\n                }\n                else {\n                    value = new Binary(buffer.slice(index, index + binarySize), subType);\n                    if (subType === BSON_BINARY_SUBTYPE_UUID_NEW && UUID.isValid(value)) {\n                        value = value.toUUID();\n                    }\n                }\n            }\n            index = index + binarySize;\n        }\n        else if (elementType === BSON_DATA_REGEXP && bsonRegExp === false) {\n            i = index;\n            while (buffer[i] !== 0x00 && i < buffer.length) {\n                i++;\n            }\n            if (i >= buffer.length)\n                throw new BSONError('Bad BSON Document: illegal CString');\n            const source = ByteUtils.toUTF8(buffer, index, i);\n            index = i + 1;\n            i = index;\n            while (buffer[i] !== 0x00 && i < buffer.length) {\n                i++;\n            }\n            if (i >= buffer.length)\n                throw new BSONError('Bad BSON Document: illegal CString');\n            const regExpOptions = ByteUtils.toUTF8(buffer, index, i);\n            index = i + 1;\n            const optionsArray = new Array(regExpOptions.length);\n            for (i = 0; i < regExpOptions.length; i++) {\n                switch (regExpOptions[i]) {\n                    case 'm':\n                        optionsArray[i] = 'm';\n                        break;\n                    case 's':\n                        optionsArray[i] = 'g';\n                        break;\n                    case 'i':\n                        optionsArray[i] = 'i';\n                        break;\n                }\n            }\n            value = new RegExp(source, optionsArray.join(''));\n        }\n        else if (elementType === BSON_DATA_REGEXP && bsonRegExp === true) {\n            i = index;\n            while (buffer[i] !== 0x00 && i < buffer.length) {\n                i++;\n            }\n            if (i >= buffer.length)\n                throw new BSONError('Bad BSON Document: illegal CString');\n            const source = ByteUtils.toUTF8(buffer, index, i);\n            index = i + 1;\n            i = index;\n            while (buffer[i] !== 0x00 && i < buffer.length) {\n                i++;\n            }\n            if (i >= buffer.length)\n                throw new BSONError('Bad BSON Document: illegal CString');\n            const regExpOptions = ByteUtils.toUTF8(buffer, index, i);\n            index = i + 1;\n            value = new BSONRegExp(source, regExpOptions);\n        }\n        else if (elementType === BSON_DATA_SYMBOL) {\n            const stringSize = buffer[index++] |\n                (buffer[index++] << 8) |\n                (buffer[index++] << 16) |\n                (buffer[index++] << 24);\n            if (stringSize <= 0 ||\n                stringSize > buffer.length - index ||\n                buffer[index + stringSize - 1] !== 0) {\n                throw new BSONError('bad string length in bson');\n            }\n            const symbol = getValidatedString(buffer, index, index + stringSize - 1, shouldValidateKey);\n            value = promoteValues ? symbol : new BSONSymbol(symbol);\n            index = index + stringSize;\n        }\n        else if (elementType === BSON_DATA_TIMESTAMP) {\n            const i = buffer[index++] +\n                buffer[index++] * (1 << 8) +\n                buffer[index++] * (1 << 16) +\n                buffer[index++] * (1 << 24);\n            const t = buffer[index++] +\n                buffer[index++] * (1 << 8) +\n                buffer[index++] * (1 << 16) +\n                buffer[index++] * (1 << 24);\n            value = new Timestamp({ i, t });\n        }\n        else if (elementType === BSON_DATA_MIN_KEY) {\n            value = new MinKey();\n        }\n        else if (elementType === BSON_DATA_MAX_KEY) {\n            value = new MaxKey();\n        }\n        else if (elementType === BSON_DATA_CODE) {\n            const stringSize = buffer[index++] |\n                (buffer[index++] << 8) |\n                (buffer[index++] << 16) |\n                (buffer[index++] << 24);\n            if (stringSize <= 0 ||\n                stringSize > buffer.length - index ||\n                buffer[index + stringSize - 1] !== 0) {\n                throw new BSONError('bad string length in bson');\n            }\n            const functionString = getValidatedString(buffer, index, index + stringSize - 1, shouldValidateKey);\n            value = new Code(functionString);\n            index = index + stringSize;\n        }\n        else if (elementType === BSON_DATA_CODE_W_SCOPE) {\n            const totalSize = buffer[index++] |\n                (buffer[index++] << 8) |\n                (buffer[index++] << 16) |\n                (buffer[index++] << 24);\n            if (totalSize < 4 + 4 + 4 + 1) {\n                throw new BSONError('code_w_scope total size shorter minimum expected length');\n            }\n            const stringSize = buffer[index++] |\n                (buffer[index++] << 8) |\n                (buffer[index++] << 16) |\n                (buffer[index++] << 24);\n            if (stringSize <= 0 ||\n                stringSize > buffer.length - index ||\n                buffer[index + stringSize - 1] !== 0) {\n                throw new BSONError('bad string length in bson');\n            }\n            const functionString = getValidatedString(buffer, index, index + stringSize - 1, shouldValidateKey);\n            index = index + stringSize;\n            const _index = index;\n            const objectSize = buffer[index] |\n                (buffer[index + 1] << 8) |\n                (buffer[index + 2] << 16) |\n                (buffer[index + 3] << 24);\n            const scopeObject = deserializeObject(buffer, _index, options, false);\n            index = index + objectSize;\n            if (totalSize < 4 + 4 + objectSize + stringSize) {\n                throw new BSONError('code_w_scope total size is too short, truncating scope');\n            }\n            if (totalSize > 4 + 4 + objectSize + stringSize) {\n                throw new BSONError('code_w_scope total size is too long, clips outer document');\n            }\n            value = new Code(functionString, scopeObject);\n        }\n        else if (elementType === BSON_DATA_DBPOINTER) {\n            const stringSize = buffer[index++] |\n                (buffer[index++] << 8) |\n                (buffer[index++] << 16) |\n                (buffer[index++] << 24);\n            if (stringSize <= 0 ||\n                stringSize > buffer.length - index ||\n                buffer[index + stringSize - 1] !== 0)\n                throw new BSONError('bad string length in bson');\n            if (validation != null && validation.utf8) {\n                if (!validateUtf8(buffer, index, index + stringSize - 1)) {\n                    throw new BSONError('Invalid UTF-8 string in BSON document');\n                }\n            }\n            const namespace = ByteUtils.toUTF8(buffer, index, index + stringSize - 1);\n            index = index + stringSize;\n            const oidBuffer = ByteUtils.allocate(12);\n            oidBuffer.set(buffer.subarray(index, index + 12), 0);\n            const oid = new ObjectId(oidBuffer);\n            index = index + 12;\n            value = new DBRef(namespace, oid);\n        }\n        else {\n            throw new BSONError(`Detected unknown BSON type ${elementType.toString(16)} for fieldname \"${name}\"`);\n        }\n        if (name === '__proto__') {\n            Object.defineProperty(object, name, {\n                value,\n                writable: true,\n                enumerable: true,\n                configurable: true\n            });\n        }\n        else {\n            object[name] = value;\n        }\n    }\n    if (size !== index - startIndex) {\n        if (isArray)\n            throw new BSONError('corrupt array bson');\n        throw new BSONError('corrupt object bson');\n    }\n    if (!isPossibleDBRef)\n        return object;\n    if (isDBRefLike(object)) {\n        const copy = Object.assign({}, object);\n        delete copy.$ref;\n        delete copy.$id;\n        delete copy.$db;\n        return new DBRef(object.$ref, object.$id, object.$db, copy);\n    }\n    return object;\n}\nfunction getValidatedString(buffer, start, end, shouldValidateUtf8) {\n    const value = ByteUtils.toUTF8(buffer, start, end);\n    if (shouldValidateUtf8) {\n        for (let i = 0; i < value.length; i++) {\n            if (value.charCodeAt(i) === 0xfffd) {\n                if (!validateUtf8(buffer, start, end)) {\n                    throw new BSONError('Invalid UTF-8 string in BSON document');\n                }\n                break;\n            }\n        }\n    }\n    return value;\n}\n\nconst regexp = /\\x00/;\nconst ignoreKeys = new Set(['$db', '$ref', '$id', '$clusterTime']);\nfunction serializeString(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_STRING;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes + 1;\n    buffer[index - 1] = 0;\n    const size = ByteUtils.encodeUTF8Into(buffer, value, index + 4);\n    buffer[index + 3] = ((size + 1) >> 24) & 0xff;\n    buffer[index + 2] = ((size + 1) >> 16) & 0xff;\n    buffer[index + 1] = ((size + 1) >> 8) & 0xff;\n    buffer[index] = (size + 1) & 0xff;\n    index = index + 4 + size;\n    buffer[index++] = 0;\n    return index;\n}\nconst NUMBER_SPACE = new DataView(new ArrayBuffer(8), 0, 8);\nconst FOUR_BYTE_VIEW_ON_NUMBER = new Uint8Array(NUMBER_SPACE.buffer, 0, 4);\nconst EIGHT_BYTE_VIEW_ON_NUMBER = new Uint8Array(NUMBER_SPACE.buffer, 0, 8);\nfunction serializeNumber(buffer, key, value, index) {\n    const isNegativeZero = Object.is(value, -0);\n    const type = !isNegativeZero &&\n        Number.isSafeInteger(value) &&\n        value <= BSON_INT32_MAX &&\n        value >= BSON_INT32_MIN\n        ? BSON_DATA_INT\n        : BSON_DATA_NUMBER;\n    if (type === BSON_DATA_INT) {\n        NUMBER_SPACE.setInt32(0, value, true);\n    }\n    else {\n        NUMBER_SPACE.setFloat64(0, value, true);\n    }\n    const bytes = type === BSON_DATA_INT ? FOUR_BYTE_VIEW_ON_NUMBER : EIGHT_BYTE_VIEW_ON_NUMBER;\n    buffer[index++] = type;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0x00;\n    buffer.set(bytes, index);\n    index += bytes.byteLength;\n    return index;\n}\nfunction serializeBigInt(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_LONG;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index += numberOfWrittenBytes;\n    buffer[index++] = 0;\n    NUMBER_SPACE.setBigInt64(0, value, true);\n    buffer.set(EIGHT_BYTE_VIEW_ON_NUMBER, index);\n    index += EIGHT_BYTE_VIEW_ON_NUMBER.byteLength;\n    return index;\n}\nfunction serializeNull(buffer, key, _, index) {\n    buffer[index++] = BSON_DATA_NULL;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    return index;\n}\nfunction serializeBoolean(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_BOOLEAN;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    buffer[index++] = value ? 1 : 0;\n    return index;\n}\nfunction serializeDate(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_DATE;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    const dateInMilis = Long.fromNumber(value.getTime());\n    const lowBits = dateInMilis.getLowBits();\n    const highBits = dateInMilis.getHighBits();\n    buffer[index++] = lowBits & 0xff;\n    buffer[index++] = (lowBits >> 8) & 0xff;\n    buffer[index++] = (lowBits >> 16) & 0xff;\n    buffer[index++] = (lowBits >> 24) & 0xff;\n    buffer[index++] = highBits & 0xff;\n    buffer[index++] = (highBits >> 8) & 0xff;\n    buffer[index++] = (highBits >> 16) & 0xff;\n    buffer[index++] = (highBits >> 24) & 0xff;\n    return index;\n}\nfunction serializeRegExp(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_REGEXP;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    if (value.source && value.source.match(regexp) != null) {\n        throw new BSONError('value ' + value.source + ' must not contain null bytes');\n    }\n    index = index + ByteUtils.encodeUTF8Into(buffer, value.source, index);\n    buffer[index++] = 0x00;\n    if (value.ignoreCase)\n        buffer[index++] = 0x69;\n    if (value.global)\n        buffer[index++] = 0x73;\n    if (value.multiline)\n        buffer[index++] = 0x6d;\n    buffer[index++] = 0x00;\n    return index;\n}\nfunction serializeBSONRegExp(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_REGEXP;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    if (value.pattern.match(regexp) != null) {\n        throw new BSONError('pattern ' + value.pattern + ' must not contain null bytes');\n    }\n    index = index + ByteUtils.encodeUTF8Into(buffer, value.pattern, index);\n    buffer[index++] = 0x00;\n    const sortedOptions = value.options.split('').sort().join('');\n    index = index + ByteUtils.encodeUTF8Into(buffer, sortedOptions, index);\n    buffer[index++] = 0x00;\n    return index;\n}\nfunction serializeMinMax(buffer, key, value, index) {\n    if (value === null) {\n        buffer[index++] = BSON_DATA_NULL;\n    }\n    else if (value._bsontype === 'MinKey') {\n        buffer[index++] = BSON_DATA_MIN_KEY;\n    }\n    else {\n        buffer[index++] = BSON_DATA_MAX_KEY;\n    }\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    return index;\n}\nfunction serializeObjectId(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_OID;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    const idValue = value.id;\n    if (isUint8Array(idValue)) {\n        for (let i = 0; i < 12; i++) {\n            buffer[index++] = idValue[i];\n        }\n    }\n    else {\n        throw new BSONError('object [' + JSON.stringify(value) + '] is not a valid ObjectId');\n    }\n    return index;\n}\nfunction serializeBuffer(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_BINARY;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    const size = value.length;\n    buffer[index++] = size & 0xff;\n    buffer[index++] = (size >> 8) & 0xff;\n    buffer[index++] = (size >> 16) & 0xff;\n    buffer[index++] = (size >> 24) & 0xff;\n    buffer[index++] = BSON_BINARY_SUBTYPE_DEFAULT;\n    buffer.set(value, index);\n    index = index + size;\n    return index;\n}\nfunction serializeObject(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path) {\n    if (path.has(value)) {\n        throw new BSONError('Cannot convert circular structure to BSON');\n    }\n    path.add(value);\n    buffer[index++] = Array.isArray(value) ? BSON_DATA_ARRAY : BSON_DATA_OBJECT;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    const endIndex = serializeInto(buffer, value, checkKeys, index, depth + 1, serializeFunctions, ignoreUndefined, path);\n    path.delete(value);\n    return endIndex;\n}\nfunction serializeDecimal128(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_DECIMAL128;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    buffer.set(value.bytes.subarray(0, 16), index);\n    return index + 16;\n}\nfunction serializeLong(buffer, key, value, index) {\n    buffer[index++] =\n        value._bsontype === 'Long' ? BSON_DATA_LONG : BSON_DATA_TIMESTAMP;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    const lowBits = value.getLowBits();\n    const highBits = value.getHighBits();\n    buffer[index++] = lowBits & 0xff;\n    buffer[index++] = (lowBits >> 8) & 0xff;\n    buffer[index++] = (lowBits >> 16) & 0xff;\n    buffer[index++] = (lowBits >> 24) & 0xff;\n    buffer[index++] = highBits & 0xff;\n    buffer[index++] = (highBits >> 8) & 0xff;\n    buffer[index++] = (highBits >> 16) & 0xff;\n    buffer[index++] = (highBits >> 24) & 0xff;\n    return index;\n}\nfunction serializeInt32(buffer, key, value, index) {\n    value = value.valueOf();\n    buffer[index++] = BSON_DATA_INT;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    buffer[index++] = value & 0xff;\n    buffer[index++] = (value >> 8) & 0xff;\n    buffer[index++] = (value >> 16) & 0xff;\n    buffer[index++] = (value >> 24) & 0xff;\n    return index;\n}\nfunction serializeDouble(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_NUMBER;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    NUMBER_SPACE.setFloat64(0, value.value, true);\n    buffer.set(EIGHT_BYTE_VIEW_ON_NUMBER, index);\n    index = index + 8;\n    return index;\n}\nfunction serializeFunction(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_CODE;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    const functionString = value.toString();\n    const size = ByteUtils.encodeUTF8Into(buffer, functionString, index + 4) + 1;\n    buffer[index] = size & 0xff;\n    buffer[index + 1] = (size >> 8) & 0xff;\n    buffer[index + 2] = (size >> 16) & 0xff;\n    buffer[index + 3] = (size >> 24) & 0xff;\n    index = index + 4 + size - 1;\n    buffer[index++] = 0;\n    return index;\n}\nfunction serializeCode(buffer, key, value, index, checkKeys = false, depth = 0, serializeFunctions = false, ignoreUndefined = true, path) {\n    if (value.scope && typeof value.scope === 'object') {\n        buffer[index++] = BSON_DATA_CODE_W_SCOPE;\n        const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n        index = index + numberOfWrittenBytes;\n        buffer[index++] = 0;\n        let startIndex = index;\n        const functionString = value.code;\n        index = index + 4;\n        const codeSize = ByteUtils.encodeUTF8Into(buffer, functionString, index + 4) + 1;\n        buffer[index] = codeSize & 0xff;\n        buffer[index + 1] = (codeSize >> 8) & 0xff;\n        buffer[index + 2] = (codeSize >> 16) & 0xff;\n        buffer[index + 3] = (codeSize >> 24) & 0xff;\n        buffer[index + 4 + codeSize - 1] = 0;\n        index = index + codeSize + 4;\n        const endIndex = serializeInto(buffer, value.scope, checkKeys, index, depth + 1, serializeFunctions, ignoreUndefined, path);\n        index = endIndex - 1;\n        const totalSize = endIndex - startIndex;\n        buffer[startIndex++] = totalSize & 0xff;\n        buffer[startIndex++] = (totalSize >> 8) & 0xff;\n        buffer[startIndex++] = (totalSize >> 16) & 0xff;\n        buffer[startIndex++] = (totalSize >> 24) & 0xff;\n        buffer[index++] = 0;\n    }\n    else {\n        buffer[index++] = BSON_DATA_CODE;\n        const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n        index = index + numberOfWrittenBytes;\n        buffer[index++] = 0;\n        const functionString = value.code.toString();\n        const size = ByteUtils.encodeUTF8Into(buffer, functionString, index + 4) + 1;\n        buffer[index] = size & 0xff;\n        buffer[index + 1] = (size >> 8) & 0xff;\n        buffer[index + 2] = (size >> 16) & 0xff;\n        buffer[index + 3] = (size >> 24) & 0xff;\n        index = index + 4 + size - 1;\n        buffer[index++] = 0;\n    }\n    return index;\n}\nfunction serializeBinary(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_BINARY;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    const data = value.buffer;\n    let size = value.position;\n    if (value.sub_type === Binary.SUBTYPE_BYTE_ARRAY)\n        size = size + 4;\n    buffer[index++] = size & 0xff;\n    buffer[index++] = (size >> 8) & 0xff;\n    buffer[index++] = (size >> 16) & 0xff;\n    buffer[index++] = (size >> 24) & 0xff;\n    buffer[index++] = value.sub_type;\n    if (value.sub_type === Binary.SUBTYPE_BYTE_ARRAY) {\n        size = size - 4;\n        buffer[index++] = size & 0xff;\n        buffer[index++] = (size >> 8) & 0xff;\n        buffer[index++] = (size >> 16) & 0xff;\n        buffer[index++] = (size >> 24) & 0xff;\n    }\n    buffer.set(data, index);\n    index = index + value.position;\n    return index;\n}\nfunction serializeSymbol(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_SYMBOL;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    const size = ByteUtils.encodeUTF8Into(buffer, value.value, index + 4) + 1;\n    buffer[index] = size & 0xff;\n    buffer[index + 1] = (size >> 8) & 0xff;\n    buffer[index + 2] = (size >> 16) & 0xff;\n    buffer[index + 3] = (size >> 24) & 0xff;\n    index = index + 4 + size - 1;\n    buffer[index++] = 0x00;\n    return index;\n}\nfunction serializeDBRef(buffer, key, value, index, depth, serializeFunctions, path) {\n    buffer[index++] = BSON_DATA_OBJECT;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    let startIndex = index;\n    let output = {\n        $ref: value.collection || value.namespace,\n        $id: value.oid\n    };\n    if (value.db != null) {\n        output.$db = value.db;\n    }\n    output = Object.assign(output, value.fields);\n    const endIndex = serializeInto(buffer, output, false, index, depth + 1, serializeFunctions, true, path);\n    const size = endIndex - startIndex;\n    buffer[startIndex++] = size & 0xff;\n    buffer[startIndex++] = (size >> 8) & 0xff;\n    buffer[startIndex++] = (size >> 16) & 0xff;\n    buffer[startIndex++] = (size >> 24) & 0xff;\n    return endIndex;\n}\nfunction serializeInto(buffer, object, checkKeys, startingIndex, depth, serializeFunctions, ignoreUndefined, path) {\n    if (path == null) {\n        if (object == null) {\n            buffer[0] = 0x05;\n            buffer[1] = 0x00;\n            buffer[2] = 0x00;\n            buffer[3] = 0x00;\n            buffer[4] = 0x00;\n            return 5;\n        }\n        if (Array.isArray(object)) {\n            throw new BSONError('serialize does not support an array as the root input');\n        }\n        if (typeof object !== 'object') {\n            throw new BSONError('serialize does not support non-object as the root input');\n        }\n        else if ('_bsontype' in object && typeof object._bsontype === 'string') {\n            throw new BSONError(`BSON types cannot be serialized as a document`);\n        }\n        else if (isDate(object) ||\n            isRegExp(object) ||\n            isUint8Array(object) ||\n            isAnyArrayBuffer(object)) {\n            throw new BSONError(`date, regexp, typedarray, and arraybuffer cannot be BSON documents`);\n        }\n        path = new Set();\n    }\n    path.add(object);\n    let index = startingIndex + 4;\n    if (Array.isArray(object)) {\n        for (let i = 0; i < object.length; i++) {\n            const key = `${i}`;\n            let value = object[i];\n            if (typeof value?.toBSON === 'function') {\n                value = value.toBSON();\n            }\n            if (typeof value === 'string') {\n                index = serializeString(buffer, key, value, index);\n            }\n            else if (typeof value === 'number') {\n                index = serializeNumber(buffer, key, value, index);\n            }\n            else if (typeof value === 'bigint') {\n                index = serializeBigInt(buffer, key, value, index);\n            }\n            else if (typeof value === 'boolean') {\n                index = serializeBoolean(buffer, key, value, index);\n            }\n            else if (value instanceof Date || isDate(value)) {\n                index = serializeDate(buffer, key, value, index);\n            }\n            else if (value === undefined) {\n                index = serializeNull(buffer, key, value, index);\n            }\n            else if (value === null) {\n                index = serializeNull(buffer, key, value, index);\n            }\n            else if (isUint8Array(value)) {\n                index = serializeBuffer(buffer, key, value, index);\n            }\n            else if (value instanceof RegExp || isRegExp(value)) {\n                index = serializeRegExp(buffer, key, value, index);\n            }\n            else if (typeof value === 'object' && value._bsontype == null) {\n                index = serializeObject(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path);\n            }\n            else if (typeof value === 'object' &&\n                value[Symbol.for('@@mdb.bson.version')] !== BSON_MAJOR_VERSION) {\n                throw new BSONVersionError();\n            }\n            else if (value._bsontype === 'ObjectId') {\n                index = serializeObjectId(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Decimal128') {\n                index = serializeDecimal128(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Long' || value._bsontype === 'Timestamp') {\n                index = serializeLong(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Double') {\n                index = serializeDouble(buffer, key, value, index);\n            }\n            else if (typeof value === 'function' && serializeFunctions) {\n                index = serializeFunction(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Code') {\n                index = serializeCode(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path);\n            }\n            else if (value._bsontype === 'Binary') {\n                index = serializeBinary(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'BSONSymbol') {\n                index = serializeSymbol(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'DBRef') {\n                index = serializeDBRef(buffer, key, value, index, depth, serializeFunctions, path);\n            }\n            else if (value._bsontype === 'BSONRegExp') {\n                index = serializeBSONRegExp(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Int32') {\n                index = serializeInt32(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'MinKey' || value._bsontype === 'MaxKey') {\n                index = serializeMinMax(buffer, key, value, index);\n            }\n            else if (typeof value._bsontype !== 'undefined') {\n                throw new BSONError(`Unrecognized or invalid _bsontype: ${String(value._bsontype)}`);\n            }\n        }\n    }\n    else if (object instanceof Map || isMap(object)) {\n        const iterator = object.entries();\n        let done = false;\n        while (!done) {\n            const entry = iterator.next();\n            done = !!entry.done;\n            if (done)\n                continue;\n            const key = entry.value[0];\n            let value = entry.value[1];\n            if (typeof value?.toBSON === 'function') {\n                value = value.toBSON();\n            }\n            const type = typeof value;\n            if (typeof key === 'string' && !ignoreKeys.has(key)) {\n                if (key.match(regexp) != null) {\n                    throw new BSONError('key ' + key + ' must not contain null bytes');\n                }\n                if (checkKeys) {\n                    if ('$' === key[0]) {\n                        throw new BSONError('key ' + key + \" must not start with '$'\");\n                    }\n                    else if (~key.indexOf('.')) {\n                        throw new BSONError('key ' + key + \" must not contain '.'\");\n                    }\n                }\n            }\n            if (type === 'string') {\n                index = serializeString(buffer, key, value, index);\n            }\n            else if (type === 'number') {\n                index = serializeNumber(buffer, key, value, index);\n            }\n            else if (type === 'bigint') {\n                index = serializeBigInt(buffer, key, value, index);\n            }\n            else if (type === 'boolean') {\n                index = serializeBoolean(buffer, key, value, index);\n            }\n            else if (value instanceof Date || isDate(value)) {\n                index = serializeDate(buffer, key, value, index);\n            }\n            else if (value === null || (value === undefined && ignoreUndefined === false)) {\n                index = serializeNull(buffer, key, value, index);\n            }\n            else if (isUint8Array(value)) {\n                index = serializeBuffer(buffer, key, value, index);\n            }\n            else if (value instanceof RegExp || isRegExp(value)) {\n                index = serializeRegExp(buffer, key, value, index);\n            }\n            else if (type === 'object' && value._bsontype == null) {\n                index = serializeObject(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path);\n            }\n            else if (typeof value === 'object' &&\n                value[Symbol.for('@@mdb.bson.version')] !== BSON_MAJOR_VERSION) {\n                throw new BSONVersionError();\n            }\n            else if (value._bsontype === 'ObjectId') {\n                index = serializeObjectId(buffer, key, value, index);\n            }\n            else if (type === 'object' && value._bsontype === 'Decimal128') {\n                index = serializeDecimal128(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Long' || value._bsontype === 'Timestamp') {\n                index = serializeLong(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Double') {\n                index = serializeDouble(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Code') {\n                index = serializeCode(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path);\n            }\n            else if (typeof value === 'function' && serializeFunctions) {\n                index = serializeFunction(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Binary') {\n                index = serializeBinary(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'BSONSymbol') {\n                index = serializeSymbol(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'DBRef') {\n                index = serializeDBRef(buffer, key, value, index, depth, serializeFunctions, path);\n            }\n            else if (value._bsontype === 'BSONRegExp') {\n                index = serializeBSONRegExp(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Int32') {\n                index = serializeInt32(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'MinKey' || value._bsontype === 'MaxKey') {\n                index = serializeMinMax(buffer, key, value, index);\n            }\n            else if (typeof value._bsontype !== 'undefined') {\n                throw new BSONError(`Unrecognized or invalid _bsontype: ${String(value._bsontype)}`);\n            }\n        }\n    }\n    else {\n        if (typeof object?.toBSON === 'function') {\n            object = object.toBSON();\n            if (object != null && typeof object !== 'object') {\n                throw new BSONError('toBSON function did not return an object');\n            }\n        }\n        for (const key of Object.keys(object)) {\n            let value = object[key];\n            if (typeof value?.toBSON === 'function') {\n                value = value.toBSON();\n            }\n            const type = typeof value;\n            if (typeof key === 'string' && !ignoreKeys.has(key)) {\n                if (key.match(regexp) != null) {\n                    throw new BSONError('key ' + key + ' must not contain null bytes');\n                }\n                if (checkKeys) {\n                    if ('$' === key[0]) {\n                        throw new BSONError('key ' + key + \" must not start with '$'\");\n                    }\n                    else if (~key.indexOf('.')) {\n                        throw new BSONError('key ' + key + \" must not contain '.'\");\n                    }\n                }\n            }\n            if (type === 'string') {\n                index = serializeString(buffer, key, value, index);\n            }\n            else if (type === 'number') {\n                index = serializeNumber(buffer, key, value, index);\n            }\n            else if (type === 'bigint') {\n                index = serializeBigInt(buffer, key, value, index);\n            }\n            else if (type === 'boolean') {\n                index = serializeBoolean(buffer, key, value, index);\n            }\n            else if (value instanceof Date || isDate(value)) {\n                index = serializeDate(buffer, key, value, index);\n            }\n            else if (value === undefined) {\n                if (ignoreUndefined === false)\n                    index = serializeNull(buffer, key, value, index);\n            }\n            else if (value === null) {\n                index = serializeNull(buffer, key, value, index);\n            }\n            else if (isUint8Array(value)) {\n                index = serializeBuffer(buffer, key, value, index);\n            }\n            else if (value instanceof RegExp || isRegExp(value)) {\n                index = serializeRegExp(buffer, key, value, index);\n            }\n            else if (type === 'object' && value._bsontype == null) {\n                index = serializeObject(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path);\n            }\n            else if (typeof value === 'object' &&\n                value[Symbol.for('@@mdb.bson.version')] !== BSON_MAJOR_VERSION) {\n                throw new BSONVersionError();\n            }\n            else if (value._bsontype === 'ObjectId') {\n                index = serializeObjectId(buffer, key, value, index);\n            }\n            else if (type === 'object' && value._bsontype === 'Decimal128') {\n                index = serializeDecimal128(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Long' || value._bsontype === 'Timestamp') {\n                index = serializeLong(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Double') {\n                index = serializeDouble(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Code') {\n                index = serializeCode(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path);\n            }\n            else if (typeof value === 'function' && serializeFunctions) {\n                index = serializeFunction(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Binary') {\n                index = serializeBinary(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'BSONSymbol') {\n                index = serializeSymbol(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'DBRef') {\n                index = serializeDBRef(buffer, key, value, index, depth, serializeFunctions, path);\n            }\n            else if (value._bsontype === 'BSONRegExp') {\n                index = serializeBSONRegExp(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Int32') {\n                index = serializeInt32(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'MinKey' || value._bsontype === 'MaxKey') {\n                index = serializeMinMax(buffer, key, value, index);\n            }\n            else if (typeof value._bsontype !== 'undefined') {\n                throw new BSONError(`Unrecognized or invalid _bsontype: ${String(value._bsontype)}`);\n            }\n        }\n    }\n    path.delete(object);\n    buffer[index++] = 0x00;\n    const size = index - startingIndex;\n    buffer[startingIndex++] = size & 0xff;\n    buffer[startingIndex++] = (size >> 8) & 0xff;\n    buffer[startingIndex++] = (size >> 16) & 0xff;\n    buffer[startingIndex++] = (size >> 24) & 0xff;\n    return index;\n}\n\nfunction isBSONType(value) {\n    return (value != null &&\n        typeof value === 'object' &&\n        '_bsontype' in value &&\n        typeof value._bsontype === 'string');\n}\nconst keysToCodecs = {\n    $oid: ObjectId,\n    $binary: Binary,\n    $uuid: Binary,\n    $symbol: BSONSymbol,\n    $numberInt: Int32,\n    $numberDecimal: Decimal128,\n    $numberDouble: Double,\n    $numberLong: Long,\n    $minKey: MinKey,\n    $maxKey: MaxKey,\n    $regex: BSONRegExp,\n    $regularExpression: BSONRegExp,\n    $timestamp: Timestamp\n};\nfunction deserializeValue(value, options = {}) {\n    if (typeof value === 'number') {\n        const in32BitRange = value <= BSON_INT32_MAX && value >= BSON_INT32_MIN;\n        const in64BitRange = value <= BSON_INT64_MAX && value >= BSON_INT64_MIN;\n        if (options.relaxed || options.legacy) {\n            return value;\n        }\n        if (Number.isInteger(value) && !Object.is(value, -0)) {\n            if (in32BitRange) {\n                return new Int32(value);\n            }\n            if (in64BitRange) {\n                if (options.useBigInt64) {\n                    return BigInt(value);\n                }\n                return Long.fromNumber(value);\n            }\n        }\n        return new Double(value);\n    }\n    if (value == null || typeof value !== 'object')\n        return value;\n    if (value.$undefined)\n        return null;\n    const keys = Object.keys(value).filter(k => k.startsWith('$') && value[k] != null);\n    for (let i = 0; i < keys.length; i++) {\n        const c = keysToCodecs[keys[i]];\n        if (c)\n            return c.fromExtendedJSON(value, options);\n    }\n    if (value.$date != null) {\n        const d = value.$date;\n        const date = new Date();\n        if (options.legacy) {\n            if (typeof d === 'number')\n                date.setTime(d);\n            else if (typeof d === 'string')\n                date.setTime(Date.parse(d));\n            else if (typeof d === 'bigint')\n                date.setTime(Number(d));\n            else\n                throw new BSONRuntimeError(`Unrecognized type for EJSON date: ${typeof d}`);\n        }\n        else {\n            if (typeof d === 'string')\n                date.setTime(Date.parse(d));\n            else if (Long.isLong(d))\n                date.setTime(d.toNumber());\n            else if (typeof d === 'number' && options.relaxed)\n                date.setTime(d);\n            else if (typeof d === 'bigint')\n                date.setTime(Number(d));\n            else\n                throw new BSONRuntimeError(`Unrecognized type for EJSON date: ${typeof d}`);\n        }\n        return date;\n    }\n    if (value.$code != null) {\n        const copy = Object.assign({}, value);\n        if (value.$scope) {\n            copy.$scope = deserializeValue(value.$scope);\n        }\n        return Code.fromExtendedJSON(value);\n    }\n    if (isDBRefLike(value) || value.$dbPointer) {\n        const v = value.$ref ? value : value.$dbPointer;\n        if (v instanceof DBRef)\n            return v;\n        const dollarKeys = Object.keys(v).filter(k => k.startsWith('$'));\n        let valid = true;\n        dollarKeys.forEach(k => {\n            if (['$ref', '$id', '$db'].indexOf(k) === -1)\n                valid = false;\n        });\n        if (valid)\n            return DBRef.fromExtendedJSON(v);\n    }\n    return value;\n}\nfunction serializeArray(array, options) {\n    return array.map((v, index) => {\n        options.seenObjects.push({ propertyName: `index ${index}`, obj: null });\n        try {\n            return serializeValue(v, options);\n        }\n        finally {\n            options.seenObjects.pop();\n        }\n    });\n}\nfunction getISOString(date) {\n    const isoStr = date.toISOString();\n    return date.getUTCMilliseconds() !== 0 ? isoStr : isoStr.slice(0, -5) + 'Z';\n}\nfunction serializeValue(value, options) {\n    if (value instanceof Map || isMap(value)) {\n        const obj = Object.create(null);\n        for (const [k, v] of value) {\n            if (typeof k !== 'string') {\n                throw new BSONError('Can only serialize maps with string keys');\n            }\n            obj[k] = v;\n        }\n        return serializeValue(obj, options);\n    }\n    if ((typeof value === 'object' || typeof value === 'function') && value !== null) {\n        const index = options.seenObjects.findIndex(entry => entry.obj === value);\n        if (index !== -1) {\n            const props = options.seenObjects.map(entry => entry.propertyName);\n            const leadingPart = props\n                .slice(0, index)\n                .map(prop => `${prop} -> `)\n                .join('');\n            const alreadySeen = props[index];\n            const circularPart = ' -> ' +\n                props\n                    .slice(index + 1, props.length - 1)\n                    .map(prop => `${prop} -> `)\n                    .join('');\n            const current = props[props.length - 1];\n            const leadingSpace = ' '.repeat(leadingPart.length + alreadySeen.length / 2);\n            const dashes = '-'.repeat(circularPart.length + (alreadySeen.length + current.length) / 2 - 1);\n            throw new BSONError('Converting circular structure to EJSON:\\n' +\n                `    ${leadingPart}${alreadySeen}${circularPart}${current}\\n` +\n                `    ${leadingSpace}\\\\${dashes}/`);\n        }\n        options.seenObjects[options.seenObjects.length - 1].obj = value;\n    }\n    if (Array.isArray(value))\n        return serializeArray(value, options);\n    if (value === undefined)\n        return null;\n    if (value instanceof Date || isDate(value)) {\n        const dateNum = value.getTime(), inRange = dateNum > -1 && dateNum < 253402318800000;\n        if (options.legacy) {\n            return options.relaxed && inRange\n                ? { $date: value.getTime() }\n                : { $date: getISOString(value) };\n        }\n        return options.relaxed && inRange\n            ? { $date: getISOString(value) }\n            : { $date: { $numberLong: value.getTime().toString() } };\n    }\n    if (typeof value === 'number' && (!options.relaxed || !isFinite(value))) {\n        if (Number.isInteger(value) && !Object.is(value, -0)) {\n            if (value >= BSON_INT32_MIN && value <= BSON_INT32_MAX) {\n                return { $numberInt: value.toString() };\n            }\n            if (value >= BSON_INT64_MIN && value <= BSON_INT64_MAX) {\n                return { $numberLong: value.toString() };\n            }\n        }\n        return { $numberDouble: Object.is(value, -0) ? '-0.0' : value.toString() };\n    }\n    if (typeof value === 'bigint') {\n        if (!options.relaxed) {\n            return { $numberLong: BigInt.asIntN(64, value).toString() };\n        }\n        return Number(BigInt.asIntN(64, value));\n    }\n    if (value instanceof RegExp || isRegExp(value)) {\n        let flags = value.flags;\n        if (flags === undefined) {\n            const match = value.toString().match(/[gimuy]*$/);\n            if (match) {\n                flags = match[0];\n            }\n        }\n        const rx = new BSONRegExp(value.source, flags);\n        return rx.toExtendedJSON(options);\n    }\n    if (value != null && typeof value === 'object')\n        return serializeDocument(value, options);\n    return value;\n}\nconst BSON_TYPE_MAPPINGS = {\n    Binary: (o) => new Binary(o.value(), o.sub_type),\n    Code: (o) => new Code(o.code, o.scope),\n    DBRef: (o) => new DBRef(o.collection || o.namespace, o.oid, o.db, o.fields),\n    Decimal128: (o) => new Decimal128(o.bytes),\n    Double: (o) => new Double(o.value),\n    Int32: (o) => new Int32(o.value),\n    Long: (o) => Long.fromBits(o.low != null ? o.low : o.low_, o.low != null ? o.high : o.high_, o.low != null ? o.unsigned : o.unsigned_),\n    MaxKey: () => new MaxKey(),\n    MinKey: () => new MinKey(),\n    ObjectId: (o) => new ObjectId(o),\n    BSONRegExp: (o) => new BSONRegExp(o.pattern, o.options),\n    BSONSymbol: (o) => new BSONSymbol(o.value),\n    Timestamp: (o) => Timestamp.fromBits(o.low, o.high)\n};\nfunction serializeDocument(doc, options) {\n    if (doc == null || typeof doc !== 'object')\n        throw new BSONError('not an object instance');\n    const bsontype = doc._bsontype;\n    if (typeof bsontype === 'undefined') {\n        const _doc = {};\n        for (const name of Object.keys(doc)) {\n            options.seenObjects.push({ propertyName: name, obj: null });\n            try {\n                const value = serializeValue(doc[name], options);\n                if (name === '__proto__') {\n                    Object.defineProperty(_doc, name, {\n                        value,\n                        writable: true,\n                        enumerable: true,\n                        configurable: true\n                    });\n                }\n                else {\n                    _doc[name] = value;\n                }\n            }\n            finally {\n                options.seenObjects.pop();\n            }\n        }\n        return _doc;\n    }\n    else if (doc != null &&\n        typeof doc === 'object' &&\n        typeof doc._bsontype === 'string' &&\n        doc[Symbol.for('@@mdb.bson.version')] !== BSON_MAJOR_VERSION) {\n        throw new BSONVersionError();\n    }\n    else if (isBSONType(doc)) {\n        let outDoc = doc;\n        if (typeof outDoc.toExtendedJSON !== 'function') {\n            const mapper = BSON_TYPE_MAPPINGS[doc._bsontype];\n            if (!mapper) {\n                throw new BSONError('Unrecognized or invalid _bsontype: ' + doc._bsontype);\n            }\n            outDoc = mapper(outDoc);\n        }\n        if (bsontype === 'Code' && outDoc.scope) {\n            outDoc = new Code(outDoc.code, serializeValue(outDoc.scope, options));\n        }\n        else if (bsontype === 'DBRef' && outDoc.oid) {\n            outDoc = new DBRef(serializeValue(outDoc.collection, options), serializeValue(outDoc.oid, options), serializeValue(outDoc.db, options), serializeValue(outDoc.fields, options));\n        }\n        return outDoc.toExtendedJSON(options);\n    }\n    else {\n        throw new BSONError('_bsontype must be a string, but was: ' + typeof bsontype);\n    }\n}\nfunction parse(text, options) {\n    const ejsonOptions = {\n        useBigInt64: options?.useBigInt64 ?? false,\n        relaxed: options?.relaxed ?? true,\n        legacy: options?.legacy ?? false\n    };\n    return JSON.parse(text, (key, value) => {\n        if (key.indexOf('\\x00') !== -1) {\n            throw new BSONError(`BSON Document field names cannot contain null bytes, found: ${JSON.stringify(key)}`);\n        }\n        return deserializeValue(value, ejsonOptions);\n    });\n}\nfunction stringify(value, replacer, space, options) {\n    if (space != null && typeof space === 'object') {\n        options = space;\n        space = 0;\n    }\n    if (replacer != null && typeof replacer === 'object' && !Array.isArray(replacer)) {\n        options = replacer;\n        replacer = undefined;\n        space = 0;\n    }\n    const serializeOptions = Object.assign({ relaxed: true, legacy: false }, options, {\n        seenObjects: [{ propertyName: '(root)', obj: null }]\n    });\n    const doc = serializeValue(value, serializeOptions);\n    return JSON.stringify(doc, replacer, space);\n}\nfunction EJSONserialize(value, options) {\n    options = options || {};\n    return JSON.parse(stringify(value, options));\n}\nfunction EJSONdeserialize(ejson, options) {\n    options = options || {};\n    return parse(JSON.stringify(ejson), options);\n}\nconst EJSON = Object.create(null);\nEJSON.parse = parse;\nEJSON.stringify = stringify;\nEJSON.serialize = EJSONserialize;\nEJSON.deserialize = EJSONdeserialize;\nObject.freeze(EJSON);\n\nconst MAXSIZE = 1024 * 1024 * 17;\nlet buffer = ByteUtils.allocate(MAXSIZE);\nfunction setInternalBufferSize(size) {\n    if (buffer.length < size) {\n        buffer = ByteUtils.allocate(size);\n    }\n}\nfunction serialize(object, options = {}) {\n    const checkKeys = typeof options.checkKeys === 'boolean' ? options.checkKeys : false;\n    const serializeFunctions = typeof options.serializeFunctions === 'boolean' ? options.serializeFunctions : false;\n    const ignoreUndefined = typeof options.ignoreUndefined === 'boolean' ? options.ignoreUndefined : true;\n    const minInternalBufferSize = typeof options.minInternalBufferSize === 'number' ? options.minInternalBufferSize : MAXSIZE;\n    if (buffer.length < minInternalBufferSize) {\n        buffer = ByteUtils.allocate(minInternalBufferSize);\n    }\n    const serializationIndex = serializeInto(buffer, object, checkKeys, 0, 0, serializeFunctions, ignoreUndefined, null);\n    const finishedBuffer = ByteUtils.allocate(serializationIndex);\n    finishedBuffer.set(buffer.subarray(0, serializationIndex), 0);\n    return finishedBuffer;\n}\nfunction serializeWithBufferAndIndex(object, finalBuffer, options = {}) {\n    const checkKeys = typeof options.checkKeys === 'boolean' ? options.checkKeys : false;\n    const serializeFunctions = typeof options.serializeFunctions === 'boolean' ? options.serializeFunctions : false;\n    const ignoreUndefined = typeof options.ignoreUndefined === 'boolean' ? options.ignoreUndefined : true;\n    const startIndex = typeof options.index === 'number' ? options.index : 0;\n    const serializationIndex = serializeInto(buffer, object, checkKeys, 0, 0, serializeFunctions, ignoreUndefined, null);\n    finalBuffer.set(buffer.subarray(0, serializationIndex), startIndex);\n    return startIndex + serializationIndex - 1;\n}\nfunction deserialize(buffer, options = {}) {\n    return internalDeserialize(ByteUtils.toLocalBufferType(buffer), options);\n}\nfunction calculateObjectSize(object, options = {}) {\n    options = options || {};\n    const serializeFunctions = typeof options.serializeFunctions === 'boolean' ? options.serializeFunctions : false;\n    const ignoreUndefined = typeof options.ignoreUndefined === 'boolean' ? options.ignoreUndefined : true;\n    return internalCalculateObjectSize(object, serializeFunctions, ignoreUndefined);\n}\nfunction deserializeStream(data, startIndex, numberOfDocuments, documents, docStartIndex, options) {\n    const internalOptions = Object.assign({ allowObjectSmallerThanBufferSize: true, index: 0 }, options);\n    const bufferData = ByteUtils.toLocalBufferType(data);\n    let index = startIndex;\n    for (let i = 0; i < numberOfDocuments; i++) {\n        const size = bufferData[index] |\n            (bufferData[index + 1] << 8) |\n            (bufferData[index + 2] << 16) |\n            (bufferData[index + 3] << 24);\n        internalOptions.index = index;\n        documents[docStartIndex + i] = internalDeserialize(bufferData, internalOptions);\n        index = index + size;\n    }\n    return index;\n}\n\nvar bson = /*#__PURE__*/Object.freeze({\n    __proto__: null,\n    BSONError: BSONError,\n    BSONRegExp: BSONRegExp,\n    BSONRuntimeError: BSONRuntimeError,\n    BSONSymbol: BSONSymbol,\n    BSONType: BSONType,\n    BSONValue: BSONValue,\n    BSONVersionError: BSONVersionError,\n    Binary: Binary,\n    Code: Code,\n    DBRef: DBRef,\n    Decimal128: Decimal128,\n    Double: Double,\n    EJSON: EJSON,\n    Int32: Int32,\n    Long: Long,\n    MaxKey: MaxKey,\n    MinKey: MinKey,\n    ObjectId: ObjectId,\n    Timestamp: Timestamp,\n    UUID: UUID,\n    calculateObjectSize: calculateObjectSize,\n    deserialize: deserialize,\n    deserializeStream: deserializeStream,\n    serialize: serialize,\n    serializeWithBufferAndIndex: serializeWithBufferAndIndex,\n    setInternalBufferSize: setInternalBufferSize\n});\n\nexports.BSON = bson;\nexports.BSONError = BSONError;\nexports.BSONRegExp = BSONRegExp;\nexports.BSONRuntimeError = BSONRuntimeError;\nexports.BSONSymbol = BSONSymbol;\nexports.BSONType = BSONType;\nexports.BSONValue = BSONValue;\nexports.BSONVersionError = BSONVersionError;\nexports.Binary = Binary;\nexports.Code = Code;\nexports.DBRef = DBRef;\nexports.Decimal128 = Decimal128;\nexports.Double = Double;\nexports.EJSON = EJSON;\nexports.Int32 = Int32;\nexports.Long = Long;\nexports.MaxKey = MaxKey;\nexports.MinKey = MinKey;\nexports.ObjectId = ObjectId;\nexports.Timestamp = Timestamp;\nexports.UUID = UUID;\nexports.calculateObjectSize = calculateObjectSize;\nexports.deserialize = deserialize;\nexports.deserializeStream = deserializeStream;\nexports.serialize = serialize;\nexports.serializeWithBufferAndIndex = serializeWithBufferAndIndex;\nexports.setInternalBufferSize = setInternalBufferSize;\n//# sourceMappingURL=bson.cjs.map\n\n\n//# sourceURL=webpack://renderer/./node_modules/bson/lib/bson.cjs?");

/***/ }),

/***/ "./node_modules/clsx/dist/clsx.mjs":
/*!*****************************************!*\
  !*** ./node_modules/clsx/dist/clsx.mjs ***!
  \*****************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   clsx: () => (/* binding */ clsx),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nfunction r(e){var t,f,n=\"\";if(\"string\"==typeof e||\"number\"==typeof e)n+=e;else if(\"object\"==typeof e)if(Array.isArray(e))for(t=0;t<e.length;t++)e[t]&&(f=r(e[t]))&&(n&&(n+=\" \"),n+=f);else for(t in e)e[t]&&(n&&(n+=\" \"),n+=t);return n}function clsx(){for(var e,t,f=0,n=\"\";f<arguments.length;)(e=arguments[f++])&&(t=r(e))&&(n&&(n+=\" \"),n+=t);return n}/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (clsx);\n\n//# sourceURL=webpack://renderer/./node_modules/clsx/dist/clsx.mjs?");

/***/ }),

/***/ "./node_modules/tailwind-merge/dist/bundle-mjs.mjs":
/*!*********************************************************!*\
  !*** ./node_modules/tailwind-merge/dist/bundle-mjs.mjs ***!
  \*********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   createTailwindMerge: () => (/* binding */ createTailwindMerge),\n/* harmony export */   extendTailwindMerge: () => (/* binding */ extendTailwindMerge),\n/* harmony export */   fromTheme: () => (/* binding */ fromTheme),\n/* harmony export */   getDefaultConfig: () => (/* binding */ getDefaultConfig),\n/* harmony export */   mergeConfigs: () => (/* binding */ mergeConfigs),\n/* harmony export */   twJoin: () => (/* binding */ twJoin),\n/* harmony export */   twMerge: () => (/* binding */ twMerge),\n/* harmony export */   validators: () => (/* binding */ validators)\n/* harmony export */ });\nconst CLASS_PART_SEPARATOR = '-';\nfunction createClassUtils(config) {\n  const classMap = createClassMap(config);\n  const {\n    conflictingClassGroups,\n    conflictingClassGroupModifiers\n  } = config;\n  function getClassGroupId(className) {\n    const classParts = className.split(CLASS_PART_SEPARATOR);\n    // Classes like `-inset-1` produce an empty string as first classPart. We assume that classes for negative values are used correctly and remove it from classParts.\n    if (classParts[0] === '' && classParts.length !== 1) {\n      classParts.shift();\n    }\n    return getGroupRecursive(classParts, classMap) || getGroupIdForArbitraryProperty(className);\n  }\n  function getConflictingClassGroupIds(classGroupId, hasPostfixModifier) {\n    const conflicts = conflictingClassGroups[classGroupId] || [];\n    if (hasPostfixModifier && conflictingClassGroupModifiers[classGroupId]) {\n      return [...conflicts, ...conflictingClassGroupModifiers[classGroupId]];\n    }\n    return conflicts;\n  }\n  return {\n    getClassGroupId,\n    getConflictingClassGroupIds\n  };\n}\nfunction getGroupRecursive(classParts, classPartObject) {\n  if (classParts.length === 0) {\n    return classPartObject.classGroupId;\n  }\n  const currentClassPart = classParts[0];\n  const nextClassPartObject = classPartObject.nextPart.get(currentClassPart);\n  const classGroupFromNextClassPart = nextClassPartObject ? getGroupRecursive(classParts.slice(1), nextClassPartObject) : undefined;\n  if (classGroupFromNextClassPart) {\n    return classGroupFromNextClassPart;\n  }\n  if (classPartObject.validators.length === 0) {\n    return undefined;\n  }\n  const classRest = classParts.join(CLASS_PART_SEPARATOR);\n  return classPartObject.validators.find(({\n    validator\n  }) => validator(classRest))?.classGroupId;\n}\nconst arbitraryPropertyRegex = /^\\[(.+)\\]$/;\nfunction getGroupIdForArbitraryProperty(className) {\n  if (arbitraryPropertyRegex.test(className)) {\n    const arbitraryPropertyClassName = arbitraryPropertyRegex.exec(className)[1];\n    const property = arbitraryPropertyClassName?.substring(0, arbitraryPropertyClassName.indexOf(':'));\n    if (property) {\n      // I use two dots here because one dot is used as prefix for class groups in plugins\n      return 'arbitrary..' + property;\n    }\n  }\n}\n/**\n * Exported for testing only\n */\nfunction createClassMap(config) {\n  const {\n    theme,\n    prefix\n  } = config;\n  const classMap = {\n    nextPart: new Map(),\n    validators: []\n  };\n  const prefixedClassGroupEntries = getPrefixedClassGroupEntries(Object.entries(config.classGroups), prefix);\n  prefixedClassGroupEntries.forEach(([classGroupId, classGroup]) => {\n    processClassesRecursively(classGroup, classMap, classGroupId, theme);\n  });\n  return classMap;\n}\nfunction processClassesRecursively(classGroup, classPartObject, classGroupId, theme) {\n  classGroup.forEach(classDefinition => {\n    if (typeof classDefinition === 'string') {\n      const classPartObjectToEdit = classDefinition === '' ? classPartObject : getPart(classPartObject, classDefinition);\n      classPartObjectToEdit.classGroupId = classGroupId;\n      return;\n    }\n    if (typeof classDefinition === 'function') {\n      if (isThemeGetter(classDefinition)) {\n        processClassesRecursively(classDefinition(theme), classPartObject, classGroupId, theme);\n        return;\n      }\n      classPartObject.validators.push({\n        validator: classDefinition,\n        classGroupId\n      });\n      return;\n    }\n    Object.entries(classDefinition).forEach(([key, classGroup]) => {\n      processClassesRecursively(classGroup, getPart(classPartObject, key), classGroupId, theme);\n    });\n  });\n}\nfunction getPart(classPartObject, path) {\n  let currentClassPartObject = classPartObject;\n  path.split(CLASS_PART_SEPARATOR).forEach(pathPart => {\n    if (!currentClassPartObject.nextPart.has(pathPart)) {\n      currentClassPartObject.nextPart.set(pathPart, {\n        nextPart: new Map(),\n        validators: []\n      });\n    }\n    currentClassPartObject = currentClassPartObject.nextPart.get(pathPart);\n  });\n  return currentClassPartObject;\n}\nfunction isThemeGetter(func) {\n  return func.isThemeGetter;\n}\nfunction getPrefixedClassGroupEntries(classGroupEntries, prefix) {\n  if (!prefix) {\n    return classGroupEntries;\n  }\n  return classGroupEntries.map(([classGroupId, classGroup]) => {\n    const prefixedClassGroup = classGroup.map(classDefinition => {\n      if (typeof classDefinition === 'string') {\n        return prefix + classDefinition;\n      }\n      if (typeof classDefinition === 'object') {\n        return Object.fromEntries(Object.entries(classDefinition).map(([key, value]) => [prefix + key, value]));\n      }\n      return classDefinition;\n    });\n    return [classGroupId, prefixedClassGroup];\n  });\n}\n\n// LRU cache inspired from hashlru (https://github.com/dominictarr/hashlru/blob/v1.0.4/index.js) but object replaced with Map to improve performance\nfunction createLruCache(maxCacheSize) {\n  if (maxCacheSize < 1) {\n    return {\n      get: () => undefined,\n      set: () => {}\n    };\n  }\n  let cacheSize = 0;\n  let cache = new Map();\n  let previousCache = new Map();\n  function update(key, value) {\n    cache.set(key, value);\n    cacheSize++;\n    if (cacheSize > maxCacheSize) {\n      cacheSize = 0;\n      previousCache = cache;\n      cache = new Map();\n    }\n  }\n  return {\n    get(key) {\n      let value = cache.get(key);\n      if (value !== undefined) {\n        return value;\n      }\n      if ((value = previousCache.get(key)) !== undefined) {\n        update(key, value);\n        return value;\n      }\n    },\n    set(key, value) {\n      if (cache.has(key)) {\n        cache.set(key, value);\n      } else {\n        update(key, value);\n      }\n    }\n  };\n}\nconst IMPORTANT_MODIFIER = '!';\nfunction createSplitModifiers(config) {\n  const separator = config.separator;\n  const isSeparatorSingleCharacter = separator.length === 1;\n  const firstSeparatorCharacter = separator[0];\n  const separatorLength = separator.length;\n  // splitModifiers inspired by https://github.com/tailwindlabs/tailwindcss/blob/v3.2.2/src/util/splitAtTopLevelOnly.js\n  return function splitModifiers(className) {\n    const modifiers = [];\n    let bracketDepth = 0;\n    let modifierStart = 0;\n    let postfixModifierPosition;\n    for (let index = 0; index < className.length; index++) {\n      let currentCharacter = className[index];\n      if (bracketDepth === 0) {\n        if (currentCharacter === firstSeparatorCharacter && (isSeparatorSingleCharacter || className.slice(index, index + separatorLength) === separator)) {\n          modifiers.push(className.slice(modifierStart, index));\n          modifierStart = index + separatorLength;\n          continue;\n        }\n        if (currentCharacter === '/') {\n          postfixModifierPosition = index;\n          continue;\n        }\n      }\n      if (currentCharacter === '[') {\n        bracketDepth++;\n      } else if (currentCharacter === ']') {\n        bracketDepth--;\n      }\n    }\n    const baseClassNameWithImportantModifier = modifiers.length === 0 ? className : className.substring(modifierStart);\n    const hasImportantModifier = baseClassNameWithImportantModifier.startsWith(IMPORTANT_MODIFIER);\n    const baseClassName = hasImportantModifier ? baseClassNameWithImportantModifier.substring(1) : baseClassNameWithImportantModifier;\n    const maybePostfixModifierPosition = postfixModifierPosition && postfixModifierPosition > modifierStart ? postfixModifierPosition - modifierStart : undefined;\n    return {\n      modifiers,\n      hasImportantModifier,\n      baseClassName,\n      maybePostfixModifierPosition\n    };\n  };\n}\n/**\n * Sorts modifiers according to following schema:\n * - Predefined modifiers are sorted alphabetically\n * - When an arbitrary variant appears, it must be preserved which modifiers are before and after it\n */\nfunction sortModifiers(modifiers) {\n  if (modifiers.length <= 1) {\n    return modifiers;\n  }\n  const sortedModifiers = [];\n  let unsortedModifiers = [];\n  modifiers.forEach(modifier => {\n    const isArbitraryVariant = modifier[0] === '[';\n    if (isArbitraryVariant) {\n      sortedModifiers.push(...unsortedModifiers.sort(), modifier);\n      unsortedModifiers = [];\n    } else {\n      unsortedModifiers.push(modifier);\n    }\n  });\n  sortedModifiers.push(...unsortedModifiers.sort());\n  return sortedModifiers;\n}\nfunction createConfigUtils(config) {\n  return {\n    cache: createLruCache(config.cacheSize),\n    splitModifiers: createSplitModifiers(config),\n    ...createClassUtils(config)\n  };\n}\nconst SPLIT_CLASSES_REGEX = /\\s+/;\nfunction mergeClassList(classList, configUtils) {\n  const {\n    splitModifiers,\n    getClassGroupId,\n    getConflictingClassGroupIds\n  } = configUtils;\n  /**\n   * Set of classGroupIds in following format:\n   * `{importantModifier}{variantModifiers}{classGroupId}`\n   * @example 'float'\n   * @example 'hover:focus:bg-color'\n   * @example 'md:!pr'\n   */\n  const classGroupsInConflict = new Set();\n  return classList.trim().split(SPLIT_CLASSES_REGEX).map(originalClassName => {\n    const {\n      modifiers,\n      hasImportantModifier,\n      baseClassName,\n      maybePostfixModifierPosition\n    } = splitModifiers(originalClassName);\n    let classGroupId = getClassGroupId(maybePostfixModifierPosition ? baseClassName.substring(0, maybePostfixModifierPosition) : baseClassName);\n    let hasPostfixModifier = Boolean(maybePostfixModifierPosition);\n    if (!classGroupId) {\n      if (!maybePostfixModifierPosition) {\n        return {\n          isTailwindClass: false,\n          originalClassName\n        };\n      }\n      classGroupId = getClassGroupId(baseClassName);\n      if (!classGroupId) {\n        return {\n          isTailwindClass: false,\n          originalClassName\n        };\n      }\n      hasPostfixModifier = false;\n    }\n    const variantModifier = sortModifiers(modifiers).join(':');\n    const modifierId = hasImportantModifier ? variantModifier + IMPORTANT_MODIFIER : variantModifier;\n    return {\n      isTailwindClass: true,\n      modifierId,\n      classGroupId,\n      originalClassName,\n      hasPostfixModifier\n    };\n  }).reverse()\n  // Last class in conflict wins, so we need to filter conflicting classes in reverse order.\n  .filter(parsed => {\n    if (!parsed.isTailwindClass) {\n      return true;\n    }\n    const {\n      modifierId,\n      classGroupId,\n      hasPostfixModifier\n    } = parsed;\n    const classId = modifierId + classGroupId;\n    if (classGroupsInConflict.has(classId)) {\n      return false;\n    }\n    classGroupsInConflict.add(classId);\n    getConflictingClassGroupIds(classGroupId, hasPostfixModifier).forEach(group => classGroupsInConflict.add(modifierId + group));\n    return true;\n  }).reverse().map(parsed => parsed.originalClassName).join(' ');\n}\n\n/**\n * The code in this file is copied from https://github.com/lukeed/clsx and modified to suit the needs of tailwind-merge better.\n *\n * Specifically:\n * - Runtime code from https://github.com/lukeed/clsx/blob/v1.2.1/src/index.js\n * - TypeScript types from https://github.com/lukeed/clsx/blob/v1.2.1/clsx.d.ts\n *\n * Original code has MIT license: Copyright (c) Luke Edwards <luke.edwards05@gmail.com> (lukeed.com)\n */\nfunction twJoin() {\n  let index = 0;\n  let argument;\n  let resolvedValue;\n  let string = '';\n  while (index < arguments.length) {\n    if (argument = arguments[index++]) {\n      if (resolvedValue = toValue(argument)) {\n        string && (string += ' ');\n        string += resolvedValue;\n      }\n    }\n  }\n  return string;\n}\nfunction toValue(mix) {\n  if (typeof mix === 'string') {\n    return mix;\n  }\n  let resolvedValue;\n  let string = '';\n  for (let k = 0; k < mix.length; k++) {\n    if (mix[k]) {\n      if (resolvedValue = toValue(mix[k])) {\n        string && (string += ' ');\n        string += resolvedValue;\n      }\n    }\n  }\n  return string;\n}\nfunction createTailwindMerge(createConfigFirst, ...createConfigRest) {\n  let configUtils;\n  let cacheGet;\n  let cacheSet;\n  let functionToCall = initTailwindMerge;\n  function initTailwindMerge(classList) {\n    const config = createConfigRest.reduce((previousConfig, createConfigCurrent) => createConfigCurrent(previousConfig), createConfigFirst());\n    configUtils = createConfigUtils(config);\n    cacheGet = configUtils.cache.get;\n    cacheSet = configUtils.cache.set;\n    functionToCall = tailwindMerge;\n    return tailwindMerge(classList);\n  }\n  function tailwindMerge(classList) {\n    const cachedResult = cacheGet(classList);\n    if (cachedResult) {\n      return cachedResult;\n    }\n    const result = mergeClassList(classList, configUtils);\n    cacheSet(classList, result);\n    return result;\n  }\n  return function callTailwindMerge() {\n    return functionToCall(twJoin.apply(null, arguments));\n  };\n}\nfunction fromTheme(key) {\n  const themeGetter = theme => theme[key] || [];\n  themeGetter.isThemeGetter = true;\n  return themeGetter;\n}\nconst arbitraryValueRegex = /^\\[(?:([a-z-]+):)?(.+)\\]$/i;\nconst fractionRegex = /^\\d+\\/\\d+$/;\nconst stringLengths = /*#__PURE__*/new Set(['px', 'full', 'screen']);\nconst tshirtUnitRegex = /^(\\d+(\\.\\d+)?)?(xs|sm|md|lg|xl)$/;\nconst lengthUnitRegex = /\\d+(%|px|r?em|[sdl]?v([hwib]|min|max)|pt|pc|in|cm|mm|cap|ch|ex|r?lh|cq(w|h|i|b|min|max))|\\b(calc|min|max|clamp)\\(.+\\)|^0$/;\n// Shadow always begins with x and y offset separated by underscore\nconst shadowRegex = /^-?((\\d+)?\\.?(\\d+)[a-z]+|0)_-?((\\d+)?\\.?(\\d+)[a-z]+|0)/;\nconst imageRegex = /^(url|image|image-set|cross-fade|element|(repeating-)?(linear|radial|conic)-gradient)\\(.+\\)$/;\nfunction isLength(value) {\n  return isNumber(value) || stringLengths.has(value) || fractionRegex.test(value);\n}\nfunction isArbitraryLength(value) {\n  return getIsArbitraryValue(value, 'length', isLengthOnly);\n}\nfunction isNumber(value) {\n  return Boolean(value) && !Number.isNaN(Number(value));\n}\nfunction isArbitraryNumber(value) {\n  return getIsArbitraryValue(value, 'number', isNumber);\n}\nfunction isInteger(value) {\n  return Boolean(value) && Number.isInteger(Number(value));\n}\nfunction isPercent(value) {\n  return value.endsWith('%') && isNumber(value.slice(0, -1));\n}\nfunction isArbitraryValue(value) {\n  return arbitraryValueRegex.test(value);\n}\nfunction isTshirtSize(value) {\n  return tshirtUnitRegex.test(value);\n}\nconst sizeLabels = /*#__PURE__*/new Set(['length', 'size', 'percentage']);\nfunction isArbitrarySize(value) {\n  return getIsArbitraryValue(value, sizeLabels, isNever);\n}\nfunction isArbitraryPosition(value) {\n  return getIsArbitraryValue(value, 'position', isNever);\n}\nconst imageLabels = /*#__PURE__*/new Set(['image', 'url']);\nfunction isArbitraryImage(value) {\n  return getIsArbitraryValue(value, imageLabels, isImage);\n}\nfunction isArbitraryShadow(value) {\n  return getIsArbitraryValue(value, '', isShadow);\n}\nfunction isAny() {\n  return true;\n}\nfunction getIsArbitraryValue(value, label, testValue) {\n  const result = arbitraryValueRegex.exec(value);\n  if (result) {\n    if (result[1]) {\n      return typeof label === 'string' ? result[1] === label : label.has(result[1]);\n    }\n    return testValue(result[2]);\n  }\n  return false;\n}\nfunction isLengthOnly(value) {\n  return lengthUnitRegex.test(value);\n}\nfunction isNever() {\n  return false;\n}\nfunction isShadow(value) {\n  return shadowRegex.test(value);\n}\nfunction isImage(value) {\n  return imageRegex.test(value);\n}\nconst validators = /*#__PURE__*/Object.defineProperty({\n  __proto__: null,\n  isAny,\n  isArbitraryImage,\n  isArbitraryLength,\n  isArbitraryNumber,\n  isArbitraryPosition,\n  isArbitraryShadow,\n  isArbitrarySize,\n  isArbitraryValue,\n  isInteger,\n  isLength,\n  isNumber,\n  isPercent,\n  isTshirtSize\n}, Symbol.toStringTag, {\n  value: 'Module'\n});\nfunction getDefaultConfig() {\n  const colors = fromTheme('colors');\n  const spacing = fromTheme('spacing');\n  const blur = fromTheme('blur');\n  const brightness = fromTheme('brightness');\n  const borderColor = fromTheme('borderColor');\n  const borderRadius = fromTheme('borderRadius');\n  const borderSpacing = fromTheme('borderSpacing');\n  const borderWidth = fromTheme('borderWidth');\n  const contrast = fromTheme('contrast');\n  const grayscale = fromTheme('grayscale');\n  const hueRotate = fromTheme('hueRotate');\n  const invert = fromTheme('invert');\n  const gap = fromTheme('gap');\n  const gradientColorStops = fromTheme('gradientColorStops');\n  const gradientColorStopPositions = fromTheme('gradientColorStopPositions');\n  const inset = fromTheme('inset');\n  const margin = fromTheme('margin');\n  const opacity = fromTheme('opacity');\n  const padding = fromTheme('padding');\n  const saturate = fromTheme('saturate');\n  const scale = fromTheme('scale');\n  const sepia = fromTheme('sepia');\n  const skew = fromTheme('skew');\n  const space = fromTheme('space');\n  const translate = fromTheme('translate');\n  const getOverscroll = () => ['auto', 'contain', 'none'];\n  const getOverflow = () => ['auto', 'hidden', 'clip', 'visible', 'scroll'];\n  const getSpacingWithAutoAndArbitrary = () => ['auto', isArbitraryValue, spacing];\n  const getSpacingWithArbitrary = () => [isArbitraryValue, spacing];\n  const getLengthWithEmptyAndArbitrary = () => ['', isLength, isArbitraryLength];\n  const getNumberWithAutoAndArbitrary = () => ['auto', isNumber, isArbitraryValue];\n  const getPositions = () => ['bottom', 'center', 'left', 'left-bottom', 'left-top', 'right', 'right-bottom', 'right-top', 'top'];\n  const getLineStyles = () => ['solid', 'dashed', 'dotted', 'double', 'none'];\n  const getBlendModes = () => ['normal', 'multiply', 'screen', 'overlay', 'darken', 'lighten', 'color-dodge', 'color-burn', 'hard-light', 'soft-light', 'difference', 'exclusion', 'hue', 'saturation', 'color', 'luminosity', 'plus-lighter'];\n  const getAlign = () => ['start', 'end', 'center', 'between', 'around', 'evenly', 'stretch'];\n  const getZeroAndEmpty = () => ['', '0', isArbitraryValue];\n  const getBreaks = () => ['auto', 'avoid', 'all', 'avoid-page', 'page', 'left', 'right', 'column'];\n  const getNumber = () => [isNumber, isArbitraryNumber];\n  const getNumberAndArbitrary = () => [isNumber, isArbitraryValue];\n  return {\n    cacheSize: 500,\n    separator: ':',\n    theme: {\n      colors: [isAny],\n      spacing: [isLength, isArbitraryLength],\n      blur: ['none', '', isTshirtSize, isArbitraryValue],\n      brightness: getNumber(),\n      borderColor: [colors],\n      borderRadius: ['none', '', 'full', isTshirtSize, isArbitraryValue],\n      borderSpacing: getSpacingWithArbitrary(),\n      borderWidth: getLengthWithEmptyAndArbitrary(),\n      contrast: getNumber(),\n      grayscale: getZeroAndEmpty(),\n      hueRotate: getNumberAndArbitrary(),\n      invert: getZeroAndEmpty(),\n      gap: getSpacingWithArbitrary(),\n      gradientColorStops: [colors],\n      gradientColorStopPositions: [isPercent, isArbitraryLength],\n      inset: getSpacingWithAutoAndArbitrary(),\n      margin: getSpacingWithAutoAndArbitrary(),\n      opacity: getNumber(),\n      padding: getSpacingWithArbitrary(),\n      saturate: getNumber(),\n      scale: getNumber(),\n      sepia: getZeroAndEmpty(),\n      skew: getNumberAndArbitrary(),\n      space: getSpacingWithArbitrary(),\n      translate: getSpacingWithArbitrary()\n    },\n    classGroups: {\n      // Layout\n      /**\n       * Aspect Ratio\n       * @see https://tailwindcss.com/docs/aspect-ratio\n       */\n      aspect: [{\n        aspect: ['auto', 'square', 'video', isArbitraryValue]\n      }],\n      /**\n       * Container\n       * @see https://tailwindcss.com/docs/container\n       */\n      container: ['container'],\n      /**\n       * Columns\n       * @see https://tailwindcss.com/docs/columns\n       */\n      columns: [{\n        columns: [isTshirtSize]\n      }],\n      /**\n       * Break After\n       * @see https://tailwindcss.com/docs/break-after\n       */\n      'break-after': [{\n        'break-after': getBreaks()\n      }],\n      /**\n       * Break Before\n       * @see https://tailwindcss.com/docs/break-before\n       */\n      'break-before': [{\n        'break-before': getBreaks()\n      }],\n      /**\n       * Break Inside\n       * @see https://tailwindcss.com/docs/break-inside\n       */\n      'break-inside': [{\n        'break-inside': ['auto', 'avoid', 'avoid-page', 'avoid-column']\n      }],\n      /**\n       * Box Decoration Break\n       * @see https://tailwindcss.com/docs/box-decoration-break\n       */\n      'box-decoration': [{\n        'box-decoration': ['slice', 'clone']\n      }],\n      /**\n       * Box Sizing\n       * @see https://tailwindcss.com/docs/box-sizing\n       */\n      box: [{\n        box: ['border', 'content']\n      }],\n      /**\n       * Display\n       * @see https://tailwindcss.com/docs/display\n       */\n      display: ['block', 'inline-block', 'inline', 'flex', 'inline-flex', 'table', 'inline-table', 'table-caption', 'table-cell', 'table-column', 'table-column-group', 'table-footer-group', 'table-header-group', 'table-row-group', 'table-row', 'flow-root', 'grid', 'inline-grid', 'contents', 'list-item', 'hidden'],\n      /**\n       * Floats\n       * @see https://tailwindcss.com/docs/float\n       */\n      float: [{\n        float: ['right', 'left', 'none']\n      }],\n      /**\n       * Clear\n       * @see https://tailwindcss.com/docs/clear\n       */\n      clear: [{\n        clear: ['left', 'right', 'both', 'none']\n      }],\n      /**\n       * Isolation\n       * @see https://tailwindcss.com/docs/isolation\n       */\n      isolation: ['isolate', 'isolation-auto'],\n      /**\n       * Object Fit\n       * @see https://tailwindcss.com/docs/object-fit\n       */\n      'object-fit': [{\n        object: ['contain', 'cover', 'fill', 'none', 'scale-down']\n      }],\n      /**\n       * Object Position\n       * @see https://tailwindcss.com/docs/object-position\n       */\n      'object-position': [{\n        object: [...getPositions(), isArbitraryValue]\n      }],\n      /**\n       * Overflow\n       * @see https://tailwindcss.com/docs/overflow\n       */\n      overflow: [{\n        overflow: getOverflow()\n      }],\n      /**\n       * Overflow X\n       * @see https://tailwindcss.com/docs/overflow\n       */\n      'overflow-x': [{\n        'overflow-x': getOverflow()\n      }],\n      /**\n       * Overflow Y\n       * @see https://tailwindcss.com/docs/overflow\n       */\n      'overflow-y': [{\n        'overflow-y': getOverflow()\n      }],\n      /**\n       * Overscroll Behavior\n       * @see https://tailwindcss.com/docs/overscroll-behavior\n       */\n      overscroll: [{\n        overscroll: getOverscroll()\n      }],\n      /**\n       * Overscroll Behavior X\n       * @see https://tailwindcss.com/docs/overscroll-behavior\n       */\n      'overscroll-x': [{\n        'overscroll-x': getOverscroll()\n      }],\n      /**\n       * Overscroll Behavior Y\n       * @see https://tailwindcss.com/docs/overscroll-behavior\n       */\n      'overscroll-y': [{\n        'overscroll-y': getOverscroll()\n      }],\n      /**\n       * Position\n       * @see https://tailwindcss.com/docs/position\n       */\n      position: ['static', 'fixed', 'absolute', 'relative', 'sticky'],\n      /**\n       * Top / Right / Bottom / Left\n       * @see https://tailwindcss.com/docs/top-right-bottom-left\n       */\n      inset: [{\n        inset: [inset]\n      }],\n      /**\n       * Right / Left\n       * @see https://tailwindcss.com/docs/top-right-bottom-left\n       */\n      'inset-x': [{\n        'inset-x': [inset]\n      }],\n      /**\n       * Top / Bottom\n       * @see https://tailwindcss.com/docs/top-right-bottom-left\n       */\n      'inset-y': [{\n        'inset-y': [inset]\n      }],\n      /**\n       * Start\n       * @see https://tailwindcss.com/docs/top-right-bottom-left\n       */\n      start: [{\n        start: [inset]\n      }],\n      /**\n       * End\n       * @see https://tailwindcss.com/docs/top-right-bottom-left\n       */\n      end: [{\n        end: [inset]\n      }],\n      /**\n       * Top\n       * @see https://tailwindcss.com/docs/top-right-bottom-left\n       */\n      top: [{\n        top: [inset]\n      }],\n      /**\n       * Right\n       * @see https://tailwindcss.com/docs/top-right-bottom-left\n       */\n      right: [{\n        right: [inset]\n      }],\n      /**\n       * Bottom\n       * @see https://tailwindcss.com/docs/top-right-bottom-left\n       */\n      bottom: [{\n        bottom: [inset]\n      }],\n      /**\n       * Left\n       * @see https://tailwindcss.com/docs/top-right-bottom-left\n       */\n      left: [{\n        left: [inset]\n      }],\n      /**\n       * Visibility\n       * @see https://tailwindcss.com/docs/visibility\n       */\n      visibility: ['visible', 'invisible', 'collapse'],\n      /**\n       * Z-Index\n       * @see https://tailwindcss.com/docs/z-index\n       */\n      z: [{\n        z: ['auto', isInteger, isArbitraryValue]\n      }],\n      // Flexbox and Grid\n      /**\n       * Flex Basis\n       * @see https://tailwindcss.com/docs/flex-basis\n       */\n      basis: [{\n        basis: getSpacingWithAutoAndArbitrary()\n      }],\n      /**\n       * Flex Direction\n       * @see https://tailwindcss.com/docs/flex-direction\n       */\n      'flex-direction': [{\n        flex: ['row', 'row-reverse', 'col', 'col-reverse']\n      }],\n      /**\n       * Flex Wrap\n       * @see https://tailwindcss.com/docs/flex-wrap\n       */\n      'flex-wrap': [{\n        flex: ['wrap', 'wrap-reverse', 'nowrap']\n      }],\n      /**\n       * Flex\n       * @see https://tailwindcss.com/docs/flex\n       */\n      flex: [{\n        flex: ['1', 'auto', 'initial', 'none', isArbitraryValue]\n      }],\n      /**\n       * Flex Grow\n       * @see https://tailwindcss.com/docs/flex-grow\n       */\n      grow: [{\n        grow: getZeroAndEmpty()\n      }],\n      /**\n       * Flex Shrink\n       * @see https://tailwindcss.com/docs/flex-shrink\n       */\n      shrink: [{\n        shrink: getZeroAndEmpty()\n      }],\n      /**\n       * Order\n       * @see https://tailwindcss.com/docs/order\n       */\n      order: [{\n        order: ['first', 'last', 'none', isInteger, isArbitraryValue]\n      }],\n      /**\n       * Grid Template Columns\n       * @see https://tailwindcss.com/docs/grid-template-columns\n       */\n      'grid-cols': [{\n        'grid-cols': [isAny]\n      }],\n      /**\n       * Grid Column Start / End\n       * @see https://tailwindcss.com/docs/grid-column\n       */\n      'col-start-end': [{\n        col: ['auto', {\n          span: ['full', isInteger, isArbitraryValue]\n        }, isArbitraryValue]\n      }],\n      /**\n       * Grid Column Start\n       * @see https://tailwindcss.com/docs/grid-column\n       */\n      'col-start': [{\n        'col-start': getNumberWithAutoAndArbitrary()\n      }],\n      /**\n       * Grid Column End\n       * @see https://tailwindcss.com/docs/grid-column\n       */\n      'col-end': [{\n        'col-end': getNumberWithAutoAndArbitrary()\n      }],\n      /**\n       * Grid Template Rows\n       * @see https://tailwindcss.com/docs/grid-template-rows\n       */\n      'grid-rows': [{\n        'grid-rows': [isAny]\n      }],\n      /**\n       * Grid Row Start / End\n       * @see https://tailwindcss.com/docs/grid-row\n       */\n      'row-start-end': [{\n        row: ['auto', {\n          span: [isInteger, isArbitraryValue]\n        }, isArbitraryValue]\n      }],\n      /**\n       * Grid Row Start\n       * @see https://tailwindcss.com/docs/grid-row\n       */\n      'row-start': [{\n        'row-start': getNumberWithAutoAndArbitrary()\n      }],\n      /**\n       * Grid Row End\n       * @see https://tailwindcss.com/docs/grid-row\n       */\n      'row-end': [{\n        'row-end': getNumberWithAutoAndArbitrary()\n      }],\n      /**\n       * Grid Auto Flow\n       * @see https://tailwindcss.com/docs/grid-auto-flow\n       */\n      'grid-flow': [{\n        'grid-flow': ['row', 'col', 'dense', 'row-dense', 'col-dense']\n      }],\n      /**\n       * Grid Auto Columns\n       * @see https://tailwindcss.com/docs/grid-auto-columns\n       */\n      'auto-cols': [{\n        'auto-cols': ['auto', 'min', 'max', 'fr', isArbitraryValue]\n      }],\n      /**\n       * Grid Auto Rows\n       * @see https://tailwindcss.com/docs/grid-auto-rows\n       */\n      'auto-rows': [{\n        'auto-rows': ['auto', 'min', 'max', 'fr', isArbitraryValue]\n      }],\n      /**\n       * Gap\n       * @see https://tailwindcss.com/docs/gap\n       */\n      gap: [{\n        gap: [gap]\n      }],\n      /**\n       * Gap X\n       * @see https://tailwindcss.com/docs/gap\n       */\n      'gap-x': [{\n        'gap-x': [gap]\n      }],\n      /**\n       * Gap Y\n       * @see https://tailwindcss.com/docs/gap\n       */\n      'gap-y': [{\n        'gap-y': [gap]\n      }],\n      /**\n       * Justify Content\n       * @see https://tailwindcss.com/docs/justify-content\n       */\n      'justify-content': [{\n        justify: ['normal', ...getAlign()]\n      }],\n      /**\n       * Justify Items\n       * @see https://tailwindcss.com/docs/justify-items\n       */\n      'justify-items': [{\n        'justify-items': ['start', 'end', 'center', 'stretch']\n      }],\n      /**\n       * Justify Self\n       * @see https://tailwindcss.com/docs/justify-self\n       */\n      'justify-self': [{\n        'justify-self': ['auto', 'start', 'end', 'center', 'stretch']\n      }],\n      /**\n       * Align Content\n       * @see https://tailwindcss.com/docs/align-content\n       */\n      'align-content': [{\n        content: ['normal', ...getAlign(), 'baseline']\n      }],\n      /**\n       * Align Items\n       * @see https://tailwindcss.com/docs/align-items\n       */\n      'align-items': [{\n        items: ['start', 'end', 'center', 'baseline', 'stretch']\n      }],\n      /**\n       * Align Self\n       * @see https://tailwindcss.com/docs/align-self\n       */\n      'align-self': [{\n        self: ['auto', 'start', 'end', 'center', 'stretch', 'baseline']\n      }],\n      /**\n       * Place Content\n       * @see https://tailwindcss.com/docs/place-content\n       */\n      'place-content': [{\n        'place-content': [...getAlign(), 'baseline']\n      }],\n      /**\n       * Place Items\n       * @see https://tailwindcss.com/docs/place-items\n       */\n      'place-items': [{\n        'place-items': ['start', 'end', 'center', 'baseline', 'stretch']\n      }],\n      /**\n       * Place Self\n       * @see https://tailwindcss.com/docs/place-self\n       */\n      'place-self': [{\n        'place-self': ['auto', 'start', 'end', 'center', 'stretch']\n      }],\n      // Spacing\n      /**\n       * Padding\n       * @see https://tailwindcss.com/docs/padding\n       */\n      p: [{\n        p: [padding]\n      }],\n      /**\n       * Padding X\n       * @see https://tailwindcss.com/docs/padding\n       */\n      px: [{\n        px: [padding]\n      }],\n      /**\n       * Padding Y\n       * @see https://tailwindcss.com/docs/padding\n       */\n      py: [{\n        py: [padding]\n      }],\n      /**\n       * Padding Start\n       * @see https://tailwindcss.com/docs/padding\n       */\n      ps: [{\n        ps: [padding]\n      }],\n      /**\n       * Padding End\n       * @see https://tailwindcss.com/docs/padding\n       */\n      pe: [{\n        pe: [padding]\n      }],\n      /**\n       * Padding Top\n       * @see https://tailwindcss.com/docs/padding\n       */\n      pt: [{\n        pt: [padding]\n      }],\n      /**\n       * Padding Right\n       * @see https://tailwindcss.com/docs/padding\n       */\n      pr: [{\n        pr: [padding]\n      }],\n      /**\n       * Padding Bottom\n       * @see https://tailwindcss.com/docs/padding\n       */\n      pb: [{\n        pb: [padding]\n      }],\n      /**\n       * Padding Left\n       * @see https://tailwindcss.com/docs/padding\n       */\n      pl: [{\n        pl: [padding]\n      }],\n      /**\n       * Margin\n       * @see https://tailwindcss.com/docs/margin\n       */\n      m: [{\n        m: [margin]\n      }],\n      /**\n       * Margin X\n       * @see https://tailwindcss.com/docs/margin\n       */\n      mx: [{\n        mx: [margin]\n      }],\n      /**\n       * Margin Y\n       * @see https://tailwindcss.com/docs/margin\n       */\n      my: [{\n        my: [margin]\n      }],\n      /**\n       * Margin Start\n       * @see https://tailwindcss.com/docs/margin\n       */\n      ms: [{\n        ms: [margin]\n      }],\n      /**\n       * Margin End\n       * @see https://tailwindcss.com/docs/margin\n       */\n      me: [{\n        me: [margin]\n      }],\n      /**\n       * Margin Top\n       * @see https://tailwindcss.com/docs/margin\n       */\n      mt: [{\n        mt: [margin]\n      }],\n      /**\n       * Margin Right\n       * @see https://tailwindcss.com/docs/margin\n       */\n      mr: [{\n        mr: [margin]\n      }],\n      /**\n       * Margin Bottom\n       * @see https://tailwindcss.com/docs/margin\n       */\n      mb: [{\n        mb: [margin]\n      }],\n      /**\n       * Margin Left\n       * @see https://tailwindcss.com/docs/margin\n       */\n      ml: [{\n        ml: [margin]\n      }],\n      /**\n       * Space Between X\n       * @see https://tailwindcss.com/docs/space\n       */\n      'space-x': [{\n        'space-x': [space]\n      }],\n      /**\n       * Space Between X Reverse\n       * @see https://tailwindcss.com/docs/space\n       */\n      'space-x-reverse': ['space-x-reverse'],\n      /**\n       * Space Between Y\n       * @see https://tailwindcss.com/docs/space\n       */\n      'space-y': [{\n        'space-y': [space]\n      }],\n      /**\n       * Space Between Y Reverse\n       * @see https://tailwindcss.com/docs/space\n       */\n      'space-y-reverse': ['space-y-reverse'],\n      // Sizing\n      /**\n       * Width\n       * @see https://tailwindcss.com/docs/width\n       */\n      w: [{\n        w: ['auto', 'min', 'max', 'fit', isArbitraryValue, spacing]\n      }],\n      /**\n       * Min-Width\n       * @see https://tailwindcss.com/docs/min-width\n       */\n      'min-w': [{\n        'min-w': ['min', 'max', 'fit', isArbitraryValue, isLength]\n      }],\n      /**\n       * Max-Width\n       * @see https://tailwindcss.com/docs/max-width\n       */\n      'max-w': [{\n        'max-w': ['0', 'none', 'full', 'min', 'max', 'fit', 'prose', {\n          screen: [isTshirtSize]\n        }, isTshirtSize, isArbitraryValue]\n      }],\n      /**\n       * Height\n       * @see https://tailwindcss.com/docs/height\n       */\n      h: [{\n        h: [isArbitraryValue, spacing, 'auto', 'min', 'max', 'fit']\n      }],\n      /**\n       * Min-Height\n       * @see https://tailwindcss.com/docs/min-height\n       */\n      'min-h': [{\n        'min-h': ['min', 'max', 'fit', isLength, isArbitraryValue]\n      }],\n      /**\n       * Max-Height\n       * @see https://tailwindcss.com/docs/max-height\n       */\n      'max-h': [{\n        'max-h': [isArbitraryValue, spacing, 'min', 'max', 'fit']\n      }],\n      // Typography\n      /**\n       * Font Size\n       * @see https://tailwindcss.com/docs/font-size\n       */\n      'font-size': [{\n        text: ['base', isTshirtSize, isArbitraryLength]\n      }],\n      /**\n       * Font Smoothing\n       * @see https://tailwindcss.com/docs/font-smoothing\n       */\n      'font-smoothing': ['antialiased', 'subpixel-antialiased'],\n      /**\n       * Font Style\n       * @see https://tailwindcss.com/docs/font-style\n       */\n      'font-style': ['italic', 'not-italic'],\n      /**\n       * Font Weight\n       * @see https://tailwindcss.com/docs/font-weight\n       */\n      'font-weight': [{\n        font: ['thin', 'extralight', 'light', 'normal', 'medium', 'semibold', 'bold', 'extrabold', 'black', isArbitraryNumber]\n      }],\n      /**\n       * Font Family\n       * @see https://tailwindcss.com/docs/font-family\n       */\n      'font-family': [{\n        font: [isAny]\n      }],\n      /**\n       * Font Variant Numeric\n       * @see https://tailwindcss.com/docs/font-variant-numeric\n       */\n      'fvn-normal': ['normal-nums'],\n      /**\n       * Font Variant Numeric\n       * @see https://tailwindcss.com/docs/font-variant-numeric\n       */\n      'fvn-ordinal': ['ordinal'],\n      /**\n       * Font Variant Numeric\n       * @see https://tailwindcss.com/docs/font-variant-numeric\n       */\n      'fvn-slashed-zero': ['slashed-zero'],\n      /**\n       * Font Variant Numeric\n       * @see https://tailwindcss.com/docs/font-variant-numeric\n       */\n      'fvn-figure': ['lining-nums', 'oldstyle-nums'],\n      /**\n       * Font Variant Numeric\n       * @see https://tailwindcss.com/docs/font-variant-numeric\n       */\n      'fvn-spacing': ['proportional-nums', 'tabular-nums'],\n      /**\n       * Font Variant Numeric\n       * @see https://tailwindcss.com/docs/font-variant-numeric\n       */\n      'fvn-fraction': ['diagonal-fractions', 'stacked-fractons'],\n      /**\n       * Letter Spacing\n       * @see https://tailwindcss.com/docs/letter-spacing\n       */\n      tracking: [{\n        tracking: ['tighter', 'tight', 'normal', 'wide', 'wider', 'widest', isArbitraryValue]\n      }],\n      /**\n       * Line Clamp\n       * @see https://tailwindcss.com/docs/line-clamp\n       */\n      'line-clamp': [{\n        'line-clamp': ['none', isNumber, isArbitraryNumber]\n      }],\n      /**\n       * Line Height\n       * @see https://tailwindcss.com/docs/line-height\n       */\n      leading: [{\n        leading: ['none', 'tight', 'snug', 'normal', 'relaxed', 'loose', isLength, isArbitraryValue]\n      }],\n      /**\n       * List Style Image\n       * @see https://tailwindcss.com/docs/list-style-image\n       */\n      'list-image': [{\n        'list-image': ['none', isArbitraryValue]\n      }],\n      /**\n       * List Style Type\n       * @see https://tailwindcss.com/docs/list-style-type\n       */\n      'list-style-type': [{\n        list: ['none', 'disc', 'decimal', isArbitraryValue]\n      }],\n      /**\n       * List Style Position\n       * @see https://tailwindcss.com/docs/list-style-position\n       */\n      'list-style-position': [{\n        list: ['inside', 'outside']\n      }],\n      /**\n       * Placeholder Color\n       * @deprecated since Tailwind CSS v3.0.0\n       * @see https://tailwindcss.com/docs/placeholder-color\n       */\n      'placeholder-color': [{\n        placeholder: [colors]\n      }],\n      /**\n       * Placeholder Opacity\n       * @see https://tailwindcss.com/docs/placeholder-opacity\n       */\n      'placeholder-opacity': [{\n        'placeholder-opacity': [opacity]\n      }],\n      /**\n       * Text Alignment\n       * @see https://tailwindcss.com/docs/text-align\n       */\n      'text-alignment': [{\n        text: ['left', 'center', 'right', 'justify', 'start', 'end']\n      }],\n      /**\n       * Text Color\n       * @see https://tailwindcss.com/docs/text-color\n       */\n      'text-color': [{\n        text: [colors]\n      }],\n      /**\n       * Text Opacity\n       * @see https://tailwindcss.com/docs/text-opacity\n       */\n      'text-opacity': [{\n        'text-opacity': [opacity]\n      }],\n      /**\n       * Text Decoration\n       * @see https://tailwindcss.com/docs/text-decoration\n       */\n      'text-decoration': ['underline', 'overline', 'line-through', 'no-underline'],\n      /**\n       * Text Decoration Style\n       * @see https://tailwindcss.com/docs/text-decoration-style\n       */\n      'text-decoration-style': [{\n        decoration: [...getLineStyles(), 'wavy']\n      }],\n      /**\n       * Text Decoration Thickness\n       * @see https://tailwindcss.com/docs/text-decoration-thickness\n       */\n      'text-decoration-thickness': [{\n        decoration: ['auto', 'from-font', isLength, isArbitraryLength]\n      }],\n      /**\n       * Text Underline Offset\n       * @see https://tailwindcss.com/docs/text-underline-offset\n       */\n      'underline-offset': [{\n        'underline-offset': ['auto', isLength, isArbitraryValue]\n      }],\n      /**\n       * Text Decoration Color\n       * @see https://tailwindcss.com/docs/text-decoration-color\n       */\n      'text-decoration-color': [{\n        decoration: [colors]\n      }],\n      /**\n       * Text Transform\n       * @see https://tailwindcss.com/docs/text-transform\n       */\n      'text-transform': ['uppercase', 'lowercase', 'capitalize', 'normal-case'],\n      /**\n       * Text Overflow\n       * @see https://tailwindcss.com/docs/text-overflow\n       */\n      'text-overflow': ['truncate', 'text-ellipsis', 'text-clip'],\n      /**\n       * Text Indent\n       * @see https://tailwindcss.com/docs/text-indent\n       */\n      indent: [{\n        indent: getSpacingWithArbitrary()\n      }],\n      /**\n       * Vertical Alignment\n       * @see https://tailwindcss.com/docs/vertical-align\n       */\n      'vertical-align': [{\n        align: ['baseline', 'top', 'middle', 'bottom', 'text-top', 'text-bottom', 'sub', 'super', isArbitraryValue]\n      }],\n      /**\n       * Whitespace\n       * @see https://tailwindcss.com/docs/whitespace\n       */\n      whitespace: [{\n        whitespace: ['normal', 'nowrap', 'pre', 'pre-line', 'pre-wrap', 'break-spaces']\n      }],\n      /**\n       * Word Break\n       * @see https://tailwindcss.com/docs/word-break\n       */\n      break: [{\n        break: ['normal', 'words', 'all', 'keep']\n      }],\n      /**\n       * Hyphens\n       * @see https://tailwindcss.com/docs/hyphens\n       */\n      hyphens: [{\n        hyphens: ['none', 'manual', 'auto']\n      }],\n      /**\n       * Content\n       * @see https://tailwindcss.com/docs/content\n       */\n      content: [{\n        content: ['none', isArbitraryValue]\n      }],\n      // Backgrounds\n      /**\n       * Background Attachment\n       * @see https://tailwindcss.com/docs/background-attachment\n       */\n      'bg-attachment': [{\n        bg: ['fixed', 'local', 'scroll']\n      }],\n      /**\n       * Background Clip\n       * @see https://tailwindcss.com/docs/background-clip\n       */\n      'bg-clip': [{\n        'bg-clip': ['border', 'padding', 'content', 'text']\n      }],\n      /**\n       * Background Opacity\n       * @deprecated since Tailwind CSS v3.0.0\n       * @see https://tailwindcss.com/docs/background-opacity\n       */\n      'bg-opacity': [{\n        'bg-opacity': [opacity]\n      }],\n      /**\n       * Background Origin\n       * @see https://tailwindcss.com/docs/background-origin\n       */\n      'bg-origin': [{\n        'bg-origin': ['border', 'padding', 'content']\n      }],\n      /**\n       * Background Position\n       * @see https://tailwindcss.com/docs/background-position\n       */\n      'bg-position': [{\n        bg: [...getPositions(), isArbitraryPosition]\n      }],\n      /**\n       * Background Repeat\n       * @see https://tailwindcss.com/docs/background-repeat\n       */\n      'bg-repeat': [{\n        bg: ['no-repeat', {\n          repeat: ['', 'x', 'y', 'round', 'space']\n        }]\n      }],\n      /**\n       * Background Size\n       * @see https://tailwindcss.com/docs/background-size\n       */\n      'bg-size': [{\n        bg: ['auto', 'cover', 'contain', isArbitrarySize]\n      }],\n      /**\n       * Background Image\n       * @see https://tailwindcss.com/docs/background-image\n       */\n      'bg-image': [{\n        bg: ['none', {\n          'gradient-to': ['t', 'tr', 'r', 'br', 'b', 'bl', 'l', 'tl']\n        }, isArbitraryImage]\n      }],\n      /**\n       * Background Color\n       * @see https://tailwindcss.com/docs/background-color\n       */\n      'bg-color': [{\n        bg: [colors]\n      }],\n      /**\n       * Gradient Color Stops From Position\n       * @see https://tailwindcss.com/docs/gradient-color-stops\n       */\n      'gradient-from-pos': [{\n        from: [gradientColorStopPositions]\n      }],\n      /**\n       * Gradient Color Stops Via Position\n       * @see https://tailwindcss.com/docs/gradient-color-stops\n       */\n      'gradient-via-pos': [{\n        via: [gradientColorStopPositions]\n      }],\n      /**\n       * Gradient Color Stops To Position\n       * @see https://tailwindcss.com/docs/gradient-color-stops\n       */\n      'gradient-to-pos': [{\n        to: [gradientColorStopPositions]\n      }],\n      /**\n       * Gradient Color Stops From\n       * @see https://tailwindcss.com/docs/gradient-color-stops\n       */\n      'gradient-from': [{\n        from: [gradientColorStops]\n      }],\n      /**\n       * Gradient Color Stops Via\n       * @see https://tailwindcss.com/docs/gradient-color-stops\n       */\n      'gradient-via': [{\n        via: [gradientColorStops]\n      }],\n      /**\n       * Gradient Color Stops To\n       * @see https://tailwindcss.com/docs/gradient-color-stops\n       */\n      'gradient-to': [{\n        to: [gradientColorStops]\n      }],\n      // Borders\n      /**\n       * Border Radius\n       * @see https://tailwindcss.com/docs/border-radius\n       */\n      rounded: [{\n        rounded: [borderRadius]\n      }],\n      /**\n       * Border Radius Start\n       * @see https://tailwindcss.com/docs/border-radius\n       */\n      'rounded-s': [{\n        'rounded-s': [borderRadius]\n      }],\n      /**\n       * Border Radius End\n       * @see https://tailwindcss.com/docs/border-radius\n       */\n      'rounded-e': [{\n        'rounded-e': [borderRadius]\n      }],\n      /**\n       * Border Radius Top\n       * @see https://tailwindcss.com/docs/border-radius\n       */\n      'rounded-t': [{\n        'rounded-t': [borderRadius]\n      }],\n      /**\n       * Border Radius Right\n       * @see https://tailwindcss.com/docs/border-radius\n       */\n      'rounded-r': [{\n        'rounded-r': [borderRadius]\n      }],\n      /**\n       * Border Radius Bottom\n       * @see https://tailwindcss.com/docs/border-radius\n       */\n      'rounded-b': [{\n        'rounded-b': [borderRadius]\n      }],\n      /**\n       * Border Radius Left\n       * @see https://tailwindcss.com/docs/border-radius\n       */\n      'rounded-l': [{\n        'rounded-l': [borderRadius]\n      }],\n      /**\n       * Border Radius Start Start\n       * @see https://tailwindcss.com/docs/border-radius\n       */\n      'rounded-ss': [{\n        'rounded-ss': [borderRadius]\n      }],\n      /**\n       * Border Radius Start End\n       * @see https://tailwindcss.com/docs/border-radius\n       */\n      'rounded-se': [{\n        'rounded-se': [borderRadius]\n      }],\n      /**\n       * Border Radius End End\n       * @see https://tailwindcss.com/docs/border-radius\n       */\n      'rounded-ee': [{\n        'rounded-ee': [borderRadius]\n      }],\n      /**\n       * Border Radius End Start\n       * @see https://tailwindcss.com/docs/border-radius\n       */\n      'rounded-es': [{\n        'rounded-es': [borderRadius]\n      }],\n      /**\n       * Border Radius Top Left\n       * @see https://tailwindcss.com/docs/border-radius\n       */\n      'rounded-tl': [{\n        'rounded-tl': [borderRadius]\n      }],\n      /**\n       * Border Radius Top Right\n       * @see https://tailwindcss.com/docs/border-radius\n       */\n      'rounded-tr': [{\n        'rounded-tr': [borderRadius]\n      }],\n      /**\n       * Border Radius Bottom Right\n       * @see https://tailwindcss.com/docs/border-radius\n       */\n      'rounded-br': [{\n        'rounded-br': [borderRadius]\n      }],\n      /**\n       * Border Radius Bottom Left\n       * @see https://tailwindcss.com/docs/border-radius\n       */\n      'rounded-bl': [{\n        'rounded-bl': [borderRadius]\n      }],\n      /**\n       * Border Width\n       * @see https://tailwindcss.com/docs/border-width\n       */\n      'border-w': [{\n        border: [borderWidth]\n      }],\n      /**\n       * Border Width X\n       * @see https://tailwindcss.com/docs/border-width\n       */\n      'border-w-x': [{\n        'border-x': [borderWidth]\n      }],\n      /**\n       * Border Width Y\n       * @see https://tailwindcss.com/docs/border-width\n       */\n      'border-w-y': [{\n        'border-y': [borderWidth]\n      }],\n      /**\n       * Border Width Start\n       * @see https://tailwindcss.com/docs/border-width\n       */\n      'border-w-s': [{\n        'border-s': [borderWidth]\n      }],\n      /**\n       * Border Width End\n       * @see https://tailwindcss.com/docs/border-width\n       */\n      'border-w-e': [{\n        'border-e': [borderWidth]\n      }],\n      /**\n       * Border Width Top\n       * @see https://tailwindcss.com/docs/border-width\n       */\n      'border-w-t': [{\n        'border-t': [borderWidth]\n      }],\n      /**\n       * Border Width Right\n       * @see https://tailwindcss.com/docs/border-width\n       */\n      'border-w-r': [{\n        'border-r': [borderWidth]\n      }],\n      /**\n       * Border Width Bottom\n       * @see https://tailwindcss.com/docs/border-width\n       */\n      'border-w-b': [{\n        'border-b': [borderWidth]\n      }],\n      /**\n       * Border Width Left\n       * @see https://tailwindcss.com/docs/border-width\n       */\n      'border-w-l': [{\n        'border-l': [borderWidth]\n      }],\n      /**\n       * Border Opacity\n       * @see https://tailwindcss.com/docs/border-opacity\n       */\n      'border-opacity': [{\n        'border-opacity': [opacity]\n      }],\n      /**\n       * Border Style\n       * @see https://tailwindcss.com/docs/border-style\n       */\n      'border-style': [{\n        border: [...getLineStyles(), 'hidden']\n      }],\n      /**\n       * Divide Width X\n       * @see https://tailwindcss.com/docs/divide-width\n       */\n      'divide-x': [{\n        'divide-x': [borderWidth]\n      }],\n      /**\n       * Divide Width X Reverse\n       * @see https://tailwindcss.com/docs/divide-width\n       */\n      'divide-x-reverse': ['divide-x-reverse'],\n      /**\n       * Divide Width Y\n       * @see https://tailwindcss.com/docs/divide-width\n       */\n      'divide-y': [{\n        'divide-y': [borderWidth]\n      }],\n      /**\n       * Divide Width Y Reverse\n       * @see https://tailwindcss.com/docs/divide-width\n       */\n      'divide-y-reverse': ['divide-y-reverse'],\n      /**\n       * Divide Opacity\n       * @see https://tailwindcss.com/docs/divide-opacity\n       */\n      'divide-opacity': [{\n        'divide-opacity': [opacity]\n      }],\n      /**\n       * Divide Style\n       * @see https://tailwindcss.com/docs/divide-style\n       */\n      'divide-style': [{\n        divide: getLineStyles()\n      }],\n      /**\n       * Border Color\n       * @see https://tailwindcss.com/docs/border-color\n       */\n      'border-color': [{\n        border: [borderColor]\n      }],\n      /**\n       * Border Color X\n       * @see https://tailwindcss.com/docs/border-color\n       */\n      'border-color-x': [{\n        'border-x': [borderColor]\n      }],\n      /**\n       * Border Color Y\n       * @see https://tailwindcss.com/docs/border-color\n       */\n      'border-color-y': [{\n        'border-y': [borderColor]\n      }],\n      /**\n       * Border Color Top\n       * @see https://tailwindcss.com/docs/border-color\n       */\n      'border-color-t': [{\n        'border-t': [borderColor]\n      }],\n      /**\n       * Border Color Right\n       * @see https://tailwindcss.com/docs/border-color\n       */\n      'border-color-r': [{\n        'border-r': [borderColor]\n      }],\n      /**\n       * Border Color Bottom\n       * @see https://tailwindcss.com/docs/border-color\n       */\n      'border-color-b': [{\n        'border-b': [borderColor]\n      }],\n      /**\n       * Border Color Left\n       * @see https://tailwindcss.com/docs/border-color\n       */\n      'border-color-l': [{\n        'border-l': [borderColor]\n      }],\n      /**\n       * Divide Color\n       * @see https://tailwindcss.com/docs/divide-color\n       */\n      'divide-color': [{\n        divide: [borderColor]\n      }],\n      /**\n       * Outline Style\n       * @see https://tailwindcss.com/docs/outline-style\n       */\n      'outline-style': [{\n        outline: ['', ...getLineStyles()]\n      }],\n      /**\n       * Outline Offset\n       * @see https://tailwindcss.com/docs/outline-offset\n       */\n      'outline-offset': [{\n        'outline-offset': [isLength, isArbitraryValue]\n      }],\n      /**\n       * Outline Width\n       * @see https://tailwindcss.com/docs/outline-width\n       */\n      'outline-w': [{\n        outline: [isLength, isArbitraryLength]\n      }],\n      /**\n       * Outline Color\n       * @see https://tailwindcss.com/docs/outline-color\n       */\n      'outline-color': [{\n        outline: [colors]\n      }],\n      /**\n       * Ring Width\n       * @see https://tailwindcss.com/docs/ring-width\n       */\n      'ring-w': [{\n        ring: getLengthWithEmptyAndArbitrary()\n      }],\n      /**\n       * Ring Width Inset\n       * @see https://tailwindcss.com/docs/ring-width\n       */\n      'ring-w-inset': ['ring-inset'],\n      /**\n       * Ring Color\n       * @see https://tailwindcss.com/docs/ring-color\n       */\n      'ring-color': [{\n        ring: [colors]\n      }],\n      /**\n       * Ring Opacity\n       * @see https://tailwindcss.com/docs/ring-opacity\n       */\n      'ring-opacity': [{\n        'ring-opacity': [opacity]\n      }],\n      /**\n       * Ring Offset Width\n       * @see https://tailwindcss.com/docs/ring-offset-width\n       */\n      'ring-offset-w': [{\n        'ring-offset': [isLength, isArbitraryLength]\n      }],\n      /**\n       * Ring Offset Color\n       * @see https://tailwindcss.com/docs/ring-offset-color\n       */\n      'ring-offset-color': [{\n        'ring-offset': [colors]\n      }],\n      // Effects\n      /**\n       * Box Shadow\n       * @see https://tailwindcss.com/docs/box-shadow\n       */\n      shadow: [{\n        shadow: ['', 'inner', 'none', isTshirtSize, isArbitraryShadow]\n      }],\n      /**\n       * Box Shadow Color\n       * @see https://tailwindcss.com/docs/box-shadow-color\n       */\n      'shadow-color': [{\n        shadow: [isAny]\n      }],\n      /**\n       * Opacity\n       * @see https://tailwindcss.com/docs/opacity\n       */\n      opacity: [{\n        opacity: [opacity]\n      }],\n      /**\n       * Mix Blend Mode\n       * @see https://tailwindcss.com/docs/mix-blend-mode\n       */\n      'mix-blend': [{\n        'mix-blend': getBlendModes()\n      }],\n      /**\n       * Background Blend Mode\n       * @see https://tailwindcss.com/docs/background-blend-mode\n       */\n      'bg-blend': [{\n        'bg-blend': getBlendModes()\n      }],\n      // Filters\n      /**\n       * Filter\n       * @deprecated since Tailwind CSS v3.0.0\n       * @see https://tailwindcss.com/docs/filter\n       */\n      filter: [{\n        filter: ['', 'none']\n      }],\n      /**\n       * Blur\n       * @see https://tailwindcss.com/docs/blur\n       */\n      blur: [{\n        blur: [blur]\n      }],\n      /**\n       * Brightness\n       * @see https://tailwindcss.com/docs/brightness\n       */\n      brightness: [{\n        brightness: [brightness]\n      }],\n      /**\n       * Contrast\n       * @see https://tailwindcss.com/docs/contrast\n       */\n      contrast: [{\n        contrast: [contrast]\n      }],\n      /**\n       * Drop Shadow\n       * @see https://tailwindcss.com/docs/drop-shadow\n       */\n      'drop-shadow': [{\n        'drop-shadow': ['', 'none', isTshirtSize, isArbitraryValue]\n      }],\n      /**\n       * Grayscale\n       * @see https://tailwindcss.com/docs/grayscale\n       */\n      grayscale: [{\n        grayscale: [grayscale]\n      }],\n      /**\n       * Hue Rotate\n       * @see https://tailwindcss.com/docs/hue-rotate\n       */\n      'hue-rotate': [{\n        'hue-rotate': [hueRotate]\n      }],\n      /**\n       * Invert\n       * @see https://tailwindcss.com/docs/invert\n       */\n      invert: [{\n        invert: [invert]\n      }],\n      /**\n       * Saturate\n       * @see https://tailwindcss.com/docs/saturate\n       */\n      saturate: [{\n        saturate: [saturate]\n      }],\n      /**\n       * Sepia\n       * @see https://tailwindcss.com/docs/sepia\n       */\n      sepia: [{\n        sepia: [sepia]\n      }],\n      /**\n       * Backdrop Filter\n       * @deprecated since Tailwind CSS v3.0.0\n       * @see https://tailwindcss.com/docs/backdrop-filter\n       */\n      'backdrop-filter': [{\n        'backdrop-filter': ['', 'none']\n      }],\n      /**\n       * Backdrop Blur\n       * @see https://tailwindcss.com/docs/backdrop-blur\n       */\n      'backdrop-blur': [{\n        'backdrop-blur': [blur]\n      }],\n      /**\n       * Backdrop Brightness\n       * @see https://tailwindcss.com/docs/backdrop-brightness\n       */\n      'backdrop-brightness': [{\n        'backdrop-brightness': [brightness]\n      }],\n      /**\n       * Backdrop Contrast\n       * @see https://tailwindcss.com/docs/backdrop-contrast\n       */\n      'backdrop-contrast': [{\n        'backdrop-contrast': [contrast]\n      }],\n      /**\n       * Backdrop Grayscale\n       * @see https://tailwindcss.com/docs/backdrop-grayscale\n       */\n      'backdrop-grayscale': [{\n        'backdrop-grayscale': [grayscale]\n      }],\n      /**\n       * Backdrop Hue Rotate\n       * @see https://tailwindcss.com/docs/backdrop-hue-rotate\n       */\n      'backdrop-hue-rotate': [{\n        'backdrop-hue-rotate': [hueRotate]\n      }],\n      /**\n       * Backdrop Invert\n       * @see https://tailwindcss.com/docs/backdrop-invert\n       */\n      'backdrop-invert': [{\n        'backdrop-invert': [invert]\n      }],\n      /**\n       * Backdrop Opacity\n       * @see https://tailwindcss.com/docs/backdrop-opacity\n       */\n      'backdrop-opacity': [{\n        'backdrop-opacity': [opacity]\n      }],\n      /**\n       * Backdrop Saturate\n       * @see https://tailwindcss.com/docs/backdrop-saturate\n       */\n      'backdrop-saturate': [{\n        'backdrop-saturate': [saturate]\n      }],\n      /**\n       * Backdrop Sepia\n       * @see https://tailwindcss.com/docs/backdrop-sepia\n       */\n      'backdrop-sepia': [{\n        'backdrop-sepia': [sepia]\n      }],\n      // Tables\n      /**\n       * Border Collapse\n       * @see https://tailwindcss.com/docs/border-collapse\n       */\n      'border-collapse': [{\n        border: ['collapse', 'separate']\n      }],\n      /**\n       * Border Spacing\n       * @see https://tailwindcss.com/docs/border-spacing\n       */\n      'border-spacing': [{\n        'border-spacing': [borderSpacing]\n      }],\n      /**\n       * Border Spacing X\n       * @see https://tailwindcss.com/docs/border-spacing\n       */\n      'border-spacing-x': [{\n        'border-spacing-x': [borderSpacing]\n      }],\n      /**\n       * Border Spacing Y\n       * @see https://tailwindcss.com/docs/border-spacing\n       */\n      'border-spacing-y': [{\n        'border-spacing-y': [borderSpacing]\n      }],\n      /**\n       * Table Layout\n       * @see https://tailwindcss.com/docs/table-layout\n       */\n      'table-layout': [{\n        table: ['auto', 'fixed']\n      }],\n      /**\n       * Caption Side\n       * @see https://tailwindcss.com/docs/caption-side\n       */\n      caption: [{\n        caption: ['top', 'bottom']\n      }],\n      // Transitions and Animation\n      /**\n       * Tranisition Property\n       * @see https://tailwindcss.com/docs/transition-property\n       */\n      transition: [{\n        transition: ['none', 'all', '', 'colors', 'opacity', 'shadow', 'transform', isArbitraryValue]\n      }],\n      /**\n       * Transition Duration\n       * @see https://tailwindcss.com/docs/transition-duration\n       */\n      duration: [{\n        duration: getNumberAndArbitrary()\n      }],\n      /**\n       * Transition Timing Function\n       * @see https://tailwindcss.com/docs/transition-timing-function\n       */\n      ease: [{\n        ease: ['linear', 'in', 'out', 'in-out', isArbitraryValue]\n      }],\n      /**\n       * Transition Delay\n       * @see https://tailwindcss.com/docs/transition-delay\n       */\n      delay: [{\n        delay: getNumberAndArbitrary()\n      }],\n      /**\n       * Animation\n       * @see https://tailwindcss.com/docs/animation\n       */\n      animate: [{\n        animate: ['none', 'spin', 'ping', 'pulse', 'bounce', isArbitraryValue]\n      }],\n      // Transforms\n      /**\n       * Transform\n       * @see https://tailwindcss.com/docs/transform\n       */\n      transform: [{\n        transform: ['', 'gpu', 'none']\n      }],\n      /**\n       * Scale\n       * @see https://tailwindcss.com/docs/scale\n       */\n      scale: [{\n        scale: [scale]\n      }],\n      /**\n       * Scale X\n       * @see https://tailwindcss.com/docs/scale\n       */\n      'scale-x': [{\n        'scale-x': [scale]\n      }],\n      /**\n       * Scale Y\n       * @see https://tailwindcss.com/docs/scale\n       */\n      'scale-y': [{\n        'scale-y': [scale]\n      }],\n      /**\n       * Rotate\n       * @see https://tailwindcss.com/docs/rotate\n       */\n      rotate: [{\n        rotate: [isInteger, isArbitraryValue]\n      }],\n      /**\n       * Translate X\n       * @see https://tailwindcss.com/docs/translate\n       */\n      'translate-x': [{\n        'translate-x': [translate]\n      }],\n      /**\n       * Translate Y\n       * @see https://tailwindcss.com/docs/translate\n       */\n      'translate-y': [{\n        'translate-y': [translate]\n      }],\n      /**\n       * Skew X\n       * @see https://tailwindcss.com/docs/skew\n       */\n      'skew-x': [{\n        'skew-x': [skew]\n      }],\n      /**\n       * Skew Y\n       * @see https://tailwindcss.com/docs/skew\n       */\n      'skew-y': [{\n        'skew-y': [skew]\n      }],\n      /**\n       * Transform Origin\n       * @see https://tailwindcss.com/docs/transform-origin\n       */\n      'transform-origin': [{\n        origin: ['center', 'top', 'top-right', 'right', 'bottom-right', 'bottom', 'bottom-left', 'left', 'top-left', isArbitraryValue]\n      }],\n      // Interactivity\n      /**\n       * Accent Color\n       * @see https://tailwindcss.com/docs/accent-color\n       */\n      accent: [{\n        accent: ['auto', colors]\n      }],\n      /**\n       * Appearance\n       * @see https://tailwindcss.com/docs/appearance\n       */\n      appearance: ['appearance-none'],\n      /**\n       * Cursor\n       * @see https://tailwindcss.com/docs/cursor\n       */\n      cursor: [{\n        cursor: ['auto', 'default', 'pointer', 'wait', 'text', 'move', 'help', 'not-allowed', 'none', 'context-menu', 'progress', 'cell', 'crosshair', 'vertical-text', 'alias', 'copy', 'no-drop', 'grab', 'grabbing', 'all-scroll', 'col-resize', 'row-resize', 'n-resize', 'e-resize', 's-resize', 'w-resize', 'ne-resize', 'nw-resize', 'se-resize', 'sw-resize', 'ew-resize', 'ns-resize', 'nesw-resize', 'nwse-resize', 'zoom-in', 'zoom-out', isArbitraryValue]\n      }],\n      /**\n       * Caret Color\n       * @see https://tailwindcss.com/docs/just-in-time-mode#caret-color-utilities\n       */\n      'caret-color': [{\n        caret: [colors]\n      }],\n      /**\n       * Pointer Events\n       * @see https://tailwindcss.com/docs/pointer-events\n       */\n      'pointer-events': [{\n        'pointer-events': ['none', 'auto']\n      }],\n      /**\n       * Resize\n       * @see https://tailwindcss.com/docs/resize\n       */\n      resize: [{\n        resize: ['none', 'y', 'x', '']\n      }],\n      /**\n       * Scroll Behavior\n       * @see https://tailwindcss.com/docs/scroll-behavior\n       */\n      'scroll-behavior': [{\n        scroll: ['auto', 'smooth']\n      }],\n      /**\n       * Scroll Margin\n       * @see https://tailwindcss.com/docs/scroll-margin\n       */\n      'scroll-m': [{\n        'scroll-m': getSpacingWithArbitrary()\n      }],\n      /**\n       * Scroll Margin X\n       * @see https://tailwindcss.com/docs/scroll-margin\n       */\n      'scroll-mx': [{\n        'scroll-mx': getSpacingWithArbitrary()\n      }],\n      /**\n       * Scroll Margin Y\n       * @see https://tailwindcss.com/docs/scroll-margin\n       */\n      'scroll-my': [{\n        'scroll-my': getSpacingWithArbitrary()\n      }],\n      /**\n       * Scroll Margin Start\n       * @see https://tailwindcss.com/docs/scroll-margin\n       */\n      'scroll-ms': [{\n        'scroll-ms': getSpacingWithArbitrary()\n      }],\n      /**\n       * Scroll Margin End\n       * @see https://tailwindcss.com/docs/scroll-margin\n       */\n      'scroll-me': [{\n        'scroll-me': getSpacingWithArbitrary()\n      }],\n      /**\n       * Scroll Margin Top\n       * @see https://tailwindcss.com/docs/scroll-margin\n       */\n      'scroll-mt': [{\n        'scroll-mt': getSpacingWithArbitrary()\n      }],\n      /**\n       * Scroll Margin Right\n       * @see https://tailwindcss.com/docs/scroll-margin\n       */\n      'scroll-mr': [{\n        'scroll-mr': getSpacingWithArbitrary()\n      }],\n      /**\n       * Scroll Margin Bottom\n       * @see https://tailwindcss.com/docs/scroll-margin\n       */\n      'scroll-mb': [{\n        'scroll-mb': getSpacingWithArbitrary()\n      }],\n      /**\n       * Scroll Margin Left\n       * @see https://tailwindcss.com/docs/scroll-margin\n       */\n      'scroll-ml': [{\n        'scroll-ml': getSpacingWithArbitrary()\n      }],\n      /**\n       * Scroll Padding\n       * @see https://tailwindcss.com/docs/scroll-padding\n       */\n      'scroll-p': [{\n        'scroll-p': getSpacingWithArbitrary()\n      }],\n      /**\n       * Scroll Padding X\n       * @see https://tailwindcss.com/docs/scroll-padding\n       */\n      'scroll-px': [{\n        'scroll-px': getSpacingWithArbitrary()\n      }],\n      /**\n       * Scroll Padding Y\n       * @see https://tailwindcss.com/docs/scroll-padding\n       */\n      'scroll-py': [{\n        'scroll-py': getSpacingWithArbitrary()\n      }],\n      /**\n       * Scroll Padding Start\n       * @see https://tailwindcss.com/docs/scroll-padding\n       */\n      'scroll-ps': [{\n        'scroll-ps': getSpacingWithArbitrary()\n      }],\n      /**\n       * Scroll Padding End\n       * @see https://tailwindcss.com/docs/scroll-padding\n       */\n      'scroll-pe': [{\n        'scroll-pe': getSpacingWithArbitrary()\n      }],\n      /**\n       * Scroll Padding Top\n       * @see https://tailwindcss.com/docs/scroll-padding\n       */\n      'scroll-pt': [{\n        'scroll-pt': getSpacingWithArbitrary()\n      }],\n      /**\n       * Scroll Padding Right\n       * @see https://tailwindcss.com/docs/scroll-padding\n       */\n      'scroll-pr': [{\n        'scroll-pr': getSpacingWithArbitrary()\n      }],\n      /**\n       * Scroll Padding Bottom\n       * @see https://tailwindcss.com/docs/scroll-padding\n       */\n      'scroll-pb': [{\n        'scroll-pb': getSpacingWithArbitrary()\n      }],\n      /**\n       * Scroll Padding Left\n       * @see https://tailwindcss.com/docs/scroll-padding\n       */\n      'scroll-pl': [{\n        'scroll-pl': getSpacingWithArbitrary()\n      }],\n      /**\n       * Scroll Snap Align\n       * @see https://tailwindcss.com/docs/scroll-snap-align\n       */\n      'snap-align': [{\n        snap: ['start', 'end', 'center', 'align-none']\n      }],\n      /**\n       * Scroll Snap Stop\n       * @see https://tailwindcss.com/docs/scroll-snap-stop\n       */\n      'snap-stop': [{\n        snap: ['normal', 'always']\n      }],\n      /**\n       * Scroll Snap Type\n       * @see https://tailwindcss.com/docs/scroll-snap-type\n       */\n      'snap-type': [{\n        snap: ['none', 'x', 'y', 'both']\n      }],\n      /**\n       * Scroll Snap Type Strictness\n       * @see https://tailwindcss.com/docs/scroll-snap-type\n       */\n      'snap-strictness': [{\n        snap: ['mandatory', 'proximity']\n      }],\n      /**\n       * Touch Action\n       * @see https://tailwindcss.com/docs/touch-action\n       */\n      touch: [{\n        touch: ['auto', 'none', 'manipulation']\n      }],\n      /**\n       * Touch Action X\n       * @see https://tailwindcss.com/docs/touch-action\n       */\n      'touch-x': [{\n        'touch-pan': ['x', 'left', 'right']\n      }],\n      /**\n       * Touch Action Y\n       * @see https://tailwindcss.com/docs/touch-action\n       */\n      'touch-y': [{\n        'touch-pan': ['y', 'up', 'down']\n      }],\n      /**\n       * Touch Action Pinch Zoom\n       * @see https://tailwindcss.com/docs/touch-action\n       */\n      'touch-pz': ['touch-pinch-zoom'],\n      /**\n       * User Select\n       * @see https://tailwindcss.com/docs/user-select\n       */\n      select: [{\n        select: ['none', 'text', 'all', 'auto']\n      }],\n      /**\n       * Will Change\n       * @see https://tailwindcss.com/docs/will-change\n       */\n      'will-change': [{\n        'will-change': ['auto', 'scroll', 'contents', 'transform', isArbitraryValue]\n      }],\n      // SVG\n      /**\n       * Fill\n       * @see https://tailwindcss.com/docs/fill\n       */\n      fill: [{\n        fill: [colors, 'none']\n      }],\n      /**\n       * Stroke Width\n       * @see https://tailwindcss.com/docs/stroke-width\n       */\n      'stroke-w': [{\n        stroke: [isLength, isArbitraryLength, isArbitraryNumber]\n      }],\n      /**\n       * Stroke\n       * @see https://tailwindcss.com/docs/stroke\n       */\n      stroke: [{\n        stroke: [colors, 'none']\n      }],\n      // Accessibility\n      /**\n       * Screen Readers\n       * @see https://tailwindcss.com/docs/screen-readers\n       */\n      sr: ['sr-only', 'not-sr-only']\n    },\n    conflictingClassGroups: {\n      overflow: ['overflow-x', 'overflow-y'],\n      overscroll: ['overscroll-x', 'overscroll-y'],\n      inset: ['inset-x', 'inset-y', 'start', 'end', 'top', 'right', 'bottom', 'left'],\n      'inset-x': ['right', 'left'],\n      'inset-y': ['top', 'bottom'],\n      flex: ['basis', 'grow', 'shrink'],\n      gap: ['gap-x', 'gap-y'],\n      p: ['px', 'py', 'ps', 'pe', 'pt', 'pr', 'pb', 'pl'],\n      px: ['pr', 'pl'],\n      py: ['pt', 'pb'],\n      m: ['mx', 'my', 'ms', 'me', 'mt', 'mr', 'mb', 'ml'],\n      mx: ['mr', 'ml'],\n      my: ['mt', 'mb'],\n      'font-size': ['leading'],\n      'fvn-normal': ['fvn-ordinal', 'fvn-slashed-zero', 'fvn-figure', 'fvn-spacing', 'fvn-fraction'],\n      'fvn-ordinal': ['fvn-normal'],\n      'fvn-slashed-zero': ['fvn-normal'],\n      'fvn-figure': ['fvn-normal'],\n      'fvn-spacing': ['fvn-normal'],\n      'fvn-fraction': ['fvn-normal'],\n      'line-clamp': ['display', 'overflow'],\n      rounded: ['rounded-s', 'rounded-e', 'rounded-t', 'rounded-r', 'rounded-b', 'rounded-l', 'rounded-ss', 'rounded-se', 'rounded-ee', 'rounded-es', 'rounded-tl', 'rounded-tr', 'rounded-br', 'rounded-bl'],\n      'rounded-s': ['rounded-ss', 'rounded-es'],\n      'rounded-e': ['rounded-se', 'rounded-ee'],\n      'rounded-t': ['rounded-tl', 'rounded-tr'],\n      'rounded-r': ['rounded-tr', 'rounded-br'],\n      'rounded-b': ['rounded-br', 'rounded-bl'],\n      'rounded-l': ['rounded-tl', 'rounded-bl'],\n      'border-spacing': ['border-spacing-x', 'border-spacing-y'],\n      'border-w': ['border-w-s', 'border-w-e', 'border-w-t', 'border-w-r', 'border-w-b', 'border-w-l'],\n      'border-w-x': ['border-w-r', 'border-w-l'],\n      'border-w-y': ['border-w-t', 'border-w-b'],\n      'border-color': ['border-color-t', 'border-color-r', 'border-color-b', 'border-color-l'],\n      'border-color-x': ['border-color-r', 'border-color-l'],\n      'border-color-y': ['border-color-t', 'border-color-b'],\n      'scroll-m': ['scroll-mx', 'scroll-my', 'scroll-ms', 'scroll-me', 'scroll-mt', 'scroll-mr', 'scroll-mb', 'scroll-ml'],\n      'scroll-mx': ['scroll-mr', 'scroll-ml'],\n      'scroll-my': ['scroll-mt', 'scroll-mb'],\n      'scroll-p': ['scroll-px', 'scroll-py', 'scroll-ps', 'scroll-pe', 'scroll-pt', 'scroll-pr', 'scroll-pb', 'scroll-pl'],\n      'scroll-px': ['scroll-pr', 'scroll-pl'],\n      'scroll-py': ['scroll-pt', 'scroll-pb'],\n      touch: ['touch-x', 'touch-y', 'touch-pz'],\n      'touch-x': ['touch'],\n      'touch-y': ['touch'],\n      'touch-pz': ['touch']\n    },\n    conflictingClassGroupModifiers: {\n      'font-size': ['leading']\n    }\n  };\n}\n\n/**\n * @param baseConfig Config where other config will be merged into. This object will be mutated.\n * @param configExtension Partial config to merge into the `baseConfig`.\n */\nfunction mergeConfigs(baseConfig, {\n  cacheSize,\n  prefix,\n  separator,\n  extend = {},\n  override = {}\n}) {\n  overrideProperty(baseConfig, 'cacheSize', cacheSize);\n  overrideProperty(baseConfig, 'prefix', prefix);\n  overrideProperty(baseConfig, 'separator', separator);\n  for (const configKey in override) {\n    overrideConfigProperties(baseConfig[configKey], override[configKey]);\n  }\n  for (const key in extend) {\n    mergeConfigProperties(baseConfig[key], extend[key]);\n  }\n  return baseConfig;\n}\nfunction overrideProperty(baseObject, overrideKey, overrideValue) {\n  if (overrideValue !== undefined) {\n    baseObject[overrideKey] = overrideValue;\n  }\n}\nfunction overrideConfigProperties(baseObject, overrideObject) {\n  if (overrideObject) {\n    for (const key in overrideObject) {\n      overrideProperty(baseObject, key, overrideObject[key]);\n    }\n  }\n}\nfunction mergeConfigProperties(baseObject, mergeObject) {\n  if (mergeObject) {\n    for (const key in mergeObject) {\n      const mergeValue = mergeObject[key];\n      if (mergeValue !== undefined) {\n        baseObject[key] = (baseObject[key] || []).concat(mergeValue);\n      }\n    }\n  }\n}\nfunction extendTailwindMerge(configExtension, ...createConfig) {\n  return typeof configExtension === 'function' ? createTailwindMerge(getDefaultConfig, configExtension, ...createConfig) : createTailwindMerge(() => mergeConfigs(getDefaultConfig(), configExtension), ...createConfig);\n}\nconst twMerge = /*#__PURE__*/createTailwindMerge(getDefaultConfig);\n\n//# sourceMappingURL=bundle-mjs.mjs.map\n\n\n//# sourceURL=webpack://renderer/./node_modules/tailwind-merge/dist/bundle-mjs.mjs?");

/***/ }),

/***/ "./node_modules/zustand/esm/index.mjs":
/*!********************************************!*\
  !*** ./node_modules/zustand/esm/index.mjs ***!
  \********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   create: () => (/* binding */ create),\n/* harmony export */   createStore: () => (/* reexport safe */ zustand_vanilla__WEBPACK_IMPORTED_MODULE_0__.createStore),\n/* harmony export */   \"default\": () => (/* binding */ react),\n/* harmony export */   useStore: () => (/* binding */ useStore)\n/* harmony export */ });\n/* harmony import */ var zustand_vanilla__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! zustand/vanilla */ \"./node_modules/zustand/esm/vanilla.mjs\");\n/* harmony import */ var react__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! react */ \"./node_modules/react/index.js\");\n/* harmony import */ var use_sync_external_store_shim_with_selector_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! use-sync-external-store/shim/with-selector.js */ \"./node_modules/use-sync-external-store/shim/with-selector.js\");\n\n\n\n\n\nconst { useDebugValue } = react__WEBPACK_IMPORTED_MODULE_1__;\nconst { useSyncExternalStoreWithSelector } = use_sync_external_store_shim_with_selector_js__WEBPACK_IMPORTED_MODULE_2__;\nlet didWarnAboutEqualityFn = false;\nfunction useStore(api, selector = api.getState, equalityFn) {\n  if (( false ? 0 : void 0) !== \"production\" && equalityFn && !didWarnAboutEqualityFn) {\n    console.warn(\n      \"[DEPRECATED] Use `createWithEqualityFn` instead of `create` or use `useStoreWithEqualityFn` instead of `useStore`. They can be imported from 'zustand/traditional'. https://github.com/pmndrs/zustand/discussions/1937\"\n    );\n    didWarnAboutEqualityFn = true;\n  }\n  const slice = useSyncExternalStoreWithSelector(\n    api.subscribe,\n    api.getState,\n    api.getServerState || api.getState,\n    selector,\n    equalityFn\n  );\n  useDebugValue(slice);\n  return slice;\n}\nconst createImpl = (createState) => {\n  if (( false ? 0 : void 0) !== \"production\" && typeof createState !== \"function\") {\n    console.warn(\n      \"[DEPRECATED] Passing a vanilla store will be unsupported in a future version. Instead use `import { useStore } from 'zustand'`.\"\n    );\n  }\n  const api = typeof createState === \"function\" ? (0,zustand_vanilla__WEBPACK_IMPORTED_MODULE_0__.createStore)(createState) : createState;\n  const useBoundStore = (selector, equalityFn) => useStore(api, selector, equalityFn);\n  Object.assign(useBoundStore, api);\n  return useBoundStore;\n};\nconst create = (createState) => createState ? createImpl(createState) : createImpl;\nvar react = (createState) => {\n  if (( false ? 0 : void 0) !== \"production\") {\n    console.warn(\n      \"[DEPRECATED] Default export is deprecated. Instead use `import { create } from 'zustand'`.\"\n    );\n  }\n  return create(createState);\n};\n\n\n\n\n//# sourceURL=webpack://renderer/./node_modules/zustand/esm/index.mjs?");

/***/ }),

/***/ "./node_modules/zustand/esm/vanilla.mjs":
/*!**********************************************!*\
  !*** ./node_modules/zustand/esm/vanilla.mjs ***!
  \**********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   createStore: () => (/* binding */ createStore),\n/* harmony export */   \"default\": () => (/* binding */ vanilla)\n/* harmony export */ });\nconst createStoreImpl = (createState) => {\n  let state;\n  const listeners = /* @__PURE__ */ new Set();\n  const setState = (partial, replace) => {\n    const nextState = typeof partial === \"function\" ? partial(state) : partial;\n    if (!Object.is(nextState, state)) {\n      const previousState = state;\n      state = (replace != null ? replace : typeof nextState !== \"object\" || nextState === null) ? nextState : Object.assign({}, state, nextState);\n      listeners.forEach((listener) => listener(state, previousState));\n    }\n  };\n  const getState = () => state;\n  const subscribe = (listener) => {\n    listeners.add(listener);\n    return () => listeners.delete(listener);\n  };\n  const destroy = () => {\n    if (( false ? 0 : void 0) !== \"production\") {\n      console.warn(\n        \"[DEPRECATED] The `destroy` method will be unsupported in a future version. Instead use unsubscribe function returned by subscribe. Everything will be garbage-collected if store is garbage-collected.\"\n      );\n    }\n    listeners.clear();\n  };\n  const api = { setState, getState, subscribe, destroy };\n  state = createState(setState, getState, api);\n  return api;\n};\nconst createStore = (createState) => createState ? createStoreImpl(createState) : createStoreImpl;\nvar vanilla = (createState) => {\n  if (( false ? 0 : void 0) !== \"production\") {\n    console.warn(\n      \"[DEPRECATED] Default export is deprecated. Instead use import { createStore } from 'zustand/vanilla'.\"\n    );\n  }\n  return createStore(createState);\n};\n\n\n\n\n//# sourceURL=webpack://renderer/./node_modules/zustand/esm/vanilla.mjs?");

/***/ }),

/***/ "./node_modules/mongodb-connection-string-url/node_modules/tr46/lib/mappingTable.json":
/*!********************************************************************************************!*\
  !*** ./node_modules/mongodb-connection-string-url/node_modules/tr46/lib/mappingTable.json ***!
  \********************************************************************************************/
/***/ ((module) => {

"use strict";
eval("module.exports = JSON.parse('[[[0,44],4],[[45,46],2],[47,4],[[48,57],2],[[58,64],4],[65,1,\"a\"],[66,1,\"b\"],[67,1,\"c\"],[68,1,\"d\"],[69,1,\"e\"],[70,1,\"f\"],[71,1,\"g\"],[72,1,\"h\"],[73,1,\"i\"],[74,1,\"j\"],[75,1,\"k\"],[76,1,\"l\"],[77,1,\"m\"],[78,1,\"n\"],[79,1,\"o\"],[80,1,\"p\"],[81,1,\"q\"],[82,1,\"r\"],[83,1,\"s\"],[84,1,\"t\"],[85,1,\"u\"],[86,1,\"v\"],[87,1,\"w\"],[88,1,\"x\"],[89,1,\"y\"],[90,1,\"z\"],[[91,96],4],[[97,122],2],[[123,127],4],[[128,159],3],[160,5,\" \"],[[161,167],2],[168,5,\" \"],[169,2],[170,1,\"a\"],[[171,172],2],[173,7],[174,2],[175,5,\" \"],[[176,177],2],[178,1,\"2\"],[179,1,\"3\"],[180,5,\" \"],[181,1,\"\"],[182,2],[183,2],[184,5,\" \"],[185,1,\"1\"],[186,1,\"o\"],[187,2],[188,1,\"14\"],[189,1,\"12\"],[190,1,\"34\"],[191,2],[192,1,\"\"],[193,1,\"\"],[194,1,\"\"],[195,1,\"\"],[196,1,\"\"],[197,1,\"\"],[198,1,\"\"],[199,1,\"\"],[200,1,\"\"],[201,1,\"\"],[202,1,\"\"],[203,1,\"\"],[204,1,\"\"],[205,1,\"\"],[206,1,\"\"],[207,1,\"\"],[208,1,\"\"],[209,1,\"\"],[210,1,\"\"],[211,1,\"\"],[212,1,\"\"],[213,1,\"\"],[214,1,\"\"],[215,2],[216,1,\"\"],[217,1,\"\"],[218,1,\"\"],[219,1,\"\"],[220,1,\"\"],[221,1,\"\"],[222,1,\"\"],[223,6,\"ss\"],[[224,246],2],[247,2],[[248,255],2],[256,1,\"\"],[257,2],[258,1,\"\"],[259,2],[260,1,\"\"],[261,2],[262,1,\"\"],[263,2],[264,1,\"\"],[265,2],[266,1,\"\"],[267,2],[268,1,\"\"],[269,2],[270,1,\"\"],[271,2],[272,1,\"\"],[273,2],[274,1,\"\"],[275,2],[276,1,\"\"],[277,2],[278,1,\"\"],[279,2],[280,1,\"\"],[281,2],[282,1,\"\"],[283,2],[284,1,\"\"],[285,2],[286,1,\"\"],[287,2],[288,1,\"\"],[289,2],[290,1,\"\"],[291,2],[292,1,\"\"],[293,2],[294,1,\"\"],[295,2],[296,1,\"\"],[297,2],[298,1,\"\"],[299,2],[300,1,\"\"],[301,2],[302,1,\"\"],[303,2],[304,1,\"i\"],[305,2],[[306,307],1,\"ij\"],[308,1,\"\"],[309,2],[310,1,\"\"],[[311,312],2],[313,1,\"\"],[314,2],[315,1,\"\"],[316,2],[317,1,\"\"],[318,2],[[319,320],1,\"l\"],[321,1,\"\"],[322,2],[323,1,\"\"],[324,2],[325,1,\"\"],[326,2],[327,1,\"\"],[328,2],[329,1,\"n\"],[330,1,\"\"],[331,2],[332,1,\"\"],[333,2],[334,1,\"\"],[335,2],[336,1,\"\"],[337,2],[338,1,\"\"],[339,2],[340,1,\"\"],[341,2],[342,1,\"\"],[343,2],[344,1,\"\"],[345,2],[346,1,\"\"],[347,2],[348,1,\"\"],[349,2],[350,1,\"\"],[351,2],[352,1,\"\"],[353,2],[354,1,\"\"],[355,2],[356,1,\"\"],[357,2],[358,1,\"\"],[359,2],[360,1,\"\"],[361,2],[362,1,\"\"],[363,2],[364,1,\"\"],[365,2],[366,1,\"\"],[367,2],[368,1,\"\"],[369,2],[370,1,\"\"],[371,2],[372,1,\"\"],[373,2],[374,1,\"\"],[375,2],[376,1,\"\"],[377,1,\"\"],[378,2],[379,1,\"\"],[380,2],[381,1,\"\"],[382,2],[383,1,\"s\"],[384,2],[385,1,\"\"],[386,1,\"\"],[387,2],[388,1,\"\"],[389,2],[390,1,\"\"],[391,1,\"\"],[392,2],[393,1,\"\"],[394,1,\"\"],[395,1,\"\"],[[396,397],2],[398,1,\"\"],[399,1,\"\"],[400,1,\"\"],[401,1,\"\"],[402,2],[403,1,\"\"],[404,1,\"\"],[405,2],[406,1,\"\"],[407,1,\"\"],[408,1,\"\"],[[409,411],2],[412,1,\"\"],[413,1,\"\"],[414,2],[415,1,\"\"],[416,1,\"\"],[417,2],[418,1,\"\"],[419,2],[420,1,\"\"],[421,2],[422,1,\"\"],[423,1,\"\"],[424,2],[425,1,\"\"],[[426,427],2],[428,1,\"\"],[429,2],[430,1,\"\"],[431,1,\"\"],[432,2],[433,1,\"\"],[434,1,\"\"],[435,1,\"\"],[436,2],[437,1,\"\"],[438,2],[439,1,\"\"],[440,1,\"\"],[[441,443],2],[444,1,\"\"],[[445,451],2],[[452,454],1,\"d\"],[[455,457],1,\"lj\"],[[458,460],1,\"nj\"],[461,1,\"\"],[462,2],[463,1,\"\"],[464,2],[465,1,\"\"],[466,2],[467,1,\"\"],[468,2],[469,1,\"\"],[470,2],[471,1,\"\"],[472,2],[473,1,\"\"],[474,2],[475,1,\"\"],[[476,477],2],[478,1,\"\"],[479,2],[480,1,\"\"],[481,2],[482,1,\"\"],[483,2],[484,1,\"\"],[485,2],[486,1,\"\"],[487,2],[488,1,\"\"],[489,2],[490,1,\"\"],[491,2],[492,1,\"\"],[493,2],[494,1,\"\"],[[495,496],2],[[497,499],1,\"dz\"],[500,1,\"\"],[501,2],[502,1,\"\"],[503,1,\"\"],[504,1,\"\"],[505,2],[506,1,\"\"],[507,2],[508,1,\"\"],[509,2],[510,1,\"\"],[511,2],[512,1,\"\"],[513,2],[514,1,\"\"],[515,2],[516,1,\"\"],[517,2],[518,1,\"\"],[519,2],[520,1,\"\"],[521,2],[522,1,\"\"],[523,2],[524,1,\"\"],[525,2],[526,1,\"\"],[527,2],[528,1,\"\"],[529,2],[530,1,\"\"],[531,2],[532,1,\"\"],[533,2],[534,1,\"\"],[535,2],[536,1,\"\"],[537,2],[538,1,\"\"],[539,2],[540,1,\"\"],[541,2],[542,1,\"\"],[543,2],[544,1,\"\"],[545,2],[546,1,\"\"],[547,2],[548,1,\"\"],[549,2],[550,1,\"\"],[551,2],[552,1,\"\"],[553,2],[554,1,\"\"],[555,2],[556,1,\"\"],[557,2],[558,1,\"\"],[559,2],[560,1,\"\"],[561,2],[562,1,\"\"],[563,2],[[564,566],2],[[567,569],2],[570,1,\"\"],[571,1,\"\"],[572,2],[573,1,\"\"],[574,1,\"\"],[[575,576],2],[577,1,\"\"],[578,2],[579,1,\"\"],[580,1,\"\"],[581,1,\"\"],[582,1,\"\"],[583,2],[584,1,\"\"],[585,2],[586,1,\"\"],[587,2],[588,1,\"\"],[589,2],[590,1,\"\"],[591,2],[[592,680],2],[[681,685],2],[[686,687],2],[688,1,\"h\"],[689,1,\"\"],[690,1,\"j\"],[691,1,\"r\"],[692,1,\"\"],[693,1,\"\"],[694,1,\"\"],[695,1,\"w\"],[696,1,\"y\"],[[697,705],2],[[706,709],2],[[710,721],2],[[722,727],2],[728,5,\" \"],[729,5,\" \"],[730,5,\" \"],[731,5,\" \"],[732,5,\" \"],[733,5,\" \"],[734,2],[735,2],[736,1,\"\"],[737,1,\"l\"],[738,1,\"s\"],[739,1,\"x\"],[740,1,\"\"],[[741,745],2],[[746,747],2],[748,2],[749,2],[750,2],[[751,767],2],[[768,831],2],[832,1,\"\"],[833,1,\"\"],[834,2],[835,1,\"\"],[836,1,\"\"],[837,1,\"\"],[[838,846],2],[847,7],[[848,855],2],[[856,860],2],[[861,863],2],[[864,865],2],[866,2],[[867,879],2],[880,1,\"\"],[881,2],[882,1,\"\"],[883,2],[884,1,\"\"],[885,2],[886,1,\"\"],[887,2],[[888,889],3],[890,5,\" \"],[[891,893],2],[894,5,\";\"],[895,1,\"\"],[[896,899],3],[900,5,\" \"],[901,5,\" \"],[902,1,\"\"],[903,1,\"\"],[904,1,\"\"],[905,1,\"\"],[906,1,\"\"],[907,3],[908,1,\"\"],[909,3],[910,1,\"\"],[911,1,\"\"],[912,2],[913,1,\"\"],[914,1,\"\"],[915,1,\"\"],[916,1,\"\"],[917,1,\"\"],[918,1,\"\"],[919,1,\"\"],[920,1,\"\"],[921,1,\"\"],[922,1,\"\"],[923,1,\"\"],[924,1,\"\"],[925,1,\"\"],[926,1,\"\"],[927,1,\"\"],[928,1,\"\"],[929,1,\"\"],[930,3],[931,1,\"\"],[932,1,\"\"],[933,1,\"\"],[934,1,\"\"],[935,1,\"\"],[936,1,\"\"],[937,1,\"\"],[938,1,\"\"],[939,1,\"\"],[[940,961],2],[962,6,\"\"],[[963,974],2],[975,1,\"\"],[976,1,\"\"],[977,1,\"\"],[978,1,\"\"],[979,1,\"\"],[980,1,\"\"],[981,1,\"\"],[982,1,\"\"],[983,2],[984,1,\"\"],[985,2],[986,1,\"\"],[987,2],[988,1,\"\"],[989,2],[990,1,\"\"],[991,2],[992,1,\"\"],[993,2],[994,1,\"\"],[995,2],[996,1,\"\"],[997,2],[998,1,\"\"],[999,2],[1000,1,\"\"],[1001,2],[1002,1,\"\"],[1003,2],[1004,1,\"\"],[1005,2],[1006,1,\"\"],[1007,2],[1008,1,\"\"],[1009,1,\"\"],[1010,1,\"\"],[1011,2],[1012,1,\"\"],[1013,1,\"\"],[1014,2],[1015,1,\"\"],[1016,2],[1017,1,\"\"],[1018,1,\"\"],[1019,2],[1020,2],[1021,1,\"\"],[1022,1,\"\"],[1023,1,\"\"],[1024,1,\"\"],[1025,1,\"\"],[1026,1,\"\"],[1027,1,\"\"],[1028,1,\"\"],[1029,1,\"\"],[1030,1,\"\"],[1031,1,\"\"],[1032,1,\"\"],[1033,1,\"\"],[1034,1,\"\"],[1035,1,\"\"],[1036,1,\"\"],[1037,1,\"\"],[1038,1,\"\"],[1039,1,\"\"],[1040,1,\"\"],[1041,1,\"\"],[1042,1,\"\"],[1043,1,\"\"],[1044,1,\"\"],[1045,1,\"\"],[1046,1,\"\"],[1047,1,\"\"],[1048,1,\"\"],[1049,1,\"\"],[1050,1,\"\"],[1051,1,\"\"],[1052,1,\"\"],[1053,1,\"\"],[1054,1,\"\"],[1055,1,\"\"],[1056,1,\"\"],[1057,1,\"\"],[1058,1,\"\"],[1059,1,\"\"],[1060,1,\"\"],[1061,1,\"\"],[1062,1,\"\"],[1063,1,\"\"],[1064,1,\"\"],[1065,1,\"\"],[1066,1,\"\"],[1067,1,\"\"],[1068,1,\"\"],[1069,1,\"\"],[1070,1,\"\"],[1071,1,\"\"],[[1072,1103],2],[1104,2],[[1105,1116],2],[1117,2],[[1118,1119],2],[1120,1,\"\"],[1121,2],[1122,1,\"\"],[1123,2],[1124,1,\"\"],[1125,2],[1126,1,\"\"],[1127,2],[1128,1,\"\"],[1129,2],[1130,1,\"\"],[1131,2],[1132,1,\"\"],[1133,2],[1134,1,\"\"],[1135,2],[1136,1,\"\"],[1137,2],[1138,1,\"\"],[1139,2],[1140,1,\"\"],[1141,2],[1142,1,\"\"],[1143,2],[1144,1,\"\"],[1145,2],[1146,1,\"\"],[1147,2],[1148,1,\"\"],[1149,2],[1150,1,\"\"],[1151,2],[1152,1,\"\"],[1153,2],[1154,2],[[1155,1158],2],[1159,2],[[1160,1161],2],[1162,1,\"\"],[1163,2],[1164,1,\"\"],[1165,2],[1166,1,\"\"],[1167,2],[1168,1,\"\"],[1169,2],[1170,1,\"\"],[1171,2],[1172,1,\"\"],[1173,2],[1174,1,\"\"],[1175,2],[1176,1,\"\"],[1177,2],[1178,1,\"\"],[1179,2],[1180,1,\"\"],[1181,2],[1182,1,\"\"],[1183,2],[1184,1,\"\"],[1185,2],[1186,1,\"\"],[1187,2],[1188,1,\"\"],[1189,2],[1190,1,\"\"],[1191,2],[1192,1,\"\"],[1193,2],[1194,1,\"\"],[1195,2],[1196,1,\"\"],[1197,2],[1198,1,\"\"],[1199,2],[1200,1,\"\"],[1201,2],[1202,1,\"\"],[1203,2],[1204,1,\"\"],[1205,2],[1206,1,\"\"],[1207,2],[1208,1,\"\"],[1209,2],[1210,1,\"\"],[1211,2],[1212,1,\"\"],[1213,2],[1214,1,\"\"],[1215,2],[1216,3],[1217,1,\"\"],[1218,2],[1219,1,\"\"],[1220,2],[1221,1,\"\"],[1222,2],[1223,1,\"\"],[1224,2],[1225,1,\"\"],[1226,2],[1227,1,\"\"],[1228,2],[1229,1,\"\"],[1230,2],[1231,2],[1232,1,\"\"],[1233,2],[1234,1,\"\"],[1235,2],[1236,1,\"\"],[1237,2],[1238,1,\"\"],[1239,2],[1240,1,\"\"],[1241,2],[1242,1,\"\"],[1243,2],[1244,1,\"\"],[1245,2],[1246,1,\"\"],[1247,2],[1248,1,\"\"],[1249,2],[1250,1,\"\"],[1251,2],[1252,1,\"\"],[1253,2],[1254,1,\"\"],[1255,2],[1256,1,\"\"],[1257,2],[1258,1,\"\"],[1259,2],[1260,1,\"\"],[1261,2],[1262,1,\"\"],[1263,2],[1264,1,\"\"],[1265,2],[1266,1,\"\"],[1267,2],[1268,1,\"\"],[1269,2],[1270,1,\"\"],[1271,2],[1272,1,\"\"],[1273,2],[1274,1,\"\"],[1275,2],[1276,1,\"\"],[1277,2],[1278,1,\"\"],[1279,2],[1280,1,\"\"],[1281,2],[1282,1,\"\"],[1283,2],[1284,1,\"\"],[1285,2],[1286,1,\"\"],[1287,2],[1288,1,\"\"],[1289,2],[1290,1,\"\"],[1291,2],[1292,1,\"\"],[1293,2],[1294,1,\"\"],[1295,2],[1296,1,\"\"],[1297,2],[1298,1,\"\"],[1299,2],[1300,1,\"\"],[1301,2],[1302,1,\"\"],[1303,2],[1304,1,\"\"],[1305,2],[1306,1,\"\"],[1307,2],[1308,1,\"\"],[1309,2],[1310,1,\"\"],[1311,2],[1312,1,\"\"],[1313,2],[1314,1,\"\"],[1315,2],[1316,1,\"\"],[1317,2],[1318,1,\"\"],[1319,2],[1320,1,\"\"],[1321,2],[1322,1,\"\"],[1323,2],[1324,1,\"\"],[1325,2],[1326,1,\"\"],[1327,2],[1328,3],[1329,1,\"\"],[1330,1,\"\"],[1331,1,\"\"],[1332,1,\"\"],[1333,1,\"\"],[1334,1,\"\"],[1335,1,\"\"],[1336,1,\"\"],[1337,1,\"\"],[1338,1,\"\"],[1339,1,\"\"],[1340,1,\"\"],[1341,1,\"\"],[1342,1,\"\"],[1343,1,\"\"],[1344,1,\"\"],[1345,1,\"\"],[1346,1,\"\"],[1347,1,\"\"],[1348,1,\"\"],[1349,1,\"\"],[1350,1,\"\"],[1351,1,\"\"],[1352,1,\"\"],[1353,1,\"\"],[1354,1,\"\"],[1355,1,\"\"],[1356,1,\"\"],[1357,1,\"\"],[1358,1,\"\"],[1359,1,\"\"],[1360,1,\"\"],[1361,1,\"\"],[1362,1,\"\"],[1363,1,\"\"],[1364,1,\"\"],[1365,1,\"\"],[1366,1,\"\"],[[1367,1368],3],[1369,2],[[1370,1375],2],[1376,2],[[1377,1414],2],[1415,1,\"\"],[1416,2],[1417,2],[1418,2],[[1419,1420],3],[[1421,1422],2],[1423,2],[1424,3],[[1425,1441],2],[1442,2],[[1443,1455],2],[[1456,1465],2],[1466,2],[[1467,1469],2],[1470,2],[1471,2],[1472,2],[[1473,1474],2],[1475,2],[1476,2],[1477,2],[1478,2],[1479,2],[[1480,1487],3],[[1488,1514],2],[[1515,1518],3],[1519,2],[[1520,1524],2],[[1525,1535],3],[[1536,1539],3],[1540,3],[1541,3],[[1542,1546],2],[1547,2],[1548,2],[[1549,1551],2],[[1552,1557],2],[[1558,1562],2],[1563,2],[1564,3],[1565,2],[1566,2],[1567,2],[1568,2],[[1569,1594],2],[[1595,1599],2],[1600,2],[[1601,1618],2],[[1619,1621],2],[[1622,1624],2],[[1625,1630],2],[1631,2],[[1632,1641],2],[[1642,1645],2],[[1646,1647],2],[[1648,1652],2],[1653,1,\"\"],[1654,1,\"\"],[1655,1,\"\"],[1656,1,\"\"],[[1657,1719],2],[[1720,1721],2],[[1722,1726],2],[1727,2],[[1728,1742],2],[1743,2],[[1744,1747],2],[1748,2],[[1749,1756],2],[1757,3],[1758,2],[[1759,1768],2],[1769,2],[[1770,1773],2],[[1774,1775],2],[[1776,1785],2],[[1786,1790],2],[1791,2],[[1792,1805],2],[1806,3],[1807,3],[[1808,1836],2],[[1837,1839],2],[[1840,1866],2],[[1867,1868],3],[[1869,1871],2],[[1872,1901],2],[[1902,1919],2],[[1920,1968],2],[1969,2],[[1970,1983],3],[[1984,2037],2],[[2038,2042],2],[[2043,2044],3],[2045,2],[[2046,2047],2],[[2048,2093],2],[[2094,2095],3],[[2096,2110],2],[2111,3],[[2112,2139],2],[[2140,2141],3],[2142,2],[2143,3],[[2144,2154],2],[[2155,2159],3],[[2160,2183],2],[2184,2],[[2185,2190],2],[2191,3],[[2192,2193],3],[[2194,2199],3],[[2200,2207],2],[2208,2],[2209,2],[[2210,2220],2],[[2221,2226],2],[[2227,2228],2],[2229,2],[[2230,2237],2],[[2238,2247],2],[[2248,2258],2],[2259,2],[[2260,2273],2],[2274,3],[2275,2],[[2276,2302],2],[2303,2],[2304,2],[[2305,2307],2],[2308,2],[[2309,2361],2],[[2362,2363],2],[[2364,2381],2],[2382,2],[2383,2],[[2384,2388],2],[2389,2],[[2390,2391],2],[2392,1,\"\"],[2393,1,\"\"],[2394,1,\"\"],[2395,1,\"\"],[2396,1,\"\"],[2397,1,\"\"],[2398,1,\"\"],[2399,1,\"\"],[[2400,2403],2],[[2404,2405],2],[[2406,2415],2],[2416,2],[[2417,2418],2],[[2419,2423],2],[2424,2],[[2425,2426],2],[[2427,2428],2],[2429,2],[[2430,2431],2],[2432,2],[[2433,2435],2],[2436,3],[[2437,2444],2],[[2445,2446],3],[[2447,2448],2],[[2449,2450],3],[[2451,2472],2],[2473,3],[[2474,2480],2],[2481,3],[2482,2],[[2483,2485],3],[[2486,2489],2],[[2490,2491],3],[2492,2],[2493,2],[[2494,2500],2],[[2501,2502],3],[[2503,2504],2],[[2505,2506],3],[[2507,2509],2],[2510,2],[[2511,2518],3],[2519,2],[[2520,2523],3],[2524,1,\"\"],[2525,1,\"\"],[2526,3],[2527,1,\"\"],[[2528,2531],2],[[2532,2533],3],[[2534,2545],2],[[2546,2554],2],[2555,2],[2556,2],[2557,2],[2558,2],[[2559,2560],3],[2561,2],[2562,2],[2563,2],[2564,3],[[2565,2570],2],[[2571,2574],3],[[2575,2576],2],[[2577,2578],3],[[2579,2600],2],[2601,3],[[2602,2608],2],[2609,3],[2610,2],[2611,1,\"\"],[2612,3],[2613,2],[2614,1,\"\"],[2615,3],[[2616,2617],2],[[2618,2619],3],[2620,2],[2621,3],[[2622,2626],2],[[2627,2630],3],[[2631,2632],2],[[2633,2634],3],[[2635,2637],2],[[2638,2640],3],[2641,2],[[2642,2648],3],[2649,1,\"\"],[2650,1,\"\"],[2651,1,\"\"],[2652,2],[2653,3],[2654,1,\"\"],[[2655,2661],3],[[2662,2676],2],[2677,2],[2678,2],[[2679,2688],3],[[2689,2691],2],[2692,3],[[2693,2699],2],[2700,2],[2701,2],[2702,3],[[2703,2705],2],[2706,3],[[2707,2728],2],[2729,3],[[2730,2736],2],[2737,3],[[2738,2739],2],[2740,3],[[2741,2745],2],[[2746,2747],3],[[2748,2757],2],[2758,3],[[2759,2761],2],[2762,3],[[2763,2765],2],[[2766,2767],3],[2768,2],[[2769,2783],3],[2784,2],[[2785,2787],2],[[2788,2789],3],[[2790,2799],2],[2800,2],[2801,2],[[2802,2808],3],[2809,2],[[2810,2815],2],[2816,3],[[2817,2819],2],[2820,3],[[2821,2828],2],[[2829,2830],3],[[2831,2832],2],[[2833,2834],3],[[2835,2856],2],[2857,3],[[2858,2864],2],[2865,3],[[2866,2867],2],[2868,3],[2869,2],[[2870,2873],2],[[2874,2875],3],[[2876,2883],2],[2884,2],[[2885,2886],3],[[2887,2888],2],[[2889,2890],3],[[2891,2893],2],[[2894,2900],3],[2901,2],[[2902,2903],2],[[2904,2907],3],[2908,1,\"\"],[2909,1,\"\"],[2910,3],[[2911,2913],2],[[2914,2915],2],[[2916,2917],3],[[2918,2927],2],[2928,2],[2929,2],[[2930,2935],2],[[2936,2945],3],[[2946,2947],2],[2948,3],[[2949,2954],2],[[2955,2957],3],[[2958,2960],2],[2961,3],[[2962,2965],2],[[2966,2968],3],[[2969,2970],2],[2971,3],[2972,2],[2973,3],[[2974,2975],2],[[2976,2978],3],[[2979,2980],2],[[2981,2983],3],[[2984,2986],2],[[2987,2989],3],[[2990,2997],2],[2998,2],[[2999,3001],2],[[3002,3005],3],[[3006,3010],2],[[3011,3013],3],[[3014,3016],2],[3017,3],[[3018,3021],2],[[3022,3023],3],[3024,2],[[3025,3030],3],[3031,2],[[3032,3045],3],[3046,2],[[3047,3055],2],[[3056,3058],2],[[3059,3066],2],[[3067,3071],3],[3072,2],[[3073,3075],2],[3076,2],[[3077,3084],2],[3085,3],[[3086,3088],2],[3089,3],[[3090,3112],2],[3113,3],[[3114,3123],2],[3124,2],[[3125,3129],2],[[3130,3131],3],[3132,2],[3133,2],[[3134,3140],2],[3141,3],[[3142,3144],2],[3145,3],[[3146,3149],2],[[3150,3156],3],[[3157,3158],2],[3159,3],[[3160,3161],2],[3162,2],[[3163,3164],3],[3165,2],[[3166,3167],3],[[3168,3169],2],[[3170,3171],2],[[3172,3173],3],[[3174,3183],2],[[3184,3190],3],[3191,2],[[3192,3199],2],[3200,2],[3201,2],[[3202,3203],2],[3204,2],[[3205,3212],2],[3213,3],[[3214,3216],2],[3217,3],[[3218,3240],2],[3241,3],[[3242,3251],2],[3252,3],[[3253,3257],2],[[3258,3259],3],[[3260,3261],2],[[3262,3268],2],[3269,3],[[3270,3272],2],[3273,3],[[3274,3277],2],[[3278,3284],3],[[3285,3286],2],[[3287,3292],3],[3293,2],[3294,2],[3295,3],[[3296,3297],2],[[3298,3299],2],[[3300,3301],3],[[3302,3311],2],[3312,3],[[3313,3314],2],[3315,2],[[3316,3327],3],[3328,2],[3329,2],[[3330,3331],2],[3332,2],[[3333,3340],2],[3341,3],[[3342,3344],2],[3345,3],[[3346,3368],2],[3369,2],[[3370,3385],2],[3386,2],[[3387,3388],2],[3389,2],[[3390,3395],2],[3396,2],[3397,3],[[3398,3400],2],[3401,3],[[3402,3405],2],[3406,2],[3407,2],[[3408,3411],3],[[3412,3414],2],[3415,2],[[3416,3422],2],[3423,2],[[3424,3425],2],[[3426,3427],2],[[3428,3429],3],[[3430,3439],2],[[3440,3445],2],[[3446,3448],2],[3449,2],[[3450,3455],2],[3456,3],[3457,2],[[3458,3459],2],[3460,3],[[3461,3478],2],[[3479,3481],3],[[3482,3505],2],[3506,3],[[3507,3515],2],[3516,3],[3517,2],[[3518,3519],3],[[3520,3526],2],[[3527,3529],3],[3530,2],[[3531,3534],3],[[3535,3540],2],[3541,3],[3542,2],[3543,3],[[3544,3551],2],[[3552,3557],3],[[3558,3567],2],[[3568,3569],3],[[3570,3571],2],[3572,2],[[3573,3584],3],[[3585,3634],2],[3635,1,\"\"],[[3636,3642],2],[[3643,3646],3],[3647,2],[[3648,3662],2],[3663,2],[[3664,3673],2],[[3674,3675],2],[[3676,3712],3],[[3713,3714],2],[3715,3],[3716,2],[3717,3],[3718,2],[[3719,3720],2],[3721,2],[3722,2],[3723,3],[3724,2],[3725,2],[[3726,3731],2],[[3732,3735],2],[3736,2],[[3737,3743],2],[3744,2],[[3745,3747],2],[3748,3],[3749,2],[3750,3],[3751,2],[[3752,3753],2],[[3754,3755],2],[3756,2],[[3757,3762],2],[3763,1,\"\"],[[3764,3769],2],[3770,2],[[3771,3773],2],[[3774,3775],3],[[3776,3780],2],[3781,3],[3782,2],[3783,3],[[3784,3789],2],[3790,2],[3791,3],[[3792,3801],2],[[3802,3803],3],[3804,1,\"\"],[3805,1,\"\"],[[3806,3807],2],[[3808,3839],3],[3840,2],[[3841,3850],2],[3851,2],[3852,1,\"\"],[[3853,3863],2],[[3864,3865],2],[[3866,3871],2],[[3872,3881],2],[[3882,3892],2],[3893,2],[3894,2],[3895,2],[3896,2],[3897,2],[[3898,3901],2],[[3902,3906],2],[3907,1,\"\"],[[3908,3911],2],[3912,3],[[3913,3916],2],[3917,1,\"\"],[[3918,3921],2],[3922,1,\"\"],[[3923,3926],2],[3927,1,\"\"],[[3928,3931],2],[3932,1,\"\"],[[3933,3944],2],[3945,1,\"\"],[3946,2],[[3947,3948],2],[[3949,3952],3],[[3953,3954],2],[3955,1,\"\"],[3956,2],[3957,1,\"\"],[3958,1,\"\"],[3959,1,\"\"],[3960,1,\"\"],[3961,1,\"\"],[[3962,3968],2],[3969,1,\"\"],[[3970,3972],2],[3973,2],[[3974,3979],2],[[3980,3983],2],[[3984,3986],2],[3987,1,\"\"],[[3988,3989],2],[3990,2],[3991,2],[3992,3],[[3993,3996],2],[3997,1,\"\"],[[3998,4001],2],[4002,1,\"\"],[[4003,4006],2],[4007,1,\"\"],[[4008,4011],2],[4012,1,\"\"],[4013,2],[[4014,4016],2],[[4017,4023],2],[4024,2],[4025,1,\"\"],[[4026,4028],2],[4029,3],[[4030,4037],2],[4038,2],[[4039,4044],2],[4045,3],[4046,2],[4047,2],[[4048,4049],2],[[4050,4052],2],[[4053,4056],2],[[4057,4058],2],[[4059,4095],3],[[4096,4129],2],[4130,2],[[4131,4135],2],[4136,2],[[4137,4138],2],[4139,2],[[4140,4146],2],[[4147,4149],2],[[4150,4153],2],[[4154,4159],2],[[4160,4169],2],[[4170,4175],2],[[4176,4185],2],[[4186,4249],2],[[4250,4253],2],[[4254,4255],2],[[4256,4293],3],[4294,3],[4295,1,\"\"],[[4296,4300],3],[4301,1,\"\"],[[4302,4303],3],[[4304,4342],2],[[4343,4344],2],[[4345,4346],2],[4347,2],[4348,1,\"\"],[[4349,4351],2],[[4352,4441],2],[[4442,4446],2],[[4447,4448],3],[[4449,4514],2],[[4515,4519],2],[[4520,4601],2],[[4602,4607],2],[[4608,4614],2],[4615,2],[[4616,4678],2],[4679,2],[4680,2],[4681,3],[[4682,4685],2],[[4686,4687],3],[[4688,4694],2],[4695,3],[4696,2],[4697,3],[[4698,4701],2],[[4702,4703],3],[[4704,4742],2],[4743,2],[4744,2],[4745,3],[[4746,4749],2],[[4750,4751],3],[[4752,4782],2],[4783,2],[4784,2],[4785,3],[[4786,4789],2],[[4790,4791],3],[[4792,4798],2],[4799,3],[4800,2],[4801,3],[[4802,4805],2],[[4806,4807],3],[[4808,4814],2],[4815,2],[[4816,4822],2],[4823,3],[[4824,4846],2],[4847,2],[[4848,4878],2],[4879,2],[4880,2],[4881,3],[[4882,4885],2],[[4886,4887],3],[[4888,4894],2],[4895,2],[[4896,4934],2],[4935,2],[[4936,4954],2],[[4955,4956],3],[[4957,4958],2],[4959,2],[4960,2],[[4961,4988],2],[[4989,4991],3],[[4992,5007],2],[[5008,5017],2],[[5018,5023],3],[[5024,5108],2],[5109,2],[[5110,5111],3],[5112,1,\"\"],[5113,1,\"\"],[5114,1,\"\"],[5115,1,\"\"],[5116,1,\"\"],[5117,1,\"\"],[[5118,5119],3],[5120,2],[[5121,5740],2],[[5741,5742],2],[[5743,5750],2],[[5751,5759],2],[5760,3],[[5761,5786],2],[[5787,5788],2],[[5789,5791],3],[[5792,5866],2],[[5867,5872],2],[[5873,5880],2],[[5881,5887],3],[[5888,5900],2],[5901,2],[[5902,5908],2],[5909,2],[[5910,5918],3],[5919,2],[[5920,5940],2],[[5941,5942],2],[[5943,5951],3],[[5952,5971],2],[[5972,5983],3],[[5984,5996],2],[5997,3],[[5998,6000],2],[6001,3],[[6002,6003],2],[[6004,6015],3],[[6016,6067],2],[[6068,6069],3],[[6070,6099],2],[[6100,6102],2],[6103,2],[[6104,6107],2],[6108,2],[6109,2],[[6110,6111],3],[[6112,6121],2],[[6122,6127],3],[[6128,6137],2],[[6138,6143],3],[[6144,6149],2],[6150,3],[[6151,6154],2],[[6155,6157],7],[6158,3],[6159,7],[[6160,6169],2],[[6170,6175],3],[[6176,6263],2],[6264,2],[[6265,6271],3],[[6272,6313],2],[6314,2],[[6315,6319],3],[[6320,6389],2],[[6390,6399],3],[[6400,6428],2],[[6429,6430],2],[6431,3],[[6432,6443],2],[[6444,6447],3],[[6448,6459],2],[[6460,6463],3],[6464,2],[[6465,6467],3],[[6468,6469],2],[[6470,6509],2],[[6510,6511],3],[[6512,6516],2],[[6517,6527],3],[[6528,6569],2],[[6570,6571],2],[[6572,6575],3],[[6576,6601],2],[[6602,6607],3],[[6608,6617],2],[6618,2],[[6619,6621],3],[[6622,6623],2],[[6624,6655],2],[[6656,6683],2],[[6684,6685],3],[[6686,6687],2],[[6688,6750],2],[6751,3],[[6752,6780],2],[[6781,6782],3],[[6783,6793],2],[[6794,6799],3],[[6800,6809],2],[[6810,6815],3],[[6816,6822],2],[6823,2],[[6824,6829],2],[[6830,6831],3],[[6832,6845],2],[6846,2],[[6847,6848],2],[[6849,6862],2],[[6863,6911],3],[[6912,6987],2],[6988,2],[[6989,6991],3],[[6992,7001],2],[[7002,7018],2],[[7019,7027],2],[[7028,7036],2],[[7037,7038],2],[7039,3],[[7040,7082],2],[[7083,7085],2],[[7086,7097],2],[[7098,7103],2],[[7104,7155],2],[[7156,7163],3],[[7164,7167],2],[[7168,7223],2],[[7224,7226],3],[[7227,7231],2],[[7232,7241],2],[[7242,7244],3],[[7245,7293],2],[[7294,7295],2],[7296,1,\"\"],[7297,1,\"\"],[7298,1,\"\"],[7299,1,\"\"],[[7300,7301],1,\"\"],[7302,1,\"\"],[7303,1,\"\"],[7304,1,\"\"],[[7305,7311],3],[7312,1,\"\"],[7313,1,\"\"],[7314,1,\"\"],[7315,1,\"\"],[7316,1,\"\"],[7317,1,\"\"],[7318,1,\"\"],[7319,1,\"\"],[7320,1,\"\"],[7321,1,\"\"],[7322,1,\"\"],[7323,1,\"\"],[7324,1,\"\"],[7325,1,\"\"],[7326,1,\"\"],[7327,1,\"\"],[7328,1,\"\"],[7329,1,\"\"],[7330,1,\"\"],[7331,1,\"\"],[7332,1,\"\"],[7333,1,\"\"],[7334,1,\"\"],[7335,1,\"\"],[7336,1,\"\"],[7337,1,\"\"],[7338,1,\"\"],[7339,1,\"\"],[7340,1,\"\"],[7341,1,\"\"],[7342,1,\"\"],[7343,1,\"\"],[7344,1,\"\"],[7345,1,\"\"],[7346,1,\"\"],[7347,1,\"\"],[7348,1,\"\"],[7349,1,\"\"],[7350,1,\"\"],[7351,1,\"\"],[7352,1,\"\"],[7353,1,\"\"],[7354,1,\"\"],[[7355,7356],3],[7357,1,\"\"],[7358,1,\"\"],[7359,1,\"\"],[[7360,7367],2],[[7368,7375],3],[[7376,7378],2],[7379,2],[[7380,7410],2],[[7411,7414],2],[7415,2],[[7416,7417],2],[7418,2],[[7419,7423],3],[[7424,7467],2],[7468,1,\"a\"],[7469,1,\"\"],[7470,1,\"b\"],[7471,2],[7472,1,\"d\"],[7473,1,\"e\"],[7474,1,\"\"],[7475,1,\"g\"],[7476,1,\"h\"],[7477,1,\"i\"],[7478,1,\"j\"],[7479,1,\"k\"],[7480,1,\"l\"],[7481,1,\"m\"],[7482,1,\"n\"],[7483,2],[7484,1,\"o\"],[7485,1,\"\"],[7486,1,\"p\"],[7487,1,\"r\"],[7488,1,\"t\"],[7489,1,\"u\"],[7490,1,\"w\"],[7491,1,\"a\"],[7492,1,\"\"],[7493,1,\"\"],[7494,1,\"\"],[7495,1,\"b\"],[7496,1,\"d\"],[7497,1,\"e\"],[7498,1,\"\"],[7499,1,\"\"],[7500,1,\"\"],[7501,1,\"g\"],[7502,2],[7503,1,\"k\"],[7504,1,\"m\"],[7505,1,\"\"],[7506,1,\"o\"],[7507,1,\"\"],[7508,1,\"\"],[7509,1,\"\"],[7510,1,\"p\"],[7511,1,\"t\"],[7512,1,\"u\"],[7513,1,\"\"],[7514,1,\"\"],[7515,1,\"v\"],[7516,1,\"\"],[7517,1,\"\"],[7518,1,\"\"],[7519,1,\"\"],[7520,1,\"\"],[7521,1,\"\"],[7522,1,\"i\"],[7523,1,\"r\"],[7524,1,\"u\"],[7525,1,\"v\"],[7526,1,\"\"],[7527,1,\"\"],[7528,1,\"\"],[7529,1,\"\"],[7530,1,\"\"],[7531,2],[[7532,7543],2],[7544,1,\"\"],[[7545,7578],2],[7579,1,\"\"],[7580,1,\"c\"],[7581,1,\"\"],[7582,1,\"\"],[7583,1,\"\"],[7584,1,\"f\"],[7585,1,\"\"],[7586,1,\"\"],[7587,1,\"\"],[7588,1,\"\"],[7589,1,\"\"],[7590,1,\"\"],[7591,1,\"\"],[7592,1,\"\"],[7593,1,\"\"],[7594,1,\"\"],[7595,1,\"\"],[7596,1,\"\"],[7597,1,\"\"],[7598,1,\"\"],[7599,1,\"\"],[7600,1,\"\"],[7601,1,\"\"],[7602,1,\"\"],[7603,1,\"\"],[7604,1,\"\"],[7605,1,\"\"],[7606,1,\"\"],[7607,1,\"\"],[7608,1,\"\"],[7609,1,\"\"],[7610,1,\"\"],[7611,1,\"z\"],[7612,1,\"\"],[7613,1,\"\"],[7614,1,\"\"],[7615,1,\"\"],[[7616,7619],2],[[7620,7626],2],[[7627,7654],2],[[7655,7669],2],[[7670,7673],2],[7674,2],[7675,2],[7676,2],[7677,2],[[7678,7679],2],[7680,1,\"\"],[7681,2],[7682,1,\"\"],[7683,2],[7684,1,\"\"],[7685,2],[7686,1,\"\"],[7687,2],[7688,1,\"\"],[7689,2],[7690,1,\"\"],[7691,2],[7692,1,\"\"],[7693,2],[7694,1,\"\"],[7695,2],[7696,1,\"\"],[7697,2],[7698,1,\"\"],[7699,2],[7700,1,\"\"],[7701,2],[7702,1,\"\"],[7703,2],[7704,1,\"\"],[7705,2],[7706,1,\"\"],[7707,2],[7708,1,\"\"],[7709,2],[7710,1,\"\"],[7711,2],[7712,1,\"\"],[7713,2],[7714,1,\"\"],[7715,2],[7716,1,\"\"],[7717,2],[7718,1,\"\"],[7719,2],[7720,1,\"\"],[7721,2],[7722,1,\"\"],[7723,2],[7724,1,\"\"],[7725,2],[7726,1,\"\"],[7727,2],[7728,1,\"\"],[7729,2],[7730,1,\"\"],[7731,2],[7732,1,\"\"],[7733,2],[7734,1,\"\"],[7735,2],[7736,1,\"\"],[7737,2],[7738,1,\"\"],[7739,2],[7740,1,\"\"],[7741,2],[7742,1,\"\"],[7743,2],[7744,1,\"\"],[7745,2],[7746,1,\"\"],[7747,2],[7748,1,\"\"],[7749,2],[7750,1,\"\"],[7751,2],[7752,1,\"\"],[7753,2],[7754,1,\"\"],[7755,2],[7756,1,\"\"],[7757,2],[7758,1,\"\"],[7759,2],[7760,1,\"\"],[7761,2],[7762,1,\"\"],[7763,2],[7764,1,\"\"],[7765,2],[7766,1,\"\"],[7767,2],[7768,1,\"\"],[7769,2],[7770,1,\"\"],[7771,2],[7772,1,\"\"],[7773,2],[7774,1,\"\"],[7775,2],[7776,1,\"\"],[7777,2],[7778,1,\"\"],[7779,2],[7780,1,\"\"],[7781,2],[7782,1,\"\"],[7783,2],[7784,1,\"\"],[7785,2],[7786,1,\"\"],[7787,2],[7788,1,\"\"],[7789,2],[7790,1,\"\"],[7791,2],[7792,1,\"\"],[7793,2],[7794,1,\"\"],[7795,2],[7796,1,\"\"],[7797,2],[7798,1,\"\"],[7799,2],[7800,1,\"\"],[7801,2],[7802,1,\"\"],[7803,2],[7804,1,\"\"],[7805,2],[7806,1,\"\"],[7807,2],[7808,1,\"\"],[7809,2],[7810,1,\"\"],[7811,2],[7812,1,\"\"],[7813,2],[7814,1,\"\"],[7815,2],[7816,1,\"\"],[7817,2],[7818,1,\"\"],[7819,2],[7820,1,\"\"],[7821,2],[7822,1,\"\"],[7823,2],[7824,1,\"\"],[7825,2],[7826,1,\"\"],[7827,2],[7828,1,\"\"],[[7829,7833],2],[7834,1,\"a\"],[7835,1,\"\"],[[7836,7837],2],[7838,1,\"ss\"],[7839,2],[7840,1,\"\"],[7841,2],[7842,1,\"\"],[7843,2],[7844,1,\"\"],[7845,2],[7846,1,\"\"],[7847,2],[7848,1,\"\"],[7849,2],[7850,1,\"\"],[7851,2],[7852,1,\"\"],[7853,2],[7854,1,\"\"],[7855,2],[7856,1,\"\"],[7857,2],[7858,1,\"\"],[7859,2],[7860,1,\"\"],[7861,2],[7862,1,\"\"],[7863,2],[7864,1,\"\"],[7865,2],[7866,1,\"\"],[7867,2],[7868,1,\"\"],[7869,2],[7870,1,\"\"],[7871,2],[7872,1,\"\"],[7873,2],[7874,1,\"\"],[7875,2],[7876,1,\"\"],[7877,2],[7878,1,\"\"],[7879,2],[7880,1,\"\"],[7881,2],[7882,1,\"\"],[7883,2],[7884,1,\"\"],[7885,2],[7886,1,\"\"],[7887,2],[7888,1,\"\"],[7889,2],[7890,1,\"\"],[7891,2],[7892,1,\"\"],[7893,2],[7894,1,\"\"],[7895,2],[7896,1,\"\"],[7897,2],[7898,1,\"\"],[7899,2],[7900,1,\"\"],[7901,2],[7902,1,\"\"],[7903,2],[7904,1,\"\"],[7905,2],[7906,1,\"\"],[7907,2],[7908,1,\"\"],[7909,2],[7910,1,\"\"],[7911,2],[7912,1,\"\"],[7913,2],[7914,1,\"\"],[7915,2],[7916,1,\"\"],[7917,2],[7918,1,\"\"],[7919,2],[7920,1,\"\"],[7921,2],[7922,1,\"\"],[7923,2],[7924,1,\"\"],[7925,2],[7926,1,\"\"],[7927,2],[7928,1,\"\"],[7929,2],[7930,1,\"\"],[7931,2],[7932,1,\"\"],[7933,2],[7934,1,\"\"],[7935,2],[[7936,7943],2],[7944,1,\"\"],[7945,1,\"\"],[7946,1,\"\"],[7947,1,\"\"],[7948,1,\"\"],[7949,1,\"\"],[7950,1,\"\"],[7951,1,\"\"],[[7952,7957],2],[[7958,7959],3],[7960,1,\"\"],[7961,1,\"\"],[7962,1,\"\"],[7963,1,\"\"],[7964,1,\"\"],[7965,1,\"\"],[[7966,7967],3],[[7968,7975],2],[7976,1,\"\"],[7977,1,\"\"],[7978,1,\"\"],[7979,1,\"\"],[7980,1,\"\"],[7981,1,\"\"],[7982,1,\"\"],[7983,1,\"\"],[[7984,7991],2],[7992,1,\"\"],[7993,1,\"\"],[7994,1,\"\"],[7995,1,\"\"],[7996,1,\"\"],[7997,1,\"\"],[7998,1,\"\"],[7999,1,\"\"],[[8000,8005],2],[[8006,8007],3],[8008,1,\"\"],[8009,1,\"\"],[8010,1,\"\"],[8011,1,\"\"],[8012,1,\"\"],[8013,1,\"\"],[[8014,8015],3],[[8016,8023],2],[8024,3],[8025,1,\"\"],[8026,3],[8027,1,\"\"],[8028,3],[8029,1,\"\"],[8030,3],[8031,1,\"\"],[[8032,8039],2],[8040,1,\"\"],[8041,1,\"\"],[8042,1,\"\"],[8043,1,\"\"],[8044,1,\"\"],[8045,1,\"\"],[8046,1,\"\"],[8047,1,\"\"],[8048,2],[8049,1,\"\"],[8050,2],[8051,1,\"\"],[8052,2],[8053,1,\"\"],[8054,2],[8055,1,\"\"],[8056,2],[8057,1,\"\"],[8058,2],[8059,1,\"\"],[8060,2],[8061,1,\"\"],[[8062,8063],3],[8064,1,\"\"],[8065,1,\"\"],[8066,1,\"\"],[8067,1,\"\"],[8068,1,\"\"],[8069,1,\"\"],[8070,1,\"\"],[8071,1,\"\"],[8072,1,\"\"],[8073,1,\"\"],[8074,1,\"\"],[8075,1,\"\"],[8076,1,\"\"],[8077,1,\"\"],[8078,1,\"\"],[8079,1,\"\"],[8080,1,\"\"],[8081,1,\"\"],[8082,1,\"\"],[8083,1,\"\"],[8084,1,\"\"],[8085,1,\"\"],[8086,1,\"\"],[8087,1,\"\"],[8088,1,\"\"],[8089,1,\"\"],[8090,1,\"\"],[8091,1,\"\"],[8092,1,\"\"],[8093,1,\"\"],[8094,1,\"\"],[8095,1,\"\"],[8096,1,\"\"],[8097,1,\"\"],[8098,1,\"\"],[8099,1,\"\"],[8100,1,\"\"],[8101,1,\"\"],[8102,1,\"\"],[8103,1,\"\"],[8104,1,\"\"],[8105,1,\"\"],[8106,1,\"\"],[8107,1,\"\"],[8108,1,\"\"],[8109,1,\"\"],[8110,1,\"\"],[8111,1,\"\"],[[8112,8113],2],[8114,1,\"\"],[8115,1,\"\"],[8116,1,\"\"],[8117,3],[8118,2],[8119,1,\"\"],[8120,1,\"\"],[8121,1,\"\"],[8122,1,\"\"],[8123,1,\"\"],[8124,1,\"\"],[8125,5,\" \"],[8126,1,\"\"],[8127,5,\" \"],[8128,5,\" \"],[8129,5,\" \"],[8130,1,\"\"],[8131,1,\"\"],[8132,1,\"\"],[8133,3],[8134,2],[8135,1,\"\"],[8136,1,\"\"],[8137,1,\"\"],[8138,1,\"\"],[8139,1,\"\"],[8140,1,\"\"],[8141,5,\" \"],[8142,5,\" \"],[8143,5,\" \"],[[8144,8146],2],[8147,1,\"\"],[[8148,8149],3],[[8150,8151],2],[8152,1,\"\"],[8153,1,\"\"],[8154,1,\"\"],[8155,1,\"\"],[8156,3],[8157,5,\" \"],[8158,5,\" \"],[8159,5,\" \"],[[8160,8162],2],[8163,1,\"\"],[[8164,8167],2],[8168,1,\"\"],[8169,1,\"\"],[8170,1,\"\"],[8171,1,\"\"],[8172,1,\"\"],[8173,5,\" \"],[8174,5,\" \"],[8175,5,\"`\"],[[8176,8177],3],[8178,1,\"\"],[8179,1,\"\"],[8180,1,\"\"],[8181,3],[8182,2],[8183,1,\"\"],[8184,1,\"\"],[8185,1,\"\"],[8186,1,\"\"],[8187,1,\"\"],[8188,1,\"\"],[8189,5,\" \"],[8190,5,\" \"],[8191,3],[[8192,8202],5,\" \"],[8203,7],[[8204,8205],6,\"\"],[[8206,8207],3],[8208,2],[8209,1,\"\"],[[8210,8214],2],[8215,5,\" \"],[[8216,8227],2],[[8228,8230],3],[8231,2],[[8232,8238],3],[8239,5,\" \"],[[8240,8242],2],[8243,1,\"\"],[8244,1,\"\"],[8245,2],[8246,1,\"\"],[8247,1,\"\"],[[8248,8251],2],[8252,5,\"!!\"],[8253,2],[8254,5,\" \"],[[8255,8262],2],[8263,5,\"??\"],[8264,5,\"?!\"],[8265,5,\"!?\"],[[8266,8269],2],[[8270,8274],2],[[8275,8276],2],[[8277,8278],2],[8279,1,\"\"],[[8280,8286],2],[8287,5,\" \"],[8288,7],[[8289,8291],3],[8292,7],[8293,3],[[8294,8297],3],[[8298,8303],3],[8304,1,\"0\"],[8305,1,\"i\"],[[8306,8307],3],[8308,1,\"4\"],[8309,1,\"5\"],[8310,1,\"6\"],[8311,1,\"7\"],[8312,1,\"8\"],[8313,1,\"9\"],[8314,5,\"+\"],[8315,1,\"\"],[8316,5,\"=\"],[8317,5,\"(\"],[8318,5,\")\"],[8319,1,\"n\"],[8320,1,\"0\"],[8321,1,\"1\"],[8322,1,\"2\"],[8323,1,\"3\"],[8324,1,\"4\"],[8325,1,\"5\"],[8326,1,\"6\"],[8327,1,\"7\"],[8328,1,\"8\"],[8329,1,\"9\"],[8330,5,\"+\"],[8331,1,\"\"],[8332,5,\"=\"],[8333,5,\"(\"],[8334,5,\")\"],[8335,3],[8336,1,\"a\"],[8337,1,\"e\"],[8338,1,\"o\"],[8339,1,\"x\"],[8340,1,\"\"],[8341,1,\"h\"],[8342,1,\"k\"],[8343,1,\"l\"],[8344,1,\"m\"],[8345,1,\"n\"],[8346,1,\"p\"],[8347,1,\"s\"],[8348,1,\"t\"],[[8349,8351],3],[[8352,8359],2],[8360,1,\"rs\"],[[8361,8362],2],[8363,2],[8364,2],[[8365,8367],2],[[8368,8369],2],[[8370,8373],2],[[8374,8376],2],[8377,2],[8378,2],[[8379,8381],2],[8382,2],[8383,2],[8384,2],[[8385,8399],3],[[8400,8417],2],[[8418,8419],2],[[8420,8426],2],[8427,2],[[8428,8431],2],[8432,2],[[8433,8447],3],[8448,5,\"a/c\"],[8449,5,\"a/s\"],[8450,1,\"c\"],[8451,1,\"c\"],[8452,2],[8453,5,\"c/o\"],[8454,5,\"c/u\"],[8455,1,\"\"],[8456,2],[8457,1,\"f\"],[8458,1,\"g\"],[[8459,8462],1,\"h\"],[8463,1,\"\"],[[8464,8465],1,\"i\"],[[8466,8467],1,\"l\"],[8468,2],[8469,1,\"n\"],[8470,1,\"no\"],[[8471,8472],2],[8473,1,\"p\"],[8474,1,\"q\"],[[8475,8477],1,\"r\"],[[8478,8479],2],[8480,1,\"sm\"],[8481,1,\"tel\"],[8482,1,\"tm\"],[8483,2],[8484,1,\"z\"],[8485,2],[8486,1,\"\"],[8487,2],[8488,1,\"z\"],[8489,2],[8490,1,\"k\"],[8491,1,\"\"],[8492,1,\"b\"],[8493,1,\"c\"],[8494,2],[[8495,8496],1,\"e\"],[8497,1,\"f\"],[8498,3],[8499,1,\"m\"],[8500,1,\"o\"],[8501,1,\"\"],[8502,1,\"\"],[8503,1,\"\"],[8504,1,\"\"],[8505,1,\"i\"],[8506,2],[8507,1,\"fax\"],[8508,1,\"\"],[[8509,8510],1,\"\"],[8511,1,\"\"],[8512,1,\"\"],[[8513,8516],2],[[8517,8518],1,\"d\"],[8519,1,\"e\"],[8520,1,\"i\"],[8521,1,\"j\"],[[8522,8523],2],[8524,2],[8525,2],[8526,2],[8527,2],[8528,1,\"17\"],[8529,1,\"19\"],[8530,1,\"110\"],[8531,1,\"13\"],[8532,1,\"23\"],[8533,1,\"15\"],[8534,1,\"25\"],[8535,1,\"35\"],[8536,1,\"45\"],[8537,1,\"16\"],[8538,1,\"56\"],[8539,1,\"18\"],[8540,1,\"38\"],[8541,1,\"58\"],[8542,1,\"78\"],[8543,1,\"1\"],[8544,1,\"i\"],[8545,1,\"ii\"],[8546,1,\"iii\"],[8547,1,\"iv\"],[8548,1,\"v\"],[8549,1,\"vi\"],[8550,1,\"vii\"],[8551,1,\"viii\"],[8552,1,\"ix\"],[8553,1,\"x\"],[8554,1,\"xi\"],[8555,1,\"xii\"],[8556,1,\"l\"],[8557,1,\"c\"],[8558,1,\"d\"],[8559,1,\"m\"],[8560,1,\"i\"],[8561,1,\"ii\"],[8562,1,\"iii\"],[8563,1,\"iv\"],[8564,1,\"v\"],[8565,1,\"vi\"],[8566,1,\"vii\"],[8567,1,\"viii\"],[8568,1,\"ix\"],[8569,1,\"x\"],[8570,1,\"xi\"],[8571,1,\"xii\"],[8572,1,\"l\"],[8573,1,\"c\"],[8574,1,\"d\"],[8575,1,\"m\"],[[8576,8578],2],[8579,3],[8580,2],[[8581,8584],2],[8585,1,\"03\"],[[8586,8587],2],[[8588,8591],3],[[8592,8682],2],[[8683,8691],2],[[8692,8703],2],[[8704,8747],2],[8748,1,\"\"],[8749,1,\"\"],[8750,2],[8751,1,\"\"],[8752,1,\"\"],[[8753,8799],2],[8800,4],[[8801,8813],2],[[8814,8815],4],[[8816,8945],2],[[8946,8959],2],[8960,2],[8961,2],[[8962,9000],2],[9001,1,\"\"],[9002,1,\"\"],[[9003,9082],2],[9083,2],[9084,2],[[9085,9114],2],[[9115,9166],2],[[9167,9168],2],[[9169,9179],2],[[9180,9191],2],[9192,2],[[9193,9203],2],[[9204,9210],2],[[9211,9214],2],[9215,2],[[9216,9252],2],[[9253,9254],2],[[9255,9279],3],[[9280,9290],2],[[9291,9311],3],[9312,1,\"1\"],[9313,1,\"2\"],[9314,1,\"3\"],[9315,1,\"4\"],[9316,1,\"5\"],[9317,1,\"6\"],[9318,1,\"7\"],[9319,1,\"8\"],[9320,1,\"9\"],[9321,1,\"10\"],[9322,1,\"11\"],[9323,1,\"12\"],[9324,1,\"13\"],[9325,1,\"14\"],[9326,1,\"15\"],[9327,1,\"16\"],[9328,1,\"17\"],[9329,1,\"18\"],[9330,1,\"19\"],[9331,1,\"20\"],[9332,5,\"(1)\"],[9333,5,\"(2)\"],[9334,5,\"(3)\"],[9335,5,\"(4)\"],[9336,5,\"(5)\"],[9337,5,\"(6)\"],[9338,5,\"(7)\"],[9339,5,\"(8)\"],[9340,5,\"(9)\"],[9341,5,\"(10)\"],[9342,5,\"(11)\"],[9343,5,\"(12)\"],[9344,5,\"(13)\"],[9345,5,\"(14)\"],[9346,5,\"(15)\"],[9347,5,\"(16)\"],[9348,5,\"(17)\"],[9349,5,\"(18)\"],[9350,5,\"(19)\"],[9351,5,\"(20)\"],[[9352,9371],3],[9372,5,\"(a)\"],[9373,5,\"(b)\"],[9374,5,\"(c)\"],[9375,5,\"(d)\"],[9376,5,\"(e)\"],[9377,5,\"(f)\"],[9378,5,\"(g)\"],[9379,5,\"(h)\"],[9380,5,\"(i)\"],[9381,5,\"(j)\"],[9382,5,\"(k)\"],[9383,5,\"(l)\"],[9384,5,\"(m)\"],[9385,5,\"(n)\"],[9386,5,\"(o)\"],[9387,5,\"(p)\"],[9388,5,\"(q)\"],[9389,5,\"(r)\"],[9390,5,\"(s)\"],[9391,5,\"(t)\"],[9392,5,\"(u)\"],[9393,5,\"(v)\"],[9394,5,\"(w)\"],[9395,5,\"(x)\"],[9396,5,\"(y)\"],[9397,5,\"(z)\"],[9398,1,\"a\"],[9399,1,\"b\"],[9400,1,\"c\"],[9401,1,\"d\"],[9402,1,\"e\"],[9403,1,\"f\"],[9404,1,\"g\"],[9405,1,\"h\"],[9406,1,\"i\"],[9407,1,\"j\"],[9408,1,\"k\"],[9409,1,\"l\"],[9410,1,\"m\"],[9411,1,\"n\"],[9412,1,\"o\"],[9413,1,\"p\"],[9414,1,\"q\"],[9415,1,\"r\"],[9416,1,\"s\"],[9417,1,\"t\"],[9418,1,\"u\"],[9419,1,\"v\"],[9420,1,\"w\"],[9421,1,\"x\"],[9422,1,\"y\"],[9423,1,\"z\"],[9424,1,\"a\"],[9425,1,\"b\"],[9426,1,\"c\"],[9427,1,\"d\"],[9428,1,\"e\"],[9429,1,\"f\"],[9430,1,\"g\"],[9431,1,\"h\"],[9432,1,\"i\"],[9433,1,\"j\"],[9434,1,\"k\"],[9435,1,\"l\"],[9436,1,\"m\"],[9437,1,\"n\"],[9438,1,\"o\"],[9439,1,\"p\"],[9440,1,\"q\"],[9441,1,\"r\"],[9442,1,\"s\"],[9443,1,\"t\"],[9444,1,\"u\"],[9445,1,\"v\"],[9446,1,\"w\"],[9447,1,\"x\"],[9448,1,\"y\"],[9449,1,\"z\"],[9450,1,\"0\"],[[9451,9470],2],[9471,2],[[9472,9621],2],[[9622,9631],2],[[9632,9711],2],[[9712,9719],2],[[9720,9727],2],[[9728,9747],2],[[9748,9749],2],[[9750,9751],2],[9752,2],[9753,2],[[9754,9839],2],[[9840,9841],2],[[9842,9853],2],[[9854,9855],2],[[9856,9865],2],[[9866,9873],2],[[9874,9884],2],[9885,2],[[9886,9887],2],[[9888,9889],2],[[9890,9905],2],[9906,2],[[9907,9916],2],[[9917,9919],2],[[9920,9923],2],[[9924,9933],2],[9934,2],[[9935,9953],2],[9954,2],[9955,2],[[9956,9959],2],[[9960,9983],2],[9984,2],[[9985,9988],2],[9989,2],[[9990,9993],2],[[9994,9995],2],[[9996,10023],2],[10024,2],[[10025,10059],2],[10060,2],[10061,2],[10062,2],[[10063,10066],2],[[10067,10069],2],[10070,2],[10071,2],[[10072,10078],2],[[10079,10080],2],[[10081,10087],2],[[10088,10101],2],[[10102,10132],2],[[10133,10135],2],[[10136,10159],2],[10160,2],[[10161,10174],2],[10175,2],[[10176,10182],2],[[10183,10186],2],[10187,2],[10188,2],[10189,2],[[10190,10191],2],[[10192,10219],2],[[10220,10223],2],[[10224,10239],2],[[10240,10495],2],[[10496,10763],2],[10764,1,\"\"],[[10765,10867],2],[10868,5,\"::=\"],[10869,5,\"==\"],[10870,5,\"===\"],[[10871,10971],2],[10972,1,\"\"],[[10973,11007],2],[[11008,11021],2],[[11022,11027],2],[[11028,11034],2],[[11035,11039],2],[[11040,11043],2],[[11044,11084],2],[[11085,11087],2],[[11088,11092],2],[[11093,11097],2],[[11098,11123],2],[[11124,11125],3],[[11126,11157],2],[11158,3],[11159,2],[[11160,11193],2],[[11194,11196],2],[[11197,11208],2],[11209,2],[[11210,11217],2],[11218,2],[[11219,11243],2],[[11244,11247],2],[[11248,11262],2],[11263,2],[11264,1,\"\"],[11265,1,\"\"],[11266,1,\"\"],[11267,1,\"\"],[11268,1,\"\"],[11269,1,\"\"],[11270,1,\"\"],[11271,1,\"\"],[11272,1,\"\"],[11273,1,\"\"],[11274,1,\"\"],[11275,1,\"\"],[11276,1,\"\"],[11277,1,\"\"],[11278,1,\"\"],[11279,1,\"\"],[11280,1,\"\"],[11281,1,\"\"],[11282,1,\"\"],[11283,1,\"\"],[11284,1,\"\"],[11285,1,\"\"],[11286,1,\"\"],[11287,1,\"\"],[11288,1,\"\"],[11289,1,\"\"],[11290,1,\"\"],[11291,1,\"\"],[11292,1,\"\"],[11293,1,\"\"],[11294,1,\"\"],[11295,1,\"\"],[11296,1,\"\"],[11297,1,\"\"],[11298,1,\"\"],[11299,1,\"\"],[11300,1,\"\"],[11301,1,\"\"],[11302,1,\"\"],[11303,1,\"\"],[11304,1,\"\"],[11305,1,\"\"],[11306,1,\"\"],[11307,1,\"\"],[11308,1,\"\"],[11309,1,\"\"],[11310,1,\"\"],[11311,1,\"\"],[[11312,11358],2],[11359,2],[11360,1,\"\"],[11361,2],[11362,1,\"\"],[11363,1,\"\"],[11364,1,\"\"],[[11365,11366],2],[11367,1,\"\"],[11368,2],[11369,1,\"\"],[11370,2],[11371,1,\"\"],[11372,2],[11373,1,\"\"],[11374,1,\"\"],[11375,1,\"\"],[11376,1,\"\"],[11377,2],[11378,1,\"\"],[11379,2],[11380,2],[11381,1,\"\"],[[11382,11383],2],[[11384,11387],2],[11388,1,\"j\"],[11389,1,\"v\"],[11390,1,\"\"],[11391,1,\"\"],[11392,1,\"\"],[11393,2],[11394,1,\"\"],[11395,2],[11396,1,\"\"],[11397,2],[11398,1,\"\"],[11399,2],[11400,1,\"\"],[11401,2],[11402,1,\"\"],[11403,2],[11404,1,\"\"],[11405,2],[11406,1,\"\"],[11407,2],[11408,1,\"\"],[11409,2],[11410,1,\"\"],[11411,2],[11412,1,\"\"],[11413,2],[11414,1,\"\"],[11415,2],[11416,1,\"\"],[11417,2],[11418,1,\"\"],[11419,2],[11420,1,\"\"],[11421,2],[11422,1,\"\"],[11423,2],[11424,1,\"\"],[11425,2],[11426,1,\"\"],[11427,2],[11428,1,\"\"],[11429,2],[11430,1,\"\"],[11431,2],[11432,1,\"\"],[11433,2],[11434,1,\"\"],[11435,2],[11436,1,\"\"],[11437,2],[11438,1,\"\"],[11439,2],[11440,1,\"\"],[11441,2],[11442,1,\"\"],[11443,2],[11444,1,\"\"],[11445,2],[11446,1,\"\"],[11447,2],[11448,1,\"\"],[11449,2],[11450,1,\"\"],[11451,2],[11452,1,\"\"],[11453,2],[11454,1,\"\"],[11455,2],[11456,1,\"\"],[11457,2],[11458,1,\"\"],[11459,2],[11460,1,\"\"],[11461,2],[11462,1,\"\"],[11463,2],[11464,1,\"\"],[11465,2],[11466,1,\"\"],[11467,2],[11468,1,\"\"],[11469,2],[11470,1,\"\"],[11471,2],[11472,1,\"\"],[11473,2],[11474,1,\"\"],[11475,2],[11476,1,\"\"],[11477,2],[11478,1,\"\"],[11479,2],[11480,1,\"\"],[11481,2],[11482,1,\"\"],[11483,2],[11484,1,\"\"],[11485,2],[11486,1,\"\"],[11487,2],[11488,1,\"\"],[11489,2],[11490,1,\"\"],[[11491,11492],2],[[11493,11498],2],[11499,1,\"\"],[11500,2],[11501,1,\"\"],[[11502,11505],2],[11506,1,\"\"],[11507,2],[[11508,11512],3],[[11513,11519],2],[[11520,11557],2],[11558,3],[11559,2],[[11560,11564],3],[11565,2],[[11566,11567],3],[[11568,11621],2],[[11622,11623],2],[[11624,11630],3],[11631,1,\"\"],[11632,2],[[11633,11646],3],[11647,2],[[11648,11670],2],[[11671,11679],3],[[11680,11686],2],[11687,3],[[11688,11694],2],[11695,3],[[11696,11702],2],[11703,3],[[11704,11710],2],[11711,3],[[11712,11718],2],[11719,3],[[11720,11726],2],[11727,3],[[11728,11734],2],[11735,3],[[11736,11742],2],[11743,3],[[11744,11775],2],[[11776,11799],2],[[11800,11803],2],[[11804,11805],2],[[11806,11822],2],[11823,2],[11824,2],[11825,2],[[11826,11835],2],[[11836,11842],2],[[11843,11844],2],[[11845,11849],2],[[11850,11854],2],[11855,2],[[11856,11858],2],[[11859,11869],2],[[11870,11903],3],[[11904,11929],2],[11930,3],[[11931,11934],2],[11935,1,\"\"],[[11936,12018],2],[12019,1,\"\"],[[12020,12031],3],[12032,1,\"\"],[12033,1,\"\"],[12034,1,\"\"],[12035,1,\"\"],[12036,1,\"\"],[12037,1,\"\"],[12038,1,\"\"],[12039,1,\"\"],[12040,1,\"\"],[12041,1,\"\"],[12042,1,\"\"],[12043,1,\"\"],[12044,1,\"\"],[12045,1,\"\"],[12046,1,\"\"],[12047,1,\"\"],[12048,1,\"\"],[12049,1,\"\"],[12050,1,\"\"],[12051,1,\"\"],[12052,1,\"\"],[12053,1,\"\"],[12054,1,\"\"],[12055,1,\"\"],[12056,1,\"\"],[12057,1,\"\"],[12058,1,\"\"],[12059,1,\"\"],[12060,1,\"\"],[12061,1,\"\"],[12062,1,\"\"],[12063,1,\"\"],[12064,1,\"\"],[12065,1,\"\"],[12066,1,\"\"],[12067,1,\"\"],[12068,1,\"\"],[12069,1,\"\"],[12070,1,\"\"],[12071,1,\"\"],[12072,1,\"\"],[12073,1,\"\"],[12074,1,\"\"],[12075,1,\"\"],[12076,1,\"\"],[12077,1,\"\"],[12078,1,\"\"],[12079,1,\"\"],[12080,1,\"\"],[12081,1,\"\"],[12082,1,\"\"],[12083,1,\"\"],[12084,1,\"\"],[12085,1,\"\"],[12086,1,\"\"],[12087,1,\"\"],[12088,1,\"\"],[12089,1,\"\"],[12090,1,\"\"],[12091,1,\"\"],[12092,1,\"\"],[12093,1,\"\"],[12094,1,\"\"],[12095,1,\"\"],[12096,1,\"\"],[12097,1,\"\"],[12098,1,\"\"],[12099,1,\"\"],[12100,1,\"\"],[12101,1,\"\"],[12102,1,\"\"],[12103,1,\"\"],[12104,1,\"\"],[12105,1,\"\"],[12106,1,\"\"],[12107,1,\"\"],[12108,1,\"\"],[12109,1,\"\"],[12110,1,\"\"],[12111,1,\"\"],[12112,1,\"\"],[12113,1,\"\"],[12114,1,\"\"],[12115,1,\"\"],[12116,1,\"\"],[12117,1,\"\"],[12118,1,\"\"],[12119,1,\"\"],[12120,1,\"\"],[12121,1,\"\"],[12122,1,\"\"],[12123,1,\"\"],[12124,1,\"\"],[12125,1,\"\"],[12126,1,\"\"],[12127,1,\"\"],[12128,1,\"\"],[12129,1,\"\"],[12130,1,\"\"],[12131,1,\"\"],[12132,1,\"\"],[12133,1,\"\"],[12134,1,\"\"],[12135,1,\"\"],[12136,1,\"\"],[12137,1,\"\"],[12138,1,\"\"],[12139,1,\"\"],[12140,1,\"\"],[12141,1,\"\"],[12142,1,\"\"],[12143,1,\"\"],[12144,1,\"\"],[12145,1,\"\"],[12146,1,\"\"],[12147,1,\"\"],[12148,1,\"\"],[12149,1,\"\"],[12150,1,\"\"],[12151,1,\"\"],[12152,1,\"\"],[12153,1,\"\"],[12154,1,\"\"],[12155,1,\"\"],[12156,1,\"\"],[12157,1,\"\"],[12158,1,\"\"],[12159,1,\"\"],[12160,1,\"\"],[12161,1,\"\"],[12162,1,\"\"],[12163,1,\"\"],[12164,1,\"\"],[12165,1,\"\"],[12166,1,\"\"],[12167,1,\"\"],[12168,1,\"\"],[12169,1,\"\"],[12170,1,\"\"],[12171,1,\"\"],[12172,1,\"\"],[12173,1,\"\"],[12174,1,\"\"],[12175,1,\"\"],[12176,1,\"\"],[12177,1,\"\"],[12178,1,\"\"],[12179,1,\"\"],[12180,1,\"\"],[12181,1,\"\"],[12182,1,\"\"],[12183,1,\"\"],[12184,1,\"\"],[12185,1,\"\"],[12186,1,\"\"],[12187,1,\"\"],[12188,1,\"\"],[12189,1,\"\"],[12190,1,\"\"],[12191,1,\"\"],[12192,1,\"\"],[12193,1,\"\"],[12194,1,\"\"],[12195,1,\"\"],[12196,1,\"\"],[12197,1,\"\"],[12198,1,\"\"],[12199,1,\"\"],[12200,1,\"\"],[12201,1,\"\"],[12202,1,\"\"],[12203,1,\"\"],[12204,1,\"\"],[12205,1,\"\"],[12206,1,\"\"],[12207,1,\"\"],[12208,1,\"\"],[12209,1,\"\"],[12210,1,\"\"],[12211,1,\"\"],[12212,1,\"\"],[12213,1,\"\"],[12214,1,\"\"],[12215,1,\"\"],[12216,1,\"\"],[12217,1,\"\"],[12218,1,\"\"],[12219,1,\"\"],[12220,1,\"\"],[12221,1,\"\"],[12222,1,\"\"],[12223,1,\"\"],[12224,1,\"\"],[12225,1,\"\"],[12226,1,\"\"],[12227,1,\"\"],[12228,1,\"\"],[12229,1,\"\"],[12230,1,\"\"],[12231,1,\"\"],[12232,1,\"\"],[12233,1,\"\"],[12234,1,\"\"],[12235,1,\"\"],[12236,1,\"\"],[12237,1,\"\"],[12238,1,\"\"],[12239,1,\"\"],[12240,1,\"\"],[12241,1,\"\"],[12242,1,\"\"],[12243,1,\"\"],[12244,1,\"\"],[12245,1,\"\"],[[12246,12271],3],[[12272,12283],3],[[12284,12287],3],[12288,5,\" \"],[12289,2],[12290,1,\".\"],[[12291,12292],2],[[12293,12295],2],[[12296,12329],2],[[12330,12333],2],[[12334,12341],2],[12342,1,\"\"],[12343,2],[12344,1,\"\"],[12345,1,\"\"],[12346,1,\"\"],[12347,2],[12348,2],[12349,2],[12350,2],[12351,2],[12352,3],[[12353,12436],2],[[12437,12438],2],[[12439,12440],3],[[12441,12442],2],[12443,5,\" \"],[12444,5,\" \"],[[12445,12446],2],[12447,1,\"\"],[12448,2],[[12449,12542],2],[12543,1,\"\"],[[12544,12548],3],[[12549,12588],2],[12589,2],[12590,2],[12591,2],[12592,3],[12593,1,\"\"],[12594,1,\"\"],[12595,1,\"\"],[12596,1,\"\"],[12597,1,\"\"],[12598,1,\"\"],[12599,1,\"\"],[12600,1,\"\"],[12601,1,\"\"],[12602,1,\"\"],[12603,1,\"\"],[12604,1,\"\"],[12605,1,\"\"],[12606,1,\"\"],[12607,1,\"\"],[12608,1,\"\"],[12609,1,\"\"],[12610,1,\"\"],[12611,1,\"\"],[12612,1,\"\"],[12613,1,\"\"],[12614,1,\"\"],[12615,1,\"\"],[12616,1,\"\"],[12617,1,\"\"],[12618,1,\"\"],[12619,1,\"\"],[12620,1,\"\"],[12621,1,\"\"],[12622,1,\"\"],[12623,1,\"\"],[12624,1,\"\"],[12625,1,\"\"],[12626,1,\"\"],[12627,1,\"\"],[12628,1,\"\"],[12629,1,\"\"],[12630,1,\"\"],[12631,1,\"\"],[12632,1,\"\"],[12633,1,\"\"],[12634,1,\"\"],[12635,1,\"\"],[12636,1,\"\"],[12637,1,\"\"],[12638,1,\"\"],[12639,1,\"\"],[12640,1,\"\"],[12641,1,\"\"],[12642,1,\"\"],[12643,1,\"\"],[12644,3],[12645,1,\"\"],[12646,1,\"\"],[12647,1,\"\"],[12648,1,\"\"],[12649,1,\"\"],[12650,1,\"\"],[12651,1,\"\"],[12652,1,\"\"],[12653,1,\"\"],[12654,1,\"\"],[12655,1,\"\"],[12656,1,\"\"],[12657,1,\"\"],[12658,1,\"\"],[12659,1,\"\"],[12660,1,\"\"],[12661,1,\"\"],[12662,1,\"\"],[12663,1,\"\"],[12664,1,\"\"],[12665,1,\"\"],[12666,1,\"\"],[12667,1,\"\"],[12668,1,\"\"],[12669,1,\"\"],[12670,1,\"\"],[12671,1,\"\"],[12672,1,\"\"],[12673,1,\"\"],[12674,1,\"\"],[12675,1,\"\"],[12676,1,\"\"],[12677,1,\"\"],[12678,1,\"\"],[12679,1,\"\"],[12680,1,\"\"],[12681,1,\"\"],[12682,1,\"\"],[12683,1,\"\"],[12684,1,\"\"],[12685,1,\"\"],[12686,1,\"\"],[12687,3],[[12688,12689],2],[12690,1,\"\"],[12691,1,\"\"],[12692,1,\"\"],[12693,1,\"\"],[12694,1,\"\"],[12695,1,\"\"],[12696,1,\"\"],[12697,1,\"\"],[12698,1,\"\"],[12699,1,\"\"],[12700,1,\"\"],[12701,1,\"\"],[12702,1,\"\"],[12703,1,\"\"],[[12704,12727],2],[[12728,12730],2],[[12731,12735],2],[[12736,12751],2],[[12752,12771],2],[[12772,12783],3],[[12784,12799],2],[12800,5,\"()\"],[12801,5,\"()\"],[12802,5,\"()\"],[12803,5,\"()\"],[12804,5,\"()\"],[12805,5,\"()\"],[12806,5,\"()\"],[12807,5,\"()\"],[12808,5,\"()\"],[12809,5,\"()\"],[12810,5,\"()\"],[12811,5,\"()\"],[12812,5,\"()\"],[12813,5,\"()\"],[12814,5,\"()\"],[12815,5,\"()\"],[12816,5,\"()\"],[12817,5,\"()\"],[12818,5,\"()\"],[12819,5,\"()\"],[12820,5,\"()\"],[12821,5,\"()\"],[12822,5,\"()\"],[12823,5,\"()\"],[12824,5,\"()\"],[12825,5,\"()\"],[12826,5,\"()\"],[12827,5,\"()\"],[12828,5,\"()\"],[12829,5,\"()\"],[12830,5,\"()\"],[12831,3],[12832,5,\"()\"],[12833,5,\"()\"],[12834,5,\"()\"],[12835,5,\"()\"],[12836,5,\"()\"],[12837,5,\"()\"],[12838,5,\"()\"],[12839,5,\"()\"],[12840,5,\"()\"],[12841,5,\"()\"],[12842,5,\"()\"],[12843,5,\"()\"],[12844,5,\"()\"],[12845,5,\"()\"],[12846,5,\"()\"],[12847,5,\"()\"],[12848,5,\"()\"],[12849,5,\"()\"],[12850,5,\"()\"],[12851,5,\"()\"],[12852,5,\"()\"],[12853,5,\"()\"],[12854,5,\"()\"],[12855,5,\"()\"],[12856,5,\"()\"],[12857,5,\"()\"],[12858,5,\"()\"],[12859,5,\"()\"],[12860,5,\"()\"],[12861,5,\"()\"],[12862,5,\"()\"],[12863,5,\"()\"],[12864,5,\"()\"],[12865,5,\"()\"],[12866,5,\"()\"],[12867,5,\"()\"],[12868,1,\"\"],[12869,1,\"\"],[12870,1,\"\"],[12871,1,\"\"],[[12872,12879],2],[12880,1,\"pte\"],[12881,1,\"21\"],[12882,1,\"22\"],[12883,1,\"23\"],[12884,1,\"24\"],[12885,1,\"25\"],[12886,1,\"26\"],[12887,1,\"27\"],[12888,1,\"28\"],[12889,1,\"29\"],[12890,1,\"30\"],[12891,1,\"31\"],[12892,1,\"32\"],[12893,1,\"33\"],[12894,1,\"34\"],[12895,1,\"35\"],[12896,1,\"\"],[12897,1,\"\"],[12898,1,\"\"],[12899,1,\"\"],[12900,1,\"\"],[12901,1,\"\"],[12902,1,\"\"],[12903,1,\"\"],[12904,1,\"\"],[12905,1,\"\"],[12906,1,\"\"],[12907,1,\"\"],[12908,1,\"\"],[12909,1,\"\"],[12910,1,\"\"],[12911,1,\"\"],[12912,1,\"\"],[12913,1,\"\"],[12914,1,\"\"],[12915,1,\"\"],[12916,1,\"\"],[12917,1,\"\"],[12918,1,\"\"],[12919,1,\"\"],[12920,1,\"\"],[12921,1,\"\"],[12922,1,\"\"],[12923,1,\"\"],[12924,1,\"\"],[12925,1,\"\"],[12926,1,\"\"],[12927,2],[12928,1,\"\"],[12929,1,\"\"],[12930,1,\"\"],[12931,1,\"\"],[12932,1,\"\"],[12933,1,\"\"],[12934,1,\"\"],[12935,1,\"\"],[12936,1,\"\"],[12937,1,\"\"],[12938,1,\"\"],[12939,1,\"\"],[12940,1,\"\"],[12941,1,\"\"],[12942,1,\"\"],[12943,1,\"\"],[12944,1,\"\"],[12945,1,\"\"],[12946,1,\"\"],[12947,1,\"\"],[12948,1,\"\"],[12949,1,\"\"],[12950,1,\"\"],[12951,1,\"\"],[12952,1,\"\"],[12953,1,\"\"],[12954,1,\"\"],[12955,1,\"\"],[12956,1,\"\"],[12957,1,\"\"],[12958,1,\"\"],[12959,1,\"\"],[12960,1,\"\"],[12961,1,\"\"],[12962,1,\"\"],[12963,1,\"\"],[12964,1,\"\"],[12965,1,\"\"],[12966,1,\"\"],[12967,1,\"\"],[12968,1,\"\"],[12969,1,\"\"],[12970,1,\"\"],[12971,1,\"\"],[12972,1,\"\"],[12973,1,\"\"],[12974,1,\"\"],[12975,1,\"\"],[12976,1,\"\"],[12977,1,\"36\"],[12978,1,\"37\"],[12979,1,\"38\"],[12980,1,\"39\"],[12981,1,\"40\"],[12982,1,\"41\"],[12983,1,\"42\"],[12984,1,\"43\"],[12985,1,\"44\"],[12986,1,\"45\"],[12987,1,\"46\"],[12988,1,\"47\"],[12989,1,\"48\"],[12990,1,\"49\"],[12991,1,\"50\"],[12992,1,\"1\"],[12993,1,\"2\"],[12994,1,\"3\"],[12995,1,\"4\"],[12996,1,\"5\"],[12997,1,\"6\"],[12998,1,\"7\"],[12999,1,\"8\"],[13000,1,\"9\"],[13001,1,\"10\"],[13002,1,\"11\"],[13003,1,\"12\"],[13004,1,\"hg\"],[13005,1,\"erg\"],[13006,1,\"ev\"],[13007,1,\"ltd\"],[13008,1,\"\"],[13009,1,\"\"],[13010,1,\"\"],[13011,1,\"\"],[13012,1,\"\"],[13013,1,\"\"],[13014,1,\"\"],[13015,1,\"\"],[13016,1,\"\"],[13017,1,\"\"],[13018,1,\"\"],[13019,1,\"\"],[13020,1,\"\"],[13021,1,\"\"],[13022,1,\"\"],[13023,1,\"\"],[13024,1,\"\"],[13025,1,\"\"],[13026,1,\"\"],[13027,1,\"\"],[13028,1,\"\"],[13029,1,\"\"],[13030,1,\"\"],[13031,1,\"\"],[13032,1,\"\"],[13033,1,\"\"],[13034,1,\"\"],[13035,1,\"\"],[13036,1,\"\"],[13037,1,\"\"],[13038,1,\"\"],[13039,1,\"\"],[13040,1,\"\"],[13041,1,\"\"],[13042,1,\"\"],[13043,1,\"\"],[13044,1,\"\"],[13045,1,\"\"],[13046,1,\"\"],[13047,1,\"\"],[13048,1,\"\"],[13049,1,\"\"],[13050,1,\"\"],[13051,1,\"\"],[13052,1,\"\"],[13053,1,\"\"],[13054,1,\"\"],[13055,1,\"\"],[13056,1,\"\"],[13057,1,\"\"],[13058,1,\"\"],[13059,1,\"\"],[13060,1,\"\"],[13061,1,\"\"],[13062,1,\"\"],[13063,1,\"\"],[13064,1,\"\"],[13065,1,\"\"],[13066,1,\"\"],[13067,1,\"\"],[13068,1,\"\"],[13069,1,\"\"],[13070,1,\"\"],[13071,1,\"\"],[13072,1,\"\"],[13073,1,\"\"],[13074,1,\"\"],[13075,1,\"\"],[13076,1,\"\"],[13077,1,\"\"],[13078,1,\"\"],[13079,1,\"\"],[13080,1,\"\"],[13081,1,\"\"],[13082,1,\"\"],[13083,1,\"\"],[13084,1,\"\"],[13085,1,\"\"],[13086,1,\"\"],[13087,1,\"\"],[13088,1,\"\"],[13089,1,\"\"],[13090,1,\"\"],[13091,1,\"\"],[13092,1,\"\"],[13093,1,\"\"],[13094,1,\"\"],[13095,1,\"\"],[13096,1,\"\"],[13097,1,\"\"],[13098,1,\"\"],[13099,1,\"\"],[13100,1,\"\"],[13101,1,\"\"],[13102,1,\"\"],[13103,1,\"\"],[13104,1,\"\"],[13105,1,\"\"],[13106,1,\"\"],[13107,1,\"\"],[13108,1,\"\"],[13109,1,\"\"],[13110,1,\"\"],[13111,1,\"\"],[13112,1,\"\"],[13113,1,\"\"],[13114,1,\"\"],[13115,1,\"\"],[13116,1,\"\"],[13117,1,\"\"],[13118,1,\"\"],[13119,1,\"\"],[13120,1,\"\"],[13121,1,\"\"],[13122,1,\"\"],[13123,1,\"\"],[13124,1,\"\"],[13125,1,\"\"],[13126,1,\"\"],[13127,1,\"\"],[13128,1,\"\"],[13129,1,\"\"],[13130,1,\"\"],[13131,1,\"\"],[13132,1,\"\"],[13133,1,\"\"],[13134,1,\"\"],[13135,1,\"\"],[13136,1,\"\"],[13137,1,\"\"],[13138,1,\"\"],[13139,1,\"\"],[13140,1,\"\"],[13141,1,\"\"],[13142,1,\"\"],[13143,1,\"\"],[13144,1,\"0\"],[13145,1,\"1\"],[13146,1,\"2\"],[13147,1,\"3\"],[13148,1,\"4\"],[13149,1,\"5\"],[13150,1,\"6\"],[13151,1,\"7\"],[13152,1,\"8\"],[13153,1,\"9\"],[13154,1,\"10\"],[13155,1,\"11\"],[13156,1,\"12\"],[13157,1,\"13\"],[13158,1,\"14\"],[13159,1,\"15\"],[13160,1,\"16\"],[13161,1,\"17\"],[13162,1,\"18\"],[13163,1,\"19\"],[13164,1,\"20\"],[13165,1,\"21\"],[13166,1,\"22\"],[13167,1,\"23\"],[13168,1,\"24\"],[13169,1,\"hpa\"],[13170,1,\"da\"],[13171,1,\"au\"],[13172,1,\"bar\"],[13173,1,\"ov\"],[13174,1,\"pc\"],[13175,1,\"dm\"],[13176,1,\"dm2\"],[13177,1,\"dm3\"],[13178,1,\"iu\"],[13179,1,\"\"],[13180,1,\"\"],[13181,1,\"\"],[13182,1,\"\"],[13183,1,\"\"],[13184,1,\"pa\"],[13185,1,\"na\"],[13186,1,\"a\"],[13187,1,\"ma\"],[13188,1,\"ka\"],[13189,1,\"kb\"],[13190,1,\"mb\"],[13191,1,\"gb\"],[13192,1,\"cal\"],[13193,1,\"kcal\"],[13194,1,\"pf\"],[13195,1,\"nf\"],[13196,1,\"f\"],[13197,1,\"g\"],[13198,1,\"mg\"],[13199,1,\"kg\"],[13200,1,\"hz\"],[13201,1,\"khz\"],[13202,1,\"mhz\"],[13203,1,\"ghz\"],[13204,1,\"thz\"],[13205,1,\"l\"],[13206,1,\"ml\"],[13207,1,\"dl\"],[13208,1,\"kl\"],[13209,1,\"fm\"],[13210,1,\"nm\"],[13211,1,\"m\"],[13212,1,\"mm\"],[13213,1,\"cm\"],[13214,1,\"km\"],[13215,1,\"mm2\"],[13216,1,\"cm2\"],[13217,1,\"m2\"],[13218,1,\"km2\"],[13219,1,\"mm3\"],[13220,1,\"cm3\"],[13221,1,\"m3\"],[13222,1,\"km3\"],[13223,1,\"ms\"],[13224,1,\"ms2\"],[13225,1,\"pa\"],[13226,1,\"kpa\"],[13227,1,\"mpa\"],[13228,1,\"gpa\"],[13229,1,\"rad\"],[13230,1,\"rads\"],[13231,1,\"rads2\"],[13232,1,\"ps\"],[13233,1,\"ns\"],[13234,1,\"s\"],[13235,1,\"ms\"],[13236,1,\"pv\"],[13237,1,\"nv\"],[13238,1,\"v\"],[13239,1,\"mv\"],[13240,1,\"kv\"],[13241,1,\"mv\"],[13242,1,\"pw\"],[13243,1,\"nw\"],[13244,1,\"w\"],[13245,1,\"mw\"],[13246,1,\"kw\"],[13247,1,\"mw\"],[13248,1,\"k\"],[13249,1,\"m\"],[13250,3],[13251,1,\"bq\"],[13252,1,\"cc\"],[13253,1,\"cd\"],[13254,1,\"ckg\"],[13255,3],[13256,1,\"db\"],[13257,1,\"gy\"],[13258,1,\"ha\"],[13259,1,\"hp\"],[13260,1,\"in\"],[13261,1,\"kk\"],[13262,1,\"km\"],[13263,1,\"kt\"],[13264,1,\"lm\"],[13265,1,\"ln\"],[13266,1,\"log\"],[13267,1,\"lx\"],[13268,1,\"mb\"],[13269,1,\"mil\"],[13270,1,\"mol\"],[13271,1,\"ph\"],[13272,3],[13273,1,\"ppm\"],[13274,1,\"pr\"],[13275,1,\"sr\"],[13276,1,\"sv\"],[13277,1,\"wb\"],[13278,1,\"vm\"],[13279,1,\"am\"],[13280,1,\"1\"],[13281,1,\"2\"],[13282,1,\"3\"],[13283,1,\"4\"],[13284,1,\"5\"],[13285,1,\"6\"],[13286,1,\"7\"],[13287,1,\"8\"],[13288,1,\"9\"],[13289,1,\"10\"],[13290,1,\"11\"],[13291,1,\"12\"],[13292,1,\"13\"],[13293,1,\"14\"],[13294,1,\"15\"],[13295,1,\"16\"],[13296,1,\"17\"],[13297,1,\"18\"],[13298,1,\"19\"],[13299,1,\"20\"],[13300,1,\"21\"],[13301,1,\"22\"],[13302,1,\"23\"],[13303,1,\"24\"],[13304,1,\"25\"],[13305,1,\"26\"],[13306,1,\"27\"],[13307,1,\"28\"],[13308,1,\"29\"],[13309,1,\"30\"],[13310,1,\"31\"],[13311,1,\"gal\"],[[13312,19893],2],[[19894,19903],2],[[19904,19967],2],[[19968,40869],2],[[40870,40891],2],[[40892,40899],2],[[40900,40907],2],[40908,2],[[40909,40917],2],[[40918,40938],2],[[40939,40943],2],[[40944,40956],2],[[40957,40959],2],[[40960,42124],2],[[42125,42127],3],[[42128,42145],2],[[42146,42147],2],[[42148,42163],2],[42164,2],[[42165,42176],2],[42177,2],[[42178,42180],2],[42181,2],[42182,2],[[42183,42191],3],[[42192,42237],2],[[42238,42239],2],[[42240,42508],2],[[42509,42511],2],[[42512,42539],2],[[42540,42559],3],[42560,1,\"\"],[42561,2],[42562,1,\"\"],[42563,2],[42564,1,\"\"],[42565,2],[42566,1,\"\"],[42567,2],[42568,1,\"\"],[42569,2],[42570,1,\"\"],[42571,2],[42572,1,\"\"],[42573,2],[42574,1,\"\"],[42575,2],[42576,1,\"\"],[42577,2],[42578,1,\"\"],[42579,2],[42580,1,\"\"],[42581,2],[42582,1,\"\"],[42583,2],[42584,1,\"\"],[42585,2],[42586,1,\"\"],[42587,2],[42588,1,\"\"],[42589,2],[42590,1,\"\"],[42591,2],[42592,1,\"\"],[42593,2],[42594,1,\"\"],[42595,2],[42596,1,\"\"],[42597,2],[42598,1,\"\"],[42599,2],[42600,1,\"\"],[42601,2],[42602,1,\"\"],[42603,2],[42604,1,\"\"],[[42605,42607],2],[[42608,42611],2],[[42612,42619],2],[[42620,42621],2],[42622,2],[42623,2],[42624,1,\"\"],[42625,2],[42626,1,\"\"],[42627,2],[42628,1,\"\"],[42629,2],[42630,1,\"\"],[42631,2],[42632,1,\"\"],[42633,2],[42634,1,\"\"],[42635,2],[42636,1,\"\"],[42637,2],[42638,1,\"\"],[42639,2],[42640,1,\"\"],[42641,2],[42642,1,\"\"],[42643,2],[42644,1,\"\"],[42645,2],[42646,1,\"\"],[42647,2],[42648,1,\"\"],[42649,2],[42650,1,\"\"],[42651,2],[42652,1,\"\"],[42653,1,\"\"],[42654,2],[42655,2],[[42656,42725],2],[[42726,42735],2],[[42736,42737],2],[[42738,42743],2],[[42744,42751],3],[[42752,42774],2],[[42775,42778],2],[[42779,42783],2],[[42784,42785],2],[42786,1,\"\"],[42787,2],[42788,1,\"\"],[42789,2],[42790,1,\"\"],[42791,2],[42792,1,\"\"],[42793,2],[42794,1,\"\"],[42795,2],[42796,1,\"\"],[42797,2],[42798,1,\"\"],[[42799,42801],2],[42802,1,\"\"],[42803,2],[42804,1,\"\"],[42805,2],[42806,1,\"\"],[42807,2],[42808,1,\"\"],[42809,2],[42810,1,\"\"],[42811,2],[42812,1,\"\"],[42813,2],[42814,1,\"\"],[42815,2],[42816,1,\"\"],[42817,2],[42818,1,\"\"],[42819,2],[42820,1,\"\"],[42821,2],[42822,1,\"\"],[42823,2],[42824,1,\"\"],[42825,2],[42826,1,\"\"],[42827,2],[42828,1,\"\"],[42829,2],[42830,1,\"\"],[42831,2],[42832,1,\"\"],[42833,2],[42834,1,\"\"],[42835,2],[42836,1,\"\"],[42837,2],[42838,1,\"\"],[42839,2],[42840,1,\"\"],[42841,2],[42842,1,\"\"],[42843,2],[42844,1,\"\"],[42845,2],[42846,1,\"\"],[42847,2],[42848,1,\"\"],[42849,2],[42850,1,\"\"],[42851,2],[42852,1,\"\"],[42853,2],[42854,1,\"\"],[42855,2],[42856,1,\"\"],[42857,2],[42858,1,\"\"],[42859,2],[42860,1,\"\"],[42861,2],[42862,1,\"\"],[42863,2],[42864,1,\"\"],[[42865,42872],2],[42873,1,\"\"],[42874,2],[42875,1,\"\"],[42876,2],[42877,1,\"\"],[42878,1,\"\"],[42879,2],[42880,1,\"\"],[42881,2],[42882,1,\"\"],[42883,2],[42884,1,\"\"],[42885,2],[42886,1,\"\"],[[42887,42888],2],[[42889,42890],2],[42891,1,\"\"],[42892,2],[42893,1,\"\"],[42894,2],[42895,2],[42896,1,\"\"],[42897,2],[42898,1,\"\"],[42899,2],[[42900,42901],2],[42902,1,\"\"],[42903,2],[42904,1,\"\"],[42905,2],[42906,1,\"\"],[42907,2],[42908,1,\"\"],[42909,2],[42910,1,\"\"],[42911,2],[42912,1,\"\"],[42913,2],[42914,1,\"\"],[42915,2],[42916,1,\"\"],[42917,2],[42918,1,\"\"],[42919,2],[42920,1,\"\"],[42921,2],[42922,1,\"\"],[42923,1,\"\"],[42924,1,\"\"],[42925,1,\"\"],[42926,1,\"\"],[42927,2],[42928,1,\"\"],[42929,1,\"\"],[42930,1,\"\"],[42931,1,\"\"],[42932,1,\"\"],[42933,2],[42934,1,\"\"],[42935,2],[42936,1,\"\"],[42937,2],[42938,1,\"\"],[42939,2],[42940,1,\"\"],[42941,2],[42942,1,\"\"],[42943,2],[42944,1,\"\"],[42945,2],[42946,1,\"\"],[42947,2],[42948,1,\"\"],[42949,1,\"\"],[42950,1,\"\"],[42951,1,\"\"],[42952,2],[42953,1,\"\"],[42954,2],[[42955,42959],3],[42960,1,\"\"],[42961,2],[42962,3],[42963,2],[42964,3],[42965,2],[42966,1,\"\"],[42967,2],[42968,1,\"\"],[42969,2],[[42970,42993],3],[42994,1,\"c\"],[42995,1,\"f\"],[42996,1,\"q\"],[42997,1,\"\"],[42998,2],[42999,2],[43000,1,\"\"],[43001,1,\"\"],[43002,2],[[43003,43007],2],[[43008,43047],2],[[43048,43051],2],[43052,2],[[43053,43055],3],[[43056,43065],2],[[43066,43071],3],[[43072,43123],2],[[43124,43127],2],[[43128,43135],3],[[43136,43204],2],[43205,2],[[43206,43213],3],[[43214,43215],2],[[43216,43225],2],[[43226,43231],3],[[43232,43255],2],[[43256,43258],2],[43259,2],[43260,2],[43261,2],[[43262,43263],2],[[43264,43309],2],[[43310,43311],2],[[43312,43347],2],[[43348,43358],3],[43359,2],[[43360,43388],2],[[43389,43391],3],[[43392,43456],2],[[43457,43469],2],[43470,3],[[43471,43481],2],[[43482,43485],3],[[43486,43487],2],[[43488,43518],2],[43519,3],[[43520,43574],2],[[43575,43583],3],[[43584,43597],2],[[43598,43599],3],[[43600,43609],2],[[43610,43611],3],[[43612,43615],2],[[43616,43638],2],[[43639,43641],2],[[43642,43643],2],[[43644,43647],2],[[43648,43714],2],[[43715,43738],3],[[43739,43741],2],[[43742,43743],2],[[43744,43759],2],[[43760,43761],2],[[43762,43766],2],[[43767,43776],3],[[43777,43782],2],[[43783,43784],3],[[43785,43790],2],[[43791,43792],3],[[43793,43798],2],[[43799,43807],3],[[43808,43814],2],[43815,3],[[43816,43822],2],[43823,3],[[43824,43866],2],[43867,2],[43868,1,\"\"],[43869,1,\"\"],[43870,1,\"\"],[43871,1,\"\"],[[43872,43875],2],[[43876,43877],2],[[43878,43879],2],[43880,2],[43881,1,\"\"],[[43882,43883],2],[[43884,43887],3],[43888,1,\"\"],[43889,1,\"\"],[43890,1,\"\"],[43891,1,\"\"],[43892,1,\"\"],[43893,1,\"\"],[43894,1,\"\"],[43895,1,\"\"],[43896,1,\"\"],[43897,1,\"\"],[43898,1,\"\"],[43899,1,\"\"],[43900,1,\"\"],[43901,1,\"\"],[43902,1,\"\"],[43903,1,\"\"],[43904,1,\"\"],[43905,1,\"\"],[43906,1,\"\"],[43907,1,\"\"],[43908,1,\"\"],[43909,1,\"\"],[43910,1,\"\"],[43911,1,\"\"],[43912,1,\"\"],[43913,1,\"\"],[43914,1,\"\"],[43915,1,\"\"],[43916,1,\"\"],[43917,1,\"\"],[43918,1,\"\"],[43919,1,\"\"],[43920,1,\"\"],[43921,1,\"\"],[43922,1,\"\"],[43923,1,\"\"],[43924,1,\"\"],[43925,1,\"\"],[43926,1,\"\"],[43927,1,\"\"],[43928,1,\"\"],[43929,1,\"\"],[43930,1,\"\"],[43931,1,\"\"],[43932,1,\"\"],[43933,1,\"\"],[43934,1,\"\"],[43935,1,\"\"],[43936,1,\"\"],[43937,1,\"\"],[43938,1,\"\"],[43939,1,\"\"],[43940,1,\"\"],[43941,1,\"\"],[43942,1,\"\"],[43943,1,\"\"],[43944,1,\"\"],[43945,1,\"\"],[43946,1,\"\"],[43947,1,\"\"],[43948,1,\"\"],[43949,1,\"\"],[43950,1,\"\"],[43951,1,\"\"],[43952,1,\"\"],[43953,1,\"\"],[43954,1,\"\"],[43955,1,\"\"],[43956,1,\"\"],[43957,1,\"\"],[43958,1,\"\"],[43959,1,\"\"],[43960,1,\"\"],[43961,1,\"\"],[43962,1,\"\"],[43963,1,\"\"],[43964,1,\"\"],[43965,1,\"\"],[43966,1,\"\"],[43967,1,\"\"],[[43968,44010],2],[44011,2],[[44012,44013],2],[[44014,44015],3],[[44016,44025],2],[[44026,44031],3],[[44032,55203],2],[[55204,55215],3],[[55216,55238],2],[[55239,55242],3],[[55243,55291],2],[[55292,55295],3],[[55296,57343],3],[[57344,63743],3],[63744,1,\"\"],[63745,1,\"\"],[63746,1,\"\"],[63747,1,\"\"],[63748,1,\"\"],[63749,1,\"\"],[63750,1,\"\"],[[63751,63752],1,\"\"],[63753,1,\"\"],[63754,1,\"\"],[63755,1,\"\"],[63756,1,\"\"],[63757,1,\"\"],[63758,1,\"\"],[63759,1,\"\"],[63760,1,\"\"],[63761,1,\"\"],[63762,1,\"\"],[63763,1,\"\"],[63764,1,\"\"],[63765,1,\"\"],[63766,1,\"\"],[63767,1,\"\"],[63768,1,\"\"],[63769,1,\"\"],[63770,1,\"\"],[63771,1,\"\"],[63772,1,\"\"],[63773,1,\"\"],[63774,1,\"\"],[63775,1,\"\"],[63776,1,\"\"],[63777,1,\"\"],[63778,1,\"\"],[63779,1,\"\"],[63780,1,\"\"],[63781,1,\"\"],[63782,1,\"\"],[63783,1,\"\"],[63784,1,\"\"],[63785,1,\"\"],[63786,1,\"\"],[63787,1,\"\"],[63788,1,\"\"],[63789,1,\"\"],[63790,1,\"\"],[63791,1,\"\"],[63792,1,\"\"],[63793,1,\"\"],[63794,1,\"\"],[63795,1,\"\"],[63796,1,\"\"],[63797,1,\"\"],[63798,1,\"\"],[63799,1,\"\"],[63800,1,\"\"],[63801,1,\"\"],[63802,1,\"\"],[63803,1,\"\"],[63804,1,\"\"],[63805,1,\"\"],[63806,1,\"\"],[63807,1,\"\"],[63808,1,\"\"],[63809,1,\"\"],[63810,1,\"\"],[63811,1,\"\"],[63812,1,\"\"],[63813,1,\"\"],[63814,1,\"\"],[63815,1,\"\"],[63816,1,\"\"],[63817,1,\"\"],[63818,1,\"\"],[63819,1,\"\"],[63820,1,\"\"],[63821,1,\"\"],[63822,1,\"\"],[63823,1,\"\"],[63824,1,\"\"],[63825,1,\"\"],[63826,1,\"\"],[63827,1,\"\"],[63828,1,\"\"],[63829,1,\"\"],[63830,1,\"\"],[63831,1,\"\"],[63832,1,\"\"],[63833,1,\"\"],[63834,1,\"\"],[63835,1,\"\"],[63836,1,\"\"],[63837,1,\"\"],[63838,1,\"\"],[63839,1,\"\"],[63840,1,\"\"],[63841,1,\"\"],[63842,1,\"\"],[63843,1,\"\"],[63844,1,\"\"],[63845,1,\"\"],[63846,1,\"\"],[63847,1,\"\"],[63848,1,\"\"],[63849,1,\"\"],[63850,1,\"\"],[63851,1,\"\"],[63852,1,\"\"],[63853,1,\"\"],[63854,1,\"\"],[63855,1,\"\"],[63856,1,\"\"],[63857,1,\"\"],[63858,1,\"\"],[63859,1,\"\"],[63860,1,\"\"],[63861,1,\"\"],[63862,1,\"\"],[63863,1,\"\"],[63864,1,\"\"],[63865,1,\"\"],[63866,1,\"\"],[63867,1,\"\"],[63868,1,\"\"],[63869,1,\"\"],[63870,1,\"\"],[63871,1,\"\"],[63872,1,\"\"],[63873,1,\"\"],[63874,1,\"\"],[63875,1,\"\"],[63876,1,\"\"],[63877,1,\"\"],[63878,1,\"\"],[63879,1,\"\"],[63880,1,\"\"],[63881,1,\"\"],[63882,1,\"\"],[63883,1,\"\"],[63884,1,\"\"],[63885,1,\"\"],[63886,1,\"\"],[63887,1,\"\"],[63888,1,\"\"],[63889,1,\"\"],[63890,1,\"\"],[63891,1,\"\"],[63892,1,\"\"],[63893,1,\"\"],[63894,1,\"\"],[63895,1,\"\"],[63896,1,\"\"],[63897,1,\"\"],[63898,1,\"\"],[63899,1,\"\"],[63900,1,\"\"],[63901,1,\"\"],[63902,1,\"\"],[63903,1,\"\"],[63904,1,\"\"],[63905,1,\"\"],[63906,1,\"\"],[63907,1,\"\"],[63908,1,\"\"],[63909,1,\"\"],[63910,1,\"\"],[63911,1,\"\"],[63912,1,\"\"],[63913,1,\"\"],[63914,1,\"\"],[63915,1,\"\"],[63916,1,\"\"],[63917,1,\"\"],[63918,1,\"\"],[63919,1,\"\"],[63920,1,\"\"],[63921,1,\"\"],[63922,1,\"\"],[63923,1,\"\"],[63924,1,\"\"],[63925,1,\"\"],[63926,1,\"\"],[63927,1,\"\"],[63928,1,\"\"],[63929,1,\"\"],[63930,1,\"\"],[63931,1,\"\"],[63932,1,\"\"],[63933,1,\"\"],[63934,1,\"\"],[63935,1,\"\"],[63936,1,\"\"],[63937,1,\"\"],[63938,1,\"\"],[63939,1,\"\"],[63940,1,\"\"],[63941,1,\"\"],[63942,1,\"\"],[63943,1,\"\"],[63944,1,\"\"],[63945,1,\"\"],[63946,1,\"\"],[63947,1,\"\"],[63948,1,\"\"],[63949,1,\"\"],[63950,1,\"\"],[63951,1,\"\"],[63952,1,\"\"],[63953,1,\"\"],[63954,1,\"\"],[63955,1,\"\"],[63956,1,\"\"],[63957,1,\"\"],[63958,1,\"\"],[63959,1,\"\"],[63960,1,\"\"],[63961,1,\"\"],[63962,1,\"\"],[63963,1,\"\"],[63964,1,\"\"],[63965,1,\"\"],[63966,1,\"\"],[63967,1,\"\"],[63968,1,\"\"],[63969,1,\"\"],[63970,1,\"\"],[63971,1,\"\"],[63972,1,\"\"],[63973,1,\"\"],[63974,1,\"\"],[63975,1,\"\"],[63976,1,\"\"],[63977,1,\"\"],[63978,1,\"\"],[63979,1,\"\"],[63980,1,\"\"],[63981,1,\"\"],[63982,1,\"\"],[63983,1,\"\"],[63984,1,\"\"],[63985,1,\"\"],[63986,1,\"\"],[63987,1,\"\"],[63988,1,\"\"],[63989,1,\"\"],[63990,1,\"\"],[63991,1,\"\"],[63992,1,\"\"],[63993,1,\"\"],[63994,1,\"\"],[63995,1,\"\"],[63996,1,\"\"],[63997,1,\"\"],[63998,1,\"\"],[63999,1,\"\"],[64000,1,\"\"],[64001,1,\"\"],[64002,1,\"\"],[64003,1,\"\"],[64004,1,\"\"],[64005,1,\"\"],[64006,1,\"\"],[64007,1,\"\"],[64008,1,\"\"],[64009,1,\"\"],[64010,1,\"\"],[64011,1,\"\"],[64012,1,\"\"],[64013,1,\"\"],[[64014,64015],2],[64016,1,\"\"],[64017,2],[64018,1,\"\"],[[64019,64020],2],[64021,1,\"\"],[64022,1,\"\"],[64023,1,\"\"],[64024,1,\"\"],[64025,1,\"\"],[64026,1,\"\"],[64027,1,\"\"],[64028,1,\"\"],[64029,1,\"\"],[64030,1,\"\"],[64031,2],[64032,1,\"\"],[64033,2],[64034,1,\"\"],[[64035,64036],2],[64037,1,\"\"],[64038,1,\"\"],[[64039,64041],2],[64042,1,\"\"],[64043,1,\"\"],[64044,1,\"\"],[64045,1,\"\"],[64046,1,\"\"],[64047,1,\"\"],[64048,1,\"\"],[64049,1,\"\"],[64050,1,\"\"],[64051,1,\"\"],[64052,1,\"\"],[64053,1,\"\"],[64054,1,\"\"],[64055,1,\"\"],[64056,1,\"\"],[64057,1,\"\"],[64058,1,\"\"],[64059,1,\"\"],[64060,1,\"\"],[64061,1,\"\"],[64062,1,\"\"],[64063,1,\"\"],[64064,1,\"\"],[64065,1,\"\"],[64066,1,\"\"],[64067,1,\"\"],[64068,1,\"\"],[64069,1,\"\"],[64070,1,\"\"],[64071,1,\"\"],[64072,1,\"\"],[64073,1,\"\"],[64074,1,\"\"],[64075,1,\"\"],[64076,1,\"\"],[64077,1,\"\"],[64078,1,\"\"],[64079,1,\"\"],[64080,1,\"\"],[64081,1,\"\"],[64082,1,\"\"],[64083,1,\"\"],[64084,1,\"\"],[64085,1,\"\"],[64086,1,\"\"],[64087,1,\"\"],[64088,1,\"\"],[64089,1,\"\"],[64090,1,\"\"],[64091,1,\"\"],[64092,1,\"\"],[[64093,64094],1,\"\"],[64095,1,\"\"],[64096,1,\"\"],[64097,1,\"\"],[64098,1,\"\"],[64099,1,\"\"],[64100,1,\"\"],[64101,1,\"\"],[64102,1,\"\"],[64103,1,\"\"],[64104,1,\"\"],[64105,1,\"\"],[64106,1,\"\"],[64107,1,\"\"],[64108,1,\"\"],[64109,1,\"\"],[[64110,64111],3],[64112,1,\"\"],[64113,1,\"\"],[64114,1,\"\"],[64115,1,\"\"],[64116,1,\"\"],[64117,1,\"\"],[64118,1,\"\"],[64119,1,\"\"],[64120,1,\"\"],[64121,1,\"\"],[64122,1,\"\"],[64123,1,\"\"],[64124,1,\"\"],[64125,1,\"\"],[64126,1,\"\"],[64127,1,\"\"],[64128,1,\"\"],[64129,1,\"\"],[64130,1,\"\"],[64131,1,\"\"],[64132,1,\"\"],[64133,1,\"\"],[64134,1,\"\"],[64135,1,\"\"],[64136,1,\"\"],[64137,1,\"\"],[64138,1,\"\"],[64139,1,\"\"],[64140,1,\"\"],[64141,1,\"\"],[64142,1,\"\"],[64143,1,\"\"],[64144,1,\"\"],[64145,1,\"\"],[64146,1,\"\"],[64147,1,\"\"],[64148,1,\"\"],[64149,1,\"\"],[64150,1,\"\"],[64151,1,\"\"],[64152,1,\"\"],[64153,1,\"\"],[64154,1,\"\"],[64155,1,\"\"],[64156,1,\"\"],[64157,1,\"\"],[64158,1,\"\"],[64159,1,\"\"],[64160,1,\"\"],[64161,1,\"\"],[64162,1,\"\"],[64163,1,\"\"],[64164,1,\"\"],[64165,1,\"\"],[64166,1,\"\"],[64167,1,\"\"],[64168,1,\"\"],[64169,1,\"\"],[64170,1,\"\"],[64171,1,\"\"],[64172,1,\"\"],[64173,1,\"\"],[64174,1,\"\"],[64175,1,\"\"],[64176,1,\"\"],[64177,1,\"\"],[64178,1,\"\"],[64179,1,\"\"],[64180,1,\"\"],[64181,1,\"\"],[64182,1,\"\"],[64183,1,\"\"],[64184,1,\"\"],[64185,1,\"\"],[64186,1,\"\"],[64187,1,\"\"],[64188,1,\"\"],[64189,1,\"\"],[64190,1,\"\"],[64191,1,\"\"],[64192,1,\"\"],[64193,1,\"\"],[64194,1,\"\"],[64195,1,\"\"],[64196,1,\"\"],[64197,1,\"\"],[64198,1,\"\"],[64199,1,\"\"],[64200,1,\"\"],[64201,1,\"\"],[64202,1,\"\"],[64203,1,\"\"],[64204,1,\"\"],[64205,1,\"\"],[64206,1,\"\"],[64207,1,\"\"],[64208,1,\"\"],[64209,1,\"\"],[64210,1,\"\"],[64211,1,\"\"],[64212,1,\"\"],[64213,1,\"\"],[64214,1,\"\"],[64215,1,\"\"],[64216,1,\"\"],[64217,1,\"\"],[[64218,64255],3],[64256,1,\"ff\"],[64257,1,\"fi\"],[64258,1,\"fl\"],[64259,1,\"ffi\"],[64260,1,\"ffl\"],[[64261,64262],1,\"st\"],[[64263,64274],3],[64275,1,\"\"],[64276,1,\"\"],[64277,1,\"\"],[64278,1,\"\"],[64279,1,\"\"],[[64280,64284],3],[64285,1,\"\"],[64286,2],[64287,1,\"\"],[64288,1,\"\"],[64289,1,\"\"],[64290,1,\"\"],[64291,1,\"\"],[64292,1,\"\"],[64293,1,\"\"],[64294,1,\"\"],[64295,1,\"\"],[64296,1,\"\"],[64297,5,\"+\"],[64298,1,\"\"],[64299,1,\"\"],[64300,1,\"\"],[64301,1,\"\"],[64302,1,\"\"],[64303,1,\"\"],[64304,1,\"\"],[64305,1,\"\"],[64306,1,\"\"],[64307,1,\"\"],[64308,1,\"\"],[64309,1,\"\"],[64310,1,\"\"],[64311,3],[64312,1,\"\"],[64313,1,\"\"],[64314,1,\"\"],[64315,1,\"\"],[64316,1,\"\"],[64317,3],[64318,1,\"\"],[64319,3],[64320,1,\"\"],[64321,1,\"\"],[64322,3],[64323,1,\"\"],[64324,1,\"\"],[64325,3],[64326,1,\"\"],[64327,1,\"\"],[64328,1,\"\"],[64329,1,\"\"],[64330,1,\"\"],[64331,1,\"\"],[64332,1,\"\"],[64333,1,\"\"],[64334,1,\"\"],[64335,1,\"\"],[[64336,64337],1,\"\"],[[64338,64341],1,\"\"],[[64342,64345],1,\"\"],[[64346,64349],1,\"\"],[[64350,64353],1,\"\"],[[64354,64357],1,\"\"],[[64358,64361],1,\"\"],[[64362,64365],1,\"\"],[[64366,64369],1,\"\"],[[64370,64373],1,\"\"],[[64374,64377],1,\"\"],[[64378,64381],1,\"\"],[[64382,64385],1,\"\"],[[64386,64387],1,\"\"],[[64388,64389],1,\"\"],[[64390,64391],1,\"\"],[[64392,64393],1,\"\"],[[64394,64395],1,\"\"],[[64396,64397],1,\"\"],[[64398,64401],1,\"\"],[[64402,64405],1,\"\"],[[64406,64409],1,\"\"],[[64410,64413],1,\"\"],[[64414,64415],1,\"\"],[[64416,64419],1,\"\"],[[64420,64421],1,\"\"],[[64422,64425],1,\"\"],[[64426,64429],1,\"\"],[[64430,64431],1,\"\"],[[64432,64433],1,\"\"],[[64434,64449],2],[64450,2],[[64451,64466],3],[[64467,64470],1,\"\"],[[64471,64472],1,\"\"],[[64473,64474],1,\"\"],[[64475,64476],1,\"\"],[64477,1,\"\"],[[64478,64479],1,\"\"],[[64480,64481],1,\"\"],[[64482,64483],1,\"\"],[[64484,64487],1,\"\"],[[64488,64489],1,\"\"],[[64490,64491],1,\"\"],[[64492,64493],1,\"\"],[[64494,64495],1,\"\"],[[64496,64497],1,\"\"],[[64498,64499],1,\"\"],[[64500,64501],1,\"\"],[[64502,64504],1,\"\"],[[64505,64507],1,\"\"],[[64508,64511],1,\"\"],[64512,1,\"\"],[64513,1,\"\"],[64514,1,\"\"],[64515,1,\"\"],[64516,1,\"\"],[64517,1,\"\"],[64518,1,\"\"],[64519,1,\"\"],[64520,1,\"\"],[64521,1,\"\"],[64522,1,\"\"],[64523,1,\"\"],[64524,1,\"\"],[64525,1,\"\"],[64526,1,\"\"],[64527,1,\"\"],[64528,1,\"\"],[64529,1,\"\"],[64530,1,\"\"],[64531,1,\"\"],[64532,1,\"\"],[64533,1,\"\"],[64534,1,\"\"],[64535,1,\"\"],[64536,1,\"\"],[64537,1,\"\"],[64538,1,\"\"],[64539,1,\"\"],[64540,1,\"\"],[64541,1,\"\"],[64542,1,\"\"],[64543,1,\"\"],[64544,1,\"\"],[64545,1,\"\"],[64546,1,\"\"],[64547,1,\"\"],[64548,1,\"\"],[64549,1,\"\"],[64550,1,\"\"],[64551,1,\"\"],[64552,1,\"\"],[64553,1,\"\"],[64554,1,\"\"],[64555,1,\"\"],[64556,1,\"\"],[64557,1,\"\"],[64558,1,\"\"],[64559,1,\"\"],[64560,1,\"\"],[64561,1,\"\"],[64562,1,\"\"],[64563,1,\"\"],[64564,1,\"\"],[64565,1,\"\"],[64566,1,\"\"],[64567,1,\"\"],[64568,1,\"\"],[64569,1,\"\"],[64570,1,\"\"],[64571,1,\"\"],[64572,1,\"\"],[64573,1,\"\"],[64574,1,\"\"],[64575,1,\"\"],[64576,1,\"\"],[64577,1,\"\"],[64578,1,\"\"],[64579,1,\"\"],[64580,1,\"\"],[64581,1,\"\"],[64582,1,\"\"],[64583,1,\"\"],[64584,1,\"\"],[64585,1,\"\"],[64586,1,\"\"],[64587,1,\"\"],[64588,1,\"\"],[64589,1,\"\"],[64590,1,\"\"],[64591,1,\"\"],[64592,1,\"\"],[64593,1,\"\"],[64594,1,\"\"],[64595,1,\"\"],[64596,1,\"\"],[64597,1,\"\"],[64598,1,\"\"],[64599,1,\"\"],[64600,1,\"\"],[64601,1,\"\"],[64602,1,\"\"],[64603,1,\"\"],[64604,1,\"\"],[64605,1,\"\"],[64606,5,\" \"],[64607,5,\" \"],[64608,5,\" \"],[64609,5,\" \"],[64610,5,\" \"],[64611,5,\" \"],[64612,1,\"\"],[64613,1,\"\"],[64614,1,\"\"],[64615,1,\"\"],[64616,1,\"\"],[64617,1,\"\"],[64618,1,\"\"],[64619,1,\"\"],[64620,1,\"\"],[64621,1,\"\"],[64622,1,\"\"],[64623,1,\"\"],[64624,1,\"\"],[64625,1,\"\"],[64626,1,\"\"],[64627,1,\"\"],[64628,1,\"\"],[64629,1,\"\"],[64630,1,\"\"],[64631,1,\"\"],[64632,1,\"\"],[64633,1,\"\"],[64634,1,\"\"],[64635,1,\"\"],[64636,1,\"\"],[64637,1,\"\"],[64638,1,\"\"],[64639,1,\"\"],[64640,1,\"\"],[64641,1,\"\"],[64642,1,\"\"],[64643,1,\"\"],[64644,1,\"\"],[64645,1,\"\"],[64646,1,\"\"],[64647,1,\"\"],[64648,1,\"\"],[64649,1,\"\"],[64650,1,\"\"],[64651,1,\"\"],[64652,1,\"\"],[64653,1,\"\"],[64654,1,\"\"],[64655,1,\"\"],[64656,1,\"\"],[64657,1,\"\"],[64658,1,\"\"],[64659,1,\"\"],[64660,1,\"\"],[64661,1,\"\"],[64662,1,\"\"],[64663,1,\"\"],[64664,1,\"\"],[64665,1,\"\"],[64666,1,\"\"],[64667,1,\"\"],[64668,1,\"\"],[64669,1,\"\"],[64670,1,\"\"],[64671,1,\"\"],[64672,1,\"\"],[64673,1,\"\"],[64674,1,\"\"],[64675,1,\"\"],[64676,1,\"\"],[64677,1,\"\"],[64678,1,\"\"],[64679,1,\"\"],[64680,1,\"\"],[64681,1,\"\"],[64682,1,\"\"],[64683,1,\"\"],[64684,1,\"\"],[64685,1,\"\"],[64686,1,\"\"],[64687,1,\"\"],[64688,1,\"\"],[64689,1,\"\"],[64690,1,\"\"],[64691,1,\"\"],[64692,1,\"\"],[64693,1,\"\"],[64694,1,\"\"],[64695,1,\"\"],[64696,1,\"\"],[64697,1,\"\"],[64698,1,\"\"],[64699,1,\"\"],[64700,1,\"\"],[64701,1,\"\"],[64702,1,\"\"],[64703,1,\"\"],[64704,1,\"\"],[64705,1,\"\"],[64706,1,\"\"],[64707,1,\"\"],[64708,1,\"\"],[64709,1,\"\"],[64710,1,\"\"],[64711,1,\"\"],[64712,1,\"\"],[64713,1,\"\"],[64714,1,\"\"],[64715,1,\"\"],[64716,1,\"\"],[64717,1,\"\"],[64718,1,\"\"],[64719,1,\"\"],[64720,1,\"\"],[64721,1,\"\"],[64722,1,\"\"],[64723,1,\"\"],[64724,1,\"\"],[64725,1,\"\"],[64726,1,\"\"],[64727,1,\"\"],[64728,1,\"\"],[64729,1,\"\"],[64730,1,\"\"],[64731,1,\"\"],[64732,1,\"\"],[64733,1,\"\"],[64734,1,\"\"],[64735,1,\"\"],[64736,1,\"\"],[64737,1,\"\"],[64738,1,\"\"],[64739,1,\"\"],[64740,1,\"\"],[64741,1,\"\"],[64742,1,\"\"],[64743,1,\"\"],[64744,1,\"\"],[64745,1,\"\"],[64746,1,\"\"],[64747,1,\"\"],[64748,1,\"\"],[64749,1,\"\"],[64750,1,\"\"],[64751,1,\"\"],[64752,1,\"\"],[64753,1,\"\"],[64754,1,\"\"],[64755,1,\"\"],[64756,1,\"\"],[64757,1,\"\"],[64758,1,\"\"],[64759,1,\"\"],[64760,1,\"\"],[64761,1,\"\"],[64762,1,\"\"],[64763,1,\"\"],[64764,1,\"\"],[64765,1,\"\"],[64766,1,\"\"],[64767,1,\"\"],[64768,1,\"\"],[64769,1,\"\"],[64770,1,\"\"],[64771,1,\"\"],[64772,1,\"\"],[64773,1,\"\"],[64774,1,\"\"],[64775,1,\"\"],[64776,1,\"\"],[64777,1,\"\"],[64778,1,\"\"],[64779,1,\"\"],[64780,1,\"\"],[64781,1,\"\"],[64782,1,\"\"],[64783,1,\"\"],[64784,1,\"\"],[64785,1,\"\"],[64786,1,\"\"],[64787,1,\"\"],[64788,1,\"\"],[64789,1,\"\"],[64790,1,\"\"],[64791,1,\"\"],[64792,1,\"\"],[64793,1,\"\"],[64794,1,\"\"],[64795,1,\"\"],[64796,1,\"\"],[64797,1,\"\"],[64798,1,\"\"],[64799,1,\"\"],[64800,1,\"\"],[64801,1,\"\"],[64802,1,\"\"],[64803,1,\"\"],[64804,1,\"\"],[64805,1,\"\"],[64806,1,\"\"],[64807,1,\"\"],[64808,1,\"\"],[64809,1,\"\"],[64810,1,\"\"],[64811,1,\"\"],[64812,1,\"\"],[64813,1,\"\"],[64814,1,\"\"],[64815,1,\"\"],[64816,1,\"\"],[64817,1,\"\"],[64818,1,\"\"],[64819,1,\"\"],[64820,1,\"\"],[64821,1,\"\"],[64822,1,\"\"],[64823,1,\"\"],[64824,1,\"\"],[64825,1,\"\"],[64826,1,\"\"],[64827,1,\"\"],[[64828,64829],1,\"\"],[[64830,64831],2],[[64832,64847],2],[64848,1,\"\"],[[64849,64850],1,\"\"],[64851,1,\"\"],[64852,1,\"\"],[64853,1,\"\"],[64854,1,\"\"],[64855,1,\"\"],[[64856,64857],1,\"\"],[64858,1,\"\"],[64859,1,\"\"],[64860,1,\"\"],[64861,1,\"\"],[64862,1,\"\"],[[64863,64864],1,\"\"],[64865,1,\"\"],[[64866,64867],1,\"\"],[[64868,64869],1,\"\"],[64870,1,\"\"],[[64871,64872],1,\"\"],[64873,1,\"\"],[[64874,64875],1,\"\"],[[64876,64877],1,\"\"],[64878,1,\"\"],[[64879,64880],1,\"\"],[[64881,64882],1,\"\"],[64883,1,\"\"],[64884,1,\"\"],[64885,1,\"\"],[[64886,64887],1,\"\"],[64888,1,\"\"],[64889,1,\"\"],[64890,1,\"\"],[64891,1,\"\"],[[64892,64893],1,\"\"],[64894,1,\"\"],[64895,1,\"\"],[64896,1,\"\"],[64897,1,\"\"],[64898,1,\"\"],[[64899,64900],1,\"\"],[[64901,64902],1,\"\"],[[64903,64904],1,\"\"],[64905,1,\"\"],[64906,1,\"\"],[64907,1,\"\"],[64908,1,\"\"],[64909,1,\"\"],[64910,1,\"\"],[64911,1,\"\"],[[64912,64913],3],[64914,1,\"\"],[64915,1,\"\"],[64916,1,\"\"],[64917,1,\"\"],[64918,1,\"\"],[[64919,64920],1,\"\"],[64921,1,\"\"],[64922,1,\"\"],[64923,1,\"\"],[[64924,64925],1,\"\"],[64926,1,\"\"],[64927,1,\"\"],[64928,1,\"\"],[64929,1,\"\"],[64930,1,\"\"],[64931,1,\"\"],[64932,1,\"\"],[64933,1,\"\"],[64934,1,\"\"],[64935,1,\"\"],[64936,1,\"\"],[64937,1,\"\"],[64938,1,\"\"],[64939,1,\"\"],[64940,1,\"\"],[64941,1,\"\"],[64942,1,\"\"],[64943,1,\"\"],[64944,1,\"\"],[64945,1,\"\"],[64946,1,\"\"],[64947,1,\"\"],[64948,1,\"\"],[64949,1,\"\"],[64950,1,\"\"],[64951,1,\"\"],[64952,1,\"\"],[64953,1,\"\"],[64954,1,\"\"],[64955,1,\"\"],[64956,1,\"\"],[64957,1,\"\"],[64958,1,\"\"],[64959,1,\"\"],[64960,1,\"\"],[64961,1,\"\"],[64962,1,\"\"],[64963,1,\"\"],[64964,1,\"\"],[64965,1,\"\"],[64966,1,\"\"],[64967,1,\"\"],[[64968,64974],3],[64975,2],[[64976,65007],3],[65008,1,\"\"],[65009,1,\"\"],[65010,1,\"\"],[65011,1,\"\"],[65012,1,\"\"],[65013,1,\"\"],[65014,1,\"\"],[65015,1,\"\"],[65016,1,\"\"],[65017,1,\"\"],[65018,5,\"   \"],[65019,5,\" \"],[65020,1,\"\"],[65021,2],[[65022,65023],2],[[65024,65039],7],[65040,5,\",\"],[65041,1,\"\"],[65042,3],[65043,5,\":\"],[65044,5,\";\"],[65045,5,\"!\"],[65046,5,\"?\"],[65047,1,\"\"],[65048,1,\"\"],[65049,3],[[65050,65055],3],[[65056,65059],2],[[65060,65062],2],[[65063,65069],2],[[65070,65071],2],[65072,3],[65073,1,\"\"],[65074,1,\"\"],[[65075,65076],5,\"_\"],[65077,5,\"(\"],[65078,5,\")\"],[65079,5,\"{\"],[65080,5,\"}\"],[65081,1,\"\"],[65082,1,\"\"],[65083,1,\"\"],[65084,1,\"\"],[65085,1,\"\"],[65086,1,\"\"],[65087,1,\"\"],[65088,1,\"\"],[65089,1,\"\"],[65090,1,\"\"],[65091,1,\"\"],[65092,1,\"\"],[[65093,65094],2],[65095,5,\"[\"],[65096,5,\"]\"],[[65097,65100],5,\" \"],[[65101,65103],5,\"_\"],[65104,5,\",\"],[65105,1,\"\"],[65106,3],[65107,3],[65108,5,\";\"],[65109,5,\":\"],[65110,5,\"?\"],[65111,5,\"!\"],[65112,1,\"\"],[65113,5,\"(\"],[65114,5,\")\"],[65115,5,\"{\"],[65116,5,\"}\"],[65117,1,\"\"],[65118,1,\"\"],[65119,5,\"#\"],[65120,5,\"&\"],[65121,5,\"*\"],[65122,5,\"+\"],[65123,1,\"-\"],[65124,5,\"<\"],[65125,5,\">\"],[65126,5,\"=\"],[65127,3],[65128,5,\"\\\\\\\\\"],[65129,5,\"$\"],[65130,5,\"%\"],[65131,5,\"@\"],[[65132,65135],3],[65136,5,\" \"],[65137,1,\"\"],[65138,5,\" \"],[65139,2],[65140,5,\" \"],[65141,3],[65142,5,\" \"],[65143,1,\"\"],[65144,5,\" \"],[65145,1,\"\"],[65146,5,\" \"],[65147,1,\"\"],[65148,5,\" \"],[65149,1,\"\"],[65150,5,\" \"],[65151,1,\"\"],[65152,1,\"\"],[[65153,65154],1,\"\"],[[65155,65156],1,\"\"],[[65157,65158],1,\"\"],[[65159,65160],1,\"\"],[[65161,65164],1,\"\"],[[65165,65166],1,\"\"],[[65167,65170],1,\"\"],[[65171,65172],1,\"\"],[[65173,65176],1,\"\"],[[65177,65180],1,\"\"],[[65181,65184],1,\"\"],[[65185,65188],1,\"\"],[[65189,65192],1,\"\"],[[65193,65194],1,\"\"],[[65195,65196],1,\"\"],[[65197,65198],1,\"\"],[[65199,65200],1,\"\"],[[65201,65204],1,\"\"],[[65205,65208],1,\"\"],[[65209,65212],1,\"\"],[[65213,65216],1,\"\"],[[65217,65220],1,\"\"],[[65221,65224],1,\"\"],[[65225,65228],1,\"\"],[[65229,65232],1,\"\"],[[65233,65236],1,\"\"],[[65237,65240],1,\"\"],[[65241,65244],1,\"\"],[[65245,65248],1,\"\"],[[65249,65252],1,\"\"],[[65253,65256],1,\"\"],[[65257,65260],1,\"\"],[[65261,65262],1,\"\"],[[65263,65264],1,\"\"],[[65265,65268],1,\"\"],[[65269,65270],1,\"\"],[[65271,65272],1,\"\"],[[65273,65274],1,\"\"],[[65275,65276],1,\"\"],[[65277,65278],3],[65279,7],[65280,3],[65281,5,\"!\"],[65282,5,\"\\\\\"\"],[65283,5,\"#\"],[65284,5,\"$\"],[65285,5,\"%\"],[65286,5,\"&\"],[65287,5,\"\\'\"],[65288,5,\"(\"],[65289,5,\")\"],[65290,5,\"*\"],[65291,5,\"+\"],[65292,5,\",\"],[65293,1,\"-\"],[65294,1,\".\"],[65295,5,\"/\"],[65296,1,\"0\"],[65297,1,\"1\"],[65298,1,\"2\"],[65299,1,\"3\"],[65300,1,\"4\"],[65301,1,\"5\"],[65302,1,\"6\"],[65303,1,\"7\"],[65304,1,\"8\"],[65305,1,\"9\"],[65306,5,\":\"],[65307,5,\";\"],[65308,5,\"<\"],[65309,5,\"=\"],[65310,5,\">\"],[65311,5,\"?\"],[65312,5,\"@\"],[65313,1,\"a\"],[65314,1,\"b\"],[65315,1,\"c\"],[65316,1,\"d\"],[65317,1,\"e\"],[65318,1,\"f\"],[65319,1,\"g\"],[65320,1,\"h\"],[65321,1,\"i\"],[65322,1,\"j\"],[65323,1,\"k\"],[65324,1,\"l\"],[65325,1,\"m\"],[65326,1,\"n\"],[65327,1,\"o\"],[65328,1,\"p\"],[65329,1,\"q\"],[65330,1,\"r\"],[65331,1,\"s\"],[65332,1,\"t\"],[65333,1,\"u\"],[65334,1,\"v\"],[65335,1,\"w\"],[65336,1,\"x\"],[65337,1,\"y\"],[65338,1,\"z\"],[65339,5,\"[\"],[65340,5,\"\\\\\\\\\"],[65341,5,\"]\"],[65342,5,\"^\"],[65343,5,\"_\"],[65344,5,\"`\"],[65345,1,\"a\"],[65346,1,\"b\"],[65347,1,\"c\"],[65348,1,\"d\"],[65349,1,\"e\"],[65350,1,\"f\"],[65351,1,\"g\"],[65352,1,\"h\"],[65353,1,\"i\"],[65354,1,\"j\"],[65355,1,\"k\"],[65356,1,\"l\"],[65357,1,\"m\"],[65358,1,\"n\"],[65359,1,\"o\"],[65360,1,\"p\"],[65361,1,\"q\"],[65362,1,\"r\"],[65363,1,\"s\"],[65364,1,\"t\"],[65365,1,\"u\"],[65366,1,\"v\"],[65367,1,\"w\"],[65368,1,\"x\"],[65369,1,\"y\"],[65370,1,\"z\"],[65371,5,\"{\"],[65372,5,\"|\"],[65373,5,\"}\"],[65374,5,\"~\"],[65375,1,\"\"],[65376,1,\"\"],[65377,1,\".\"],[65378,1,\"\"],[65379,1,\"\"],[65380,1,\"\"],[65381,1,\"\"],[65382,1,\"\"],[65383,1,\"\"],[65384,1,\"\"],[65385,1,\"\"],[65386,1,\"\"],[65387,1,\"\"],[65388,1,\"\"],[65389,1,\"\"],[65390,1,\"\"],[65391,1,\"\"],[65392,1,\"\"],[65393,1,\"\"],[65394,1,\"\"],[65395,1,\"\"],[65396,1,\"\"],[65397,1,\"\"],[65398,1,\"\"],[65399,1,\"\"],[65400,1,\"\"],[65401,1,\"\"],[65402,1,\"\"],[65403,1,\"\"],[65404,1,\"\"],[65405,1,\"\"],[65406,1,\"\"],[65407,1,\"\"],[65408,1,\"\"],[65409,1,\"\"],[65410,1,\"\"],[65411,1,\"\"],[65412,1,\"\"],[65413,1,\"\"],[65414,1,\"\"],[65415,1,\"\"],[65416,1,\"\"],[65417,1,\"\"],[65418,1,\"\"],[65419,1,\"\"],[65420,1,\"\"],[65421,1,\"\"],[65422,1,\"\"],[65423,1,\"\"],[65424,1,\"\"],[65425,1,\"\"],[65426,1,\"\"],[65427,1,\"\"],[65428,1,\"\"],[65429,1,\"\"],[65430,1,\"\"],[65431,1,\"\"],[65432,1,\"\"],[65433,1,\"\"],[65434,1,\"\"],[65435,1,\"\"],[65436,1,\"\"],[65437,1,\"\"],[65438,1,\"\"],[65439,1,\"\"],[65440,3],[65441,1,\"\"],[65442,1,\"\"],[65443,1,\"\"],[65444,1,\"\"],[65445,1,\"\"],[65446,1,\"\"],[65447,1,\"\"],[65448,1,\"\"],[65449,1,\"\"],[65450,1,\"\"],[65451,1,\"\"],[65452,1,\"\"],[65453,1,\"\"],[65454,1,\"\"],[65455,1,\"\"],[65456,1,\"\"],[65457,1,\"\"],[65458,1,\"\"],[65459,1,\"\"],[65460,1,\"\"],[65461,1,\"\"],[65462,1,\"\"],[65463,1,\"\"],[65464,1,\"\"],[65465,1,\"\"],[65466,1,\"\"],[65467,1,\"\"],[65468,1,\"\"],[65469,1,\"\"],[65470,1,\"\"],[[65471,65473],3],[65474,1,\"\"],[65475,1,\"\"],[65476,1,\"\"],[65477,1,\"\"],[65478,1,\"\"],[65479,1,\"\"],[[65480,65481],3],[65482,1,\"\"],[65483,1,\"\"],[65484,1,\"\"],[65485,1,\"\"],[65486,1,\"\"],[65487,1,\"\"],[[65488,65489],3],[65490,1,\"\"],[65491,1,\"\"],[65492,1,\"\"],[65493,1,\"\"],[65494,1,\"\"],[65495,1,\"\"],[[65496,65497],3],[65498,1,\"\"],[65499,1,\"\"],[65500,1,\"\"],[[65501,65503],3],[65504,1,\"\"],[65505,1,\"\"],[65506,1,\"\"],[65507,5,\" \"],[65508,1,\"\"],[65509,1,\"\"],[65510,1,\"\"],[65511,3],[65512,1,\"\"],[65513,1,\"\"],[65514,1,\"\"],[65515,1,\"\"],[65516,1,\"\"],[65517,1,\"\"],[65518,1,\"\"],[[65519,65528],3],[[65529,65531],3],[65532,3],[65533,3],[[65534,65535],3],[[65536,65547],2],[65548,3],[[65549,65574],2],[65575,3],[[65576,65594],2],[65595,3],[[65596,65597],2],[65598,3],[[65599,65613],2],[[65614,65615],3],[[65616,65629],2],[[65630,65663],3],[[65664,65786],2],[[65787,65791],3],[[65792,65794],2],[[65795,65798],3],[[65799,65843],2],[[65844,65846],3],[[65847,65855],2],[[65856,65930],2],[[65931,65932],2],[[65933,65934],2],[65935,3],[[65936,65947],2],[65948,2],[[65949,65951],3],[65952,2],[[65953,65999],3],[[66000,66044],2],[66045,2],[[66046,66175],3],[[66176,66204],2],[[66205,66207],3],[[66208,66256],2],[[66257,66271],3],[66272,2],[[66273,66299],2],[[66300,66303],3],[[66304,66334],2],[66335,2],[[66336,66339],2],[[66340,66348],3],[[66349,66351],2],[[66352,66368],2],[66369,2],[[66370,66377],2],[66378,2],[[66379,66383],3],[[66384,66426],2],[[66427,66431],3],[[66432,66461],2],[66462,3],[66463,2],[[66464,66499],2],[[66500,66503],3],[[66504,66511],2],[[66512,66517],2],[[66518,66559],3],[66560,1,\"\"],[66561,1,\"\"],[66562,1,\"\"],[66563,1,\"\"],[66564,1,\"\"],[66565,1,\"\"],[66566,1,\"\"],[66567,1,\"\"],[66568,1,\"\"],[66569,1,\"\"],[66570,1,\"\"],[66571,1,\"\"],[66572,1,\"\"],[66573,1,\"\"],[66574,1,\"\"],[66575,1,\"\"],[66576,1,\"\"],[66577,1,\"\"],[66578,1,\"\"],[66579,1,\"\"],[66580,1,\"\"],[66581,1,\"\"],[66582,1,\"\"],[66583,1,\"\"],[66584,1,\"\"],[66585,1,\"\"],[66586,1,\"\"],[66587,1,\"\"],[66588,1,\"\"],[66589,1,\"\"],[66590,1,\"\"],[66591,1,\"\"],[66592,1,\"\"],[66593,1,\"\"],[66594,1,\"\"],[66595,1,\"\"],[66596,1,\"\"],[66597,1,\"\"],[66598,1,\"\"],[66599,1,\"\"],[[66600,66637],2],[[66638,66717],2],[[66718,66719],3],[[66720,66729],2],[[66730,66735],3],[66736,1,\"\"],[66737,1,\"\"],[66738,1,\"\"],[66739,1,\"\"],[66740,1,\"\"],[66741,1,\"\"],[66742,1,\"\"],[66743,1,\"\"],[66744,1,\"\"],[66745,1,\"\"],[66746,1,\"\"],[66747,1,\"\"],[66748,1,\"\"],[66749,1,\"\"],[66750,1,\"\"],[66751,1,\"\"],[66752,1,\"\"],[66753,1,\"\"],[66754,1,\"\"],[66755,1,\"\"],[66756,1,\"\"],[66757,1,\"\"],[66758,1,\"\"],[66759,1,\"\"],[66760,1,\"\"],[66761,1,\"\"],[66762,1,\"\"],[66763,1,\"\"],[66764,1,\"\"],[66765,1,\"\"],[66766,1,\"\"],[66767,1,\"\"],[66768,1,\"\"],[66769,1,\"\"],[66770,1,\"\"],[66771,1,\"\"],[[66772,66775],3],[[66776,66811],2],[[66812,66815],3],[[66816,66855],2],[[66856,66863],3],[[66864,66915],2],[[66916,66926],3],[66927,2],[66928,1,\"\"],[66929,1,\"\"],[66930,1,\"\"],[66931,1,\"\"],[66932,1,\"\"],[66933,1,\"\"],[66934,1,\"\"],[66935,1,\"\"],[66936,1,\"\"],[66937,1,\"\"],[66938,1,\"\"],[66939,3],[66940,1,\"\"],[66941,1,\"\"],[66942,1,\"\"],[66943,1,\"\"],[66944,1,\"\"],[66945,1,\"\"],[66946,1,\"\"],[66947,1,\"\"],[66948,1,\"\"],[66949,1,\"\"],[66950,1,\"\"],[66951,1,\"\"],[66952,1,\"\"],[66953,1,\"\"],[66954,1,\"\"],[66955,3],[66956,1,\"\"],[66957,1,\"\"],[66958,1,\"\"],[66959,1,\"\"],[66960,1,\"\"],[66961,1,\"\"],[66962,1,\"\"],[66963,3],[66964,1,\"\"],[66965,1,\"\"],[66966,3],[[66967,66977],2],[66978,3],[[66979,66993],2],[66994,3],[[66995,67001],2],[67002,3],[[67003,67004],2],[[67005,67071],3],[[67072,67382],2],[[67383,67391],3],[[67392,67413],2],[[67414,67423],3],[[67424,67431],2],[[67432,67455],3],[67456,2],[67457,1,\"\"],[67458,1,\"\"],[67459,1,\"\"],[67460,1,\"\"],[67461,1,\"\"],[67462,3],[67463,1,\"\"],[67464,1,\"\"],[67465,1,\"\"],[67466,1,\"\"],[67467,1,\"\"],[67468,1,\"\"],[67469,1,\"\"],[67470,1,\"\"],[67471,1,\"\"],[67472,1,\"\"],[67473,1,\"\"],[67474,1,\"\"],[67475,1,\"\"],[67476,1,\"\"],[67477,1,\"\"],[67478,1,\"\"],[67479,1,\"\"],[67480,1,\"\"],[67481,1,\"\"],[67482,1,\"\"],[67483,1,\"\"],[67484,1,\"\"],[67485,1,\"\"],[67486,1,\"\"],[67487,1,\"\"],[67488,1,\"\"],[67489,1,\"\"],[67490,1,\"\"],[67491,1,\"\"],[67492,1,\"\"],[67493,1,\"q\"],[67494,1,\"\"],[67495,1,\"\"],[67496,1,\"\"],[67497,1,\"\"],[67498,1,\"\"],[67499,1,\"\"],[67500,1,\"\"],[67501,1,\"\"],[67502,1,\"\"],[67503,1,\"\"],[67504,1,\"\"],[67505,3],[67506,1,\"\"],[67507,1,\"\"],[67508,1,\"\"],[67509,1,\"\"],[67510,1,\"\"],[67511,1,\"\"],[67512,1,\"\"],[67513,1,\"\"],[67514,1,\"\"],[[67515,67583],3],[[67584,67589],2],[[67590,67591],3],[67592,2],[67593,3],[[67594,67637],2],[67638,3],[[67639,67640],2],[[67641,67643],3],[67644,2],[[67645,67646],3],[67647,2],[[67648,67669],2],[67670,3],[[67671,67679],2],[[67680,67702],2],[[67703,67711],2],[[67712,67742],2],[[67743,67750],3],[[67751,67759],2],[[67760,67807],3],[[67808,67826],2],[67827,3],[[67828,67829],2],[[67830,67834],3],[[67835,67839],2],[[67840,67861],2],[[67862,67865],2],[[67866,67867],2],[[67868,67870],3],[67871,2],[[67872,67897],2],[[67898,67902],3],[67903,2],[[67904,67967],3],[[67968,68023],2],[[68024,68027],3],[[68028,68029],2],[[68030,68031],2],[[68032,68047],2],[[68048,68049],3],[[68050,68095],2],[[68096,68099],2],[68100,3],[[68101,68102],2],[[68103,68107],3],[[68108,68115],2],[68116,3],[[68117,68119],2],[68120,3],[[68121,68147],2],[[68148,68149],2],[[68150,68151],3],[[68152,68154],2],[[68155,68158],3],[68159,2],[[68160,68167],2],[68168,2],[[68169,68175],3],[[68176,68184],2],[[68185,68191],3],[[68192,68220],2],[[68221,68223],2],[[68224,68252],2],[[68253,68255],2],[[68256,68287],3],[[68288,68295],2],[68296,2],[[68297,68326],2],[[68327,68330],3],[[68331,68342],2],[[68343,68351],3],[[68352,68405],2],[[68406,68408],3],[[68409,68415],2],[[68416,68437],2],[[68438,68439],3],[[68440,68447],2],[[68448,68466],2],[[68467,68471],3],[[68472,68479],2],[[68480,68497],2],[[68498,68504],3],[[68505,68508],2],[[68509,68520],3],[[68521,68527],2],[[68528,68607],3],[[68608,68680],2],[[68681,68735],3],[68736,1,\"\"],[68737,1,\"\"],[68738,1,\"\"],[68739,1,\"\"],[68740,1,\"\"],[68741,1,\"\"],[68742,1,\"\"],[68743,1,\"\"],[68744,1,\"\"],[68745,1,\"\"],[68746,1,\"\"],[68747,1,\"\"],[68748,1,\"\"],[68749,1,\"\"],[68750,1,\"\"],[68751,1,\"\"],[68752,1,\"\"],[68753,1,\"\"],[68754,1,\"\"],[68755,1,\"\"],[68756,1,\"\"],[68757,1,\"\"],[68758,1,\"\"],[68759,1,\"\"],[68760,1,\"\"],[68761,1,\"\"],[68762,1,\"\"],[68763,1,\"\"],[68764,1,\"\"],[68765,1,\"\"],[68766,1,\"\"],[68767,1,\"\"],[68768,1,\"\"],[68769,1,\"\"],[68770,1,\"\"],[68771,1,\"\"],[68772,1,\"\"],[68773,1,\"\"],[68774,1,\"\"],[68775,1,\"\"],[68776,1,\"\"],[68777,1,\"\"],[68778,1,\"\"],[68779,1,\"\"],[68780,1,\"\"],[68781,1,\"\"],[68782,1,\"\"],[68783,1,\"\"],[68784,1,\"\"],[68785,1,\"\"],[68786,1,\"\"],[[68787,68799],3],[[68800,68850],2],[[68851,68857],3],[[68858,68863],2],[[68864,68903],2],[[68904,68911],3],[[68912,68921],2],[[68922,69215],3],[[69216,69246],2],[69247,3],[[69248,69289],2],[69290,3],[[69291,69292],2],[69293,2],[[69294,69295],3],[[69296,69297],2],[[69298,69372],3],[[69373,69375],2],[[69376,69404],2],[[69405,69414],2],[69415,2],[[69416,69423],3],[[69424,69456],2],[[69457,69465],2],[[69466,69487],3],[[69488,69509],2],[[69510,69513],2],[[69514,69551],3],[[69552,69572],2],[[69573,69579],2],[[69580,69599],3],[[69600,69622],2],[[69623,69631],3],[[69632,69702],2],[[69703,69709],2],[[69710,69713],3],[[69714,69733],2],[[69734,69743],2],[[69744,69749],2],[[69750,69758],3],[69759,2],[[69760,69818],2],[[69819,69820],2],[69821,3],[[69822,69825],2],[69826,2],[[69827,69836],3],[69837,3],[[69838,69839],3],[[69840,69864],2],[[69865,69871],3],[[69872,69881],2],[[69882,69887],3],[[69888,69940],2],[69941,3],[[69942,69951],2],[[69952,69955],2],[[69956,69958],2],[69959,2],[[69960,69967],3],[[69968,70003],2],[[70004,70005],2],[70006,2],[[70007,70015],3],[[70016,70084],2],[[70085,70088],2],[[70089,70092],2],[70093,2],[[70094,70095],2],[[70096,70105],2],[70106,2],[70107,2],[70108,2],[[70109,70111],2],[70112,3],[[70113,70132],2],[[70133,70143],3],[[70144,70161],2],[70162,3],[[70163,70199],2],[[70200,70205],2],[70206,2],[[70207,70209],2],[[70210,70271],3],[[70272,70278],2],[70279,3],[70280,2],[70281,3],[[70282,70285],2],[70286,3],[[70287,70301],2],[70302,3],[[70303,70312],2],[70313,2],[[70314,70319],3],[[70320,70378],2],[[70379,70383],3],[[70384,70393],2],[[70394,70399],3],[70400,2],[[70401,70403],2],[70404,3],[[70405,70412],2],[[70413,70414],3],[[70415,70416],2],[[70417,70418],3],[[70419,70440],2],[70441,3],[[70442,70448],2],[70449,3],[[70450,70451],2],[70452,3],[[70453,70457],2],[70458,3],[70459,2],[[70460,70468],2],[[70469,70470],3],[[70471,70472],2],[[70473,70474],3],[[70475,70477],2],[[70478,70479],3],[70480,2],[[70481,70486],3],[70487,2],[[70488,70492],3],[[70493,70499],2],[[70500,70501],3],[[70502,70508],2],[[70509,70511],3],[[70512,70516],2],[[70517,70655],3],[[70656,70730],2],[[70731,70735],2],[[70736,70745],2],[70746,2],[70747,2],[70748,3],[70749,2],[70750,2],[70751,2],[[70752,70753],2],[[70754,70783],3],[[70784,70853],2],[70854,2],[70855,2],[[70856,70863],3],[[70864,70873],2],[[70874,71039],3],[[71040,71093],2],[[71094,71095],3],[[71096,71104],2],[[71105,71113],2],[[71114,71127],2],[[71128,71133],2],[[71134,71167],3],[[71168,71232],2],[[71233,71235],2],[71236,2],[[71237,71247],3],[[71248,71257],2],[[71258,71263],3],[[71264,71276],2],[[71277,71295],3],[[71296,71351],2],[71352,2],[71353,2],[[71354,71359],3],[[71360,71369],2],[[71370,71423],3],[[71424,71449],2],[71450,2],[[71451,71452],3],[[71453,71467],2],[[71468,71471],3],[[71472,71481],2],[[71482,71487],2],[[71488,71494],2],[[71495,71679],3],[[71680,71738],2],[71739,2],[[71740,71839],3],[71840,1,\"\"],[71841,1,\"\"],[71842,1,\"\"],[71843,1,\"\"],[71844,1,\"\"],[71845,1,\"\"],[71846,1,\"\"],[71847,1,\"\"],[71848,1,\"\"],[71849,1,\"\"],[71850,1,\"\"],[71851,1,\"\"],[71852,1,\"\"],[71853,1,\"\"],[71854,1,\"\"],[71855,1,\"\"],[71856,1,\"\"],[71857,1,\"\"],[71858,1,\"\"],[71859,1,\"\"],[71860,1,\"\"],[71861,1,\"\"],[71862,1,\"\"],[71863,1,\"\"],[71864,1,\"\"],[71865,1,\"\"],[71866,1,\"\"],[71867,1,\"\"],[71868,1,\"\"],[71869,1,\"\"],[71870,1,\"\"],[71871,1,\"\"],[[71872,71913],2],[[71914,71922],2],[[71923,71934],3],[71935,2],[[71936,71942],2],[[71943,71944],3],[71945,2],[[71946,71947],3],[[71948,71955],2],[71956,3],[[71957,71958],2],[71959,3],[[71960,71989],2],[71990,3],[[71991,71992],2],[[71993,71994],3],[[71995,72003],2],[[72004,72006],2],[[72007,72015],3],[[72016,72025],2],[[72026,72095],3],[[72096,72103],2],[[72104,72105],3],[[72106,72151],2],[[72152,72153],3],[[72154,72161],2],[72162,2],[[72163,72164],2],[[72165,72191],3],[[72192,72254],2],[[72255,72262],2],[72263,2],[[72264,72271],3],[[72272,72323],2],[[72324,72325],2],[[72326,72345],2],[[72346,72348],2],[72349,2],[[72350,72354],2],[[72355,72367],3],[[72368,72383],2],[[72384,72440],2],[[72441,72447],3],[[72448,72457],2],[[72458,72703],3],[[72704,72712],2],[72713,3],[[72714,72758],2],[72759,3],[[72760,72768],2],[[72769,72773],2],[[72774,72783],3],[[72784,72793],2],[[72794,72812],2],[[72813,72815],3],[[72816,72817],2],[[72818,72847],2],[[72848,72849],3],[[72850,72871],2],[72872,3],[[72873,72886],2],[[72887,72959],3],[[72960,72966],2],[72967,3],[[72968,72969],2],[72970,3],[[72971,73014],2],[[73015,73017],3],[73018,2],[73019,3],[[73020,73021],2],[73022,3],[[73023,73031],2],[[73032,73039],3],[[73040,73049],2],[[73050,73055],3],[[73056,73061],2],[73062,3],[[73063,73064],2],[73065,3],[[73066,73102],2],[73103,3],[[73104,73105],2],[73106,3],[[73107,73112],2],[[73113,73119],3],[[73120,73129],2],[[73130,73439],3],[[73440,73462],2],[[73463,73464],2],[[73465,73471],3],[[73472,73488],2],[73489,3],[[73490,73530],2],[[73531,73533],3],[[73534,73538],2],[[73539,73551],2],[[73552,73561],2],[[73562,73647],3],[73648,2],[[73649,73663],3],[[73664,73713],2],[[73714,73726],3],[73727,2],[[73728,74606],2],[[74607,74648],2],[74649,2],[[74650,74751],3],[[74752,74850],2],[[74851,74862],2],[74863,3],[[74864,74867],2],[74868,2],[[74869,74879],3],[[74880,75075],2],[[75076,77711],3],[[77712,77808],2],[[77809,77810],2],[[77811,77823],3],[[77824,78894],2],[78895,2],[[78896,78904],3],[[78905,78911],3],[[78912,78933],2],[[78934,82943],3],[[82944,83526],2],[[83527,92159],3],[[92160,92728],2],[[92729,92735],3],[[92736,92766],2],[92767,3],[[92768,92777],2],[[92778,92781],3],[[92782,92783],2],[[92784,92862],2],[92863,3],[[92864,92873],2],[[92874,92879],3],[[92880,92909],2],[[92910,92911],3],[[92912,92916],2],[92917,2],[[92918,92927],3],[[92928,92982],2],[[92983,92991],2],[[92992,92995],2],[[92996,92997],2],[[92998,93007],3],[[93008,93017],2],[93018,3],[[93019,93025],2],[93026,3],[[93027,93047],2],[[93048,93052],3],[[93053,93071],2],[[93072,93759],3],[93760,1,\"\"],[93761,1,\"\"],[93762,1,\"\"],[93763,1,\"\"],[93764,1,\"\"],[93765,1,\"\"],[93766,1,\"\"],[93767,1,\"\"],[93768,1,\"\"],[93769,1,\"\"],[93770,1,\"\"],[93771,1,\"\"],[93772,1,\"\"],[93773,1,\"\"],[93774,1,\"\"],[93775,1,\"\"],[93776,1,\"\"],[93777,1,\"\"],[93778,1,\"\"],[93779,1,\"\"],[93780,1,\"\"],[93781,1,\"\"],[93782,1,\"\"],[93783,1,\"\"],[93784,1,\"\"],[93785,1,\"\"],[93786,1,\"\"],[93787,1,\"\"],[93788,1,\"\"],[93789,1,\"\"],[93790,1,\"\"],[93791,1,\"\"],[[93792,93823],2],[[93824,93850],2],[[93851,93951],3],[[93952,94020],2],[[94021,94026],2],[[94027,94030],3],[94031,2],[[94032,94078],2],[[94079,94087],2],[[94088,94094],3],[[94095,94111],2],[[94112,94175],3],[94176,2],[94177,2],[94178,2],[94179,2],[94180,2],[[94181,94191],3],[[94192,94193],2],[[94194,94207],3],[[94208,100332],2],[[100333,100337],2],[[100338,100343],2],[[100344,100351],3],[[100352,101106],2],[[101107,101589],2],[[101590,101631],3],[[101632,101640],2],[[101641,110575],3],[[110576,110579],2],[110580,3],[[110581,110587],2],[110588,3],[[110589,110590],2],[110591,3],[[110592,110593],2],[[110594,110878],2],[[110879,110882],2],[[110883,110897],3],[110898,2],[[110899,110927],3],[[110928,110930],2],[[110931,110932],3],[110933,2],[[110934,110947],3],[[110948,110951],2],[[110952,110959],3],[[110960,111355],2],[[111356,113663],3],[[113664,113770],2],[[113771,113775],3],[[113776,113788],2],[[113789,113791],3],[[113792,113800],2],[[113801,113807],3],[[113808,113817],2],[[113818,113819],3],[113820,2],[[113821,113822],2],[113823,2],[[113824,113827],7],[[113828,118527],3],[[118528,118573],2],[[118574,118575],3],[[118576,118598],2],[[118599,118607],3],[[118608,118723],2],[[118724,118783],3],[[118784,119029],2],[[119030,119039],3],[[119040,119078],2],[[119079,119080],3],[119081,2],[[119082,119133],2],[119134,1,\"\"],[119135,1,\"\"],[119136,1,\"\"],[119137,1,\"\"],[119138,1,\"\"],[119139,1,\"\"],[119140,1,\"\"],[[119141,119154],2],[[119155,119162],3],[[119163,119226],2],[119227,1,\"\"],[119228,1,\"\"],[119229,1,\"\"],[119230,1,\"\"],[119231,1,\"\"],[119232,1,\"\"],[[119233,119261],2],[[119262,119272],2],[[119273,119274],2],[[119275,119295],3],[[119296,119365],2],[[119366,119487],3],[[119488,119507],2],[[119508,119519],3],[[119520,119539],2],[[119540,119551],3],[[119552,119638],2],[[119639,119647],3],[[119648,119665],2],[[119666,119672],2],[[119673,119807],3],[119808,1,\"a\"],[119809,1,\"b\"],[119810,1,\"c\"],[119811,1,\"d\"],[119812,1,\"e\"],[119813,1,\"f\"],[119814,1,\"g\"],[119815,1,\"h\"],[119816,1,\"i\"],[119817,1,\"j\"],[119818,1,\"k\"],[119819,1,\"l\"],[119820,1,\"m\"],[119821,1,\"n\"],[119822,1,\"o\"],[119823,1,\"p\"],[119824,1,\"q\"],[119825,1,\"r\"],[119826,1,\"s\"],[119827,1,\"t\"],[119828,1,\"u\"],[119829,1,\"v\"],[119830,1,\"w\"],[119831,1,\"x\"],[119832,1,\"y\"],[119833,1,\"z\"],[119834,1,\"a\"],[119835,1,\"b\"],[119836,1,\"c\"],[119837,1,\"d\"],[119838,1,\"e\"],[119839,1,\"f\"],[119840,1,\"g\"],[119841,1,\"h\"],[119842,1,\"i\"],[119843,1,\"j\"],[119844,1,\"k\"],[119845,1,\"l\"],[119846,1,\"m\"],[119847,1,\"n\"],[119848,1,\"o\"],[119849,1,\"p\"],[119850,1,\"q\"],[119851,1,\"r\"],[119852,1,\"s\"],[119853,1,\"t\"],[119854,1,\"u\"],[119855,1,\"v\"],[119856,1,\"w\"],[119857,1,\"x\"],[119858,1,\"y\"],[119859,1,\"z\"],[119860,1,\"a\"],[119861,1,\"b\"],[119862,1,\"c\"],[119863,1,\"d\"],[119864,1,\"e\"],[119865,1,\"f\"],[119866,1,\"g\"],[119867,1,\"h\"],[119868,1,\"i\"],[119869,1,\"j\"],[119870,1,\"k\"],[119871,1,\"l\"],[119872,1,\"m\"],[119873,1,\"n\"],[119874,1,\"o\"],[119875,1,\"p\"],[119876,1,\"q\"],[119877,1,\"r\"],[119878,1,\"s\"],[119879,1,\"t\"],[119880,1,\"u\"],[119881,1,\"v\"],[119882,1,\"w\"],[119883,1,\"x\"],[119884,1,\"y\"],[119885,1,\"z\"],[119886,1,\"a\"],[119887,1,\"b\"],[119888,1,\"c\"],[119889,1,\"d\"],[119890,1,\"e\"],[119891,1,\"f\"],[119892,1,\"g\"],[119893,3],[119894,1,\"i\"],[119895,1,\"j\"],[119896,1,\"k\"],[119897,1,\"l\"],[119898,1,\"m\"],[119899,1,\"n\"],[119900,1,\"o\"],[119901,1,\"p\"],[119902,1,\"q\"],[119903,1,\"r\"],[119904,1,\"s\"],[119905,1,\"t\"],[119906,1,\"u\"],[119907,1,\"v\"],[119908,1,\"w\"],[119909,1,\"x\"],[119910,1,\"y\"],[119911,1,\"z\"],[119912,1,\"a\"],[119913,1,\"b\"],[119914,1,\"c\"],[119915,1,\"d\"],[119916,1,\"e\"],[119917,1,\"f\"],[119918,1,\"g\"],[119919,1,\"h\"],[119920,1,\"i\"],[119921,1,\"j\"],[119922,1,\"k\"],[119923,1,\"l\"],[119924,1,\"m\"],[119925,1,\"n\"],[119926,1,\"o\"],[119927,1,\"p\"],[119928,1,\"q\"],[119929,1,\"r\"],[119930,1,\"s\"],[119931,1,\"t\"],[119932,1,\"u\"],[119933,1,\"v\"],[119934,1,\"w\"],[119935,1,\"x\"],[119936,1,\"y\"],[119937,1,\"z\"],[119938,1,\"a\"],[119939,1,\"b\"],[119940,1,\"c\"],[119941,1,\"d\"],[119942,1,\"e\"],[119943,1,\"f\"],[119944,1,\"g\"],[119945,1,\"h\"],[119946,1,\"i\"],[119947,1,\"j\"],[119948,1,\"k\"],[119949,1,\"l\"],[119950,1,\"m\"],[119951,1,\"n\"],[119952,1,\"o\"],[119953,1,\"p\"],[119954,1,\"q\"],[119955,1,\"r\"],[119956,1,\"s\"],[119957,1,\"t\"],[119958,1,\"u\"],[119959,1,\"v\"],[119960,1,\"w\"],[119961,1,\"x\"],[119962,1,\"y\"],[119963,1,\"z\"],[119964,1,\"a\"],[119965,3],[119966,1,\"c\"],[119967,1,\"d\"],[[119968,119969],3],[119970,1,\"g\"],[[119971,119972],3],[119973,1,\"j\"],[119974,1,\"k\"],[[119975,119976],3],[119977,1,\"n\"],[119978,1,\"o\"],[119979,1,\"p\"],[119980,1,\"q\"],[119981,3],[119982,1,\"s\"],[119983,1,\"t\"],[119984,1,\"u\"],[119985,1,\"v\"],[119986,1,\"w\"],[119987,1,\"x\"],[119988,1,\"y\"],[119989,1,\"z\"],[119990,1,\"a\"],[119991,1,\"b\"],[119992,1,\"c\"],[119993,1,\"d\"],[119994,3],[119995,1,\"f\"],[119996,3],[119997,1,\"h\"],[119998,1,\"i\"],[119999,1,\"j\"],[120000,1,\"k\"],[120001,1,\"l\"],[120002,1,\"m\"],[120003,1,\"n\"],[120004,3],[120005,1,\"p\"],[120006,1,\"q\"],[120007,1,\"r\"],[120008,1,\"s\"],[120009,1,\"t\"],[120010,1,\"u\"],[120011,1,\"v\"],[120012,1,\"w\"],[120013,1,\"x\"],[120014,1,\"y\"],[120015,1,\"z\"],[120016,1,\"a\"],[120017,1,\"b\"],[120018,1,\"c\"],[120019,1,\"d\"],[120020,1,\"e\"],[120021,1,\"f\"],[120022,1,\"g\"],[120023,1,\"h\"],[120024,1,\"i\"],[120025,1,\"j\"],[120026,1,\"k\"],[120027,1,\"l\"],[120028,1,\"m\"],[120029,1,\"n\"],[120030,1,\"o\"],[120031,1,\"p\"],[120032,1,\"q\"],[120033,1,\"r\"],[120034,1,\"s\"],[120035,1,\"t\"],[120036,1,\"u\"],[120037,1,\"v\"],[120038,1,\"w\"],[120039,1,\"x\"],[120040,1,\"y\"],[120041,1,\"z\"],[120042,1,\"a\"],[120043,1,\"b\"],[120044,1,\"c\"],[120045,1,\"d\"],[120046,1,\"e\"],[120047,1,\"f\"],[120048,1,\"g\"],[120049,1,\"h\"],[120050,1,\"i\"],[120051,1,\"j\"],[120052,1,\"k\"],[120053,1,\"l\"],[120054,1,\"m\"],[120055,1,\"n\"],[120056,1,\"o\"],[120057,1,\"p\"],[120058,1,\"q\"],[120059,1,\"r\"],[120060,1,\"s\"],[120061,1,\"t\"],[120062,1,\"u\"],[120063,1,\"v\"],[120064,1,\"w\"],[120065,1,\"x\"],[120066,1,\"y\"],[120067,1,\"z\"],[120068,1,\"a\"],[120069,1,\"b\"],[120070,3],[120071,1,\"d\"],[120072,1,\"e\"],[120073,1,\"f\"],[120074,1,\"g\"],[[120075,120076],3],[120077,1,\"j\"],[120078,1,\"k\"],[120079,1,\"l\"],[120080,1,\"m\"],[120081,1,\"n\"],[120082,1,\"o\"],[120083,1,\"p\"],[120084,1,\"q\"],[120085,3],[120086,1,\"s\"],[120087,1,\"t\"],[120088,1,\"u\"],[120089,1,\"v\"],[120090,1,\"w\"],[120091,1,\"x\"],[120092,1,\"y\"],[120093,3],[120094,1,\"a\"],[120095,1,\"b\"],[120096,1,\"c\"],[120097,1,\"d\"],[120098,1,\"e\"],[120099,1,\"f\"],[120100,1,\"g\"],[120101,1,\"h\"],[120102,1,\"i\"],[120103,1,\"j\"],[120104,1,\"k\"],[120105,1,\"l\"],[120106,1,\"m\"],[120107,1,\"n\"],[120108,1,\"o\"],[120109,1,\"p\"],[120110,1,\"q\"],[120111,1,\"r\"],[120112,1,\"s\"],[120113,1,\"t\"],[120114,1,\"u\"],[120115,1,\"v\"],[120116,1,\"w\"],[120117,1,\"x\"],[120118,1,\"y\"],[120119,1,\"z\"],[120120,1,\"a\"],[120121,1,\"b\"],[120122,3],[120123,1,\"d\"],[120124,1,\"e\"],[120125,1,\"f\"],[120126,1,\"g\"],[120127,3],[120128,1,\"i\"],[120129,1,\"j\"],[120130,1,\"k\"],[120131,1,\"l\"],[120132,1,\"m\"],[120133,3],[120134,1,\"o\"],[[120135,120137],3],[120138,1,\"s\"],[120139,1,\"t\"],[120140,1,\"u\"],[120141,1,\"v\"],[120142,1,\"w\"],[120143,1,\"x\"],[120144,1,\"y\"],[120145,3],[120146,1,\"a\"],[120147,1,\"b\"],[120148,1,\"c\"],[120149,1,\"d\"],[120150,1,\"e\"],[120151,1,\"f\"],[120152,1,\"g\"],[120153,1,\"h\"],[120154,1,\"i\"],[120155,1,\"j\"],[120156,1,\"k\"],[120157,1,\"l\"],[120158,1,\"m\"],[120159,1,\"n\"],[120160,1,\"o\"],[120161,1,\"p\"],[120162,1,\"q\"],[120163,1,\"r\"],[120164,1,\"s\"],[120165,1,\"t\"],[120166,1,\"u\"],[120167,1,\"v\"],[120168,1,\"w\"],[120169,1,\"x\"],[120170,1,\"y\"],[120171,1,\"z\"],[120172,1,\"a\"],[120173,1,\"b\"],[120174,1,\"c\"],[120175,1,\"d\"],[120176,1,\"e\"],[120177,1,\"f\"],[120178,1,\"g\"],[120179,1,\"h\"],[120180,1,\"i\"],[120181,1,\"j\"],[120182,1,\"k\"],[120183,1,\"l\"],[120184,1,\"m\"],[120185,1,\"n\"],[120186,1,\"o\"],[120187,1,\"p\"],[120188,1,\"q\"],[120189,1,\"r\"],[120190,1,\"s\"],[120191,1,\"t\"],[120192,1,\"u\"],[120193,1,\"v\"],[120194,1,\"w\"],[120195,1,\"x\"],[120196,1,\"y\"],[120197,1,\"z\"],[120198,1,\"a\"],[120199,1,\"b\"],[120200,1,\"c\"],[120201,1,\"d\"],[120202,1,\"e\"],[120203,1,\"f\"],[120204,1,\"g\"],[120205,1,\"h\"],[120206,1,\"i\"],[120207,1,\"j\"],[120208,1,\"k\"],[120209,1,\"l\"],[120210,1,\"m\"],[120211,1,\"n\"],[120212,1,\"o\"],[120213,1,\"p\"],[120214,1,\"q\"],[120215,1,\"r\"],[120216,1,\"s\"],[120217,1,\"t\"],[120218,1,\"u\"],[120219,1,\"v\"],[120220,1,\"w\"],[120221,1,\"x\"],[120222,1,\"y\"],[120223,1,\"z\"],[120224,1,\"a\"],[120225,1,\"b\"],[120226,1,\"c\"],[120227,1,\"d\"],[120228,1,\"e\"],[120229,1,\"f\"],[120230,1,\"g\"],[120231,1,\"h\"],[120232,1,\"i\"],[120233,1,\"j\"],[120234,1,\"k\"],[120235,1,\"l\"],[120236,1,\"m\"],[120237,1,\"n\"],[120238,1,\"o\"],[120239,1,\"p\"],[120240,1,\"q\"],[120241,1,\"r\"],[120242,1,\"s\"],[120243,1,\"t\"],[120244,1,\"u\"],[120245,1,\"v\"],[120246,1,\"w\"],[120247,1,\"x\"],[120248,1,\"y\"],[120249,1,\"z\"],[120250,1,\"a\"],[120251,1,\"b\"],[120252,1,\"c\"],[120253,1,\"d\"],[120254,1,\"e\"],[120255,1,\"f\"],[120256,1,\"g\"],[120257,1,\"h\"],[120258,1,\"i\"],[120259,1,\"j\"],[120260,1,\"k\"],[120261,1,\"l\"],[120262,1,\"m\"],[120263,1,\"n\"],[120264,1,\"o\"],[120265,1,\"p\"],[120266,1,\"q\"],[120267,1,\"r\"],[120268,1,\"s\"],[120269,1,\"t\"],[120270,1,\"u\"],[120271,1,\"v\"],[120272,1,\"w\"],[120273,1,\"x\"],[120274,1,\"y\"],[120275,1,\"z\"],[120276,1,\"a\"],[120277,1,\"b\"],[120278,1,\"c\"],[120279,1,\"d\"],[120280,1,\"e\"],[120281,1,\"f\"],[120282,1,\"g\"],[120283,1,\"h\"],[120284,1,\"i\"],[120285,1,\"j\"],[120286,1,\"k\"],[120287,1,\"l\"],[120288,1,\"m\"],[120289,1,\"n\"],[120290,1,\"o\"],[120291,1,\"p\"],[120292,1,\"q\"],[120293,1,\"r\"],[120294,1,\"s\"],[120295,1,\"t\"],[120296,1,\"u\"],[120297,1,\"v\"],[120298,1,\"w\"],[120299,1,\"x\"],[120300,1,\"y\"],[120301,1,\"z\"],[120302,1,\"a\"],[120303,1,\"b\"],[120304,1,\"c\"],[120305,1,\"d\"],[120306,1,\"e\"],[120307,1,\"f\"],[120308,1,\"g\"],[120309,1,\"h\"],[120310,1,\"i\"],[120311,1,\"j\"],[120312,1,\"k\"],[120313,1,\"l\"],[120314,1,\"m\"],[120315,1,\"n\"],[120316,1,\"o\"],[120317,1,\"p\"],[120318,1,\"q\"],[120319,1,\"r\"],[120320,1,\"s\"],[120321,1,\"t\"],[120322,1,\"u\"],[120323,1,\"v\"],[120324,1,\"w\"],[120325,1,\"x\"],[120326,1,\"y\"],[120327,1,\"z\"],[120328,1,\"a\"],[120329,1,\"b\"],[120330,1,\"c\"],[120331,1,\"d\"],[120332,1,\"e\"],[120333,1,\"f\"],[120334,1,\"g\"],[120335,1,\"h\"],[120336,1,\"i\"],[120337,1,\"j\"],[120338,1,\"k\"],[120339,1,\"l\"],[120340,1,\"m\"],[120341,1,\"n\"],[120342,1,\"o\"],[120343,1,\"p\"],[120344,1,\"q\"],[120345,1,\"r\"],[120346,1,\"s\"],[120347,1,\"t\"],[120348,1,\"u\"],[120349,1,\"v\"],[120350,1,\"w\"],[120351,1,\"x\"],[120352,1,\"y\"],[120353,1,\"z\"],[120354,1,\"a\"],[120355,1,\"b\"],[120356,1,\"c\"],[120357,1,\"d\"],[120358,1,\"e\"],[120359,1,\"f\"],[120360,1,\"g\"],[120361,1,\"h\"],[120362,1,\"i\"],[120363,1,\"j\"],[120364,1,\"k\"],[120365,1,\"l\"],[120366,1,\"m\"],[120367,1,\"n\"],[120368,1,\"o\"],[120369,1,\"p\"],[120370,1,\"q\"],[120371,1,\"r\"],[120372,1,\"s\"],[120373,1,\"t\"],[120374,1,\"u\"],[120375,1,\"v\"],[120376,1,\"w\"],[120377,1,\"x\"],[120378,1,\"y\"],[120379,1,\"z\"],[120380,1,\"a\"],[120381,1,\"b\"],[120382,1,\"c\"],[120383,1,\"d\"],[120384,1,\"e\"],[120385,1,\"f\"],[120386,1,\"g\"],[120387,1,\"h\"],[120388,1,\"i\"],[120389,1,\"j\"],[120390,1,\"k\"],[120391,1,\"l\"],[120392,1,\"m\"],[120393,1,\"n\"],[120394,1,\"o\"],[120395,1,\"p\"],[120396,1,\"q\"],[120397,1,\"r\"],[120398,1,\"s\"],[120399,1,\"t\"],[120400,1,\"u\"],[120401,1,\"v\"],[120402,1,\"w\"],[120403,1,\"x\"],[120404,1,\"y\"],[120405,1,\"z\"],[120406,1,\"a\"],[120407,1,\"b\"],[120408,1,\"c\"],[120409,1,\"d\"],[120410,1,\"e\"],[120411,1,\"f\"],[120412,1,\"g\"],[120413,1,\"h\"],[120414,1,\"i\"],[120415,1,\"j\"],[120416,1,\"k\"],[120417,1,\"l\"],[120418,1,\"m\"],[120419,1,\"n\"],[120420,1,\"o\"],[120421,1,\"p\"],[120422,1,\"q\"],[120423,1,\"r\"],[120424,1,\"s\"],[120425,1,\"t\"],[120426,1,\"u\"],[120427,1,\"v\"],[120428,1,\"w\"],[120429,1,\"x\"],[120430,1,\"y\"],[120431,1,\"z\"],[120432,1,\"a\"],[120433,1,\"b\"],[120434,1,\"c\"],[120435,1,\"d\"],[120436,1,\"e\"],[120437,1,\"f\"],[120438,1,\"g\"],[120439,1,\"h\"],[120440,1,\"i\"],[120441,1,\"j\"],[120442,1,\"k\"],[120443,1,\"l\"],[120444,1,\"m\"],[120445,1,\"n\"],[120446,1,\"o\"],[120447,1,\"p\"],[120448,1,\"q\"],[120449,1,\"r\"],[120450,1,\"s\"],[120451,1,\"t\"],[120452,1,\"u\"],[120453,1,\"v\"],[120454,1,\"w\"],[120455,1,\"x\"],[120456,1,\"y\"],[120457,1,\"z\"],[120458,1,\"a\"],[120459,1,\"b\"],[120460,1,\"c\"],[120461,1,\"d\"],[120462,1,\"e\"],[120463,1,\"f\"],[120464,1,\"g\"],[120465,1,\"h\"],[120466,1,\"i\"],[120467,1,\"j\"],[120468,1,\"k\"],[120469,1,\"l\"],[120470,1,\"m\"],[120471,1,\"n\"],[120472,1,\"o\"],[120473,1,\"p\"],[120474,1,\"q\"],[120475,1,\"r\"],[120476,1,\"s\"],[120477,1,\"t\"],[120478,1,\"u\"],[120479,1,\"v\"],[120480,1,\"w\"],[120481,1,\"x\"],[120482,1,\"y\"],[120483,1,\"z\"],[120484,1,\"\"],[120485,1,\"\"],[[120486,120487],3],[120488,1,\"\"],[120489,1,\"\"],[120490,1,\"\"],[120491,1,\"\"],[120492,1,\"\"],[120493,1,\"\"],[120494,1,\"\"],[120495,1,\"\"],[120496,1,\"\"],[120497,1,\"\"],[120498,1,\"\"],[120499,1,\"\"],[120500,1,\"\"],[120501,1,\"\"],[120502,1,\"\"],[120503,1,\"\"],[120504,1,\"\"],[120505,1,\"\"],[120506,1,\"\"],[120507,1,\"\"],[120508,1,\"\"],[120509,1,\"\"],[120510,1,\"\"],[120511,1,\"\"],[120512,1,\"\"],[120513,1,\"\"],[120514,1,\"\"],[120515,1,\"\"],[120516,1,\"\"],[120517,1,\"\"],[120518,1,\"\"],[120519,1,\"\"],[120520,1,\"\"],[120521,1,\"\"],[120522,1,\"\"],[120523,1,\"\"],[120524,1,\"\"],[120525,1,\"\"],[120526,1,\"\"],[120527,1,\"\"],[120528,1,\"\"],[120529,1,\"\"],[120530,1,\"\"],[[120531,120532],1,\"\"],[120533,1,\"\"],[120534,1,\"\"],[120535,1,\"\"],[120536,1,\"\"],[120537,1,\"\"],[120538,1,\"\"],[120539,1,\"\"],[120540,1,\"\"],[120541,1,\"\"],[120542,1,\"\"],[120543,1,\"\"],[120544,1,\"\"],[120545,1,\"\"],[120546,1,\"\"],[120547,1,\"\"],[120548,1,\"\"],[120549,1,\"\"],[120550,1,\"\"],[120551,1,\"\"],[120552,1,\"\"],[120553,1,\"\"],[120554,1,\"\"],[120555,1,\"\"],[120556,1,\"\"],[120557,1,\"\"],[120558,1,\"\"],[120559,1,\"\"],[120560,1,\"\"],[120561,1,\"\"],[120562,1,\"\"],[120563,1,\"\"],[120564,1,\"\"],[120565,1,\"\"],[120566,1,\"\"],[120567,1,\"\"],[120568,1,\"\"],[120569,1,\"\"],[120570,1,\"\"],[120571,1,\"\"],[120572,1,\"\"],[120573,1,\"\"],[120574,1,\"\"],[120575,1,\"\"],[120576,1,\"\"],[120577,1,\"\"],[120578,1,\"\"],[120579,1,\"\"],[120580,1,\"\"],[120581,1,\"\"],[120582,1,\"\"],[120583,1,\"\"],[120584,1,\"\"],[120585,1,\"\"],[120586,1,\"\"],[120587,1,\"\"],[120588,1,\"\"],[[120589,120590],1,\"\"],[120591,1,\"\"],[120592,1,\"\"],[120593,1,\"\"],[120594,1,\"\"],[120595,1,\"\"],[120596,1,\"\"],[120597,1,\"\"],[120598,1,\"\"],[120599,1,\"\"],[120600,1,\"\"],[120601,1,\"\"],[120602,1,\"\"],[120603,1,\"\"],[120604,1,\"\"],[120605,1,\"\"],[120606,1,\"\"],[120607,1,\"\"],[120608,1,\"\"],[120609,1,\"\"],[120610,1,\"\"],[120611,1,\"\"],[120612,1,\"\"],[120613,1,\"\"],[120614,1,\"\"],[120615,1,\"\"],[120616,1,\"\"],[120617,1,\"\"],[120618,1,\"\"],[120619,1,\"\"],[120620,1,\"\"],[120621,1,\"\"],[120622,1,\"\"],[120623,1,\"\"],[120624,1,\"\"],[120625,1,\"\"],[120626,1,\"\"],[120627,1,\"\"],[120628,1,\"\"],[120629,1,\"\"],[120630,1,\"\"],[120631,1,\"\"],[120632,1,\"\"],[120633,1,\"\"],[120634,1,\"\"],[120635,1,\"\"],[120636,1,\"\"],[120637,1,\"\"],[120638,1,\"\"],[120639,1,\"\"],[120640,1,\"\"],[120641,1,\"\"],[120642,1,\"\"],[120643,1,\"\"],[120644,1,\"\"],[120645,1,\"\"],[120646,1,\"\"],[[120647,120648],1,\"\"],[120649,1,\"\"],[120650,1,\"\"],[120651,1,\"\"],[120652,1,\"\"],[120653,1,\"\"],[120654,1,\"\"],[120655,1,\"\"],[120656,1,\"\"],[120657,1,\"\"],[120658,1,\"\"],[120659,1,\"\"],[120660,1,\"\"],[120661,1,\"\"],[120662,1,\"\"],[120663,1,\"\"],[120664,1,\"\"],[120665,1,\"\"],[120666,1,\"\"],[120667,1,\"\"],[120668,1,\"\"],[120669,1,\"\"],[120670,1,\"\"],[120671,1,\"\"],[120672,1,\"\"],[120673,1,\"\"],[120674,1,\"\"],[120675,1,\"\"],[120676,1,\"\"],[120677,1,\"\"],[120678,1,\"\"],[120679,1,\"\"],[120680,1,\"\"],[120681,1,\"\"],[120682,1,\"\"],[120683,1,\"\"],[120684,1,\"\"],[120685,1,\"\"],[120686,1,\"\"],[120687,1,\"\"],[120688,1,\"\"],[120689,1,\"\"],[120690,1,\"\"],[120691,1,\"\"],[120692,1,\"\"],[120693,1,\"\"],[120694,1,\"\"],[120695,1,\"\"],[120696,1,\"\"],[120697,1,\"\"],[120698,1,\"\"],[120699,1,\"\"],[120700,1,\"\"],[120701,1,\"\"],[120702,1,\"\"],[120703,1,\"\"],[120704,1,\"\"],[[120705,120706],1,\"\"],[120707,1,\"\"],[120708,1,\"\"],[120709,1,\"\"],[120710,1,\"\"],[120711,1,\"\"],[120712,1,\"\"],[120713,1,\"\"],[120714,1,\"\"],[120715,1,\"\"],[120716,1,\"\"],[120717,1,\"\"],[120718,1,\"\"],[120719,1,\"\"],[120720,1,\"\"],[120721,1,\"\"],[120722,1,\"\"],[120723,1,\"\"],[120724,1,\"\"],[120725,1,\"\"],[120726,1,\"\"],[120727,1,\"\"],[120728,1,\"\"],[120729,1,\"\"],[120730,1,\"\"],[120731,1,\"\"],[120732,1,\"\"],[120733,1,\"\"],[120734,1,\"\"],[120735,1,\"\"],[120736,1,\"\"],[120737,1,\"\"],[120738,1,\"\"],[120739,1,\"\"],[120740,1,\"\"],[120741,1,\"\"],[120742,1,\"\"],[120743,1,\"\"],[120744,1,\"\"],[120745,1,\"\"],[120746,1,\"\"],[120747,1,\"\"],[120748,1,\"\"],[120749,1,\"\"],[120750,1,\"\"],[120751,1,\"\"],[120752,1,\"\"],[120753,1,\"\"],[120754,1,\"\"],[120755,1,\"\"],[120756,1,\"\"],[120757,1,\"\"],[120758,1,\"\"],[120759,1,\"\"],[120760,1,\"\"],[120761,1,\"\"],[120762,1,\"\"],[[120763,120764],1,\"\"],[120765,1,\"\"],[120766,1,\"\"],[120767,1,\"\"],[120768,1,\"\"],[120769,1,\"\"],[120770,1,\"\"],[120771,1,\"\"],[120772,1,\"\"],[120773,1,\"\"],[120774,1,\"\"],[120775,1,\"\"],[120776,1,\"\"],[120777,1,\"\"],[[120778,120779],1,\"\"],[[120780,120781],3],[120782,1,\"0\"],[120783,1,\"1\"],[120784,1,\"2\"],[120785,1,\"3\"],[120786,1,\"4\"],[120787,1,\"5\"],[120788,1,\"6\"],[120789,1,\"7\"],[120790,1,\"8\"],[120791,1,\"9\"],[120792,1,\"0\"],[120793,1,\"1\"],[120794,1,\"2\"],[120795,1,\"3\"],[120796,1,\"4\"],[120797,1,\"5\"],[120798,1,\"6\"],[120799,1,\"7\"],[120800,1,\"8\"],[120801,1,\"9\"],[120802,1,\"0\"],[120803,1,\"1\"],[120804,1,\"2\"],[120805,1,\"3\"],[120806,1,\"4\"],[120807,1,\"5\"],[120808,1,\"6\"],[120809,1,\"7\"],[120810,1,\"8\"],[120811,1,\"9\"],[120812,1,\"0\"],[120813,1,\"1\"],[120814,1,\"2\"],[120815,1,\"3\"],[120816,1,\"4\"],[120817,1,\"5\"],[120818,1,\"6\"],[120819,1,\"7\"],[120820,1,\"8\"],[120821,1,\"9\"],[120822,1,\"0\"],[120823,1,\"1\"],[120824,1,\"2\"],[120825,1,\"3\"],[120826,1,\"4\"],[120827,1,\"5\"],[120828,1,\"6\"],[120829,1,\"7\"],[120830,1,\"8\"],[120831,1,\"9\"],[[120832,121343],2],[[121344,121398],2],[[121399,121402],2],[[121403,121452],2],[[121453,121460],2],[121461,2],[[121462,121475],2],[121476,2],[[121477,121483],2],[[121484,121498],3],[[121499,121503],2],[121504,3],[[121505,121519],2],[[121520,122623],3],[[122624,122654],2],[[122655,122660],3],[[122661,122666],2],[[122667,122879],3],[[122880,122886],2],[122887,3],[[122888,122904],2],[[122905,122906],3],[[122907,122913],2],[122914,3],[[122915,122916],2],[122917,3],[[122918,122922],2],[[122923,122927],3],[122928,1,\"\"],[122929,1,\"\"],[122930,1,\"\"],[122931,1,\"\"],[122932,1,\"\"],[122933,1,\"\"],[122934,1,\"\"],[122935,1,\"\"],[122936,1,\"\"],[122937,1,\"\"],[122938,1,\"\"],[122939,1,\"\"],[122940,1,\"\"],[122941,1,\"\"],[122942,1,\"\"],[122943,1,\"\"],[122944,1,\"\"],[122945,1,\"\"],[122946,1,\"\"],[122947,1,\"\"],[122948,1,\"\"],[122949,1,\"\"],[122950,1,\"\"],[122951,1,\"\"],[122952,1,\"\"],[122953,1,\"\"],[122954,1,\"\"],[122955,1,\"\"],[122956,1,\"\"],[122957,1,\"\"],[122958,1,\"\"],[122959,1,\"\"],[122960,1,\"\"],[122961,1,\"\"],[122962,1,\"\"],[122963,1,\"\"],[122964,1,\"\"],[122965,1,\"\"],[122966,1,\"\"],[122967,1,\"\"],[122968,1,\"\"],[122969,1,\"\"],[122970,1,\"\"],[122971,1,\"\"],[122972,1,\"\"],[122973,1,\"\"],[122974,1,\"\"],[122975,1,\"\"],[122976,1,\"\"],[122977,1,\"\"],[122978,1,\"\"],[122979,1,\"\"],[122980,1,\"\"],[122981,1,\"\"],[122982,1,\"\"],[122983,1,\"\"],[122984,1,\"\"],[122985,1,\"\"],[122986,1,\"\"],[122987,1,\"\"],[122988,1,\"\"],[122989,1,\"\"],[[122990,123022],3],[123023,2],[[123024,123135],3],[[123136,123180],2],[[123181,123183],3],[[123184,123197],2],[[123198,123199],3],[[123200,123209],2],[[123210,123213],3],[123214,2],[123215,2],[[123216,123535],3],[[123536,123566],2],[[123567,123583],3],[[123584,123641],2],[[123642,123646],3],[123647,2],[[123648,124111],3],[[124112,124153],2],[[124154,124895],3],[[124896,124902],2],[124903,3],[[124904,124907],2],[124908,3],[[124909,124910],2],[124911,3],[[124912,124926],2],[124927,3],[[124928,125124],2],[[125125,125126],3],[[125127,125135],2],[[125136,125142],2],[[125143,125183],3],[125184,1,\"\"],[125185,1,\"\"],[125186,1,\"\"],[125187,1,\"\"],[125188,1,\"\"],[125189,1,\"\"],[125190,1,\"\"],[125191,1,\"\"],[125192,1,\"\"],[125193,1,\"\"],[125194,1,\"\"],[125195,1,\"\"],[125196,1,\"\"],[125197,1,\"\"],[125198,1,\"\"],[125199,1,\"\"],[125200,1,\"\"],[125201,1,\"\"],[125202,1,\"\"],[125203,1,\"\"],[125204,1,\"\"],[125205,1,\"\"],[125206,1,\"\"],[125207,1,\"\"],[125208,1,\"\"],[125209,1,\"\"],[125210,1,\"\"],[125211,1,\"\"],[125212,1,\"\"],[125213,1,\"\"],[125214,1,\"\"],[125215,1,\"\"],[125216,1,\"\"],[125217,1,\"\"],[[125218,125258],2],[125259,2],[[125260,125263],3],[[125264,125273],2],[[125274,125277],3],[[125278,125279],2],[[125280,126064],3],[[126065,126132],2],[[126133,126208],3],[[126209,126269],2],[[126270,126463],3],[126464,1,\"\"],[126465,1,\"\"],[126466,1,\"\"],[126467,1,\"\"],[126468,3],[126469,1,\"\"],[126470,1,\"\"],[126471,1,\"\"],[126472,1,\"\"],[126473,1,\"\"],[126474,1,\"\"],[126475,1,\"\"],[126476,1,\"\"],[126477,1,\"\"],[126478,1,\"\"],[126479,1,\"\"],[126480,1,\"\"],[126481,1,\"\"],[126482,1,\"\"],[126483,1,\"\"],[126484,1,\"\"],[126485,1,\"\"],[126486,1,\"\"],[126487,1,\"\"],[126488,1,\"\"],[126489,1,\"\"],[126490,1,\"\"],[126491,1,\"\"],[126492,1,\"\"],[126493,1,\"\"],[126494,1,\"\"],[126495,1,\"\"],[126496,3],[126497,1,\"\"],[126498,1,\"\"],[126499,3],[126500,1,\"\"],[[126501,126502],3],[126503,1,\"\"],[126504,3],[126505,1,\"\"],[126506,1,\"\"],[126507,1,\"\"],[126508,1,\"\"],[126509,1,\"\"],[126510,1,\"\"],[126511,1,\"\"],[126512,1,\"\"],[126513,1,\"\"],[126514,1,\"\"],[126515,3],[126516,1,\"\"],[126517,1,\"\"],[126518,1,\"\"],[126519,1,\"\"],[126520,3],[126521,1,\"\"],[126522,3],[126523,1,\"\"],[[126524,126529],3],[126530,1,\"\"],[[126531,126534],3],[126535,1,\"\"],[126536,3],[126537,1,\"\"],[126538,3],[126539,1,\"\"],[126540,3],[126541,1,\"\"],[126542,1,\"\"],[126543,1,\"\"],[126544,3],[126545,1,\"\"],[126546,1,\"\"],[126547,3],[126548,1,\"\"],[[126549,126550],3],[126551,1,\"\"],[126552,3],[126553,1,\"\"],[126554,3],[126555,1,\"\"],[126556,3],[126557,1,\"\"],[126558,3],[126559,1,\"\"],[126560,3],[126561,1,\"\"],[126562,1,\"\"],[126563,3],[126564,1,\"\"],[[126565,126566],3],[126567,1,\"\"],[126568,1,\"\"],[126569,1,\"\"],[126570,1,\"\"],[126571,3],[126572,1,\"\"],[126573,1,\"\"],[126574,1,\"\"],[126575,1,\"\"],[126576,1,\"\"],[126577,1,\"\"],[126578,1,\"\"],[126579,3],[126580,1,\"\"],[126581,1,\"\"],[126582,1,\"\"],[126583,1,\"\"],[126584,3],[126585,1,\"\"],[126586,1,\"\"],[126587,1,\"\"],[126588,1,\"\"],[126589,3],[126590,1,\"\"],[126591,3],[126592,1,\"\"],[126593,1,\"\"],[126594,1,\"\"],[126595,1,\"\"],[126596,1,\"\"],[126597,1,\"\"],[126598,1,\"\"],[126599,1,\"\"],[126600,1,\"\"],[126601,1,\"\"],[126602,3],[126603,1,\"\"],[126604,1,\"\"],[126605,1,\"\"],[126606,1,\"\"],[126607,1,\"\"],[126608,1,\"\"],[126609,1,\"\"],[126610,1,\"\"],[126611,1,\"\"],[126612,1,\"\"],[126613,1,\"\"],[126614,1,\"\"],[126615,1,\"\"],[126616,1,\"\"],[126617,1,\"\"],[126618,1,\"\"],[126619,1,\"\"],[[126620,126624],3],[126625,1,\"\"],[126626,1,\"\"],[126627,1,\"\"],[126628,3],[126629,1,\"\"],[126630,1,\"\"],[126631,1,\"\"],[126632,1,\"\"],[126633,1,\"\"],[126634,3],[126635,1,\"\"],[126636,1,\"\"],[126637,1,\"\"],[126638,1,\"\"],[126639,1,\"\"],[126640,1,\"\"],[126641,1,\"\"],[126642,1,\"\"],[126643,1,\"\"],[126644,1,\"\"],[126645,1,\"\"],[126646,1,\"\"],[126647,1,\"\"],[126648,1,\"\"],[126649,1,\"\"],[126650,1,\"\"],[126651,1,\"\"],[[126652,126703],3],[[126704,126705],2],[[126706,126975],3],[[126976,127019],2],[[127020,127023],3],[[127024,127123],2],[[127124,127135],3],[[127136,127150],2],[[127151,127152],3],[[127153,127166],2],[127167,2],[127168,3],[[127169,127183],2],[127184,3],[[127185,127199],2],[[127200,127221],2],[[127222,127231],3],[127232,3],[127233,5,\"0,\"],[127234,5,\"1,\"],[127235,5,\"2,\"],[127236,5,\"3,\"],[127237,5,\"4,\"],[127238,5,\"5,\"],[127239,5,\"6,\"],[127240,5,\"7,\"],[127241,5,\"8,\"],[127242,5,\"9,\"],[[127243,127244],2],[[127245,127247],2],[127248,5,\"(a)\"],[127249,5,\"(b)\"],[127250,5,\"(c)\"],[127251,5,\"(d)\"],[127252,5,\"(e)\"],[127253,5,\"(f)\"],[127254,5,\"(g)\"],[127255,5,\"(h)\"],[127256,5,\"(i)\"],[127257,5,\"(j)\"],[127258,5,\"(k)\"],[127259,5,\"(l)\"],[127260,5,\"(m)\"],[127261,5,\"(n)\"],[127262,5,\"(o)\"],[127263,5,\"(p)\"],[127264,5,\"(q)\"],[127265,5,\"(r)\"],[127266,5,\"(s)\"],[127267,5,\"(t)\"],[127268,5,\"(u)\"],[127269,5,\"(v)\"],[127270,5,\"(w)\"],[127271,5,\"(x)\"],[127272,5,\"(y)\"],[127273,5,\"(z)\"],[127274,1,\"s\"],[127275,1,\"c\"],[127276,1,\"r\"],[127277,1,\"cd\"],[127278,1,\"wz\"],[127279,2],[127280,1,\"a\"],[127281,1,\"b\"],[127282,1,\"c\"],[127283,1,\"d\"],[127284,1,\"e\"],[127285,1,\"f\"],[127286,1,\"g\"],[127287,1,\"h\"],[127288,1,\"i\"],[127289,1,\"j\"],[127290,1,\"k\"],[127291,1,\"l\"],[127292,1,\"m\"],[127293,1,\"n\"],[127294,1,\"o\"],[127295,1,\"p\"],[127296,1,\"q\"],[127297,1,\"r\"],[127298,1,\"s\"],[127299,1,\"t\"],[127300,1,\"u\"],[127301,1,\"v\"],[127302,1,\"w\"],[127303,1,\"x\"],[127304,1,\"y\"],[127305,1,\"z\"],[127306,1,\"hv\"],[127307,1,\"mv\"],[127308,1,\"sd\"],[127309,1,\"ss\"],[127310,1,\"ppv\"],[127311,1,\"wc\"],[[127312,127318],2],[127319,2],[[127320,127326],2],[127327,2],[[127328,127337],2],[127338,1,\"mc\"],[127339,1,\"md\"],[127340,1,\"mr\"],[[127341,127343],2],[[127344,127352],2],[127353,2],[127354,2],[[127355,127356],2],[[127357,127358],2],[127359,2],[[127360,127369],2],[[127370,127373],2],[[127374,127375],2],[127376,1,\"dj\"],[[127377,127386],2],[[127387,127404],2],[127405,2],[[127406,127461],3],[[127462,127487],2],[127488,1,\"\"],[127489,1,\"\"],[127490,1,\"\"],[[127491,127503],3],[127504,1,\"\"],[127505,1,\"\"],[127506,1,\"\"],[127507,1,\"\"],[127508,1,\"\"],[127509,1,\"\"],[127510,1,\"\"],[127511,1,\"\"],[127512,1,\"\"],[127513,1,\"\"],[127514,1,\"\"],[127515,1,\"\"],[127516,1,\"\"],[127517,1,\"\"],[127518,1,\"\"],[127519,1,\"\"],[127520,1,\"\"],[127521,1,\"\"],[127522,1,\"\"],[127523,1,\"\"],[127524,1,\"\"],[127525,1,\"\"],[127526,1,\"\"],[127527,1,\"\"],[127528,1,\"\"],[127529,1,\"\"],[127530,1,\"\"],[127531,1,\"\"],[127532,1,\"\"],[127533,1,\"\"],[127534,1,\"\"],[127535,1,\"\"],[127536,1,\"\"],[127537,1,\"\"],[127538,1,\"\"],[127539,1,\"\"],[127540,1,\"\"],[127541,1,\"\"],[127542,1,\"\"],[127543,1,\"\"],[127544,1,\"\"],[127545,1,\"\"],[127546,1,\"\"],[127547,1,\"\"],[[127548,127551],3],[127552,1,\"\"],[127553,1,\"\"],[127554,1,\"\"],[127555,1,\"\"],[127556,1,\"\"],[127557,1,\"\"],[127558,1,\"\"],[127559,1,\"\"],[127560,1,\"\"],[[127561,127567],3],[127568,1,\"\"],[127569,1,\"\"],[[127570,127583],3],[[127584,127589],2],[[127590,127743],3],[[127744,127776],2],[[127777,127788],2],[[127789,127791],2],[[127792,127797],2],[127798,2],[[127799,127868],2],[127869,2],[[127870,127871],2],[[127872,127891],2],[[127892,127903],2],[[127904,127940],2],[127941,2],[[127942,127946],2],[[127947,127950],2],[[127951,127955],2],[[127956,127967],2],[[127968,127984],2],[[127985,127991],2],[[127992,127999],2],[[128000,128062],2],[128063,2],[128064,2],[128065,2],[[128066,128247],2],[128248,2],[[128249,128252],2],[[128253,128254],2],[128255,2],[[128256,128317],2],[[128318,128319],2],[[128320,128323],2],[[128324,128330],2],[[128331,128335],2],[[128336,128359],2],[[128360,128377],2],[128378,2],[[128379,128419],2],[128420,2],[[128421,128506],2],[[128507,128511],2],[128512,2],[[128513,128528],2],[128529,2],[[128530,128532],2],[128533,2],[128534,2],[128535,2],[128536,2],[128537,2],[128538,2],[128539,2],[[128540,128542],2],[128543,2],[[128544,128549],2],[[128550,128551],2],[[128552,128555],2],[128556,2],[128557,2],[[128558,128559],2],[[128560,128563],2],[128564,2],[[128565,128576],2],[[128577,128578],2],[[128579,128580],2],[[128581,128591],2],[[128592,128639],2],[[128640,128709],2],[[128710,128719],2],[128720,2],[[128721,128722],2],[[128723,128724],2],[128725,2],[[128726,128727],2],[[128728,128731],3],[128732,2],[[128733,128735],2],[[128736,128748],2],[[128749,128751],3],[[128752,128755],2],[[128756,128758],2],[[128759,128760],2],[128761,2],[128762,2],[[128763,128764],2],[[128765,128767],3],[[128768,128883],2],[[128884,128886],2],[[128887,128890],3],[[128891,128895],2],[[128896,128980],2],[[128981,128984],2],[128985,2],[[128986,128991],3],[[128992,129003],2],[[129004,129007],3],[129008,2],[[129009,129023],3],[[129024,129035],2],[[129036,129039],3],[[129040,129095],2],[[129096,129103],3],[[129104,129113],2],[[129114,129119],3],[[129120,129159],2],[[129160,129167],3],[[129168,129197],2],[[129198,129199],3],[[129200,129201],2],[[129202,129279],3],[[129280,129291],2],[129292,2],[[129293,129295],2],[[129296,129304],2],[[129305,129310],2],[129311,2],[[129312,129319],2],[[129320,129327],2],[129328,2],[[129329,129330],2],[[129331,129342],2],[129343,2],[[129344,129355],2],[129356,2],[[129357,129359],2],[[129360,129374],2],[[129375,129387],2],[[129388,129392],2],[129393,2],[129394,2],[[129395,129398],2],[[129399,129400],2],[129401,2],[129402,2],[129403,2],[[129404,129407],2],[[129408,129412],2],[[129413,129425],2],[[129426,129431],2],[[129432,129442],2],[[129443,129444],2],[[129445,129450],2],[[129451,129453],2],[[129454,129455],2],[[129456,129465],2],[[129466,129471],2],[129472,2],[[129473,129474],2],[[129475,129482],2],[129483,2],[129484,2],[[129485,129487],2],[[129488,129510],2],[[129511,129535],2],[[129536,129619],2],[[129620,129631],3],[[129632,129645],2],[[129646,129647],3],[[129648,129651],2],[129652,2],[[129653,129655],2],[[129656,129658],2],[[129659,129660],2],[[129661,129663],3],[[129664,129666],2],[[129667,129670],2],[[129671,129672],2],[[129673,129679],3],[[129680,129685],2],[[129686,129704],2],[[129705,129708],2],[[129709,129711],2],[[129712,129718],2],[[129719,129722],2],[[129723,129725],2],[129726,3],[129727,2],[[129728,129730],2],[[129731,129733],2],[[129734,129741],3],[[129742,129743],2],[[129744,129750],2],[[129751,129753],2],[[129754,129755],2],[[129756,129759],3],[[129760,129767],2],[129768,2],[[129769,129775],3],[[129776,129782],2],[[129783,129784],2],[[129785,129791],3],[[129792,129938],2],[129939,3],[[129940,129994],2],[[129995,130031],3],[130032,1,\"0\"],[130033,1,\"1\"],[130034,1,\"2\"],[130035,1,\"3\"],[130036,1,\"4\"],[130037,1,\"5\"],[130038,1,\"6\"],[130039,1,\"7\"],[130040,1,\"8\"],[130041,1,\"9\"],[[130042,131069],3],[[131070,131071],3],[[131072,173782],2],[[173783,173789],2],[[173790,173791],2],[[173792,173823],3],[[173824,177972],2],[[177973,177976],2],[177977,2],[[177978,177983],3],[[177984,178205],2],[[178206,178207],3],[[178208,183969],2],[[183970,183983],3],[[183984,191456],2],[[191457,194559],3],[194560,1,\"\"],[194561,1,\"\"],[194562,1,\"\"],[194563,1,\"\"],[194564,1,\"\"],[194565,1,\"\"],[194566,1,\"\"],[194567,1,\"\"],[194568,1,\"\"],[194569,1,\"\"],[194570,1,\"\"],[194571,1,\"\"],[194572,1,\"\"],[194573,1,\"\"],[194574,1,\"\"],[194575,1,\"\"],[194576,1,\"\"],[194577,1,\"\"],[194578,1,\"\"],[194579,1,\"\"],[194580,1,\"\"],[194581,1,\"\"],[194582,1,\"\"],[194583,1,\"\"],[194584,1,\"\"],[194585,1,\"\"],[194586,1,\"\"],[194587,1,\"\"],[194588,1,\"\"],[194589,1,\"\"],[194590,1,\"\"],[194591,1,\"\"],[194592,1,\"\"],[194593,1,\"\"],[194594,1,\"\"],[194595,1,\"\"],[194596,1,\"\"],[194597,1,\"\"],[194598,1,\"\"],[194599,1,\"\"],[194600,1,\"\"],[194601,1,\"\"],[194602,1,\"\"],[194603,1,\"\"],[194604,1,\"\"],[194605,1,\"\"],[194606,1,\"\"],[194607,1,\"\"],[194608,1,\"\"],[[194609,194611],1,\"\"],[194612,1,\"\"],[194613,1,\"\"],[194614,1,\"\"],[194615,1,\"\"],[194616,1,\"\"],[194617,1,\"\"],[194618,1,\"\"],[194619,1,\"\"],[194620,1,\"\"],[194621,1,\"\"],[194622,1,\"\"],[194623,1,\"\"],[194624,1,\"\"],[194625,1,\"\"],[194626,1,\"\"],[194627,1,\"\"],[194628,1,\"\"],[[194629,194630],1,\"\"],[194631,1,\"\"],[194632,1,\"\"],[194633,1,\"\"],[194634,1,\"\"],[194635,1,\"\"],[194636,1,\"\"],[194637,1,\"\"],[194638,1,\"\"],[194639,1,\"\"],[194640,1,\"\"],[194641,1,\"\"],[194642,1,\"\"],[194643,1,\"\"],[194644,1,\"\"],[194645,1,\"\"],[194646,1,\"\"],[194647,1,\"\"],[194648,1,\"\"],[194649,1,\"\"],[194650,1,\"\"],[194651,1,\"\"],[194652,1,\"\"],[194653,1,\"\"],[194654,1,\"\"],[194655,1,\"\"],[194656,1,\"\"],[194657,1,\"\"],[194658,1,\"\"],[194659,1,\"\"],[194660,1,\"\"],[194661,1,\"\"],[194662,1,\"\"],[194663,1,\"\"],[194664,3],[194665,1,\"\"],[[194666,194667],1,\"\"],[194668,1,\"\"],[194669,1,\"\"],[194670,1,\"\"],[194671,1,\"\"],[194672,1,\"\"],[194673,1,\"\"],[194674,1,\"\"],[194675,1,\"\"],[194676,3],[194677,1,\"\"],[194678,1,\"\"],[194679,1,\"\"],[194680,1,\"\"],[194681,1,\"\"],[194682,1,\"\"],[194683,1,\"\"],[194684,1,\"\"],[194685,1,\"\"],[194686,1,\"\"],[194687,1,\"\"],[194688,1,\"\"],[194689,1,\"\"],[194690,1,\"\"],[194691,1,\"\"],[194692,1,\"\"],[194693,1,\"\"],[194694,1,\"\"],[194695,1,\"\"],[194696,1,\"\"],[194697,1,\"\"],[194698,1,\"\"],[194699,1,\"\"],[194700,1,\"\"],[194701,1,\"\"],[194702,1,\"\"],[194703,1,\"\"],[194704,1,\"\"],[[194705,194706],1,\"\"],[194707,1,\"\"],[[194708,194709],1,\"\"],[194710,1,\"\"],[194711,1,\"\"],[194712,1,\"\"],[194713,1,\"\"],[194714,1,\"\"],[194715,1,\"\"],[194716,1,\"\"],[194717,1,\"\"],[194718,1,\"\"],[194719,1,\"\"],[194720,1,\"\"],[194721,1,\"\"],[194722,1,\"\"],[194723,1,\"\"],[194724,1,\"\"],[194725,1,\"\"],[194726,1,\"\"],[194727,1,\"\"],[194728,1,\"\"],[194729,1,\"\"],[194730,1,\"\"],[194731,1,\"\"],[194732,1,\"\"],[194733,1,\"\"],[194734,1,\"\"],[194735,1,\"\"],[194736,1,\"\"],[194737,1,\"\"],[194738,1,\"\"],[194739,1,\"\"],[194740,1,\"\"],[194741,1,\"\"],[194742,1,\"\"],[194743,1,\"\"],[194744,1,\"\"],[194745,1,\"\"],[194746,1,\"\"],[194747,1,\"\"],[194748,1,\"\"],[194749,1,\"\"],[194750,1,\"\"],[194751,1,\"\"],[194752,1,\"\"],[194753,1,\"\"],[194754,1,\"\"],[194755,1,\"\"],[194756,1,\"\"],[194757,1,\"\"],[194758,1,\"\"],[194759,1,\"\"],[194760,1,\"\"],[194761,1,\"\"],[194762,1,\"\"],[194763,1,\"\"],[194764,1,\"\"],[194765,1,\"\"],[194766,1,\"\"],[194767,1,\"\"],[194768,1,\"\"],[194769,1,\"\"],[194770,1,\"\"],[194771,1,\"\"],[194772,1,\"\"],[194773,1,\"\"],[194774,1,\"\"],[194775,1,\"\"],[194776,1,\"\"],[194777,1,\"\"],[194778,1,\"\"],[194779,1,\"\"],[194780,1,\"\"],[194781,1,\"\"],[194782,1,\"\"],[194783,1,\"\"],[194784,1,\"\"],[194785,1,\"\"],[194786,1,\"\"],[194787,1,\"\"],[194788,1,\"\"],[194789,1,\"\"],[194790,1,\"\"],[194791,1,\"\"],[194792,1,\"\"],[194793,1,\"\"],[194794,1,\"\"],[194795,1,\"\"],[194796,1,\"\"],[194797,1,\"\"],[194798,1,\"\"],[194799,1,\"\"],[194800,1,\"\"],[194801,1,\"\"],[194802,1,\"\"],[194803,1,\"\"],[194804,1,\"\"],[194805,1,\"\"],[194806,1,\"\"],[194807,1,\"\"],[194808,1,\"\"],[194809,1,\"\"],[194810,1,\"\"],[194811,1,\"\"],[194812,1,\"\"],[194813,1,\"\"],[194814,1,\"\"],[194815,1,\"\"],[194816,1,\"\"],[194817,1,\"\"],[194818,1,\"\"],[194819,1,\"\"],[194820,1,\"\"],[194821,1,\"\"],[194822,1,\"\"],[194823,1,\"\"],[194824,1,\"\"],[194825,1,\"\"],[194826,1,\"\"],[194827,1,\"\"],[194828,1,\"\"],[194829,1,\"\"],[194830,1,\"\"],[194831,1,\"\"],[194832,1,\"\"],[194833,1,\"\"],[194834,1,\"\"],[194835,1,\"\"],[194836,1,\"\"],[194837,1,\"\"],[194838,1,\"\"],[194839,1,\"\"],[194840,1,\"\"],[194841,1,\"\"],[194842,1,\"\"],[194843,1,\"\"],[194844,1,\"\"],[194845,1,\"\"],[194846,1,\"\"],[194847,3],[194848,1,\"\"],[194849,1,\"\"],[194850,1,\"\"],[194851,1,\"\"],[194852,1,\"\"],[194853,1,\"\"],[194854,1,\"\"],[194855,1,\"\"],[194856,1,\"\"],[194857,1,\"\"],[194858,1,\"\"],[194859,1,\"\"],[[194860,194861],1,\"\"],[194862,1,\"\"],[194863,1,\"\"],[194864,1,\"\"],[194865,1,\"\"],[194866,1,\"\"],[194867,1,\"\"],[194868,1,\"\"],[194869,1,\"\"],[194870,1,\"\"],[194871,1,\"\"],[194872,1,\"\"],[194873,1,\"\"],[194874,1,\"\"],[194875,1,\"\"],[194876,1,\"\"],[194877,1,\"\"],[194878,1,\"\"],[194879,1,\"\"],[194880,1,\"\"],[194881,1,\"\"],[194882,1,\"\"],[194883,1,\"\"],[194884,1,\"\"],[194885,1,\"\"],[[194886,194887],1,\"\"],[194888,1,\"\"],[194889,1,\"\"],[194890,1,\"\"],[194891,1,\"\"],[194892,1,\"\"],[194893,1,\"\"],[194894,1,\"\"],[194895,1,\"\"],[194896,1,\"\"],[194897,1,\"\"],[194898,1,\"\"],[194899,1,\"\"],[194900,1,\"\"],[194901,1,\"\"],[194902,1,\"\"],[194903,1,\"\"],[194904,1,\"\"],[194905,1,\"\"],[194906,1,\"\"],[194907,1,\"\"],[194908,1,\"\"],[[194909,194910],1,\"\"],[194911,3],[194912,1,\"\"],[194913,1,\"\"],[194914,1,\"\"],[194915,1,\"\"],[194916,1,\"\"],[194917,1,\"\"],[194918,1,\"\"],[194919,1,\"\"],[194920,1,\"\"],[194921,1,\"\"],[194922,1,\"\"],[194923,1,\"\"],[194924,1,\"\"],[194925,1,\"\"],[194926,1,\"\"],[194927,1,\"\"],[194928,1,\"\"],[194929,1,\"\"],[194930,1,\"\"],[194931,1,\"\"],[194932,1,\"\"],[194933,1,\"\"],[194934,1,\"\"],[194935,1,\"\"],[194936,1,\"\"],[194937,1,\"\"],[194938,1,\"\"],[194939,1,\"\"],[194940,1,\"\"],[194941,1,\"\"],[194942,1,\"\"],[194943,1,\"\"],[194944,1,\"\"],[194945,1,\"\"],[194946,1,\"\"],[194947,1,\"\"],[194948,1,\"\"],[194949,1,\"\"],[194950,1,\"\"],[194951,1,\"\"],[194952,1,\"\"],[194953,1,\"\"],[194954,1,\"\"],[194955,1,\"\"],[194956,1,\"\"],[194957,1,\"\"],[194958,1,\"\"],[194959,1,\"\"],[194960,1,\"\"],[194961,1,\"\"],[194962,1,\"\"],[194963,1,\"\"],[194964,1,\"\"],[194965,1,\"\"],[194966,1,\"\"],[194967,1,\"\"],[194968,1,\"\"],[194969,1,\"\"],[194970,1,\"\"],[194971,1,\"\"],[194972,1,\"\"],[194973,1,\"\"],[194974,1,\"\"],[194975,1,\"\"],[194976,1,\"\"],[194977,1,\"\"],[194978,1,\"\"],[194979,1,\"\"],[194980,1,\"\"],[194981,1,\"\"],[194982,1,\"\"],[194983,1,\"\"],[194984,1,\"\"],[194985,1,\"\"],[194986,1,\"\"],[194987,1,\"\"],[194988,1,\"\"],[194989,1,\"\"],[194990,1,\"\"],[194991,1,\"\"],[194992,1,\"\"],[194993,1,\"\"],[194994,1,\"\"],[194995,1,\"\"],[194996,1,\"\"],[194997,1,\"\"],[194998,1,\"\"],[194999,1,\"\"],[195000,1,\"\"],[195001,1,\"\"],[195002,1,\"\"],[195003,1,\"\"],[195004,1,\"\"],[195005,1,\"\"],[195006,1,\"\"],[195007,3],[195008,1,\"\"],[195009,1,\"\"],[195010,1,\"\"],[195011,1,\"\"],[195012,1,\"\"],[195013,1,\"\"],[195014,1,\"\"],[195015,1,\"\"],[195016,1,\"\"],[195017,1,\"\"],[195018,1,\"\"],[195019,1,\"\"],[195020,1,\"\"],[195021,1,\"\"],[195022,1,\"\"],[195023,1,\"\"],[195024,1,\"\"],[195025,1,\"\"],[195026,1,\"\"],[195027,1,\"\"],[195028,1,\"\"],[195029,1,\"\"],[195030,1,\"\"],[195031,1,\"\"],[195032,1,\"\"],[195033,1,\"\"],[195034,1,\"\"],[195035,1,\"\"],[195036,1,\"\"],[195037,1,\"\"],[195038,1,\"\"],[195039,1,\"\"],[195040,1,\"\"],[195041,1,\"\"],[195042,1,\"\"],[195043,1,\"\"],[195044,1,\"\"],[195045,1,\"\"],[195046,1,\"\"],[195047,1,\"\"],[195048,1,\"\"],[195049,1,\"\"],[195050,1,\"\"],[195051,1,\"\"],[195052,1,\"\"],[195053,1,\"\"],[195054,1,\"\"],[195055,1,\"\"],[195056,1,\"\"],[195057,1,\"\"],[195058,1,\"\"],[195059,1,\"\"],[195060,1,\"\"],[195061,1,\"\"],[195062,1,\"\"],[195063,1,\"\"],[195064,1,\"\"],[195065,1,\"\"],[195066,1,\"\"],[195067,1,\"\"],[195068,1,\"\"],[195069,1,\"\"],[[195070,195071],1,\"\"],[195072,1,\"\"],[195073,1,\"\"],[195074,1,\"\"],[195075,1,\"\"],[195076,1,\"\"],[195077,1,\"\"],[195078,1,\"\"],[195079,1,\"\"],[195080,1,\"\"],[195081,1,\"\"],[195082,1,\"\"],[195083,1,\"\"],[195084,1,\"\"],[195085,1,\"\"],[195086,1,\"\"],[195087,1,\"\"],[195088,1,\"\"],[195089,1,\"\"],[195090,1,\"\"],[195091,1,\"\"],[195092,1,\"\"],[195093,1,\"\"],[195094,1,\"\"],[195095,1,\"\"],[195096,1,\"\"],[195097,1,\"\"],[195098,1,\"\"],[195099,1,\"\"],[195100,1,\"\"],[195101,1,\"\"],[[195102,196605],3],[[196606,196607],3],[[196608,201546],2],[[201547,201551],3],[[201552,205743],2],[[205744,262141],3],[[262142,262143],3],[[262144,327677],3],[[327678,327679],3],[[327680,393213],3],[[393214,393215],3],[[393216,458749],3],[[458750,458751],3],[[458752,524285],3],[[524286,524287],3],[[524288,589821],3],[[589822,589823],3],[[589824,655357],3],[[655358,655359],3],[[655360,720893],3],[[720894,720895],3],[[720896,786429],3],[[786430,786431],3],[[786432,851965],3],[[851966,851967],3],[[851968,917501],3],[[917502,917503],3],[917504,3],[917505,3],[[917506,917535],3],[[917536,917631],3],[[917632,917759],3],[[917760,917999],7],[[918000,983037],3],[[983038,983039],3],[[983040,1048573],3],[[1048574,1048575],3],[[1048576,1114109],3],[[1114110,1114111],3]]');\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb-connection-string-url/node_modules/tr46/lib/mappingTable.json?");

/***/ }),

/***/ "./node_modules/mongodb/package.json":
/*!*******************************************!*\
  !*** ./node_modules/mongodb/package.json ***!
  \*******************************************/
/***/ ((module) => {

"use strict";
eval("module.exports = JSON.parse('{\"name\":\"mongodb\",\"version\":\"6.3.0\",\"description\":\"The official MongoDB driver for Node.js\",\"main\":\"lib/index.js\",\"files\":[\"lib\",\"src\",\"etc/prepare.js\",\"mongodb.d.ts\",\"tsconfig.json\"],\"types\":\"mongodb.d.ts\",\"repository\":{\"type\":\"git\",\"url\":\"git@github.com:mongodb/node-mongodb-native.git\"},\"keywords\":[\"mongodb\",\"driver\",\"official\"],\"author\":{\"name\":\"The MongoDB NodeJS Team\",\"email\":\"dbx-node@mongodb.com\"},\"dependencies\":{\"@mongodb-js/saslprep\":\"^1.1.0\",\"bson\":\"^6.2.0\",\"mongodb-connection-string-url\":\"^3.0.0\"},\"peerDependencies\":{\"@aws-sdk/credential-providers\":\"^3.188.0\",\"@mongodb-js/zstd\":\"^1.1.0\",\"gcp-metadata\":\"^5.2.0\",\"kerberos\":\"^2.0.1\",\"mongodb-client-encryption\":\">=6.0.0 <7\",\"snappy\":\"^7.2.2\",\"socks\":\"^2.7.1\"},\"peerDependenciesMeta\":{\"@aws-sdk/credential-providers\":{\"optional\":true},\"@mongodb-js/zstd\":{\"optional\":true},\"kerberos\":{\"optional\":true},\"snappy\":{\"optional\":true},\"mongodb-client-encryption\":{\"optional\":true},\"gcp-metadata\":{\"optional\":true},\"socks\":{\"optional\":true}},\"devDependencies\":{\"@iarna/toml\":\"^2.2.5\",\"@istanbuljs/nyc-config-typescript\":\"^1.0.2\",\"@microsoft/api-extractor\":\"^7.36.4\",\"@microsoft/tsdoc-config\":\"^0.16.2\",\"@mongodb-js/zstd\":\"^1.1.0\",\"@octokit/core\":\"^4.2.4\",\"@types/chai\":\"^4.3.5\",\"@types/chai-subset\":\"^1.3.3\",\"@types/express\":\"^4.17.17\",\"@types/kerberos\":\"^1.1.2\",\"@types/mocha\":\"^10.0.1\",\"@types/node\":\"^20.5.9\",\"@types/saslprep\":\"^1.0.1\",\"@types/semver\":\"^7.5.0\",\"@types/sinon\":\"^10.0.16\",\"@types/sinon-chai\":\"^3.2.9\",\"@types/whatwg-url\":\"^11.0.0\",\"@typescript-eslint/eslint-plugin\":\"^5.62.0\",\"@typescript-eslint/parser\":\"^5.62.0\",\"chai\":\"^4.3.7\",\"chai-subset\":\"^1.6.0\",\"chalk\":\"^4.1.2\",\"eslint\":\"^8.48.0\",\"eslint-config-prettier\":\"^8.10.0\",\"eslint-plugin-import\":\"^2.28.1\",\"eslint-plugin-prettier\":\"^4.2.1\",\"eslint-plugin-simple-import-sort\":\"^10.0.0\",\"eslint-plugin-tsdoc\":\"^0.2.17\",\"eslint-plugin-unused-imports\":\"^2.0.0\",\"express\":\"^4.18.2\",\"gcp-metadata\":\"^5.2.0\",\"js-yaml\":\"^4.1.0\",\"mocha\":\"^10.2.0\",\"mocha-sinon\":\"^2.1.2\",\"mongodb-client-encryption\":\"^6.0.0\",\"mongodb-legacy\":\"^6.0.0\",\"nyc\":\"^15.1.0\",\"prettier\":\"^2.8.8\",\"semver\":\"^7.5.4\",\"sinon\":\"^15.2.0\",\"sinon-chai\":\"^3.7.0\",\"snappy\":\"^7.2.2\",\"socks\":\"^2.7.1\",\"source-map-support\":\"^0.5.21\",\"ts-node\":\"^10.9.1\",\"tsd\":\"^0.28.1\",\"typescript\":\"^5.0.4\",\"typescript-cached-transpile\":\"^0.0.6\",\"v8-heapsnapshot\":\"^1.3.1\",\"yargs\":\"^17.7.2\"},\"license\":\"Apache-2.0\",\"engines\":{\"node\":\">=16.20.1\"},\"bugs\":{\"url\":\"https://jira.mongodb.org/projects/NODE/issues/\"},\"homepage\":\"https://github.com/mongodb/node-mongodb-native\",\"scripts\":{\"build:evergreen\":\"node .evergreen/generate_evergreen_tasks.js\",\"build:ts\":\"node ./node_modules/typescript/bin/tsc\",\"build:dts\":\"npm run build:ts && api-extractor run && node etc/clean_definition_files.cjs && eslint mongodb.d.ts --fix\",\"build:docs\":\"./etc/docs/build.ts\",\"build:typedoc\":\"typedoc\",\"build:nightly\":\"node ./.github/scripts/nightly.mjs\",\"check:bench\":\"node test/benchmarks/driverBench\",\"check:coverage\":\"nyc npm run test:all\",\"check:integration-coverage\":\"nyc npm run check:test\",\"check:lambda\":\"mocha --config test/mocha_lambda.json test/integration/node-specific/examples/handler.test.js\",\"check:lambda:aws\":\"mocha --config test/mocha_lambda.json test/integration/node-specific/examples/aws_handler.test.js\",\"check:lint\":\"npm run build:dts && npm run check:dts && npm run check:eslint && npm run check:tsd\",\"check:eslint\":\"eslint -v && eslint --max-warnings=0 --ext \\'.js,.ts\\' src test\",\"check:tsd\":\"tsd --version && tsd\",\"check:dependencies\":\"mocha test/action/dependency.test.ts\",\"check:dts\":\"node ./node_modules/typescript/bin/tsc --noEmit mongodb.d.ts && tsd\",\"check:search-indexes\":\"nyc mocha --config test/mocha_mongodb.json test/manual/search-index-management.prose.test.ts\",\"check:test\":\"mocha --config test/mocha_mongodb.json test/integration\",\"check:unit\":\"mocha test/unit\",\"check:ts\":\"node ./node_modules/typescript/bin/tsc -v && node ./node_modules/typescript/bin/tsc --noEmit\",\"check:atlas\":\"mocha --config test/manual/mocharc.json test/manual/atlas_connectivity.test.js\",\"check:drivers-atlas-testing\":\"mocha --config test/mocha_mongodb.json test/atlas/drivers_atlas_testing.test.ts\",\"check:adl\":\"mocha --config test/mocha_mongodb.json test/manual/atlas-data-lake-testing\",\"check:aws\":\"nyc mocha --config test/mocha_mongodb.json test/integration/auth/mongodb_aws.test.ts\",\"check:oidc\":\"mocha --config test/mocha_mongodb.json test/manual/mongodb_oidc.prose.test.ts\",\"check:oidc-azure\":\"mocha --config test/mocha_mongodb.json test/integration/auth/mongodb_oidc_azure.prose.test.ts\",\"check:ocsp\":\"mocha --config test/manual/mocharc.json test/manual/ocsp_support.test.js\",\"check:kerberos\":\"nyc mocha --config test/manual/mocharc.json test/manual/kerberos.test.ts\",\"check:tls\":\"mocha --config test/manual/mocharc.json test/manual/tls_support.test.ts\",\"check:ldap\":\"nyc mocha --config test/manual/mocharc.json test/manual/ldap.test.js\",\"check:socks5\":\"mocha --config test/manual/mocharc.json test/manual/socks5.test.ts\",\"check:csfle\":\"mocha --config test/mocha_mongodb.json test/integration/client-side-encryption\",\"check:snappy\":\"mocha test/unit/assorted/snappy.test.js\",\"fix:eslint\":\"npm run check:eslint -- --fix\",\"prepare\":\"node etc/prepare.js\",\"preview:docs\":\"ts-node etc/docs/preview.ts\",\"test\":\"npm run check:lint && npm run test:all\",\"test:all\":\"npm run check:unit && npm run check:test\",\"update:docs\":\"npm run build:docs -- --yes\"},\"tsd\":{\"directory\":\"test/types\",\"compilerOptions\":{\"strict\":true,\"target\":\"esnext\",\"module\":\"commonjs\",\"moduleResolution\":\"node\"}}}');\n\n//# sourceURL=webpack://renderer/./node_modules/mongodb/package.json?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			id: moduleId,
/******/ 			loaded: false,
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Flag the module as loaded
/******/ 		module.loaded = true;
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = __webpack_module_cache__;
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/node module decorator */
/******/ 	(() => {
/******/ 		__webpack_require__.nmd = (module) => {
/******/ 			module.paths = [];
/******/ 			if (!module.children) module.children = [];
/******/ 			return module;
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// module cache are used so entry inlining is disabled
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	var __webpack_exports__ = __webpack_require__(__webpack_require__.s = "?5938");
/******/ 	renderer = __webpack_exports__;
/******/ 	
/******/ })()
;